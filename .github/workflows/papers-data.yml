name: Automated Uploading of Papers Data

on:
  workflow_dispatch:
  schedule:
    - cron: "0 4 * * SUN" # runs every Sunday at 04:00 UTC

jobs:
  scrape-latest:
    runs-on: ubuntu-latest
    steps:

      - name: Checkout repo
        uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.8'
      - name: Downloading Papers Dataset from Kaggle
        run: |
          python -m pip install --upgrade pip
          python -m pip install kaggle
          kaggle datasets download Cornell-University/arxiv
        env:
          KAGGLE_USERNAME: ${{ secrets.KAGGLEUSERNAME }}
          KAGGLE_KEY: ${{ secrets.KAGGLEKEY }}
      - name: Unzip Downloaded File
        uses: montudor/action-zip@v1
        with: 
          args: unzip -qq arxiv.zip -d arxiv
      - name: Moving Files to Data Upload Directory
        run: |
          ls -la
          sudo mv ./arxiv/arxiv-metadata-oai-snapshot.json ./data-upload
      - name: Installing Dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install dask[bag] --upgrade
          python -m pip install pymongo dnspython pdfplumber uuid yake
      - name: Executing Python Script to Upload Papers
        run: |
          cd ./data-upload
          python PaperUpdater.py
      - name: Adding Log Files
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git pull
          git add .
          git commit -m ":rocket: Papers Updated"
          git push
