[
{"website": "Galois", "title": "SMACCMPilot: Open-Source Autopilot Software for UAVs", "author": "Unknown", "link": "https://galois.com/blog/2013/10/smaccmpilot-open-source-autopilot-software-for-uavs/", "abstract": "As part of DARPA’s High Assurance Cyber Military Systems (HACMS), Galois is building critical flight control software using new software methods for embedded systems programming. Recently, Signal Online reported an overview of the HACMS program . We’ve been working on the HACMS program for about a year and we’d like to share more details about open source work we’ve done so far. The flagship application for the technologies we’ve developed under the HACMS program is called SMACCMPilot: a new flight controller for small quadcopter unmanned aerial vehicles (UAVs). SMACCMPilot is written in the Ivory language , a new domain-specific language for safe systems programming. We’ve built an ecosystem of libraries on top of the Ivory language, including a concurrency framework and drivers for microcontroller hardware. Ivory has a simple interface to external C code, which allows SMACCMPilot to re-use software components from the ArduCopter open source project . We’ve also implemented communications protocol stacks and control primitives in Ivory. SMACCMPilot is currently alpha-quality software as we actively develop the flight control software itself and evolve the new technologies we’ve used to build it. We’ll be continuing work on the SMACCMPilot project for the next few years. All of the software behind SMACCMPilot is open source and available on Galois’s github , and documented on the project web site . We welcome collaboration with programming languages, formal methods, and flight control researchers! For more information, contact Lee Pike and Pat Hickey .", "date": "2013-10-02"},
{"website": "Galois", "title": "Galois and voidALPHA Produce Free Game for DARPA to Help Crowdsource Software Security", "author": "Unknown", "link": "https://galois.com/blog/2014/02/galois-and-voidalpha-produce-free-game-for-darpa-to-help-crowdsource-software-security/", "abstract": "As part of DARPA’s Crowd Sourced Formal Verification (CSFV) program, Galois has partnered with game design and development experts voidALPHA to produce a free online formal verification game, StormBound . Formal verification is the most rigorous way to thwart attacks against IT systems and applications upon which military, government, and commercial organizations rely. Traditional formal methods, however, require specially trained engineers to manually scour software—a process that up to now has been too slow and costly to apply beyond small software components. In contrast, CSFV games such as StormBound translate players’ actions into program annotations and generate mathematical proofs to help verify the absence of important classes of flaws in software written in the C programming language.  We have developed an automated process that creates new puzzles for each verification problem in need of a solution. With StormBound , we aim to investigate whether large numbers of non-experts playing the game can perform formal verification faster and more cost-effectively than conventional processes. For more information, contact Aaron Tomb or Jef Bell . Approved for Public Release, Distribution Unlimited", "date": "2014-02-03"},
{"website": "Galois", "title": "Interview: Crowd-sourcing Software Verification", "author": "Unknown", "link": "https://galois.com/blog/2014/06/interview-crowd-sourcing-software-verification/", "abstract": "Aaron Tomb recently gave an interview with the Machine Intelligence Research Institute (MIRI) about what Galois is doing on DARPA’s Crowd Sourced Formal Verification (CSFV) program to crowd-source the problem of software verification. Read the article here: http://intelligence.org/2014/05/29/aaron-tomb/", "date": "2014-06-02"},
{"website": "Galois", "title": "Cryptol User’s Mailing List", "author": "Unknown", "link": "https://galois.com/blog/2009/01/cryptol-users-mailing-list/", "abstract": "Cryptol now has a mailing list for discussions: The language, the tool set, programming idioms, everthing and anything related to Cryptol. Looking forward to seeing you join us!", "date": "2009-01-29"},
{"website": "Galois", "title": "MD6 in Cryptol", "author": "Unknown", "link": "https://galois.com/blog/2009/01/md6-in-cryptol/", "abstract": "NIST is currently running a competition to come up with the next generation message hashing function that it intends to standardize and FIPS recommend upon completion (assuming one good candidate is left standing and well at the conclusion of the evaluation process): http://csrc.nist.gov/groups/ST/hash/sha-3/index.html Apart from the need to come up with better alternatives to its current recommendation, the SHA-2 family of hashing functions, this competition draws inspiration from the success that the AES competition had a couple of years ago in engaging the community in coming up with a replacement for the DES block cipher. As then, a lot of new innovation has resulted.As with block ciphers, many common types of hashing functions lend themselves well to expression in Cryptol . To demonstrate some of the features of Cryptol and how it could be used to express SHA-3 candidates, here’s one of the submissions, MD6 from the CSAIL group at MIT, headed by Ronald L. Rivest: http://groups.csail.mit.edu/cis/md6/ The goal of this writeup is twofold: Introduce you to the MD6 hashing algorithm and its construction. Expose you to the Cryptol language, and how it lends itself to expressing MD6. Ideally, you’ll come away with enthusiasm on both accounts! Setting the context We won’t try to re-count or re-express the design and implementation details of MD6 here, but assume the reader has either a basic knowledge of its structure or is able to separately consult a description of MD6 (such as its specification, a mighty fine and interesting document.) Instead, we’ll limit ourselves to presenting some code snippets representing key portions of MD6 and highlight the Cryptol features that it employs. A pointer to the complete code of MD6 in Cryptol is provided at the end, for your own use and experimentation. The MD6 hashing function mode At the toplevel, MD6 accommodates running in a number of different modes, tailored to the resources of the execution environment and external parameters like the digest output size and the number of rounds to apply each step. The implementation presented here is limited to the sequential/iterative version.The Cryptol function that implements the MD6 sequential mode of operation is md6 , having the following type: md6 : {a b c d} ( ...type constraints... ) =>\r\n( [8*a][b] // input message\r\n, [32]     // bit width of original message input (before byte-padding)\r\n, [8]      // number of rounds (104 for 256.)\r\n, [c][8]   // key (zero for hashing applications)\r\n, [32]     // output digest length (in bits.)\r\n) -> [16][64]; To explain the Cryptol type signature, let’s start at the end — the result. It is made up of 16 64-bit words. In Cryptol, [N] is the type of an N-bit wide value. You can concatenate the [] sequence type operators, so [N]Ty is the type for a sequence of N Ty values; in fact, the [N] syntax is a shorthand for [N]Bit , i.e., an N-bit wide sequence of bits. So for the above result type, [16][64] is the type of a sequence of 16 64-bit values.The inputs to the md6 function mirror those of the parameters to MD6 SEQ (see specification; Fig 2.6). The argument types make use of Cryptol’s size polymorphism via type variables; for example, the input message’s type is given as [8*a][b] . This means: a sequence with widths that are a multiple of 8 (i.e., if needs be, the input message has already been padded out to make it so.) of [b] values, i.e., b-bit wide words (for any b). Notice that we’ve left out the type constraints from the above signature. It is a somewhat long and involved for this function, but this portion of the Cryptol type signature let’s you state constraints that must hold for type variables, like: select5 : {a b} ( a >= 5 ) => [a]b -> b;\r\nselect5 xs = xs@4; The indexing operator @ better be restricted to sequence values that have at least 5 elements, which is what the type constraint expresses here. If you try to evaluate select5 with the Cryptol interpreter for narrower sequence, you’ll see something like this: Cryptol> :l \"select.cry\"\r\n...\r\nSelect> select5 [1 2 3]\r\n[\"command line\", line 1, col 1 \"select.cry\", line 1, col 13]:\r\nInferred size of 3 is too small - expected to be >= 5\r\nSelect> select5 [1..10]\r\n0x5\r\nSelect> That’s just a flavor of Cryptol’s type system; it is capable of expressing the shape and sizes of the data you manipulate quite precisely and with some sophistication. Like size polymorphism for the md6 mode function signature, letting you use type variables instead of concrete sizes, but in a constrained manner. The size preconditions that must hold for an argument to a function like md6 are separately specificed using type constraints.Notice that Cryptol is able to infer the most general type for most definitions and values, so writing out the type signature is optional. But due to its compact and precise nature, it provides valuable documentation that’s worth including alongside its definition. One popular way of using the type inference mechanism is to have Cryptol come up with the initial type for a definition, which you then copy in and use. Indeed, that was how the md6 type signature ended up being derived!Enough on types for now; time to get to grips with the bit and word values that md6 work over. The MD6 mode of operation MD6 defines its toplevel, mode-of-operation as follows: md6 (msg,wi,rnds,ks,digLen) = compress(last_chunk, rnds)\r\nwhere {\r\n// The final 89-word chunk to compress:\r\nlast_chunk = qs # key # [uu vv] # r # last padMsg;\r\nr = cs @ (width(padMsg) - 1);\r\n// sequential mode of operation, each compression round\r\n// is fed into the next (cf. the 'c <- cs' knot-tying below.)\r\ncs = [c0] # [| compress((qs # key # [u v] # c # b), rnds)\r\n|| c <- cs || u <- us || v <- vs || b <- padMsg |];\r\n...\r\n}; MD6 iteratively operates on chunks of 89 64-bit values, each chunk made up out of internal state, the chained output from the previous “round” (this being the sequential, Merkle-Damgaard rendition of the algorithm.) The result is one final application of the diffusion function compress on the last of these chunks ( last_chunk .) We won’t drill down here into detail about how that final chunk is constructed, but the syntax of last_chunk ‘s Cryptol definition merits some unscrambling: last_chunk = qs # key # [uu vv] # r # last padMsg; i.e., it is a sequence constructed by the concatenation of number of sub-sequences ( # is the Cryptol concatentation operator); the constant Q sequence (see spec), an (optional) key, the control words U and V, and the final portion of the suitably padded input message. Preceding it is r , which is the output of the (last-1) chained compression steps. That value ( r ) is computed by taking the last element of the cs sequence: // sequential mode of operation, each compression round\r\n// is fed into the next (cf. the 'c <- cs' knot-tying below.)\r\ncs = [c0] # [| compress((qs # key # [u v] # c # b), rnds)\r\n|| c <- cs || u <- us || v <- vs || b <- padMsg |]; It is defined using Cryptol’s parallel sequence comprehensions, prefixed by the initial value/chunk (IV) c0 . The function compress is computed for each element, with the desired chaining of output from one compress invocation being fed into the next through the use of the recursive use of cs in one of the “arms” of the comprehension.Recursive sequences allow us to capture stateful computations in Cryptol without the explicit mentioning of registers or an internal state being iteratively updated. It is a common “functional” / declarative idiom used in Cryptol code, using such sequences to express chaining/feedback.As c0 , which can be likened to the initial state of the mode function, is initially prefixed to cs , the recursive definition will produce values for any N , i.e., element N can be computed only by knowing the value of the sequence element (N-1) — not N itself nor successive elements. The number of elements in this comprehension is equal to the length of the shortest of its “arms”. In the above, that would be the padded-out sequence of message chunks.The net effect being that the md6 mode function will iterate over all the chunks of the input message, applying at each step the compression function to the internal state and the chained output from the previous step. To finalize and generate output, the compress function is called again on the final element.The construction used by this MD6 mode (i.e., it’s not the only one, alternative versions are supported by the spec.) is standard. Indeed, we could easily re-factor the md6 function to have it be parameterized over the compression function to call at each step. The resulting chained-mode function could then be instantiated by any algorithm that uses the same mode-of-operation, but furnishing their own compression/diffusion function.Back to MD6 in Cryptol, expressing the compression function is next. The compress function At the heart of MD6 is the function that compresses/diffuses the incoming message, called repeatedly by the chained mode in the previous section. Like with md6 , let’s first consider its Cryptol type: compress : ([89][64],[8]) -> [16][64]; A function of two arguments, the first being the message block/chunk to process, which consists of 89 64-bit words. The second argument is the number of rounds to iterate over that chunk. For 512-bit digest outputs, the suggested number of rounds is 168.The result is 16 words wide. The function is expressed as follows in Cryptol: compress (chunk,r) = as @@ outs\r\nwhere {\r\nas = chunk # [| cf (a,b,c,d)\r\n|| a <- ss || b <- a_ts\r\n|| c <- rs || d <- ls |];\r\ncf (s_i,a_i,r_i,l_i) = x3\r\nwhere {\r\nx1 = s_i ^ a_i;\r\nx2 = x1 ^ (x1 >> r_i);\r\nx3 = x2 ^ (x2 << l_i);\r\n};\r\na_ts = [| a ^ b ^ (c & d) ^ (e & f)\r\n|| a <- as || b <- drop(n-t_0,as)\r\n|| c <- drop(n-t_1,as) || d <- drop(n-t_2,as)\r\n|| e <- drop(n-t_3,as) || f <- drop(n-t_4,as) |];\r\nouts : [16][32];\r\nouts = [| (t + 89 - 16 + x) || x <- [0 .. 15] |];\r\nt : [32];\r\nt = (r # zero) * (c # zero);\r\nc : [8];\r\nc = 16;\r\nn : [8];\r\nn = 89;\r\n}; The final 16 word result is produced by applying the @@ operator, which indexes its first argument sequence value by the indices from the second. The MD6 compression function slides a window across its input chunk, so in this case the result is the last 16 words in that window — see the MD6 spec for details about the portion that outs selects.The as sequence is defined using a common Cryptol idiom, the parallel sequence comprehension: as = chunk # [| cf (a,b,c,d) || a <- ss || b <- a_ts || c <- rs || d <- ls |]; Its first element is the input chunk, followed by sequence values of equal chunk width, each computed by applying the function cf to successive elements of four generator sequences, ss , a_ts , rs , and ls . Apart from a_ts , these are constant-valued sequences that the MD6 specification defines. a_ts is rather more interesting, another parallel sequence comprehension: a_ts = [| a ^ b ^ (c & d) ^ (e & f)\r\n|| a <- as || b <- drop(n-t_0,as)\r\n|| c <- drop(n-t_1,as) || d <- drop(n-t_2,as)\r\n|| e <- drop(n-t_3,as) || f <- drop(n-t_4,as) |]; It is recursively defined in terms of the above as sequence value, i.e., to compute element I it reaches ‘back’ at previous values at 5 different positions of the ‘as’ sequence, as determined by the tap positions t_X ( 0 =< X <= 5) that MD6 specifies. In the words of the specification, a_ts implements a non-linear feedback shift register . The drop(Num,Seq) Cryptol built-in operator returns the sequence Seq , but with its first Num elements chopped off. In the above, n is the constant chunk size, 89. The values from these different positions are then combined together by simple (and hardware efficient) composition of word-sized bit operators.The result of compress is then the final 16 words of the as sequence. The length of the as sequence is determined by the number of iterations or rounds to perform, r .That’s it – a tidy and simple compression function at the heart of MD6. Its expression in Cryptol is, we hope, reasonably clear and close to the specification.What’s really gained from using Cryptol here? From a programming perspective, having the backing of its sized type system lends great help wrt. correctness and consistency of the word-level operations. The resulting declarative Cryptol program has a number of follow-on benefits though: to generate and derive an efficient hardware implementation (for mapping to FPGAs, perhaps). The types aid the generation of this hardware mapping. But, more importantly, use of the recursive sequence idiom allows the Cryptol implementation to infer how to effectively ‘render’ the function in hardware, mapping the feedback loop to a register-based design. as input to Cryptol’s C code generator to output C code for embedding into other codebases. to check correctness of the generated implementations by using Cryptol’s symbolic verification support. for prototyping and ‘playing around’ with ideas and variations of MD6. Cryptol’s equivalence checking support can help you determine if the transformations you do to one maintain equivalence with previous versions. to check equivalence between this Cryptol ‘specification’ and other, non-Cryptol implementations in either C or VHDL. Cryptol’s toolchain is able to symbolically execute code in either language, followed by the equivalence checking them via SAT solvers. Being nice and high-level isn’t the goal (but we don’t mind! 🙂 ), but using Cryptol to help the hard work of generating algorithms that are correct and possibly high-performing. Cryptol sample implementation The Cryptol files making up the MD6 implementation is available for download via the Galois Cryptol pages as a .zip archive . To use the code, simply load it in: Cryptol> :load \"MD6.cry\"\r\n...\r\nMD6> t1 // runs the t1 test, see MD6/Tests.cry.\r\nTrue\r\nMD6> Please fire up an editor to have a look at the various “.cry” files. Next up: Skein If that left you wanting more, the next Cryptol blog entry will present a reference implementation for another SHA-3 candidate, Schneier et al.’s Skein . Stay tuned. Author (\"Sigbjorn Finne\" # \"Galois, Inc\" # \"2009-01-23\") : [35][8]", "date": "2009-01-24"},
{"website": "Galois", "title": "Verifying ECC Implementations", "author": "Unknown", "link": "https://galois.com/blog/2012/03/verifying-ecc-implementations/", "abstract": "Last Thursday, the University of Bristol posted a press release and paper describing a way to exploit a bug in version 0.9.8g of OpenSSL and extract the value of a private key. The bug was known, and has been fixed in recent versions of OpenSSL (0.9.8g was released in 2007, and 0.9.8h fixed the bug in 2008), but an exploit was not previously known, and version 0.9.8g is still in production use. The bug was in the modular reduction algorithm, used in the implementation of Elliptic Curve Cryptography (ECC), particularly the Elliptic Curve Diffie-Helman (ECDH) and Elliptic Curve Digital Signature Algorithm (ECDSA) code. These algorithms can be used to agree on shared encryption keys to implement the Secure Sockets Layer (SSL) used to encrypt HTTP transactions. An attacker who could discover the agreed-upon encryption key could therefore eavesdrop on secure web transactions. The authors of the Bristol paper use the bug and associated exploit as an argument for the formal verification of key security components such as OpenSSL. Galois has long been a strong advocate for this position, and much of our formal methods work has been directed at establishing information assurance properties of security-critical software. As we describe below, our work recently used formal methods to prove the equivalence of a Java ECDSA implementation and a reference specification, discovering in the process that our Java implementation shared a very similar bug. During 2011 we developed a high-speed Java implementation of ECDSA with the intent of formally proving its equivalence to a reference specification written in Cryptol , the domain-specific language we have developed for the high-level description of cryptographic algorithms. As a validation step, we confirmed the implementation generated the correct hashes for NIST test vectors, and subjected the implementation to one hundred thousand randomly-generated test vectors to ensure the property that the signature verification algorithm always succeeded on messages properly signed by the signature algorithm. In January 2012, we completed the verification of our Java ECDSA implementation (with respect to our Cryptol specification) and in the process discovered a bug in our own implementation of the same modular reduction algorithm that led to the vulnerability in OpenSSL. Our verification process used a symbolic simulation tool for Java that we built during 2010 and 2011, and was able to discover a bug that had evaded our validation strategy based on testing. To obtain empirical evidence of the difficulty of testing algorithms such as ECDSA, we ran the buggy implementation through millions of test vectors to determine how long it would take to discover the bug through manual testing alone. For the bug in our ECDSA implementation, we were able to reproduce the bug after running 600 thousand sign/verify test vectors, which amounted to more than 8 billion field reductions.  The OpenSSL bug is even more rare, and should cause incorrect results for less than one out of every 2 29 test vectors.  Despite the rarity of the bug, the OpenSSL bug was exploitable through an adaptive attack against the SSL server. Our formal verification results show that our Java ECDSA implementation corresponds to the specification for all 2 1152 legal inputs to ECDSA signing, and 2 1920 legal inputs to ECDSA signature verification.  Although the possibility still remains that the specification is incorrect, or the implementation is vulnerable to side channel attacks, the OpenSSL ECDSA bug shows that security can be compromised even if the bug only affects a very small fraction of the overall input space. There simply is no alternative to formal verification for comprehensive coverage of input spaces this large.", "date": "2012-03-07"},
{"website": "Galois", "title": "High-Assurance Base64", "author": "Unknown", "link": "https://galois.com/blog/2013/09/high-assurance-base64/", "abstract": "Author: David Lazar Galois’ mission is improving the trustworthiness of critical systems. Trustworthiness is an inherent property of a system, but we need to produce evidence of its trustworthiness in order for people to make informed decisions. The evidence, and its presentation is a key part of what is often called an assurance case . The kinds of evidence that make up an assurance case can differ, depending on how critical the system is. The more critical, the more thorough and convincing the assurance case should be. Formal methods — mathematical proofs of software correctness — are often called for when evaluating the most critical systems. A formal method approach to assurance produces a strong argument about a model of the system. In contrast, testing produces a weak argument about the system itself. The reason it is a weak argument is that for any non-trivial component, testing will only exercise a minuscule percent of the possible input space. In contrast, a formal proof says that for a model of the system, some property holds for all inputs . Phrased this way, it’s clear that testing and formal evidence provide complementary evidence of a system’s correctness. In this post we describe a fast, formally verified C implementation of Base64 encoding. The 10,000 foot description of the proof approach is: choose the system, create a formal specification of the system, create a model of the implementation, and prove that the implementation meets the specification. The code and proof are available here: https://github.com/davidlazar/base64 The following sections describe the different parts of this repository. The C Code The C code in base64encode.c is a fast implementation of Base64 encoding. It is based on libb64 , which uses coroutines to achieve speed. The nontrivial control-flow of this code makes proving it correct more challenging. This is the artifact we want to develop assurance evidence for. Typing “make” at the top of our repository builds the b64enc tool, a simple frontend to the C code. Here is a quick timing comparison between our code and the base64 utility that is part of GNU Coreutils: $ time b64enc 500MB.random > x.b64\r\nreal: 1.197s  user: 0.61s  cpu: 0.48s\r\n\r\n$ time base64 -w0 500MB.random > y.b64\r\nreal: 2.615s  user: 1.81s  cpu: 0.62s\r\n\r\n$ diff -w x.b64 y.b64\r\n$ The Cryptol Specification The Cryptol specification in base64.cry is based on RFC 4648 . Ignoring padding and assuming Cryptol is in big-endian mode, the encoding routine is just two lines: encode : {a c} (fin a, c == (8 * a + 5) / 6, 6 * c >= 8 * a) =>\r\n        [a][8] -> [c][8];\r\nencode xs = [| alphabet @ x || x <- groupBy(6, join xs # zero) |]; The corresponding decode function is similarly short. The b64encode and b64decode functions are wrappers around encode and decode that handle padding. Our specification provides the following correctness theorem, polymorphic over all lengths of x : theorem b64encodeLeftInv: {x}. b64decode (b64encode x) == x; Cryptol can’t prove polymorphic theorems on its own, so we must monomorphize the theorem to prove it: base64> :prove (b64encodeLeftInv : [16][8] -> Bit)\r\nQ.E.D.\r\n\r\nbase64> :prove (b64encodeLeftInv : [200][8] -> Bit)\r\nQ.E.D. The Proof This proof/ subdirectory contains infrastructure for proving the C code correct. The Makefile in this directory orchestrates the proof. Typing make n=16 generates and proves a theorem that says the base64_encode function from the C code (as compiled by Clang) is equivalent to the b64encode function in the Cryptol specification for the given input length n : $ make n=16\r\nProving function equivalent to reference:\r\nencode_aig : [16][8] -> [24][8]\r\nQ.E.D. Let’s see what the Makefile is doing behind the scenes. The C code in sym_encode.c is a wrapper around our C code that passes a symbolic value to the base64_encode function. This code is compiled by Clang to LLVM bytecode. The LLVM Symbolic Simulator (a prototype tool currently under development by Galois) is used to extract a formal model encode_aig of the LLVM bytecode. The model can be loaded into Cryptol and used like any other function: proof> :t encode_aig\r\nencode_aig : [16][8] -> [24][8]\r\n\r\nproof> encode_aig \"16 characters...\"\r\n\"MTYgY2hhcmFjdGVycy4uLg==\" In particular, we can write a theorem about this function: theorem MatchesRef : {x}. encode_aig x == b64encode x; …and then prove it: proof> :prove MatchesRef\r\nQ.E.D. Success! Amazingly, this proof systems scales to large values of n where exhaustive checking is not feasible: $ time make n=1000\r\nProving function equivalent to reference:\r\nencode_aig : [1000][8] -> [1336][8]\r\nQ.E.D.\r\nreal: 17.882s  user: 16.31s  cpu: 1.50s Summary The success of the proof gives us high confidence that our C code is correct. To reiterate our steps: choose the system — we chose Base64 encode, create a formal specification of the system — we did this with a few lines of Cryptol, create a model of the implementation — we used our LLVM Symbolic Simulator to generate the model from the C code , and prove that the implementation meets the specification — to do this, the Cryptol tool calls out to a SAT solver to prove the AIGs are equivalent. The weak-link of many approaches to using formal methods applied to the software correctness challenge is the model-to-code correspondence. The approach we took above addresses that weakness by automatically generating the model via symbolic simulation of a low-level representation of the program — in this case, the LLVM bytecode. This approach would miss bugs or malware in the path from LLVM to executable, but remains a compelling argument for the correctness of the C code. In critical applications, it makes sense to include the compiler in the scope of an overall assurance case.", "date": "2013-09-11"},
{"website": "Galois", "title": "Building a business with Haskell: Case Studies: Cryptol, HaLVM and Copilot", "author": "Unknown", "link": "https://galois.com/blog/2010/12/building-a-business-with-haskell-case-studies-cryptol-halvm-and-copilot/", "abstract": "During BelHac , the Ghent Haskell Hackathon in November, we took an afternoon session for a “Functional Programming in Industry” impromptu workshop. The following are slides I presented on Galois’ experience building a business using our functional programming expertise, in particular, Haskell. The talk describes three case studies where “functional thinking” helped shape the solution to the client’s problem, whether via types, semantics, abstractions or otherwise. The examples are taken from the Cryptol , Embedded Systems and Secure Networking research programs at Galois. A PDF of the slides are also available. Building a business with Haskell: Case Studies: Cryptol, HaLVM and Copilot More about functional programming at Galois…", "date": "2010-12-10"},
{"website": "Galois", "title": "GHC Nominated for Programming Language Award", "author": "Unknown", "link": "https://galois.com/blog/2010/01/ghc-nominated-for-programming-language-award/", "abstract": "ACM SIGPLAN recently announced a new award: The SIGPLAN Programming Languages Software Award is awarded to an institution or individual(s) to recognize the development a software system that has had a significant impact on programming language research, implementations, and tools. The impact may be reflected in the wide-spread adoption of the system or its underlying concepts by the wider programming language community either in research projects, in the open-source community, or commercially. The award includes a prize of $2,500. I think that GHC (Glasgow Haskell Compiler) and the two Simons (Peyton Jones and Marlow) are prime candidates for this. So, being careful to stay within the 500 word limit, I submitted a nomination statement for GHC as follows: For the last decade, Haskell has been at the center of the most exciting innovations within programming languages, with work on software transactional memory, generalized algebraic data types, rank-N polymorphism, monads, multi-parameter type classes, embedded domain-specific languages, property-based testing, data parallelism, thread-profiling, and so on, generating hundreds of research papers from many diverse research groups.GHC, the Glasgow Haskell Compiler, is the vehicle that made this research possible.It is hard to explore radical ideas on real systems, yet the GHC team created a flexible platform that allows other researchers to explore the implications of their ideas and to test whether they really work in the large. From the first beta release in 1991, GHC emphasized collaboration and open “bazaar” style development, as opposed to the “cathedral” development of most of its contemporaries. GHC was open source even before Linux made open source cool. GHC has continued in the same vein, now listing over 60 contributors to the codebase.In those early days, efficient compilation of a higher-order, allocation-rich, lazy functional language seemed to be a pipe dream. Yet GHC has risen to be a top-flight performer in the online language performance shootout (shootout.alioth.debian.org), comparable with Java Server-6, and approaching native C in performance overall. This is a tribute to the incredible amount of profound optimization built into the compiler, with techniques like cross-module code migration, unboxed data types, and automated removal of intermediate data structures, all done through correctness-preserving transformations that exploit the algebraic simplicity of Haskell terms, even in the presence of monadic effects.The impact GHC has had on programming language research would be sufficient to merit an award by itself, but GHC is having a corresponding influence in industry. By showing the feasibility of purely functional, statically-typed programming in the large, GHC Haskell has also had clear influence on many of the newest generation of languages, such as C#, F#, Java Generics, LINQ, Perl 6, Python, and Visual Basic 9.0. As Soma Somasegar, Microsoft Developer Division Chief, said in 2007, “One of the important themes in programming languages over recent years has been a move to embrace ideas from functional programming, [which] are helping us address some of the biggest challenges facing the industry today, from the impedance mismatch between data and objects to the challenges of the multi-core and parallel computing space.”GHC now supports a burgeoning professional Haskell world. The O’Reilly book Real World Haskell, targeted to professional programmers and oriented to GHC, was published in 2008. It went on to win the Jolt Award for best technical book of the year. In 2009 there were 3500+ Haskell package updates, with more than 100,000 package downloads in November alone. GHC is now used across the financial sector in institutions like Credit Suisse and Standard Chartered Bank, and for high assurance software in companies like Amgen, Eaton, and Galois. Some of these companies came together in 2009 to create the Industrial Haskell Group, whose purpose is to ensure the health and longevity of GHC. 499 words. Whew! There is so much that could be said, but let’s hope this is enough. I think the case is very strong, and both Simon’s deserve honor and accolade for their work. Thank you both so much!", "date": "2010-01-06"},
{"website": "Galois", "title": "Engineering Large Projects in Haskell: A Decade of FP at Galois", "author": "Unknown", "link": "https://galois.com/blog/2009/04/engineering-large-projects-in-haskell-a-decade-of-fp-at-galois/", "abstract": "Galois has been building systems in Haskell for the past decade. This talk describes some of what we’ve learned about in-the-large, commercial Haskell programming in that time. ( Download slides :: .pdf). When and where we use Haskell Correctness, productivity, scalabilty, maintainability What language features we like: types, purity, types, abstractions, types, concurrency, types! The Haskell toolchain: FFI, HPC, Cabal, compiler, libraries, build systems, etc. Being a commercial entity in a largely open source community This talk was presented Monday 20th April at λondon HUG.", "date": "2009-04-27"},
{"website": "Galois", "title": "Trustworthy Voting Systems", "author": "Unknown", "link": "https://galois.com/blog/2009/03/trustworthy-voting-systems/", "abstract": "Accurate and reliable elections are a critical component of an effective democracy. However, completely secure and trustworthy voting procedures are difficult to design, and no perfect solutions are known. Ideally, a trustworthy voting system should guarantee both verifiability (the ability to prove that the counted vote matches the submitted ballots) and privacy (the inability to link the contents of a vote with the voter who cast it).These guarantees may now be achievable. Many researchers have proposed voting protocols that achieve verifiability and privacy in theory, and a few do so under assumptions that are satisfied by current election practices. Most of the protocols involve posting an encrypted version of the contents of every ballot in some public place (likely a web site), and depend on the properties of cryptographic operations to achieve privacy while allowing anyone to verify the final tally.Now that practical, secure voting protocols exist, the time has come to bring them into use. One existing solution that comes close to achieving these goals while retaining compatibility with current voting practices is the Scantegrity II system. It has the advantage that it can operate under current US election conditions, without requiring any modification to existing optical ballot scanners, and with very little change to the individual voting process.However, the software used in this system is only a prototype, with a number of shortcomings. Voter privacy depends on ability of a computer system to keep a key database completely secret, and accurate vote counting depends on the correct implementation of complex cryptographic algorithms. The software is tens of thousands of lines of code, and as with any other software of that size, many bugs certainly exist.We believe that the importance of trustworthy election results and the past lack of success in creating reliable solutions warrants a new approach to the design of voting systems. In particular, we advocate a class of techniques known as formal methods that allow us to make precise mathematical assertions about how software should behave, and determine whether it satisfies those assertions. Government agencies within the Department of Defense make use of formal methods to ensure the reliability of important computer systems, and the draft update to the development standards used by the Federal Aviation Administration, DO178C , includes provisions for the use of formal methods. Voting systems deserve similar care. One Approach Formal Methods Software designers employ a number of techniques to combat the difficulty of producing correct software. At the simple extreme, running the software directly through a few scenarios that match expected operating conditions and observing the results can help eliminate egregious mistakes, but does little to prevent subtle mistakes or malicious attacks. Most software, including that in existing voting machines, undergoes little more than this preliminary sanity checking.The goal of formal methods is instead to prove that a piece of software necessarily behaves properly under all possible circumstances. The first step toward this goal is to make a connection between the concrete software and some well-defined mathematical model. It can be possible to extract a model directly from the concrete software. Alternatively, software architects can build the model first, and derive the concrete software from the mathematical abstraction.In either case, the connection between the model and the concrete software should be such that a proving a property of the model guarantees that the property holds of the software. A Formal Model of the Voting Process We advocate developing a formal model of the complete pipeline of voting events, including ballot creation, vote marking, ballot recording or scanning, ballot aggregation and counting, and final certification. If described appropriately, in a fully-executable language, portions of this formal model can be used directly in a software implementation. This method of software development also makes feasible a wide variety of techniques to gain confidence in the correctness of the software, potentially including a complete formal proof of correctness for key components. It has the additional benefit of allowing us to make confident statements about the security and reliability of the non-computerized stages of the process.The Voluntary Voting System Guidelines recommendation released in 2007 by the National Institute of Standards and Technology makes significant steps toward a formal definition of voting, going as far as including UML process diagrams and mathematical descriptions of a few important properties. We advocate taking this work a step farther, and describing as much of the process as possible in a precise, formal, and machine-readable language. High-Assurance Cryptography Voting protocols that provide simultaneous guarantees of integrity and privacy typically depend heavily on the properties of cryptographic algorithms. While, in theory, these algorithms transform data in ways that achieve the properties necessary for trustworthy voting, it is absolutely critical that the algorithms be implemented properly. Recent work has made significant progress toward high-assurance cryptography. Researchers at Stanford have done work to formally verify that Java code implementing a cryptographic algorithm matches a specification written in a functional language. Galois’ own programming language, Cryptol , is also a functional language, designed specifically for implementation of cryptographic algorithms at a high level of abstraction, and also allows the high-level specification to be proven equivalent to code generated in C or VHDL. The use of a functional language in both approaches allows developers to describe cryptographic algorithms in a form that closely resembles their mathematical specification, making it significantly easier to gain confidence in their correctness.The existence of these approaches demonstrates the feasibility of high-assurance implementations of cryptographic algorithms. These specific technologies may or may not be the most appropriate solutions for a standard, highly trustworthy voting system, but they show that such a system can be built. Guaranteed Privacy Secure voting protocols often depend on the secrecy of certain pieces of information to protect voter privacy. To prevent vote buying and voter intimidation, it must be infeasible to prove that a specific voter cast a particular vote. Technology exists to provide this guarantee, as well. Work on cross domain solutions has resulted in a number of highly trustworthy systems. As an example, Galois’ Trusted Services Engine (TSE) includes a software component that enforces strong separation between different information domains. A formal proof of correctness, designed for evaluation at EAL6 , guarantees that private information can never be accessed by unauthorized parties. General Dynamics also has a whole suite of products aimed at this market.In the context of voting systems, a cross domain component could be used to protect the database used to generate ballots. This database could be inaccessible to any human user, while still allowing auditors, and even the general public, to view the data necessary to tally votes, and verify that any particular vote was recorded correctly. Though these existing systems, as they stand, may not be  entirely appropriate for use in a voting system (none of them are available to the general public, for instance) they do show that it is feasible to gain a high degree of assurance in the separation of secret and public data. Openness Because of the importance of voting to an effective democracy, and the temptations to subvert the process, we believe that transparency is essential. Therefore, we advocate that all software source code, design documents, and assurance artifacts involved in a voting system be made freely available to the public (either in the public domain or under an OSI-approved open source license). In particular, any interested party should be able to obtain the source code and use it to build executable software identical to that stored in the voting systems in use. Conclusion We argue that a key component of a secure voting system is trustworthy software that is developed using the best known assurance techniques and completely open to public inspection. In addition, the essence of the voting process should remain software independent, in that a manual recount should always be possible. Higher software reliability should make the necessity of a hand recount less common, but software should never be designed in such a way that a hand recount is impossible, or even more difficult than it would be in a completely manual election.", "date": "2009-03-02"},
{"website": "Galois", "title": "Orc in Haskell, now on Hackage", "author": "Unknown", "link": "https://galois.com/blog/2010/06/orc-in-haskell-now-on-hackage/", "abstract": "Orc is a concurrent scripting language, now available as an embedded DSL in Haskell. I like to think of Orc as the combination of three things: many-valued concurrency, external actions (effects), and managed resources, all packaged in a high-level set of abstractions that feel more like scripting rather than programming. It provides a very flexible way to manage multiple concurrent actions, like querying remote web sites, along with timeouts and default actions.Source code is available on Hackage; the easiest way to access it is with cabal (i.e. ‘cabal install orc’).Also available is a draft paper entitled Concurrent Orchestration in Haskell which explains how to use Orc, as well as describing the implementation in detail.Feedback welcome. Enjoy!", "date": "2010-06-14"},
{"website": "Galois", "title": "cabal-dev: sandboxed development builds for Haskell", "author": "Unknown", "link": "https://galois.com/blog/2010/12/cabal-dev-sandboxed-development-builds-for-haskell/", "abstract": "Performing consistent builds is critical in software development, but the current system in GHC/ Haskell of per-user and per-system GHC package databases interferes with this need for consistency. It is difficult to precisely identify the dependencies of a given project, and changes necessary to enable one project to build may render another project inoperable. If each project had a separate package database, each project could be built in a sandbox. Galois has released cabal-dev :  a tool for managing development builds of Haskell projects within sandboxes. Both cabal-install repositories and sandboxed ghc package databases are used to prevent interactions between disparate projects, or user package databases. cabal-dev is similar to capri , which was coincidentally developed concurrently. The two projects take slightly different approaches to sandboxing, and exhibit slightly different behaviors depending on the state of the global package database, and the versions of the tools installed. For most packages, just use cabal-dev instead of cabal, and you will get a sandboxed build that will not install anything (even automatically installed dependencies) into the user or global ghc package databases. If your build depends on patched or unreleased libraries, you can add them to your sandboxed build environment so they can be installed by cabal-dev or cabal by running: > cabal-dev add-source /path/to/source/code Where /path/to/source/code is either a path to a source directory containing a .cabal file, or an sdist tarball.Cabal-dev has been in use at Galois for roughly six months now, but it should currently be treated as alpha software: we’ve exercised a few execution paths heavily, but it still has a number of rough edges.Cabal-dev is hosted on hackage and git-hub . A brief tutorial can be found in the README.md .", "date": "2010-12-20"},
{"website": "Galois", "title": "Galois Awarded DHS Project: Roots of Trust for Mobile Devices", "author": "Unknown", "link": "https://galois.com/blog/2013/09/galois-awarded-dhs-project-roots-of-trust-for-mobile-devices/", "abstract": "Galois is delighted to announce that our proposal “Practical Roots of Trust for Mobile Devices” has been selected for award by the Department of Homeland Security . In this Phase I Small Business Innovative Research (SBIR) award, Galois will be investigating methods to provide secure yet practical methods for mobile devices to authenticate to critical systems. This work builds on Galois’ expanding experience in mobile device security, including our previous work with SRI and United States Marine Corps . Contact Leah Daniels at 503-808-7152 for more information.", "date": "2013-09-23"},
{"website": "Galois", "title": "Galois Awarded Phase II SBIR with Office of Naval Research: Programmer Intention Capture Tool (PICT)", "author": "Unknown", "link": "https://galois.com/blog/2013/09/galois-awarded-phase-ii-sbir-with-office-of-naval-research-programmer-intention-capture-tool-pict/", "abstract": "Galois has been selected by the Office of Naval Research (ONR) for a Phase II Small Business Innovative Research (SBIR) award, for its PICT tool that interactively captures and manages programmers’ intentions. The design of a software product often isn’t fully captured by the semantics and syntax of the language – many aspects of the design reside in documents, in the heads of programmers, and other places not easily analyzed. PICT is a mechanism to capture these programmer “intentions” in such a way that static analysis tools can be guided to check how the code and these intentions match up. By providing a mechanism for essentially scripting static analysis methods, we reduce the difficulty of taking advantage of them to analyze code for a wide variety of intentions. Contact Leah Daniels at 503-808-7152 for more information.", "date": "2013-09-23"},
{"website": "Galois", "title": "Galois Working with SRI on Trustworthy Mobile Device for USMC", "author": "Unknown", "link": "https://galois.com/blog/2013/04/galois-working-with-sri-on-trustworthy-mobile-device-for-usmc/", "abstract": "SRI announced this week that, with Galois’ help, it is beginning final development of a trusted mobile device for the U.S. Marine Corps. Galois is pleased to be working with SRI on improving the trustworthiness of commercial mobile phones. Read more about it here .", "date": "2013-04-12"},
{"website": "Galois", "title": "2019: Year in review", "author": "Unknown", "link": "https://galois.com/blog/2020/01/2019-year-in-review/", "abstract": "2019 marked another eventful year for Galois, publishing 15 papers, sharing 26 talks, and announcing several large project awards. It seems cliche, but it’s true: our partners and collaborators play a central role in all of our work. We’re very grateful to be part of such a great community. Below, we highlight some of the contributions we made in 2019. Overview 2019 was another eventful year for the technical area of secure computation . We announced a $15 million partnership with IARPA to make secure computation, the process of working with data without ever exposing it, accessible to data scientists and other programmers who are not experts in cryptography. We continued to demonstrate and discuss the practical uses of secure computation through numerous talks and publications. We also spoke about using differential privacy to analyze data without revealing information about individuals. This year, we kicked off a public hardware red-teaming effort at DEF CON to evaluate the security of DARPA SSITH processors, which aim to protect systems against classes of hardware vulnerabilities exploited through software. The red-teaming effort seeks to allow hackers to perform their own security evaluations on mock demonstration systems of the hardware prototypes. Secure processors would address a critical area of concern for DoD and industrial users alike: hardware vulnerability attacks. In the area of software correctness , we continue to collaborate with Amazon Web Services (AWS) to verify the correctness of security-critical cloud infrastructure. We spoke about model-driven testing approaches used to find and remediate high-priority bugs in key software used to communicate with hardware security modules (HSMs). We also shared a significant number of talks and publications on formal verification, programming language design, type theory, and other programming language concepts. Additionally, we launched Muse Dev , a spin-off company focused on developing tools that help you find critical bugs early in the development process. Muse Dev is serving a number of early, private beta customers. We have shared a number of talks that illustrate the problems the Muse Dev team is tackling. Relating to cybersecurity , we announced a $8.6 Million contract awarded as part of DARPA’s CHESS program to build a cyber reasoning tool for vulnerabilities . We have partnered with Harvard University and Trail of Bits and aim to build scalable and more cost-effective tools that identify hard-to-find vulnerabilities. The team behind our elections security spin-off, Free & Fair , partnered with Microsoft’s Defending Democracy program to develop and release the ElectionGuard SDK . ElectionGuard is a software development kit that enables end-to-end verifiable elections technology. It is open source and available for anyone to use and deploy. As we tackled that exciting work, the health of the Galois community was a major focus for us in 2019. We strive to improve how we work together. Among other things, this year we reevaluated parental leave, making it 16 weeks for all new parents, and pursued an increased focus on ensuring an inclusive workspace and company activities . On Life at Galois , we share details about how we organize ourselves, which we consider to be a staple of our well-being at Galois. We added some fun ‘color’ relating to our role of Project Lead at Galois and what it entails. Below you’ll find links to the papers, talks, and other public contributions we made in 2019, as well as other miscellaneous news. We hope you find something interesting. From all of us at Galois, we wish you a happy 2020. High Assurance Cryptography Assuring Real-World Differential Privacy , FMfSS Dr. José Manuel Calderón Trilla and Dr. Scott Moore gave a talk on differential privacy at the Workshop on Formal Methods for Statistical Software (FMfSS). The talk described motivations behind using differential privacy to analyze data without revealing information about individuals, and gave an overview of approaches to verifying that differential privacy implementations are correct. RAMPARTS: A Programmer-Friendly System for Building Homomorphic Encryption Applications , WAHC@CCS 2019 Dr. David W. Archer, Dr. José Manuel Calderón Trilla, Jason Dagit, and Dr. Alex J. Malozemoff were part of a team that published a paper on a project that aims to make Homomorphic Encryption, an emerging technology that enables computing on data while data is encrypted, easier to use and implement. Also part of the team: Yuriy Polyakov, Kurt Rohloff, Gerard W. Ryan. Privacy-Preserved Data Sharing for Evidence-Based Policy Decisions , Bipartisan Policy Center Dr. David Archer, along with partners at Allegheny County, PA and the Bipartisan Policy Center, published a white paper on privacy-preserving data analysis. The paper outlines a demonstration project that uses multiparty computation to achieve improved data analysis and tangible privacy protections for public policy decision-making. From the paper: “This project used real-world government data to illustrate the applicability of secure computation compared to the classic data infrastructure available to some local governments. The project took place in a domestic, non-intelligence setting to increase the salience of potential lessons for public agencies.” Also part of the team: Nicholas R. Hart and Eric Dalton. Jana, RAMPARTS, and the World of Tomorrow , Columbia University Dr. David Archer gave a lecture on privacy-preserving data sharing technologies as a lecture in a Columbia University course on secure multi-party computation. This talk focused on information security, why software engineering processes are generally poor at ensuring it, deeper dives on select secure computation technologies, and descriptions of selected Galois-led developments in secure computation technologies. Can secure computation balance data privacy and utility? GCN Dr. David Archer published an article exploring the utility of secure computation. “Your secretssss….we Needsss them, Precioussss” , Nike Corporation Engineering Forum Dr. David Archer gave a talk on privacy, why it matters, and how technologists can protect it at the Nike Corporation Engineering Forum. The talk focused on current and emerging privacy risks, surveillance as the business model of the Internet, impact of privacy exploitation, and current and emerging privacy-preserving technologies to fight that exploitation. Paper is for Writing. Brains are for Thinking. Blockchains are for…what exactly? University of Oregon Cyber Security Day Dr. David Archer gave a talk on blockchain technology and why you need it vanishingly seldom. The talk focused on software engineering as a discipline, why it’s done poorly, and how that failure makes complex technologies (including blockchain) risky; what blockchains are, how they work, and how they compare to mature, robust technologies such as distributed databases; and why all of us should treat blockchain enthusiasm with extreme skepticism. High Assurance Cryptography and Verifiable Elections: Three Galois Projects , VeTSS Dr. Daniel M. Zimmerman gave an invited talk about Galois projects in high assurance cryptography and verifiable elections at the VeTSS Workshop on Verified Software . Software Correctness and Formal Verification Semantics-Driven Testing of the PKCS11 API , HCSS 2019 Dr. Matt Bauer and Dr. Mike Dodds gave a talk on our collaboration with Amazon Web Services to test the PKCS11 API at High Confidence Software and Systems Conference (HCSS). The talk described a model-driven testing approach to reveal high-priority bugs in PKCS11 implementations used to communicate with cryptographic devices such as hardware security modules (HSMs). The talk describes applying our approach to two PCKS11 libraries. Automated Verification of Query Equivalence Using Satisfiability Modulo Theories , Proceedings of the VLDB Endowment Dr. Bill Harris was part of a team that published a paper describing an algorithm that automatically determines if given SQL queries are equivalent. Also part of the team: Qi Zhou, Joy Arulraj, Shamkant B. Navathe, William Harris, Dong Xu. ASN.1 Encoding Schemes Done Right Using CMPCT, Bx 2019 Dr. Mark Tullsen At the Eighth International Workshop on Bidirectional Transformations (Bx 2019). The talk describes an intermediate language for describing ASN.1 types as well as ASN.1 encoding schemes. Our intermediate language, CMPCT, demonstrates the elegance of using “bidirectional transformation” methods. CMPCT allows one to create arbitrary encoding schemes that are correct by construction. The Software Analysis Workbench as a Platform for Verification Research , DSV 2019 Dr. Aaron Tomb gave an invited talk about how to use SAW as an open platform that third parties could use as a foundation for new verification research at the Workshop on Democratizing Software Verification , co-located with CAV 2019. Functors of the World, Unite! , Compose Conference Kenny Foner held a talk about a new, fun way of building a type system, using an elegant piece of theory called recursion schemes at Compose Conference . A HoTT Quantum Equational Theory , QPL 2019 Dr. Jennifer Paykin was part of a team that presented a paper on equational theory for the QRAM model of quantum computation, formulated as an embedded language inside of homotopy type theory, at Quantum Physics and Logic 2019 (QPL 2019). The authors prove that this equational theory is sound and complete with respect to established models of quantum computation. Also part of the team: Steve Zdancewic. Weird Machines as Insecure Compilation , FCS Dr. Scott Moore presented a paper with Dr. Jennifer Paykin, Eric Mertens, Dr. Mark Tullsen, Luke Maurer and Benoit Razet describing how software exploitation can be viewed through the lense of secure compilation at the Workshop on Foundations of Computer Security (FCS). Fast and secure global payments with Stellar , SOSP 2019 Dr. Giuliano Losa was part of a team that presented a paper about the Stellar payment network, including the formal verification of its core component, the Stellar Consensus Protocol at The 27th ACM Symposium on Operating Systems Principles . Also part of the team: Marta Lokhava,, David Mazières, Graydon Hoare, Nicolas Barry, Eli Gafni, Jonathan Jove, Rafał Malinowsky, and Jed McCaleb. Stellar Consensus by Instantiation , DISC 2019 Dr. Giuliano Losa was part of a team that presented a paper on describing a theoretical analysis of consensus in the Stellar Network, and in particular the new type of permissionless quorum system that arises in the Stellar Network at 33rd International Symposium on Distributed Computing . Also part of the team: Eli Gafni and David Mazières. Verifying the Stellar Consensus Protocol , VDS 2019 Dr. Giuliano Losa gave a talk describing the techniques employed in the formal verification of safety properties of the Stellar Consensus Protocol at the Verification of Distributed Systems workshop (VDS 2019). You can find the proof itself here . Dr. Losa also spoke about this topic at Mathematical Foundations of Programming Semantics (MFPS) XXXV. Language Oriented Programming , WG 2.16 Dr. Iavor Diatchki gave a talk on monads at the Working Group on Programming Language Design (WG 2.16). From the abstract: “A common programming idiom in Haskell is that of a “monad”–a concept often considered to be quite difficult to understand for programmers familiar with other languages. In this talk I will introduce “monads” using terminology that is likely to be familiar to language designers, and argue that they provide an interesting way of structuring programs in any language. Furthermore, the experience of using monads in Haskell has identified a number of useful abstractions, which may form the basis for a new programming language design.” Dependently Typed Haskell in Industry (Experience Report) , ICFP 2019 Dr. David Thrane Christiansen, Dr. Iavor S. Diatchki, Dr. Robert Dockins, Dr. Joe Hendrix, and Dr. Tristan Ravitch presented Galois’s experiences using advanced Haskell type system features in the development of Crucible, a general framework for writing symbolic simulators, at the 24th ACM SIGPLAN International Conference on Functional Programming . Bidirectional Type Checking , Compose Conference Dr. David Thrane Christiansen presented a tutorial talk on a design technique for type systems that are straightforwardly implementable at Compose Conference. Normalization by Evaluation , RacketFest 2019 Dr. David Thrane Christiansen gave an introduction to the technique of normalization by evaluation, for programmers used to the Racket programming language. What About the Natural Numbers? PWLConf 2019 Dr. José Manuel Calderón Trilla gave a talk called “What About the Natural Numbers at Papers We Love Conf. The talk focused on using semantically-meaningful number systems (such as the Natural Numbers) in our programs can aid in the design of an API. The talk coincided with the 30th Anniversary of Prof. Colin Runciman’s paper “What about the natural numbers?” and used that paper as a foundation for the discussion. The Secret Life of Not-A-Number! !!ConWest 2019 Annie Cherkaev gave a talk about a technique used by some interpreters called NaN-Boxing at !!ConWest. Towards Verified Binary Raising , SpISA 2019 Dr. Joe Hendrix, Guanan Wei, and Simon Winwood presented their work on building verified binary reverse engineering tool that lifts x86_64 machine code into LLVM, and verifies semantics are preserved. Hardware and Cyber-physical Systems Secure Systems: Voting / Future Technology: SSITH , DARPA ERI Summit 2019 Dr. Joe Kiniry gave a talk outlining the goals of DARPA’s SSITH program and of Galois’s efforts to measure and evaluate the security of SSITH hardware. Dr. Kiniry explained why one of the approaches being considered to evaluate the security of SSITH hardware prototypes is public red-teaming: allowing hackers to perform their own security evaluations on mock systems with prototypes of SSITH processors. The red teaming effort was kicked off at DEF CON 2019. RISC-V: An Open Platform for Security R&D , Real World Crypto Dr. Joe Kiniry gave a talk on the RISC-V open-source hardware instruction set architecture and the efforts of the RISC-V Foundation at Real World Crypto 2019 . Dr. Kiniry also delved into the advances in security-related R&D as it pertains to RISC-V. 21st Century Cryptography , DARPA ERI Summit 2019 Dr. Daniel M Zimmerman and William Koven gave a talk describing why getting cryptography right, especially in hardware, is difficult, and the approach Galois is taking in relevant projects. The talk focused on our hardware design approach, including synthesis from formal specifications in Cryptol and asynchronous logic, and how we are using it to mitigate power side channels in high assurance cryptographic hardware. Correct-by-Construction Hardware Synthesis , Shonan Meeting #133 Dr. Daniel M. Zimmerman gave a talk describing the synthesis of hardware from Cryptol, the GULPHAAC project, and our approaches to cryptography and hardware. Shonan Meeting #133: Asynchronous Circuit Design and its Applications: Past, Present and Future . Human-Machine Ethics: Experiments in Moral Responsibility , TVIW 2019 David Burke gave a talk presenting a paper at Tennessee Valley Interstellar Workshop (TVIW 2019) that addressed the question “What would it take for human beings to trust machines to help them make life-or-death decisions?” through a series of experimental scenarios, and then captured the results in a conceptual ‘congruency’ framework for thinking about moral responsibility and machine decision-making. Read the abstract here and find the paper in the link above. Cybersecurity Protecting Election Integrity with ElectionGuard Dr. Joey Dodds wrote a blog post announcing the release of ElectionGuard, an SDK that enables anyone to create end-to-end verifiable (E2E-V) elections technology. ElectionGuard was developed in partnership with Microsoft. Find the main repo here , and the core ElectionGuard API SDK here . The Art (Not Science) of Deepfakes , Nextgov Dr. David Archer published an article that explains and explores the implications of Deepfakes. Robust, Assured Diversity for Software Systems, RRTO Moving Target Defense Solutions Dr. Benjamin Davis presented our automated software diversity research and variant generation technology, and how it can protect software systems by detecting and recovering from common classes of cyber attacks at Rapid Reaction Technology Office (RRTO) Moving Target Defense Solutions event . Our range of practical binary-rewriting- and compiler-based capabilities take an application to defend and automatically generate multiple variants that each behave detectably differently when under attack. Our research revealed cases where randomization-based approaches do not compose and naive layering of techniques end up negating the protections they were intended to add. Instead of randomizing blindly, we use formal reasoning to guide the layout of code and data in our variants to produce sets that maximize the chance that an attack causes observable discrepancies in variant behavior. To learn more about our approach, see this tech report on the topic. Scientific Computing Point Movement in a DSL for Higher-Order FEM Visualization , VIS Dr. Charisee Chiw co-authored a paper presented at 2019 IEEE Visualization Conference (VIS). The work seeks to expose the common structure of visualization methods, apart from the specifics of how the fields being visualized are formed. Also part of the team: John Reppy Data Analysis and Machine Learning Artificial Intelligence and Cybersecurity Workshop Dr. John Launchbury led the Artificial Intelligence and Cybersecurity Workshop with Patrick McDaniel. The workshop’s aim was to assess the current and future research challenges and opportunities at the intersection of cybersecurity and artificial intelligence and to identify key research gaps. Find the briefing slides here . An Inductive Synthesis Framework for Verifiable Reinforcement Learning , PLDI 2019 Dr. Stephen Magill and Dr. He Zhu were part of a team that published a paper on making assurance guarantees for machine-learning applications. The paper considers “how formal verification techniques developed for traditional software systems can be repurposed for verification of reinforcement learning-enabled ones, a particularly important class of machine learning systems.” Watch the talk on the paper here . Also part of the team: Zikang Xiong and Suresh Jagannathan at Purdue University. Mental Health How Can I Academia When My Brain Can’t Even? Mental Health in Grad School and Beyond , PLMW 2019 Kenny Foner gave an invited talk about mental health in academia at the Programming Languages Mentoring Workshop at SPLASH 2019 , telling the story of their own experiences of mental illness within and after grad school, and giving strategies and resources for future researchers to support themselves and others in the world of academia and beyond. Contract Award Announcements Galois Awarded $8.6 Million DARPA Contract To Build Cyber Reasoning Tool that Discovers Security Vulnerabilities : Galois partners with Harvard University and Trail of Bits to build scalable and more cost-effective tools that identify hard-to-find vulnerabilities. Galois Awarded $15M IARPA Contract To Expand Government, Commercial Use Of Privacy-Preserving Technology : Project for IARPA’s HECTOR Program focused on making secure computation accessible to data scientists, other programmers who are not experts in cryptography. Spin-out News Muse Dev : We spun out Muse Dev, a startup developing tools that help you find critical bugs early in the development process. Muse Dev is serving a number of early, private beta customers. The Muse Dev team held numerous talks, including Shifting QA Left: Emerging Trends in Code Quality and Security Automation at DOES 2019, Code + AI: Will Robots Take Our Coding Jobs? at GOTO 2019, and A data-driven look at practices behind exemplar open source projects at Github Universe. Tangram Flex : Tangram Flex grew significantly in 2019. The team also launched theFramework , a series of articles that delve into systems engineering, security and safety, and integration. Tozny : Tozny launched TozID , a privacy-first identity management solution with privacy and end-to-end encryption built in. Other News Life as a Galois Project Lead : We continue to share what working at Galois is like on Life at Galois . This year we explored what being a Project Lead is like at Galois. Girls Who Code Chapter : At this year’s Grace Hopper celebration , we didn’t bring Galois branded swag, and instead used the funding to support a chapter of Girls Who Code in Dayton, Ohio. The chapter purchased programmable robot kits and is tackling a number of projects in teams. Parental leave : We revised our approach to parental leave and increased it to 16 weeks. Increased focus on a more inclusive workspace: We started organizing company lunches for under-represented groups in computer science. We also started an action group on proactive changes the company can make to be more inclusive of current and future Galwegians regardless of race, gender, sexuality, religion, or disability. More inclusive company activities: We started organizing company activities focused on an expanding variety of interests for mental health and relaxation. Examples include paint nights, pumpkin decorating, gingerbread houses, and a craft corner. Tech Talks : Galois organized and hosted 8 public tech talks on a variety of topics. James Edmondson joins Galois as Principal Scientist : We welcomed Dr. James Edmondson to the Galois team as Principal Scientist. Dr. Edmondson’s research focuses on the command and control, visualization, determinism, and trust of distributed artificial intelligence in robotics. IEEE Micro Best Paper Award : Dr. Georgios Dimou was awarded “Best Paper” for Loihi: A Neuromorphic Manycore Processor with On-Chip Learning . Washington Technology 2019 Industry Innovators : Washington Technology named Galois one of the winners of the Industry Innovator Awards, which aims to show the breadth and depth of capabilities of government contractors. Reboot Leadership Awards – Influencer: Joe Kiniry : Dr. Joe Kiniry was recognized by SC Magazine for his work in collaboration with DARPA, Microsoft, and the State of Colorado. Reboot Leadership Awards – Privacy Leads: David Archer : Dr. David archer was recognized by SC Magazine for his work on secure computation with DARPA, The Census Bureau, DHS, and IARPA. Continuous Formal Verification of Amazon s2n – honorable mention : The paper that details our initial work with Amazon Web Services to integrate formal methods in the development workflow for security-critical software at AWS was selected for an honorable mention in the Best Scientific Cybersecurity Paper Competition sponsored NSA’s Research Directorate. Read the paper here . Functional Programming competition : We sponsored a competition for the students in the introductory Functional Programming class. Browse the student projects here . Press Highlights And now a Bicycle for None : Dr. Georgios Dimou spoke with the New York Times about neuromorphic chips with on-chip learning capabilities that are designed to imitate the network of neurons in the brain. DARPA to Bring its Smart Ballot Boxes to DEF CON for Hacking : Dr. Daniel Zimmerman was interviewed by Dark Reading about the kick-off of the public red-teaming effort to evaluate the security of DARPA SSITH processor prototypes. Microsoft offers software tools to secure elections : The Associated Press reported on ElectionGuard, the software development kit that enables end-to-end verifiable elections technology, developed in partnership with Microsoft. Building Security Into RISC-V Systems: Dr. Joe Kiniry was interviewed as part of a panel of experts on Building Security into RISC-V Hardware in Semiconductor Engineering. Other Community Engagements Dr David Archer served as co-editor for the UN Privacy Preserving Techniques Handbook Dr. John Launchbury served on the Forum on Cyber Resilience of the National Academies of Sciences, Engineering, and Medicine served as a steering committee member for DARPA’s Information Science and Technology (ISAT) Study Group served on the steering committee for High-confidence Software and Systems (HCSS) served as a member of the Working Group on Functional Programming (WG2.8) participated in Computing Community Consortium’s Assured Autonomy Workshop served as a distinguished expert in the selection committee of NSA’s Best Scientific Cybersecurity Paper Competition Dr. Iavor Diatchki served on the program committee for International Symposium on Practical Aspects of Declarative Languages (PADL 2020) continued to serve on the Glasgow Haskell Compiler (GHC) steering committee served as chair of the Haskell Symposium steering committee Dr. David Thrane Christiansen and Dr. Iavor S. Diatchki held a one-day introduction to Cryptol and SAW at the 24th ACM SIGPLAN International Conference on Functional Programming David Thrane Christiansen served on the program committee for the 2019 Workshop on Metaprogramming (META 2019) at SPLASH Dr. Charisee Chiw organized an outreach event with a local high-school Robotics team. About 20 students from St. Marys spent half a day at the Galois office. Various Galweigans gave short technical talks covering topics like quantum computing, creating safe voting machines, 3D modeling design, and domain-specific languages. We also had an open discussion about various engineering topics and career paths. Dr. Scott Moore served on the program committee of the Workshop on Foundations of Computer Security Program (FCS 2020) served on the program committee of Computer Security Foundations Symposium (CSF 2020) Dr. Jennifer Paykin served on the program committee of the International Conference on Functional Programming (ICFP 2019) Served on the programming committee of the Workshop on Programming Languages for Quantum Computing (PLanQC 2020). Dr. Joe Hendrix served as chair of the Workshop on Satisfiability Modulo Theories (SMT 2019), and served on the FMCAD 2019 program committee. Dr. Georgios D. Dimou served on the program committee for ASYNC Symposium Dr. Aaron Tomb served as a committee member for the Workshop on Satisfiability Modulo Theories (SMT 2019) Dr. Aaron Tomb and Dr. Daniel M. Zimmerman participated in High Assurance Systems Engineering (HASE) workshop. Dr. Daniel M. Zimmerman gave the keynote talk at E-Vote-ID about the evolution of Galois and Free & Fair’s research efforts in the elections space. Dr. David Archer and Meckler Izaak gave a workshop on formal verification for zero-knowledge systems at ZKProof 2019 Dr. David Archer gave a keynote talk on how and why to deploy continuous formal verification as an assurance method for complex ASIC/FPGA products at Modern Formal Verification in Practice, Verification Sciences & Engineering Workshop Dr. Joe Kiniry gave a talk at a panel on DARPA’s POSH and IDEA programs . Software Releases Cryptol : We released two new versions of Cryptol ( 2.7.0 and 2.8.0 ). Feature highlights include adding support for test vector creation, useful for generating tests from a trusted Cryptol specification to apply to an implementation written in another language, and a variety of small changes to the language that make it more convenient to express common patterns. Software Analysis Workbench : We released two new versions of SAW ( 0.3 and 0.4 ). In 0.3, Java and LLVM verification was overhauled to use the new Crucible symbolic execution engine. In 0.4, we significantly improved functionality along with major bug fixes. ElectionGuard SDK : In collaboration with Microsoft, we released ElectionGuard, an SDK that enables anyone to create end-to-end verifiable (E2E-V) elections technology. Find the main repo here , and the core ElectionGuard API SDK here . Matterhorn : Galois continues to maintain and improve our open-source Mattermost terminal client.", "date": "2020-01-13"},
{"website": "Galois", "title": "Of Protocols and Pythons", "author": "Unknown", "link": "https://galois.com/blog/2021/05/of-protocols-and-pythons/", "abstract": "We’ve been working to improve usability for SAW , our tool for verification of C and Java programs. The primary way that users interact with SAW is its specification and scripting language. In order to make SAW as accessible as possible, Python can now be used as that language for SAW! We’ve built an example to demonstrate that new capability, performing verification of part of the C implementation of the Signal Protocol . In particular, we identify the conditions under which a Signal Protocol message will be successfully authenticated as a SAW specification. The Python SAW client SAW can be controlled from Python through the saw-client library on PyPI . There’s nothing magic about Python that makes this work—it controls SAW through a JSON-RPC API, as demonstrated in an earlier post . The saw-client library has come a long way since then, and the library now offers a high-level interface that takes care of the RPC-related details behind the scenes. Besides Python, SAW also has an alternative scripting language called SAWScript. While SAWScript is capable of writing the same proofs as Python, it’s not without its drawbacks. SAWScript is a custom language, so it imposes a barrier to entry for those trying to learn SAW for the first time. Moreover, SAWScript has basically nothing in the way of external libraries. If you want to do something in SAWScript that the standard library doesn’t provide, you will have to figure out how to implement it yourself. On the other hand, Python is a widely used language that will be familiar to many more people from the get-go. It also has a rich ecosystem of libraries and tooling through PyPI. Even if Python isn’t your favorite programming language, we encourage you to give saw-client a try. If nothing else, the code in saw-client can serve as inspiration for how to implement a similar client in a different language. A basic spec in saw-client Let’s see how saw-client can be used to write specifications for real-world C code. Our case study is libsignal-protocol-c . This library contains a C implementation of the Signal Protocol , a cryptographic protocol used to encrypt instant messages, voice calls, and video calls. This protocol is used in the Signal messenger application , after which it is named, but it is also supported in other applications such as WhatsApp, Facebook Messenger, and Skype. If you are more interested in a high-level description of what SAW is able to prove about libsignal-protocol-c , feel free to skip to the Future Directions section. To start, let’s take a look at a key data structure used in libsignal-protocol-c , the signal_buffer : struct signal_buffer {\n    size_t len;\n    uint8_t data[];\n}; A signal_buffer is an array of bytes (data) where the length is equal to len. Any time you send a message using libsignal-protocol-c , a signal_buffer will lie at the heart of the message. If we want to have confidence that libsignal-protocol-c is working as advertised, we will need to verify that the contents of a message’s signal_buffer match what is expected. The library checks whether two signal_buffers match up by way of the signal_constant_memcmp function: int signal_constant_memcmp(const void *s1, const void *s2, size_t n)\n{\n    size_t i;\n    const unsigned char *c1 = (const unsigned char *) s1;\n    const unsigned char *c2 = (const unsigned char *) s2;\n    unsigned char result = 0;\n\n    for (i = 0; i < n; i++) {\n        result |= c1[i] ^ c2[i];\n    }\n\n    return result;\n} Intuitively, signal_constant_memcmp checks if the contents of two signal_buffers ’ byte arrays are the same. If they are the same, the function will return 0 . If they are not the same, they will return a value indicating the bytes in which the contents of the arrays differ. With that said, it might not be obvious at first glance that this function returns 0 if the arrays are the same. After all, there is a fair amount of bit-twiddling going on, and it’s possible that someone made a mistake when writing the bit-manipulating code. We can verify this code’s correctness by checking it against a specification written in saw-client . The specification will look broadly like this: from saw_client.llvm import *\n\nclass ConstantMemcmpEqualSpec(Contract):\n    def specification(self) -> None:\n        _1\n\n        self.execute_func(_2)\n\n        _3 The Contract class characterizes SAW specifications by way of the specification method. To write your own specification, you simply create a subclass of Contract and override the specification method as shown above. Each specification has three parts: Preconditions (_1), which indicate the assumptions to make before invoking the function being verified. The arguments to pass to the function being verified (_2). Postconditions (_3), which indicate the things that must be checked after invoking the function being verified. With this vocabulary in mind, we can turn our intuition of how s ignal_constant_memcmp works into a SAW specification: class ConstantMemcmpEqualSpec(Contract):\n    n: int\n\n    def __init__(self, n: int):\n        super().__init__()\n        self.n = n\n\n    def specification(self) -> None:\n        s1  = self.fresh_var(array_ty(self.n, i8), \"s1\")\n        s1p = self.alloc(array_ty(self.n, i8), points_to = s1)\n        s2  = self.fresh_var(array_ty(self.n, i8), \"s2\")\n        s2p = self.alloc(array_ty(self.n, i8), points_to = s2)\n        self.precondition(cryptol(f\"{s1.name()} == {s2.name()}\"))\n\n        self.execute_func(s1p, s2p, cryptol(f\"{self.n} : [64]\"))\n\n        self.returns(cryptol(\"0 : [32]\")) The preconditions are that there are two byte arrays (s1p and s2p) whose contents (s1 and s2) are the same. The call to self.precondition (…) in particular is what ensures that the contents are the same. The argument to self.precondition (…) is written in Cryptol , a DSL for specifying cryptographic code. This particular Cryptol expression is rather simple, as it only performs an equality check, but we will see more complicated Cryptol examples later. The arguments to the function are the two byte arrays along with their length ( self.n ), which is first converted into a Cryptol expression so that SAW can reason about it. Finally, the postcondition is that the function returns 0 , again as a Cryptol expression. Once that scaffolding is in place, we can actually check that signal_constant_memcmp matches the specification we wrote: mod = llvm_load_module(\"libsignal-protocol-c.bc\") # An LLVM bitcode file\narray_len = 42 # Pick whichever length you want to check\nllvm_verify(mod, \"signal_constant_memcmp\", \nConstantMemcmpEqualSpec(array_len)) If all goes well, we can run this code in Python and see the following result: ✅  Verified: lemma_ConstantMemcmpEqualSpec (defined at signal_protocol.py:122) Hooray! SAW verified the correctness of signal_constant_memcmp , and what’s more, we never needed to mention anything about the bit-twiddling inside of the function—SAW is powerful enough to reason about this automatically. Note, however, that ConstantMemcmpEqualSpec only specifies what happens when the byte arrays are equal. If we wanted to characterize what happens when the byte arrays are not equal, we would need a slightly more sophisticated spec. One additional thing to note is that there is some amount of repetition in the code above, as we call self.fresh_var () followed by self.alloc () twice. Fortunately, the use of Python makes abstracting out this pattern cheap and cheerful: def ptr_to_fresh(spec: Contract, ty: LLVMType,\n                 name: str) -> Tuple[FreshVar, SetupVal]:\n    var = spec.fresh_var(ty, name)\n    ptr = spec.alloc(ty, points_to = var)\n    return (var, ptr)\n\nclass ConstantMemcmpEqualSpec(Contract):\n    ...\n\n    def specification(self) -> None:\n        (s1, s1p) = ptr_to_fresh(self, array_ty(self.n, i8), \"s1\")\n        (s2, s2p) = ptr_to_fresh(self, array_ty(self.n, i8), \"s2\")\n        ... Verifying code involving HMAC There’s much more to libsignal-protocol-c than just storing messages—it also has to send and receive them. Moreover, it needs to encrypt messages so that they can only be read by the intended receiver, lest private communication be vulnerable to interception by third parties. One key step in encrypting a message is attaching a message authentication code (MAC), which can be used to verify that the contents of a message have not been changed after it was sent. In particular, libsignal-protocol-c uses HMAC , a type of MAC that is computed using a cryptographic hash function. The precise details of how HMAC works are beyond the scope of this post, and luckily, we don’t need to know the details precisely in order to write SAW specifications related to HMAC. Instead, we can abstract away the details using uninterpreted functions . To start, let’s define some Cryptol functions that outline the skeleton of how HMAC works: hmac_init : {n} [n][8] -> HMACContext\nhmac_init = undefined\n\nhmac_update : {n} [n][8] -> HMACContext -> HMACContext\nhmac_update = undefined\n\nhmac_final : HMACContext -> [SIGNAL_MESSAGE_MAC_LENGTH][8]\nhmac_final = undefined These will be the uninterpreted functions we use to specify HMAC-related code in libsignal-protocol-c. The basic idea is that given a cryptographic key as input, hmac_init will produce an HMACContext . This HMACContext will be updated multiple times with hmac_update using the data from the first argument. Lastly, hmac_final will turn the HMACContext into a signal_buffer that is sufficiently long to store the MAC. The definition of HMACContext depends on which cryptographic hash function is used in conjunction with HMAC. libsignal-protocol-c is parameterized over the hash functions it uses, so one could plug and play OpenSSL , Common Crypto , or another suitable library. Because these functions will appear uninterpreted, SAW will not evaluate them during verification. As a result, the implementations of these functions are unimportant. We have chosen undefined for the sake of convenience, but any other implementation would suffice. With these functions defined, we can link them up to the corresponding C functions in the library itself. For example, here is an abridged specification for the signal_hmac_sha256_init C function: class SignalHmacSha256InitSpec(Contract):\n    key_len: int\n\n    def specification(self) -> None:\n        hmac_context_ptr = self.alloc(...)\n        (key_data, key)  = ptr_to_fresh(self, array_ty(self.key_len, i8),\n                                        \"key_data\")\n   \t \n        self.execute_func(..., hmac_context_ptr, key,\n                          cryptol(f\"{self.key_len} : [64]\"))\n\n        init = f\"hmac_init`{{ {self.key_len} }} {key_data.name()}\"\n        dummy_hmac_context = self.alloc(..., points_to = cryptol(init))\n        self.points_to(hmac_context_ptr, dummy_hmac_context)\n        self.returns(cryptol(\"0 : [32]\"))\n\n\nkey_len = 32\ninit_spec = llvm_assume(mod, \"signal_hmac_sha256_init\",\n                        SignalHmacSha256InitSpec(key_len)) Don’t worry about understanding every line of code here. The most important part is the last line, which uses llvm_assume instead of llvm_verify . The llvm_assume function allows SAW to use a specification without actually simulating it—in effect, treating it like an axiom. This allows us to tie the behavior of signal_hmac_sha256_init to the uninterpreted hmac_init function in the spec’s postconditions. We can also use llvm_assume in similar ways to create specifications involving hmac_update and hmac_final . Once that is done, it is time to verify a very important MAC-related function: signal_message_verify_mac . In essence, this function takes a message as an argument, computes the MAC for the data inside of the message, and checks that it matches the MAC that is attached to the end of the message. If they match, we can be reasonably sure that the message was not modified while being sent to the receiver. Explaining every detail of how signal_message_verify_mac works would be quite involved, so for the purposes of this post, we will only present the punchline: what should the contents of the message look like? The data inside of the message can be arbitrary, but the MAC at the end must have a very particular shape. That shape can be defined with a Python function: def mk_hmac(serialized_len: int, serialized_data: FreshVar,\n        \treceiver_identity_key_data : FreshVar,\n        \tsender_identity_key_data: FreshVar,\n        \tmac_key_len: int, mac_key_data: FreshVar) -> SetupVal:\n    sender_identity_buf = f\"\"\"\n        [{DJB_TYPE}] # {sender_identity_key_data.name()}\n            : [{DJB_KEY_LEN} + 1][8]\n        \"\"\"\n    receiver_identity_buf = f\"\"\"\n        [{DJB_TYPE}] # {receiver_identity_key_data.name()}\n            : [{DJB_KEY_LEN} + 1][8]\n        \"\"\"\n    hmac = f\"\"\"\n        hmac_final\n         (hmac_update`{{ {serialized_len} }} {serialized_data.name()}\n          (hmac_update`{{ {DJB_KEY_LEN}+1 }} ({receiver_identity_buf})\n           (hmac_update`{{ {DJB_KEY_LEN}+1 }} ({sender_identity_buf})\n            (hmac_init`{{ {mac_key_len} }} {mac_key_data.name()}))))\n        \"\"\"\n    return cryptol(hmac) Whew, that’s quite hefty! Again, don’t try to understand every line of code here. The important part is that this first calls hmac_init, followed by multiple hmac_update calls, and topped off with an hmac_final call. This very closely corresponds to the intuitions we developed earlier for HMAC, so if SAW verifies that the MAC looks like this Cryptol expression, we can be confident that it is working as expected. Next, we need to use this in a specification. Here is an excerpt of the specification for signal_message_verify_mac , which describes what a valid message should look like in its preconditions: class SignalMessageVerifyMacSpec(Contract):\n    serialized_len: int\n\n    def specification(self) -> None:\n        ...\n        mac_index = 8 + self.serialized_len - SIGNAL_MESSAGE_MAC_LENGTH\n        ser_len   = f\"{self.serialized_len} : [64]\"\n\n        self.points_to(serialized[0], cryptol(ser_len))\n        self.points_to(serialized[8], serialized_message_data)\n        self.points_to(serialized[mac_index], mk_hmac(...))\n\n        self.execute_func(...)\n\n        self.returns(cryptol(\"1 : [32]\")) Here, serialized points to the signal_buffer for the overall message. We can use Python’s slice notation (e.g., serialized[0] ) to describe the memory contained in different parts of the buffer. The first part contains self.serialized_len , the overall length of the message. Eight bytes after that is where serialized_message_data, the message data, is found. Finally, the very end of the buffer contains the MAC as computed by mk_hmac (…). The rubber finally hits the road when we call llvm_verify in concert with this spec. This time, we have to pass some additional arguments. We need to explicitly indicate which assumptions we made earlier with llvm_assume by way of the lemmas argument. We also need to tell the SMT solver which functions should be treated as uninterpreted by way of the script argument: uninterps = [\"hmac_init\", \"hmac_update\", \"hmac_final\"]\nllvm_verify(mod, \"signal_message_verify_mac\",  SignalMessageVerifyMacSpec(...),\n            lemmas=[init_spec, update_spec1, update_spec2, final_spec],\n            script=ProofScript([z3(uninterps)])) The result of all this work is a very, very satisfying green checkmark: ✅  Verified: lemma_SignalMessageVerifyMacSpec (defined at protocol.py:160) Future directions With saw-client , we were able to prove some interesting results about the code in libsignal-protocol-c . We were able to demonstrate that signal_message_verify_mac , the function which checks the integrity of a message sent using the Signal Protocol, works correctly when the last part of a message contains a proper message authentication code (MAC). Moreover, we characterized what the contents of the MAC should be relative to an abstract specification of cryptographic hash functions. There is so much more that could be done beyond what was shown in this post, however. While we verified a key property of the code which checks the integrity of messages, we did not go as far as demonstrating that messages sent over the wire pass this integrity check. We also avoided completely specifying the behavior of HMAC, although this would be possible to do—see this post for the full details. Although saw-client can hold its own as a tool for writing proofs, there are some places where saw-client hasn’t quite reached parity with SAWScript. There are some SAW capabilities that saw-client doesn’t currently support, such as initializing global variables in specs. Moreover, there are some SAWScript idioms that don’t look quite as nice in saw-client , such as quasiquotation of Cryptol expressions . We believe these limitations can be overcome with more thought and implementation effort. Going forward, we aim to make Python a first-class citizen when it comes to writing SAW proofs, and this work is a first step in that direction. If you want to take a closer look at the code presented in this post, you can find it at the saw-demos repo under the demos/ signal-verification directory. We encourage you to try out saw-client yourself, and if you find anything that could be improved, don’t hesitate to file issues on the SAW issue tracker .", "date": "2021-05-14"},
{"website": "Galois", "title": "Who is verifying their cryptographic protocols?", "author": "Unknown", "link": "https://galois.com/blog/2021/05/who-is-verifying-their-cryptographic-protocols/", "abstract": "Building secure communication systems requires both secure cryptographic primitives and also secure cryptographic protocols that build messaging schemes on top of those primitives. Well-designed protocols are the backbone of almost all modern digital communication, enabling key exchange, entity authentication, secure channels, and anonymous messaging. On the other hand, improperly designed protocols can render the best cryptography useless, for example, if the protocol inadvertently leaks a secret key. Because cryptographic protocols are simultaneously critical to our infrastructure and extremely difficult to get right, the formal verification community has spent over two decades developing tools and techniques to validate the correctness of protocol designs. The field has progressed to the point where very few scientific barriers prevent us from formally verifying all of the new protocols we develop. Despite this, we still have a long way to go on the adoption curve. Let’s take a look at what protocols verification is happening today and who is doing it. Perhaps more importantly, let’s also look at who isn’t verifying their cryptographic protocols and examine potential solutions for closing the gap. What is cryptographic protocol verification? At a most basic level, formal verification techniques aim to give a precise mathematical meaning (or semantics) to real-world processes and objects. This semantics captures how these entities behave and provides an environment for verifying, with mathematical precision, what is and is not true of a system. So long as the encoding is accurate, properties proven over the semantics should hold over the real system. In the case of cryptographic protocols, we seek to prove properties like the absence of man-in-the-middle attacks, data leaks, and privacy violations. When we formally verify a protocol, we establish a resilience to these kinds of flaws against an adversary with a particular set of capabilities. It’s impossible to verify protocols correct with respect to adversaries with unlimited power. For instance, an adversary with unbounded computational power could decrypt any message by trying every possible encryption key. So instead, protocols are typically verified under two main types of adversaries with different limitations in their power. In the computational model , correctness is established with respect to a computationally bounded adversary that manipulates bitstrings. Formal verification efforts in this framework involve mechanizing the pen-and-paper proofs typically done by cryptographers. It requires taking an English proof written by a mathematician and encoding the underlying mathematical objects and inference steps into a machine-readable form that a computer can check. While there is some tooling in this space, including EasyCrypt and CryptoVerif , proofs in the computational model often require extensive manual effort by cryptographic experts. The verification community has centered around another analysis framework called the symbolic model to benefit from full automation . By simplifying the threat model to a Dolev-Yao attacker which has full control of the network but that can only manipulate symbolic messages, verification becomes amenable to automation. You can think of this analysis framework as one that treats the cryptographic primitives as a black box. For a key k and a message m, a ciphertext is represented as a symbolic term like enc(m,k),and such a message can only be decrypted if the attacker holds the secret key k. In spite of the fact that the symbolic model narrows the attack surface, formal verification efforts in this framework are still effective at ruling out classes of attacks and have proven successful in finding bugs in a number of widely used protocols, including Google’s single-sign-on protocol . The most well-known symbolic verification tools include ProVerif , Tamarin , and Maude-NPA . What kinds of protocols are being verified? There is a great deal of protocol verification happening today. Some of the most exciting work involves verifying new, novel protocols. For example, the Signal protocol combines several sophisticated cryptographic primitives to achieve an array of deep security properties. Its ensuing verification efforts required researchers to meet at the cutting edge of both crypto and verification research. In the computation model, formally verifying these protocols requires extremely complicated and intricate mathematical reasoning to be encoded in machine-checkable format. On the other hand, symbolic tools often won’t analyze these complex protocols out of the box, meaning new analysis techniques need to be designed. Still important, but somewhat less challenging to verify are the protocols developed by standards bodies and major industry frameworks. These protocols are high impact, often use (variants of) well understood cryptographic primitives and are rigorously documented, making them great targets for tool builders and academic security researchers. Perhaps the best example of the verification community rallying around an industrial protocol came with the development of TLS 1.3. Numerous verification efforts using multiple tools took place hand in hand with the development efforts and helped to influence the protocol’s design. This paper is a great summary of those results. Major industrial standards such as Bluetooth and 5G have received similar scrutiny from the academic community. Protocols follow the long tail rule: a few big important protocols are verified, but many more protocols exist in the long tail, and most of these remain un-verified. The problem with focusing on major protocols like TLS and Bluetooth is that those protocols are already the subject of extensive human review and attack. Security researchers and hackers spend years creatively trying to uncover and exploit flaws in their designs. As a result, formal verification of these protocols is less likely to uncover flaws. The majority of bugs are in the long tail, and these are the protocols that aren’t getting formally verified. Chances are if a protocol isn’t the backbone of an industrial standard or a novel piece of open source cryptography, it only receives manual human review and testing, which is prone to error and oversight. To make matters worse, the teams developing smaller-scale protocols often don’t have the in house cryptographic expertise necessary to perfect their designs. Unlike the case with TLS and Bluetooth, the academic community can’t come to the rescue for these smaller scale and proprietary protocols. For every interesting research article on formally verifying aerospace , automotive , IoT , or power grid protocols, there are likely dozens of similar protocols that haven’t received the same level of care. To extend the reach of verification in this domain, we really need a grassroots level of adoption where tools are accessible to industrial teams who want to carry out the verification work themselves. Challenges for adoption It’s common in formal methods research to claim that the complexity of tools is the main barrier to adoption. For example, proving functional correctness of a code block or operating a theorem prover requires a high baseline level of knowledge. I would argue that this is actually not the case for protocol analysis tools. Let’s stop to think for a second about what the ingredients are for a symbolic analysis: Specify the protocol Specify the attacker and cryptographic primitives Specify the security properties of interest In most cases, proprietary protocols aren’t starting with a blank slate. They are bending and molding existing protocols to fit a specific use case. If you are building secure messaging infrastructure for IoT devices and your protocol doesn’t resemble any well-known schemes, there is probably something wrong. The good news is that this means that steps 1-3 aren’t going to require a lot of intensive modeling effort. Equational theories for well known crypto primitives can be pulled off the shelf, and existing protocol and property specifications can be adapted from a slew of representative examples. So why the adoption gap? I would argue that there are two basic hurdles: 1) being able to understand and operate the tools and 2) being able to demonstrate the return on investment compared to the cost of formal verification. Let’s start with the first challenge, using the tools. While the theoretical complexity of tool use is low, adopting any new technology takes energy. Right off the jump, you need to wade through a sea of possible protocol verification tools and approaches, each with its own guarantees, assumptions, and limitations. Making the right selection can take time. Each tool will have its own specification and modeling language that needs to be well understood before any analysis can occur. The second challenge is being able to articulate ROI. Cryptographic protocol verification clearly has had a big impact on improving the security of our communication infrastructure as a whole. The nauce comes in articulating that value on a project by project basis. Is there a visible outcome from a symbolic protocol verification that can be presented to budget holders? There is, of course, no guarantee of finding bugs. And most development teams are reasonably confident in their protocol design work, so a reaffirmation of a protocol’s correctness may not weigh heavily in planning. Compounding the problem further, the type of vulnerabilities that can be ruled out via formal verification varies from tool and tool. Each has its own reasoning framework and subtle assumptions of the threat model. Next steps I believe what’s needed is to unify behind a common language and analysis framework for protocols. Every symbolic protocol verification tool is underpinned by the same core logical framework (the applied pi-calculus), yet every tool implements its own variation. Unifying behind a common specification and analysis framework would go a long way towards simplifying the messaging and curbing the ease of adoption and use. When protocol designers write protocols, they typically write them in what’s called security protocol notation (or Alice and Bob notation). It’s a very intuitive way to write protocols that is accessible at the undergraduate level, but it’s still rigorous enough to permit deep analysis. Why then, do we require these rigorous designs to be translated into one of a dozen potential languages provided by the analysis tools? We should meet protocol designers where they are, and provide analysis tools that build off the models they already have. This shortens the learning curve and makes it easier to build clear messaging around a common language. Works like, Alice and Bob: Reconciling Formal Models and Implementation , represent important progress in that direction in that they give simple high-level semantics for Alice and Bob notation as well as precise low-level semantics that is amenable to analysis with existing symbolic protocol verification tools. Formal verification is starting to show its worth in real-world protocol assurance. Verification can provide a high level of confidence in systems or even eliminate certain types of bugs. So far, the big wins in protocol verification have focused on the most widespread types of protocols. I believe it’s time we democratize protocol verification and make the highest standards of assurance available to any team that wants it. If you’re interested in discussing cryptographic protocol verification further, please contact us !", "date": "2021-05-07"},
{"website": "Galois", "title": "Actually, You Are Rolling Your Own Crypto", "author": "Unknown", "link": "https://galois.com/blog/2021/03/actually-you-are-rolling-your-own-crypto/", "abstract": "The mantra “don’t roll your own crypto” is widely known and accepted amongst programmers, but what does it actually mean? It turns out that such a simple statement is not so simple to follow. What many people take away from “don’t roll your own crypto” is that they shouldn’t create their own crypto algorithms . This makes sense. After all, most people wouldn’t even know where to start. So, instead of making up an algorithm when they need to encrypt data, an engineer might take on OpenSSL or BouncyCastle as a dependency and pat themselves on the back for using a well-established scheme. What they might not realize is that the algorithms themselves are the first in a series of traps, each of which can have catastrophic effects on the outcomes of cryptography use. Algorithm selection, algorithm use, and protocol creation are all potential pitfalls that await once you’ve decided not to create your own algorithm. We’ll briefly explain examples of each of these. Algorithm Selection There are a massive number of existing algorithms that do a wide range of things. The encryption space, for example, can first be broken down into symmetric and asymmetric. Each of those categories has a number of usable algorithms, and many of those algorithms have some other number of usable modes. Let’s look at the range of choices someone might face if they want to do symmetric encryption. AES is a good algorithm, but at this point, you’ve likely seen the Wikipedia image explaining why you shouldn’t use the ECB mode. That’s great! You could pick CBC or CTR, but those aren’t authenticated. The data you send with those modes would be confidential, but someone else might be able to pose as you and send different messages. If you need authentication, you could look to GCM or OCB, but OCB has a history of patents, so there are fewer vetted implementations. That leaves you with GCM, which can be problematic for reasons we’ll discuss in the next section. Whew. Even worse, it’s hard to tell if you’ve made a bad choice! If you just watched a few blocks of ECB on the wire, they’d probably look random enough. If you encrypted JPG instead of a bitmap image, you’d likely not even be able to see the pattern, but the risk would remain. You would experience a similar challenge if you picked a mode that does not provide authentication, but your security requirements depend on that property. No number of test cases or amount of system observation would alert you to the mistake. Algorithm Use A number of algorithms are secure if used properly but can be disastrous if used incorrectly. AES-GCM, for example, requires a nonce (a single-use value) as an additional input. A single nonce reuse can reveal the plaintexts and a significant amount of information about the key. Nonce reuse can be observed, to some extent, but can also be a low-probability event that results from subtleties in state management or concurrent programming. Other algorithms have even less obvious modes of misuse. Take the example of hashing passwords for storage. SHA2 might seem like a good choice, after all, it is a good hash. Unfortunately, while SHA2 is a good hash, it is designed for speed, which is the opposite of what you want for password hashing. A better selection is Argon2 or bcrypt. Once an appropriate algorithm is selected, it’s still essential that passwords are salted before they are hashed. Otherwise, attackers can pre-compute hashes and quickly reverse large numbers of passwords if the password database is ever compromised. Protocol Design So you’ve chosen a secure algorithm in a secure mode that fits your operational environment. Now you need an implementation, no problem! You can pull one off the shelf from a highly trusted provider such as OpenSSL, BouncyCastle, or a managed Hardware Security Module (HSM) service. You’re not done there, though. This is where things start getting hard. Unless you are encrypting data at rest, your crypto is probably going to be deployed inside a protocol scheme that enables secure communication. When it comes to protocols, there is rarely an off-the-shelf solution. As a result, developers are often forced to implement their own protocols, even though they understand it is risky. Most protocol designs are variants of a few well-known schemes. For example, Diffie-Helman is the foundation for many key exchange protocols, and secure channels are often established through some variant of SSL, IPSec or SSH. But these protocols are not one-size-fits-all. They frequently need to be modified to meet the constraints of a particular operating environment. What’s often overlooked is that even small deviations to the designs can completely invalidate a security argument. What’s more, the threat model under which the original protocol was designed may not be valid for the environment in which it is deployed. A perfect example of this comes with the Bluetooth protocol. Bluetooth uses a relatively standard set of cryptographic primitives and protocol constructs to pair and authenticate devices. Despite the fact that the Bluetooth protocols were developed under the scrutiny of a standards committee, we see a host of new damaging flaws emerge every year. Recent examples of man in the middle and cryptographic strength downgrade attacks are just the tip of the iceberg. The attack types aren’t new, yet they re-emerge every time a new protocol gets adopted. Help, I rolled my own crypto For most applications, it’s easy to avoid rolling your own cryptographic algorithms. Making good decisions around algorithm choice, algorithm use, and (especially) protocol design is much more difficult. Our advice at Galois is to always use the biggest pre-built building blocks possible that meet your needs. For primitives, you can consider using the highest level interfaces of a library such as NaCl . For protocols, see if something such as an existing TLS implementation will meet your needs. In general, something widely used and with fewer configuration choices will be harder to misuse than something highly configurable. Unfortunately, this answer only gets us so far. Time, speed, maintenance, and legacy demands can all get in the way of sticking to the safest path for cryptography implementations. If you absolutely must roll your own cryptographic design, our advice is to move slowly, audit extensively, and presume that your system contains security bugs. If you’re wondering where to start, please reach out . We’d love to talk with you to help you understand where your cryptography might be exposing you to risk and what you can do about it. Thanks : Christoff Elce for pointing out an inaccuracy about OCB Reddit user /u/ScottContini for pointing out a serious mistake describing SHA2 as acceptable for password hashing.", "date": "2021-03-15"},
{"website": "Galois", "title": "Galois’s BASALISC Project Wins $15.3M DARPA Contract and Aims to Finish “The Last Mile” of Data Confidentiality", "author": "Unknown", "link": "https://galois.com/blog/2021/03/galois-basalisc-project-wins-15-3m-darpa-contract/", "abstract": "The basilisk is a creature from legend that could permanently stop its adversaries with only a glance. Its venom was also described by Pliny the Elder as being able to run up the spear of an adversary and permanently end that threat, as well. Inspired by the legendary creature’s prowess at securing “the last mile” of its own vulnerability, Galois, along with our partners KU Leuven , University of Arkansas, and Verilab , developed Bespoke Asynchronous Silicon-Accelerated LWE Intrinsics through Software/Hardware Codesign (BASALISC) – a multifaceted project that aims to secure the “last mile” of data confidentiality. BASALISC is part of DARPA’s Data Protection in Virtual Environments ( DPRIVE ) program, which aims to design and implement hardware accelerators for Fully Homomorphic Encryption (FHE) computations. BASALISC is truly a multidisciplinary effort. The project will realize both hardware and software innovations, bringing together Galois’s core strengths in homomorphic encryption, formal verification, advanced ASIC design, and compiler development to create a hardware solution that maximizes efficient FHE performance while remaining flexible enough to support diverse FHE parameter settings and application needs. This project aims to dramatically improve performance of homomorphic encryption over what is currently achievable using software or FPGA hardware FHE techniques. We believe BASALISC will succeed by taking a software/hardware co-design approach to achieve performance, and by employing formal methods to provably verify key properties of the basic computation engines included in the BASALISC design. We’re particularly excited that BASALISC will bring together all of these aspects of Galois’s expertise. Be sure to check our blog for updates! You can read more specifics about BASALISC on our project page . This material is based upon work supported by the Defense Advanced Research Projects Agency (DARPA) under Contract No. HR0011-21-C-0034. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the Defense Advanced Research Projects Agency (DARPA).", "date": "2021-03-08"},
{"website": "Galois", "title": "Real-time Robotics Control in the Lean Language", "author": "Unknown", "link": "https://galois.com/blog/2021/03/real-time-robotics-control-in-the-lean-language/", "abstract": "Microsoft Research recently published a pre-release of Lean 4 .  Prior versions of Lean focused on being a proof assistant – a software tool that facilitates the development of rigorous mathematical proof through a form of interactive human-machine teaming. The main application of Lean so far has been to digitize theoretical mathematics . A major goal of Lean 4 is to make Lean a good programming language rather than just a proof assistant. The syntax has been reworked in many ways to make it easier to write a wider variety of programs. An optimizing compiler that generates efficient C code was written. It features a novel memory management technique that is highly performant and helps us avoid problematic runtime pauses that frequently accompany such tools (i.e., garbage collection), and it is easy to integrate with existing C/C++ code when necessary. Lean is now largely self-hosting and written in Lean itself. To assess Lean’s suitability as a programming language for real systems, we set out to write a Lean implementation of a robotics controller running on a single board computer. To make things more interesting, we chose a controller for a two-wheeled robotics platform. If Lean programs are not able to provide real-time commands to the motors in response to sensor inputs, the system will literally fall down. Our goal was to build a working controller in Lean. This is different from what one usually thinks of when using theorem provers. Typically, one would specify a formal model of the controller that may omit low-level details, define axioms that capture assumptions expected to be true of the environment, and then try to prove the controller stabilized the system in a world satisfying the environment’s axioms. This is a worthwhile goal and one we would like to pursue eventually. However, as the actual controller implementation for this project would use Lean, we needed to include low-level details that may be otherwise omitted. We started by buying a $90 two-wheeled robot and began doing experiments in Lean. We inspected the generated C code and the runtime library and found that it was quite portable. Unfortunately, the pre-release version of the Lean runtime brings in dependencies (e.g., libgmp) and is too large for the Arduino-based controller on the robot. Fortunately, the generated code could run quite easily on the Rasberry Pi . We bought the 8GB version so we could compile Lean directly on it — this added $80 to our project’s cost. This fit within our desired hardware constraints and the authors of Lean are interested in addressing runtime library size issues. The next step was to partition the existing robotic controller code to work over a Bluetooth serial connection to run all the control algorithms on a Rasberry Pi while keeping minimal code to control the motor and read the accelerometer data on the Arduino board. This was pretty straightforward but required some use of Google Translate to understand the code’s initial comments. You can see the original code after translating comments here and the partitioned Arduino code after extracting the control algorithms here . Next, we translated the control code from C into Lean through a manual but fairly straightforward process. Lean 4 ultimately produces functional definitions and has precision, modularity, and compositional benefits of functional programming. However, it has a rich source language that permits use of for loops, mutable local variables, and structured control flow statements like `break` and `continue.` Internally, Lean 4 uses a sophisticated analysis process to automatically and transparently restructure the code into a functional definition. This reduced the level of effort required to port from C to Lean. The Lean code we wrote is publicly available on Github . The primary control step function BalanceCar.update runs every 5ms. It uses a Kalman filter to estimate the robot orientation from gyroscope and accelerometer readings (6 DoF IMU). A PD controller accepts the orientation state as input and determines the motor speed thus, closing the control loop. After finishing the porting, we wrote a bit of C code to connect the Lean control code to the Bluetooth serial APIs and tried it out. The initial results were entertaining but not quite right: This was a bit disappointing but happens in real-world programming.  We did some tests, made some changes to decrease Bluetooth latency, and fixed a bug in Lean we discovered along the way. In the end, we successfully created a working robot: As noted earlier, this was just a small experiment to test Lean out in a real-time controller and the work required to manually lift C code into Lean. We haven’t verified the controller correctness (yet), but when we have a bit more time, we plan to work on this and integrate Lean-based controllers into the ROS ecosystem so more people can try it out.  We also have a larger project using Haskell, Lean, and SMT solver together to produce a verified decompiler from 64-bit x86 to LLVM. We’ll have more information on that in the future. All of the work we did for this project is publicly available to try out if you are interested. We intentionally used a relatively low-cost robot so that it is easy for people to try out the code. This could be a way to personally try out Lean or to show students that you can write real programs in these languages. If you have any questions about the project, you can chat with us on the Lean Real-time Systems Channel on Zulip. We want to thank the authors of Lean for their help in making this possible, and Joey Dodds for comments that helped improve this blog post.", "date": "2021-03-29"},
{"website": "Galois", "title": "The Dog Ate My Protocol Spec; A Demo", "author": "Unknown", "link": "https://galois.com/blog/2021/03/the-dog-ate-my-protocol-spec-a-demo/", "abstract": "One of the key understandings of growing up is beginning to appreciate the difference between “should” and “do”. We should eat a balanced diet full of green leafy vegetables, but life happens, and ice cream tastes really good. As engineers and software developers … same thing, different day. We should write good data and protocol definitions , evaluate them for correctness , and continuously monitor and update them over time . But we don’t. Because life happens. In the world of pure software, maybe this isn’t a big problem. We can replace our broken XML serializer with a JSON serializer, and maybe no one notices. But in the world of cyber-physical systems, we have bigger issues. That CAT scanner, or that radar system, is a combination of software and hardware that’s been certified (in its exact configuration!) for use in safety-critical systems. Throwing it away and starting over is expensive . At the same time, keeping a Windows 3.11 (for Workgroups!) machine running on eBay-scrounged hardware, just so that we can run the original interface software … well, that also isn’t a great life. But the company that made the thing went out of business, and the specifications were lost in the fire sale, so … what can we do? Well, I’m glad you asked. We often ask companies for the specifications of their protocols when we verify their critical systems. We then run into a variety of reasons why those specifications aren’t available. Most often, this is due to a piece of the system that was built by a third party who is now out of business, but we’ve heard some great stories. (So far: flood and fire, but not famine.) As a result, we have been working with researchers at Tufts University to investigate ways to recover the specifications, quickly and correctly. The demo above gives you a quick outline of that task. We use a suite of tools to reverse engineer a protocol based on example data captured from real data streams. These tools can help you quickly visualize common patterns in the data, and find interesting common pieces of protocols: checksums, type/length/value or length/value sections, sequence numbers or timestamps, etc. Our plan is to keep expanding our set of detectors as we go, to identify interesting semantic values as well. A couple of examples “this is a float that (based on the values observed) appears to be in radians,” or “this is one of several common serialization formats for latitude.” This effort is part of a larger model recovery, verification, and digital engineering effort at Galois. The truth is that there aren’t good models, specifications, or requirements for many existing systems in the world. This is a significant limiting factor in our ability to formally verify critical systems, or even do good resilience reviews. Furthermore, reverse engineering these things by hand is difficult, expensive, and error prone. So, through a variety of projects, including this one, we are looking to leverage our and our partners’ expertise to help accelerate this process. This will make it easier and cheaper for all of us to know what the heck is actually going on with our systems. Well, and to mess with botnets. Obviously. Now if we could just get it to help us eat more leafy greens at dinner…", "date": "2021-03-25"},
{"website": "Galois", "title": "QUIC Testing, a Quick Replication", "author": "Unknown", "link": "https://galois.com/blog/2021/03/quic-testing-a-quick-replication/", "abstract": "At Galois, we’re always looking for better ways to build reliable systems. A big part of that is doing our own research. At 130 people, we’re one of the world’s largest formal methods research teams! But another part of our work is understanding new tools and techniques from the research community. We’re interested in solving problems using any approach that works, including learning from other formal-methods researchers. Of course, it can be difficult to know how well a technique will work in practice from reading a research paper, so we often test new techniques out ourselves to learn more about them. One area that we’re very interested in at the moment is black-box testing of network protocol implementations. Two important examples are the ubiquitous TLS protocol and QUIC, a new transport-layer protocol under standardization at the IETF that will underlie HTTP/3. These protocols are critical for security but are notoriously difficult to get right, and implementations of TLS have often suffered from security vulnerabilities in the wild. To make matters worse, network protocols are inherently difficult to test because exercising a bug might require that several nodes play out a long sequence of interactions. Traditionally, protocol developers use interoperability testing, in which, e.g., a server running implementation A of QUIC is tested against a client running a different implementation B. By running the protocol between the two implementations, long sequences of complex interactions can be generated. This approach also provides a limited sort of adversarial testing, as implementation B might have interpreted the QUIC specification differently, resolved ambiguities differently, or might behave erroneously. The problem with this approach is that it is very hard to achieve a high coverage of the QUIC specification. Doing so depends on the implementation of B, the precise sequence of network operations, and other contingent factors. Testing erroneous behaviour is even more challenging. That’s why we were excited to see two papers from Ken McMillan and Lenore Zuck which use some pretty clever ideas from formal methods to address the shortcomings of interoperability testing: McMillan, Kenneth L., and Lenore D. Zuck. “ Formal specification and testing of QUIC. ” Proceedings of the ACM Special Interest Group on Data Communication . 2019. McMillan, Kenneth L., and Lenore D. Zuck. “ Compositional Testing of Internet Protocols. ” 2019 IEEE Cybersecurity Development (SecDev) . IEEE, 2019. McMillan and Zuck develop a testing tool built on top of the Ivy formal verification framework that uses specification-based testing to test much more diverse scenarios. In their approach, McMillan and Zuck develop a formal model of the IETF QUIC specification and use it to randomly simulate network nodes that send packets to the implementation under test. For example, a QUIC server implementation would be tested by randomly simulating a QUIC client (or clients) using the formal model. Compared to interoperability testing, the randomized, simulated client produces much more diverse stimulus than the concrete implementation B for testing the server A. McMillan and Zuck find a bunch of interesting bugs in implementations of QUIC, including vulnerabilities to denial-of-service attacks and an information leak similar to the famous Heartbleed bug . Sounds pretty cool! So we were curious what it would be like to apply this new tool ourselves. There’s a lot of great formal methods research happening at the moment, but in our experience, there can be a gap between research and what’s needed for a practical engineering tool. Academic researchers are focused on pushing the frontiers, which means that research tools sometimes have rough edges that make them difficult for new users. Research tools can also be specialised to a particular use-case in a way that makes them hard to generalise. We wanted to replicate McMillan and Zuck’s results and understand how useful their approach would be for testing other QUIC implementations. The good news is that the tool worked as we’d hoped! We applied it to Picoquic , a simple QUIC implementation, and even managed to find a non-conformance problem in the version we tested. That’s a good indicator that this approach could be practical in the future. That said, this is definitely a research tool rather than something ready for deployment to customers. Using it currently requires a deep understanding of the Ivy language, the QUIC protocol, and the target implementation. We’re confident that these aspects of the tool could be improved with more engineering work. So, in general, the results of our investigations were very positive, and we’re excited to apply this idea ourselves in the future. If you are curious to try it out, we packaged our experiment using Docker for easy replication and made it available at https://github.com/GaloisInc/ivy-quic-testing-demo . Let’s dig a bit more into McMillan and Zuck’s approach and see what we find. Overview of the Tool Ivy is a general-purpose formal verification tool, but McMillan and Zuck use it specifically for black-box testing of protocols. Ivy’s testing of QUIC works by analysing events visible on the wire rather than any internal events of the implementation. This means Ivy only needs to be able to communicate through the network with the implementation under test and requires no source-code access or instrumentation. The testing tool masquerades as just another peer on the network, which makes it easy to deploy. Ivy models are written in the Ivy modeling language, which is approachable to someone who has programmed, e.g., in C or Python. Models in Ivy are written using imperative (i.e., C-like) statements and pre/post-conditions which are expressed in first-order logic. These models are very flexible and can specify the behaviour of protocols with unbounded numbers of peers, unbounded data, unbounded sequences of network packets, etc. Ivy translates those models into the language of the Z3 SMT solver to generate tests and check for compliance. The QUIC model consists of a monitor, which is an (infinite) state-machine which monitors the events visible on the wire: each wire event is associated with a precondition, which stipulates in which states of the monitor the event is allowed to take place and an update of the monitor’s state. A sequence of packets observed on the wire is correct if, when we run the monitor on each event in order, no precondition is ever violated. This modeling style enables what is called assume-guarantee testing 1 of network components. For example, to test a server, we will check that, assuming that the packets sent by clients never cause a precondition violation (the assumption), then the packets sent by the server never cause a precondition violation (the guarantee). In practice, a test of a QUIC server might proceed as follows: Ivy initializes the model and then calls the Z3 SMT solver to find a random packet that a client can send to the server; this will likely be a client HELLO packet, which is used in QUIC to establish a new connection. Z3 finds values for all the fields in the packet (e.g., the connection id) such that those fields agree with the precondition of the client HELLO packet, and Ivy calls its network shim to actually send that packet on the wire. The monitor state is then updated according to the monitor’s state-update function. For example, the monitor remembers the connection id used in the client request. The server then responds, likely with a server HELLO packet. Upon receiving the response, Ivy calls Z3 again, but this time to check that the received packet satisfies the precondition that the monitor associates with server HELLO packets. For example, it checks that the destination connection id is the same connection id that the client used in its HELLO packet, which is available in the monitor state. Subsequently, Ivy calls Z3 again to find a new packet that can be sent to the server, and the exchange of packets between the simulated client and the server continues in this fashion. Upon failure, Ivy displays a high-level event trace and the location of the assertion that was violated. Since the model is used both to generate packets to send the implementation under test and to check that the responses are correct, a failed test may reveal not only a) bugs in the implementation, but also cases in which the model is b) too strong or c) too weak. The model is too strong when a precondition is too restrictive and fails on a packet that is intended to be legal by the authors of the IETF specification; if a component under test generates such a packet, a spurious precondition violation will occur. Conversely, the model is too weak when it can cause a packet that is not intended to be legal to be generated during a test; such a packet is likely to be rejected by the component under test, cause it to crash, or behave unexpectedly. In both cases, we are likely to get an error trace that can be inspected. In other words, protocol testing with Ivy allows us to test both the implementation and the model at the same time! This is important because, like programming, developing models is an error-prone process and models must be debugged too. This means that a user can begin with a candidate model that is gradually refined at the same time that bugs are fixed in the implementation under test. One note of caution is that when a test failure occurs and Ivy displays an error trace, figuring out whether we are in situations a), b), or c) is a manual process of interpretation, requiring close inspection of the trace, the Ivy model, and the IETF specification. Because the specification expresses the whole protocol for a network of any size, testing can begin any component, and any size of network can be tested. The user can add logical conditions that restrict (or disable) protocol steps, thereby narrowing down the set of interactions produced. Conversely, test-generation can be made more permissive by removing logical conditions: this has the effect of allowing more interactions. The specification can also be modified to allow invalid requests in order to test the component for robustness against bugs or security attacks. Finally, we should note that Ivy’s protocol-testing facility is not specific to QUIC and can be applied to other protocols. However, Ivy comes with a QUIC specification (based on IETF draft 23) and a configuration to use it to test sample QUIC implementations ( Quant and Picoquic ). Results According to the QUIC specification , only packets containing ACK-eliciting frames should be acknowledged with an ACK. An ACK frame itself is not considered ACK eliciting, as this can result in an ACK loop. The Ivy QUIC specification did not specify this requirement, we so added it ourselves. Then, we tested the Picoquic server using one of the predefined test scenarios that come with the Ivy distribution. In this test, Ivy simulates a client downloading an HTML file from the Picoquic server under test. In each run, Ivy picks at random a behavior of the client that is consistent with the Ivy QUIC specification, thus exposing the server to a wide range of client behaviors. This exposed a case in which the Picoquic server acknowledges a client packet that contains only an ACK frame, which violates the specification (note that we used an old version of Picoquic, written against IETF draft 23, because the Ivy QUIC specification follows IETF draft 23). Our results can be replicated using the Docker setup hosted at https://github.com/GaloisInc/ivy-quic-testing-demo Lessons Learned The first snag we ran into on the project was that the Quant server  didn’t seem to interoperate well with underlying TLS libraries embedded into the test generator (the Quant server returned “TLS error 120” upon receiving packets from the test generator). We did not understand the cause of this error, and we ended up switching from Quant to Picoquic as a workaround. Picoquic uses Picotls under the hood, which is also what McMillan and Zuck’s original test generator uses. The Ivy specification covers a wide range of scenarios, and its breadth can be overwhelming.  It must be augmented by additional constraints if one wants to target a particular scenario. The test framework is designed to randomly explore all permissible actions, and thus hitting a particular test requirement is unlikely to occur without a custom spec that narrowly constrains the simulated components to particular steps. Our experience with the demo scenario above showed that creating a specific test scenario requires a good understanding of both the Ivy specification and the IETF specification. The test output, and in particular the Ivy traces, are difficult to interpret. It took a lot of digging into the code to understand which actions originated from the test environment and which actions originated from the system under test. This is no fundamental limitation, but it would take time to polish the tool to make the output more user-friendly. When a test case fails, one gets an event trace and a pointer to an assumption violation on a code line in the Ivy spec. Only someone deeply familiar with both the Ivy spec and the IETF spec can understand why a test has failed. In general (and perhaps unsurprisingly), interpreting an error requires deep knowledge of the QUIC protocol. Arbitrary debug events can be inserted in the spec to facilitate debugging. The Ivy QUIC specification covers a large part of the protocol logic but is not complete. It also does not specify serialization formats and SSL protocol logic. Therefore, it does not generate randomized tests covering those aspects (it uses concrete implementations of those to generate test inputs). The current QUIC specification written in Ivy is based on the QUIC IETF draft number 23, which is outdated. To apply Ivy to test a new implementation, the Ivy specification must first be updated to the corresponding IETF draft version. We have not tried the offline trace-checking mode, and PCAP trace capture does not work currently. Conclusions At Galois, we’re big fans of formal verification, which is the gold standard of systems assurance. But for many projects, developing a formal proof would be too expensive. At the same time, it can be difficult to test a complex system such as a network protocol. The exciting thing about McMillan and Zuck’s work is that it suggests we can have some of the best of both worlds. By using a formal model, we can systematically test a very complex protocol implementation without the cost of formally verifying the whole codebase. We’re really happy with the results we got in this preliminary study, and we hope to see a lot more research on this type of compositional testing in the future. 1 Giannakopoulou, Dimitra, C. S. Păsăreanu, and Colin Blundell. “Assume-guarantee testing for software components.” IET Software 2.6 (2008): 547-562.", "date": "2021-03-22"},
{"website": "Galois", "title": "Curious about C Verification using SAW? Start here.", "author": "Unknown", "link": "https://galois.com/blog/2021/03/curious-about-c-verification-using-saw-start-here/", "abstract": "What does long-term success look like for a verification tool like SAW ? For us, it involves improving the quality, correctness, and security of as much code as possible. We know that the best way to get there is not Galois hoarding all of the proofs and proof skills and keeping you all out. We love the proofs, but now we need to set them free. With that in mind, we set some of our best teachers to create a new introduction to SAW . It was written by Dylan Mcnamee , David Christiansen , and Chris Phifer and should take you from a machine with no SAW at all to writing your first few proofs. It’s built around a number of guided examples, guided by exercises. We’ve already used it to bring some new users up to speed, improving it each time. We’d love any feedback you have on the training, either by email or posted as issues or pull requests in its repository . Should I use SAW? Like any method for increasing the probability of your code being correct, using SAW is a matter of weighing the cost of applying the method with the benefits it will provide. The benefits of SAW include: Dramatic reduction or elimination of bug classes in C code. Ongoing correctness guarantees when included in a CI system. Unambiguous specifications for functions that can be used for code review and developer communication. New reasoning abilities for developers. The first two points can be objectively measured to some extent. They imply that SAW will become more valuable as the cost of any given bug increases. The second two points suggest that a team’s performance will be altered if it uses a tool like SAW in such a way that it can be hard to measure. The cost of applying SAW is a function of: Code complexity How often code is changed Engineer Capability The tool itself Again, the first two are somewhat measurable. A program that has already been written might be easy or hard to verify, as will each update to that program. Engineer capability is a more complicated point. While it can take a while for an engineer to become an expert with SAW, SAW can also make engineers expert in C. This is because SAW is not just a program proof tool. It is a program understanding tool. We have seen our proof engineers comprehend extremely challenging code-bases in a matter of months when they approach it through the lens of SAW. The final point is on us. We are working on many fronts to build SAW into a tool that is easy to use. One effort we have going on included the documentation that inspired that post. We’ve also been investing in user experience with a new API-based Python interface, making SAW more programmable and usable than ever before. Watch our blog for updates on these efforts!", "date": "2021-03-02"},
{"website": "Galois", "title": "Cryptol as an SMT Frontend", "author": "Unknown", "link": "https://galois.com/blog/2021/02/cryptol-as-an-smt-frontend/", "abstract": "At Galois, we’ve run into NCC’s Cryptography Group numerous times, because Galois’ services and NCC’s complement each other extremely well. For example in the ‘ blst’ cryptographic library project from Supranational , Ethereum Foundation , and Protocol Labs , NCC provided a public audit and report , while we at Galois have verified much of the core library . When I saw a recent post by Gérald Doussot ( twitter ) titled Software Verification and Analysis using Z3 I was pretty excited. It turned out to be a great article! The team definitely understands where they can get mileage using SMT solvers such as Z3. An ongoing research area at Galois involves building tools that help engineers interface with SMT solvers, especially in the world of Cryptography. In the NCC article, they use SMT-LIB directly but also say Z3 has several, perhaps more approachable APIs available, including in the Python language. Cryptol , a tool developed at Galois, is one such interface. And for me, it’s what I reach for when I need to do work like what’s shared in the NCC post. Cryptol provides, among other things: Approachable syntax Strongly typed length-dependent sequences, allowing static guarantees of program safety First-class functions, which makes it easy to build abstractions. From here on, this post was written live as I programmed the first half of Gérald’s post in Cryptol. If you’d like to see the completed code, you can find it here . If you’d like to, you can follow along. I’ve included all of the commands I use to run the program. You’ll need to get Cryptol first. Reproducing the Demo Gérald’s post starts with a demo. Find values for x and y such that x + y = 5 Let’s create a file quic.cry . In Cryptol solvers reason about functions into the Bit types (a single bit of data, like a boolean), so we’ll make one of those that takes two variables and tells us if adding them together gives 5. sum_eq_5 x y = x + y == 5 Save that one line into the file, then in the terminal: $ cryptol quic.cry That loads the file and type checks it. Now we need to tell it what we want the solver to do. In the repl type :sat sum_eq_5 That command asks for all of the variables to be satisfied. I got Main> :sat sum_eq_5 \nSatisfiable\nsum_eq_5 5 0 = True To show off, we can also curry values in Cryptol, so if I want to fix the value of x I can do that: Main> :sat sum_eq_5 3\nSatisfiable\nsum_eq_5 3 2 = True Let’s take a look at the formulation used by NCC group in SMT-LIB: ; this is a comment - it is ignored by solvers\n\n; declare x as integer\n(declare-const x Int)\n\n; declare y as an integer\n(declare-const y Int)\n\n; express the problem - e.g. add the formula to the list of \n; formulas we are trying to prove\n(assert (= (+ x y) 5)) \n\n; query the solver to determine if the SMT \n; problem is satisfiable\n(check-sat) \n\n; if it is, show one possible solution\n(get-model) and here is what the solution looked like: sat\n(model \n  (define-fun y () Int\n    0)\n  (define-fun x () Int\n    5)\n) That’s remarkably similar to what’s going on under the hood in Cryptol! We can actually see what Cryptol is doing if we set the prover to “offline” which outputs an SMT-LIB file Main> :set prover=offline\nMain> :sat sum_eq_5 6\n; Some boilerplate...\n(define-fun s3 () Int 5)\n(declare-fun s0 () Int)\n(declare-fun s1 () Int)\n(define-fun s2 () Int (+ s0 s1))\n(define-fun s4 () Bool (= s2 s3))\n(assert s4)\n(check-sat) If you compare the handwritten SMT-LIB to the Cryptol, you’ll notice that Cryptol uses a lot more definitions. This is because Cryptol aggressively breaks down expressions and shares them where possible. For many applications, this makes representations far more efficient! Checking the QUIC DecodePacketNumber Function In this section, we’re going to implement the DecodePacketNumber function. Then we’ll constrain the inputs and outputs as required by the specification and see if the algorithm suggested by the specification meets those constraints. I’m going to skip all of the explanations of what the function does. The NCC article does a great job of explaining that part. I’m just going to reproduce the SMT work. Here’s the code snippet that was analyzed. I’ll port this to Cryptol. I think it’ll be easier to use this version than the SMT-LIB version from the article because I haven’t used SMT-LIB very much. DecodePacketNumber(largest_pn, truncated_pn, pn_nbits):\n  expected_pn  = largest_pn + 1\n  pn_win       = 1 << pn_nbits\n  pn_hwin      = pn_win / 2\n  pn_mask      = pn_win - 1\n  # The incoming packet number should be greater than\n  # expected_pn - pn_hwin and less than or equal to\n  # expected_pn + pn_hwin\n  #\n  # This means we can't just strip the trailing bits from\n  # expected_pn and add the truncated_pn because that might\n  # yield a value outside the window.\n  #\n  # The following code calculates a candidate value and\n  # makes sure it's within the packet number window.\n  candidate_pn = (expected_pn & ~pn_mask) | truncated_pn\n  if candidate_pn <= expected_pn - pn_hwin:\n     return candidate_pn + pn_win\n  # Note the extra check for underflow when candidate_pn\n  # is near zero.\n  if candidate_pn > expected_pn + pn_hwin and\n     candidate_pn > pn_win:\n     return candidate_pn - pn_win\n  return candidate_pn The article starts with a bunch of limits on the input. In the case of Cryptol, we’ll save those for the properties we specify at the end. This will let us distinguish between adversarial and non-adversarial environments as we check properties. Let’s set up the function type. The article used 64-bit bit-vectors, which seems like a good choice. DecodePacketNumber : [64] -> [64] -> [64] -> [64] 3 64 bit sequences in, and 1 out. Perfect. Cryptol’s type system enforces that DecodePacketNumber must only take sequences that are 64 bits long. Otherwise, the type system will complain. Cryptol uses where which might seem a little upside-down. Here we’re saying that there’s some value called result that we define after the where keyword. DecodePacketNumber : [64] -> [64] -> [64] -> [64]\nDecodePacketNumber largest_pn truncated_pn pn_nbits = result where\n   result = 0 Sometimes it’s nice to set results to 0 or undefined to see if they type-check. If you already loaded the file in the repl it’s easy to reload once it’s been changed on disk: Main> :r\nLoading module Cryptol\nLoading module Main It type-checked! Let’s fill in the rest of the functionality. Most of it is copy-paste from the reference. We mess with the names a little since Cryptol is functional and it can be confusing to rebind names. When I was copy-pasting, I forgot that | wasn’t in Cryptol. The post says it’s bitwise or. I think it’s || . Let’s check: Cryptol> :? ||\n\n    (||) : {a} (Logic a) => a -> a -> a\n\nPrecedence 40, associates to the right.\n\nLogical 'or' over bits. Extends element-wise over sequences, tuples. that’s what we want. Same for “and”. Here’s a version of the function that type checks, I’m not sure if it’s right yet: DecodePacketNumber : [64] -> [64] -> [64] -> [64]\nDecodePacketNumber largest_pn truncated_pn pn_nbits = result where\n    expected_pn  = largest_pn + 1\n    pn_win       = 1 << pn_nbits\n    pn_hwin      = pn_win / 2\n    pn_mask      = pn_win - 1\n    candidate_pn = (expected_pn && ~pn_mask) || truncated_pn\n    result = if candidate_pn <= expected_pn - pn_hwin\n             then candidate_pn + pn_win\n             else if candidate_pn > expected_pn + pn_hwin /\\ candidate_pn > pn_win\n                  then candidate_pn - pn_win\n                  else candidate_pn The article does some division but uses a shift with an offset. I think Cryptol division should work fine here (it might be implemented that way internally, I don’t know). Our if statements look a little different than the ifs in the reference. That’s because Cryptol is a functional language, and there is no concept of a statement. In C, you might be used to updating values and calling functions in a sequence, each separated by a semicolon. The right-hand side of those sequences are expressions. Functional languages, such as Cryptol, consist almost entirely of expressions and have no statements at all. For example, a Cryptol if expression is much more like a conditional operator than an if statement in C. The reference has a single test case (probably not enough for a function with this much branching behavior). Let’s try it out. We’ll program the test vector in Cryptol: DecodePacketNumber_test1 = DecodePacketNumber (0 # 0xa82f30ea) (0 # 0x9b32) 16\nDecodePacketNumber_test1_correct = DecodePacketNumber_test1 == (0 # 0xa82f9b3) It’s nice to write the test separately so that we can see the result if the test fails. I’m sure we won’t need that, though. Main> DecodePacketNumber_test1_correct\nFalse Noooooooo. Time to bug hunt. We’ll run the program and see what we get. Main> DecodePacketNumber_test1\n0x00000000a82f9b32 Uhh weird. That looks like the result we expected but multiplied by 16 + 2… or a copy-paste error. Whoops, our implementation is fine after all, as is the one in the article. Just the article’s quote of the spec was off (The original post has been fixed since). We’ll add that 2 on the back of our test checker and everything’s happy! In the article, Z3 spits out all of the intermediate values. We don’t do that in Cryptol because it would usually be pretty hard to filter out what’s useful. It could be a cool future opportunity for debugging, though! Let’s encode some of the conditions around the function now. For example truncated-pn has a max of 2**32-1 : truncated_pn_max tpn = tpn <= 2^^32-1 There are more input requirements, so we write those down as well. There’s also an output requirement, which is that the result does not exceed 2^^62-1 . result_max result = result <= 2^^62-1 I’m going to diverge a bit from the post here because I LIKE TO VERIFY. That is, rather than asking the solver for an example of the condition being violated, I’m going to ask it if the program can never violate the condition. It’s actually almost the same question to ask, and the result will be exactly the same. Putting it all together we get: decode_packet_number_correct fn largest_pn truncated_pn pn_nbits =\n    (truncated_pn_max truncated_pn /\\\n     largest_pn_max largest_pn /\\\n     largest_pn_min largest_pn /\\\n     pn_nbits_vals pn_nbits /\\\n     truncated_bn_range truncated_pn pn_nbits) ==>\n     result_max (fn largest_pn truncated_pn pn_nbits) It’s worth noting that Cryptol has first-class functions, just like Haskell, Python, and JavaScript. That means that a function or property can take another function as an argument. You can see that we actually parameterize this property over functions with the same signature as DecodePacketNumber . This will be useful when we fix the function in a minute! Let’s try to prove that the function meets the specification: Main> :prove decode_packet_number_correct DecodePacketNumber\nCounterexample\ndecode_packet_number_correct DecodePacketNumber\n  0x3ffffffffeb2f6ad 0x000000007d2941d6 0x0000000000000020 = False We got a counterexample. Not the one that the NCC article calls out as less interesting. I won’t go through the exercise of eliminating cases one at a time, but we can do them in the same way as the article by restricting the inputs or outputs in the spec. We can also try fixing the function. In the full file that’s called DecodePacketNumberFixed . Checking that we get: Main> :prove decode_packet_number_correct DecodePacketNumberFixed \nCounterexample\ndecode_packet_number_correct DecodePacketNumberFixed\n  0x3fffffffffffffff 0x0000000000000015 0x0000000000000008 = False Huh. It seems like this failure case might be a mistake of the precondition being too permissive with the range on the first argument. I can’t claim to understand the function well enough to know if this is actually a bug. If we update the precondition we get: Main> :prove decode_packet_number_correct DecodePacketNumberFixed \nQ.E.D. Which means the property holds! Wrapping up Overall, this went really smoothly. The specification ported over nicely to Cryptol, with the only change being adapting slightly to the functional style. We were able to keep our properties separate from the implementation, which will let us use them separately later. Or to reuse the properties with different implementations. Cryptol also allowed us to work directly with hex values, which let us copy test cases directly from the spec. I plan on following this post with the Finite Field Arithmetic Verification that makes up the second part of the NCC post. I hope it goes as well as this one did.", "date": "2021-02-25"},
{"website": "Galois", "title": "2020: Year in Review", "author": "Unknown", "link": "https://galois.com/blog/2021/02/2020-year-in-review/", "abstract": "2020 was certainly an interesting year . Amidst a global pandemic and major societal issues,  keeping software and hardware systems trustworthy continued to be challenging. From election systems to ransomware to privacy breaches and online banking theft, the challenges of trustworthy software are alive and well. In this arena, Galois and our partners advanced the state of art for high assurance cryptography, software correctness, formal methods, machine learning, data science, cybersecurity, hardware, and cyber-physical systems. Even while transitioning to a 100% remote working environment for the first time in our 21 year history, we continued to share ideas through exciting new formats – including a new podcast, blog posts, articles in respected publications, and more. Thank you so much to our partners and customers, and teammates who helped this work advance. Below you can dig into some fun detail. Here’s to a prosperous 2021! This is The Way Galois led the team that created and helped run DARPA’s first-ever bug bounty program, the DARPA Finding Exploits to Thwart Tampering (FETT) . Lead by Dr. Joseph Kiniry, Dr. Daniel Zimmerman, and Reuben Broadfoot. How D-Day Relates to Zero-Knowledge Proofs The United States CyberSecurity Magazine editors invited Dr. David Archer to write an article about zero-knowledge proofs and their applications, specifically focusing on proofs of software security. Zero-Knowledge Proofs, D-Day, and the Promise of Trustable Software appeared in the magazine’s January 2021 issue. Best Practices in Reliability Galois launched a brand new podcast, Building Better Systems , about tools and techniques that make programmers, and their programs, more correct and secure. Dr. Joey Dodds and Shpat Morina host the podcast. A Series of Fortunate Blog Posts We launched the blst blog series by Dr. Joey Dodds, which describes the blst verification Galois is undertaking with Supranational, Ethereum Labs, and Protocol Labs. We regularly contributed to the Galois blog in 2020, giving further context to the work we’re doing with our partners at DARPA and beyond. We also blogged on topics related to our continuing work. For example, Dr. Mike Dodds wrote that Proofs Should Repair Themselves , about the continuing state-of-the-art formal verification of software proofs. New Grounds For Conversation We continued to work on our internal company culture. COVID 19 and the resulting stay at home orders made it difficult for co-workers to discuss their shared interests. Galois created an aid for its internal culture with Coffeebot , a program that randomly pairs up willing participants for a weekly “coffee chat.” Anyone who would like to participate can sign up on a spreadsheet by adding their name, email address, and a list of topics they enjoy discussing. Galois made the program open source so other companies could give it a try. Below, see links for our papers, talks, software releases, and public presentations we made in 2020. High Assurance Cryptography Dr. David Archer was invited to speak at 2020 Improving Privacy with Advanced Cryptographic Techniques (IMPACT) conference on the topic, “De-confliction in Large Coalitions: When you Gotta Know Where Not to Go.”  The talk covered an increasing trend of diverse coalitions needing to avoid conflicting use of shared resources. Dr. Archer described recent privacy-preserving de-confliction prototypes that show how to resolve this conundrum efficiently and securely. Dr. David Archer was a guest on the new Cryptography.fm podcast. The topic was Zero knowledge proofs and their applications for software vulnerabilities and safety. Dr. Adam Wick, Dr. Eric Davis, and Erin Chapman co-authored a paper, Invasion of the Botnet Snatchers: A Case Study in Applied Malware Cyberdeception , that they presented at Hawaii International Conference on System Sciences (HICSS). Their presentation concerned the initial steps towards a botnet deception mechanism, called 2face. As context for the work, the team showed how 2face could be used to help reverse engineer and then generate deceptive traffic for the Mirai protocol. They also discussed how this work could be extended to address future threats. Also part of the team: Jared Chandler and Kathleen Fisher of TuftsUniversity. Dr. David Darais co-authored a paper, DuetSGX: Differential Privacy with Secure Hardware , for Theory and Practice of Differential Privacy (TPDP 2020). The paper concerned publicly queryable databases over sensitive data, using differential privacy type systems (via Duet) and secure hardware (via SGX). Also part of the team:  Phillip Nguyen (University of Vermont), Alex Silence (University of Vermont),  and Joseph Near (University of Vermont). Software Correctness and Formal Methods Dr. Jennifer Paykin, Dr. Daniel Zimmerman, and Dr. Brian Huffman co-authored a paper, Formal Verification of Flow Equivalence in Desynchronized Designs , for ASYNC Symposium. They presented a counterexample to a long-accepted proof related to flow equivalence , a notion of equivalence between synchronous circuit specifications and their desynchronized bundled-data asynchronous equivalents. The paper also demonstrated how to formalize flow equivalence in Coq and provide mechanized, machine-checkable proofs of our results. Also part of the team:  Peter A. Beerel (Galois/USC). Dr. Joseph Kiniry was a panelist at “Dead or Alive? The Fate of Formal Methods in Securing ‘Everyday’ SoCs” at the Design Automation Conference (DAC) . The panel discussed using formal methods to reason about the security of hardware designs. Dr. Aaron Tomb, Dr. Stuart Pernsteiner, and Dr. Mike Dodds gave a tutorial, Symbolic Testing for C and Rust , describing how to use Crux to improve assurance of C and Rust code at the Institute of Electrical and Electronics Engineers (IEEE). Dr. Giuliano Losa co-organized The 7th Workshop on Formal Reasoning in Distributed Algorithms (FRIDA 2020) with Marijana Lazić. Dr. Charisee Chiw was invited to speak about Tensor computations, applications, and optimization at the Dagstuhl Seminar . Dr. Mike Dodds and Dr. Joey Dodds spoke at the High Confidence Software and Systems (HCSS) conference.  Dr. Mike Dodds discussed Formal Verification of Production Distributed Protocols , real-world distributed protocols focusing on the Stellar Consensus Protocol. Dr. Joey Dodds gave a talk on Verification is Engineering , a discussion of the Galois engineering process, and how we treat verification like engineering to find success in developing proofs. Dr. Giuliano Losa and Dr. Mike Dodds presented a paper, On the Formal Verification of the Stellar Consensus Protocol , for the Workshop on Formal Methods for Blockchains (FMBC 2020). They discussed the formal verification of safety and liveness properties of the Stellar Consensus Protocol, which forms the basis of the Stellar blockchain network. Dr. David Thrane Christiansen and Langston Barrett presented a video abstrac t on “Klister,” an ML-like language, at TyDe 2020 . Type-driven Development (TyDe) is a workshop on types, type-driven programming, and type-based formal methods. Klister’s hygienic type-driven macros have a predictable yet procedural programming model. Klister’s macros are hygienic because they prevent variable capture by default. They are type-driven because macros have access to the type that is expected for the expression that is to be produced. Macros are written in the full Klister language, rather than a restricted subset in the style of Scheme’s syntax-rules, and macro developers can be unaware of the type checker’s implementation details – particularly the order in which it traverses expressions. Also part of the presentation: Samuel Gelineau of SimSpace. Machine Learning Dr. Jennifer Paykin gave a presentation about quantum computing aimed at programming languages researchers at the PLanQC (Programming Languages for Quantum Computing) conference. Dr. David Darais served as a program committee member of Programming Language Design and Implementation (PLDI), a top-tier publication venue in programming languages, and Dr. Mike Dodds served on the external review committee of PLDI 2020. Dr. Walt Woods was a guest on the Data Skeptic podcast episode, Adversarial Explanations with Data Skeptic. The interview regarded adversarial explanations, which leverage a security loophole in state-of-the-art neural networks to demonstrate their internal logic more robustly. Dr. Yerim Lee, Dr. Nichole Schimanski, Dr. William Harris, Dr. Mark Tullsen, Dr. Eric Davis, Dr. Walt Woods, Richard Jones, and Sam Cowger co-authored a paper, ICARUS: Building Parsers out of Feathers and Wax , for LangSec 2020, on how real-world data formats evolve as they find use in real-world applications. The paper discussed how a comprehensive ICARUS toolchain for understanding and hardening resulting de facto formats can identify and address security risks arising from this evolution. You can also view a video of the presentation. Data Science Dr. David Archer will present the paper, Privacy-Preserving Computation on Multi-Agency Sensitive Government Data, for the New Techniques and Technologies for Statistics (NTTS) conference in Spring 2021. He will report the methods, results, and performance characterization of statistical computations on multiple linked datasets. All data remains private to individual data providers during all parts of the data analysis. Dr. David Darais co-authored Short Paper: Probabilistically Almost-Oblivious Computation , for Programming Languages and Analysis for Security (PLAS 2020). He discussed how oblivious data structures are not purely oblivious, but they are almost oblivious; or, some adventures in formally verifying oblivious algorithms. Also part of the team:  Ian Sweet (University of Maryland) and Michael Hicks (University of Maryland). Dr. James Parker presented a paper: Verifying replicated data types with typeclass refinements in Liquid Haskell for OOPSLA . The paper presented an extension to Liquid Haskell that facilitates stating and semi-automatically proving properties of typeclasses. Also part of the team: Yiyun Liu , Patrick Redmond , Lindsey Kuper , Michael Hicks , Niki Vazou . Dr. Ajay Eeralla and Christopher Lynch presented a paper, Bounded ACh Unification , for MSCS (Mathematical Structures in Computer Science), on how they designed an algorithm to solve a problem of unification modulo ACh (Associativity, Commutativity, homomorphism) theory and implemented it in Maude. Hardware and Cyber-Physical Systems Dr. Georgios Dimou served on the steering committee for the ASYNC Composium , which sought to define the direction of the ASYNC Composium and the research community as a whole. Dr. Daniel Zimmerman, Dr. Joseph Kiniry, and Max Orhai presented a paper, The BESSPIN Tool Suite : Balancing the Evaluation of System Security Properties with Industrial Needs, for GOMACTech . The paper provided a high-level overview of the BESSPIN Tool Suite, which Galois developed as part of our project in DARPA MTO’s SSITH program. The DARPA SSITH program aims to allow hardware security architectures and their properties to be expressed and reasoned about at both the abstract (model) and concrete (product) levels. Dr. Joseph Kiniry participated on the Ask the Hardware Security Experts your Security Questions panel at the Virtual Hardware Security Summit panel on the core challenges and opportunities for hardware security. Dr. Aditya Zutshi was a program committee member on Hybrid Systems: Computation and Control (HSCC) , which is one of the most important conferences for hybrid systems and the intersection of controls and computer science. Dr. Aditya Zutshi was invited to the Runtime Verification Panel for Autonomy to talk about runtime verification challenges at the 20th International Conference on Runtime Verification . Dr. Aditya Zutshi, Dr. Matthew Clark, and Yi Chou presented a paper, High Assurance Run-Time Monitoring Architecture for Autonomous Control, for AIAA SciTech , on a run-time assurance approach to provide safe recovery when using complex learning-enabled autonomous components in safety-critical systems. Cybersecurity Dr. Joseph Kiniry was invited to be a guest speaker at USC Election Cybersecurity Initiative: Oregon , the Oregon edition of the USC Election Cybersecurity Initiative (USC Annenberg Center on Communication Leadership and Policy University of Southern California). Dr. Daniel Zimmerman was a guest at the podcast embedded.fm episode, “ Integrity of the Curling Club,” concerning election security and hardware security. Dr. David Archer wrote, “ Can private data as a service unlock government data sharing? ” for Government Computer News . Government organizations hold sensitive data that can be used to improve citizen services, prevent cyber-related incursions, or provide more personalized health care. Although this data’s impact is capped because data sharing between organizations is highly restricted, emerging privacy-preserving technologies hold promise in solving this conundrum. Dr. Tristan Ravitch gave a talk, Embrittle: Binary Diversification and Fault Encouragement, at Software Security Summer School at Purdue University . This tutorial session demonstrated the tools developed under the Software Fault Encouragement for practitioners. Contract Award Announcements LINK by Dr. Charisee Chiw and Dr. Eric Davis Part of DARPA’s Computable Models (COMPMods) program, LINK aims to make it easier for scientists to build multiphysics models with an end-to-end, automatic, and portable solution. SuperMaas by Dr. Eric Davis A modeling-as-a-service (MaaS) model registry framework for existing models. Galois is developing the SuperMaaS project as part of DARPA’s World Modelers program . Galois is also partnering with the Bill and Melinda Gates Foundation and the Ethiopian government’s Decision Support Modeling Tools for Ethiopia (DSMT-E) project, which focuses on food security modeling. AIMEE Program:  SEEC project by Dr. Jennifer Paykin, Dr. Scott Moore, and Raj Petra . SEEC is part of DARPA’s Artificial Intelligence Mitigations of Emergent Execution (AIMEE) program, whose goal is to anticipate the potential for emergent computations early in a system’s design. SEEC is designed to identify unexpectedly programmable behaviors of systems that could be manipulated by bad actors. SEEC’s goal is to create a reusable framework that helps designers build systems that are resilient to these emergent computations. Extending AMIDOL to Support Integrated Platforms for Automating Scientific Knowledge Extraction by Dr. Eric Davis Galois’s Agile Metamodel Inference using Domain-specific Ontological Languages (AMIDOL) project has been a great success throughout 2020. The project funding currently amounts to $2.7 million as part of DARPA’s Automating Scientific Knowledge Extraction (ASKE) program , which was designed to encourage the automation of data models. SIEVE Program: FROMAGER project by Dr. Bill Harris, Dr. Alex Malozemoff, and Dr. David Archer A zero-knowledge proof (ZKP) is a mathematical tool that provides irrefutable proof of a claim’s validity without revealing anything else about the claim or the data used to prove it. We won a $12.6 million zero-knowledge proof contract with the U.S. Defense Advanced Research Projects Agency (DARPA) as part of the Securing Information for Encrypted Verification and Evaluation (SIEVE) program. FROMAGER seeks to scale ZKPs to support complex proof statements, such as proving that a vulnerability exists without revealing the vulnerability or proving that software satisfies safety guarantees without revealing the proof of safety. RACE Program: ROCKY project by Dr. Alex Malozemoff and Dr. David Archer Galois project, Reliable Obfuscated Communications Kit for everYone (ROCKY), won $7 million as part of the DARPA Resilient Anonymous Communication for Everyone (RACE) program. ROCKY seeks to hide critical data within network traffic through sophisticated cryptographic methods and advanced machine learning techniques – delivering a knock-out for privacy protection. GAPS Program:  PIRATE project by Dr. Joe Hendrix Galois was awarded a  $7.5 million contract by DARPA to work on PIRATE, a set of software development tools for designing and building high-performance, physically-partitioned applications that protect sensitive information. The project is part of DARPA’s Guaranteed Architecture for Physical Security ( GAPS ) program. Assured Autonomy Program:  Leveraging Symbolic Representations for Safe and Assured Learning by Dr. Matthew Clark As part of DARPA’s Assured Autonomy program, this Galois project aims to develop an assurance framework specifically for cyber-physical systems that rely on machine learning or learning-enabled controllers. NSA Vulnerability Triage Study by Dr. Ben Davis, Dr. Scott Moore, Dr. John Launchbury. This project explores opportunities for machine assistance in assessing whether software vulnerabilities should be fixed or reserved for intelligence use. ARCOS Program: RACK project by Dr. David Archer RACK (Rapid Assurance Curation Kit), part of the DARPA ARCOS (Automated Rapid Certification Of Software) program, uses a structured semantic data model. RACK specifically provides a “data ingestion interface” for ARCOS performers who need evidence to craft assurance arguments. Software Releases DaeDaLus : DaeDaLus is a flexible data description language for generating parsers with data dependencies. Format Analysis Workbench (FAW) : FAW is a platform for running and analyzing the output from many parsers dealing with a single file format. Matterhorn : In 2020, we made 9 releases of the Matterhorn project (our Unix terminal Mattermost client) and added dozens of new features and bug fixes. Hundreds of users download Matterhorn each month, and it continues to be a successful open source Haskell project that Galois maintains. Many people also use Matterhorn within Galois. (The team included Jonathan Daugherty, Kevin Quick, Eric Mertens, Isaiah Mindich, as well as community members.) Software Analysis Workbench (SAW) :  We released versions 0.5 and 0.6 in 2020 (PDI Team). Crux :  We made the first public release of Crux, version 0.4, in 2020 (PDI Team). Cryptol :  We released versions 2.9.0, 2.9.1, and 2.10.0 in 2020 (PDI Team). Flex Language:  This software was developed by Galois, and then transitioned to its spin-out, Tangram Flex. Flex Language was released in Tangram Pro 1.2. (The team included James Lamar, Andrew Kent, and Dr. John Launchbury.) Other Community Engagements Dr. David Archer: –Serves on the United Nations Privacy-Preserving Task Team steering committee , which develops opportunities and provides training to United Nation member states on privacy-preserving techniques and technology, especially for official statistics computations. –Serves as a member of the Information Science and Technology (ISAT)’s Data-Oblivious Interdisciplinary Representation (DOPLR) Working Group. Data-oblivious programming is a key enabler across several domains, yet remains impractical and unsupported by current programming languages. This working group seeks to explore the extent to which DARPA might address this problem. –Served as a program committee member for Real World Crypto Conference 2021. Dr. David Darais: –Serves as chair of the steering committee for Type-driven Development (TyDe) a workshop on types, type-driven programming, and type-based formal methods. –Provided perspectives on research opportunities in industry at the PhD Recruiting Workshop . Dr. Eric Davis: –Serves as a member of the University of Florida Industrial Advisory Board for research and academics at the University of Florida Computer and Information Science and Engineering Department. –Serves on the program committee for the American Statistical Association’s Justice, Equity, Diversity, and Inclusion (JEDI) Outreach Group. Dr. Mike Dodds: –Serves on the steering committee for the Logic Mentoring Workshop, a mentoring workshop for members of the logic community at the Logic in Computer Science (LICS) conference . Dr. Joseph Kiniry: –Serves as a member of the Board of Advisors for Verified Voting. –Serves on the editorial board of IEEE IT Pro He co-writes the column, “Formal Methods in Industry.” Dr. John Launchbury: –Identifies topics in cybersecurity that need to be brought to the attention of national policy makers for the National Academies Forum on Cyber Security. –Serves on the Information Science and Technology (ISAT) Steering Committee, shaping and shepherding multiple concept studies to help DARPA visioning. –Served on the National Security Agency’s panel of Distinguished Experts and helped select the annual best paper in Science of Security for an NSA award. –Appeared at the SEI DARPA Workshop on Software Engineering, focusing on the Identification of Grand Challenges and Visions in future software engineering. Dr. John Launchbury and Dr. Stephen Magill: –Served on the steering committee for the NSA/DARPA conference on High Confidence Systems and Software (HCSS). Launchbury and Magill shaped the content and schedule for the HCSS conference, which brings together government, industry, and academia. Dr. Jennifer Paykin: –Served on the program committee for the 5th Workshop on Principles of Secure Compilation (PriSC) 2021. Dr. Tristan Ravitch and Dr. Charisee Chiw: –Served on the program committee for the Correctness Workshop . Dr. Aaron Tomb: –Served on the program committee for Computer Aided Verification (CAV) 2020. Dr. Walt Woods: –Invited to talk at PurdelPL about understanding de facto formats through grammar inference, and why reinforcement learning might help.", "date": "2021-02-05"},
{"website": "Galois", "title": "Automated Reasoning as an Annoying Child", "author": "Unknown", "link": "https://galois.com/blog/2020/10/automated-reasoning-as-an-annoying-child/", "abstract": "This blog is the second in a series of posts about a joint project between Galois, Supranational, The Ethereum Foundation, and Protocol labs verifying the blst signature library. You can find the first post here . It’s a combination of my bad jokes and an overview of what we’re trying to achieve. It’s happening already. The development team is deep into conversations with the proof tools, and they’re taking a lot of effort. The best description of how these conversations go is “like talking to a child.” Before I get too deep into explaining what’s difficult about our work, let’s spend a post describing what exactly we’re trying to achieve and what a proof tool for program verification (like our SAW tool) actually is. A program proof tool like SAW takes a program, along with a description of what that program should do, and tells you if the two are in agreement or not. Along the way, the tool might highlight spots where it doesn’t have enough information to do this successfully or even where the program is buggy. Basically, using a program proof tool is like talking to an incredibly curious and insistent child. In fact, make that two children. Every time you tell them something, they listen, nod, and then ask, “but why?”. Then you answer questions for a while, and before long, you’re sitting in the grocery store parking lot with two masked heroes staring back at you: Creepy, I know. If all of this sounds frustrating, you’re right – it can be! But just like explaining the Clone Saga to two inquisitive Spider-Men, the feeling when the tool finally understands you more than makes up for it. Let’s do a quick example to demonstrate exactly how child-like a prover can be, and why, at the end of the day, this childish curiosity actually turns out to be a great thing. SAW helps us prove that programs are correct. We call the process of writing a proof of program correctness formal verification . How does SAW help us? The first thing SAW does is give us a precise language for describing what a program should do. We call this a specification . Specifications in SAW (and loads of other verification tools) take the form: If you have a collection of objects and variables called M (mostly described as a memory layout in C) And you call a function F with parameters P The result will be memory layout M’ and return value R Seems pretty simple right? It’s exactly how we all think about programs we write. In particular, we “skip over” thinking about the specifics of function operations by instead thinking about how they’re meant to be called, and what happens when they’re done. It’s abstraction. I really like abstraction. I also love abstraction. I guess I have Positive Feelings for abstraction. There’s a key difference in the way verification tools think about memory layouts like M and parameters like P . When we run a function, our memory layouts look like this (with respect to the tension between 1 indexing and putting a value at memory cell 0): Memory Cell 1 2 3 4 5 Value 1 3 4 8 9 Every cell of memory has a concrete variable. Concrete means we know the value. In SAW, M looks more like: Memory Cell 1 2 3 4 5 Value x y 4 z 9 We just stuck variables in there. Right in memory! Each variable represents any number . The memory cell x might contain 17, or 1729, or 127 billion, and this memory layout represents all those possibilities. That means we can use SAW to understand millions of different possible memory layouts, all using the same specification. The program F is just a normal function. Suppose it’s a (pseudocode) function that increments every value in an array. void inc_all(int[] r, size s){\n\tfor(int i=0; i<size; i++){\n\t\tr[i] = r[i] + 1\n\t}\n} Yeah yeah, I write C pseudocode. It gives you some real insight into where my head is these days. I did leave out a semicolon as a nod to my Haskell and Python buddies. We also need parameters to call this function with. Let’s say that r starts at memory cell 1 and has a size of 5 (so it ends at 5). What do we expect once the function is done? We called that memory layout M’ Memory Cell 1 2 3 4 5 Value x +1 y +1 5 z +1 10 And there you have it, a full specification of inc_all (when called at a certain size with a specific memory layout). If we know the value of x in the original memory layout, we know the value of x in the result, no matter what number we chose. The first question a proof tool asks of a proof engineer is what do you want me to prove? The answer to this question comes in the form of a specification and a program. It’s not unusual to find bugs at this stage. Just the act of trying to explain what a program is supposed to do is likely to uncover some mistakes in the program if they exist. Once we have described what the function should do, how do we use SAW to find out whether it actually does it? This is where the real questions start, and there are a lot of them! For the program inc_all SAW will ask all of these questions: Can I write integers 0..s to i? Can I dereference r[0..s]? Is r non null? Is 0..s guaranteed to be within the allocated region pointed to by r? Can I write to r[0..s]? Is r non null? Is r read-only? Is 0..s guaranteed to be within the allocated region pointed to by r? Does the M’ that the proof tool obtained match the one suggested in the specification for each memory value? It’s a lot of questions for a 2 line program, but each of these questions guards against a particular thing that could go wrong in the program. It turns out many things can go wrong in C without semicolons. After all, C is a powerful language, and with great power comes great responsibility. Uncle Ben always knew the perfect thing to say on the first day of class. The good news is that proof automation allows the proof tool to answer many (or sometimes all) of these questions without any help from the programmer! In fact, that’s most of what SAW does – ask questions, and then answer the questions itself. Spider-Men don’t do this unfortunately. The best thing about program proof tools is that they will always ask every question, no matter how meticulous, and that they won’t prove a program correct unless they are fully convinced of the answers. This meticulousness is a notion we often refer to as soundness . If you want to send me on a rant, please ask me how I feel about the phrase soundness. I don’t even know why I brought it up. It couldn’t possibly be because I want you to engage with me on Twitter about it (I’m @ n1nj4 ) . In this case, our proof automation can answer all of these questions about the program, which means the proof will succeed. In other cases, either the code or the specification is wrong, and we need to figure out how. Again, a lot of the bugs get shaken out just because our proof engineers know that the tool will be asking so many questions of the code. It leaves no room for sloppiness or for hand-waving errors. The proof tool reduces most code to either correct or incorrect with regards to a specification, and it will not consider the proof complete until it is fully convinced. Learning to think about programs on top of a framework like this fundamentally changes the way proof engineers think about programs. In fact, our tech lead, Andrei Stefanecsu , will often analyse a new piece of code with SAW first, instead of inspecting it manually. This is because for him, SAW provides a useful framework for thinking about the important properties of code rather than the surface structure. If you’ve spent time programming, you’ve likely had your thinking transformed by program reasoning tools. Everything from type systems to functions influence our thinking about programs, to the point where even when they’re not available we use them to guide our programming. Ask any programmer who’s moved from a strongly typed language to a dynamically typed one, or a Rust programmer who has gone back to using C. Program proof tools like SAW and others are a natural extension of this. In particular, the child-like aspects of program proof tools change the way that engineers think about their programs. Developing the mindset of never getting away with anything because you know that the tool will call you on it will make you a better programmer in the same way kids make you a better person by asking you why you need 8 boxes of cookies when you take them to the grocery store. All of this becomes more concrete in the details of how we specify programs and develop proofs. For the next post in this series, I’ll show you some examples of our blst specifications and break them down in detail.", "date": "2020-10-27"},
{"website": "Galois", "title": "Proofs Should Repair Themselves", "author": "Unknown", "link": "https://galois.com/blog/2020/12/proofs-should-repair-themselves/", "abstract": "In his 1900 book The Wonderful Wizard of Oz, L. Frank Baum tells a story that will resonate with any software engineer. A woodman by the name of Nick Chopper suffers a series of workplace accidents. In turn, his arms, legs, body, and even his head are replaced by metal prosthetics. Eventually, what remains is an entirely different man made of tin. Like Baum’s Tin Man, all software projects are repaired and reconfigured, and a project can transform by degrees into something entirely unlike its starting point. As software engineers have long known, this shift of code and specification is the norm. Studies have shown that maintenance consumes the majority of resources in large-scale projects 1 , and many systems are built on the bones of previous projects. In recent years, many companies have begun to use formal proofs to provide assurance for software. For example, AWS now formally verifies significant portions of its s2n library, which provides cryptographic security for Amazon.com, Alexa, and more. Proofs are used for assurance at Facebook, Google, Intel, Apple, and others. For these companies, proof engineering is software engineering . As software evolves, proofs of that software must evolve in kind. A key method for success at these companies has been a close alignment between proof tools and continuous integration (CI) development environments. This linkage between proofs and code means that edits to the code can be rechecked within seconds in order to re-establish assurance of the software as it changes. However, experience shows this linkage is fragile. Automated tools can often re-establish a proof if code changes are small. But if the code is restructured beyond a certain point, proof tools are typically unable to re-establish a proof of correctness, even if the software contains no defects. Instead, the internal scaffolding of the proof must be rebuilt by hand by a formal methods expert. Consequently, proofs are tended and maintained by embedded proof experts who work alongside regular software engineers. This approach cannot scale, and therefore proof repair is a scalability issue. If proofs require regular repair by experts, there is an inherent limit on how widely they can be deployed. Formal methods experts are in short supply, and the time and cost involved in the manual reconstruction of proofs is considerable. For the foreseeable future, human expertise will continue to be necessary in constructing formal proofs, but we should aim for the effort of maintaining a proof to be comparable to the effort of maintaining the software. If we are to reach a world where proofs are a routine part of software engineering, then moderate code changes should result in moderate — and automated — proof repairs. We have reason to think such proof repair is tractable. Rather than trying to synthesize a complete proof from nothing — a problem known to be immensely difficult — we start from a correct proof of fairly similar software. We will be attempting proof reconstruction within a known neighborhood. Successful proof repair is likely to require a combination of different strategies. For example: Local repair search. Many properties in a proof are local to a particular piece of code, meaning that a code change may only invalidate a small portion of the proof. Often, proof tools do not consider this locality and perform a potentially exponential analysis of all the code. By the same token, when proofs fail, current proof tools do not do a good job of localizing the source of the failure in the program. In many cases, it will be possible to adapt proof tools to search locally for repairs to existing proofs. When a proof requires repair, the tool would identify the minimal slice of code and proof affected and then search for a local fix to re-establish assurance. Change-resistant proofs. Formal proofs represent two kinds of properties: fundamental properties necessary to assert correct behavior, and accidental properties that reflect the structure of the code. Most current proofs intermingle these concerns and become inflexible in the face of changes in the code. Proofs should be designed reducing the coupling between the fundamental properties and the accidental. When proofs express such distinctions, it will be more feasible to identify opportunities for repair in the structure of the proof itself. Transfer learning between proofs. Proofs, like programs, are very diverse, but repairs often follow a small set of patterns. Current proof tools operate on the current code alone, independent of any other patterns. The new research area of Big Code has identified approaches for applying machine learning to code updates by observing code use patterns and corresponding properties. Where such patterns arise again, even in quite different applications, the proof tool will obtain guidance (akin to human insight) regarding techniques to try to affect the proof repair. Learning from other uses creates a virtuous cycle, where successful proof repairs add to the examples driving learning. Understandable proof repairs. Some repairs can be applied automatically, but some will require input from humans even with local code changes. Currently, proof tools require formal methods expertise. We believe it is possible to create a path whereby the software developers — who intuitively understand the intent of their code — can interact with the proof repair tools. Tools should propose possible repairs in terms that make sense to software developers, including explanations of the ramifications of change for the overall assurance results. The tools may go as far as to demonstrate that a proof cannot be repaired, and suggest possible program repairs instead. An increasing number of real-world software projects now have accompanying proofs. Some of these proofs are already integrated into software engineering pipelines. This represents both a risk and an opportunity for proof engineering as a field. No matter the assurance gains that are possible from proofs, if they can’t be maintained, they will quickly be set aside. We must quickly develop techniques that can deal with change, which is ubiquitous in real software. Nonetheless, there is reason for optimism. Automated proof repair is little studied, and (as I have laid out above) there are several possible avenues for success. Many of the current commercial proofs are open source, with complete changelogs stored in their repositories. This represents a rich set of test data with which we can refine our ideas. The time is right for ambitious research to solve this problem, and we are just getting started. Thanks to Byron Cook, John Launchbury, and Mike Whalen for comments on this post. 1 For a survey of research, see “Software Maintenance Costs”, by Jussi Koskinen. https://wiki.uef.fi/display/tktWiki/Jussi+Koskinen", "date": "2020-12-08"},
{"website": "Galois", "title": "SuperMaaS: A Model Registry That Helps Real-Life Superheroes Respond to Crises in Real-Time", "author": "Unknown", "link": "https://galois.com/blog/2020/12/supermaas-a-model-registry-that-helps-real-life-superheroes-respond-to-crises-in-real-time/", "abstract": "Galois is innovating ways to create accessible data models or make existing data models actionable during a crisis like COVID 19. I blogged about this in April and, more specifically, in October when I wrote about our AMIDOL project . This month, I wanted to talk about our exciting work with SuperMaaS – a modeling-as-a-service (MaaS) model registry framework for existing models. Galois is developing the SuperMaaS project as part of DARPA’s World Modelers program . Galois is also partnering with the Bill and Melinda Gates Foundation and the Ethiopian government’s Decision Support Modeling Tools for Ethiopia (DSMT-E) project, which focuses on food security modeling. In September 2020, DARPA and stakeholders from DSMT-E were able to use a simulated version of SuperMaaS. The simulation involved “food shock cascades.” A “food shock” is any crisis that affects scarce food supply. A food shock could be a natural disaster, or it could result from a societal effect, such as a spike in agricultural prices. Participants were able to model the effects of the following food shock cascades on Ethiopia’s food supply: COVID 19’s supply chain disruptions, desert locusts affecting crops; floods; and refugees migrating from other countries. I’m pleased to say that SuperMaaS worked as we intended: participants successfully examined data from each food shock cascade and predicted outcomes using the SuperMaaS tool. But how, exactly, does SuperMaaS work?  Read on to learn more. “Look! Up there in the cloud! It’s … SuperMaaS!” Modeling-as-a-Service (MaaS) is a state-of-the-art solution for outputs based on existing data sets. SuperMaaS takes this concept further. Our idea is to combine human and machine intelligence so that professionals of all skill levels – domain modelers, general modelers, and policymakers – can update a data model in real-time, with fewer errors. Many of us “team-up” with machine learning software on a daily basis; if you’re typing on a word processor, you’re teaming up with a machine. SuperMaas is designed to do a far more complicated task:  multiple groups teaming up with multiple machines. Experts would use interfaces designed specifically for their work. For example, an analyst’s interface would look different from a general modeler’s interface (which can see the underlying model) and a domain modeler’s interface. The Justice League of Data Models We intend to make SuperMaaS a model registry for domain modelers, but how do we do that? This is the process we are developing: The goal of the model registry process is to simplify many tasks that domain modelers do by hand. The model registry would take a domain modeler’s code and create an abstract version of the model in SuperMaaS. The model would then be considered a registered model in SuperMaaS. The model registry takes common design patterns present in many scientific models and creates a simplified interface for all registered models. This would work for hand-coded models, machine-learned models, and even models that are nothing more than simple scripts. SuperMaaS uses containers, instead of virtual machines, to create interfaces. Containers provide powerful capabilities to handle complex run-time requirements, execution environments, and more. Our end goal is to support a registry process that can be completed in a day or less by a domain expert with minimal knowledge of the process of containerization. Fortress of Datacubes SuperMaaS also seeks to simplify model outputs. Currently, model outputs are not actionable in real-time because they are often incompatible with other models. SuperMaaS is testing a new concept called the datacube , which is a type of point lattice. The axes of the datacube would be annotated with mappings to a hierarchical concept graph within SuperMaaS. This would help users search for, interpret, and transform datacubes for analysis, visualization, and comparison. Datacubes produced by models will also be labeled automatically, allowing users to easily search for different types of data. For instance, if a user had a datacube with a temperature in Kelvin but needed data representing Celsius, SuperMaaS would locate the correct transforms so they can find the part of the concept map they need to see. Additionally, the general modeler interface in SuperMaaS helps a general modeler discover models or data within SuperMaaS that can be used to generate datacubes based on requests from analysts. Real-World Problems Solved in Real-Time So, what’s next for SuperMaaS? Participants at our September presentation helped identify some bugs that we are currently addressing. For example, we will work to smooth out interactions between analysts, general modelers, and domain modelers and close feedback loops. Data scientists, academics, and policymakers are the real-life superheroes of our world. And the effort to amass real-world models in real-time and then update those same models is nothing short of superheroic. Stay tuned for further updates, true believers! To read more about SuperMaaS, see our project page . You can also read about the SuperMaaS Hackathon event we held in June 2020 . This material is based upon work supported by the Army Research Office/Defense Advanced Research Projects Agency and the Army Contract Command under Contract No. W911NF-20-C-0056. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the Army Research Office/Defense Advanced Research Projects Agency and the Army Contracting Command.", "date": "2020-12-01"},
{"website": "Galois", "title": "Keep Moving Data Forward: Galois TKOs $7M DARPA Contract for ROCKY", "author": "Unknown", "link": "https://galois.com/blog/2020/11/keep-moving-data-forward-galois-tkos-7m-darpa-contract-for-rocky/", "abstract": "In the film Rocky Balboa , Rocky tells his son , “Nobody is gonna hit as hard as life. But it ain’t how hard you hit; it’s about how hard you can get hit and keep moving forward.” At Galois, we appreciate Rocky’s tenacity and inventiveness. Rocky is the ultimate underdog who perseveres despite overwhelming odds. We think these attributes are indispensable when we talk about assuring the security of data – its confidentiality, integrity, and availability – particularly data moving through networks where an adversary may have an overwhelming capability to surveil – and censor – communications. We’re pleased to announce a project entitled Reliable Obfuscated Communications Kit for everYone, or ROCKY, part of the DARPA Resilient Anonymous Communication for Everyone (RACE) program. ROCKY is currently in its first phase, but we’ve already achieved two significant program milestones in early field test exercises of undetectable communications schemes. In both exercises, we exceeded expectations for reliability and delivered bandwidth. These initial schemes “hide in plain sight,” mimicking normal, everyday communications in the same network area. We foresee many opportunities for ROCKY. We plan to make ROCKY open source and see the potential for many applications outside the government sphere. In particular, we’re discussing transition opportunities with NGOs focused on censorship avoidance around the world. To learn specifics about the ROCKY project, visit our project page . Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the United States Air Force and DARPA. This project or effort depicted was or is sponsored by the Air Force Research Laboratory (AFRL) and DARPA under contract number FA8750-19-C-0085. Distribution Statement “A” (Approved for Public Release, Distribution Unlimited).  If you have any questions, please contact the Public Release Center.", "date": "2020-11-19"},
{"website": "Galois", "title": "Introducing the Building Better Systems podcast", "author": "Unknown", "link": "https://galois.com/blog/2020/11/introducing-the-building-better-systems-podcast/", "abstract": "Shpat Morina and I are happy to introduce the new Galois podcast, Building Better Systems. We put this podcast together to provide us an opportunity to have deep, directed discussions with anyone who wants to build better systems. We’re approaching the challenge from two sides. We want to know what challenges people face today and what’s coming next to help people build more correct and secure systems than anything we’ve seen in the past. We want all of the techniques we discuss to be applied (or at least applicable) to real systems, so we’ll steer away from conversations that are too deeply technical. Our guests will include everyone from faculty members doing cutting edge software correctness researchers to engineers who are applying modern techniques daily to improve the quality of their work. We’ll also talk about cryptography, hardware, and concurrent systems because each of these fields presents unique challenges and solutions as we think about system quality. Building Better Systems is available on Apple Podcasts , Spotify , Stitcher , and other podcast platforms. You can also subscribe and watch on our Youtube channel . We’re actively looking for guests. If you have recommendations (including yourself), please reach out to us at podcast@galois.com. Otherwise, enjoy listening, and please ask questions if you have them, or share your thoughts with us via Twitter !", "date": "2020-11-13"},
{"website": "Galois", "title": "Demo: Symbolic Testing of Rust using Crux", "author": "Unknown", "link": "https://galois.com/blog/2020/10/demo-symbolic-testing-of-rust-using-crux/", "abstract": "The standard development tools for the Rust language provide a convenient mechanism for embedding tests within your code that can then be automatically run using the `cargo test` command. This video shows how to migrate from testing to verification of Rust programs by converting a standard Rust test to use Galois’ Crux tool. Crux can automatically ensure that tests will not fail for any possible input value of a given type, rather than the limited set of manually or randomly chosen inputs used for normal test suites. It exposes this functionality through a very similar `cargo crux-test` command. Here we demonstrate how easy it can be to adopt verification within a project by demonstrating Crux on a real-world cryptographic library, curve25519-dalek . Learn more about Crux on our blog or at crux.galois.com", "date": "2020-10-23"},
{"website": "Galois", "title": "Crux: Introducing our new open-source tool for software verification", "author": "Unknown", "link": "https://galois.com/blog/2020/10/crux-introducing-our-new-open-source-tool-for-software-verification/", "abstract": "We are happy to announce the first formal release of Crux , a new open-source verification tool from Galois. This new tool aims to improve software assurance using symbolic testing, a technique that allows for smooth migration from testing to verification. Crux builds on the same infrastructure as our Software Analysis Workbench (SAW) , but with a much simpler user interface. Using Crux Preparing input for Crux is similar to the process of integrating with many common testing frameworks, including the testing support built into the Cargo tool for Rust. To use Crux, you write code similar to a test harness that consists of the following steps: Specify or generate values for all inputs. Execute the code to be tested on those inputs. Check that the result of executing the code satisfies some correctness criteria. Crux works with both C/C++ and Rust code. As a first example of how it works, consider the following normal Rust test harness, not using Crux: #[test]\nfn test_inc_correct_concrete() {\n    let x = 12345;\n    assert!(x + 1 > x);\n} The #[test] attribute on this function indicates that it should be executed when running the cargo test command, which in this case, will succeed. The following code checks the same property using Crux: #[crux_test]\nfn test_inc_correct_symbolic() {\n    let x = u32::symbolic(\"x\");\n    assert!(x + 1 > x);\n} Instead of specifying a single concrete input, this code generates a symbolic input using the u32::symbolic call. The result, stored in x , can be thought of as simultaneously representing all possible values of type u32 . Similarly, the #[crux_test] attribute on this second harness indicates that it should be executed when running the cargo crux-test command. If you’re familiar with two’s complement arithmetic, and Rust’s default overflow checking , you might have noticed, however, that there’s a value of x for which the call to assert! would fail, namely the largest 32-bit unsigned integer. And, indeed, Crux will report failure for the version of test_inc_correct_symbolic above. Consider the following modified version, instead: #[crux_test]\nfn test_inc_correct_good() {\n    let x = u32::symbolic(\"x\");\n    if(x != u32::MAX) {\n        assert!(x + 1 > x);\n    }\n} There are now no values of x that will result in assert! being called with an argument of false , and Crux can quickly confirm this (almost as quickly as running the single concrete test described first). How Crux Works We call Crux a symbolic testing tool because it uses an interface very similar to existing test frameworks. But, instead of executing your program normally, Crux uses a process called symbolic execution to build up a mathematical formula that describes what the output or resulting state of the program will look like for any possible values of any symbolic inputs. In the common terminology used by the field of program analysis, the values used during normal program execution are called “concrete” values, and formulas representing many possible executions of the program are called “symbolic” values. Symbolic execution is then the process of executing a program on symbolic inputs and constructing a symbolic result. When encountering a call to assert! , Crux passes the symbolic value of its argument to a tool called a Satisfiability Modulo Theories (SMT) solver. The solver can automatically either prove that the formula is true, regardless of the values of any variables it contains, or produce a concrete value that makes it false. For those interested in the more technical details, Crux builds on a symbolic execution engine called Crucible that: Uses path merging by default. When symbolic execution of two separate paths reaches the same point in the control flow graph (a node that post-dominates all nodes in both paths), Crux will merge the two paths’ symbolic states into a single symbolic state. Optionally, this behavior can be turned off, and Crux will explore each path independently until reaching the end of the program. Supports many SMT solvers, including Boolector, CVC4, dReal, STP, Yices, and Z3. Uses aggressive formula simplification and common subterm sharing to keep symbolic values small. Allows path satisfiability checking to be turned on or off. Attempts to construct a complete final symbolic state for the program, making it suitable for verification of programs that are intrinsically bounded. Options exist to impose bounds on execution depth for bug finding in programs with potentially unbounded execution. Supports profiling of the symbolic execution process with an HTML-based profile viewer. Profiles include symbolic execution time for each function and solving time for each call to an SMT solver. Supports reasoning about floating-point values using either the real or floating-point theories available within some SMT solvers. The interface provided by Crux is similar to that provided by CBMC and other tools that participate in the Competition on Software Verification (SV-COMP) . At the moment, Crux works very similarly to CBMC on C code, though we have future plans to build on the SAW infrastructure to support features not available in CBMC. Getting Crux and Learning More Two versions of Crux exist. The first, Crux-LLVM, can analyze C and C++ code by working with the LLVM intermediate language generated by the clang compiler. In principle, Crux can also analyze LLVM code generated from compilers for other languages, but it has been more widely tested on C and C++ programs. The second, Crux-MIR, can analyze Rust code by working with the MIR language used internally by the Rust compiler. More information on Crux is available on the Crux website , including a video demonstrating its use to verify portions of the curve25519-dalek Rust library. For a complete summary of the API available within user programs for interacting with Crux, see the C header file and Rust module that define them. Binaries of Crux-LLVM and Crux-MIR for Ubuntu Linux and macOS are available on GitHub . We expect to make binaries for other platforms available in the future. Crux can also be used through Docker by downloading one of the images from DockerHub : docker pull galoisinc/crux-llvm:0.4 docker pull galoisinc/crux-mir:0.4 We’d love feedback! Feel free to file issues here , or contact us at crux@galois.com .", "date": "2020-10-19"},
{"website": "Galois", "title": "Demo: Control SAW From Any Language", "author": "Unknown", "link": "https://galois.com/blog/2020/10/demo-control-saw-from-any-language/", "abstract": "The Software Analysis Workbench (SAW) is one of Galois’s flagship verification tools. SAW has been used to verify important, real-world cryptographic algorithms, such as AES block cipher , the Secure Hash Algorithm (SHA), and Elliptic Curve Digital Signature Algorithm (ECDSA). We have used this to verify existing, widely used libraries such as libgcrypt and Bouncy Castle . SAW is highly automated, using a combination of symbolic execution, automated solvers, and human guidance. Traditionally, SAW proofs are orchestrated using SAWScript, a custom DSL reminiscent of ML and Haskell. Recently, however, my colleagues and I have been working on a new interface to SAW. This new interface is a JSON-RPC API that enables SAW to be controlled from any language. Or at least any language that supports either sockets or pipes! As part of this ongoing development, we’ve constructed a Python interface. Using a popular programming language lowers the entry barriers for new users. It gives us access to a rich world of libraries, making it much easier to produce convenient user interfaces. This video demonstrates our prototype Python interface to SAW. I hope you enjoy it!", "date": "2020-10-15"},
{"website": "Galois", "title": "LINK: A $1M DARPA Contract to Help Scientists Build Better Multiphysics Models", "author": "Unknown", "link": "https://galois.com/blog/2020/10/link-1m-darpa-contract-build-better-multiphysics-models/", "abstract": "We’re pleased to announce Galois’s LINK project, part of DARPA’s Computable Models (COMPMods) program. The project aims to make it easier for scientists to build multiphysics models with an end-to-end, automatic, and portable solution. Multiphysics models are challenging to create, customize, and reuse. One problem is the software and hardware are often outdated, which makes it difficult to leverage solutions for more than one physics type. Even when legacy systems use one type of physics, the code combines the problem and solution, and this is not always transferable to a different kind of physics that needs to be modeled. For us, working with scientists and thinking of ways to solve their domain problems with custom tools is a dream come true. The LINK project team consists of computer scientists with strong engineering skills, so we have proactively engaged with domain experts during the development process to understand their workflow, current tools, and issues.  We have been working on designing an interface with those practicalities in mind. A Textbook Multiphysics Problem Let’s use NASA as an example. NASA is interested in designing vehicles with increased payloads suitable for launching advanced robotic and human missions to Mars. However, the payload requirements for these missions exceed current capabilities, which use traditional parachutes to decelerate. One potential solution is reducing the vehicle’s speed for entry, descent, and landing with aerobraking and retro-propulsion. NASA wants to model how the thermal protection material is affected by the retro-propulsion system during descent. This is a “textbook” multiphysics problem with multiple components: fluid flow, thermodynamics, and solid mechanics. The problem is that there is a manual translation to high-performance code, models for each physics component are created independently, and they all use different solvers. There is no unified system to address the missing features. To address this problem, we’re designing LINK to help domain scientists separate what they want to compute from how they want to compute it. LINK would provide scientists with domain-specific languages (DSLs) that use terminologies familiar to each scientist’s domain, making it easier for scientists to quickly and accurately build models. LINK would have several DSLs, giving domain experts unprecedented freedom to prototype for particular types of physics. We want to empower scientists to define their problem and trust LINK to automate the rest. That includes writing a problem definition and coupling in DSLs, a compatibility check for the independent models, and generation of high-performance code. We believe LINK’s use of domain-specific tools to define domain problems will result in more reliable and efficient code. We also think it is a superior solution to the current scenario where domain experts work with general programming languages. LINK would provide clear abstractions for the users in their specific domains of interest. Our objectivity allows us to take a step back and consider making the whole modeling toolchain better and creating impactful change. To learn more about LINK, please see our project page . Approved for public release; distribution is unlimited. This material is based upon work supported by the Defense Advanced Research Projects Agency (DARPA) under Agreement No. HR00112090064", "date": "2020-10-13"},
{"website": "Galois", "title": "Galois team wraps up the Jana project", "author": "Unknown", "link": "https://galois.com/blog/2020/10/galois-team-wraps-up-the-jana-project/", "abstract": "After four and a half years of work on the DARPA I2O Brandeis Program, we are excited to announce the completion of Jana, a project which set out to develop accessible privacy-preserving data as a service (PDaaS) to protect the privacy of data subjects while retaining data utility to users. The Galois-led Jana project aimed to demonstrate how interoperable, open-source cryptographic algorithms, secure computation, relational databases, and privacy-preserving analytics can be combined to provide practical solutions that translate to real-world frameworks. We are thrilled to share some of the Jana project contributions, including technical innovations and real-world applications. Why is PDaaS important? As the world’s capacity and effort to collect, store, and mine data continues to grow exponentially, organizations have come to rely on access to that data as a fundamental service on which their business models rely – Data as a Service (DaaS). Unfortunately, privacy assurance about that data has not kept pace. Data breaches occur by the thousands each year. Insider threats to privacy are commonplace. De-identification of data can often be reversed and has little in the way of a principled security model. Data synthesis techniques can only model correlations across data attributes for unrealistically low-dimensional schemas. Jana was inspired by the challenge of developing capabilities to prevent unintended privacy gaps while maintaining utility features important to relational database users. Our approach to achieving these results includes end-to-end data encryption, even during computation, formal methods to analyze privacy leakage, and differential privacy to mitigate that leakage. Jana Contributions We tackled a lot throughout the Jana project, but we’re especially proud of a few stand-out things about the Jana PDaaS system. Jana Is currently the only pluggable relational database replacement that employs secure computation to guarantee privacy. Is currently the only system to compute differential privacy within the secure computation engine, assuring that the database server learned nothing during the process of adding differential privacy noise to query results. Is currently the only system of its kind that incorporates role-based policies to control access to query results, enforcing those policies within the secure computation engine. Uniquely enables the database administrator to select how information is stored and processed in the Jana engine: unencrypted for non-sensitive data; property-preserving encrypted for time-sensitive queries where data resists the kinds of leakage typical in property-preserving encryption systems; or encrypted secret shares for sensitive data where query processing time is less constrained. Challenges in Realizing the Jana PDaaS System Jana confirmed some of the key challenges we expected when proposing this effort. Performance of queries evaluated in our linear secret sharing protocols remained disappointing, with JOIN-intensive and nested queries on realistic data running up to 10,000 times slower than the same queries without privacy protection. Generation of appropriate randomness inside our secret sharing engine for specifying differential privacy noise addition also encountered some performance constraints. The information-theoretic leakage of property-preserving encryptions was surprisingly stubborn, although novel techniques were developed by our team to address those problems. Finally, the fundamentals of differential privacy and its extension toward practical, understandable privacy budgets remained a challenge throughout the project. Real-world applications of Jana The primary purpose of Jana was as a research platform to study the trade-space of privacy versus query performance for diverse database sizes. Jana fulfilled that need, but also showed its value in real-world prototype applications. One such prototype was used in a study sponsored by the Bipartisan Policy Center . This study focused on inter-agency sharing of sensitive data for developing public policy, such as resource allocation for public good. Jana in Education As part of the Jana project, Galois released an open-source version of Jana for use in an upper-level class about secure computation at Columbia University. This was the first class at a major university to receive hands-on access to a secure computation platform while needing no direct support from the system’s creators. We hope that this will contribute to CS education on a broader scale in the future. Other Key Contributions of the Jana Project While the Jana PDaaS system was a key part of the overall Jana project, our team built prototypes and demonstrated practical performance using technologies divergent from that system. Most notably, the Jana team brought its expertise to bear on several prototypes that employed Private Set Intersection (PSI) techniques. In PSI, two or more groups willing to share data (but needing to retain the privacy of that data) conduct a protocol that reveals, to parties agreed on in advance, only the common data held by the parties (which we call the intersection of their separate data sets) or some function of that intersection. One such prototype was a naval conflict avoidance tool suited to prevent navies conducting exercises in the same general area from accidental engagement, while keeping their exercise plans private. Another such prototype enables data sharing among government organizations to analyze longitudinal outcomes where different organizations hold diverse data about the same individuals, while preventing organizations from learning anything else about each others’ databases. Yet another prototype enables de-confliction of network resources in cyber-security settings, allowing parties to learn only how many other parties plan on utilizing the same resource. The Forward-Looking Face of Jana Jana, our project’s namesake, is the two-faced Roman goddess of secrets and doorways. Some say that one of her faces looks always to the future, and one to the past. We at Galois look to the future as well: a future where organizations can analyze data contributed by all, while revealing nothing except the beneficial results of that analysis. Today, policy and statute largely enshrine the notion that such a future is not possible. From Jana and our other continuing projects, we at Galois know different. In future projects and technology transition efforts, our secure computation team aims to show how and where the notion of computing on encrypted data can achieve those privacy goals while also providing practically performant solutions for the data mining problems of the future. This material is based upon work supported by the Defense Advanced Research Projects Agency (DARPA) and Space and Naval Warfare Systems Center, Pacific (SSC Pacific) under Contract No. N66001-15-C-4070.  Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of DARPA or SSC Pacific.", "date": "2020-10-08"},
{"website": "Galois", "title": "Discovering and Mitigating Emergent Computations With Innovative Program Synthesis", "author": "Unknown", "link": "https://galois.com/blog/2020/10/discovering-and-mitigating-emergent-computations-with-innovative-program-synthesis/", "abstract": "One of our previous projects explored how flaws in the design and implementation of systems can introduce “weird machines” that make them vulnerable to exploitation. Now we have begun a follow-up project, Synthesizing Evidence of Emergent Computation (SEEC). SEEC is part of DARPA’s Artificial Intelligence Mitigations of Emergent Execution (AIMEE) program, whose goal is to anticipate the potential for emergent computations early in a system’s design. SEEC’s objective is to develop tools that allow users to: Analyze system designs to determine if they allow emergent computation, Generate concrete examples of emergent computation, Identify which computations pose the greatest risk of exploitation from attackers, and Prototype mitigations that prevent emergent computations. SEEC is innovative because of its program synthesis approach, which automatically searches for vulnerable components and the programmable behaviors they enable. SEEC is being built upon Rosette , a Racket dialect with support for solver-aided programming. Theoretical applications of SEEC might include prototyping novel platforms such as the secure hardware being developed by DARPA’s SSITH program . Another application could be evaluating compiler mitigations against speculation vulnerabilities such as Spectre and Meltdown. Directly testing for the presence of information leaks that lead to these vulnerabilities is challenging. SEEC can potentially identify residual vulnerabilities after a mitigation is applied because SEEC would automatically reason about differences in possible behaviors between an ideal model of a system and a potential implementation with mitigations. Plus, SEEC performs these functions without requiring the designer to think of all possible workarounds or new exploits. The end result of this project will be a framework that helps designers avoid costly security problems before a system or vulnerability mitigation is implemented, rather than reacting to the discovery of highly exploitable vulnerabilities in a system once it has been deployed. For more information on SEEC, see our project page: https://galois.com/project/seec/ Approved for public release; distribution is unlimited. This material is based upon work supported by the Defense Advanced Research Projects Agency (DARPA) under Agreement NO. HR00112090030.", "date": "2020-10-07"},
{"website": "Galois", "title": "Galois’s AMIDOL Wins $2.7M From DARPA, and Aims To Make COVID-19 Modeling Actionable In Real-Time", "author": "Unknown", "link": "https://galois.com/blog/2020/10/galoiss-amidol-wins-2-7m-from-darpa/", "abstract": "We wanted to update our April 2020 blog post which discussed the goal of creating open and accessible COVID 19 data models. I’m pleased to report that Galois’s Agile Metamodel Inference using Domain-specific Ontological Languages (AMIDOL) project began its third phase in May 2020. The entire AMIDOL project has been a great success. The project funding currently amounts to $2.7 million as part of DARPA’s Automating Scientific Knowledge Extraction (ASKE) program, which was designed to encourage the automation of data models. AMIDOL aims to be a platform that helps domain experts, scientists, and programmers create more accurate and updateable models in real-time.  Policy makers at the local, state, and federal level all rely on scientific models to help them manage imminent or existing emergencies. However, it is difficult to make these models actionable – reproducible and modifiable in real-time – because the models are based on pure mathematics, and the underlying data is not made available to other agencies or domain experts. When scientists recode models with their own data sets, it is a lengthy and painstaking process. AMIDOL is making great progress in addressing these challenges. Our current work focuses on the COVID 19 pandemic – we are primarily aiming to establish model credibility. We’ve had promising success resolving differences between scientific theory and its implementation, and in making scientific models actionable. Doctor, Doctor, Give Me the News AMIDOL uses an innovative three-phase approach. The first stage involves creating a set of domain-specific languages (DSLs). In the case of COVID 19, we aim to help enable scientists to generate code directly from diagrams representing susceptible patients, infected patients, and recovered patients. We’re also aiming to help scientists create equations that describe the pandemic. Current modeling practices require scientists to write programs in general-purpose languages. This often introduces errors into the model because scientists are trying to replicate a model from their notes. Each time the scientist crafts code by hand, it can lead to errors, because the coding required to make an equation replicable is not usually a scientist’s core skill. As we noted in April, one of our aims was to help “clean” models that have errors in them.  When scientists import a model into AMIDOL, errors can be identified and often automatically repaired in AMIDOL’s Intermediate Representation (IR). If scientists build a model within AMIDOL, they wouldn’t need to hand-code at all. They could simply use existing mathematical or formal diagram representations they wish to model. AMIDOL takes these representations and automatically synthesizes code on the back-end. This ability to factor in (or factor out) data in the IR gives a scientist the ability of a software engineer without needing to actually be a software engineer. Scientists could rapidly synthesize models and quickly verify if the data makes sense. Shake It Up With Modified Data Inputs AMIDOL is designed to let scientists change inputs, assign particular rewards to a model for measuring data, and extract data that could be used elsewhere. This gets around the need to build an entirely new model every time the inputs change. For instance, if scientists want to track how many people infected with COVID 19 also require hospitalization, they can modify the representation of what they’re tracking over a period of time. AMIDOL would also allow a scientist to track how many people recover from COVID 19 or how many people are asymptomatic spreaders of the virus. In addition to COVID 19, every autumn brings the onset of multiple respiratory infections. With AMIDOL, scientists could show the effects of different infections at once. The new diagram generated for a research paper could be used by AMIDOL to synthesize new code that automatically reflects these changes. Modeling Has a Fever, and Our Proposed Cure is More AMIDOL AMIDOL’s next phase is being designed as a proposed AMIDOL as a Service (AaaS) that can be used by government institutes like the Centers for Disease Control (CDC) and the National Institutes of Health (NIH). As we noted in April, resource allocation (e.g. how much Personal Protective Equipment is needed for hospitals in a city) is one challenge AMIDOL aims to address. An AaaS framework could allow agencies and local governments to make data-driven decisions to ensure accurate resource allocation management. Other ideas could include the following: Helping scientists create models for potential COVID 19 vaccines. Determining how social distancing is working at outbreaks in a particular city or state. Modeling which states are testing sufficiently for COVID 19. Tracking the effectiveness of social distancing. AMIDOL’s goal is for gathered data to be deployed so that states can share data and models. Currently, it can take years to transfer data between localities. The Cure We’re Thinking Of The COVID 19 crisis has provided a potential opportunity to make policy-based gains within governmental organizations. AMIDOL could particularly help policymakers respond to crises in real-time, making knowledge more actionable in the near-term. If (or when) another pandemic struck, AMIDOL could help domain experts, data scientists, and programmers create more accurate and updateable models in real-time, with far less ambiguity. Scientists could leverage existing scientific knowledge and not be hampered by a single implementation. Every research paper could match the model – essentially ensuring reproducible science that other domain experts can use. For more information about AMIDOL, please see our project page https://galois.com/project/amidol/ Acknowledgment of Support and Disclaimer: The Performer shall include an acknowledgment of the Government’s support in the publication of any material based on or developed under this Agreement, stated in the following terms: “This material is based upon work supported by the Defense Advanced Research Projects Agency (DARPA) under Agreement No. HR00111990005.”", "date": "2020-10-02"},
{"website": "Galois", "title": "Creating an Assurance Model for Secure Embedded Systems", "author": "Unknown", "link": "https://galois.com/blog/2020/08/creating-an-assurance-model-for-secure-embedded-systems/", "abstract": "In 2019, Galois and its spinout Tangram Flex were awarded a $5 million contract for the DARPA I2O Cyber Assured Systems Engineering (CASE) program . We wanted to present an update for the project’s progress. Introducing Cyber-Assured Plugins to embedded computer systems “The problem is not in our stars … but in ourselves,” is a paraphrase from a famous line from Shakespeare’s play Julius Caesar that could easily apply to making sure modern computer systems are cyber-resilient. DARPA created the Cyber Assured Engineering System (CASE) to “develop the necessary design, analysis, and verification tools to allow system engineers to design-in cyber resiliency … when designing embedded computing systems.” Put simply, how do DoD systems engineers design systems with cybersecurity “baked in” to the requirements, the models, and the code? CASE makes that possible. However, there is a big gap between the way current systems engineers think about models and what is needed to effectively infuse cybersecurity into these systems. Galois and Tangram Flex have been working to bridge this gap with Cyber-Assured Plugins (CAP), an “additive only” approach so TA6 partner engineers can use their own systems, while incorporating CASE tools for system analysis, assurance, and mitigation. Galois and Tangram Flex are ideally suited for this project because both companies have previous success understanding the applications of TA performers; translating underlying concepts into workflows that match the TA’s applications; and supporting integration of those tools to match their workflows. “The CAP program is aligned to Tangram Flex’s purpose,” says Matt Farrell, operations lead with Tangram Flex. “This project helps us know the market need, the tooling and design of an embedded system, and any issues with adoption.” “Bad software leaks bad characteristic behaviors” Embedded computer systems were once less vulnerable to cyber-attacks because they weren’t connected to networks. Current network connectivity now all but ensures that embedded systems can and will be exposed to cyber-attacks. “Bad software leaks bad behavior characteristics,” says Matthew Clark, Principal Scientist at Galois and Tangram Flex. This means a vulnerability can be exploited by attackers without the need to actually target the embedded system. So a major challenge in making embedded systems cyber-resilient is hardening them against behavior attacks. Systems are often designed without assurance built-in, but then have a set of “assurance checklists bolted on at the end,” says Don Barrett, a lead systems engineer with Tangram Flex. This method has not proven effective, and it increases industry cyber mitigation costs. Galois and Tangram Flex believe that companies must design systems with analysis and mitigation functions built in from their inception. However, this is easier said than done.  “The degree of assurance Galois and Tangram Flex can offer its TA6 partner’s system is highly dependent on the degree a system is open and in some cases modular,” Mr. Clark says.  “Often we are faced with the legacy software issue, where the first step in cyber design is reverse engineering and effective modeling.” Reverse engineering legacy software for cyber-hardening During the project’s first phase, Galois and Tangram Flex noted that the tool suite used by the TA6 partner had an elegant UI/UX interface, but it was not compatible with CASE tools, which use AADL ( Architecture Analysis and Design Language ). Many system engineers haven’t worked with AADL-designed tools, and their own commercial tools do not create models that are suitable for analysis. This caused a problem for the ability to easily transition CAP. During the second phase, Galois and Tangram Flex used a tool from DARPA CODE to extract models from a commercial SysML tool, hoping to use automation to bridge the modeling gap. “The team found that commercial tool changes from version x to x.1 broke our CAP plugins and any ability for analysis along with it … [so] we found that a level of manual reverse engineering existing software is crucial to cyber hardening that software. There is no free lunch,” Mr. Clark says. Mr. Clark and his colleagues recommend the first step in assuring a TA performer’s system to first understand how individual components exchange information.  Once that is understood, automated tools can re-write the code that exchanges that information in a more effective, cyber assured way. He says, “The auto generation of a custom message passing system and highly reliable transforms between dissimilar message interfaces is a means to an end for assurance.” Demonstrating modeling functionality Galois and Tangram Flex are currently planning for CAP’s third phase, which aims to focus on tools, training, and educational materials. The plan calls for showing how CAP (using AADL architectural modeling) can analyze, find, and then mitigate threats: Developing a series of models demonstrating how CAP can work with TA6 partner legacy software Describing best practices for how to develop automated analysis AADL models Using AADL to iteratively document forensic evidence Analyzing the AADL model to recommend cyber-mitigations One of the goals for this phase will be to show the TA6 partner how an assurance tool can be built into their embedded system architecture from the beginning of its development. “The major effort [for this intended phase of CAP] will be to generate small examples of modeling functionality and tool use that can be applied to our TA6 partner models by their employees, without Galois or Tangram needing to be involved,” says Mr. Clark. A hopeful paradigm shift for the future The planned end result for CAP’s third phase will be a collection of example models, but a larger goal will be the promotion of a broader knowledge base for effective cyber modeling and analysis; even for legacy systems. Engineers like the UI/UX function of their legacy software because it is simple to use and makes their workflow efficient.  Don Barrett says, “designers can create the best tool imaginable, but if average engineers can’t decipher its functionality, then they won’t use it. So designing software for the experienced engineer scientist doing the work is crucial.  Tangram Flex takes this mission to heart and wants to develop a tool that engineers and developers can use without it being disruptive to their workflow.” The goal is for CAP to be a model for working CASE tools that can be used to design a stable and secure system from the ground up.  This would be a massive “paradigm shift,” says Mr. Barrett. Matt Clark also believes the work being done with CAP has the potential to help transform component-based development and analysis. “Enabling a way to forensically [model and mitigate] threats from legacy software would be great,” he says.  “There is still a ton of room to define what it means to do component based development and analysis.” This research was developed with funding from the Defense Advanced Research Projects Agency (DARPA). The views, opinions and/or findings expressed are those of the author and should not be interpreted as representing the official views or policies of the Department of Defense or the U.S. Government. DISTRIBUTION STATEMENT A. Approved for public release: distribution unlimited.", "date": "2020-08-21"},
{"website": "Galois", "title": "Announcing the ‘blst’ BLS verification project", "author": "Unknown", "link": "https://galois.com/blog/2020/09/announcing-the-blst-bls-verification-project/", "abstract": "I’m happy to share something new the Galois cryptography verification team is working on in collaboration with the Ethereum Foundation , Protocol Labs , and Supranational . However, I’m sorry to inform you that Galois has sold out to dramatic live-blogging. We’ve sold out so much that I, unrequested by anyone, took the liberty of making us a Survivor-style logo. This blog series should be less dramatic than Survivor , but more tasteful than Jersey Shore. I’m Joey Dodds . I am part of the team’s leadership at Galois that’s performing the verification effort in collaboration with Supranational. I plan on doing my best to make this series not only educational but entertaining. My apologies beforehand if that means you need to slog through some bad jokes to get to the meaty technical details that you really crave. This first blog post will kick off a series covering our formal verification of the ‘blst’ signature library developed by Supranational. ‘blst’ is a BLS signature library that provides asymmetric authentication of data. It allows a signer to provide evidence that information originated from them, without requiring an exchange of information with the party verifying the signature. BLS signatures are an important part of consensus protocols for next-gen blockchain technologies like Eth2 and Filecoin. This effort will be the first time Galois has verified such a scheme, and we’re particularly excited about sharing it with you all from the start. We’re also excited to share all of the twists and turns of our adventure, although I’ll probably leave out the bits where I delay writing blog posts because I’m trying to come up with clever things to say. In this project, we’re writing proofs. Proofs are fairly certain artifacts stating that code is correct. As imprecise as that statement sounds, it’s actually very precise. While it’s not completely certain, the uncertainty is reduced to very specific parts of the problem. We’ll get deep into that idea in a future post. Over the next nine months, we will prove the safety and correctness of the BLS signature code. Throughout the project, we will combine a steady proof engineering effort with new research. We expect the BLS codebase to push our tools, particularly our x86 proof tools, past their current limits. We will share our successes and our (real, non-blog related) struggles, explaining problems we run into and how we work to overcome them. Supranational Supranational is developing hardware-accelerated cryptography in order to provide security and privacy in a high-performance, memory-efficient manner. They place a heavy emphasis on correctness and verifiability because cryptography now protects billions of dollars of assets. Supranational is composed of an expert team of hardware and software engineers, all of whom have stellar reputations in their fields. They’ve already gained a remarkable amount of traction in their target markets while simultaneously pushing novel open-source software out to the public. It is an honor to work with them, and over this series, we look forward to giving a deeper understanding of who they are and what they do. Ethereum Foundation The Ethereum Foundation (EF) is a non-profit organization dedicated to supporting Ethereum and its ecosystem. Its work with Galois is part of the Eth2 effort to upgrade the Ethereum network. Eth2 will scale capacity by roughly two orders of magnitude, reduce energy consumption, as well as increase security. Technically speaking Eth2 is a proof-of-stake system. BLS signature aggregation plays a key role in the decentralization of consensus participants, allowing for millions of so-called validators. The first stage of Eth2, named phase 0, is planned to launch in 2020. Protocol Labs Protocol Labs is an open-source R&D lab that builds protocols, tools, and services to radically improve the internet. Protocol Labs’ projects include IPFS , Filecoin , libp2p , and more — which serve thousands of organizations and millions of people. They aim to make human existence orders of magnitude better through technology. The Filecoin Project is a decentralized storage network with the mission of creating a decentralized, efficient, and robust foundation for humanity’s information. The road ahead This is a verification project. Roughly, verification is the act of writing proofs about the correctness of software. Over the coming months, we will verify the codebase using our Cryptol and SAW toolchain. Once we’re done, we will have mathematically proved that the code behaves exactly as expected. Not only will we guarantee the absence of code failures due to undefined behavior in C code, but we will also show that the C code exactly meets a specification. Once we’re done, I’ll also likely take the team out for a round of ice cream, because this work is going to be hard . Conceptually, the first part of this effort involves precisely documenting the expected behavior of the code in a Cryptol specification. Next, we use SAW to ingest the code. SAW will only be able to work on the code if it can show conclusively that the code has no undefined behavior, including memory safety violations. Finally, we use SAW to show that the code exhibits exactly the behavior defined in the Cryptol specification. However, this project presents an additional challenge because it uses hand-tuned x86 implementations, which are necessary to squeeze every last drop of performance out of the hardware. We will not only show that the optimizations in those x86 implementations are safe, but we will also show that a C program can safely call the x86 without breaking the expectations that C code has for functions that it calls. In practice, we do things a bit out of order to minimize risk and increase the likelihood of early valuable feedback. We’ll cover that approach in a later post. As grand as these claims sound, formal verification is just another tool for understanding software, not a magic wand. I do, from time to time, dream about a formal verification magic wand, high on a frozen mountain top… Until I take that magical journey though, formal verification will have limitations. These limitations might be due to challenges in verifying specific code, or the need for someone to actually understand what the proofs mean. It’s also possible that although our tools are thoroughly tested and widely trusted, they might not be perfect and could allow for mistakes. In later posts, we’ll detail why this is the case and why we believe it is unlikely to result in a “wrong proof.” The proofs that we produce as a result of our verification effort will be installed in a continuous integration (CI) environment, where they will continuously check the code. That means that the code will not only be valid on the day we deliver the proofs, but it will also be continuously checked as the code evolves, and the proofs will be reestablished with each code update. In some cases, this can happen automatically, and in others, it requires manual effort. Throughout this series of posts, we will discuss: the benefits formal verification provides to software developers, what our approaches mean for the correctness of software, making the tools easier to use through automation, limitations in proofs, reasoning about x86 code called by C code, and continuous assurance for live codebases We look forward to interacting with the programming languages (PL) and cryptography communities to discuss the benefits and challenges of this work. Both Supranational and Galois feel that it’s critical that we not only perform this work but share and explain it as thoroughly as possible. We are doing this to break away from thinking of formal verification of a check-box to be achieved, and to explain where it applies well, where it falls down, what value it provides, and perhaps even more importantly, what value it doesn’t provide. Ideally, by the end of this post series, when you see a project present formal verification as a claim of its correctness, you will be armed with some questions that will help you understand what that really means.", "date": "2020-09-16"},
{"website": "Galois", "title": "Project Fromager: $12M Project to Apply Zero-Knowledge Proofs to Software Assurance", "author": "Unknown", "link": "https://galois.com/blog/2020/09/project-fromager-12m-project-to-apply-zero-knowledge-proofs-to-software-assurance/", "abstract": "A zero-knowledge proof (ZKP) is a mathematical tool that provides irrefutable proof of a claim’s validity, without revealing anything else about the claim or the data used to prove it. Today, the application of ZKPs often gravitates towards cryptocurrency transactions, where they can be used to prove that a transaction is valid without revealing details such as the source, destination, or amount of a transaction. However, the current state of the art in ZKPs is limited to handling such small proofs. Because of this limitation, a broader application of zero-knowledge proofs has yet to emerge. At Galois, we remain focused on using ZKPs for far more complex proof statements and, importantly, for practical government and commercial use cases. Toward that aim, we are excited to announce today our new $12.6 million zero-knowledge proof contract with the U.S. Defense Advanced Research Projects Agency (DARPA) as part of the Securing Information for Encrypted Verification and Evaluation (SIEVE) program. We’re thrilled to be able to participate in this opportunity to enhance information security and trusted computing. Project Fromager Our SIEVE project, Fromager , seeks to scale ZKPs to support complex proof statements, such as proving that a vulnerability exists without revealing what the vulnerability is, or proving that software satisfies safety guarantees without revealing the proof of safety. The project aims to initially address two key research challenges: 1) how might we best construct a formal proof statement that a software program has a vulnerability – which is complicated to determine, and 2) how might we efficiently convert this proof statement into a zero-knowledge proof. This means transitioning from “I know this program has a vulnerability but I’m not going to tell you what it is” to a proof that tells you nothing except the fact there is a vulnerability. Fromager also seeks to tackle another challenge with ZKPs – scalability. Zero-knowledge proofs are constructed by one party – the prover – and then transmitted to and verified by another party – the verifier . Prior work in efficient ZKPs has largely focused on minimizing both the cost to verify proofs and the cost to transmit the proofs, as these are vital in cryptocurrency applications. However, these requirements come at the cost of increased effort on the part of the prover. By moving some computation onto the verifier, we aim to reduce prover complexity and through that reduce the overall computation time, as well as enable proofs to be created for more complex proof statements. Delivering on this scalability requires new techniques and technologies that our team aims to explore with Fromager. Zero-Knowledge Proofs for Vulnerability Disclosure ZKPs have a wide variety of potential uses. For example, if you hire a cloud server to run a program for you, how do you know for certain that it provided a genuine answer, or ran your program at all? How do you know that your medical data, when analyzed by a neural network, produced the answer that the service provider actually gave you? This area of threat mitigation – often called computational integrity assurance – will continue to grow in importance as we rely more and more on computation done on machines and software not under our direct control. With Project Fromager, one setting where we imagine a critical role for zero-knowledge proofs is in fostering a better relationship between software companies and security researchers/public watchdogs.  Consider the benefit if a researcher could offer irrefutable proof that a vulnerability exists, without revealing its details in a way that would allow bad actors to exploit it until a patch is made available. With Project Fromager and under this ZKP scenario, a researcher/watchdog could publish a zero-knowledge proof that a vulnerability exists in an ethical way – without revealing how it was done, but with the vulnerability being verifiable. That way, the software firm is motivated to act to fix it, and there is less room for misunderstandings. In government, it has always been difficult to verify cyber vulnerabilities and operations without surrendering sensitive information. If there is a piece of software being used for cybersecurity, a DoD user, for example, would like to know that it is provably secure from one or a class of vulnerabilities. The problem: that the user may not have security clearance to view the source code. With zero-knowledge proofs, the user can rely confidently on that software without needing clearance to inspect the relevant security proof. Fromager will deliver practical zero-knowledge capabilities, including the abilities to (1) prove that vulnerabilities exist in critical software without revealing how they are caused; and (2) assess properties of cyberspace operations capabilities without needing to access source code. Fromager is led by Galois, with research contributions from faculty at Katholieke Universiteit. Leuven (Belgium), Aarhus University (Denmark), Columbia University (USA), and researchers at QEDIT Corporation (Israel). Fromager leverages standardization efforts in the zero-knowledge proof community to help define interfaces among SIEVE program performers. To learn more about our work on SIEVE, visit the Fromager project page. “Distribution Statement “A” (Approved for Public Release, Distribution Unlimited)”", "date": "2020-09-15"},
{"website": "Galois", "title": "Coffeebot: a tool for having hallway conversations while working remotely", "author": "Unknown", "link": "https://galois.com/blog/2020/09/coffeebot-a-tool-for-having-hallway-conversations-while-working-remotely/", "abstract": "Since the onset of working remotely, we’ve built a program at Galois called Coffeebot to help facilitate virtual “coffee chats” in support of maintaining our culture through spontaneous exchanges. Today we’re releasing Coffeebot, and we’re happy to share it along with simple instructions on how to set-up your own! Percolating the idea As a result of the Covid-19 pandemic and physical distancing measures, Galois, along with many other companies, shifted to remote workflows to enable employees to work from home. We were very fortunate to have had established infrastructure to work in a distributed fashion already, so this part of the transition went smoothly. However, an adverse effect of being physically distanced is unintentional social distancing. We can go about our day-to-day work independently (even in our PJs if we want!), only connecting with colleagues via video conferencing systems during planned meetings. As GoogleHangouts, Zoom, and Mattermost have indefinitely become the main forums for discussion; we found ourselves missing out on the joys of serendipitous, face-to-face communication that once came about naturally while being together in physical spaces. Can a coffee stain exist when no one is around to notice? Research shows that informal conversations, whether about work or personal things, have various outcomes such as the accomplishment of work-related tasks, collaboration between different groups of people, underpinning of the workplace culture, and enabling social activities. These interactions happen seamlessly when people are in the same place. They are an essential part of how Galwegians learn what our coworkers are up to, discover opportunities, and foster community. Let’s look at a few examples of how this works. As you’re grabbing lunch, you might bump into someone in the common room and ask about their work or how a project is going. In response, they might bring up a need they have in your area of interest or an idea that translates to your own work. In another case, you might pass by someone in the hallway and ask how their weekend was only to learn that they love running as much as you do, so you start an after-work running group. In many other situations, you just have a delightful conversation with someone that makes your connection stronger. Under the current circumstances, it seems laborious, almost unnatural, to find out what our colleagues are up to via an email or scheduling a meeting to simply have a conversation. However, it’s evident that the heart of Galois culture is in the frequent exchanges, casual interactions, and informal conversations. To help us bridge this gap, we developed a tool called Coffeebot to simulate the fortuitous encounters we once cherished at the office. How Coffeebot works Coffeebot is a program that randomly pairs up willing participants for a weekly “coffee chat.” Anyone who would like to participate can sign up on a spreadsheet by adding their name, email address, and a list of topics that they like talking about. Coffeebot runs on Monday mornings, pairing people up and sending each participant an email letting them know who they have been scheduled to chat with, along with each person’s listed topics of interest. The topics each person lists aren’t meant to be prescriptive; they’re only there to make it easier to talk to someone you don’t yet know — at least you know something about them! Set-up your own! Many people at Galois have enjoyed Coffeebot as a way to have serendipitous conversations with coworkers. Since it was well-received internally, we’re happy to be releasing the code for others to use. If you’re a member of an organization that cares about culture and collaboration like we do at Galois, but are lacking the avenue (ie. being in physical spaces with others) that once made it possible, Coffeebot could work well for you! The implementation is written in appscript, and runs off of a spreadsheet. It’s easy to set-up and doesn’t require any programming knowledge to make it work. If you’d like to set-up your own Coffeebot, follow these steps here . We hope you might enjoy running your own Coffeebot.", "date": "2020-09-04"},
{"website": "Galois", "title": "Providing Safety and Verification for Learning-Enabled Cyber-Physical Systems", "author": "Unknown", "link": "https://galois.com/blog/2020/08/providing-safety-and-verification-for-learning-enabled-cyber-physical-systems/", "abstract": "Machine learning has revolutionized cyber-physical systems (CPS) in multiple industries – in the air, on land, and in the deep sea. And yet, verifying and assuring the safety of advanced machine learning is difficult because of the following reasons: State-Space Explosion: Autonomous systems are characteristically adaptive, intelligent, and/or may incorporate learning capabilities. Unpredictable Environments: The power of autonomous agents is the ability to perform in unknown, untested environmental conditions. Emergent Behavior: Interactions between systems and system factors may induce unintended consequences. Human-Machine Communication: Handoff, communication, and interplay between operator and autonomy become a critical component to the trust and effectiveness of an autonomous system. Galois seeks to solve these problems with Leveraging Symbolic Representations for Safe and Assured Learning (“Assured Learning”). As part of DARPA’s Assured Autonomy program, Assured Learning aims to develop an assurance framework specifically for CPS systems that rely on machine learning or learning-enabled controllers. The Assured Learning project is designed to test and verify the safety of cyber-physical systems, but it could also go further. Assured Learning aims to explore the following approaches: Use Run-Time approaches to detect and recover from errors in operation. Automate testing of learning enabled controllers to increase assurance Leverage testing to create symbolic representations learning enabled controllers that enable deeper, for formal verification of their behavior. Assured Learning will set a new standard by providing learning-enabled CPS with the ability to learn from mistakes. Galois and research partners at Purdue University, University of Texas at Austin, Oregon State University, and Rice University have developed a three-part process to explore how such a system can work: Training Galois will help design and implement a toolchain that introduces an abstract interpretation training strategy that can train neural networks and make them provably correct. Testing and Verification Inspired by the concept of concolic testing (e.g. a mix of concrete and symbolic), Galois plans to use a symbolic model of the neural network and its environs. Run-Time Assurance Run-Time Assurance technologies will do two things:  monitor software for expected failures and automatically recover from those failures. Galois has chosen a domain-specific language named CoPilot (and co-created with NASA) to develop Run-Time Assurance technologies for this purpose. Galois believes that Assured Learning can extend assurance to the entire autonomy domain. One day, this could even apply to applications that take humanity to the furthest reaches of space. This research was developed with funding from the Defense Advanced Research Projects Agency (DARPA). The views, opinions and/or findings expressed are those of the author and should not be interpreted as representing the official views or policies of the Department of Defense or the U.S. Government.", "date": "2020-08-31"},
{"website": "Galois", "title": "Building DaeDaLus and ICARUS As We All Try to Stay Out of the Sun", "author": "Unknown", "link": "https://galois.com/blog/2020/08/building-daedalus-icarus-as-we-all-try-to-stay-out-of-the-sun/", "abstract": "Document and protocol formats are the languages in which computing systems exchange information. The notion of a “document-format” certainly isn’t foreign to most computer users: everyday, vast swaths of users directly create, edit, and share documents and media in formats such as PDF, JPEG, and Word. But in principle, the concept of a “format” is quite flexible and describes the messages that are exchanged deep within the guts of operating systems and networking protocols as well. The theory of describing formats using formalisms such as regular expressions and context-free grammars goes back almost to the birth of computer science, starting more or less with the definition of the Chomsky hierarchy in 1956 . Today, there are plenty of practical frameworks in use for defining formats and parsing them that do the job well enough to get by–many of them seeing plenty of day-to-day use at Galois. However, the art and science of format definition and parser construction still has plenty of problems left to be addressed.  Languages based on formalisms such as regular expressions and context-free grammars are simple and self-contained, and when they fit the format of interest they’re hard to beat, but they can’t be used to describe an industrial-standard format, like PDF. These shortcomings are evident to end-users and seen in a consistent stream of critical, system level security exploits that result from under-specified formats and buggy parsers. Funded by the DARPA SafeDocs Program , Galois–in close collaboration with Trail of Bits Inc. and students and faculty at Cornell, Penn State, Princeton, Purdue, and Tufts–is currently performing research focused on improving the state of the art and science of finding security vulnerabilities. To that end, we are excited to share an update about our work on DaeDaLus and developing the Format Analysis Workbench (FAW). Although there’s plenty of work ahead, after about a year of research the tools we’ve built throughout the process so far have contributed to the design of a very practical, very complex format. We’ve uncovered seven novel issues that the PDF Association aims to fix by updating the next version of the standard. Getting Precise About the Real-World Formats Although decades of research have explored tradeoffs in making data description languages (i.e., languages in which people write machine-readable format definitions) more expressive versus the time taken to parse their formats, the dust hasn’t settled to yield a language yet. At Galois, we’re leading the design of a novel data description language—named DaeDaLus—that aims to aid in shaping expressive format definitions that are easily understandable. DaeDaLus is designed to be expressive enough to describe practical formats precisely, but also declarative and self-contained enough to be understood with a reasonable amount of effort, especially by format experts who aren’t necessarily expert programmers. Traditional libraries that define parser combinators are a powerful and useful tool for rapidly building programmer-understandable parsers for practical formats. However, the hallmarks of parser combinators that give them so much flexibility (that they provide mechanisms for building parsers that can be used by arbitrary programs in a general-purpose language) can actually work against them. To address this issue, DaeDaLus parsing algorithms seek to ensure that a parser defined using DaeDaLus acts as a declarative format specification that can be easily understood by non-programmers. DaeDaLus is still relatively young, but our work with it so far has been promising: over the span of a few months, we’ve not only defined the entire language and built first prototypes of its parsing algorithms, but we’ve used it to define a machine-readable definition of a “surface” syntax of PDF objects. DaeDaLus has been expressive enough that we’ve been able to transcribe the details of the PDF standard into it. DaeDaLus is currently supported by parsing algorithms implemented in Haskell, so that it can be integrated into a Haskell project to build parsing results as Haskell datatypes. DaeDaLus is now open-source software, available from GitHub . In the future, we hope to add more efficient parsing algorithms and parser generators, as well as self-certifying parsers (i.e., parsers that are either correct by construction or that generate easily-checkable certificates that their results are correct to accompany the results themselves). Formats from Giant Tarballs of Documents It’s no small thing to be able to manually translate standards written in natural language into a machine-readable form. Primarily because 1. It can get pretty exhausting after a while; 2. it’s not even clear what you actually want (a lot of the time). In reality, formats aren’t just official standards documents; they’re implicit understandings of what features users decide they want, and what parser implementers decide they’re going to support. We’re working in close collaboration with Trail of Bits to develop a toolkit that a format expert can use to generate a machine-readable description of formats as they’re actually used from existing documents and parsers. Trail of Bits has recently released a suite of tools— PolyFile and PolyTracker —that enable users to understand existing documents and parsers. PolyFile takes a document and a library of known formats and labels document bytes as pieces of the candidate formats, PolyTracker tracks which components of a given parser process which pieces of an input. DaeDaLus will be supported by the Format Analysis Workbench (FAW) , which enables a user to access a corpus of documents using a suite of existing parsers and quickly navigate the plethora of error and warning messages that practical parsers generate. Our goal is that, using FAW, a format expert can quickly determine which documents should act as the ground truth of an implicit format in use, balancing their informal understanding of the meaning of various parser error messages with the practical implications of accepting or rejecting the sets of documents that trigger such messages. Our hope is that in the future, this will be useful both to global document standards bodies and to organizations looking to define restricted, trusted formats for internal use (e.g., a version of PDF that does not contain JavaScript). That’s all not to imply that parsing doesn’t leave a bit of time for fun and games. A recent competition hosted by Kudu Dynamics tested the parsing prototypes of various groups that are carrying out research under the SafeDocs program. Every team had their strengths, but in the end, a particular piece of hardware will be calling SW 6th Ave in Portland, home for the foreseeable future… This research was developed with funding from the Defense Advanced Research Projects Agency (DARPA). The views, opinions and/or findings expressed are those of the author and should not be interpreted as representing the official views or policies of the Department of Defense or the U.S. Government.", "date": "2020-08-07"},
{"website": "Galois", "title": "What4: New Library to Help Developers Build Verification and Program Analysis Tools", "author": "Unknown", "link": "https://galois.com/blog/2020/07/what4-new-library-to-help-devs-build-verification-program-tools/", "abstract": "At Galois, we develop formal verification tools that rely on a variety of automated solvers for answering mathematical queries. The main solvers we use are called Satisfiability Modulo Theories (SMT) solvers.  These solvers offer the ability to answer questions such as “find me inputs for which a mathematical property holds.”  We have found these tools to be very useful. There are a variety of solvers developed that support different problem domains and are very efficient at solving complex constraint systems. Among other things, we have used them to verify the correctness of many cryptographic algorithms in seconds, even though the number of inputs is incredibly large (2^256 possible inputs or even larger). Last week, we released a Haskell library called What4 we use internally for interacting with different SMT solvers. What4 takes its name from Why3 , an OCaml-based framework for connecting programs to solvers. What4 is designed primarily for making it easier for developers to build new verification and program analysis tools that use SMT solvers. A more complete feature list is below, but we wanted a library that made it easier for developers to programmatically construct expressions and send those expressions to solvers for verification or model finding. What4 leverages Haskell’s powerful type system to help ensure expressions are well-formed. What4 also includes many internal expression simplification rules to keep expressions in a reduced form so the solver encoding is compact. What4 is available on Github and Hackage: Github: https://github.com/GaloisInc/what4 Hackage: https://hackage.haskell.org/package/what4 The README on Hackage has a short tutorial showing how to use What4. What4’s features include: Strongly-typed symbolic expressions using GADTs. Sending problems to solvers and parsing back results (including counterexamples). Optimization and constant-folding routines to simplify and efficiently encode problems. Interaction with a variety of solvers (Z3, Yices, CVC4, Boolector, STP, and dReal). Additional support for non-SMT solvers (e.g., ABC, BLT) through libraries available on Github. Support for both single file and incremental solver interactions depending on performance priorities. Explicit DAG-based term representation to minimize problem size. Comprehensive support for real/integer arithmetic, bitvectors, and extensional arrays; limited support for other theories. Representation of floating-point values as reals, IEEE, or uninterpreted, with the same what4 program. An active team of engineers who use it every day, and are paid to develop and maintain it. We invite you to play with What4, model things in it, break it, complain about it, and improve it. All feedback is much appreciated.", "date": "2020-07-27"},
{"website": "Galois", "title": "PIRATE: $7.5M DARPA Contract To Accelerate Secure Application Development", "author": "Unknown", "link": "https://galois.com/blog/2020/07/pirate-darpa-contract-to-accelerate-secure-application-development/", "abstract": "I’m excited to announce we’ve been awarded a  $7.5 million contract by the Defense Advanced Research Projects Agency (DARPA) to work on PIRATE, a set of software development tools for designing and building high-performance, physically-partitioned applications that protect sensitive information. PIRATE stands for Partitioning Information via Resource-Aware Transformations for Everyone.  The project is part of DARPA’s Guaranteed Architecture for Physical Security ( GAPS ) program, which focuses on developing hardware and software architectures that can provide physically provable guarantees around high-risk transactions, or where data moves between systems of different security levels. Today, DoD, other government agencies and commercial organizations face a time consuming and extended accreditation process when building systems and applications that process sensitive information (military and intelligence systems, medical systems, financial systems, etc.). With PIRATE, we aim to address this challenge by accelerating the development of real-time interconnected applications with built-in multilevel security . To ensure the technology can be used across a range of commercial and government applications, much of the work is focused on building extensions to existing open-source tools and technologies. Goals and team PIRATE’s goal is to enable developers to rapidly build systems where sensitive information can be securely stored and safely shared when approved. We aim to produce a framework and tools that make that type of application development easier and more accessible.  We envision a process where a “GAPS-built” system or application using our framework and tools will go through the certification and accreditation process much more quickly and securely. We aim to do this by extending existing mainstream languages. The project addresses a core objective of GAPS by ensuring the technology can be adopted by mainstream languages and development tools. To facilitate upstream adoption, we aim to release PIRATE software publicly under open source licenses. PIRATE is a four and a half year effort. Our team consists of Galois and Two Six Labs. Galois will contribute its experience in language design, compiler development, and formal methods; Two Six Labs will contribute its experience in low level software development, hardware integration, and construction and use of board support packages (BSPs) for embedded systems. More information on the project can be found on the PIRATE project page as the effort progresses. The material is based upon work supported by Defense Advanced Research Projects Agency (DARPA) under Contract No. HR0011-19-C-0103. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the Defense Advanced Research Projects Agency (DARPA).", "date": "2020-07-15"},
{"website": "Galois", "title": "Measuring the Privacy of Computations", "author": "Unknown", "link": "https://galois.com/blog/2020/07/measuring-the-privacy-of-computations/", "abstract": "Secure computation enables users to compute some result without revealing the inputs. Privacy schemes that are shown to only reveal outputs are said to have input privacy. However, learning these outputs still tells you something about the private inputs. The important question is: “how much?” The Defense Advanced Research Projects Agency (DARPA) Brandeis program aims to enable safe and predictable sharing of data while preserving privacy. On this program, the Galois-led TAMBA team’s focus has been to develop and apply new approaches to evaluating privacy-preserving systems. One tool we developed is luigi-qif , which can quantify how much an adversary who can observe (only) the output of a secure computation  can infer about the private data used in that computation. luigi-qif evaluates privacy leakage of secure multi-party computation programs written in the popular MPC framework SCALE-MAMBA. luigi-qif is an analysis tool and doesn’t perform the secure computation itself. Instead, luigi-qif takes the description of an MPC program (as unmodified Python SCALE-MAMBA code) as input, along with information about the known bounds of possible private data, and produces two metrics: 1. static leakage : an ‘expected’ level of leakage, i.e. an estimate of how much could leak without knowledge of what the program’s real output would be 2. dynamic leakage : the ‘real’ leakage associated with one specific output from the computation These are both well-studied metrics in the field of Quantitative Information Flow (please see this tutorial for more background). If an adversary is trying to ‘guess’ the private data’s values, the leakage *values* provide a mathematical notion to how much an adversary is aided in their guess by seeing the output of the computation. Using the Tool “If you and your friends each privately submit a number between 0 and 4 to a secure computation that prints only the sum of all your numbers, how much does seeing the result help someone guess what number you submitted?” We use luigi-qif to answer this question by giving the following inputs: The unmodified SCALE-MAMBA code for the (secure sum) computation A file describing the bounds of possible inputs Let’s quickly go over an example of each. Our input program Our tool analyzes unmodified SCALE-MAMBA programs, like the following which  performs a simple multi-party computation: take one input from each of 10 parties, and sum them together. numbers = [sint.get_private_input_from(i) for i in range(10)]\nacu = sint(0)\nfor x in numbers:\n    acu += x\nprint_ln(\"RESULT: %s\", acu.reveal()) Bounds on the possible inputs Most computations have some bounds on the possible values that are valid inputs. For example, an unsigned 16-bit integer must at least be between 0 and 2^16-1, but in many cases the range of valid inputs are much narrower. Consider a private input known to be in the range between 0 and 100. If the adversary knows the inputs are between 0 and 100 then they’ll never guess anything outside that range. If the computation reveals “the input was less than 500” doesn’t help the adversary guess either since they already know it’s between 0 and 100. Users of luigi-qif model this information about valid input values by providing a “priors” input file to accompany the associated MPC file. Here’s the priors file for our example computation that sums the 10 private values between 0 and 4. There is one line for each private variable, and each line contains the lower and upper bound for that value. 0 4\n0 4\n0 4\n0 4\n0 4\n0 4\n0 4\n0 4\n0 4\n0 4 Running luigi-qif With both our SCALE-MAMBA code and our .priors file, we can run luigi-qif to help us reason about how much can be inferred about our private data if we take part in this computation (i.e. about the potential leakage of the computation). As mentioned in the Introduction, luigi-qif can provide two metrics, let’s take a look at both, first static leakage: >> luigi-qif --priors examples/sum.priors --mpc examples/sum.mpc static-leakage\n\nNumber of possible outputs: 41\nSTATIC LEAKAGE: 5.357552 bits out of 23.219281 bits total\n\nAnd now dynamic leakage:\n\n>> luigi-qif --priors examples/sum.priors --mpc examples/sum.mpc dynamic-leakage 8\n\nPrior vulnerability: 1/9765625\nPosterior vulnerability: 1/22110\nLeakage: 8.786870 bits out of 23.219281 bits Note that for dynamic-leakage we used the output value of 8. We can plot the dynamic leakage of each possible output for this program to see how the observed output relates to how much leakage would occur (this is possible for this program, but infeasible for programs with a large output space!): Seeing the results shown in the Figure above helps us reinforce some of our intuitions. There are many possible ways for all the values to sum up to 20, i.e. low leakage. There is only way to sum to 0, i.e. high leakage. This is reflected in the results for those points on the x-axis. Use of leakage analysis in a realistic scenario luigi-qif is capable of analyzing scenarios much more complex than the simple “sum” example above, where the privacy impact of sharing the result is less obvious. On the Brandeis program, the Enterprise Collaborative Research Team developed a scenario for Pacific-bordering nations’ collaborative response to natural disasters in the Pacific. While many countries are willing to cooperate as part of emergency response, the optimal response depends on potentially sensitive data about the participants’ assets and capabilities. Coalition nations would like to cooperate in response to the disaster while ensuring that certain sensitive details of their capabilities remain private. This situation exemplifies the classic conundrum at the heart of privacy preserving technologies: the trade-off between privacy and utility. luigi-qif can help quantify these trade-offs and find a middle ground. The Scenario The goal of this scenario is for nations to determine an aid-distribution schedule to allocate their shared resources in a way that best responds to the disaster. This is a complex scenario where each participant has several types of private information (ship locations and capabilities), and the scheduling optimization process to allocate ships to ports involves many constraints (not all allocations are feasible). It is not obvious how much an adversary could infer about the private data from the resulting aid distribution schedule, due to the many constraints and types of information involved in this operation. luigi-qif can fully model the schedule optimization algorithm, which will be performed in secure multiparty computation, and then reason about exactly how much the schedule can reveal about each participants’ private information. This enables potential participants to make a decision about whether to participate in the computation that has been informed by a measure of potential privacy loss. The Data You can divide the actors in the scenario into two main groups: Aid providers and aid recipients. In the scenario, each of these has data that they consider private. For aid providers, this data corresponds to information about their ships: Location Length (size) Draft (how deep the ship sits in the water) Maximum speed For aid recipients this data corresponds to information about the ports, generally, and specific berths at each port. The table below shows the data that is relevant to the port as a whole and to each berth individually: Port information Berth Information Available? Length Offload capacity Occupied start time Harbor depth Occupied end time As you can see the scenario not only has more data than our sum example, but the various dimensions of the data interact in non-trivial ways. Perhaps a ship is close enough to a port, and is capable of a speed that would reach that port, but the port harbour depth is too shallow. There are several constraints on the ability of a ship to dock at a specific berth at a specific time, including the position of other ships! This confluence of factors makes it more difficult to reason about what an adversary might learn about the private data from observing the final resource allocation solution. As with our sum example above, all of these data fields are modelled in luigi-qif using a prior file that sets domain specific bounds on the possible values in our scenario. If you are interested in more details on the scenario itself and other approaches to leakage analysis for this scenario, we co-wrote a paper for the 2019 Scheduling and Planning Applications Workshop with our colleagues at SRI. Results of Running the Analysis The TAMBA team has taken the resource allocation algorithm, written in SCALE-MAMBA and used luigi-qif to provide insight about what information can be inferred about the data provided by coalitions members. As an information-theoretic measure, the results below are in ‘bits’. You can think of each additional leaked bit as halving the possible number of guesses that an adversary might take. With that in mind, for any nation taking part in the coalition scenario, luigi-qif reports that the static leakage would be 9.1 bits of information. luigi-qif also reports this was out of 148.75 initial bits in the state space. Alone knowing that an algorithm leaks 9.1 bits may not be actionable information. Indeed, luigi-qif comes into its own when used to compare the leakages of various approaches. We used luigi-qif to analyze various possible resource allocation strategies, giving analysts and decision makers the ability to quantify the privacy/utility tradeoff when making their decisions (please see our paper for more detail). Furthermore, ‘bits’ may not be the most intuitive metric. Depending on the domain in question, you can use the results to display the information in a more intuitive way. Below we show a map where red indicates the possible locations of a ship from our scenario after the scheduling algorithm is run. Here you can more easily visualize what the loss of privacy corresponds to in the physical world: Conclusion Metrics and visualizations like the above provide insights and intuitions for policy makers and system analysts that they can then use to inform their decisions. In particular, tools like luigi-qif can add weight to the argument for deploying systems that use MPC, as the privacy/utility tradeoff can be made more explicit and avoid the pitfalls of ‘all or nothing’ collaboration between parties that may not fully trust each other with their secret data. Building tools like luigi-qif is one way Galois works towards its goal of ensuring systems do _ only _ what they are intended to do. In using MPC, it can be easy to think that all the inputs are private, they stay private after the output is revealed. Providing tools for reasoning about the degree to which that may or may not be true helps ensure that private data stays private, and that implementers reckon with the leakage that does exist. Acknowledgments This material is based upon work supported by the United States Air Force and DARPA under Contract No FA8750-16-C-0022. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the United States Air Force and DARPA. DISTRIBUTION STATEMENT A. Approved for public release: distribution unlimited.", "date": "2020-07-13"},
{"website": "Galois", "title": "Protecting Election Integrity with ElectionGuard", "author": "Unknown", "link": "https://galois.com/blog/2019/05/protecting-election-integrity-with-electionguard/", "abstract": "Today, Microsoft announced our joint work on ElectionGuard and the upcoming release of the software development kit. This SDK will be freely available, and can be used to enable end-to-end verifiable (E2E-V) elections around the world. An E2E-V election uses cryptography to produce proofs that an election has been run correctly. In a properly implemented E2E-V system, it is impossible for the voting system to cheat without detection. E2E-V puts the power to fully check election correctness into the hands of the public, allowing us all to independently confirm election accuracy. We are thrilled to be taking part in the design and implementation of the ElectionGuard SDK. Collaborating with Dr. Josh Benaloh, Microsoft Research, and Microsoft’s Defending Democracy Program team has been ideal in bringing such a wide-ranging vision to light. We hope that today’s announcement will kick off an even bigger collaboration, one that we expect will involve the entire elections community, including other cryptographic researchers, accessibility experts, hackers, elections vendors, and everyone in between. One of the most incredible aspects of the ElectionGuard SDK is that it will be usable by anyone . The SDK can be used as the core of most of today’s election systems. It will be designed for a wide range of hardware, operating systems, and election configurations. Our documentation and API design methodologies will make it straightforward to convert existing systems to use ElectionGuard. The same approaches also serve to make ElectionGuard hard to misuse; the API design makes entire classes of misuse impossible. Moreover, ElectionGuard will encourage the kind of open source ecosystem where hobbyist programmers can easily develop and share open election systems. The SDK will be easy enough to use that a class of high-school programmers might develop an election system for use by their own school. Those elections can then be run on software that the school already owns, and by the nature of end-to-end verifiability, the results can be checked with as much certainty as they can in any other E2E-V election in the world. The presence of end-to-end verifiability is not a reason to let down our guard. Every day, Galois works to secure the world’s most critical systems, and we are using the best we have on ElectionGuard. We have already started building up layered evidence of the correctness of ElectionGuard, starting with rigorous specification languages, and continuing with formal verification, cryptographically secure logging, and constant internal consistency checks. Thorough and formal specifications of the E2E-V protocol are being developed in collaboration with Microsoft Research and other top cryptographers from around the world. On top of all of this, ElectionGuard will support risk limiting audits as yet another independent way to confirm the validity of election results. As the summer progresses we will release our cryptographic specifications, system designs and documentation, and eventually a usable SDK. Each of these releases will provide opportunities for the elections community to provide feedback on ElectionGuard. Our work on building correct and secure systems is meant to inspire trust, but our techniques will only inspire confidence if they can be understood. We intend to take the time to explain our entire assurance case, to give those concerned with system correctness the ability to read our formal documents in order to decide for themselves if the properties we prove of our software are appropriate. ElectionGuard represents an opportunity to change the way that the world view elections, and we can’t wait to share this experience with all of you.", "date": "2019-05-05"},
{"website": "Galois", "title": "Creating open and accessible COVID-19 data models", "author": "Unknown", "link": "https://galois.com/blog/2020/04/creating-open-and-accessible-covid-19-data-models/", "abstract": "Projections based on data models for COVID-19 are serving as a critical foundation for Federal, state and local government policy makers charged with making rapid and informed decisions to fight the spread of the novel coronavirus. Data models like the model presented by researchers at Imperial College London on March 16, which many believe led to a dramatic shift by the U.K. government to a strict lockdown, inform life and death decisions: whether to issue statewide “stay-at-home” orders, closing schools and businesses, forecasting potential hospital bed shortages, identifying current and emerging COVID-19 hot spots and countless other critical aspects of the pandemic. These models and research papers continue to play a pivotal role. However, oftentimes models are published only as raw mathematics, data sets are not made available, and the code used to implement a model is not distributed. This means that it is a difficult, manual and lengthy process for others to re-use the model for their own specific purposes. This is particularly true for Governors and other state and local officials facing unique and rapidly changing circumstances. To enable decision makers at every level more rapidly adapt data models to their own specific needs and geographic factors, Galois is partnering with DARPA’s ASKE and World Modelers programs to produce reliable insights and data models. Most critically, we are releasing all data, models, and resources under the MIT open source license to encourage collaboration. Making COVID-19 Models and Data More Widely Available As part of this effort, we are analyzing the data and models emerging from the COVID-19 pandemic. We are leveraging a novel pipeline and toolset to produce cleaned data sets, model analysis, and other resources for the federal, state, and local governments; the scientific community; and other friends and colleagues working on this crisis. Our aim is to improve the agility, speed, and confidence of data and model analysis for crisis response, to allow domain experts to inform their decisions, policy, and actions with machine intelligence and automated reasoning. Three key areas of COVID-19 modeling where Galois believes it can have the most immediate impact relative to existing modeling tools are summarized below: Rapidly adapt and localize existing COVID-19 models There are good models out there today, great models actually, that can now be quickly and easily adapted by state and local government leaders and other officials for their unique requirements. For example, if local officials want to take a national COVID-19 contagion model and adjust it for their city’s population demographics, we can set new parameters with curve fitting tools for the local data to rapidly inform policy decisions. In addition to adapting existing national models or those from other localities, we can also quickly create new models based on specific parameters and challenges, such as: when will my peak infections occur? When will hospital resources run out? Where are nearby cities in terms of peak cases and can resources be shared and staged out between cities (even across state lines)? Identify errors with existing models One could argue that the only scenario more dangerous than a lack of usable COVID-19 models is a model with errors that can not only lead to devastating policy decisions, but re-used by decision makers to build equally flawed models. With current data models based on raw mathematics however, it is difficult to identify model flaws and bugs, thus making models harder to validate. We aim to produce cleaned data sets by quickly identifying and correcting model bugs and errors. As a result, we can build tools you can rapidly develop validation with and generate re-usable versions. Develop consumable models and datasets During health crises, the ability to compress the time between data generation and producing models and datasets that are consumable and actionable for policy decision makers can make the difference between life and death. It can often take weeks or longer to present data in an intuitive way, which is further challenged as some of the most widely used data models change the way they publish data. This can add time to the process that no one has right now. Galois offers an alternative to traditional modeling and data analysis, which can be a slow, opaque,  bespoke, and error prone process. Galois is using methods and technologies developed under work on Automated Scientific Knowledge Extraction, and World Modelers, to assemble, clean, and validate models and data from a wide range of sources, using automated reasoning and code synthesis. Why are we doing this? At Galois we take our commitment to developing ideas and technologies for the common good pretty seriously. It manifests itself in how we conduct work, and in things like our boundary policy . We’re lucky to be afforded the opportunity to work as part of programs like ASKE and World Modelers mentioned above, and want to make sure that we do our part in helping government decision makers at all levels make fully informed decisions on policies. We are encouraged to see others commit to making COVID-19 datasets more accessible and open source so modeling isn’t restricted by models that are difficult to adapt, interpret or visualize. Stay tuned for updates to this blog, the project page , and our Github page for the COVID-19 pandemic for a list of published models and data.", "date": "2020-04-06"},
{"website": "Galois", "title": "Protecting Applications with Automated Software Diversity", "author": "Unknown", "link": "https://galois.com/blog/2018/09/protecting-applications-with-automated-software-diversity/", "abstract": "On the DARPA CFAR program, the Galois “RADSS” team is developing new ways to mitigate memory corruption attacks against legacy C/C++ systems without requiring finding and fixing each individual bug. CFAR is about “Cyber Fault-tolerant Attack Recovery” and our general approach is: Given some application to defend, generate multiple variants of that application such that all variants behave the same when given benign input, but behave differently when given malicious input. Run a set of multiple variants simultaneously in a multi-variant execution environment (MVEE) that unifies input/outputs and can monitor the set, detect when variants diverge in behavior, then react and recover. The Galois-led team includes the University of California Irvine , Immunant , and Trail of Bits . Our focus is on the development of tools that can generate a diverse set of variants that maximize the detection of attacks while remaining within a performance envelope suitable for real-world systems. Our defenses have proven effective and practical in red-teaming exercises on CFAR, where we protect the Apache web server and other real-world applications from common forms of attack. In this post we outline our approach and where these defenses are most effective. A follow-up post will cover how our defenses protect against specific types of attacks as well as some surprising ways that composing variant generation techniques can inadvertently negate the intended security protections. Variant Generation Strategy We focus on approaches that surface memory corruption vulnerabilities (such as buffer overflows) that are common in many legacy systems written in unsafe languages like C/C++. Our strategy is for variants to preserve well-defined behavior in the application but introduce diversity in the effect of undefined behavior (such as out-of-bounds accesses). Our team includes UC Irvine and Immunant, who develop the multicompiler . They’ve built the multicompiler on the clang/LLVM compiler framework by adding many transformations that introduce variation (known as software diversity ) in the binaries produced. That is, from one input program, the multicompiler can produce many different output binaries that exhibit the same behavior under normal circumstances, but different behavior when attacked. This is possible because the code a programmer writes does not fully specify all aspects of the resulting binary representation, but low-level exploits are very sensitive to these properties. The multicompiler’s transformations range from randomization of memory layouts for the globals, stack, functions, and vtables, to more sophisticated changes in how the resulting variants store data in memory. While the multicompiler generates variants of a program directly by compiling its source code, we may also wish to protect systems (or subsystems/libraries) that are available only in binary form. Our team also includes Trail of Bits, who bring McSema to tackle this issue. McSema can lift a binary to LLVM bitcode that the multicompiler can diversify, allowing us to generate variants of applications even when they are only available in binary form. Success: Strong Defenses The CFAR program includes a separate team responsible for performing regular security evaluations of our techniques. In these evaluations, our defenses have prevented the evaluation team from exploiting concrete instances of: code and data information disclosure vulnerabilities (including ones resembling the “Heartbleed” bug) corruption of stack variables: overflow and offset corruption vulnerabilities corruption of globals: overflow and offset corruption vulnerabilities corruption of heap objects: overflow and offset corruption vulnerabilities use-after-free vulnerabilities, including use of heap grooming control-flow hijacking vulnerabilities, including use of ROP The evaluation team modeled vulnerabilities after common CWEs (drawn from the community-developed “common weakness enumeration” list), intended to be representative of vulnerabilities found in the wild. Our defenses were successful even after granting the evaluation team strong capabilities, including: full access to application source and knowledge of vulnerabilities in the original application full knowledge of all variant binaries, with online and offline inspection capabilities As the program progressed, the evaluations expanded to grant further capabilities to the evaluation team, intended to model an adversary with a once-in-a-decade vulnerability or some other nightmare scenario for defenders. This included giving the evaluation team information about runtime memory layouts and even full memory content of each variant as it ran in the multi-variant environment, simulating side-channel information (such as via Meltdown/Spectre style attacks). Our defenses succeeded even under these harsh operating conditions. We generate variants that each behave differently when the set is attacked, allowing us to detect attacks by observing these differences in variant behavior. After detecting the attack we can restart or roll back variants to a known good state, and in some cases we can do even better by repairing the corrupted state and safely continuing execution. The details are beyond the scope of this post, but the idea is we construct variant sets so that certain attacks cannot corrupt the same state in all variants simultaneously, and we repair corrupted program state using uncorrupted state from other variants. Practical Design Decisions We’ve designed our variant set transformations to preserve legitimate behavior specified by the programmer. Instead, we change many aspects of the implementation that the source language specification leaves implementation specific. This can prevent or reveal many common types of attacks, and correctly written code will not depend on the properties of the undefined behavior that we change. To support diversification of real-world code that may include violations of the language standard, we support various “whitelisting” techniques to omit diversification of specific problematic regions, functions, variables, or data structures. Using these tools and techniques, we have been able to generate diversified multi-variant sets of each of Apache, nginx, lighttpd, and thttpd web servers that have each passed their respective test suites. The MVEE briefly pauses and cross-checks variants when they make sensitive operations like system calls, but otherwise variants run “full speed” as long as the host has the resources (CPU & memory) to accommodate the multiple instances of the application. The most extensive performance analysis evaluations on CFAR have taken place on the variant sets we have generated from the Apache web server. Our performance goals for RADSS are roughly 10% performance overhead for the MVEE and 10% overhead for our diversity transformations, and sets containing most of our transformations (combined) fit within this performance envelope in testing. The few transformations with larger performance impact (e.g. fine-grained heap-object-ID checks) trade additional overhead for extra protection against sophisticated attacks. Conclusion The combination of software diversity and multi-variant execution can provide strong protection from sophisticated adversaries. But making the most of this can be surprisingly tricky, and simply maximizing software diversity can end up negating the protections you intended to add. Please see our followup post where we describe some of these issues and the hazards of blindly applying software diversity techniques. Acknowledgments This material is based upon work supported by the United States Air Force and DARPA under Contract No. FA8750–15-C–0124. The views, opinions and/or findings expressed are those of the author and should not be interpreted as representing the official views or policies of the Department of Defense or the U.S. Government. Distribution Statement “A” (Approved for Public Release, Distribution Unlimited).", "date": "2018-09-10"},
{"website": "Galois", "title": "The Zimmerman Telegram, Enigma, and Inter-Agency Data Sharing", "author": "Unknown", "link": "https://galois.com/blog/2018/10/the-zimmerman-telegram-enigma-and-inter-agency-data-sharing/", "abstract": "This article originally appeared in the Fall 2018 edition of the U.S. Cybersecurity Magazine When obdurate isolationist Woodrow Wilson won 1916 re-election under the slogan, “He kept us out of the war!”, he hadn’t anticipated a simple act of data sharing. On January 17, 1917, Room 40 (British Naval Intelligence) finally decrypted the infamous German “Zimmerman telegram” that read, in part, “We intend to begin unrestricted submarine warfare…We shall endeavor in spite of this to keep the United States neutral. In the event of not succeeding, we make Mexico a proposal…make war together…”. Room 40 delayed sharing that telegram with Wilson until February 26 to protect British sources and methods – an example of sharing data while preserving privacy. Nevertheless, the shared data was compelling: on April 2, Wilson asked Congress to declare war. Fast forward to 1942. British intelligence gradually succeeded in breaking the 3-rotor Enigma. However, on February 1 of that year, German U-boats started to use the 4-rotor version. From then until August 1942, Germany spent (lost) 22 U-boats to cost the Allies some 600 merchant ships. By April 1943, data sharing with the US cracked Enigma altogether. In May of that year, 18 of 49 U-boats patrolling the North Atlantic were sunk, while only 2 merchant ships were lost. A common thread in these disparate vignettes is the sharing of data that its owning agencies consider sensitive, to achieve valuable public outcomes. That thread continues today in venues outside common defense. In the US for example, juvenile justice is a popular area for data sharing. 35 states have laws reaching back to the 1990s that permit data-sharing in search of improved juvenile justice outcomes. 27 of those states share data across their child welfare and juvenile justice systems for the same purpose. Washington State integrates criminal justice, social service, health, and workforce data to understand relationships between policy and outcomes. Allegheny County, PA is another beacon of data sharing in the service of outcome-driven policy enabled by inter-agency data sharing. Far more is possible, but privacy laws restrict both inter-agency sharing and agency-outsider sharing (for example with researchers who often provide statistical expertise to make sense of data). In general, personally identifiable information (PII) is constrained by these laws to stay inside the agency that collected it. A recent poll of government agencies working on such inter-agency sharing found that having the right data to share ranked far below other barriers to sharing. The leading barriers included the cost of assuring legal compliance when sharing; stakeholder concerns about the perception of whether privacy is preserved when sharing; and the difficulty in making data interoperable for sharing when de-identification works directly against such interoperability. The result? Inter-agency sharing of sensitive data often remains impossible, or impractically expensive and difficult. How might we move both law and technology toward practical, cost-effective inter-agency sharing of sensitive data? 1917 and 1943 are a start, but we need to show it can be done in the context of modern public policy. One upcoming example is the bipartisan Right To Know Before You Go Act of 2017. Rising tuition and job uncertainty are at the forefront of student and parent concerns, along with the recognition that a college education is the second biggest investment that many college-bound citizens will ever make. Students and parents have a right to know all they can about how to make that investment wisely. What do they want to know? An amalgam of recent discussions sums up this way: “When other students like me choose this college, and that program of study, how much did it cost? What’s the chance that a student like me will graduate? How long will that take? Will I be able to get a job afterward, and if so, how much can I expect to earn? What’s the chance that I’ll be able to repay my student loans?” Today, most of that information comes to students from the least reliable sources: college brochures, family member input, and the Internet. The current, ridiculously bad outcome? Something less than 60% of students graduate from the institutions where they started, while as many as 44% of students at for-profit 4-year institutions don’t graduate, according to Pew Research. Not…good…enough. Who holds the real data that can answer these questions accurately? Several agencies that are unable or unwilling to share that data. The US Census Bureau holds residence, family size, employment, and disability data. The Internal Revenue Service holds a wealth (no pun intended) of data about income. The Department of Education’s Federal Student Aid agency holds student loan, grant, and loan repayment data. The National Student Clearinghouse (not part of .gov) holds program of study, degree, scholarship, and other details of college careers. The Department of Veterans Affairs holds service record and GI Bill data. By sharing and linking that data, we can fulfill the student Right to Know. All of that raw data is personally identifiable, and much is quite sensitive. Yet the answers we owe to students don’t require revealing any sensitive personal information in public. The answers students need are statistical summaries that either can’t be re-identified, or that we know how to protect from re-identification — for example using techniques such as epsilon- differential privacy. So, providing those statistical outputs to students puts no PII at risk. Instead, the challenge here is to protect the privacy of subjects of that detailed, sensitive input data while it is being used to compute those results. Many solutions today de-identify data before sharing it. However, study after study shows that de-identification simply doesn’t prevent re-identification. In addition, such de-identification must be done anew each time the data is used for different purposes. De-identification also prevents exactly the cross-dataset linking needed to generate accurate answers, and prevents accurate data cleaning during the analysis process. In short, de-identification doesn’t work, is expensive, and destroys data utility. Some solutions take original data and create synthetic models of it – matching statistical distributions of various data attributes – before sharing the synthesized substitute. The problem here is that the synthesis process can only model distributions that are explicitly chosen and known in advance. Meaningful correlations can be lost, hiding exactly the relationships that students and parent want to discover. Secure computation is a promising alternative, though performance and usability are still being improved. Here, data is shared in full, so no utility is lost. However, that data remains encrypted at all times – even during computation, and even while results are filtered and fitted up with differential privacy – so that its privacy remains fully protected. With secure computation, the data and any potentially re-identifiable results are never “in the clear”, even if analysis platforms are hacked. Inter-agency sharing of sensitive data needs to move from the realm of “it would be nice, but I’m sorry…we just can’t” to “we have a wealth of administrative data among us…what public good can we do?” Technologies – some limited, others very promising – exist to get the job done. Agencies such as DARPA, IARPA, DHS S&T, Census, and NIST are improving these technologies. Some key members of Congress understand and are advocates for the possibilities. As cyber security professionals, we can get more examples in play to help these and other advocates push policies and statutes to keep up with technology.", "date": "2018-10-01"},
{"website": "Galois", "title": "2018: Year in Review", "author": "Unknown", "link": "https://galois.com/blog/2019/01/2018-year-in-review/", "abstract": "2018 was a year of growth and impact at Galois. We furthered our work from cryptography to software and hardware assurance through both our R&D efforts and our spin-out companies. Our team grew significantly, and like most everyone in this industry, we continue to hire. We’ve been fortunate to work with many great partners and clients, many of them new this year, while publishing 35 papers and articles, and sharing 20 public talks. Overview 2018 was an eventful year for our work on secure computation , the process of working with data without exposing it. Secure computation holds the promise of true data privacy without losing the utility of data analysis. Multiple government agencies and commercial entities engaged with us in 2018, not only to further research in secure computation, but also to deploy variants of it in real-world scenarios. In software correctness , our experience in streamlining formal verification and assurance for real-world, impactful commercial software took center stage in our publications and talks. Together with the Amazon Web Services (AWS) team, we published a paper on our work to formally verify AWS’s s2n encryption library. We also spoke, published, and held many talks and workshops related to industrial formal methods and functional programming. In 2018 we announced the BESSPIN project funded by DARPA’s SSITH program. The project aims to develop tools and methodologies that enable provable hardware security. In our talks and publications, we focused on sharing what we have learned and developed in BESSPIN and other projects in the space of hardware safety and verification. We directed our efforts in formal assurance for the RISC-V architecture and have held many talks and publications related to high-assurance hardware . More generally in cybersecurity , we published papers related to our ADAPT project, part of DARPA’s Transparent Computing program. In ADAPT, we worked on anomaly detection to uncover unknown cyberattacks. We also wrote a number of articles and papers on our results from RADSS , our software diversity project within DARPA’s CFAR program. In RADSS, we try to mitigate memory corruption attacks against legacy C/C++ systems, without requiring finding and fixing each individual bug, by generating and running multiple variants of a program in parallel in a way that reveals attacks. Additionally, in 2018 we launched our fourth spin-off company, Tangram Flex (Tangram), that provides software development tools for cyber assurance and resilience in embedded systems. Tangram is building on years of work developing cyber-physical systems safety, security, and reconfigurability to provide a product suite for complex embedded systems (planes, ships, automobiles, trains, drones, satellites, etc.). In December, Tangram announced a $4.5M investment from Hale Capital Partners and is growing accordingly. Tozny , a Galois spin-out focused on data privacy and mobile security, also saw significant growth. In October, Tozny announced a number of commercial and government deployments of their InnoVault platform, a toolkit that enables developers to embed end-to-end data security encryption capabilities into their websites, apps, and other software. Organizationally, we’re continually attending to how we work together as a team. This year we published https://lifeatgalois.com , a website where we detail the workings of our unconventional organizational structure. We consider the way we organize ourselves to be a staple of our well-being as people, in addition to facilitating our research and our business’s progress. Most articles are accompanied by videos that discuss specific topics; for example, here is one that talks about how we organize ourselves without a fixed hierarchy, and why it is essential to how we work together: A company without managers . We hope it gives a glimpse of what we’re about as a company. Below you’ll find links to the papers, talks, and other public contributions we shared in 2018. We hope you find something interesting. From all of us at Galois, we wish you a peaceful and productive 2019. High Assurance Cryptography Callisto: A Cryptographic Approach To Detect Serial Predators Of Sexual Misconduct , Best note at ACM COMPASS Dr. David Archer was part of a team that published a paper about using secure computation to detect serial sexual misconduct. Also part of the team: Anjana Rajan Lucy Qin Dan Boneh Tancrède Lepoint Mayank Vari. Architectural Security, the Ardennes, and Alfred the Great , U.S. Cybersecurity Magazine Dr. David Archer published an article about the application of secure computation for the Callisto project above and the lessons that can be learned to make “hardened applications that treat information security as a first-class requirement — part of a checkerboard defense appropriate for the limited aims adversary model, and cryptographically hard to defeat,” outlining a design paradigm that stewards sensitive information. Dr. Archer also wrote a post on the ShareMind blog on a similar topic, which you find here: The Search for Killer Apps in Secure Computation . From Keys to Databases – Real-World Applications of Secure Multi-Party Computation , The Computer Journal Dr. David Archer was part of a team that published a paper discussing “the widely increasing range of applications of a cryptographic technique called multi-party computation. For many decades, this was perceived to be of purely theoretical interest, but now it has started to find application in a number of use cases.” IACR eprint . Privacy-preserving, Evidence-based Decisions in Public Policy . Bipartisan Policy Center Dr. David Archer spoke at the Bipartisan Policy Center on how organizations in the government can jointly use multi-party computation to make decisions based on their respective datasets, while protecting the privacy of that data. Keep it Secret, Keep It Safe – Cryptographic Tools for EMR Security , UA Health Sciences Dr. David Archer gave a talk at the UA Health Sciences Medicine Grand Rounds on information security as it relates to electronic medical records. Your Secrets are Safe with Julia: A Compiler for Secure Computation , StrangeLoop Jason Dagit gave a talk at StrangeLoop on a compiler that translates a subset of the Julia programming language into a form suitable for computation under homomorphic encryption, which provides the ability to compute functions over encrypted data without the need to decrypt. The Zimmerman Telegram, Enigma, and Inter-Agency Data Sharing , U.S. Cybersecurity Magazine Dr. David Archer published an article on practical, cost-effective inter-agency sharing of sensitive data. From the article: “Inter-agency sharing of sensitive data needs to move from the realm of ‘it would be nice, but I’m sorry…we just can’t’ to ‘we have a wealth of administrative data among us…what public good can we do?’ Technologies – some limited, others very promising – exist to get the job done.” Software Correctness and Formal Verification High-Assurance Blockchains: Applications and Verification , HCSS 2018 Dr. Joe Hendrix gave a talk at the High Confidence Software and Systems (HCSS) conference about providing and maintaining data integrity guarantees via blockchains even when systems are compromised, and verifying a blockchain implementation satisfies security and functionality requirements. Continuous formal verification of Amazon s2n , CAV The Galois team, working with Amazon Web Services on formal assurance for the s2n encryption library, published a paper at Computer Aided Verification (CAV) about our efforts so far. Authors: Andrey Chudnov, Nathan Collins, Byron Cook, Josiah Dodds, Brian Huffman, Colm MacCarthaigh, Stephen Magill, Eric Mertens, Eric Mullen, Serdar Tasiran, Aaron Tomb and Edwin Westbrook. Continuously Verified Cryptography , PNW PLSE Dr. Mike Dodds gave a talk on our work with Amazon Web Services to formally verify portions of the s2n encryption library at the Workshop on Programming Languages and Software Engineering. Continuous verification in industry , FMATS Dr. Mike Dodds gave a talk at Sixth Workshop on Formal Methods and Tools for Security on automating formal verification for use in industry. Continuous Verification of Critical Software , IEEE SecDev Dr. Mike Dodds, Dr. Stephen Magill, and Dr. Aaron Tomb held a tutorial at IEEE SecDev on continuous verification of critical software. You can find the paper on the sessions here . Comprehensive Language and Protocol Verification at Galois . LangSec Workshop Dr. Joey Dodds presented our team’s approach to language verification, considering both parsers and protocol languages. You can find the description of the talk and the slides here . Proving the Correctness of Amazon’s s2n TLS Library , ICMC Dr. Aaron Tomb held a talk on our approach to constructing proofs of the functional correctness of several components of s2n, and the tools and techniques we have leveraged. Find the slides here . A Data-Driven CHC Solver , Distinguished Paper Award at PLDI Dr. He Zhu, Dr. Stephen Magill, and Dr. Suresh Jagannathan (Purdue University) published a paper at PLDI on “data-driven technique to solve Constrained Horn Clauses (CHCs) that encode verification conditions of programs containing unconstrained loops and recursions.” You can watch the video of the presentation here: https://www.youtube.com/watch?v=MIVboi74v1w Mechanizing the Construction and Rewriting of Proper Functions in Coq , CoqPL Dr. Edwin Westbrook published and presented a paper at the on mechanising the construction and rewriting of proper functions in Coq at the Coq for Programming Languages Workshop. Getting Satisfaction out of Games: Learning to use SAT solvers through puzzles and games , ICFP Eric Mertens and Dr. José Manuel Calderón Trilla held a tutorial at the International Conference on Functional Programming (ICFP) on how to identify SAT problems and how to encode them using the Ersatz Monad by using puzzles and games as concrete examples. A Surprisingly Competitive Conditional Operator: miniKanrenizing the Inference Rules of Pie , Scheme 2018 Dr. David Thrane Christiansen was part of a team that presented a paper on a new search operator in miniKanren that allows developers to use domain-specific knowledge to prioritize likely paths to solutions at the Workshop on Scheme and Functional Programming . The main contributors and the rest of the team: Benjamin Boskin, Weixi Ma, and Daniel Friedman. You can watch a video of the presentation here . Extensible Type-Directed Editing , ICFP Dr. David Thrane Christiansen and Joomy Korkut published a paper at the International Workshop on Type-Driven Development (TyDe) at ICFP on extending Idris’s metaprogramming facilities with primitives for describing new type-directed editing features. A Little Taste of Dependent Types , Strange Loop Dr. David Thrane Christiansen held a talk at Strange Loop that gave an introduction to dependent types and demonstrated a proof hat is also a program. Dr. Christiansen also held a talk on the same topic at FlatMap Oslo . The Little Typer , book Dr. David Thrane Christiansen, together with Daniel P. Friedman (Indiana University) published The Little Typer , a introductory book about dependent types that begins with a very small language that looks like Scheme and extends it to cover both programming with dependent types and using dependent types for mathematical reasoning. Reflections on industrial use of Frama-C , Sound Static Analysis Workshop Dr. Dan Zimmerman and Dr. Joe Kiniry gave a talk on the use of Frama-C across multiple projects at Galois focused on mission-critical systems at the Sound Static Analysis Workshop. Haskell Mini-Course , IFL 2018 Dr. David Thrane Christiansen and Dr. José Manuel Calderón Trilla held a Haskell mini-course at the symposium on Implementation and Application of Functional Languages. Integration of Quantifier Eliminator with Model Checker and Compositional Reasoner . IEEE ICCA Matt Clark was part of a team that published a paper on integration of quantifier elimination (QE) technique with model checking and compositional verification at IEEE International Conference on Control and Automation. Also part of the team: Hao Ren and Ratnesh Kumar. The Software Analysis Workbench , Dagstuhl Seminar on Program Equivalence Dr. Aaron Tomb held a talk at the Dagstuhl Seminar on Program Equivalence on Galois’s Software Analysis Workbench (SAW) and its inner workings. What is Formal Verification? (video) We published a video giving a light introduction to mathematically verifying the correctness of software systems. Cryptography and Formal Methods (video) We published a video on cryptography and what makes it so difficult to get right, and what can we do to avoid flaws and vulnerabilities. Hardware and Cyber-physical Systems Formal Verification of a Vehicle-to-Vehicle (V2V) Messaging System , CAV Dr. Mark Tullsen presented our work on verifying a V2V Messaging system at Computer Aided Verification. Authors: Mark Tullsen, Lee Pike, Nathan Collins and Aaron Tomb. Formal Assurance for RISC-V Implementations , RISC-V Workshop Dr. Dan Zimmerman presented our work on and approach to verifying the correctness and security of RISC-V implementations. Find the video in the link above and the slides here . Formal Methods Need Not Be Black Magic , RISC-V Summit Dr. Joe Kiniry and Dr. Dan Zimmerman held a talk at the RISC-V Summit that gave an introduction to formal methods as they relate to hardware development and RISC-V specifications. Find the video in the link above, and the slides of the talk here . SSITH and BESSPIN , ERI Summit Dr. Joe Kiniry and Dr. Linton Salmon (DARPA) introduced DARPA’s SSITH program and Galois’s BESSPIN project as part of SSITH at the Electronics Resurgence Initiative Summit. A Formally Verified Cryptographic Extension to a RISC-V Processor , CARRV Dr. Joe Kiniry, Dr. Dan Zimmerman, and Dr. Robert Dockins were part of a team that published a paper detailing the creation of a formally verified cryptographic extension to a RISC-V Processor at the Workshop on Computer Architecture Research with RISC-V (CARRV 2018). Also part of the team: Rishiyur Nikhil (Bluespec, Inc.). Achieving memory safety without compromise , Embedded.com Adam Foltzer published an article on Embeded.com about memory-safe programming languages and the tradeoffs involved in using them. Construction of Stability-Based Hybrid Automata for Safety Verification Using Continuation Methods , 2018 AIAA Guidance, Navigation, and Control Conference Matt Clark was part of a team that published a paper on the use of continuation methods to automatically transform a non-linear dynamical system into a series of simplified hybrid modes relative to particular bifurcation points. The method, as a proof of concept, enables the linearization and control of highly dynamical nonlinear systems. Also part of the team: Peter Uth, and Anshu Narang-Siddarth. Loihi: A Neuromorphic Manycore Processor with On-Chip Learning , IEEE Micro Dr. Georgios Dimou was part of a team that published a paper on Loihi, a 60-mm2 chip fabricated in Intel’s 14-nm process that advances the state-of-the-art modeling of spiking neural networks in silicon. See link above for the rest of the team. Secure pprzlink: encrypted communications for open source drones Michal Podhradsky wrote an article on Secure pprzlink, an encrypted communication protocol for UAVs that Galois was involved in developing. Secure Pprzlink is backed by a formally verified cryptographic library. Cybersecurity Enforcing Unique Code Target Property for Control-Flow Integrity , CCS 2018. Dr. Bill Harris was part of a team that published a paper on a new approach for accurately and efficiently monitoring programs to ensure that they satisfy control-flow integrity, a fundamental security property. Also part of the team: Hong Hu, Chenxiong Qian , Carter Yagemann, Simon Pak Ho Chung, Taesoo Kim, and Wenke Lee. Trustworthy Elections , DEFCON Voting Village Dr. Joe Kiniry held a talk on trustworthy elections and voting technology at the DEFCON Voting Village. The talk focused on the deficiencies of the elections ecosystem today and what can be done to fix it. Adding Noise to the Signal: Using Deceptive Traffic Generation to Defend and Distract , Cyber Shorelines Dr. Adam Wick held a talk on using cyber deception to detect and prevent advanced attacks in networks. Protecting Applications with Automated Software Diversity Dr. Ben Davis wrote two posts detailing our work on the Robust, Assured Diversity for Software Systems (RADSS) project as part of DARPA’s CFAR program. Find the first post in the link above, and the second post here: Automated Software Diversity: Sometimes More Isn’t Merrier . Composition Challenges for Automated Software Diversity , Tech Report Dr. Ben Davis, Dr. Simon Winwood, and Dr. Stephen Magill were part of a team that published a tech report on the issues that must be considered when composing software diversity transformations and is part of Galois’s RADSS project. The tech report was originally presented at the Layered Assurance Workshop (LAW), 2016. Also part of the team: Per Larsen, Stijn Volckadert, David Melski, Michael Franz. Blockchain: Hype or Hope for Transactional Security? Security Boulevard Dr. David Archer published an article about blockchain technology, its types and uses, and the tradeoffs and security in relation to more traditional solutions. Assuming you know: epistemic semantics of relational annotations for expressive flow policies , 2018 IEEE Computer Security Foundations Symposium. Dr. Andrey Chudnov was part of a team that published a paper on “unified framework for expressing, giving meaning and enforcing information downgrading policies that builds on commonly known and widely deployed concepts and techniques, especially static and dynamic assertion checking.” Also part of the team: David A. Naumann. What’s the Over/Under? Probabilistic Bounds on Information Leakage , POST 2018 Dr. José Manuel Calderón Trilla and Dr. Stephen Magill were part of a team that published a paper about using novel techniques for improving the bounds on computing quantitative information flow at Principles of Security and Trust Conference. Also part of the team: Ian Sweet, Chad Scherrer, and Michael Hicks. Data Analysis and Machine Learning Quine: A Temporal Graph System for Provenance Storage and Analysis , IPAW 2018 Ryan Wright published a paper and delivered a demonstration at the International Provenance and Annotation Workshop that introduced Quine, a prototype graph database and processing system designed for provenance analysis with capabilities that include fine-grained graph versioning to support querying historical data after it has changed, standing queries to execute callbacks as data matching arbitrary queries is streamed in, and queries through time to express arbitrary causal ordering on past data. Detecting Cyberattack Entities from Audit Data via Multi-View Anomaly Detection with Feedback , AICS 2018 Dr. David Archer, Ryan Wright, and Alec Theriault published a paper on detecting unknown cyberattacks from audit data of system-level events at the Artificial Intelligence for Cyber Security (AICS). The work is the result of the ADAPT project funded by DARPA’s Transparent Computing program. Feedback-Guided Anomaly Discovery via Online Optimization , KDD Ryan Wright, Alec Theriault, and Dr. David Archer were part of a team that published a paper at the Conference on Knowledge Discovery and Data Mining introducing a new method for online training of anomaly detectors to tailor the results to what an analyst considers to be anomalous. This work (video) advances the state of the art in human-machine teaming for improved results over existing machine learning techniques alone, and was a result of the ADAPT project funded by DARPA’s Transparent Computing program. Rendering and Extracting Extremal Features in 3D Fields , Best Paper award at EuroVis 2018 Dr. Charisee Chiw was part of a team that received the best paper award on their paper about the Diderot language at EuroVis 2018. Diderot is a DSL designed for scientific visualization and image analysis. The paper demonstrated the language’s ability to do feature extraction and volume rendering on 3D fields. Code + ML – Will Automation Take Our Jobs? DevOps Summit Dr. Stephen Magill gave a lighting talk about the state of the art in combining programming and machine learning at DevOps Summit. Using Formal Methods to Reason About Neural Network Based Autonomous Systems , HCSS Dr. Stephen Magill presented on using formal methods to reason about machine learning at the High Confidence Software and Systems (HCSS) conference. Other Life at Galois : We detailed the workings of our unconventional organizational structure through a series of articles. We discussed the following: A company without managers : How we organize ourselves without a fixed hierarchy, and why it is essential to how we work together. Defaulting to transparency : How we enable everything to be transparent within the walls of Galois. How finding work works : People at Galois choose their own projects instead of being told what to work on. We explain what that means for the company. A transparent approach to pay : A look into why our salaries are transparent, and pay is based on future results. Stewards and nurturing people : Details on how we encourage everyone to think about their long-term goals and career and getting what they need out of their day-to-day at Galois, and not just the other way around. The boundary policy – doing purposefully good work : A look at how we reason through what projects we decide to take on as a company that are non-damaging and produce value for the world. Tangram Flex : We spun out our fourth company, Tangram Flex (Tangram), that provides software development tools for cyber assurance and resilience in embedded systems. Tangram is taking years of work in safety, security, and reconfigurability of cyber-physical systems software and providing it as a product suite for complex embedded systems (planes, ships, automobiles, trains, drones, satellites, etc.). Tangram announced Ricky Peters as CEO. Tangram Flex funding : In December, Tangram announced a $4.5M investment from Hale Capital Partners. Tech talks : Galois organized and hosted 10 public tech talks on a variety of topics. c2rust : We open sourced c2rust, a tool that translates C into semantically equivalent Rust code. Eric Mertens wrote a blog post with more details. Cryptol 2.6.0 : We released a new version of Cryptol with support for unbounded integers, modular integers, and parameterized modules. Allegheny County : The Bipartisan Policy Center partnered with Allegheny County and Galois on a new privacy-preserving data project. Tozny InnoVault : Charles River Analytics announced they are building a smartphone app that detects illnesses and injuries and that leveraging Tozny’s InnoVault product to protect the privacy of user data with end-to-end encryption. Facebook C++ verification : Galois was awarded a grant from Facebook to build a verification toolchain for C++ cryptographic libraries. Cryptographic Analysis, Verification, Exploration, and Synthesis (CAVES) : Navy Awards Galois $2 Million Contract For Cryptographic Security. Balancing Evaluation of System Security Properties with Industrial Needs (BESSPIN) : Galois Awarded $4.5 Million DARPA Contract To Strengthen Hardware Security. Framework for Information Disclosure with Ethical Security (FIDES) : DHS Awarded Galois $800K Contract To Enable Sensitive Network Data To Remain Encrypted When Shared And Analyzed. RISC-V Security Standing Committee : The RISC-V Foundation announced the Security Standing Committee with strong Galois involvement. Press Highlights Using Functions for Easier Programming : Dr. Iavor Diatchki gave an interview for CACM on using functions for easier programming. Thoughts on Secure Development : Dr. Mike Dodds gave an interview on formal verification and secure development on the Thoughts on Secure Development blog. Open-Source RISC-V Hardware and Security : Dr. Joe Kiniry was interviewed as part of a panel of experts on Open-Source RISC-V Hardware and Security in Semiconductor Engineering. Building tools to secure computer processors : Dr. Joe Kiniry gave an interview as part of a Government Computer News (GCN) article that detailed our aims with the BESSPIN project on hardware security. Navy Beefing Up At-Sea Enterprise Network : Dr. Aaron Tomb was interviewed as part of a National Defense Magazine article about Navy enterprise networks that in part detailed our work in the CAVES project. How privacy is moving data security to the top of corporate agendas : Dr. David Archer spoke with CSO magazine about security as part of an article on corporate privacy and data issues. Committees, reviewers, guest editing, panels Dr. David Archer Was part of the organizing team for the Provenance-based security workshop Participated in Zero Knowledge Proof Standardization workshop Served on the UN Statistics Division Privacy Preserving Technology Team Dr. David Archer and Dr. Alex J. Malozemoff participated in the FHE standardization workshop Dr. Charisee Chiw Participated in Dagstuhl 2018 Loop Optimization workshop Served on the GPCE 2018 Committee Dr. David Thrane Christiansen Served as Workshops chair for ICFP Served on the ICFP Program Committee Served on the ICFP Distinguished Papers Committee Dr. Alex J. Malozemoff Program Committee member at Crypto Workshop on Encrypted Computing and Applied Homomorphic Cryptography External Reviewer at Asiacrypt Privacy Preserving Machine Learning Workshop Computer and Communications Security Conference Dr. John Launchbury participated in the IFIP Working Group 2.8 on Functional Programming Dr. Scott Moore participated in DARPA’s ISAT workshop “An Analytic Framework for Cyber Automation” Dr. Bill Harris Served as a Program Committee member at the Symposium on Fundamentals of Computation Theory (FCT) Served as External Reviewer for IEEE S&P (“Oakland”) Dr. Georgios Dimou served on the best paper award committee at IEEE ASYNC 2018 Symposium. Dr. Joe Kiniry and Dr. Dan Zimmerman participated in Open Source Trusted Enclaves Workshop Dr. Joe Kiniry Spoke on the Keynote Panel at RISC V Summit: Opportunities and Challenges in Security for Open Source Hardware Served on the RISC-V Security Standing Committee as vice-chair Served on the Program Committee at ACM 2018 High Integrity Language Technology workshop Served as Chair of Industry Day at the 3rd World Congress on Formal Methods Dr. Dan Zimmerman served on the RISC-V Cryptographic Hardware Extension Technical Group as vice-chair Dr. Aaron Tomb served as member of the Pnwplse.org Committee", "date": "2019-01-23"},
{"website": "Galois", "title": "Galois: 2017 Highlights", "author": "Unknown", "link": "https://galois.com/blog/2018/01/galois-2017-highlights/", "abstract": "2017 brought continued growth in concern about the trustworthiness of computing systems. The breadth of our work at Galois has grown correspondingly. We opened a third office in Dayton, Ohio , grew past 70 employees, and continue to actively hire. We are grateful to our partners and clients that have helped us successfully develop the projects and intellectual contributions highlighted below. We’re excited to continue the effort with you in 2018. Overview In cyber-physical systems security and reliability research, we continued our work on both ground and air vehicles. We published an in-depth look at automotive vulnerabilities and approaches to secure automotive software in a special issue of IEEE Software. We also presented preliminary work on formally verifying a vehicle-to-vehicle (V2V) messaging system, and on extending and retrofitting UxAS, a software system from the Air Force Research Laboratory (AFRL) for multi-UAV cooperative decision making. We released our first report on applying formal methods to autonomous systems that incorporate neural-network-based reinforcement learning. Our efforts showed that, in combination, our formal methods approach enabled policy training with dramatically less data. Our work with Amazon to formally verify core components of the s2n encryption library continued to play a role in making essential software more secure. It is being leveraged by other important open source libraries, and we also gave a number of presentations on the process of automation and continuous integration of formal verification techniques in use with s2n. We continued to work on secure computation, the groundbreaking process of using sensitive, encrypted data without decrypting it. This year, our work focused on making these processes faster and more accessible . Our work on automatically detecting and preventing Distributed Denial of Service (DDoS) attacks evolved into more general network flow analysis and anomaly detection . At the Canadian ISP summit, we presented approaches that assist administrators by automating the detection of unusual patterns and anomalous flows, and the search for known issues that might cause them. More generally in cybersecurity, we published articles on government in-depth defense , and released tech reports on reducing return-oriented programming (ROP) exploits , a mechanism that allows attackers to string together small snippets of existing executable code in order to exploit programs. We announced three contract awards from the U.S. Air Force, Navy, and the Intelligence Advanced Research Projects Activity (IARPA), and won many more which we will be announcing in 2018. We also actively contributed to the public conversation around cybersecurity and software assurance through a number of interviews and articles in the press. Below you will find more detail on those contributions, organized by field. From all of us at Galois, we wish you a happy and productive new year. High-assurance Cryptography Privacy Technologies for Controlled Information Sharing in Coalition Operations , Best Paper award at KSCO Dr. Stephen Magill and Dr. David Archer were part of the team that published a paper on improving secure information sharing at Knowledge Systems for Coalition Operations (KSCO 2017). The paper considers how advanced privacy technologies can enable improved information sharing among coalition partners by both providing increased control over how information is used or released, and enabling principled characterizations of the impact of individual and cumulative sharing activities. It describes this work in the context of a humanitarian aid and disaster relief scenario, showing how the technologies can enable significantly increased and informed sharing. Also part of the team: Karen Myers, Tim Ellis, Tancrède Lepoint, Ronald A. Moore, Grit Denker, Steve Lu, Rafail Ostrovsky. Assuring Crypto-code with Automated Reasoning , QCon 2017 Dr. Aaron Tomb gave a talk at QCon 2017 where he described the capabilities and operation of open source tools that allow developers to conclusively and largely automatically determine whether a low-level cryptographic implementation exactly matches a higher-level mathematical specification. Dr. Tomb used Galois’s collaboration with Amazon to illustrate how these tools were integrated into the continuous integration system of their s2n implementation of TLS. See the source link for the slide deck and video of the presentation. Attribute-based Key Exchange with General Policies , TPMPC 2017 Dr. Alex Malozemoff gave an invited talk on attribute-based key exchange at the Theory and Practice of Multi-Party Computation Workshop (TPMPC 2017) . Attribute-based key exchange allows the establishment of a secure channel between a server and client if and only if the client satisfies some underlying policy. Julia for Fully Homomorphic Encryption: Current Progress and Challenges , JuliaCon Dr. José Calderón gave a presentation on Julia extensions for Fully Homomorphic Encryption at JuliaCon 2017 . In the talk, Dr. Calderón introduced a Julia module, Fhe.jl, which supports running Julia functions over an FHE-encrypted data set. This is done by using symbolic execution to convert a Julia function into its circuit representation, which we then evaluate over the encrypted data. The work is part of Galois’s RAMPARTS project. Jana – Private Data as a Service , HCSS 2017 Dr. David Archer gave a talk on Jana, a privacy preserving data service in which data is encrypted at all times, at High Confidence Software and Systems (HCSS 2017). The project is part of Galois’s efforts on DARPA Brandeis. Faster Secure Two-party Computation in the Single-execution Setting , Eurocrypt 2017 Dr. Alex J. Malozemoff was part of a team that published and presented a paper introducing a two-party computation protocol at Eurocrypt 2017 . The paper proposes a new protocol for two-party computation, secure against malicious adversaries, that is significantly faster than prior work in the single-execution setting Also part of the team: Xiao Wang, Jonathan Katz. 5Gen-C: Multi-input Functional Encryption and Program Obfuscation for Arithmetic Circuits , CCS 2017 Brent Carmer and Dr. Alex J. Malozemoff were part of a team that published a paper on cryptographic program obfuscation at the ACM Conference on Computer and Communications Security (CCS 2017). From the abstract: “In this work, we explore in detail cryptographic program obfuscation and the related primitive of multi-input functional encryption (MIFE). In particular, we extend the 5Gen framework (CCS 2016) to support circuit-based MIFE and program obfuscation, implementing both existing and new constructions. We then evaluate and compare the efficiency of these constructions in the context of PRF obfuscation.” Also part of the team: Mariana Raykova. Revolution and Evolution: Fully Homomorphic Encryption , US Cybersecurity Magazine, vol. 5, no. 16, 2017 U.S. Cybersecurity Magazine published an introduction to fully homomorphic encryption by Dr. David Archer. The article introduces the concept of computing on data while it remains encrypted and presents the current state of the technology. You can find the article on www.uscybersecurity.net or on the Galois blog here . Homomorphic Encryption Standardization Workshop , White Papers, Microsoft Research Dr. David Archer and Dr. Alex J. Malozemoff participated in Microsoft Research’s Homomorphic Encryption Standardization Workshop, where they co-authored to two white papers: Applications of Homomorphic Encryption , and A Standard API for RLWE-based Homomorphic Encryption . Applying NIST’s New Privacy Risk Management Framework , HCSS 2017 Isaac Potoczny-Jones, CEO of Galois spin-off Tozny , gave a presentation on NIST’s Privacy Risk Management Framework at High Confidence Software and Systems (HCSS 2017). In the talk, Potoczny-Jones gave an overview of NIST’s Privacy Framework and related standards (800–53, 800–63); described the implementation of a product, E3DB , based on these standards; and gave an in-depth review of the E3DB’s cryptographic approach and how it supports privacy. Data Privacy Issues in Distributed Security Monitoring Systems Dr. David Archer co-authored a book chapter titled “Data Privacy Issues in Distributed Security Monitoring Systems” in Security and Privacy in Cyber-Physical Systems: Foundations, Principles, and Applications. Software Correctness and Formal Verification Formal Methods and the KRACK Vulnerability Dr. Joey Dodds, with input from other Galwegians, weighed in on the WPA2 KRACK vulnerability that was revealed to enable a range of attacks on the protocol. The article covered some of the concerns around standards and formal verification presented in the original paper with the goal of providing insights into real-world cryptography verification. Abstract Interpretation at Galois , N40AI Dr. Aaron Tomb gave a talk on abstract interpretation at Galois at the Next 40 Years of Abstract Interpretation (N40AI) series at POPL 2017 . From the abstract: “Abstract interpretation has been part of Galois since its inception, even so far as to influence the original name of the company: Galois Connections. Aaron Tomb will talk about how Galois has used abstract interpretation in practice over the last decade and a half, and describe some long range ideas for what might make the techniques even more useful over the next four decades.” Type Theory in the Software Analysis Workbench (SAW) , TTT 2017 Dr. Aaron Tomb gave an invited talk on Galois’s Software Analysis Workbench (SAW) and its use of dependently typed features at Type Theory Based Tools (TTT) series at POPL 2017 . Dr. Tomb described the basic structure and capabilities of SAW, including some examples of widely used cryptographic code that we have verified with it. He also described the features of SAW’s intermediate language, including details about how it uses the dependently typed features. Proving Amazon’s s2n Correct , HCSS 2017 Dr. Joey Dodds presented our ongoing work to formally verify components of Amazon’s s2n TLS encryption library at High Confidence Software and Systems (HCSS 2017). Dr. Dodds gave an overview of the process by which verification is being done, particularly focusing on automation and continuous integration of the verification tools. The verification runs automatically with each code change, often keeping the proof intact despite changes to the software. For more information on the project, visit the project page on the Galois website. Proving Functional Correctness with the Software Analysis Workbench (SAW) , AFRL S5 Dr. Aaron Tomb gave a talk on using SAW to prove functional correctness at the Air Force Research Laboratory’s Safe and Secure Systems and Software Symposium (S5 2017). The talk used the verification of s2n components to demonstrate current capabilities. Modular Model-Checking of a Byzantine Fault-Tolerant Protocol , NASA Formal Methods Symposium 2017 Dr. Lee Pike and Dr. Benjamin Jones presented a paper on model checking distributed, fault tolerant systems at the NASA Formal Methods Symposium . The paper presented a general framework for modeling distributed, fault-tolerant systems and walked through a case study, modeling variations on the Oral Messages algorithm that vary in their timing model, node behavior, and fault model. Laziness Boxes You In , POPL 2017 Dr. José Calderón and Dr. Stephen Magill presented a paper at POPL 2017 on inferring information leakage via forced thunks. The talk and paper gave an overview on representing sensitive information as lazy values to give bounds on the amount of information leakage from a program. Starling: Lightweight Concurrency Verification with Views , CAV 2017 Dr. Mike Dodds presented a paper at the Computer Aided Verification (CAV 2017) conference on verifying concurrent programs. Dr. Dodds also presented similar work at the Mathematical Foundations of Programming Semantics XXXIII (MFPS 2017) and at NII Shonan Meeting Seminar 100 . From the abstract: “Starling is a lightweight, automated tool for verifying racy concurrent algorithms. Starling proofs are written in an abstracted Hoare-logic style, and converted into terms discharged by a sequential solver (for example, Z3). Starling is built on the Views framework, an abstract form of separation logic. In this talk I’ll describe how we specialise the Views framework into a simple, generic verification tool, and how we can apply this approach to verify complex pointer programs.” High-assurance Cyber-physical Systems Programming Languages for High-Assurance Vehicles , LangSec Workshop, IEEE Security & Privacy ( video ) Dr. Lee Pike presented our experiences in synthesizing a fully featured autopilot from embedded domain-specific languages (EDSLs) hosted in Haskell at the LangSec Workshop at IEEE Security & Privacy. The autopilot was built for the DARPA High-Assurance Cyber-Military Systems (HACMS) program. Full video of the invited talk can be found here. Secure Automotive Software: The Next Steps , IEEE Software, Volume 34, Issue:3 Dr. Lee Pike, Jamey Sharp, Dr. Mark Tullsen, Patrick C. Hickey, and James Bielman published an article on automotive vulnerabilities on a special IEEE Software issue focused on automotive software. The article reviews research that revealed pervasive software vulnerabilities in modern automobiles, explores the challenges that the automotive industry faces that can impede improved software security, and discusses four general approaches to secure automotive software systems: compile-time assurance, runtime protection, automated testing, and architecture security. You can find a pre-copyedited version of the paper here . Formal Verification of a Vehicle-to-Vehicle (V2V) Messaging System , ESCAR USA 2017 and HCSS 2017 Dr. Mark Tullsen presented a paper at ESCAR USA 2017 on formally verifying a V2V messaging system. The paper was authored by Nathan Collins, Mark Tullsen, Dr. Aaron Tomb and Dr. Lee Pike. Dr. Tullsen also presented similar work at High Confidence Software and Systems (HCSS 2017); find the abstract here. Formal Verification of a Vehicle-to-Vehicle (V2V) Messaging System , CPS V&V I&F Workshop 2017 Dr. Stephen Magill presented work on verifying a V2V messaging system at the Cyber Physical Systems Verification & Validation: Industrial Challenges & Foundations Workshop (CPS V&V I&F 2017). The talk presented the generation and formal verification of an ASN.1 encoder/decoder pair, implemented in C, using the High-Assurance ASN.1 Workbench and the Software Analysis Workbench. Improving Communication Security of Open Source UAVs: Encrypting Radio Control Link , ICUAS USA 2017 Michal Podhradsky was part of a team that published a paper on securing radio control links in open-source UAV software at the 2017 International Conference on Unmanned Aircraft Systems (ICUAS USA 2017). The paper proposes an implementation of an encrypted radio control (RC) link that can be used with a number of popular RC transmitters, using the ArduinoLibs, Galois Embedded Crypto library and openLRSng open-source radio project. Also part of the team: Nathan V. Hoffer and Calvin Coopmans. A Commitment Logic for Reasoning about Trust in Complex Systems , HCSS 2017 David Burke gave a presentation on commitment logic at High Confidence Software and Systems (HCSS 2017). Mr. Burke presented a framework based on commitment logic to reason about the trustworthiness of human-machine collectives (humans and AI agents). Memory Safety of UxAS Tasks / Retrofitting UxAS with Rust , AFRL S5 2017 Adam Foltzer presented work on using Rust to rewrite parts of UXaS , a software system for multi-UAV cooperative decision-making, at Safe and Secure Systems and Software Symposium (S5 2017) organized by the Air Force Research Laboratory (AFRL). Breaking the Human-Robot Deadlock: Surpassing Shared Control Performance Limits with Sparse Human-Robot Interaction , RSS 2017 Dr. Pete Trautman published a paper in Robotics: Science and Systems (RSS 2017) on human-machine teaming and interaction. The paper introduced generalized shared control, and proved that it optimizes human and robot agreement and intent under arbitrary ambiguity in a computationally efficient manner. Sparse Interacting Gaussian Processes: Efficiency and Optimality Theorems of Autonomous Crowd Navigation , Conference on Decision and Control 2017 Dr. Pete Trautman presented a paper about autonomous crowd navigation in Conference on Decision and Control (CDC 2017). The paper studies “the sparsity and optimality properties of crowd navigation and find that existing techniques” are lacking. It then diagnoses the cause of the deficiencies and introduces a novel solution. Probabilistic Versus Linear Blending Approaches to Shared Control for Wheelchair Driving, International Conference on Rehabilitation Robotics, 2017 Dr. Pete Trautman was part of a team that published a paper on shared control for wheelchair driving at the International Conference on Rehabilitation Robotics, 2017 . Also part of the team: C. Ezeh, L. Devigne, V. Bureau, M. Babel and T. Carlson. Dr. Trautman was also part of a team that published a paper on wheelchair shared control approaches at the IEEE International Conference on Systems, Man, and Cybernetics, 2017. Dr. Trautman also published a number of other papers on the topics of shared control: Generalized Shared Control versus Classical Shared Control: Illustrative Examples , Pete Trautman. Manifold Relevance Determination: Learning the Latent Space of Robotics , Pete Trautman. Integrating High and Low Level Path Planning , Pete Trautman. Cybersecurity Tech Report: Systems Support for Hardware Anti-ROP Jason Dagit, Dr. Simon Winwood, Getty Ritter, Jem Berkes, and Dr. Adam Wick were part of a team that published a tech report on hardware extensions and software modifications that reduce return-oriented programming (ROP) exploits, a mechanism whereby an attacker can string together small snippets of existing executable code—known as gadgets—in order to exploit programs without injecting new bits of code. Also part of the team: Andrew White and George Coker, NSA. Tech Report: Code Re-use Attacks and their Mitigation Jason Dagit, Dr. Simon Winwood, Getty Ritter, Jem Berkes, and Dr. Adam Wick published a tech report that provided a brief summary of notable attacks and mitigations with a focus on return-oriented programming (ROP). Provenance of Computation Meets Persistent Threat Detection: A Progress Report , TaPP 2017 Dr. David Archer gave an invited talk on detecting advanced persistent threats (APTs) at the 9th International Workshop on Theory and Practice of Provenance (TaPP 2017). Dr. Archer described our approach to detecting APTs using a combination of statistical anomaly detection and computational provenance exploration, walked through the architecture of our detection system, described the sensor data model we use as input to our analysis, explored our anomaly detection and provenance computation methods, and presented preliminary results from a recent adversarial engagement on real systems under realistic attack. Network Information Sharing: One World, One Love: Sharing Intel to Make the Network Safer , Oregon CyberSecurity Summit Galois co-organized the Oregon CyberSecurity Summit, at which Dr. David Archer presented our approach to privacy-preserving analysis of network compromise that allows for sharing indicators of compromise between distinct networks without revealing the data that led to establishing those IoCs. DDoS Defense with a Community of Peers (3DCoP ), Flocon 2017 Jem Berkes gave a presentation on defending against DDoS attacks using collaborative techniques at Flocon 2017 . In the presentation, Mr. Berkes gave an overview of 3DCoP, a Galois project that aims to use information sharing for automatic DDoS defense. He also presented 3DCoP at DHS S&T R&D Showcase and Technical Workshop. You can find that presentation here . I Want Your Flows To Be Lies , Flocon 2017 Dr. Adam Wick gave a presentation at Flocon 2017 on using cyber deception to mask flow data in a network in order to thwart attackers that are looking to gain a foothold on a network. The talk also illustrated how Galois’s CyberChaff and Prattle can be used to mask the real flows in a network. Gossiping for Good: The Benefits of Automatic Collaboration , Canadian ISP Summit Dr. Adam Wick gave a talk on detecting problems within networks through flow-data analysis at the Canadian ISP summit . The talk presented a tool that assists administrators by automating the detection of unusual patterns and anomalous flows, and the search for known issues that might cause them. End-to-end Information Flow Control for Hybrid Android Applications , IEEE MoST (Mobile Security Technologies) 2017 Dr. Andrey Chudnov was part of a team that presented a paper on enforcing security in hybrid Android applications at Mobile Security Technologies (IEEE MoST 2017). The paper explored how to leverage static analysis of Android/Java and dynamic analysis of Javascript to enforce information flow policies in such applications. Also part of the team: Julian Sexton and Dr. David Naumann. With Government Cyber Defense, Sometimes It’s Best to Give up Hope , Federal News Radio Dr. Adam Wick published an opinion piece on Federal News Radio on ways that government entities should approach cyber defense. From the introduction: “As counterintuitive as that may sound, there is no magic bullet that will solve all our cybersecurity challenges. A sufficiently motivated and capable adversary will get around our defenses, given enough time. The question then becomes: How can we tax that motivation, or increase the cost of these attacks? What emerging areas of cybersecurity should government decision makers focus on to extend the range and capability of our deterrents? Three areas in particular warrant government attention: cyber deception, defense in-depth and formal verification.” Data Analysis and Machine Learning Tech Report: Applying Formal Methods to Reinforcement Learning Dr. He Zhu and Dr. Stephen Magill published a tech report on formal methods guided testing of autonomous systems. In particular, the report looks at closed-loop control systems that incorporate neural network based reinforcement learning components. Using Formal Methods to Reason About Neural Network Based Autonomous Systems , AFRL S5 Dr. Stephen Magill presented work by Dr. He Zhu and Dr. Magill on using formal methods to reason about machine learning at the Air Force Research Laboratory’s Safe and Secure Systems and Software Symposium (S5 2017). GraPPa: Spanning the Expressivity vs. Efficiency Continuum , PPS 2017. Dr. Eddy Westbrook, Dr. Chad Scherrer, Nathan Collins, and Eric Mertens presented a paper on GraPPa, the Galois Probabilistic Programming Language, at the workshop on probabilistic programming semantics series at POPL 2017. Announcements, Events, and Releases Galois organized 7 public tech talks on a wide range of topics. Visit the tech talks page for the complete list. Galois Awarded Air Force Grant for Advanced Cyber Deception Technology . The $750,000 grant from the Air Force Research Lab (AFRL) aims to develop a new, advanced network cyber deception technology, Prattle, that generates realistic traffic to tag adversaries monitoring network activity, mislead them about things they may have learned, and cause them to make mistakes that increase the likelihood of detection. DARPA, Galois Launch Benchmark Challenges to Prvent Software ‘Reverse Engineering’. The challenges invited competitive submissions able to break the security of program obfuscation technology designed to prevent software ‘reverse engineering.’ Galois Awarded $2.7 Million Navy Contract to Develop New Cyber Resilience Capability. The ONR-funded project focuses on protecting real-time and embedded military software systems by making them resilient to attack. The project aims to harden control systems by using binary rewriting to add brittleness to legacy binaries. Galois Awarded $1 Million IARPA Contract to Improve Security of Data Computation. The project explored advancing the practical ease of programming, optimizing compilers, and high-performance libraries for fully homomorphic encryption. Galois launched the first office in Dayton, OH , co-located with the Nucleus incubator, Mile Two, and the Wright Brothers Institute . Galois established Discussions on Trustworthy Systems (DOTS) , a periodic gathering of individuals and organizations interested in closing the gaps on cyber vulnerabilities in embedded systems, in collaboration with the Armed Forces Communications and Electronics Association (AFCEA). The first gathering featured talks from the University of Illinois, Galois, and AFRL. The second gathering featured talks from Purdue University, Aurora Flight Sciences, and AFRL Autonomy Initiative, and can be found on YouTube here . Our collaboration with Amazon Web Services to formally verify parts of s2n continued to make essential software more secure . From the Amazon Web Services’ blog post: “Earlier this year, with Galois, we completed a proof of our implementation of AES_CTR_DRBG, and formally verified that our code in s2n is equivalent to the written specification. Recently, both the OpenSSL and glibc projects have been looking to replace their random number generators. They, too, are going with AES_CTR_DRBG, based in some part on the work in s2n and the availability of formal verifications that can be applied to code. That’s pretty sweet.” Galois presented work on high-assurance, formally verified, end-to-end systems and formally verified trusted boot for RISC-V at the 7th RISC-V Workshop . Galois spin-off Tozny launched InnoVault , an end-to-end encryption toolkit for developers. Galois spin-off Free & Fair was awarded a contract by the State of Colorado to develop a risk-limiting audit system that was used in the November 2017 general election, marking the first time that risk-limiting audits have been conducted on a regular, statewide basis in the U.S. For more information, see Free & Fair’s page on RLAs or check out this story on the auditing process. Free & Fair attended and presented at SXSW , with the aim of providing material and education on elections technology, potential vulnerabilities, and mitigation. Following SXSW, Free & Fair shipped a election education technology platform called Election Security 101 . Free & Fair co-sponsored and helped organized and run the annual Elections Verification Network Symposium and Conference in Washington, D.C. and the Global Election Technology Summit in San Francisco. Galois released ddosflowgen , an open-source tool that simulates DDoS attacks. Galois released Matterhorn, a terminal client for the Mattermost chat system. Galois released Cryptol 2.5.0 , with major improvements to the interpreter and type checker. Dr. Mike Dodds joined Galois as Principal Investigator. Dr. John Launchbury re-joined Galois as Chief Scientist. Press Coverage Highlights Loose Lips may better Air Force security with ‘Prattle’ , Federal News Radio Air Force goes after cyber deception technology , Network World Crypto-currency software emerges as tool to block cyber attacks , Bloomberg Business Week Galois wins $5.6m contract to help defeat reverse engineering threats , Washington Technology Northwest universities evaluating new approach to DDoS attacks , University Business How to make Fully Homomorphic Encryption “practical and usable” , Network World Privacy and Encryption Above the Data: Interview with Dave Archer , Fast Forward Labs (Interview with David Archer) EDUCATION ENCRYPTION BILL DROPS , Politico, (Quotes David Archer) The Security Panacea: Striking Balance with Usability , Tyntec (Interview with Isaac Potoczny-Jones) Why next gen vehicles should consider security from the start , StateScoop (Interview with Isaac Potoczny-Jones) Galois elections technology spin off, Free & Fair, saw broad coverage and interviews, from publications such as Route Fifty , Federal Computer Week , and the New York Times. For a complete list of coverage, see the news section on freeandfair.us . Program Committees, Reviewing, Guest Editing Iavor Diatchki, Program Committee Chair for Haskell Symposium 2017. Trevor Elliott, external reviewer for Haskell Symposium 2017 and FMCAD 2017. Eric Mertens, external reviewer for Haskell Symposium 2017. Dr. Alex J. Malozemoff, External reviewer for Crypto 2017 , ACM CCS 2017 , TCC 2017 , LatinCrypt 2017 , IndoCrypt 2017 . Dr. Stephen Magill, HCSS Program Committee. Dr. Lee Pike, FMCAD Program Committee. Dr. José Calderón, chair of SIGPLAN Research Highlights Committee ; video chair for ICFP 2017 ; external reviewer for Haskell Symposium 2017. Dr. Andrey Chudnov, reviewer for the Formal Aspects of Computing journal . Dr. Pete Trautman, Chair of “Autonomous Robots 1” session at Conference on Decision and Control. Dr. Adam, Track, Host of Modern CS in the Real World at QCon 2017 . Dr. Scott Moore, DLS and ACM SIGSAC PLAS Program Committees. Dr. Mike Dodds, ECOOP 2017 Program Committee.", "date": "2018-01-10"},
{"website": "Galois", "title": "Automated Software Diversity: Sometimes More Isn’t Merrier", "author": "Unknown", "link": "https://galois.com/blog/2018/09/automated-software-diversity-sometimes-more-isnt-merrier/", "abstract": "This is a followup to our previous post , which introduces our research exploring new strategies for protecting legacy applications on the DARPA CFAR program. Briefly, our approach is to generate variants of a target application that behave the same when given benign input but different when given malicious input. Then we run a set of these variants in a multi-variant execution environment (MVEE) that can detect a divergence in behavior, revealing attacks like buffer overflows, after which we can react and recover. Please check out our previous post for an overview of our approach before diving into the details below. In this post, we describe some of our strategies for generating secure variant sets and highlight some findings that illustrate why choosing the appropriate transformations can be surprisingly challenging, as in some cases layering additional defenses may negate previously-applied protections. Variant Generation Transformations Previously , we described our workflow of generating variants of a program by building the target application with a diversifying compiler. We call this a “multicompiler” and call the specific techniques that diversify a program “transformations.” Some of the transformations we support include: code layout randomization : reorder functions in a binary so code of interest exists at different locations in each variant globals layout randomization : pad and reorder globals so their absolute and relative positions are different in each variant stack variable randomization : like globals layout randomization, but for the variables in each stack frame heap layout randomization : runtime over-provisioning and random allocation to place heap objects at different locations in each variant C++ vtable randomization : reorder virtual function table entries to detect attacks that use these code pointers data randomization : XOR data before storing it in memory, XORing back on load. Partition variables via alias analysis and give each set a different XOR key in each variant, so an out-of-bounds write from X to Y fills Y with the attacker’s data XORed with X ’s key data cross-checks : check that data values used in conditionals correspond across all variants in a set function-entry cross-checks : make sure variants in a set are always executing corresponding functions at runtime fine-grained heap object ID checks : track allocations and cross-check variants in a set to detect e.g., use-after-free attacks struct layout randomization : in general, the programmer is permitted to make assumptions about the underlying order of struct field, but in circumstances where it is safe to permute this can help detect within-struct attacks Running Variant Sets Memory corruption exploits are brittle in that they depend on specific internal and low-level properties of a program. By varying these properties in each variant, we can produce variant sets where an exploit that works against one variant cannot work against another. But how exactly are variants run together in a MVEE? The feature/performance trade-offs of different MVEEs vary, but we rely on the core property that all variants run simultaneously, and the MVEE unifies input to and output from each variant (and effects, e.g. syscalls) to make the set appear to be a single instance to other parts of the system. This means the MVEE broadcasts the attacker’s input to all variants – an attacker cannot send different input to each variant. Similarly, the MVEE intercepts each variant’s attempt to produce output (or other system effect, like file I/O) and unifies this output – or detects/blocks/reacts to a divergence in behavior. So, an attacker cannot directly query each variant for variant-specific data. Hazards of Blindly Applying Software Diversity Techniques Conceptually, if randomization reduces the chance of an attack succeeding to some probability P , and you combine N variants in a set, one might guess that the probability that the set remains vulnerable is P^N . In fact, this is not always the case, and composing software diversification techniques requires care as some combinations can negate the security you thought you were adding. This section contains some examples of this hazard and guidelines for constructing secure variant sets. We discuss this problem in more detail in our Layered Assurance Workshop paper, titled “Composition Challenges for Automated Software Diversity” . Example: “Skewed Return” Attack Imagine the application to defend has some stack variable X and a vulnerability exists that allows an attacker to overflow past the end of X and overwrite the saved return address on the stack, controlling the execution of the application when the function returns. application :  | VariableX_1 | ... |  RET  |   // attacker's RET goal = 12345\r\npayload     :  | Xfiller>>>>>>>>>>>> 12345 | When the MVEE unifies the variant set’s input and output it will duplicate the payload from the attacker and pass it to each variant simultaneously. Against a set of two duplicate variants, the attacker’s chosen value will overwrite the saved return address in each variant identically. If we apply code randomization to each variant, then a desirable function the attacker wishes to execute will be located at different addresses in each variant. The attacker can make the variants jump to whatever address they wish but cannot choose different addresses for each variant. The MVEE can detect when a variant starts to be have differently than the others (or crash), revealing the attack. variant 1 :  | VariableX_1 | ... | RET_1 |   // RET_1 goal = 12345\r\nvariant 2 :  | VariableX_2 | ... | RET_2 |   // RET_2 goal = ABCDE\r\npayload   :  | Xfiller>>>>>>>>>>>> 12345 |   // cannot achieve both goals In the sample above, the “twinned” layout prevents the attacker from constructing any payload that will overwrite RET with the (different) desired values in both variants. Consider now that instead of overwriting the return, the attacker wishes to overwrite from X to some adjacent stack variable Y . We can randomize the order of stack variables, so an overwrite past the end of X may access Y in one variant, but not another. For example, if we align the vulnerable buffer X : variant 1 :           | VarX_1 | VarY_1 |\r\nvariant 2 :  | VarY_2 | VarX_2 |          // attacker cannot reach Y_2\r\npayload   :           | Xfiller>> AtkY1 | In variant 2, Y is before X and thus not vulnerable to this overwrite of X . If the variants each attempt to print their values of Y , for example, the MVEE will see variant 1 printing the attacker-corrupted value, and variant 2 printing the uncorrupted value. Unfortunately, adding stack variable shuffling has negated the protection we originally gained from our code shuffling example above. Shuffling the stack variables changes the offset from the X buffer to the saved return address in each variant, so the attacker now can craft a single payload that overwrites RET with a different code address in each variant simultaneously. variant 1 :           | VarX_1 | Var_Y1 |  ...  | RET_1 | // attacker wins\r\nvariant 2 :  | VarY_2 | VarX_2 |  ...   | RET_2 |         // attacker wins\r\npayload   :           | Xfiller>>>>>>>>>> ABCDE > 12345 | Padding vs. Shuffling In additional to shuffling the order of variables, we can insert random padding between variables to increase the amount of entropy. This may seem particularly appealing in regions with few variables (e.g., small stack frames). While there are instances where padding can make it more difficult for an attacker to guess a random layout, there are situations where adding padding makes it harder to detect attacks in a multi-variant environment. Imagine a vulnerability that allows an attacker to perform an offset write over the contents of an important permission variable. With variable shuffling, there is some chance that an offset write from the vulnerable buffer to permission in one variant manifests as an overwrite of, for example, some function pointer in another variant in the set. If the attacker’s desired permission value is not a valid function pointer then the MVEE may also detect the attack if the variant uses that function pointer. However, introducing padding increases the chance that an out-of-bounds write that is advantageous in one variant ends up only overwriting padding in another variant. This decreases the chance of “incidental” detection (via corruption of other state) and makes it easier for an attacker to overtake variants via “skewed” attacks as described above, or by overtaking single variants one at a time. Cross-Stack-Frame Attacks and SafeStack Code randomization leads to the detection of many buffer-overflows that write past the end of a stack variable buffer and onto contents of a parent stack frame, as these overflows clobber the return address between the two stack frames. An attacker’s payload must contain valid a return address value, which the variant uses used to return to the function caller’s context where the (corrupted) data in the parent stack frame is in scope. Well-selected data layouts (avoiding pitfalls such as those described above) constrain the attacker, leaving them unable to create a payload that overwrites the return address with valid code addresses in all variants without the MVEE detecting the attack. Similarly, it may be impossible for the attacker to overwrite the saved base pointer with valid addresses in all variants. original stack: | vuln[] | saved RBP | RET | parent_frame_data[] |\r\npayload:        | ATTACK>>>>>>>>(RBP)>(RET)>>>OVERWRITE_PARENT>> | SafeStack is a stack protection technique in clang that moves all potentially vulnerable stack variables to a separate “unsafe stack”. Specifically, address-taken variables are moved to the unsafe stack as these are typically prone to out-of-bounds accesses. This leaves return addresses and variables known to be only accessed safely on the “real” stack, which the attacker cannot reach from the overflows on the unsafe stack. Unfortunately, adding SafeStack to variants can make it easier for an attacker to overflow and corrupt data in parent stack frames, as there are no saved return addresses (or saved base pointers, etc.) between stack frames on SafeStack’s “unsafe stack” containing vulnerable buffers. \"safe\" stack:   | saved RBP | RET |\r\n\r\n\"unsafe\" stack: | vuln[] | parent_frame_data[] |\r\npayload:        | ATTACK>>>>OVERWRITE_PARENT>> | In this scenario, adding SafeStack to variants actually introduces the possibility of previously-infeasible data-only parent-stack-frame overwrites. Hazard: Data Randomization + “Skewed Data” The examples above show some hazards of combining multiple transformations, but we must also reason carefully about individual transforms to understand the limitations of each. Our “data randomization” transformation uses alias analysis to determine the set of memory locations that can be addressed by a given memory access. The results of the alias analysis are used to partition data references and give each set a unique XOR “key.” Variants XOR data with its corresponding key before storing it in memory, then XOR it back on load. This means that an out-of-bounds write from variable X to variable Y will write data to Y using X ’s key, which the variant will XOR with Y ’s key instead when it later retrieves it from memory. The keys are different in each variant, so this gives data values protected by these keys a similar protection as what we get for code pointers from code randomization: even if the attacker knows what values they need in each variant, they cannot write different values to each variant. At least one variant ends up with “garbage” the attacker cannot control. At first glance, this seems quite strong: with 64-bit keys, there is a 1 in 2 64 chance the keys “line up” to give the attacker a specific desired value. However, there is an issue: the “skewed data range” problem. Specifically, the attacker’s desired value(s) may not be evenly distributed across the possible values for the target variable. Consider the code: if (is_admin) { ... } The attacker does not need to completely control the content of is_admin in each variant, but only to make is_admin nonzero across the set, which is extremely likely even with data randomization. Our solution is to insert data cross-checks to make sure the exact content of values used in conditionals are equivalent across the variant set. During variant generation, we instrument variants to pass these values to the MVEE monitor at runtime, so the MVEE can do the comparison across all variants in the set. This maximizes the value of our data randomization transformation, as now the MVEE detects divergent behavior if is_admin has a different value in each variant, even if the conditional expression would have evaluated to true in each. The insertion of these cross-checks requires some additional analysis to avoid cross-checking pointer values, as we expect addresses to vary across the set as a result of our other transformations. Secure Variant Set Design So, what makes a good variant set? A full analysis and assurance case is beyond the scope of this post, but some general guidelines: Randomize code layout differently in each variant. Enforce disjoint memory layouts such that there is no absolute address that is valid in all variants. Apply data randomization and cross-checks, with different data rando keys in each variant. Additionally, it is useful to have two “ twin ” variants with the same relative data layouts but different code layouts and data randomization keys. Twinned data layouts make it impossible for attackers to use many vulnerabilities to write different variables in each variant, exposing attacks on: code pointers values via code layout randomization (and/or disjoint memory) data values, via data randomization & data cross-checks Adding a third variant with a reversed -order data layout of the twins can rule out attacks based on vulnerabilities that can only write one direction, e.g. common overflows past one end of a buffer. In this case, if X can overflow onto Y in the twinned variants, Y will be before X in the “reversed” variant. Conclusion Software diversity transformations interact in subtle ways that can impact the security of a multi-variant set, and naively maximizing randomness does not always maximize the chance to detect an attack. We have strengthened our defenses by taking a more structured approach. Please see our paper “Composition Challenges for Automated Software Diversity” for additional detail and recommendations for variant set composition. Acknowledgments This material is based upon work supported by the United States Air Force and DARPA under Contract No. FA8750–15-C–0124. The views, opinions and/or findings expressed are those of the author and should not be interpreted as representing the official views or policies of the Department of Defense or the U.S. Government. Distribution Statement “A” (Approved for Public Release, Distribution Unlimited).", "date": "2018-09-10"},
{"website": "Galois", "title": "C2rust", "author": "Unknown", "link": "https://galois.com/blog/2018/08/c2rust/", "abstract": "Motivation The c2rust project exists to help bridge the fact that there is a lot of valuable software written in C and that there have been great strides in making safer and more-reliable programming languages since C was designed. Rust offers many modern improvements for C while still preserving the low-level control that makes it attractive. Beyond that, Rust provides new abstraction capabilities like parametricity, type-traits, methods, a module system, thread-safety, and more. Rust improves on the memory management model of C with a new, checked ownership system. We’d like to be able to migrate C code to take advantage of this. Along the way we’d like to avoid introducing new bugs during translation. To support this we are developing this mechanical translator to handle the initial, error-prone work of the initial port to a new language. C has many opportunities to make a mistake during porting. The control flow structures are slightly different, and C has a lot of implicit cast behavior that can be important to preserve. Once we’ve made that translation to explicit behavior in Rust we can work toward increasingly idiomatic and safe Rust! Architecture Understanding C code goes beyond simply translating from one syntax to the other. In order to understand the meaning and behavior of C we have to be able to type-check it. The types will dictate the behaviors of different operators, determine if an operation can overflow or not, and determine implicit coercions. Type checking C is not a trivial process, and it’s not something that we wanted to reimplement. Fortunately there is a high-quality C compiler available that we can use as a library to aid in assisting with the process of understanding C. Clang The Clang project offers a C++ library for making clang-based tools called LibTooling . This library solves a couple different problems that are encountered when processing C files: processing command-line flags, running the preprocessor, parsing, and type-checking. It provides access to clang’s lexer, parser, type-checker, various transformation and analysis building blocks, and integrated access to the pre-processor. We’ve written a tool using LibTooling called ast-extractor that is able to process C files into type-annotated abstract syntax trees (AST). These are suitable for processing by the translator. This AST extractor does no translation itself and simply handles serializing the clang representation of a program into a format suitable for processing by external tools. In order to make the extracted AST easy to process by multiple tools, we’re using CBOR . This binary format is compact, has a self-describing structure, and has implementations in many languages. Choosing CBOR has saved time in both implementation of the serialization and deserialization process, and it has also helped when we’ve wanted to inspect serialized ASTs directly for debugging purposes. C files in large projects don’t exist in isolation. They exist in an ecosystem of include paths, preprocessor flags, language extension flags, and more. We can’t ignore all of these flags when processing a C file, and it would be a lot of work to correctly implement the logic to handle all of them. LibTooling has already undertaken the hard work of reaching compatibility with GCC’s flags, and this was no small endeavor. Fortunately we’re able to build on top of this work. Integration with the build systems that provide these flags is a challenge discussed below. libsyntax As a Rust compiler, rustc needs to be able to parse and print Rust source code. This functionality is contained in the internal crate libsyntax . This crate makes it possible to reliably parse and print Rust from our own tools and tools like bindgen . As an internal component of the compiler, this crate is only exposed on nightly releases. Its API is not stable, which means that our use of it requires us to fix to a specific nightly release. Keeping pace with the changes has been a minor inconvenience compared with the benefits of having a complete Rust parser, abstract syntax tree and printer. Handling comments in an abstract syntax tree is always a challenge. Comments are typically part of the lexical syntax of a language and are removed before parsing happens. Comments are able to fit into places in the syntax where it wouldn’t make sense to have attachment points in the AST. Consider some of the many places one can put comments into a for-loop! for x /*a*/ in /*b*/ 1 /*c*/ .. /*d*/ 10 { println!(\"{}\",x) } To handle this, libsyntax tracks comments in parallel to the AST. The comments are then cross-referenced with the AST by byte position. This allows comments to be reinserted into the concrete syntax back to the positions where they were originally parsed from. The byte-oriented placement of comments is a challenge, however, when you’re generating syntax trees programmatically. We don’t know the byte-positions of the final concrete syntax until we actually render our generated AST! In order to work around needing to know byte-positions, we assign temporary, unique byte-positions to any element that needs a comment attached. As a final pass, we renumber all of these byte-positions to ensure they occur in ascending order in the final AST before we print it. This enables the pretty printer to correctly associate comments with the corresponding concrete syntax. Challenges While Rust is able to express most of what C can, there are some areas that require more care when translating. In the following sections a few of the challenges are described. Build system integration Software projects are more than a set of source files. We also need to know how to combine all of those source files to produce an executable. Build systems automate the process of compiling source files, specifying extensions, distinguishing search paths, and more. We need this information in able to translate the C files for a project. LibTooling expects to find the flags used to compile a C source file in a compile commands database file named compile_commands.json . It will automatically use this database when processing C source files. To get all the correct settings in place for clang it’s enough to generate this file. We have two options for generating the compile commands database automatically. The most direct way is for projects built using CMake which will generate the database when activated with a simple flag. For other projects that aren’t using CMake, we can use Bear . This tool is able to wrap an existing build process and intercept builds commands in order to track the flags that were needed. While the CMake approach is the most convenient, most projects aren’t using CMake to manage their build process. Bear is useful on a wider range of projects, but also involves actually building the projects. Beyond translating a project we still have the challenge of integrating the generated Rust back into the project’s build process. We don’t have an automated solution for this. Currently it is necessary to invoke the Rust compiler to create a single static library from all of the translated Rust sources and to link that library into the project. CPP and Macros In order to be able to write more portable, efficient, and compact code C programs are run through a pre-processor before actually being compiled. This allows a C program to be customized uniquely for each platform that it is run on before being compiled, and it also helps address some of the limited abstraction facilities in the C language. While both useful and powerful, the C pre-processor (CPP) operates at the level of string concatenation. It neither knows nor respects the syntactic structures of C. This means that it is generally impossible to parse a file using CPP as having anything to do with C. In order to perform our translation we need to be able to parse and type-check the C source code. This forces us to operate on the output of the CPP and means that our translation will lose the abstractions that only exist in CPP code as these abstractions live at the superficial level of string concatenation. On the other hand, this extreme flexibility means that C files can use syntax that will only be valid on some platforms and hide this compatibility code from parsing on others. LibTooling does provide support for tracking source positions corresponding to both macro location and expanded source location. Perhaps in the future work we’ll be able to recreate some of the simpler CPP abstractions in the translated Rust. In our current implementation, we lose the CPP abstractions, however. Control Flow Unlike C, Rust has no support for goto or fall-through in switch statements. This led us to need to do an extensive analysis of the control-flow graph of our C programs to transform them to use syntax that exists in Rust. Static Initializers Rust is more particular than C when it comes to initializing static variables. There are multiple reasons for this. One reason is that some functionality that is primitive to C is hidden behind method invocations in Rust. When compiling to an object file the compiler needs to know the exact values that a static variable should be initialized with. It doesn’t generate code to do this. Only specially marked const fn methods are able to be called in Rust in these contexts. Another issue derives from Rust’s attempts to be thread-safe. Only certain types are suitable for being stored in static mutable variables. Loading string literals into static variables was another challenge. The type of Rust string and byte-string literals does not correspond to those in C. This requires us to perform a chain of casts in some cases to get equivalent behavior, where we would be able to write shorter translations outside of the initializers. To work around these limitations and others related to pointers into static variable, we lift some static variable initializers out to a top-level initialization function. This function will need to be run when the module is loaded. In other cases we are able to produce messier code that is able to work around the Rust limitations and without extracting the initializers to a top-level function. While this approach works, we anticipate these initializers will be an early target for refactoring. Variable-length Arrays Variable-length arrays (VLA) are an useful feature added in C99. These allow for arrays to be dynamically sized while still being declared as automatic variables. Perhaps surprisingly these can also be used in function arguments as seen below. void example(int a, int b, int c, int my_array[a][b][c]) { ... } pub unsafe extern \"C\" fn example\r\n  (mut a: c_int, mut b: c_int, mut c: c_int,\r\n   mut my_array: *mut libc::c_int) {\r\n\r\n    let vla_0 = b as usize;\r\n    let vla_1 = c as usize;\r\n    ...\r\n} To provide C implementation flexibility, the standard places no requirements on where these arrays are actually allocated. This frees our translation to be able to use the standard Rust Vec type. VLAs are never initialized in C code. In our translation we compute and store all of the size components of a VLA and declaration time and then save those components for use later when computing offsets into the array. Caching these values becomes important because the sizes can be computed from arbitrary expressions (including function calls) and the variables that these sizes are computed from can change later (without affecting the array). Beyond finding a way to allocate VLAs, the translation also needs to be able to compute indices into VLAs. These index computations require dynamically computing the strides for the various index components. These computations will use the cache size values as seen in the example code above (e.g. vla_0 ). Perhaps surprisingly, nested VLAs are not represented as nested Rust Vec types but as a single flat Vec with computed offsets. This is due to layout requirements in C. VLAs need to be compatible with their non-VLA counterparts. While we back VLAs with Vec we actually pass them around as pointers (as seen in the example). Variadic Functions Typical C code, including the standard C library, makes use of variable argument functions. Unfortunately, Rust has limited support for variable argument functions. Our translator does the best that it can to support the features that fit into Rust. Rust supports importing variadic C functions. This means that we can translate code that calls functions like printf . When calling these functions it is necessary for the Rust code to manually promote arguments. Fortunately these promotions are already computed by clang for us in the exported AST. In upcoming work, Rust will support writing functions that manipulate va_list values manually. This means that we can translate functions like vprintf . We currently support the proposed form of this feature, though using it requires a custom-compiled rustc . We don’t currently have a way to define new variadic functions. This means our translator is unable to process such function definitions during translation. Our current work-around is to declare these as external functions and require them to be compiled as C manually. The programmer performing the translation would need to refactor the code to not need this feature to finish translating to Rust. Note This research was developed with funding from the Defense Advanced Research Projects Agency (DARPA). The views, opinions and/or findings expressed are those of the author and should not be interpreted as representing the official views or policies of the Department of Defense or the U.S. Government.", "date": "2018-08-14"},
{"website": "Galois", "title": "Architectural Security, the Ardennes, and Alfred the Great", "author": "Unknown", "link": "https://galois.com/blog/2018/05/architectural-security-the-ardennes-and-alfred-the-great/", "abstract": "This article originally appeared in the Spring 2018 edition of the U.S. Cybersecurity Magazine Much of cyber defense today relies on the same approach used in kinetic defense over the last few thousand years. We use hard perimeters (firewalls) to repel attacks, sentries (IDSs) to trigger incident response, and carefully guarded entry points (VPNs, websites) to meet functional requirements (wait…security is still a non-functional requirement?). It’s both a poor defense, and indicative that we have a poor model of our cyber adversaries. Admittedly, the standard defense model is easier and less (immediately) costly than the alternative of hardened applications and databases. Nobody seems to notice, though, how that defensive strategy often worked out for the defenders. “I have a firewall” worked out poorly for example on May 12, 1940, when a poorly supported and organized Wehrmacht Army Group A punched through the “impenetrable perimeter” of the Ardennes at Sedan, 20 kilometers west of where Fort No. 505 terminated the Maginot Line, and sprinted through France’s “soft center” to the English Channel — sealing the fate of France and Belgium in WWII. Alfred the Great. By Odejea , CC BY-SA 3.0 , Link Fast rewind to 895AD. Wessex. Alfred the Great. Over 20 years, Alfred studied his enemy, and carefully organized Wessex into a checkerboard defense, combining an array of fortified, garrisoned towns with a standing mobile field force. How did that work out? Wessex was the sole kingdom and royal house in England to survive the micel hœden here — the “great heathen army” — a loose confederation of viking war bands that destroyed nearby Northumbria, East Anglia, and Mercia. 1,107 years later, Alfred ranked 14th in a poll of the “100 greatest Britons”. Alfred’s defense-in-depth, what Miksche called “islands of resistance”, assumed that attackers would penetrate every defensive perimeter, and that localized defensive strength had to stand alone. This defense might have failed against an invading force intent on destroying the checkerboard. But against a “limited aims” offensive strategy (one that seeks to plunder specific targets), the checkerboard paid off. As it turns out, it also paid off against an adversary intent on destroying the defenders in 1942, when Auchinleck stopped Rommel at the first battle of el Alamein. Today, we call the checkerboard a “zero-trust model”. It assumes that every network and host is already compromised and may be malicious. Interesting, isn’t it, how the “limited aims” attack strategy models modern cyber attacks better than the “destroy the defender” strategy? So why do we still choose defenses against the latter when most often faced with the former? But…can application developers ever be motivated, like Alfred, to design security into every application from the ground up? So far, it’s been an easy escape to cite expensive development and distraction from functional requirements – a “dancing pigs” argument. Perhaps, given sufficient commitment and exemplars, we can change that tide. I’ve recently been lucky to have a view into a “security, built-in” approach to new application development at Callisto, a non-profit working to combat sexual assault and harassment in a variety of industries. A quick tour of their raison d’être and technical approach to information security may offer a good example of a better way. Callisto’s validated premise is that reporting an incident of sexual assault is both significantly more rapid and likely when survivors know they are not the only victim of an assailant. In Callisto’s new invitation-only system, users from partner organizations can submit detailed information about incidents and perpetrators, along with relevant personal data about themselves. Invited users receive encrypted email invitations to activate accounts on the system and verify their identity. Once verified, users are free to submit incident reports that include one or more identities of the accused perpetrator: a cell phone number, a social URL, an e-mail address. When a perpetrator is identified by more than one victim, a lawyer will reach out to each victim individually (and if appropriate, may connect the group of matched victims together) to help them find their desired pathway to justice. Callisto’s data corpus is thus highly sensitive personally identifiable information, and a rich target for exfiltration. In response, Callisto’s design is a model for a new generation of application designs where zero trust systems is the new black. Callisto’s security stance is driven by the NIST Risk Management Framework. Comprehensive use of privacy-preserving encryption technologies, cryptographic proofs, multi-factor authentication, and best practices in system security design protect user data and activities. Personal information of users, their accounts of incidents, and the identities of perpetrators are encrypted before they leave the user’s browser and remain encrypted until they are decrypted on the personal workstation of a lawyer. That is, Callisto servers never store or compute on data about users, incidents, or victims in plaintext form. In addition, everyone — even Callisto’s trusted lawyers — is cryptographically prevented from accessing incident or perpetrator identity information unless more than one user has identified the same perpetrator . This part of Callisto’s security story begins when the user’s browser interviews the user and collects detailed information about the incident and perpetrator. Because matching perpetrator identities among disparate users and incidents is a key part of Callisto functionality, those identities must be stored in a way that allows their comparison but prevents them from being learned. First, a pair of servers aids the client browser by providing an oblivious pseudo-random function service that boosts entropy of the perpetrator identity without the servers learning that identity. That boosted value is always the same for a given identity, giving a common reference point among users. Next, the client creates a secret share of the boosted value (by mapping it to a point in the space of possible perpetrator identities); and also derives a pseudo-random value from the boosted value that allows discovery of perpetrators in common among distinct users. The pseudo-random value is used by the system to periodically perform an off-line search for multiple occurrences of a perpetrator. Matching is done without access to perpetrator identities or incident records in unencrypted form, so no adversary penetrating the servers can learn anything about perpetrator identities or incidents from the data stored there, or from the matching process. The secret share is encrypted with the public key of a Callisto lawyer. Possession of a single decrypted share offers no information. However, possession of two or more shares from distinct users for a matching perpetrator allows the lawyer to plot a line in the perpetrator identity space, find its intercept, and thus recover the perpetrator’s identity. Because the perpetrator identity is the source of a key used to encrypt the relevant incident report, the lawyer can then decrypt those incident reports, identify the reporting users, and then decrypt their personal contact information and begin the resolution process. These techniques, along with others we haven’t covered, make Callisto a hardened application that treats information security as a first-class requirement — part of a checkerboard defense appropriate for the limited aims adversary model, and cryptographically hard to defeat. It sets dancing pigs aside in favor of a design paradigm that more organizations should follow in stewarding sensitive information. The Callisto crypto demonstration and white paper can be found at https://cryptography.projectcallisto.org . Take a minute, and look at an ancient new way to make your organization secure: one app at a time.", "date": "2018-05-23"},
{"website": "Galois", "title": "Secure pprzlink: encrypted communications for open source drones", "author": "Unknown", "link": "https://galois.com/blog/2018/04/encrypted-communications-for-open-source-drones/", "abstract": "Earlier this month, the Paparazzi team released Secure pprzlink , an encrypted communication protocol for UAVs. While developing Secure pprzlink was a community effort, Galois supported Secure Pprzlink in part as an internal research project I was involved in, and in part as my innovation week project. Secure Pprzlink is an encrypted version of pprzlink . Pprzlink is a multi-UAV communication protocol, similar to MAVLink. However, both Pprzlink and MAVLink are unencrypted, making communication easier, but also risky. Without encryption, anyone can listen to your drone communication, and can potentially send modified or outright “fake” commands to it, steering it off course, or causing it to crash. Using an encrypted radio link is similar to using an encrypted connection to the internet, and should be  common practice. The new secure Pprzlink uses a strong and fast cipher ChaCha20 with Poly1305 authenticator. For better security and user convenience, we implemented a variation of station-to-station key-exchange protocolto allow seamless key-exchange between the UAV and the GCS. Secure Pprzlink is backed by a formally verified cryptographic library HACL* (yes, the same library that is a part of new Mozilla Firefox). Secure Pprzlink was inspired by Galois Embedded Crypto (GEC ) library, which was designed for SMACCMPIlot secure autopilot as a part of Galois’s effort on HACMS project. Why is using a formally verified crypto library important? In short, cryptography is hard to do right, and formal methods help make sure that the encryption algorithms behave as intended. This short video may give you a better idea: Secure Pprzlink uses a formally verified cryptography library, but is not verified itself. However, it could be verified in the future, to provide additional guarantees. How can I use it? The Paparazzi team prepared a wiki page with instructions and examples. In short, choose a secure link as your mode of communication when building the autopilot code, and the rest is handled automatically. Also, the GCS part of secure pprzlink is written in Rust , a memory-safe language, which guarantees that the code written in Rust is itself memory-safe and thus eliminates a large amount of possible software bugs. Give it a try, and please send us any feedback and ask questions on the paparazzi gitter channel , or via the paparazzi mailing list . Wishing everyone happy (and secure) flying!", "date": "2018-04-02"},
{"website": "Galois", "title": "Is the NIST Risk Management Framework poised to become a national cybersecurity standard?", "author": "Unknown", "link": "https://galois.com/blog/2012/08/is-the-nist-risk-management-framework-poised-to-become-a-national-cybersecurity-standard/", "abstract": "A lot of organizations, including small businesses and critical infrastructure operators, might soon get new technical security requirements from the federal government. This will probably be very costly, especially for small businesses that don’t already implement the kinds of security measures that are standard for large federal contractors. I’ll give a brief overview of two efforts: a bill in the US Senate called the Cybersecurity Act of 2012 (CSA) that just failed , but gives us an idea of how Congress is thinking about securing critical infrastructure operators, and a new federal contracting rule that’s closely related to parts of CSA in its goals and technical details. Both of these efforts focus on NIST’s Risk Managment Framework, and if you’re not already familiar with this process, now might be the time to get up to speed. NIST’s cybersecurity standards Almost 10 years ago, Congress passed a law requiring federal agencies to develop and follow computer security plans that conform to standards set by the National Institute of Standards and Technology (NIST). In turn, NIST implemented the Risk Management Framework (RMF), which is a set of interlocking security standards that includes processes and specific technical requirements. By law, federal agencies have to follow these standards, and the GAO regularly calls out organizations that aren’t doing enough. Lately, the federal government has started to push rules and legislation that would bring NIST standards more forcefully into the private sector. DoD contractors may get new security requirements The first example is a proposed federal contract rule that would apply to many companies that do business with the DoD. This includes 76% of small businesses that work with the DoD. In its current draft form , the rule would mean that businesses need to apply complex and detailed NIST technical security requirements (called “controls”) to unclassified data kept on their own systems. A small business might be required to drastically modify their internal communications and collaboration systems since the controls state that they must apply the “Principle of Least Privilege,” meaning users can access only data they need to do their job. Another rule would require the use of FIPS certified cryptography to protect unclassified information. This is just a small sampling; other controls cover training, security auditing, configuration management, contingency planning, authentication, incident response, visitor controls, physical protections, and many others. Risk management vs. legislating technical requirements The NIST framework normally distinguishes between systems based on the potential negative impacts of a security incident and recommends different controls for different types of systems based on a risk assessment. My reading of the contracting rules as currently described is that they dictate specific technical controls without performing any risk assessment. The upside of including a specific set of controls might be that small companies don’t have to perform a complex risk assessment to decide which controls to implement. The NIST risk management framework is designed for extremely large government agencies, and there is currently no guidance for applying it to small businesses. There is a downside, though, to dictating specific controls without a risk assessment. Businesses might have to implement overly restrictive systems that aren’t justified by the risks. For instance, many of the proposed security controls would normally be applied only to systems where a security incident would cause a “serious” effect like significant financial loss or significant harm to individuals. A few of the controls, like the FIPS certification of cryptography, are usually recommended only for systems with potential “catastrophic” effects. Will these new rules make it hard for small businesses to work with the federal government? The goal of these rules is clearly to improve security for organizations that handle DoD data, but the compliance requirements for small federal contractors will likely be expensive (according to the proposal itself) and put them at a disadvantage in the commercial and government markets. At the same time, DARPA programs like the Cyber Fast Track are seeking out non-traditional small businesses to create innovative security solutions, and it’s designed to work well for firms who have not previously done work with the federal government. It’s reasonable to expect that, if these rules are put into place, and if they are applied to such companies, it will make it harder for programs like Cyber Fast Track to bring in new talent. The Cybersecurity Act of 2012 Another major effort by the federal government to bring better cybersecurity into the private sector was the Cybersecurity Act of 2012 (CSA). This is a bill just failed in the Senate, but it was strongly backed by President Obama in a Wall Street Journal op-ed . Even though the bill didn’t pass, it gives us some insight on the direction Congress would like to go. This law would have given NIST the power to set cybersecurity standards for operators of critical infrastructure like the electric grid. The law would require risk assessments across all the critical infrastructure industries, establish performance requirements, and provide for civil penalties for failure to meet the requirements. The Cybersecurity Act would also establish standards for certified third-party assessors who can measure an organization’s security. If an organization complies with the security requirements or passes this type of assessment, they won’t be held liable if there is a damaging cyber attack. The law doesn’t seem to say that the NIST RMF would be used, but that NIST would set the standards and would use a risk assessment in doing so. It’s reasonable to guess that the standards would look a lot like the existing RMF. Challenges in applying NIST’s framework Taken together, the existing laws and potential new laws and regulations point to the major influence of the NIST Risk Management Framework over improving cybersecurity efforts, large and small. I’m a big fan of the framework, but there are significant gaps in it. For instance, it is pretty complex, and NIST should build a streamlined version for small businesses rather than giving contractors specific technical requirements without any risk assessments. Furthermore, federal cybersecurity requirements might make it difficult for businesses ( especially small businesses ) to use cloud services, create new barriers to entry for innovative small cloud service providers, and give established large contractors a leg-up in secure cloud services in private industry. The rules that govern federal agencies are confusing enough that last year, Microsoft and Google engaged in a war of words about whether their products met federal standards and could be used for government services. This type of confusion might spread to private industry if these rules are adopted over the next few years, slowing the pace of cloud adoption. Is the NIST Risk Management Framework poised to become a national cybersecurity standard? There is no guarantee that these laws and regulations will pass, but changes are coming in cybersecurity, and it’s very likely that NIST’s approach will win the day since it’s so widespread in the federal government. If you think you might be affected by the new rules, you should familiarize yourself with the NIST process so you can plan for the new regulations, and potentially even effect them before they are put in place.", "date": "2012-08-02"},
{"website": "Galois", "title": "A Disciplined Approach to Talking About Security", "author": "Unknown", "link": "https://galois.com/blog/2011/11/a-disciplined-approach-to-talking-about-security/", "abstract": "Recently, a thread about a security problem in a piece of open source software got a lot of attention. There was a vulnerability report, a defensive developer, persistent security folks, and of course sideline comments taking one side or the other. This discussion perfectly illustrates why it can be hard to have a civil discussion about security, and why even with the best of intentions and with skilled developers, security problems can persist in a software system. I want to take the incident in question as an example to illustrate a better way to reason about and to talk about security.  I’ll generalize and fictionalize the incident so it’s clear how it applies more broadly, not just to open source discussions between a handful of people, but also in a corporate context: Your typical hard-working and dedicated development team gets a report from the security team (or an external security researcher) that there are a pile of security problems with their project They take it a little bit personally: they are worried they might get into trouble. No one told them to care about security, or maybe they are frustrated that the security team is always slowing things down when they have features they need to develop. They wonder why the organization / community is investing time in finding security problems when there’s barely enough budget for the development team to get the features implemented. The security team starts suggesting really disruptive fixes before it’s even clear that there’s a problem, and even if there was a problem, maybe it’s not that big of a deal. Because after all, no one is supposed to use the system for sensitive data, or because no external people are allowed to use the system, or because of the firewall/VPN, or because it’s an embedded device, or because it’s just a beta test, or because users have root on these devices anyway, etc., etc. The development team grudgingly patches one of the problems and calls it a day, but the security team comes right back and claims it’s not fixed. They tell a senior manager that the developers didn’t implement their suggested fix, and now there are rumors that the project is completely insecure. The senior manager shows up one day and tells the developers that the critical IP of the company is being protected by their project, and now that these problems have surfaced, security has to be perfect from here on out. Now everyone is unhappy: The security team thinks their vulnerabilities will never be fixed so they write exploits to show how dangerous the problem is, the developers know that the system will never be perfectly secure because nothing ever is so they start hiding problems, the managers are terrified that their critical data is at risk so they start threatening people’s jobs, and the rest of the poor users are worried they’re going to lose a software tool that they rely on to get their job done. This kind of communication problem, and the resulting security problems, can be avoided by using a disciplined approach to reasoning about and talking about security. This approach can be applied to restructuring large organizations or just having an effective conversation between two people. It goes something like this: identify the assets you’re trying to protect, their value, and their nature, identify the threats against those assets, discover the vulnerabilities that can be exploited by the threats, and identify and implement countermeasures that can mitigate those vulnerabilities. These steps are the foundations of Security Risk Management and you can start with them or you can invoke them when the conversation about security seems to be going at cross purposes: when one person is talking about vulnerabilities but the other person is talking about firewall, or that no one would ever attack them anyway. Each element has to be addressed and ignoring one of them will probably lead you to the wrong conclusions about where to invest time and money. The conversation might go something like this: Developer: I understand there might be a vulnerability here, but I thought that we weren’t going to worry about security because there is no critical data in this system. Risk manager: Let’s get the person in charge of the data to tell us how critical the data is. (Identify the assets.) Senior manager: Yes, this data is completely critical. If it gets leaked, our competition will beat us to market and if it gets deleted, we will lose months of work. Risk manager: The software is operated completely inside the firewall, do you ever get advanced attacks that get inside? (Identify the threats against those assets.) Security team: No, that never happens, but legal requirements say that insiders should not be allowed to modify the data, even if they can access it. Risk manager: Can any of the vulnerabilities be exploited from outside the firewall? (Discover the vulnerabilities.) Security team: No, you have to be on the internal network. Risk manager: Can any of the vulnerabilities be used by an insider to modify the data? (Discover the vulnerabilities.) Security team: Yes, one of the vulnerabilities can be used to modify data if the attacker is already on the internal network. Risk manager: Let’s look at the budget and estimate how many of these vulnerabilities we can fix, prioritizing the ones that can be used to modify data. (Implement countermeasures.) Getting back to the incident that started this discussion , if you read the thread carefully you’ll find that the developer has a particular point of view about the assets (that local root exploits on a single-user machine aren’t a critical problem) but that the entire conversation has been about vulnerabilities , exploits , and mitigations . If the security folks had been able to act as “risk managers” and surfaced this misunderstanding early on, they could have potentially gotten the developer on their side by explaining the less-obvious threats related to local root exploits. In the end, the security guys just kept posting exploits until they felt too bored and insulted to bother anymore. The developer unhappily disabled the component that he felt had been hugely useful for his users since he didn’t think it could be salvaged. Maybe this was inevitable, but maybe a better outcome for everyone could have been discovered.", "date": "2011-11-17"},
{"website": "Galois", "title": "Heartbleed: A great time to think about incident response", "author": "Unknown", "link": "https://galois.com/blog/2014/04/heartbleed-a-great-time-to-think-about-incident-response/", "abstract": "Heartbleed is the nickname of a dangerous OpenSSL vulnerability that was just announced. A security update was already available before the announcement, and this is definitely a vulnerability where quickly patching makes a big difference. A fast response matters here because malware wasn’t in the wild yet, so many sites likely can prevent any negative consequences with quick action. The necessity for rapid response to vulnerabilities illustrates why you should have an incident response procedure in place. An incident response procedure allows for a measured, planned response to a security incident like this one. In this blog post, we’ll walk you through the basics of putting together an incident response plan, mostly based on NIST’s incident response process . What is a security incident and what should I do to plan for it? A security incident is any “violation or imminent threat of violation of computer security policies, acceptable use policies, or standard security practices.” This might include attacks from the outside or inappropriate use internally. Every organization should have a definition of what types of events they consider to be security incidents and how they respond to and report different kinds of incidents. Heartbleed should be considered an incident because it’s an imminent threat, although not necessarily a violation yet. If you have an incident response procedure in place, you probably already know if you are affected by Heartbleed and have possibly addressed the incident. Without a procedure in place, you might just be reading news reports and wondering if you should care. The difference in these two responses will have a huge impact on whether sensitive information gets leaked and how long it will take to address Heartbleed. More generally, without an incident response procedure, administrators make preventable mistakes in handling or reporting an incident. The development of an incident response procedure is a security best practice according to both SANS’ top 20 list of recommended security controls , and NIST 800-53 , which recommends incident response (IR-4) for even “low impact” security environments. Here’s the basic approach: preparation, detection and analysis, containment, eradication, recovery, and recording lessons learned. SANS suggests that there is a set of quick wins that will help immensely: develop a set of written procedures, including personnel roles; who should report incidents; when they should report them; what information they should provide; and how users are to be trained. Communication with the media can be crucial for high-profile incidents. Preparation: Establish the incident response capability in the first place, open the lines of communication to the relevant people inside and outside your organization, and have the correct tools in place, e.g., forensic hardware and software. Most importantly, know who is accountable for watching for incidents and responding to them. With Heartbleed, many administrators were able to patch it before most people had even heard about it. Detection and analysis: This step involves discovering the type of incident (in this case, a serious vulnerability in critical software). Are you vulnerable? Do you operate an OpenSSL server? An Intrusion Detection System can often help, but in this case it’s all about monitoring vulnerability announcements and knowing your infrastructure. Logging is also important for analysis, so maintaining good logs is important. This step includes documenting the incident as you analyze it, and notifying the appropriate parties. Notification is extremely important since other organizations that you collaborate with might also need to handle the incident in their environments. For instance, if your users’ passwords or clients’ private data were disclosed, what steps should they take? Containment, eradication, and recovery: Containment is about stopping the spread of the incident, whether through privilege escalation or the spread of a virus. For Heartbleed, containment is everything. The longer your systems remain vulnerable, the more likely it is that someone will get around to extracting sensitive information from them. This is a case where, after patching the server, you should go back to the “analysis” step. If an attacker did get into the system, what might they have gotten? If they extracted the server’s private key, what could they do with it? Is there any evidence that someone used privileges from this system to get into another system? This step often includes forensics, i.e., gathering information without damaging evidence. Eradication and recovery sometimes involve restoring systems from a known, good backup. Post-incident activity: This step involves analyzing lessons learned and cause analysis. Was your team’s response effective? Could it have been better? What new processes should be put in place? Retaining evidence for potential legal activity is also important. Recording the process you followed also helps when your users, clients, or the media have questions later about how you handled the incident. Benefits of having an incident response plan Again, the detailed documentation from NIST helps to clarify why incident response is important: quicker containment and recovery from attacks, better preparation for future attacks, and dealing with legal issues that can arise. Besides the positive benefits, it can be required by law in some circumstances. It helps to make sure the appropriate steps are taken – e.g., patching quickly, making sure that the attacker doesn’t gain access to other parts of the system, making sure critical servers don’t get taken offline. Without a plan in place, administrators might fail to contain the damage, fail to collect forensic information, and even fail to stop the attack. It helps to recover quickly so that disruption and loss is minimized. For Internet retailers, every hour of downtime costs money. For some organizations, every hour lost can damage their mission. It helps in learning; incidents should be examined and procedures modified so that the handling of future incidents is improved. It helps to deal with the legal issues that arise; it provides steps for collecting appropriate information before the logs are destroyed. Team considerations People are everything, and each organization is different. Think through these questions for your organization: How centralized should your incident response team be? How should the team communicate with other parties? Should it be made up of employees or include external parties? Is 24/7 response necessary? NIST also emphasizes providing the team with learning and growth opportunity through training. Conclusion Heartbleed is a very serious security incident, and it’s likely that your team needs to handle it immediately. Once the dust has settled, take some time to put a security incident response plan in place. It’s a stitch in time that will save nine. Contact us if you’d like some help. About Galois Galois’ mission is to ensure trustworthiness in critical systems. Security incident response helps address today’s problem, risk management helps address tomorrow’s problems. Our goal is that some day, critical systems can be built with powerful tools to completely eliminate the root causes of many vulnerabilities.", "date": "2014-04-09"},
{"website": "Galois", "title": "Galois Announces ISC: The Imperfect Stitch Compiler", "author": "Unknown", "link": "https://galois.com/blog/2016/04/galois-announces-isc-the-imperfect-stitch-compiler/", "abstract": "This was an April Fool’s post published on April 1, 2016. The Imperfect Stitch Compiler is a fictional product. Galois is known for building perfect software. But is our software too perfect? The imperfect stitch , or Persian flaw, is a deliberate error in an otherwise perfect work of art. The term derives from the proverb, “a Persian rug is perfectly imperfect, and precisely imprecise.” It signifies the inherent humanity and imperfection of the artist. Nowadays, the term is used more generally; for example, Captain Jean Luc Picard’s Persian flaw is his inability to “sit down, shut up, and wait.” With tools like Cryptol , SAW , and Copilot , Galois produces formally verified software day after day. So, we asked ourselves, does this perfection strip our engineers of their artistic creativity? Are our code and proofs void of the human touch? Not any longer. Today, we are pleased to announce ISC, the Imperfect Stitch Compiler. ISC is the latest of Galois’s innovations. Based on a collection of the developer’s personality traits along more than 20 dimensions, ISC introduces a subtle and unique bug in a software verification and implementation. The verification bug is made less obvious by innovative techniques such as slightly modifying the formal specification to differ from reality or adding antecedents until the precondition evaluates to false. “ISC is very subtle,” commented one Galois engineer. “One bug took me over week to fix after accidentally enabling ISC during a test build.” ISC has gone live, and interacts seamlessly with a variety of programming languages (including Haskell, ML, and Python) and verification engines (including SMT solvers, Coq, and Isabelle). At the time of writing, we have not developed a C interface, since nobody has ever written a bug-free C program in the first place. Some quotes from our satisfied customers: “I love guaranteed correct software, but it always felt so impersonal: it’s proven to always do one thing, and it’s the same for everyone! With my ISC-generated software, I know I have a unique, one-of-a-kind showpiece.” “I’ve had a 20-year career in software testing. When our company started working with Galois, my job was on the line. Fortunately, with ISC, I can chase after that last, elusive bug. Thanks!” “One word: authentic. When I started using Galois DSLs, my bug-free demos looked totally fake.  With ISC we get those necessary hiccups that prove the authenticity of the work.” “My ISC program works perfectly! Except for every once in a while… but then I just turn it off and back on again.” Galois expects to release ISC from private beta on April 1, 2017.", "date": "2016-04-01"},
{"website": "Galois", "title": "Revolution and Evolution: Fully Homomorphic Encryption", "author": "Unknown", "link": "https://galois.com/blog/2017/12/revolution-evolution-fully-homomorphic-encryption/", "abstract": "This article originally appeared in the Summer 2017 edition of the U.S. Cybersecurity Magazine More and more computation is being outsourced to public clouds such as Amazon’s GovCloud and Elastic Compute Cloud, RackSpace, and others. It’s the new “gig” economy for computer hardware. These cloud computers can be just as vulnerable as any other computer, putting the privacy of sensitive data at risk. As nation-state cyber weapons become increasingly available to amateur and low-level professional cyber criminals, the external threats against those cloud-based systems continue to grow. In addition, clouds are controlled by vendors who have intimate access to those machines, creating an insider threat that presents an even greater risk to privacy. But why is privacy at risk here? Surely we’re all smart enough to encrypt our data while it’s on the move into and out of cloud-based systems. TLS, among other protocols, takes care of that for us (if we remember to use it). And surely – surely – we’re all smart enough to keep our data encrypted while at rest on these untrusted cloud servers. Right? Right? Is this microphone working? Even if we take care of both of those concerns, there’s still one unprotected attack surface: we must decrypt that data in order to compute on it, and the results of our computations still appear “in the clear” until we encrypt them. So even on our best day, privacy is at risk whenever we use the data we send to the cloud. Could we compute on our data in the cloud while it remains encrypted? That notion sounds like science fiction. How can data that by definition is obscured to look like white noise be used for any kind of computation? Until recently, there was no good answer to that question. However, in the past few years the advent of practical homomorphic encryption (HE) and a competing technology, secure multi-party computation , promises a solution. HE carries out computation on encrypted inputs, keeps internal variables private even from observers who can look inside the running program, and produces encrypted outputs accessible only to a user who holds the right cryptographic key. HE provides security guarantees that are cryptographically as sound (and based on some of the same hard mathematical problems) as more familiar cryptography such as the block ciphers that protect our data at rest and the public key constructions that enables security in transit. What can the cryptography community demonstrate with HE today? Voice-over-IP communications at streaming rates that don’t require a trusted central server because voice streams are never decrypted except at the receiver’s phone 1 . Checking encrypted files for the presence of selected strings without decrypting them. Facial recognition where facial images remain encrypted throughout the process 2 . Analytics such as linear regression on encrypted data. Fast written character recognition 3 with encrypted input images. Some of these prototypes are quite fast, some very slow. Simpler programs tend to perform better, but not always. How does this seemingly magical technology work? Like all computation, it begins with a program to run and a set of choices about how secure we need the inputs, variables, and outputs of that program to be. But not every program can be transformed using HE, because such transformation requires that the program first be turned into a circuit : a collection of interconnected logic (think AND or NOT) or arithmetic (think addition and multiplication) gates. We’ll avoid descending into Galois Field theory, but it’s enough to say that these circuits are either Boolean , where all values are either 0 or 1, or they are arithmetic , where values are integers. We can use those Boolean or arithmetic fields to represent many kinds of data: strings, bit vectors, integers, fixed-point numbers, and with extra work, floating-point numbers. Many simple program statements are easy to transform into such circuits. However, things get problematic when control flow in our program is data-dependent — that is, when program flow such as loops or other conditional statements depend on the value of variables in the program rather than constants. So, although many programs and data types can be represented in HE, there are some limits. Once we have a program that we can transform into a suitable circuit, we need to encrypt the input data for the circuit. HE works because of a mathematical property called homomorphism . Roughly speaking, a homomorphism is a mapping where each element in one domain corresponds to an element in another, the same mathematical operations (addition and multiplication in our case) apply in each, and the results of those operations carry back and forth between them. Encrypting in HE is the process of mapping one domain, such as 32-bit integers, into another domain, such as integers in a very large prime modulus, in a way that preserves this homomorphism. The figure below shows how HE works. First, the owner of the sensitive data generates a key pair consisting of a public and a private key. Second, the owner (or a trusted repository of the sensitive data) uses the public key to encrypt the data, mapping it to the new domain. Third, an untrusted computer takes the encrypted data (which it cannot decrypt because it doesn’t get the private key) and computes the intended program on it. Fourth, the encrypted result of that computation is decrypted by whoever holds the private key. The encryptions used for HE introduce one notable problem that explains part of the performance cost of HE: each operation in the embedded domain introduces “noise”. As information flows through each gate in our HE circuit, that noise builds up, and at some point we lose the ability to decrypt an output back into a valid plaintext. This problem originally prevented homomorphic encryption from being more than a theoretical exercise. Today, we use two approaches to prevent noise from growing too large: leveled HE schemes that can accommodate deep circuits if properly configured in advance; and bootstrapping , a process that resets noise without losing privacy. These tools give us a new capability: fully homomorphic encryption (FHE) that is usable on circuits of any depth, limited only by the user’s patience. If FHE is so well understood, why isn’t it in broad use today? In addition to the limitations on the kinds of programs that can be transformed into circuits suitable for FHE, there are two significant limitations on FHE: user patience (by which I mean performance), and ciphertext expansion. I’ll employ here the standard automotive caution: your mileage may vary. Intuition about what makes computing slow in plaintext often offers little insight into performance in the FHE domain. However, broadly speaking, when we do math in very large fields it takes longer. In addition, it takes time to encrypt inputs into those fields, and it takes time to bootstrap when noise grows too large. Thus FHE computations can take a long time relative to their plaintext counterparts. In 2011, long time meant that such computations were either impossible, or might take up to 12 orders of magnitude as long as computing in the clear. Today, long time might mean from as little as 1000 to as much as a million times longer than computing “in the clear” – and things continue to improve. In addition to performance concerns, the encryption of data from the natural fields we compute on, such as 32-bit or 64-bit integers, into the fields used in FHE causes significant expansion : resulting ciphertexts ended up much larger than their associated plaintext. A few years ago, that expansion was typically a factor of thousands. More recently, expansion factors are closer to one order of magnitude: not trivial, but much improved. I lied in the previous paragraph. There’s one more important limitation to broad use of FHE: making it easy to use. As you might expect, the needs to transform programs into circuits, carefully configure FHE computations, manage encryption and decryption, and other complexities make programming FHE applications the domain of a small number of expert researchers. To bring FHE into practical use, we need to integrate FHE capabilities as seamlessly as possible into existing programming environments; allow for programmers to write in the same languages to express both normal and FHE computation; automate the tedious process of converting programs into efficient circuits; make selection of the many necessary configuration parameters simple for non-experts; and transparently handle the encryption and decryption process so that from the programmer’s perspective, calling FHE-protected functions is no different from calling normal code. For the past nine months, a joint team from Galois, Inc. and the New Jersey Institute of Technology has been researching ways to address these needs. This work, sponsored by the Intelligence Advanced Research Projects Agency (IARPA), aims to pioneer new methods in FHE ease of use and lay the groundwork for substantial further improvement. To provide seamless integration, our team built FHE capabilities into the Julia scientific programming language. To enable ease of programming, we taught the Julia compiler to generate FHE code from normal Julia functions as programmers typically write them (with a few small additions in syntax). To automate the circuit conversion process, we integrated Galois tools that use symbolic execution to automatically transform the actions of a program on variables into formulas for those variables that are then automatically expressed as circuits for FHE. We added behind-the-scenes support to handle encryption, FHE computation in the cloud, and decryption of returned results so that using FHE functions is as easy as using other Julia functions. Supporting this “front end” work was a high-value “back end”: the creation of a large, full-featured library of FHE primitives that the compiler suite calls to provide the complex mathematics needed for program execution. Recent demonstrations of RAMPARTS results at JuliaCon and to government sponsors show how far we’ve come, and our work continues today. Still, there’s much more to do, and our project just scratches the surface. We need standardization of library interfaces and configuration settings so that FHE can leverage the combined efforts of many library developers. We need further work in FHE cryptographic theory to reduce ciphertext expansion and improve performance. And among other things, we need to develop practical examples of applications that show how FHE can be effective and efficient in enabling secure computation on real-world problems. The need for privacy is evident anywhere that computing on sensitive data is outsourced to untrusted computers like those in modern clouds. The risk of losing that privacy continues to grow as cyber threats grow both more numerous and more sophisticated. Even on our best day, we still expose data to those threats at least long enough to compute on it — too long to avoid compromise. FHE offers one way to secure that privacy by computing on data while it remains encrypted. There’s still some way to go before FHE can be ubiquitous: we need better performance and a significant focus on ease of use. But then every gig economy is driven by new technology. Hey, can you give me a Lyft to my AirBnB? And do you take Bitcoin? Footnotes 1 Archer, David W., and Kurt Rohloff. “Computing with data privacy: Steps toward realization.” IEEE Security & Privacy 13, no. 1 (2015): 22-29. 2 Troncoso-Pastoriza, J.R., González-Jiménez, D. and Pérez-González, F., 2013. Fully private noninteractive face verification. IEEE Transactions on Information Forensics and Security, 8(7), pp.1101-1114. 3 Nathan Dowlin, Ran Gilad-Bachrach, Kim Laine, Kristin Lauter, Michael Naehrig, and John Wernsing. 2016. CryptoNets: applying neural networks to encrypted data with high throughput and accuracy. In Proceedings of the 33rd International Conference on International Conference on Machine Learning – Volume 48 (ICML’16), Maria Florina Balcan and Kilian Q. Weinberger (Eds.), Vol. 48. JMLR.org 201-210.", "date": "2017-12-19"},
{"website": "Galois", "title": "Formal Methods and the KRACK Vulnerability", "author": "Unknown", "link": "https://galois.com/blog/2017/10/formal-methods-krack-vulnerability/", "abstract": "On Monday, the KRACK vulnerability to WPA2 was revealed in a paper by Mathy Vanhoef and Frank Piessens. KRACK enables a range of attacks against the protocol, resulting in a total loss of the privacy that the protocol attempts to guarantee. For more technical details on the attack, the website and the Key Reinstallation Attacks (KRA) paper are the best place to look. The paper presents the problem clearly, and you will learn about a protocol that you use constantly. Furthermore, it presents a number of compelling attacks that show exactly how big of a problem KRACK is. This post will discuss what the KRACK paper has to teach us about formal methods and cryptography standards. It’s a little surprising that a protocol as widely used as WPA2 still harbors critical vulnerabilities. Even more surprising is that portions of the protocol have been formally verified (mathematically proved) to be secure! Why don’t these factors guarantee that the protocol is free of such critical vulnerabilities? The KRA paper raises the following concerns about standards and formal verification. These provide us with valuable insight into pitfalls to avoid as we perform and present our work: Specifications for a protocol may not be precise enough to guarantee security. Real-world implementations may not match formal specifications used in proofs. Formal proofs might lead to complacency, discouraging future audits and inspections. At Galois, we believe strongly in the value of formal verification, so we think it’s worth examining each of these points. In doing so, we gain some insights into real-world cryptography verification. Concern: Specifications may not be precise enough It is impossible to test for security. Security is a property of all possible behaviors of a system, so the time to get security right is when the system is defined. KRACK is a vulnerability in the specification of the WPA2 protocol, and it is exacerbated in some cases by decisions that implementors made in the face of an ambiguous specification. Any of these decisions allow the implementations to function correctly. After all, we’ve been successfully utilizing WPA2 for a long time without noticing any significant functionality shortcomings. In the face of the KRACK vulnerability, however, these ambiguities allow for significantly more damaging attacks. We can ensure that specifications are unambiguous by making them more formal. Often, ambiguity hides in natural language specifications in ways that are difficult to understand until the specifications are represented formally. A formal specification serves as an intermediate point between the easily ingestible natural language specifications we typically see today and the more complicated implementations. A successful specification language for Cryptography allows the cryptographic community to express themselves precisely. The specifications should be readable by mathematicians and software engineers alike. They should allow natural language specification to sit side-by-side with code that looks almost exactly like the mathematics that occurs in the research literature, RFCs, and standards. Examples of language that can be used for Cryptography specification include our own Cryptol language, F* (as used in miTLS ), Coq (In particular the FCF library and Fiat ). All of these are open-source tools that are free for use by anyone. For an example of how implementation and natural language specifications can coexist, see our ChaCha20 specification . That file can be both compiled to an attractive PDF for printing and reading as well as typechecked and executed by Cryptol. This is a “best of both worlds” combination of readability and rigor. Of course, rigorous specifications are only useful if they are available for inspection by the scientific community. IEEE’s policy of putting standards behind a paywall discourages scientists from examining and reasoning about those standards. Matt Green does an excellent job of explaining this in his blog post on the topic. Concern: Real-world Implementations might not match specifications This concern is absolutely correct. There is not much value in proving specifications correct if the specifications don’t reflect the reality of implementations. The technologies to match protocol specifications to implementations are becoming more usable (and more widely used) every day. We call such proofs end-to-end proofs, as they carry properties all the way from high level security proofs down to source code, even in challenging languages such as C. Examples of these techniques in the cryptography world include recent work using Coq and VST to verify HMAC and DRBG , the code-generation approach of Project Everest , and our own efforts to verify parts of s2n . The KRA paper, however, is really concerned that the models used in proofs don’t fully match the specification. Of course, this also implies that the models in proofs won’t match implementations, but implementations are not needed to discover this. Matching proofs to specifications is a challenging problem because it requires a mapping between imprecise, natural language protocol specifications, and models that are typically created with a certain property in mind. But the models used for previous proofs of WPA2 match the specification (as far as we know today.) The discovery of KRACK doesn’t invalidate either of the original security proofs, because those proofs don’t cover the behavior where KRACK appears. This is not an oversight, it is intentional. Every security proof is part of a larger security picture. The authors of the KRA paper were able to understand what the proofs were about, and why they don’t cover the KRACK vulnerability. Even though the original proofs didn’t reveal security flaws, a principled approach would use these proofs in order to discover where to look. Imagine software as an adhesive sheet with bubbles (bugs or vulnerabilities) under it. Your goal is to get the bubbles out without ever looking at the sheet. You could either start from a good location and methodically work the bubbles out, or you could poke at the sheet randomly until you hit some bubbles. Now try to do the same exercise with a team. Each team member gets to work for 5 minutes in succession, only providing the next member with a description of the work already done. If you smooth an entire area, you can tell the next person “The bottom left 5 square inches are clear, ignore them”. If you’ve poked around you will have a much harder time explaining what you’ve done. Formal proofs of software and protocols are analogous to the smoothing approach. They provide well defined areas that are completely free of a certain class of problem. In the case of WPA2, the formal proofs didn’t reveal any problems, but other formal approaches have been much more successful. For example, the miTLS project used formal methods to discover many of the recent high-profile vulnerabilities in TLS implementations. He and Mitchell discovered a problem in an early version of WPA2 that resulted in an improvement to the specification. This paper is cited as related work in the KRACK paper. A key to making this all work is the description of the work done. While the formal proofs carry rigorous definitions, they can be very difficult to understand. Like software and protocol specifications, theorem statements must combine rigor and readability. Concern: Formal proofs might lead to complacency Looking back at the adhesive smoothing example, formal proofs should discourage future work. If the verification is presented correctly, it should not induce complacency. Improper representation of verification, however, can be a serious problem. The value of formal methods as opposed to more manual techniques is that once they are done they discourage work in clear and well defined areas. For this to work, however, proof presentation must be clear and precise. If readers come away thinking a proof is even a little more broad than it is in reality, that opens up space for bugs and vulnerabilities to hide. This is a risk that is all too tempting for formal methods researchers to take. When we complete our proofs, we know what we have proved, and we fear that it won’t be interesting to others. To sell our work we then make grand statements in our abstracts and introductions. Statements such as “we have proved this protocol secure”. Statements that will be held up as evidence of the inefficacy of formal methods when a vulnerability is found in the protocol we verified. We must be as clear in our documentation and publications as we are in our theorem statements. In the words of Edsger Dijkstra, “… we take the position that it is not only the programmer’s responsibility to produce a correct program but also to demonstrate its correctness in a convincing manner, …”. Formal methods are a tool that can be used to guide everyone, from other verification experts to engineers looking to write test libraries. When formal methods are explainable and accessible to the security research community at large, the authors of the next security vulnerability paper can brag that they were guided by previous formal proofs about the system, instead of trumpeting that they found a vulnerability in spite of them. This post was written with input from Brent Carmer, Thomas DuBuisson, Mike Dodds, Stephen Magill, Alex Malozemoff, Shpat Morina, Kevin Quick, Aaron Tomb, and Dan Zimmerman.", "date": "2017-10-19"},
{"website": "Galois", "title": "SIMON and SPECK in Cryptol", "author": "Unknown", "link": "https://galois.com/blog/2013/06/simon-and-speck-in-cryptol/", "abstract": "Last week, the NSA published two families of lightweight block ciphers, SIMON and SPECK : http://eprint.iacr.org/2013/404 We’ve formally specified both ciphers in Cryptol: https://github.com/GaloisInc/cryptol/blob/master/examples/contrib/simon.cry https://github.com/GaloisInc/cryptol/blob/master/examples/contrib/speck.cry The following sections explore some applications of our specifications. Parameters SIMON and SPECK are cipher families : each algorithm in the family offers different security and performance based on parameters such as block size, key size, and number of rounds. In Cryptol, we can use type variables to represent these parameters. For example, consider the type signature of SIMON’s encrypt function: encrypt : {n m T j} (...) => [m][n] -> ([n], [n]) -> ([n], [n]); Each type variable corresponds to a parameter in the cipher: n is the word size (the block size is 2n ) m is the number of key words T is the number of rounds j specifies which round constant to use The encrypt function can be instantiated with almost any values for its parameters (subject to some constraints not shown here). This gives us an elegant way to construct the variants of SIMON: Simon32_64  = encrypt `{n=16, m=4, T=32, j=0};\r\nSimon48_72  = encrypt `{n=24, m=3, T=36, j=0};\r\nSimon48_96  = encrypt `{n=24, m=4, T=36, j=1};\r\nSimon64_96  = encrypt `{n=32, m=3, T=42, j=2};\r\nSimon64_128 = encrypt `{n=32, m=4, T=44, j=3};\r\n... We can also experiment with stronger or weaker variants of the cipher: simon> :let weakSimon = encrypt `{n=8, m=4, T=16, j=0}\r\nsimon> :type weakSimon\r\nweakSimon : [4][8] -> ([8],[8]) -> ([8],[8]) Verification An important property of block ciphers is that decryption is the inverse operation of encryption. We can state this property in Cryptol for the Speck64_96 encryption function (and its corresponding Speck64_96' decryption function) as follows: theorem correctSpeck64_96: {k b}. Speck64_96' k (Speck64_96 k b) == b; The theorem is universally quantified over all keys k and all blocks b . We can use Cryptol’s :check command to test whether the theorem holds for several randomly generated inputs: speck> :check correctSpeck64_96\r\nChecking case 1000 of 1000 (100.00%)\r\n1000 tests passed OK\r\n[Coverage: 0.00%. (1000/1461501637330902918203684832716283019655932542976)] However this did not give us good coverage of the state space. Instead, we can use Cryptol’s :prove command to show the theorem holds for every possible input: speck> :prove correctSpeck64_96\r\nQ.E.D. Cryptol proves the theorem by asking a SAT solver whether the negation of the theorem is satisfiable. If the negation is satisfiable, Cryptol returns the satisfying assignment as a counterexample to the theorem. In this case, the SAT solver says the negation is unsatisfiable so the theorem holds. The proof completes in less than 30 seconds!", "date": "2013-06-24"},
{"website": "Galois", "title": "Part three: Proving Program Equivalence with SAW", "author": "Unknown", "link": "https://galois.com/blog/2016/09/proving-program-equivalence-with-saw/", "abstract": "This is the third in a series of three blog posts detailing the use of SAW and Cryptol to prove the correctness of the HMAC implementation in Amazon’s s2n TLS library. Part one: Verifying s2n HMAC with SAW . Part two: Specifying HMAC in Cryptol . In the second post , we left off with the Cryptol specification for HMAC. That’s all well and good, but to bring back an example from last post, knowing that a tiger is a large orange and black cat doesn’t do you very much good if you can’t see.  In this post, we will discuss how we recognize that a program is actually described by a Cryptol specification. We will perform this recognition using the Software Analysis Workbench (SAW). SAW uses a language called SAW Script to help guide automated proofs between two programs. It helps you do things like set up mappings between corresponding elements of the two programs. For example if we had the following two tiger-recognition programs global boolean hasStripes;\r\nisTiger(Animal animalType, Color\r\n        animalColor){\r\n  return (hasStripes\r\n         && animalType == Cat\r\n         && animalColor == Orange)\r\n} \r\n\r\nnotTiger(String type, String the_color,\r\n         boolean striped){\r\n if (type == “cat”\r\n     && the_color == “orange”\r\n     && striped)\r\n then\r\n  return “It’s a tiger. Do not hunt”\r\n else\r\n  return “Not a tiger, you’re on your own”\r\n} We would use SAW Script to tell SAW that we wish to show that the results of isTiger and notTiger are the same assuming that hasStripes is the same as striped . We will also need to specify some correspondence between the other inputs, and specify that a result of true from isTiger corresponds to a result of “It’s a tiger. Do not hunt” from notTiger . This means that the SAW Script is actually part of the specification. Without understanding the SAW Script you can’t be sure that SAW is actually verifying the correct thing. Equivalence between high and low level Cryptol Last post we asserted that is easier to do proofs between two Cryptol specifications than it is to do a proof between a Cryptol specification and a C code. To warm up, we’ll start with the easy one. To prove equivalence between the high and low level Cryptol specs we run: $ saw hmac_imp_correct.saw On a file containing: import \"spec/HMAC.cry\";\r\n \r\nlet check n = do {\r\n   print (str_concat \"Checking 'hmac_c_state_correct' for byte count \" (show n));\r\n   time (prove_print abc {{ hmac_c_state_correct : HMAC_c_state -> [n][8] -> [n][8] -> Bit }});\r\n};\r\n \r\nfor [0, 1, 2, 63, 64, 65, 127, 128, 129 , 1000] check; Where HMAC.cry contains a property definition: hmac_c_state_correct : { key_size, msg_size }\r\n            ( 32 >= width msg_size, 64 >= width (8 * key_size) )\r\n           => HMAC_c_state -> [key_size][8] -> [msg_size][8] -> Bit\r\nproperty hmac_c_state_correct st0 key msg =\r\nhmacSHA256 key msg == hmac_c_state st0 key msg Which states that the results of running the high and low level specifications on the same specs are equivalent. Then we wait a while and each time SAW prints out “verified” telling us that the property has been proved at the sizes specified. SAW can not yet do polymorphic proofs. That means that before proving a property we must instantiate all of the type variables to specific values and then the proof is done at those values. Remember your homework from last time? We’ll wait right here if you want to update your answer. Proving C correct with respect to Cryptol Now for the hard part. We want to prove the C implementation correct with respect to our low-level Cryptol specification. First we load in our two files: import \"HMAC.cry\";\r\nm <- llvm_load_module \"../bitcode/all_llvm.bc\"; Let’s talk about LLVM Notice that we are loading in LLVM bitcode, not the C code. There is an important implication here. Information is lost in the compilation from C to LLVM. Some of this information is more important than other. The important kind of information that is lost is about undefined behavior in C. The definition of undefined behavior is good for compiler writers because it gives them license to simply not worry about what their compiler does in certain cases. For example, a valid C compiler could take the expression: x=1/0 And compile it into LLVM that does nothing to the value of x and as a side effect calls you a rude name in stdout. Because SAW is only aware of the LLVM, it won’t be aware that we are trying to prove something about a program that we can’t even reason about (because of undefined behavior). Instead, SAW will just see a program strongly suggests that the user not go to a zoo lest their odor frightens the animals. In the general case, this implies that to gain the highest assurance from a SAW proof, a compilation must be done through LLVM by the same compiler that compiled the bitcode used for the proof. Even better, the bitcode used for the proof could be used directly to create the executable. This is the case unless you can separately verify that there is no undefined behavior in the C program. Amazon has done this, and they discuss it here . In this case, it is reasonable to expect that your compiler of choice will produce programs that do the same thing as a different compiler that uses LLVM. There is less challenging loss of information in the form of source information that is translated into a more readily machine-readable form. The example of this that we run into in our verification is that record names are transformed into record indices between C and LLVM. That means that our SAW Script doesn’t get to mention record names, and instead references record indices. Fortunately, in this case we can mostly use a function to encapsulate our use of these indices. We created a function to initialize a Cryptol record with the values in the LLVM struct: let setup_initial_hash_state prefix = do {\r\n   // Make struct path using 'prefix'.\r\n   let p before after = str_concat before (str_concat prefix after);\r\n \r\n   alg0 <- llvm_var (p \"\" \"0\") (llvm_int 32);\r\n \r\n   hash_ctx0_h     <- llvm_var (p \"((\" \"1).0).0\") (llvm_array 8 (llvm_int 64));\r\n   hash_ctx0_Nl     <- llvm_var (p \"((\" \"1).0).1\") (llvm_int 64);\r\n   …\r\n \r\n     let st0 = {{\r\n     { h     = hash_ctx0_h\r\n     , Nl     = hash_ctx0_Nl\r\n     …\r\n       } : SHA512_c_state\r\n   }};\r\n \r\n   return (alg0, st0);\r\n} We define a similar function check_final_hash_state that allows us to compare a LLVM hash state to a Cryptol record. We also create the analogous functions for the HMAC state. This is a limitation that we believe can be fixed by including debug information in the bitcode along with some engineering work on SAW, but for now it slightly affects the readability of our proof scripts. It can also lead to a challenge in counter-examples, when the index paths are printed instead of the name paths. It is easy enough to reverse engineer them, but it is an additional step in the debugging process. Specifying HMAC update Now that we understand the implications of proving things about LLVM (and why the important one doesn’t really matter for this case), and we’ve encapsulated the ugliness that currently comes with verifying LLVM, we can get back to business. We will start by creating a specification for the HMAC_update function, starting with the definition : let hmac_update_spec\r\n     msg_size\r\n     (cfg : { name            : String\r\n            , hmac_alg        : Term\r\n            , digest_size     : Int\r\n            , block_size      : Int\r\n            , hash_block_size : Int\r\n            }) = do { The arguments to this specification are the size of a message and an array that defines all of the variables that vary depending on the hash function. This allows us to easily use this specification to verify HMAC with any of the s2n hash functions. First we need to allocate the symbolic variable that corresponds to the llvm function parameter in . We do this with the SAW function llvm_pointer . Next we use the setup_initial_hmac_state which allocates an entire symbolic HMAC state and returns a record containing all of the fields of that state. We then load the initial value of in into variable in0 and do the same with size and size0 to complete our initialization of the state. llvm_ptr \"in\" (llvm_array msg_size (llvm_int 8));\r\n   st0 <- setup_initial_hmac_state;\r\n   in0 <- llvm_var \"*in\" (llvm_array msg_size (llvm_int 8));\r\n   size0 <- llvm_var \"size\" (llvm_int 32); Now we perform a number of assertions using the llvm_assert_eq function which takes a LLVM variable name as its first argument and a Cryptol expression as the second. You can think of this function as defining an equality as a precondition. That means that the verification of this function will get to assume that these equalities hold, and in order to use this function you must be able to prove these equalities. In this case, we are asserting that the HMAC state matches the HMAC configuration that was supplied to the specification. llvm_assert_eq \"state->0\" cfg.hmac_alg;\r\n \r\n   let hash_block_size = cfg.hash_block_size;\r\n   llvm_assert_eq \"state->1\" {{ `hash_block_size : [16] }};\r\n   let block_size = cfg.block_size;\r\n   llvm_assert_eq \"state->3\" {{ `block_size : [16] }};\r\n   let digest_size = cfg.digest_size;\r\n   llvm_assert_eq \"state->4\" {{ `digest_size : [8] }};\r\n   llvm_assert_eq \"size\" {{ `msg_size : [32] }}; Now we call our Cryptol implementation of HMAC update and store the result in variable st1. let st1 = {{ hmac_update_c_state st0 in0 }}; Finally we check the results of the function. We have two results that we need to check. First we use check_final_hmac_state st1 which is a function we defined to check if the struct at LLVM variable state is equal to its argument. In this case the argument is st1 that we created by calling the Cryptol function. We also need to be sure that the C function returned without errors, and we do that using llvm_return check_final_hmac_state st1;\r\n   llvm_return {{ 0 : [32] }}; We now set options that determine how the specification will be verified. These are not run at the time of this definition, but rather when we try to prove that a C function meets this spec, SAW will use the tactic contained in the specification to perform the verification. First we set an option that is for performance only (not correctness related). llvm_sat_branches true says that at every branch (including loops) the solver should check if both branches are feasible before entering them. In cases where all branches are always feasible, it is better to leave this option false because it will result in unnecessary calls to the solver. In cases where a branch might be eliminated, leaving this option true can save SAW from examining branches that are irrelevant. Finally, we describe what prover we will use. In this case we will use Z3, but when we come across the Cryptol functions hash_init_c_state etc. we will not unfold their definitions. Instead we will treat them as opaque uninterpreted functions. All we know about them is that when called on the same arguments, they will give the same result. llvm_sat_branches true;\r\n   llvm_verify_tactic do {\r\n       unint_z3 [ \"hash_init_c_state\"\r\n                 , \"hash_update_c_state\"\r\n                 , \"hash_digest_c_state\"\r\n                 ];\r\n   }; The Cryptol with uninterpreted functions matches with the C code, because we also write SAW specifications stating that the hash functions are equivalent to the Cryptol functions. These specifications look much like the one that you just saw, but for the tactic we give llvm_no_simulate; This tactic means that when we try to verify a C function with respect to the spec, SAW won’t try to do any work, it will just trust that the specification is correct. We are alright with doing this for two reasons We can always check them against the specification later, and nothing we could verify about a hash would be of much interest to HMAC anyways. Running the verification Once we have specified all of the functions we wish to verify, we can tell SAW what we would actually like to verify. In order to verify the HMAC update specification we just defined we add the following statement hmac_update_ov <-\r\n   llvm_verify m \"s2n_hmac_update\" hash_ovs (hmac_update_spec msg_size cfg); The llvm_verify function takes a llvm module m which we loaded at the very beginning, a LLVM function to verify ”s2n_hmac_update” a list of overrides , or specifications that we will use in place of their respective llvm functions when we come across a call to that function. In the statement above, we have already rolled all of the hash specifications together into a list called hash_ovs . We also give the specification that we are verifying with respect to. The llvm_verify function returns an override that can be used in future verifications. The output of hmac.saw when run for a single hash, message size, and key size is something like: Verifying HMAC: alg = SHA512, key size = 128, msg size = 10 ...\r\nWARNING: skipping simulation of @s2n_hash_init\r\n…\r\nSuccessfully verified @s2n_hmac_update (overriding [Symbol \"s2n_hash_init\",Symbol \"s2n_hash_update\",Symbol \"s2n_hash_update\",Symbol \"s2n_hash_update\",Symbol \"s2n_hash_update\",Symbol \"s2n_hash_digest\"])\r\nSuccessfully verified @s2n_hmac_digest (overriding [Symbol \"s2n_hash_init\",Symbol \"s2n_hash_update\",Symbol \"s2n_hash_update\",Symbol \"s2n_hash_update\",Symbol \"s2n_hash_update\",Symbol \"s2n_hash_digest\"])\r\nDone! The warnings are for functions that we skipped the proof of using llvm_no_simulate . In this case we aren’t worried about them. Then SAW tells us what functions we verified and we are done! Integrating SAW tests with s2n With the verification complete, we have learned that s2n is equivalent to the high level specification. Almost important, however, is to integrate the SAW verification with the s2n code so that verification can continuously be run as the code continues. It should be fully automatic to run enough SAW verifications to make a very convincing argument that the s2n_hmac functions are implemented correctly, and it should require no additional user effort beyond starting the tests. We have created two kinds of tests that will be run by calling make saw from the s2n root directory. The first kind of test is standard verification. We prove that the s2n implementation is equal to the Cryptol implementation for various hashes, message sizes, and key sizes. The second kind of tests are negative tests. These are tests to insure that SAW is working properly to catch bugs by intentionally introducing bugs and making sure that SAW does not successfully verify the functions. We achieved the negative tests by copying all of the s2n code, patching the copy with bugs, and then compiling the patched code to LLVM for verification with the exact same SAW file that was used for the standard verification tests. One of the negative test cases involves the code we discussed in the previous post: state->currently_in_hash_block += (4294949760 + size) % state->hash_block_size; Which we change to state->currently_in_hash_block += (429494976 1 + size) % state->hash_block_size; This is a particularly compelling negative test case because the large constant was computed by the developers of s2n and is not contained in any standard. When SAW tries to verify it, it returns a counterexample. What that counter example is isn’t particularly meaningful, since this bug should trigger an error one a wide variety of test cases. To show SAW’s ability to find bugs that occur more rarely, we introduce a bug that occurs in one out of every 256 cases. More specifically, it checks the 10th byte of a message for a certain value, and changes it if it has that value. This sort of case would be almost impossible to catch by testing alone but SAW finds it in around 20 seconds, returning a counterexample that shows that the input message should have its 10th bit set to the correct value in order to find the bug. We also modified the Amazon Travis CI script, so now when you see the green “build:passing” button on the Amazon Github page, you know that our SAW tests have been successfully run on that version. Answers to the Homework Now let’s discuss exactly what our verification means, and what you still need to trust to be absolutely certain that the s2n code is correct. In the last post, we discussed asking the question “why should I believe a SAW verification of s2n HMAC is correct?” and asked you to make a list of the answers to that question. Here are our answers to that question. On the left we have the answers for believing a SAW proof is correct and on the right is believing that s2n’s implementation of HMAC is correct using the current tests as evidence: LLVM behaves the way SAW believes LLVM behaves C compiler believes the way that the reader/s2n’s developers believe it does Running SAW at specific sizes is sufficient to show full program equivalence Specific s2n tests are sufficient to show full correctness of the program Cryptol implementation of HMAC is correct C program is correct SMT solver makes correct decisions about equations Reader’s handwritten math is correct Now we will discuss why each of the SAW points on the left is a significant improvement over the comparable test point on the right. Compiler behavior: SAW has been tested on a wide range of C programs already. If the assertions SAW makes about program behavior turn out to be incorrect, SAW will be fixed and be more correct about LLVM behavior going forward. Any individual’s understanding of the C language, however, is unlikely to be very complete or correct. The C language is massive, and has no shortage of tricky corner cases. Making sure to test every corner case every time is much better done by verification software than humans. Coverage: SAW does not prove full program equivalence yet, it proves it at specific input sizes, however as we discussed in the first post, SAW running at even a single input size covers far more cases than we could ever hope to cover with test cases. Specification/Implementation correctness: Cryptol is a language that has been designed specifically to be readable by cryptography experts. The specifications look as close as possible to the math that appears in standards and should be visually comparable to those specifications. Furthermore, a single specification could be used to prove multiple implementations correct. This would further increase trust that the specification is correct. C implementations on the other hand are very specific to the library they are part of. Each has its own optimizations, safety features, and memory layout. All of these things can have an effect on program correctness, and distract from the real meaning of the program from a correctness point of view. Solving equations: SMT solvers are very widely used for solving equations, making bugs unlikely. Many solvers are capable of generating evidence of correctness that can independently be checked by hand or by other programs. Comparably, math done by hand is less likely to be correct, and should be less convincing when presented as an argument for program correctness. There are still things that need to be trusted in order to be completely sure that s2n HMAC is correct, but by running the SAW proofs, we have taken a gigantic step from “not particularly sure” to “pretty darn sure” about the correctness of s2n HMAC. Furthermore, each individual thing that needs to be trusted about SAW can be made easier to trust through further development of SAW. For example, we would love to allow SAW to do inductive reasoning so that it doesn’t need to be limited to a finite number of input sizes. This would give us the ability to cover the input/output space of a program completely, which would be an incredible capability. Conclusion As we said in Post 1, s2n is now at the forefront of verification in cryptography libraries. We would like to thank the team at Amazon for taking such a forward-thinking approach towards the correctness of their library, and giving us the opportunity to collaborate on such a great piece of software. If you enjoyed these posts, you are now at least partially qualified to try a similar verification yourself. We would encourage you to grab your favorite C implementation of HMAC and see where you get verifying it with respect to the same specification we have already used. By doing proofs against new libraries using the same specification, you will not only strengthen trust in your library of choice, but in all other libraries that are verified using that same specification. Any of the authors of this work would love to support you in your efforts to write SAW proofs. You’ll hear from us again when we’ve verified more. Happy proving!", "date": "2016-09-15"},
{"website": "Galois", "title": "Matterhorn Experience Report", "author": "Unknown", "link": "https://galois.com/blog/2017/05/matterhorn-experience-report/", "abstract": "Since August 2016, Galois has been funding the development of Matterhorn , a Haskell terminal client for the MatterMost chat system. Recently, our core development team— Jonathan Daugherty , Jason Dagit and myself —made the first public release of Matterhorn. In this post we’ll discuss our experience building it. All three of us—as well as several other coworkers—were used to terminal-based clients for chatting, clients like irssi , weechat , finch , and glirc . After Galois started using the web-based MatterMost system, we wanted to continue using that style of client. We tried using the IRC “bridge” for MatterMost, a system that would intercept messages from MatterMost and would forward them as though they were IRC messages, thus allowing us to use the IRC client of our choice. This was sufficient for simple chatting but it quickly became apparent that it wasn’t really enough: MatterMost is one of a new crop of chat systems that includes features like indefinite persistent history, editing and deletion of past messages, rich formatting, metadata, and so forth, whereas IRC is still very much based on the metaphor of a stream of simple plain-text messages. The IRC bridge necessarily only exposed only a small subset of MatterMost’s functionality. Instead of using the IRC bridge, we opted to build our own client that would expose these richer features directly to the user while permitting us to stay in the terminal-based environments that we prefer, allowing us to work in a text-dense and keyboard-controlled setting without sacrificing the richer features of MatterMost. It’s still a work in progress and we still add new features on a regular basis, but we’re very proud of the program that we’ve built so far. After a few early prototypes in other languages—including Python and Emacs—we decided to write Matterhorn in the Haskell programming language: all three of us were proficient in Haskell and we had already written several libraries which we planned to use in this application. Haskell is a very good general-purpose programming language, but perhaps because of its origins as a research language it doesn’t tend to be a common choice for moderately-sized user-facing applications like this (although another of our coworkers, Eric Mertens, has also written an excellent terminal-based IRC client, glirc , in Haskell). We wanted to write an experience report about writing this kind of project in Haskell, commenting on the parts that worked very well, the parts that didn’t work out as well, and various aspects of writing this kind of software. Programming the terminal with Brick A major reason we chose to use Haskell was that we wanted to be able to use brick , a library of Jonathan’s creation designed for building terminal-based user interfaces using higher-level layout combinators. One of our design goals with Matterhorn was to maintain a user experience that closely matches that of the official web client, simultaneously sticking to the metaphors of the original client and making transition from the web client to the terminal painless. This meant that we’d need to be able to program non-trivial terminal interfaces quickly, both during initial development and when MatterMost releases new features. We also knew that we’d be exploring the UI design space to find a good terminal alternative to the MatterMost web interface so we’d need to be able to quickly prototype new interface ideas. Brick allows us to do that by writing our interfaces declaratively and by separating event handling, state updates, and drawing from each other. This helped facilitate a relatively clean separation of concerns while making rapid prototyping of new user interface ideas very inexpensive. Managing state with lenses We used lenses from the very start, and this turned out to be a spectacular choice. In general, lenses helped us manage access to our increasingly complex ChatState application state type. As the application evolved, more fields were added to the state, some fields became record types, and soon the ability to reach into the application state to read or write became critical for writing comprehensible state transformations and event handlers. The variety of composition and transformation primitives available with lenses made sophisticated state transformations concise. An unexpected advantage of using lenses is that they’re excellent for helping with data representation refactoring. At various points we found that our main ChatState type had gotten overly large and we needed to refactor it into smaller chunks. But almost every operation in Matterhorn uses some part of the ChatState and many of them involve updating multiple fields of the state. Even a rename of a single state field could involve touching several parts of the program, to say nothing of a deeper reorganization of its fields. As we refactored ChatState with better abstractions, we realized that we could maintain a lens API that emulated the old structure even though we had changed the representation of the underlying types. We could reorganize the state type into a new shape but then write lenses that “faked” the old structure. We could then gradually remove those lenses as part of other refactors until the old interface lenses were unnecessary. This allowed us to incrementally refactor the rest of the program while providing a backwards-compatible lens interface to the older state structure. Easy multi-threading For a while, our application had two primary threads: the main application thread and a background thread for receiving websocket events. It quickly became apparent that we needed another background worker thread to make some HTTP requests asynchronously. Luckily, we were using Haskell, so the first draft of our code for managing asynchronous requests involved about a dozen lines of code. We added a new constructor to our brick event type to represent the successful result of a background task and created a new STM.TChan that we could use to queue up background requests. A background request is represented simply: as an IO computation that returns a function of type ChatState -> ChatState . Consequently, adding a new background computation looks like this: STM.atomically $ STM.writeTChan asyncQueue $ do\r\n  -- Work done here is done asynchronously.\r\n  -- After we’re done working, return a function to\r\n  -- transform the state with the results of the work.\r\n  return (\\ state -> ...) When Matterhorn starts up, it spawns a new thread to process these requests. In a loop, the thread grabs an IO computation from the channel, executes it, and sends the resulting state transformation back to the brick event loop: void $ forkIO $ forever $ do\r\n  request <- STM.atomically $ STM.readTChan asyncQueue\r\n  response <- request\r\n  writeBChan brickEventChan (AsyncResponseEvent update) Then the brick event handler can use the ChatState -> ChatState function that’s included in the event and apply it to the state: onAppEvent :: ChatState -> MHEvent -> EventM Name (Next ChatState)\r\nonAppEvent state (AsyncResponseEvent f) = continue (f state) And with less than a dozen lines, we’ve got a background worker thread with a work queue that integrates cleanly into our existing application! It’s only a few more lines to add proper error handling and only a few more to implement high-priority background tasks which get higher priority in the queue. Large Haskell projects can be hard to structure A consistent problem in writing Matterhorn was that new functions had an obvious place to go—many of them were about state manipulation, so they’d go in State.hs ! Those functions would (usually) be small, maybe a dozen lines at most, and were nicely composable and orthogonal in functionality. Unfortunately, there were also tons of them. In most object-oriented languages (and even some non-object-oriented languages, like Rust ), data types serve double duty as modules or namespaces. This choice has both advantages and disadvantages, but one advantage is that namespaces become cheap. An operation on a piece of data is namespaced to that piece of data, so instead of head(list) , you can write list.head() , and code that deals with a type is scoped to that type. Haskell does not do this: functions can be namespaced within modules, but beyond that, they all live at the top level. It’s up to the programmer to organize them effectively, and this affords more flexibility in terms of code structure but that also means more opportunities to structure code poorly. When you’re adding a lot of effectful operations over the stateful core of a program that needs to keep track of lots of pieces of information—user lists and statuses, chat messages, rendered message caches, network connectivity information—it’s easy to toss them all in a bin until that bin overflows. This is less of a problem when you’re writing a small application with fewer conceptual parts (or parts that are less closely-linked), and it’s also easier when you’re writing a library. In a language with more lightweight namespaces—for example, in Rust, where you can create a new local namespace with mod , without having to create a new file and add it to your package description—it’d be easier to gradually break apart a module’s functionality. Our experience with Matterhorn has shown that it’s useful to throw everything into one place in the beginning when the ultimate design isn’t yet clear, so long as there is time set aside to pull things apart later as useful abstraction boundaries become more evident. Cabal new-build is awesome! All of us were early adopters of Cabal’s Nix-style new-build system and it’s excellent . Like the Nix package manager , new-build builds shared packages and identifies them with a hash of their dependencies and configuration and any other ambient state which might change the built package. It doesn’t require sandboxes, and dependencies that can be shared will be shared, but it also doesn’t put packages into the global namespace like non-sandboxed cabal. It also affords you the ability to use a cabal.project file, which combines multiple individual cabal modules into a larger whole. A cabal.project file can specify a set of related local packages which can then be built as a single unit. It’s still in the ‘tech demo’ phase, but we’ve all had a remarkably stable and consistent time with it. Haskell’s library ecosystem is an asset At this point Haskell’s library ecosystem is rich enough that we didn’t have to implement any core components ourselves. For many tasks–JSON processing, HTTP, SSL, configuration file handling, etc.–we had many options available. An abundance of choices is both a blessing and a curse: having many choices to solve a problem means some solutions may be more tailored to one’s needs, but it can also be difficult to evaluate the available options. For choosing Hackage packages, especially in cases where we weren’t already familiar with the options, we found that there are some decent heuristics for narrowing down the set of choices: Look at the number of releases and the date of the most recent release. A recent release and/or a large number of releases at least suggests that the package is likely to be maintained. Check http://packdeps.haskellers.com/reverse to get a sense for how many other package depend on the package in question. Is the package maintained or written by an author of note in the community? This is not necessary but if you already know the author or trust their work, it can be helpful. Look at the number of downloads for the package in the last 30 days. Is the package receiving attention? These checks are by no means perfect, and it’s also important to give all of the options a fair shake because newcomers make valuable contributions and more established packages can build up technical debt that is not readily apparent. However, these checks can at least provide a decent measure of the “liveness” of a package. Matterhorn has enough direct dependencies that the complete set of transitive dependencies is quite large. As with any software, direct and transitive dependencies always bring with them some amount of technical debt. In some ways it’s worse with transitive dependencies because those dependencies are often even more out of our control and problems in those dependencies can limit portability, GHC compatibility, or licensing. This isn’t necessarily bad, but it represents a trade-off that deserves consideration: using others’ works to save considerable time, potentially taking on technical debt and giving up control, versus building it yourself, paying the cost to build from scratch and having more control. Looking ahead Going forward, our development team will be maintaining compatibility with the latest MatterMost server release, adding new features to maintain feature parity with the upstream client, and maintaining a presence on Hackage and GitHub. We’re definitely interested in contributions, so stop by the GitHub page to get started! Links Matterhorn: GitHub: https://github.com/matterhorn-chat/matterhorn Hackage: http://hackage.haskell.org/package/matterhorn Mattermost-api: GitHub: https://github.com/matterhorn-chat/mattermost-api Hackage: http://hackage.haskell.org/package/mattermost-api MatterMost: http://about.mattermost.com/", "date": "2017-05-24"},
{"website": "Galois", "title": "Part two: Specifying HMAC in Cryptol", "author": "Unknown", "link": "https://galois.com/blog/2016/09/specifying-hmac-in-cryptol/", "abstract": "This is the second in a series of three blog posts detailing the use of SAW and Cryptol to prove the correctness of the HMAC implementation in Amazon’s s2n TLS library. Part one: Verifying s2n HMAC with SAW . Part three: Proving Program Equivalence with SAW . In the first post, we described how we proved equivalence between a mathematical description of the HMAC algorithm: HMAC(K, m) = H((K' ⊕ opad) || H ((K' ⊕ ipad) || m)) and the s2n C implementation of the HMAC algorithm, which is written in 166 lines of C code. The first step in this process was to write a Cryptol specification that we can visually trust defines the same thing as the mathematical definition. Despite the fancy name, specifications aren’t a fancy or novel idea. In fact, our ancient ancestors used specifications. A parent caveman would specify a tiger to his kids “A large orange and black cat is a tiger. It tastes bad and will eat you. Run when you see it.” In this case, the specification is “large orange and black cat.” It doesn’t tell you how to make a tiger, and frankly you don’t care (or even want to know). As an ancient human, all you really need to know is how to identify a tiger, so that you can appropriately run from it instead of trying to hunt it. Now we don’t see many tigers, and modern parents say “Read this Cryptol spec for HMAC. A bad implementation behaves differently. Those implementations taste bad and will eat you. Run when you see them.” As an added benefit, those parents no longer get asked to read bedtime stories, leaving them free to prove more programs correct. Humans like to use language to convey their specifications. This works well when humans need to be able to both understand the specification and check against it. In the case of verification, the specifications have double duty. They need to be understandable by both humans and computers, so that computers can do the checking. Cryptol is a language that was written for precisely this purpose. It comes as no surprise, then, that it is generally less work to verify equivalence between two Cryptol programs than a Cryptol program and a C program, or two C programs. We can leverage the fact that program equivalence is a transitive property to perform the proof in layers, so that we can do as much work using only Cryptol specifications as possible. To illustrate this, we can think of the proof between the high level Cryptol spec and the C code as a distance that we need to traverse. Now imagine that we have two cars. One is really fast, but only runs on smooth roads (Cryptol to Cryptol equivalence). The other is much slower, but is capable of reaching all of the way to our end goal (equivalence involving C). In general, we would like to take the fast car as far as we can (as long as we don’t have to go too far out of our way to keep taking it) before switching over to the all-terrain vehicle for the last leg. This blog post is about choosing the point where we should switch cars. A more detailed look at the high level spec We listed the high-level Cryptol specification in the previous blog post, but we will do it again here in order to examine the type signatures and learn more about Cryptol: hmac : { msgBytes, pwBytes, digest, blockLength }\r\n       ( fin pwBytes, fin digest, fin blockLength )\r\n    => ([blockLength + msgBytes][8] -> [8*digest])\r\n    -> ([blockLength + digest][8] -> [8*digest])\r\n    -> ([pwBytes][8] -> [8*digest])\r\n    -> [pwBytes][8]\r\n    -> [msgBytes][8]\r\n    -> [digest*8]\r\n\r\nhmac hash hash2 hash3 key message = hash2 (okey # internal)\r\n where\r\n   ks : [blockLength][8]\r\n   ks = kinit hash3 key\r\n   okey = [k ^ 0x5C | k <- ks]\r\n   ikey = [k ^ 0x36 | k <- ks]\r\n   internal = split (hash (ikey # message)) In the first line, we declare a number of type variables. These variables are numeric values, but types are allowed to depend on them. Next, we list constraints on those variables. In this case we say that some of the variables are finite ( fin ), but we can do more interesting things as well. For example, if we hated security, we could add in 3 >= pwBytes . Then if a security zealot with a 4 character password (“1234” instead of our typical “123”) tried to call our function they’d get the message: cryptol> hmac `{blockLength=64} SHA256 SHA256 SHA256 \"1234\" \"DARKEST SECRETS\"\r\nUnsolvable constraint:\r\n    3 >= 4\r\n      arising from\r\n      use of expression hmac\r\n      at <interactive>:1:1--1:9 We should note that this is a static check. Like all of your favorite typechecking properties, this check occurs when the Cryptol source is loaded, not when it is executed. This means that it is also impossible for another function to use our new, small key only, version of HMAC unless it can guarantee that the argument it supplies to the HMAC function is always shorter than 3 bytes. The type variables are also values, however, so we can do computation on them as well. For example we could write a function that checks to see if 3 >= pwBytes and returns the message “chill out please, your key is too long” instead of running HMAC if the key is too long. This code would interpret fine, and only complain when it was actually called with a long key. We, of course, love security, and authentication of our “DARKEST SECRETS” is certainly not protected by the password “123”. We just had IT add the “4”. With the exception of that type fanciness, Cryptol mostly behaves like the functional languages you already know and love (you do love them right??). The incremental Cryptol specification So far, we’ve talked about HMAC as if it is a single function that takes a message and a key and outputs an authentication code. In reality, this can be terribly inefficient. The message could become available gradually, and waste valuable processing time as it arrives. To help with this problem, the C code offers an initialize/update/digest interface, which allows the authentication code to be constructed incrementally as the message arrives. To prove that the C code is equivalent to the highest level spec, we would like to make a lower level Cryptol specification that makes two major steps in the direction of the C code. It models a state similar to the one that appears in the C code, and It implements the initialize/update/digest interface that the C code uses. In order to model the state, we declare a record in Cryptol that matches the struct that is declared in the C code. So in the C code we see: struct s2n_hmac_state {\r\n   s2n_hmac_algorithm alg;\r\n\r\n   uint16_t hash_block_size;\r\n   uint32_t currently_in_hash_block;\r\n   uint16_t block_size;\r\n   uint8_t digest_size;\r\n   …\r\n} And in Cryptol our state is type HMACState = {\r\n       alg : [32]\r\n     , hash_block_size : [16]\r\n     , currently_in_hash_block : [32]\r\n     , block_size : [16]\r\n     , digest_size : [8]\r\n       …\r\n} Each of the types (which occur after the colons) specify the size of the input in bits. Now all of our HMAC functions will be transformations over a HMACState. For example the hmac_init function: hmac_init : { pwBytes }\r\n            ( fin pwBytes, 64 >= width (8*pwBytes) )\r\n         => [pwBytes][8]\r\n         -> HMACState\r\nhmac_init key =\r\n    … takes a key (of size ( [pwBytes][8] ), since size specification is in bits and there are 8 bits in a byte, you can think of this as pwBytes bytes) as an argument and creates a new HMACState. The update function takes a HMAC state and (part of) a message and returns an updated HMACState. The digest function takes the HMACState and returns a finalized HMACState and an output whose size matches the output of the hash function being used. A generic specification One of the most interesting parts of verifying HMAC is that internally HMAC can use a wide variety of hash functions. The HMAC state carries around a number of states for these hash functions, but the HMAC algorithm isn’t very concerned with the states and simply assumes that they interact properly with the provided hash functions. It can’t really care about the result of the hash, and if it could, we probably wouldn’t want to use that hash. For the purpose of specification, then, it really doesn’t matter what our Cryptol code does once it reaches the call to the hash function because our verification won’t care. We will discuss how we achieve this and why in the next post. What we might want to do, however, is execute our specification on real inputs in order to further convince ourselves of its correctness. Furthermore, if our verification turns up a counterexample that might cause the specification to differ from the implementation, we would like to be able to actually run that counterexample. In order to allow the hash function to be swapped out easily, we define intermediate functions (we leave out their definitions, since these functions simply rename another function): hash_init_c_state : SHA512_c_state -> SHA512_c_state\r\n\r\nhash_update_c_state : {msg_size} (fin msg_size) => SHA512_c_state -> [msg_size][8] ->\r\nSHA512_c_state\r\n\r\nhash_digest_c_state : {digest_size} (fin digest_size) => SHA512_c_state -> [digest_size][8] These functions allow us to easily swap out the hash implementation when it is convenient. We could also define all of these functions to be undefined a value which causes an error if it is evaluated. Even though the evaluation would cause an error, during verification we will always stop evaluation at the point of those functions, meaning that a function that can’t be evaluated might still represent a valid specification. If these functions are generic why do we see mention of SHA512 in the types? To allow our function to be generic despite needing different states, we took a page from the C book. In C, a union of types is statically given the size of the largest type in the union. In the case of the hashes available in s2n, this is SHA512. Because it is the biggest state, any of the other states can fit inside of it. In order to define a function with the type required by our hash_c_state functions, we need a function to translate e.g. a SHA512 state that contains a SHA256 state into just a SHA256 state so the SHA256 Cryptol implementation can do its work. Once that work is done, the state can be put back into the SHA512 state. What do we leave out? We made the state and interface in the Cryptol specification match those in the C program, but there are still a few places that things don’t match as closely. As an example, s2n has a statement specifically designed to avoid a timing attack on x86 processors: state->currently_in_hash_block += (4294949760 + size) % state->hash_block_size; As the comment in the source code states, the constant 4294949760 is a multiple of all possible values of state->hash_block_size and size is always small enough that there will never be any overflow. That means that this code should be functionally equivalent to the code that doesn’t add in the large constant. The constant is actually there because on many architecture the modulo operator behaves significantly more efficiently on a small input. That means that timing the update function could leak information about the length of the message. Ensuring that the argument to the modulo operator is always large avoids this timing attack. The current Cryptol code is: currently_in_hash_block =\r\n      (s.currently_in_hash_block +\r\n       ((128000 + `n) % (zero # s.hash_block_size))) Which has a different constant, that is also functionally equivalent to not being there. The constant we used matched the C code when we started development, but the C code’s constant was increased to improve timing attack resistance. The update did not stop the proofs of correctness from working, so we did not modify our specification. And since the top-level specification (the one line of math at the top of this post) does not include either of these constants, our proof tells us that they do not have an effect on the input / output behavior of the hmac computation. That’s the spec In this post, we have given two definitions of what it means to be HMAC. The first is meant to be visibly comparable to the mathematical specification that exists in standards and the second is meant to be similar to the structure of the C code. In the next post, we will show how we prove equivalence between the two Cryptol specs, and the incremental Cryptol spec and the C code. Your homework Yeah, this is a blog post, but it’s still going to tell you what to do… After this you’ll still want to come back and read the next one right? Anyways, it’s a fun homework; you get to ask the same question over and over. This is how a good verification researcher behaves. The question to ask is “why should I trust (or believe in) this?” So if someone comes to you with a tool and claims that it finds all undefined behavior in a C program, an interested researcher might ask “why should I trust your tool?”. Often the tool developer will give some argument about soundness. They might give this as if it is the whole answer, but don’t forget that you’re tasked with asking the same question over and over again.  “Why should I trust that your soundness argument’s representation of the C language corresponds to what your compiler does?” Perhaps the tool also depends on a library that helps generate side conditions .“Why should I trust the library?”. Perhaps the library has a soundness proof of its own and you can ask more questions. Eventually, while asking “why should I trust this?” you will hit a point at which you can go no further. Ideally it will be some sort of axioms that are simple enough for you to verify visually, but this is rarely, if ever, the case. In reality, it takes a very long time to provide enough evidence that you only need to trust a few things to be true, and getting trust to this level often greatly slows further development of software as well. So developers of verification tools always walk a fine line between answering all of the questions, and actually getting their software developed and making it useful to their customers. Your homework, then, is to ask “why should I trust this?” about the proofs we are presenting here as many times as possible. Write down a list of exactly what you need to believe in order to trust the SAW verification. Next to that write down the same list of things for s2n all on its own. Hopefully this will illuminate where SAW is helping with the trustworthiness of the code, and where we can apply future work to help make SAW more trustworthy. Our answers will be in the next post, we look forward to seeing yours!", "date": "2016-09-06"},
{"website": "Galois", "title": "Simulating DDoS attacks with ddosflowgen", "author": "Unknown", "link": "https://galois.com/blog/2017/04/simulating-ddos-attacks-ddosflowgen/", "abstract": "At Galois, we’ve been investigating new ways to defend against very large distributed denial of service (DDoS) attacks. Under the DHS-funded DDoS Defense program , we’re developing 3DCoP : software that creates a “community of peers” that can detect and mitigate attacks together. We’re interested in attacks that can exceed 1 Tbps (terabits per second) of total traffic, such as the DNS-based attacks from October 2016. To develop solutions for these giant attacks, we need to study this kind of traffic and run experiments with it. This is where we run into some problems. Traffic captures of real DDoS attacks – especially at magnitudes anywhere near 1 Tbps – are hard to come by. Even with captures of smaller DDoS attacks, we can only see the traffic as viewed from one network, such as a victim or a recipient of backscatter from the attack. For our work, we need the whole picture of a DDoS attack: views of the traffic from all networks involved, with many thousands of end points. Unfortunately, this is very difficult to simulate with standard network simulation software like ns-3 and OMNeT++, especially when you add in realistic non-attack traffic. To tackle this problem we created ddosflowgen : a tool that models a DDoS attack and generates synthetic traffic datasets from multiple views. You can define the number of attacking networks and adjust parameters such as the attack vectors present, the amplification factor, and the number of attack sources per network. Our tool includes non-attack traffic in the output by rewriting IP addresses from a reference noise dataset. An attack model in ddosflowgen Unlike packet-based simulations, which are not feasible at terabit scales, ddosflowgen simulates traffic using a “flow” representation. This format (implemented with SiLK ) uses summaries of IP headers to describe traffic in a compact form. Flow representation makes it possible to simulate extremely high packet and bit rates, and we’re currently experimenting with 1.2 Tbps attack scenarios. ddosflowgen simulates a variety of threats: amplifiers/reflectors, such as DNS and NTP servers flooders within a botnet, like Mirai in attack mode probes from a botnet, like Mirai scanning for IoT ddosflowgen is open source, and is available on Github . We are releasing this primarily as an aid to other researchers, and to start a discussion about how best to generate repeatable test cases for defenses against massive attacks. Please enjoy, and we’re happy to consider updates, but understand that we intend this tool largely as reference material rather than as a long-running software project. This project is the result of funding provided by the Science and Technology Directorate of the United States Department of Homeland Security under contract number D15PC00186. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of the Department of Homeland Security, or the U.S. Government.", "date": "2017-04-25"},
{"website": "Galois", "title": "Galois: 2016 highlights", "author": "Unknown", "link": "https://galois.com/blog/2016/12/galois-2016-highlights/", "abstract": "2016 saw a remarkable increase in the awareness and impact of our work in provably secure software and high assurance critical systems. As the year comes to a close, we want to pause and reflect on the intellectual contributions that Galwegians have made as result of that work. Overview This year we partnered with Amazon Web Services to formally verify subcomponents of the s2n SSL/TLS encryption library, making Amazon’s s2n a leading example of verification applied to industrial cryptographic code. We also shared the tools and techniques that enable such verification in multiple venues. SAW, a core component of our formal verification toolset, was released under a 3-clause BSD license , making it widely available for public use. In 2016, we continued our work on secure and correct cyber-physical systems software. Among multiple contributions, we published a paper outlining tips and techniques for effectively building high-assurance cyber-physical systems based on experience in DARPA’s High Assurance Cyber Military Systems (HACMS) work. In the field of network defense and cybersecurity, we held multiple talks on our new DHS-funded effort to an build an innovative DDoS defense mechanism that leverages collaboration between peers to stop DDoS attacks early. We also shared our work on the use of unikernels to deploy and secure low cost microservices, and also used them to build CyberChaff, an effective network defense product. On the heels of last year’s work on elections technology, we announced Free & Fair, an elections technology spin-off focused on enabling verifiable, transparent and secure elections. Free & Fair took an active part in the national conversation on elections integrity and the future of elections technology. Galois also launched Formaltech , a technology transition spin-off specializing in the commercialization of new technologies derived from research and development, like CyberChaff and FUSE . Tozny , Galois’s secure authentication and encryption spin-off, announced a developer preview of their new secure database, E3DB , based on the NIST-funded Personal Data Storage project announced last year. Tozny’s authentication technology was also used in the Atlanta Streetcar System ticketing app to enable secure, passwordless authentication. Our work on securing cyber-physical systems, formal verification and network security was covered in national media throughout the year . This year we announced a $10 million award from DARPA’s CFAR program to leverage software diversity techniques in developing breakthrough cyber defenses for existing and future software systems. We also announced a second award of $6.2 million from DARPA’s Brandeis program to measure the privacy, performance and utility of Brandeis systems. We announced three other major awards , and won many more. Below are additional details and links to our intellectual highlights of 2016. Happy holidays from all of us at Galois, we wish you the best in the year to come! High-assurance Cryptography Galois Ultra Low Power High Assurance Asynchronous Crypto , Lightweight Crypto 2016 Dr. Joe Kiniry held a talk on ultra low power high assurance crypto at the Lightweight Cryptography Workshop organized by the National Institute of Standards and Technology (NIST). In the talk, Dr. Kiniry presented the results from an R&D project focused on synthesizing low power, high assurance hardware crypto implementations from formal specifications. Formally verifying the HMAC algorithm in Amazon’s s2n TLS library In collaboration with Amazon Web Services, Galois formally verified subcomponents of the s2n TLS/SSL encryption library by leveraging the Cryptol and SAW toolsets. SAW was also integrated in the build system in order to perform continuous automated verification as s2n development continues. Dr. Joey Dodds published a series of three posts describing the process of verification in detail, as well as the importance of formal verification for cryptographic implementations in today’s cyber environment. At AWS re:invent, Amazon Web Services’ Byron Cook, held a session on automated formal reasoning and AWS systems, which included an overview of the formal verification work conducted on s2n. Automated Verification of Real-World Cryptographic Implementations , IEEE Security & Privacy Dr. Aaron Tomb published a paper in IEEE Security & Privacy (Volume: 14, Issue: 6, Nov.-Dec. 2016) detailing approaches and tools like Cryptol and SAW that make it possible to automatically and rigorously verify real-world cryptographic implementations against machine-readable specifications. Top-to-bottom Verification of Cryptographic Code , MVD 2016 Dr. Aaron Tomb gave the keynote talk on comprehensively verifying cryptographic algorithms at the Midwest Verification Day (MVD) 2016, hosted at Iowa State University. Dr. Tomb described recent advancements that have shown that top-to-bottom verification of cryptographic code is quite practical and walked through a variety of real-world case studies, most involving verification of code that is actively used in production today. Intro to Cryptol and High-Assurance Crypto Engineering (video), LambdaConf 2015 Adam Foltzer introduced Cryptol at LambdaConf 2015 (video published in 2016). Foltzer implemented and checked a classical cryptosystem in order to teach the basic syntax and semantics of the language, check correctness through the use of QuickCheck and SMT, and demonstrate how the theorem-driven development approach reveals a bug that requires a revision of the cipher. High-assurance Cryptography , RWC 2016 Dr. Joe Kiniry presented the tools and techniques used at Galois to build and formally verify cryptographic implementations at the Real World Cryptography Conference 2016. Dr. Kiniry walked the audience through the Galois High Assurance Crypto Tool Suite which includes Cryptol and SAW. He also touched on using a subset of tools to automatically synthesize provably correct hardware and software cryptographic implementations. Maturity and Performance of Programmable Secure Computation , IEEE Security & Privacy. Dr. David Archer was part of a team that published a review of the state of the art in secure computation in IEEE Security & Privacy, Sep/Oct 2016 Vol 14, No. 5. The paper reviewed the results of U.S. and European secure computation research programs and other published literature to present the state of the art in what can be achieved with today’s secure computing technology. The team also included Dan Bogdanov, Benny Pinkas, and Pille Pullonen. MPC: Practical Dynamic Composition of Operators in Secure Computation: VoIP and SQL , DiMACS ORAM, June 2016 Dr. David Archer held an invited talk on multi-party computation at the DiMACS ORAM workshop. In the talk, Dr. Archer presents two use cases where the circuit model for secure computation is impractical and gives way to the RAM model: privacy-preserving signal processing and secure database queries. 5Gen: A Framework for Prototyping Applications Using Multilinear Maps and Matrix Branching Programs , ACM CSS 2016. Dr. Dave Archer , Dr. Daniel Wagner , Dr. Alex Malozemoff , and Adam Foltzer were part of a team that published a study of applications of multilinear maps (mmaps) in cryptography at the 23rd ACM Conference on Computer and Communications Security ( ACM CCS ). The paper presents a framework to experiment with mmap application to program obfuscation and multi-input functional encryption (MIFE). Also part of the team: Kevin Lewi, Daniel Apon, Brent Carmer, Dan Boneh, Jonathan Katz, and Mariana Raykova. Attribute-based Key Exchange with General Policies , ACM CCS 2016. Dr. Alex Malozemoff was part of a team that published a paper presenting an attribute-based key exchange solution at ACM CCS 2016. The approach combines attribute-based encryption (ABE), and attribute-based credentials (ABCs) with garbled circuits to construct an interactive key exchange solution involving a client that holds a certificate (issued by an authority) vouching for that client’s attributes and a server that holds a policy computable on such a set of attributes. Also part of the team: Vladimir Kolesnikov, Hugo Krawczyk, Yehuda Lindell, and Tal Rabin. What Else is Revealed by Order-Revealing Encryption ? ACM CCS 2016 Tom DuBuisson was part of a team that published a paper analyzing order-revealing encryption leakage at ACM CSS 2016 . The paper describes multiple ways in which plaintext information can be extracted from ORE ciphertexts by applying known and new attacks to concrete ORE schemes on non-uniform data. Also part of the team: F. Betül Durak and David Cash. Software correctness and formal verification Constructing Semantic Models of Programs with The Software Analysis Workbench , VSTTE 2016. Dr. Aaron Tomb presented a paper detailing the structure of the Software Analysis Workbench, which was presented at 8th International Conference on Verified Software: Theories, Tools, and Experiments ( VSTTE 2016 ). The paper, by Dr. Robert Dockins , Adam Foltzer , Dr. J oe Hendrix , Brian Huffman, Dylan McNamee, and Dr. Aaron Tomb, presents experimental results demonstrating the benefits of SAW’s implementation techniques. Formal Methods at Galois and Free & Fair , DeepSpec 2016. Dr. Joe Kiniry presented an overview on the use of formal methods at Galois and Free & Fair , Galois’s election technology spin-off, at DeepSpec 2016. Dr. Kiniry walked through the reasons why formal methods are applicable and effective in elections software by using the Free & Fair tabulator as a case study. A verified information-flow architecture , Journal of Computer Security Nathan Collins was part of a team that published a paper detailing a verified information-flow architecture in the Journal of Computer Security, vol. 24, no. 6, pp. 689-734, 2016. The paper presents a formal, machine-checked model of the key hardware and software mechanisms used to dynamically control information flow in SAFE (a clean-slate design for a highly secure computer system), and a machine-checked end-to-end proof of noninterference for this model. Also part of the team were Arthur Azevedo de Amorim, André DeHon, Delphine Demange, Cătălin Hriţcu, David Pichardie, Benjamin C. Pierce, Randy Pollack, and Andrew Tolmach. Access the complete paper here and the formal proof here . Insights on Formal Methods in Cybersecurity , IEEE Computer Society Dr. Joe Kiniry weighed in on the current use and practice of formal methods in cybersecurity for IEEE Computer Society . Dr. Kiniry stated that the part of the FM community that is looking for opportunities to use FM in practice is growing over time in response to the increasing need for FM in industry, particularly in matters relating to critical systems and cybersecurity. Binary Static Previrtualization , Navy FST 2016 Dr. Joe Hendrix presented APTREE , a project focused on performing whole-program optimization on binaries, at the Navy Forum for SBIR/STTR transition. The goal of the project is to develop tools that take existing compiled binaries, along with platform-specific supporting libraries, and builds reoptimized binaries tailored for a particular platform. The tools strip identify and strip out unused code that may contain security risk, can relocate fixed addresses to make it harder for adversaries to exploit fixed structures, and apply optimization across library boundaries to enable more efficient code and eliminate redundant operations. High-assurance cyber-physical systems Hints for High-Assurance Cyber-Physical System Design , IEEE SecDev 2016 Dr. Lee Pike published and presented a paper on high-assurance cyber-physical system design at the IEEE Cybersecurity Development ( SecDev ), 2016. The paper outlines several “hints” for designing high-assurance cyber-physical system software based on the lessons learned in DARPA’s HACMS program: (1) Constrain the programming languages, (2) Secure the interfaces, (3) Automate the tedium, (4) The Verifier’s Dilemma, and (5) The mythical verification month. Read the full paper here and see the presentation slides here . Hints for High-Assurance Cyber-Physical System Design , HCCV 2016 Dr. Pike also gave an invited talk presenting “Hints for High-Assurance Cyber-Physical System Design” at the Workshop on High-Consequence Control Verification . See the abstract of the talk here , Programming Languages for High-Assurance Autonomous Vehicles, MUSE PI meeting, 2016. Dr. Lee Pike gave an invited talk describing the use of embedded domain-specific languages (EDSLs) for embedded systems in autonomous vehicles at the MUSE PI meeting. The talk focused on using EDSLs to improve programmer productivity and increase software assurance in the context of building an autopilot for unpiloted aircraft called SMACCMPilot, work performed for DARPA under the High-Assurance Cyber Military Systems (HACMS) program. SMACCMPilot was a “green field” design in which most of the architecture and software were designed from scratch. We will discuss both successes and remaining challenges with our approach. TrackOS: A Security-Aware Real-Time Operating System , RV 2016 Dr. Lee Pike , Pat Hickey, Trevor Elliott , Eric Mertens , and Dr. Aaron Tomb presented a paper at the 16th International Conference on Runtime Verification describing an approach to control-flow integrity protection for real-time systems. The paper details TrackOS , a security-aware real-time operating system that detects malware in real-time embedded systems. TrackOS does this by checking a task’s control stack against a statically-generated call graph, generated by an abstract interpretation-based tool that requires no source code. Performance bounds for human machine teaming, RSS 2016 Dr. Peter Trautman gave an invited talk on performance bounds for human machine teaming at the Robotics Science and Systems (RSS) Shared Autonomy and Collaborative Robotics Workshop 2016. Perspectives on Analysis and Design of Human-Centered Robotics workshop , IROS 2016. Dr. Peter Trautman gave an invited talk about at the Perspectives on Analysis and Design of Human-Centered Robotics workshop, part of 2016 International Conference on Intelligent Robots and Systems ( IROS ). Performance Limits of Human-Machine Interface Technology , ShARP Dr. Peter Trautman gave a keynote talk on shared control at the AAAI Symposium on Shared Autonomy in Research and Practice. Performance Bounds for Human Machine Teaming and Design , AFRL S5 Dr. Peter Truatman gave a talk on the mathematical theory of human machine teaming at Air Force Research Laboratory’s Safe & Secure Systems and Software Symposium (AFRL S5). Cybersecurity Provenance Segmentation , TaPP ‘16. Dr. David Archer and Erin Chapman were part of a team that published a paper on provenance segmentation at the 8th USENIX Workshop on the Theory and Practice of Provenance (TaPP), which was hosted in conjunction with ProvenanceWeek . The paper describes segmentation (approximating, compressing or summarizing part or all of the provenance graph) as an approach to garner insights from provenance data, with the goal of securing mainstream systems. Also part of the team: Rui Abreu, James Cheney, Hoda Eldardiry, and Adria Gascón. Combining computational provenance and anomaly detection to reveal cautious, persistent threats , Provenance-based Security and Transparent Computing Workshop Dr. David Archer presented ongoing work to detect advanced persistent threats as part of DARPA’s Transparent Computing program at the Provenance-based Security and Transparent Computing workshop, Provenance Week . Dr. Archer described the architecture of the system, the approach on each of these technical efforts, and preliminary results to date. For more information on Galois’s Transparent Computing project, visit the ADAPT project page . Composition Challenges for Automated Software Diversity, LAW 2016. Dr. Benjamin Davis presented research performed in collaboration with Dr. Stephen Magill and Dr. Simon Winwood at Galois, as well as David Melski, Per Larsen, Michael Franz, and Stijn Volckaert. The work, presented at the Layered Assurance Workshop (LAW) describes issues that must be considered when composing software diversity transformations and is part of Galois’ RADSS project . 3DCoP: DDoS Defense for a Community of Peers (video), DHS S&T R&D Showcase Jem Berkes presented 3DCoP, an ongoing research project focused on developing an innovative DDoS defense system, at the DHS S&T R&D Showcase and Technical Workshop. 3DCoP enables a community of peers to collaborate for better DDoS defense. Berkes also presented 3DCoP at BSidesPDX 2016 . For more information on 3DCoP, watch the video above or visit the project page . Collaborative DDoS Defense and New IoT Threats, IEEE Winnipeg Section Jem Berkes presented current research efforts on collaborative DDoS defense and emerging IoT threats at IEEE Winnipeg Section, University of Manitoba. Berkes presented Galois’s 3DCoP project, and explained the new IoT-based botnet threats that have emerged over the past year. For more information on 3DCoP visit the project page . Critical Applications for Mobile Roots of Trust (video), DHS S&T R&D Showcase Erin Chapman presented Galois Mobile Roots of Trust project at the DHS S&T R&D Showcase and Technical Workshop. Chapman walked through the results of the project as well as the current state of the mobile roots of trust ecosystem, their benefits, and uses. For more information on the Mobile Roots of Trust project watch the video above, visit the project page, or watch this informational video. Mobile Roots of Trust: The Next Step in Mobile Security (video) Galois published a short informational video explaining mobile roots of trust, their applications and the role they play in the mobile ecosystem, as part of the DHS Mobile Roots of Trust project. Don’t Lose Track of the Actual Problem: Building Trustworthy Mission-critical Systems, The Roles of Hardware & Software , Hardware Security Workshop Dr. Joe Kiniry and Dr. Dylan McNamee gave a talk at the Hardware Security Workshop, co-organized by Galois, Mentor Graphics, and Intel. This talk focused on the implications on assurance, capabilities, and business for the application of formal methods on secure hardware, and hence high assurance secure systems. TFER: Collaboration and Automation for Threat Assessment and Mitigation , HCSS 2016 Dr. David Archer presented TFER, a decision analysis system focused on automating cyber threat analysis and assessment at the High Confidence Software and Systems Conference (HCSS). TFER augments human analysts with automated measurements of a system’s security. This helps determine which threats are most dangerous in the current operational context, which assets are at greatest risk, and which mitigations provide the greatest reduction of risk. Designing an Evidential Assertion Language for Multiple Analysts , BELIEF 2016. David Burke published a paper describing the design of an evidence-based language in the proceedings of the 4th International Conference on Belief Functions ( BELIEF 2016 ). The expressive language is designed for use by analysts as part of a decision support system for managing cyber threats. The paper describes how the language design provides flexibility to analysts in terms of expressing and combining evidence, while supporting rich interactions between analysts, and then illustrate our approach with examples. Wigmore: A Constrain-Based Language for Reasoning About Evidence and Uncertainty , HCSS 2016 David Burke presented Wigmore, the evidence-based language detailed in the BELIEF 2016 paper above, at the High-Confidence Software and Systems Conference ( HCSS 2016 ). From the abstract: “In the cybersecurity realm, we are often dealing with great amounts of uncertainty, and it is our experience that in this domain, we are dealing with events that are better characterized by ambiguity, not risk, primarily due to the fact that the adversary is not best modeled as a natural, stochastic process, but rather, as a sentient, learning entity. We are interested in creating software tools to reason about this kind of uncertainty in order to support effective decision-making in the cyber domain.” Mixing Communications and Paranoia in the New Cyber Defense , Oregon Cyber Security Day Dr. Adam Wick gave a talk at the Oregon Cyber Security Day describing a variety of new network defense technologies and tactics at Galois and the concrete projects that have been created as a result, including 3DCoP and CyberChaff, highlighting how these techniques can be reified into next-generation cyber solutions. Diocletian, Constantine, Bedouin Sayings, and Network Defense , StrangeLoop 2016 Dr. Adam Wick gave a talk at StrangeLoop 2016 on the parallels between border defense in the 4th century Roman Empire and modern day network cyberdefense. Dr. Wick argues that when it comes to protecting networks, we are outnumbered, and any technical superiority we may have had is dwindling. He also talks through how we can apply some of the lessons learned: a reactive style to better protect our networks, designing systems to better survive in the new environment, and the fact that trust is not an all-or-nothing property. Unikernel Microservices: Build, Test, Deploy, Rejoice . StrangeLoop 2016. Unikernels are a new mechanism to deploy lightweight, scalable, secure microservices that offer big functionality for relatively low cost. Dr. Adam Wick , Adam Foltzer , and Trevor Elliott held a workshop at StrangeLoop 2016 on designing, building, testing, and deploying microservices using unikernels. The team showed a simple microservice design using the HaLVM, and walked through how to build, test, and deploy it into Amazon’s cloud. Selling Unikernels: The CyberChaff Experience . QCon SF 2016. Dr. Adam Wick gave a talk about using unikernels to develop network defense software at QCon SF 2016 . Dr. Wick walked through the experience of developing of CyberChaff, a novel network defense solution with unikernels built into its core, why unikernels were appropriate, and the pros and cons of using unikernels in a project. CyberChaff: HaLVM unikernels protecting corporate networks , unikernel.org Dr. Adam Wick and Amir Chaudhry published an article detailing network defense through decoy hosts and the use of unikernels to implement CyberChaff securely. Adam Wick on Security, Formal Methods, Types, Unikernels, HaLVM, DRM (video), QCon 2015 In this interview, Dr. Adam Wick talks about cybersecurity in general and some common pitfalls and possible solutions when it comes to securing systems. Dr. Wick also walks through formal methods and proving program correctness as a possible solution to critical vulnerabilities. Unikernels are also discussed, as an approach to give attackers minimal attack surface for critical applications. The interview was recorded in 2015 and published in 2016. Datanauts 063: Unikernels vs. Containers (Datanauts Podcast) Just as containers are finding their place alongside virtual machines in the application landscape, unikernels are emerging as a container alternative. Unikernels strip down an application’s execution environment to the barest essentials, increasing efficiency and reducing attack surface. Dr. Adam Wick joins the Datanauts to explain unikernels and how they differ from containers, discuss what kinds of applications they run, and explore issues like networking, security, and orchestration. Encryption debate: The issue isn’t strong crypto, it’s easy crypto. NextGov. Isaac Potoczny-Jones published an article on the 2016 encryption debate on NextGov. In the article, Potoczny-Jones argues that, although strong encryption is perceived as a new development that has spurred the debate, it is actually easy to use and ubiquitous encryption behind it, with strong encryption having been available for a long time. Personal data services promise user privacy , Network Computing Isaac Potoczny-Jones published an article about Personal Data Services (PDSs) on Network Computing. In the article, Potoczny-Jones outlined the benefits of PDSs in situations where both strong user data privacy and the ability to share with user consent is required. Data analysis and machine learning CAFe: Coarray Fortran Extensions for Heterogeneous Computing , HIPS Workshop, IEEE IPDPS 2016 Dr. Matthew Sottile was part of a team that presented a paper on coarray Fortran extensions targeting emerging hybrid accelerator architectures at the 21st International Workshop On High-Level Parallel Programming Models And Supportive Environments ( HIPS ) at the 30th IEEE IPDPS conference. The paper presented preliminary work examining how Fortran coarray syntax can be extended to provide simpler access to accelerator architectures. Also part of the team: Craig Rasmussen, Soren Rasmussen, Dan Nagle, and William Dumas. Array Types for a Graph Processing Language . IEEE IPDPS 2016. Dr. Matthew Sottile and Dr. Mark Tullsen published a paper in the proceedings of 2016 Graph Algorithms Building Blocks Workshop at the 30th IEEE IPDPS conference presenting HAL (Hierarchical Array Language), a typed language for array processing. HAL was designed to efficiently process and operate with graphs, which are frequently represented and manipulated in the form of arrays encoding their adjacency matrices. Machine Learning, AI, and Cyber Security, at the Oregon Machine Learning Summit 2016 Dr. David Archer gave an invited talk on the intersection of machine learning and cyber security at the Oregon Machine Learning Summit. Dr. Archer argued that modern cyber conflict is an asymmetric battlefield where cyber network defense operators are at a disadvantage. Dr. Archer then presented the case for machine learning technologies such as anomaly detection and behavior classification as a means to level the battlefield by amplifying the attention of those defenders. Announcements, events, and releases Galois formally verified subcomponents of Amazon’s s2n SSL/TLS encryption library In collaboration with Amazon Web Services, Galois leveraged Cryptol and SAW to verify the HMAC algorithm in the s2n encryption library. Read more. Galois was awarded a $10m DARPA contract to make legacy systems more secure Galois announced a $10 million award by the Defense Advanced Research Projects Agency (DARPA) Cyber Fault-tolerant Attack Recovery (CFAR) program to make security vulnerabilities lurking in military and commercial legacy, embedded and other mission critical systems code bases unexploitable. The Galois-led team also includes Trail of Bits, Immunant, and University of California, Irvine. For more information, visit the project page . Galois and Guardtime Federal were awarded a $1.8M DARPA contract to formally verify blockchain-based integrity monitoring system Galois and Guardtime Federal announced they have jointly been awarded a $1.8 million contract by the Defense Advanced Research Projects Agency (DARPA) to verify the correctness of Guardtime Federal’s Keyless Signature Infrastructure (KSI). The contract will fund a significant effort that aims to advance the state of formal verification tools and all blockchain-based integrity monitoring systems. Galois was awarded a $6 million DARPA contract to address advanced persistent threats (APTs) in systems and networks Galois announced $6 million contract award under a Defense Advanced Research Projects Agency (DARPA) program to develop a system to detect Advanced Persistent Threat (APT) cyber attacks in increasingly complex enterprise network and system environments. The project aims to design a system that enhances network visibility to better detect, understand and manage APT attacks in complex network and system environments. The Galois-led team also includes the University of Edinburgh, PARC (a Xerox company), and the Oregon State University,  For more information, visit project page . Galois was awarded a $1.7 million DHS contract award to combat DDoS attacks Galois announced a $1.7 million contract by the Department of Homeland Security (DHS) Science and Technology Directorate (S&T) to create technology that is capable of defending against large and sophisticated Distributed Denial of Service (DDoS) attacks. The contract is part of the DHS S&T Cyber Security Division’s larger Distributed Denial of Service Defenses (DDoSD) program. For more information, visit the project page . Galois was awarded a $6.2 million DARPA contract to ‘crash test’ system privacy Galois was awarded a $6.2 Million contract by Defense Advanced Research Projects Agency (DARPA) to measure the privacy, performance and utility of systems for its Brandeis program, which is focused on developing tools and techniques for building systems in which private data may be used only for its intended purpose and no other. The Galois-led team also includes which includes the University of Pennsylvania, the University of Maryland College Park, The Hebrew University of Jerusalem and Charles River Analytics. For more information, visit the project page. Galois launched Free & Fair, an election technology spinoff that enables verifiable, transparent and secure elections Free & Fair provides elections services and systems meeting the same reliability and security standards as the US federal government demands for national security. For more information, see the original announcement and visit http://freeandfair.us . Galois launched Formaltech, a technology transition spin-off specializing in commercializing new technologies Formaltech turns cutting-edge technology research into application, computer, and network security products for cybersecurity OEMs, application developers and enterprises. For more information, visit https://formal.tech . CyberChaff at Reed College Formaltech, a Galois subsidiary, and Reed College, announced the deployment of CyberChaff on a core Reed network. CyberChaff an innovative network defense system that uses cyber deception to thwart detect and slow down advanced persistent threats on a network. For more information on CyberChaff, visit the Formaltech CyberChaff page . Undirector of Engineering Jef Bell , engineering and project lead at Galois, published a post explaining the unusual nature of the “director of engineering” position at Galois. The post details two attributes of how we organize ourselves at Galois: having no traditional managers, and leadership by council. Galois co-organized a day long workshop in hardware security with Intel and Mentor Graphics at Intel. The workshop focused on the challenges of designing, fabricating, verifying, and using secure hardware.  The workshop had over one hundred attendees from industry and academia. Galois hosted the third annual summer school on probabilistic programming As part of the ​Probabilistic Programming for Advancing Machine Learning ( PPAML ) program, Galois hosted the third of four annual summer schools on the topic. The two week program is designed to teach participants the necessary background on probabilistic programming languages being developed as part of PPAML, and give them an opportunity to work directly with the creators of these languages to solve their own problems using these tools. Galois spin-off Tozny announced developer preview of new secure database, E3DB E3DB is a NIST-funded tool for programmers who want to build an end-to-end encrypted database with sharing into their projects. For more information, visit the product page . Tozny announced Atlanta Streetcar ticketing app has Tozny authentication technology built-in. Atlanta Streetcar System launched a Moovel transit app today that leverages Tozny technology to enable secure, passwordless authentication. See Tozny announcement here . Galois released BLT , a solver for bounded integer linear programming problems BLT is a C/C++ library for solving certain integer linear programming (ILP) problems using techniques that come from the theory of lattices. It is complementary to many existing, traditional ILP solvers in that there are problems it solves very well and very quickly which traditional solvers do not. Galois released the Software Analysis Workbench (SAW), under a 3-clause BSD license. We announced that SAW, our formal verification platform, will be available under a 3-clause BSD license. Galois released ec2-unikernel , a tool to upload unikernels to Amazon EC2 The tool is designed to provide a single-step mechanism for uploading your unikernels to run on Amazon EC2. Galois released halvm-web , a simple web server for the Haskell Lightweight Virtual Machine (HaLVM). To learn more about HalVM, visit the github page. Galois released version 2.4.0 of Cryptol, a custom toolset to design and analyze cryptographic algorithms. To learn more about Cryptol, visit http://cryptol.net Galois released an updated version of FreeRTOS for Xen on ARM systems. Highlights of the update included improved compatibility with new versions of Xen and kernel relocation support. Galois released LandHere , an extension to the Intel x86_64 instruction set architecture The extension adds two features to help mitigate code-reuse attacks, Galois held 8 tech talks on a wide range of topics. Visit the tech talks page for a complete list and our Vimeo page for publicly available recordings. Press Coverage Highlights Galois elections technology spin off, Free & Fair, saw broad coverage and interviews in publications ranging from Techcrunch to Popular Science. For a complete list of elections related coverage, see the Free & Fair news page . Research coverage Computer Scientists Close In on Perfect, Hack-Proof Code , WIRED Even the US military is looking at blockchain technology – to secure nuclear weapons , Quartz Department of Homeland Security doles out $1.7 million for DDoS protection , The Washington Times. For New Cybersecurity Pilot Program, Collaboration Is Key . Government Technology. Consortium Partnership project to attack DDoS . Campus Technology Cool tech at AWS re:Invent , Network World Galois wins $6.2M contract to support DARPA data privacy program , Washington Technology. Portland tech firm Galois spins out new company to make elections more secure . Portland Business Journal DARPA looks to measure privacy protection , GCN DARPA Awards Galois $10 Million Contract To Secure Legacy Cyber Systems . Defense Daily Is Your Network Acting Odd? DARPA’s Latest Tool Aims to Sound the Alarm , Defense One New security tool addresses Android app collusion threat, BetaNews Interviews Isaac Potoczny-Jones: Minimum Viable App Doesn’t Mean Minimum Security , DevOps. Isaac Potoczny-Jones: Mobile security Q&A: Securing the mobile minimum viable app , CSO. David Archer Are cyber compliance requirements getting in the way of security? C4ISR David Archer: Marine Corps C2 platform unleashes mission critical data . C4ISR David Archer: DoD plans to bolster APT security , C4ISR Adam Wick: Zero day attacks: How DoD should defend from the unknown . C4ISR Other contributions Dr. Peter Trautman was a panelist at AAAI Symposium on Shared Autonomy in Research and Practice. Dr. Peter Trautman was a panelist at AAAI Symposium on Cross-Disciplinary Challenges for Autonomous Systems. Dr. Peter Trautman was a member of the program committee at the International Joint Conference on AI ( IJCAI 2016 ) Dr. Lee Pike was on the program committee at the Runtime Verification Conference Dr. Lee Pike was on the program committee at the International Symposium on Advances in Embedded Systems and Applications ( EMBEDDED’16 ) Dr. Lee Pike was on the program committee at NFM’16 (NASA Formal Methods Symposium) Dr. Lee Pike was on the program committee at FMCAD’16 Dr. Lee Pike was a reviewer for Air Force Office of Scientific Research Dr. Lee Pike was a NSF Panelist in 2016. Dr. Lee Pike was a guest editor Wireless Commuications, Networking, and Positioning with Unmanned Aerial Vehicles, IEEE Communications Magazine.Read the overview and the articles . Dr. Stephen Magill was a program committee member for the 2016 IEEE Computer Security Foundations Symposium (CSF) Dr. Stephen Magill was a program committee member for the 2016 International Conference on Trust & Trustworthy Computing (TRUST) Stephen Magill was a co-chair of the 2016 High-Confidence Software and Systems Conference (HCSS) Dr. Stephen Magill was the co-organizer of the 2016 Logic Mentoring Workshop (LMW) Dr. Stephen Magill was an NSF Panelist in 2016 Dr. Joe Kiniry participated in the Elections Verification Network (EVN) Coordinating Committee as part of a multi-year commitment to EVN. Dr. Joe Kiniry continued to be active on the Board of Advisors for Verified Voting, which primarily this year focused on the Presidential Election. Dr. Joe Kiniry was on the Editorial Board of the Journal of Elections Technology, the premier journal in the area of elections research. Dr. Dave Archer was a program committee member at the Workshop on Ubiquitous Sensing and Actuation (UbSA) via the Internet of Things, IEEE World Forum on IoT, December 2016 Dr. Dave Archer was the co-chair of Provenance-based Security and Transparent Computing, Provenance Week 2016 Dr. Alex Malozemoff was an external reviewer for PKC 2017, Eurocrypt 2017, and IEEE Security & Privacy 2017.", "date": "2016-12-29"},
{"website": "Galois", "title": "60 Minutes features DARPA, highlights Galois R&D work", "author": "Unknown", "link": "https://galois.com/blog/2015/02/60-minutes-galois/", "abstract": "Galois helped demonstrate security vulnerabilities in modern automobiles and small UAVs as part of a “60 Minutes” profile of DARPA. We also demonstrated our secure UAV autopilot technology as an alternative to the currently available software systems that are prone to remote takeovers and other security vulnerabilities. Watch the quadcopter demo below: The world’s most secure UAV software As a performer on DARPA’s HACMS (High-Assurance Cyber Military Systems) program, Galois was part of a team that produced a completely new set of provably correct and secure software that runs on commercial UAVs. The software was evaluated by an independent, world-class penetration testing team. The team was unable to gain remote access to the vehicle and the resulting work was dubbed as “likely the most secure UAV software in the world” by a noted US government cyber-security expert. We demonstrated the UAV software at the Pentagon on HACMS Demo Day in May, 2014. For the CBS “60 Minutes” report, we demonstrated an exploit that allows an attacker to completely take over a commercial, off-the-shelf UAV in flight. We then showed the same UAV running our high-assurance UAV software , not subject to any of the security vulnerabilities it was previously subject to. Galois also arranged for security researchers from the University of Washington (UW) to demonstrate an exploit that allows an attacker to completely take over a specific car model, remotely. The exploit was based on research done by the same UW team that showed cyber-security problems with modern automobiles and served, in part, as initial motivation for the HACMS program: http://www.cbsnews.com/videos/preview-darpa-dan/ We also demonstrated supporting work from other researchers, showing tethered vulnerabilities on other car models. Our goal was to demonstrate how widespread and unsolved these problems are and serve as motivation for improving the assurance of critical embedded systems. Since 1999, Galois has been performing computer science research and development services for the federal government. In addition to HACMS, Galois is currently involved in a number of active DARPA programs, including PROCEED , Plan X , and PPAML .", "date": "2015-02-09"},
{"website": "Galois", "title": "Part one: Verifying s2n HMAC with SAW", "author": "Unknown", "link": "https://galois.com/blog/2016/09/verifying-s2n-hmac-with-saw/", "abstract": "In June 2015, Amazon introduced its s2n library , an open-source TLS library that prioritizes simplicity. A stated benefit of this simplicity is ease of auditing and testing. Galois r ecently collaborated with Amazon to show that this benefit extends to verifiability by proving the correctness of s2n’s implementation of the keyed-Hash Message Authentication Code (HMAC) algorithm. To construct this proof, we used Galois’s Software Analysis Workbench (SAW). This is the first in a series of three blog posts (including part two and part three ) explaining the project, what we proved, and how we used SAW to prove it. Amazon’s s2n is now at the forefront of verification in cryptography libraries. We would like to thank the team at Amazon for taking such a forward-thinking approach towards the correctness of their library, and giving us the opportunity to collaborate on such a great piece of software. Why Verify? Cryptography libraries like s2n are responsible for much of the security and privacy you experience on the internet from day to day. They protect your credit card numbers, keep people from snooping on your video chats, and even keep your employer from finding out that you spend all day looking at cat pictures. Because of its importance, weak, incorrect, or misused cryptography is the root cause of a large number of security vulnerabilities on the web today. Because cryptography libraries take so much responsibility for our daily security, it is essential that they are correctly implemented. Verification is the ultimate in showing program correctness. Verification allows you to use mathematical reasoning to make strong statements about all possible program  behaviors. This is in direct contrast to testing, which can only make statements about the program behaviors covered by the test suite. Anyone who has programmed knows the pain of believing that they wrote a program perfectly, and even tested sufficiently, only to later find the strange edge case that causes everything to go wrong. For example, we can use SAW to prove that “for any message of length 64 bytes, and any key of length 64 bytes, the s2n_hmac function behaves correctly”. To make a statement of equivalent strength using testing you would need to have a test suite with ~1.7×10 308 tests. To allow you to easily conceptualize this number, if each test case were an inch long, you could use your chain of test cases to reach across the measurable universe ~4.8×10 279 times. To allow you to conceptualize that number, if each trip across the universe were an inch long you could use your chain of trips to reach across the universe… ok, we’d have to do this at least 9 times before we got to a number any of us would have a chance of fitting in our heads. In conclusion, if someone tells you they can verify such a property completely with test cases, you should jump on their spaceship and enjoy the ride. On the other hand, if the software contains an error that would trigger precisely one of those test cases, SAW will find that error within a minute, though we still won’t have a spaceship, intergalactic or otherwise. Specifying HMAC In order to prove a program correct, you need to state what it means to be correct. If you’ve learned what HMAC is, you’ve likely seen something like this: HMAC(K, m) = H((K' ⊕ opad) || H((K' ⊕ ipad) || m))\r\nopad = 0x5c5c5c…5c5c\r\nipad = 0x363636…3636 If you haven’t learned what HMAC is, you have now seen it too. In this formula, K is the secret key, m is the message to be authenticated, and is K’ a key of a specific size that is derived from K . ipad and opad and are constants used for padding. It is hard to deny the appeal behind such a specification. It is concise and unambiguous, and gives a complete description of how to implement HMAC if you want a correct implementation that nobody would like to use because it is inefficient (s2n’s implementation is correct and efficient; we’ll say more on that later). This mathematical definition appears in documents such as this IETF RFC or this FIPS standard . Such documents are some of the most widely examined specifications of what it means to be HMAC, and therefore the most likely to present a correct specification of a message authentication code. So to prove an implementation of HMAC correct, we should prove that it is equivalent to the mathematical specification. To facilitate such proofs, Galois has developed Cryptol , a domain specific language for specifying cryptographic primitives and proving properties of those primitives. Cryptol allows cryptographers to create executable programs that look like the mathematical notation commonly used in RFCs and FIPS standards. The Cryptol specification for HMAC (with comments denoting the related math) is: // H((K’ xor opad) || H((K’ xor ipad) || message))\r\nhmac hash hash2 hash3 key message = hash2 (okey # internal)\r\n where\r\n  ks : [blockLength][8]\r\n  ks = kinit hash3 key // K’\r\n  okey = [k ^ 0x5C | k <- ks] // K’ xor opad\r\n  ikey = [k ^ 0x36 | k <- ks] // K’ xor ipad\r\n  // H((K’ xor ipad) || message)\r\n  internal = split (hash (ikey # message)) The comments show how similar the structure of these two definitions really are. One noticeable quirk is that the Cryptol specification uses three different hash functions (hash, hash2, and hash3). This is due to a technicality in the type checker: Cryptol types for byte arrays include the length of those arrays and Cryptol does not allow for a function supplied as an argument to be used at multiple lengths (type theory folks will recognize this as Cryptol supporting rank-1 polymorphism). When using the Cryptol hmac function, we just pass the same hash function in three times, so the instantiation of hmac using the SHA256 hash function is given by: hmacSHA256 = hmac `{blockLength=64} SHA256 SHA256 SHA256 The argument in curly braces is a type that can’t be inferred automatically. Without that argument, the definition of hmacSHA256 would give an error, because Cryptol would be unable to determine blockLength . Proving the C code correct Cryptol allows us to describe, test, and manipulate the specification. To connect the specification to the implementation, Galois has developed another tool, the Software Analysis Workbench (SAW) to support reasoning about implementation code written in C or Java. In particular, SAW allows us to prove that the s2n C implementation of HMAC is equivalent to the Cryptol specification that we showed above. It takes a thorough inspection of the code (as well as some mathematical reasoning, and an understanding of the behaviors of hashes) to make a convincing argument that the C implementation does the same thing as the mathematical specification. There are 166 lines of C code (comments and whitespace excluded). Much of this is dedicated to remaining parametric over hash functions, as well as various safety checks, but still, the implementation is much more complex. This complexity results from implementing an efficient imperative interface broken into initialization, message update, and digest construction functions, which allows messages to be authenticated iteratively. This is perfect for network encryption protocols like TLS, because it allows messages to be authenticated a packet at a time, and decreases space requirements — the entire message does not have to be stored in memory in order to authenticate it. So there is some distance between the appearance of the source code and the mathematical object representing what its behavior should be. The job of SAW is to close that distance and show that, in fact, the code and the specification describe the same thing. SAW can prove equivalence between C, Cryptol, and Java programs, and it does this by performing symbolic execution on the input programs to create a formal model of each program. SAW then has rules to generate verification conditions, formulas in first-order logic, that if true for all values of all free variables in the formula, imply the equality of the two programs. Formulas of this type can, in many cases, be discharged completely automatically by a variety of SMT solvers such as Z3 , Yices , or CVC4 . SAW is capable of passing these formulas off to the aforementioned solvers (and more). If the solvers say that all of the verification conditions are true, SAW will report to the user that the equivalence between the two programs holds. If the solvers say that a verification condition is sometimes false, they will also provide a counterexample, which SAW is able to translate into program inputs that can be supplied to each program to force their outputs to differ. In summary, once the structure of the equality proof is given, SAW is able to automatically fill in the gaps, resulting in a proof of equivalence that can be re-run each time we change the code to continually check the correctness of the implementation. For example, we can create a test case that adds the following pseudocode to the HMAC update function: if (msg == “Mess up the hash, please”) \r\nthen (msg == “EEEEVVVILLLLLL”) Assuming that we didn’t accidentally program the same “bug” into our Cryptol spec, SAW will quickly return a message letting us know that if we run the update function with the admittedly polite message “Mess up the hash, please” we will see different outputs from the C code and the Cryptol code. Putting it all together We completed the verification and integrated the resulting proof checking procedure into s2n’s existing build system. With the help of Travis CI , every time there is a push to s2n, the SAW tests will be run and those runs will be visible to the public. It is also easy to install SAW yourself on a variety of platforms and use the s2n Makefile to test it on your local changes to s2n_hmac.c. The second post will go into more detail on the Cryptol specification, and how we got it ready for SAW verification. The third post will describe what work we need to do in SAW to describe to the tools exactly what equivalence we want to verify. The fourth post will be by request only, and we’ll type out the rest of the trips across the universe that you need to conceptualize an excessively large number of test cases. Just kidding, we won’t do that.", "date": "2016-09-04"},
{"website": "Galois", "title": "Update: FreeRTOS for Xen on ARM systems", "author": "Unknown", "link": "https://galois.com/blog/2016/07/update-freertos-xen-arm-systems/", "abstract": "We are pleased to release an updated version of our work on FreeRTOS for Xen on ARM systems. This release extends our port of FreeRTOS 7.6.0 to run on Xen 4.7. Highlights of this update include: Improved compatibility with new versions of Xen by using Xen’s guest device tree to obtain interrupt controller and Xen service configuration details Kernel relocation support FreeRTOS is an open-source real-time operating system for embedded devices with limited resources. This project modifies FreeRTOS to run as a Xen guest, which allows lightweight real-time virtual machines to run alongside and communicate with other Xen-supported guest operating systems. The FreeRTOS port is one of our most recent projects in the Xen community, which include the Haskell Lightweight Virtual Machine (HaLVM) and our MAC-enhanced version of the XenStore. To get started with the FreeRTOS port, visit the project’s GitHub page and see the original announcement.", "date": "2016-07-26"},
{"website": "Galois", "title": "Undirector of Engineering", "author": "Unknown", "link": "https://galois.com/blog/2016/06/undirector-of-engineering/", "abstract": "At times, we have advertised to hire a Director of Engineering, but the first line of the job description says “Director of Engineering is a role, not a job title, and we don’t call it Director of Engineering anyhow.” What does that mean? To explain, I’d like to talk about two ideas driving how we organize ourselves at Galois: no managers, and leadership by council. No managers. We don’t have managers in a traditional sense, nor do we have a fixed hierarchical organizational structure. Still, the cornerstone of our org structure is the relationship between internal customers and performers, just as the relationship between a manager and a direct report is key in a traditional structure. In a customer role at Galois, one or more performers are fully accountable to you, but only for the results they have committed to producing specifically for you. Performers typically have multiple customers (accountable to each of them for a different set of results). We are a project-based company, so this idea comes pretty naturally. I might be accountable to the Project Lead (PL) of the Alpha project for Alpha results, and accountable to the Beta project PL for Beta results. And at the same time, I could be a PL myself on the Gamma project, with performers accountable to me for Gamma results. Where it gets weird is that a Gamma performer could also be my Beta PL, so I’m both performer and customer to the same person. These cycles work because “Project Lead” is not a position, it’s a role, and we all have the opportunity to take on many roles. So, rather than having a typical org chart that looks like an upside-down tree that changes slowly over time, ours can be visualized as a densely-connected, frequently-changing web of customer/performer relationships. In fact, we call our organizational structure the Collaborative Web. Because the majority of Galwegians are in at least one customer role, and because of cycles in the org chart, there aren’t always clear hierarchies in parts of the organization, nor is there really a “top” of the org chart—even our CEO is at times in a performer role to other Galwegians. As I mentioned, these customer/performer relationships, and how roles are inhabited, change all the time. When the Gamma project ends, I may no longer be a Project Lead, at least until another suitable project starts, but I continue to be a performer on Alpha and Beta. And when the Omega project starts and I’m interested in contributing, I talk to the Omega PL to negotiate a set of results, and may also need to renegotiate my results with the Alpha or Beta PLs. As you can see, all of this is self-directed: I choose the roles I’d like to take on, make offers to perform in that role to appropriate customers, and negotiate results with those customers. Of course, this is tempered by the fact that there is a finite set of projects and other work opportunities, so I may not always get my first choice of roles, or projects. Leadership by council. It’s probably not surprising to hear that technologists often have little desire to be managers, and that the notion of climbing the management ladder is largely foreign. After all, they are in their chosen field because they are deeply passionate about technology, and have invested themselves (often since childhood) in learning about and practicing with the technologies they love. Becoming a manager distracts from that passion, and consumes time that could otherwise be spent geeking out, building or investigating. This is not to say career advancement is unimportant, but that advancement is typically focused on learning, taking on broader and more influential technical roles, and thus gaining the respect of peers. Suspicion between management and engineers is in my experience often rooted in the (real or perceived) lack of technical competence by managers. And this suspicion is warranted if the manager doesn’t really have the technical background/experience relevant to the project they are leading. Technical competence is required to communicate well with the team, to earn their respect, and to make even slightly-technical decisions. So how does the occasional geek that wants to be a good leader manage to stay technically competent so they can be a good leader, and how do they do that without abandoning their passion for technology? One thing that helps us with this is our use of councils. The Engineering Council (okay, nobody calls it that, everyone calls it the Jedi Council) jointly leads the engineering team, sharing the accountabilities that a Director of Engineering would “normally” hold. None of us are full time council members, which allows each of us to stay involved in the technical work as an individual contributor and/or PL. At any time, we’ve had 4 to 8 members of the council. Some stay on it for the long term, and some for a year or so. We work to ensure that there is a good mix of representation of various engineering roles on the council—PLs, researchers, and developers. Many council responsibilities are held by a single person on the council, such as leading hiring efforts or overall budget management. Other responsibilities are shared, such as annual planning or being a point of contact for the council with other engineers. Smaller council roles allow an engineer to dip their toes in the water and see if that kind of leadership role appeals to them, without having to make a big change in their career path. One role that every councilor holds is Jedi Customer. This focuses on ensuring that an engineer is gaining personal value from their engineering roles, that they are getting any support they need in finding project work, and that they are providing accurate predictions about how much time they’ll be spending on project work, as our business model is based on billable hours. Council Caretaker is a special council role, making sure the council keeps running, and serving as a customer to councilors for their council results. The Caretaker role has moved from person to person every two to three years. Personally, I’ve been on the Jedi Council since we formed it nearly 10 years ago. Over that time I’ve worked in nearly every role on the council, some of which I liked and/or was good at, and some I didn’t like or do as well at. The council structure has given me the chance to explore and grow (or I wouldn’t have stayed for 10 years!) That’s another benefit of the council approach—it lets councilors play to their strengths, and doesn’t rely on us being somehow able to find the Director of Engineering who’s strong in all areas (and incidentally, who would be a single point of failure). Lest I paint too rosy a picture, let me point out some thorns. With many people involved in engineering leadership, a lot of communication amongst council members is necessary. Likewise, it’s not always obvious to an engineer who is the best councilor to go to for a particular issue. So it’s not always the most efficient approach, but we do believe it’s a very effective approach. So, when we are looking for a “Director of Engineering” we are actually looking for a Technically-Capable Jedi Councilor and Project Lead. That just doesn’t sound as good in a job ad. If you’d like to learn more about the Collaborative Web, see this paper on the topic, or send me an email at jefb@galois.com .", "date": "2016-06-30"},
{"website": "Galois", "title": "CyberChaff at Reed College", "author": "Unknown", "link": "https://galois.com/blog/2016/05/cyberchaff-reed-college/", "abstract": "Formaltech, a Galois subsidiary, and Reed are excited to celebrate CyberChaff’s first month of service at Reed. Formaltech’s CyberChaff allows you to deploy low-cost, secure decoy hosts on a network. The hosts alert administrators when an attacker is detected while also slowing down key steps in the attacker’s workflow. In March, Galois and Formaltech engineers installed CyberChaff on a core Reed network during Reed’s Spring Break, and have been slowly expanding the CyberChaff presence since then. During this period, Reed has been able to use CyberChaff to detect and address anomalies on their network. Visit the announcement for more information.", "date": "2016-05-18"},
{"website": "Galois", "title": "New BSD-Licensed SAW Release", "author": "Unknown", "link": "https://galois.com/blog/2016/04/new-bsd-licensed-saw-release/", "abstract": "A new release of the Software Analysis Workbench (SAW) is now available! This release includes a large collection of new features and bug fixes enabling verification of a wider variety of Java and LLVM programs. A list of changes is available here , along with binaries for a variety of platforms. Additionally, this release changes the license of SAW to the standard 3-clause BSD license (replacing the previous license that allowed only non-commercial use). Our goal is for this license change to encourage wider adoption of the tools, and to facilitate the construction of new tools on top of SAW.", "date": "2016-04-14"},
{"website": "Galois", "title": "Galois: 2015 highlights", "author": "Unknown", "link": "https://galois.com/blog/2015/12/galois-2015-highlights/", "abstract": "2015 was an active and productive year at Galois. From numerous awards, to new projects and spin-offs, to a vast array of publications and talks, Galwegians contributed to a wide range of fields this year. Below, we highlight some of the contributions we made in 2015. Overview In our core fields of cryptography and formal verification we further delved into secure computation , the groundbreaking process of using sensitive, encrypted data without decrypting it. We also shared formal verification methods and tools that ensure code correctness and minimize exploitable flaws. Finally, we announced a public preview of the Software Analysis Workbench (SAW) , a toolset that leverages automated SAT and SMT solvers to formally verify properties of code. Relating to cybersecurity, we explored using unikernels for increased security and resource efficiency. We wrote numerous articles in national publications on computer security, network security, data privacy, and mitigating IoT vulnerabilities. Galois technical staff were quoted on articles about election systems, vehicle security, and cybersecurity in general. In 2015, we expanded into a relatively new field for us: the transparency and reliability of election systems . We were part of a team that released a comprehensive study on the feasibility of Internet voting . We also presented a variety of publications and talks on the transparency and trustworthiness of election systems. Our contributions included speaking before the San Francisco Election Commission on the benefits of open source software for elections technology. This year we also made a significant number of contributions on the topic of the security and reliability of cyber-physical systems . We presented practical tools and methods to secure vehicles like UAVs and automobiles, making them invulnerable to a wide range of vulnerabilities. One paper detailed a comprehensive approach to securing the automobile that would start to address the cyber reliability of today’s automobiles. Other publications presented programming languages that can produce secure software for embedded systems. Our work on securing UAVs and automobiles was also featured on national media several times throughout the year. This year, Galois and Tozny , our mobile security and identity spin-off, announced a $1.86M award from the National Institute of Science and Technology (NIST) to build a secure data storage system that enables next-generation IoT capabilities without sacrificing privacy. We announced three other major awards , and won many more. We also announced a new spin-off, Sailfan Research , that provides data analytics services in audio, video, and signal analysis. Below you will find some of the intellectual contribution highlights of 2015 by field. Happy holidays from everyone at Galois; we wish you the best in the year to come. Cryptography Computing with Data Privacy: Steps toward Realization . IEEE Security & Privacy, 2015 Dr. David Archer , Galois’s Cryptography Research Lead, and Prof. Kurt Rohloff of the New Jersey Institute of Technology published an article for the IEEE Security and Privacy magazine on the topic of groundbreaking process of computing on sensitive, encrypted data without decrypting it. The method has major implications for businesses that would benefit from sharing data, yet need to keep that data private. The article looks at two new cryptographic methods: linear secret sharing (LSS) and fully homomorphic encryption (FHE). Maturity and Performance of Programmable Secure Computation . IACR Cryptology, 2015 Dr. David Archer was part of a team that published a paper reviewing the results of U.S. and European secure computation research programs and other published literature to present the state of the art in what can be achieved with today’s secure computing technology.  The team also included Dan Bogdanov, Benny Pinkas, and Pille Pullonen. Applying Satisfiability to the Analysis of Cryptography . SAT 2015 Dr. Aaron Tomb , Galois’s Software Correctness Research Lead, delivered an invited talk on applying satisfiability to the analysis of cryptography at SAT 2015, the International Conference on Theory and Applications of Satisfiability Testing. In the talk, Dr. Tomb walked through the properties of cryptographic code that are within the reach of existing solvers, and described some of the tools in applying SAT solvers to cryptographic algorithms. Find the full abstract here , the slide deck here , and a collection of examples here . Encrypting strings in Android: Let’s make better mistakes Tozny , Galois’s mobile security and identity spin-off, released an open source Android class for encrypting and decrypting strings after a review of commonly available encryption code found online revealed serious flaws in most libraries. Watch Isaac Potoczny-Jones ’s talk on the topic here . Don’t be a Monkey: Do Crypto Right . BSides PDX 2015 Dr. Dylan McNamee and Dr. Joe Kiniry held a workshop at this year’s BSides PDX conference on implementing correct cryptographic code. In the two-part workshop, McNamee and Kiniry walked through using Galois’s Cryptol and other tools to verify that C and Java crypto implementations match the specification, ensuring that crypto implementations are free of bugs, and using Microsoft Research’s F* tool and others to specify, reason about, and synthesize code for crypto protocols. High Assurance Cryptography Synthesis with Cryptol . HCSS 2015 Dr. Joe Kiniry presented a set of new backends for Galois’s open source Cryptol toolset and the Galois Software Assurance Workbench ( SAW ). The backends are capable of synthesizing formally verified implementations and test benches for arbitrary cryptographic algorithms, and target C, JCM, CHDL, and Verilog and will produce Cryptol-independent evidence of the synthesized code’s correctness. Formal methods and verification Multi-Language and Multi-Prover Verification with SAWScript . HCSS 2015 Dr. Aaron Tomb demonstrated SAWScript , Galois’s software analysis orchestration tool, at HCSS 2015. Dr. Tomb demonstrated using SAWScript to verify multiple programming languages using multiple provers.  An integrated, interactive environment, SAWScript allows an automated and integrated proof process, replacing what would otherwise have been a tedious and error-prone effort of manually combining results from a collection of subsidiary proof attempts. SAWScript has been used to verify equivalence of a number of production-quality algorithms, including implementations of Suite B cryptographic primitives from the OpenSSL and BouncyCastle libraries. This talk demonstrated the use of SAWScript on a number of examples of verification and analysis. Frama-C at Galois. Frama-C Day at CEA Dr. Aaron Tomb gave a talk at the 2015 Frama-C Day about the ways in which Galois is using Frama-C or may use it in the future. It covered using Frama-C to verify unannotated programs, inspired by work on STORM ; application of Frama-C to verifying a fragment of the kLIBC library; and the potential use of Frama-C to verify code generated by Ivory or Cryptol . Model checking distributed mandatory access control policies . ACM Transactions on Information and System Security, 2015 Dr. Lee Pike was part of a team that published a paper on model checking techniques to verify system-level security properties of a collection of interacting machines. The paper examined how local access control policies can be shown to satisfy global access control constraints. Also part of the team were Peter Loscocco, NSA, and George Coker, NSA. Bounded Integer Linear Constraint Solving via Lattice Search . SMT Workshop 2015 Dr. Benjamin Jones and Dr. Joe Hendrix published a paper presenting a novel algorithm for solving integer linear constraint problems of the form l ≤ Ax ≤ u. The algorithm, and the ensuing solver, was motivated by efforts to apply SMT solvers to signal processing algorithms. In particular, the paper describes the problem of reversing JPEG, that is, finding compressed data that decompress into an image satisfying given constraints. From the abstract: “This problem can be expressed as a bounded integer linear constraint problem, but was intractable to the SMT solvers we tried. In contrast, BLT is able to solve many of the examples in seconds, including both SAT and UNSAT problems.” Formal methods at Galois. Workshop on Formal methods for Robotics: benchmarks and evaluation metrics Dr. Peter Trautman gave an invited talk at the Workshop on Formal Methods for Robotics on formal methods work at Galois. Dr. Trautman talked about current results, ongoing work, and future challenges, and touched on Galois’s work on DARPA’s HACMS program. Ten years of Layered Assurance at Galois, lessons learned and looking forward Dr. Dylan McNamee gave an invited talk at the Layered Assurance Workshop of the 2015 Annual Computer Security Applications Conference, describing Galois’s work in the areas of using composable architectures to build high assurance cross domain systems, cyber-physical systems, and cryptographic systems. Cyber-physical systems and robotics Guilt-free Ivory . Haskell Symposium, 2015 A team of Galwegians published a paper detailing Ivory, a programming language for writing secure, high-assurance software for embedded systems such as those found in automobiles, UAVs, etc. Software written in Ivory is guaranteed to be memory safe and is provably invulnerable to large classes of attack. The paper provides a detailed overview of the Ivory language, semantics, implementation in the GHC type system, and the built-in tools for testing and verification. Ivory was designed and implemented as part of DARPA’s High Assurance Cyber Military Systems ( HACMS ) program and was used to write a secure UAV autopilot. The Galois team was comprised of Trevor Elliott , Lee Pike , Simon Winwood , Pat Hickey, James Bielman , and Jamey Sharp . Also part of the team were Eric Seidel, UC San Diego, and John Launchbury, Willamette University. Securing the Automobile: a Comprehensive Approach .  Embedded Security in Cars (ESCAR) A team of Galwegians published a paper on securing the automobile, which was presented at the Embedded Security in Cars ( ESCAR ) Conference in May. The paper walks through a comprehensive approach to secure the modern automobile, taking into account static assurance, dynamic assurance, software, and networks, while considering the constraints of the automotive industry. The team comprised of Galois’s Lee Pike , Jamey Sharp , Mark Tullsen , Pat Hickey, and James Bielman . Programming Languages for High-Assurance Autonomous Vehicles , VSTTE 2015. Dr. Lee Pike gave the keynote talk on July 19 at the Conference of Verified Software: Theories, Tools, and Experiments. He described the use of embedded domain-specific languages to improve programmer productivity and increase software assurance in the context of building a fully featured autopilot for unpiloted aircraft. Assuring the Guardians . Runtime Verification, 2015 Dr. Lee Pike , Galois’s Cyber-Physical Systems Research Lead, was part of a team that published a paper describing a framework for verifying runtime monitoring systems that check ultra-critical autonomous systems. Runtime verification involves monitors that detect and respond to stability issues and failures of critical systems at while they are running. The tools described in the paper are integrated in Copilot , a language developed by Galois and NASA to write runtime monitors for critical systems that detect software and system failures in critical systems. Also part of the team were Alwyn Goodloe, NASA Langley Research Center, and Jonathan Laurent,  École Normale Supérieure. Trustworthy Software in the Real World . Open Source Bridge 2015 Jamey Sharp presented SMACCMPilot , a high-assurance quadcopter autopilot developed as part of DARPA’s HACMS program, and the new tools and technologies that make it feasible to trust a large piece of software. In the talk, Jamey introduced tools for improving software quality that have been traditionally restricted to academia, and talked about how engineers can apply similar tools in real world-critical systems like vehicles, medical devices, banking systems, etc. Read the abstract here and watch the video here . Assistive Planning in Complex, Dynamic Environments: a Probabilistic Approach .   HRI 2015 Workshop on Human Robot Teaming Dr. Peter Trautman presented a paper on shared control at Human Robot Interaction (HRI) 2015. From the abstract: “Shared control fuses human inputs and autonomy inputs into a single command.  However, if the environment or the operator exhibits ambiguity (common to search and rescue robots, teleoperated robots facing communication degradation, assistive medical devices, and assistive driving technologies), many state of the art approaches (e.g., linear blending) are suboptimal with respect to safety, efficiency, and operator-autonomy agreement—see our recent paper at http://arxiv.org/pdf/1506.06784.pdf .  To prove and rectify the above sub-optimalities, we introduced probabilistic shared control (PSC), which simultaneously optimizes autonomy objectives and operator-autonomy agreement under ambiguous conditions.  Importantly, because PSC optimizes operator-autonomy agreement, it exhibits stronger ‘centaur’ like properties than the state of the art: PSC naturally leverages the complementary abilities of the human and the machine.” Other shared control contributions in 2015 included a conference paper at Systems man and cybernetics , and talks at the Interactive Robotics group at MIT , Oregon State university robotics lab , and the Safe and Secure Systems Symposium (S5). Elections technology Elections technology and the benefits of open source software , San Francisco Elections Commission Dr. Joseph Kiniry , Galois’s election systems expert, spoke before the Elections Commission of San Francisco on open source software and the benefits it will bring to elections technology.  Dr. Kiniry also touched on the barriers that have kept open software from manifesting in the elections world until now. Find our responses to the questions posed by the Elections Commission on this topic here . Listen to the recording here . The Future of Voting: End-to-End Verifiable Internet Voting – Specification and Feasibility Study , National Association of Secretaries of State Galois’s election systems team, in collaboration with the U.S. Vote Foundation, a team of elections experts, and the Democracy Fund, published a comprehensive study on the feasibility of conducting secure elections online. Starting from the premise that public elections in the U.S. are a matter of national security, the report explores whether End-to-End Verifiable Internet Voting (E2E-VIV) systems are a viable and responsible alternative to traditional election systems. It contains the most complete set of requirements to date that must be satisfied by any Internet voting system used in public elections. The team included experts in election integrity, election administration, high-assurance engineering, and cryptography. The U.S. Vote Foundation, the Democracy Fund, and Galois presented the report at the National Association of Secretaries of State (NASS) Conference in Portland, Maine. Promises of Technology to Increase the Transparency and Trustworthiness of Elections , Voting and Elections Summit Dr. Joseph Kiniry gave a talk on the promises of technology to increase the transparency and trustworthiness of elections at the Voting and Elections Summit. Dr. Kiniry discussed the trade-offs that election officials face when considering currently available election technology systems. He also outlined some of the benefits that well-built elections systems offer to voters and officials, including efficient voting, verifiability, auditing, and accountability. The Impact of Legislation on Election Systems: Design, Cost and Lifespan Dr. Joseph Kiniry was a member of a panel on the impact of legislation on election systems at the National Conference of State Legislators (NCSL). Find Galois’s comments here . Cybersecurity 7 Cyber security questions to expect to answer after OPM breach . Government Computer News In the wake of the OPM breach, Dr. David Archer and a team of Galwegians presented a set of questions that officials in private companies and public institutions can ask to quickly assess the security stance of an organization. The piece included example answers that would give confidence that a sound security stance is an active priority. The article also lists key, practical steps an organization can follow as a first step toward a positive security stance. Tor in Haskell & Other Unikernel Tricks . QCon 2015 Dr. Adam Wick , Galois’s Systems Software and Mobile Security Research Lead, gave a talk at QCon 2015 about implementing the Tor anonymity system using unikernels, which are single-purpose, lightweight virtual machines. The talk discussed the aspects of Tor that make it an attractive target for unikernels, what it took to build a Tor unikernel, and what actual challenges developers will face when implementing real-world systems. An Introduction to Unikernels with the HaLVM . StrangeLoop 2015 Adam Wick , Trevor Elliott , and Adam Foltzer introduced unikernels in a workshop at StrangeLoop 2015. The attendees were introduced to Galois’s open-source Haskell Lightweight Virtual Machine (HaLVM) and were guided through using unikernels and building lightweight web services. IoT security and passwords on Network Computing Isaac Potoczny-Jones , CEO of Tozny and Galois’s Mobile Security and Identity Research Lead, published two educational articles around network computing, on the topics of IoT and password security. The articles explore IoT vulnerabilities and alternative approaches to building protection in IoT devices, as well as why passwords are inadequate security measures in today’s world: IoT Security and Privacy: Reducing Vulnerabilities Why We Need To Move Beyond Passwords Strategies for building cyber security into software development . Software Magazine Isaac Potoczny-Jones wrote an article on what vendors can do to build cyber security into their products from the start. “Cyber security should not be an afterthought in the software development process; it should be the first thought. As applications, systems and devices increasingly fall victim to hacks, vendors may be tempted to assume that business users and consumers have become desensitized to the problem. That adding two-factor authorization or offering three months of credit monitoring service will somehow wipe the slate clean with no damage done to brand perception, customer growth, and revenues. This is not the case. Building cyber security into the front end of the software development process is critical to ensuring software works only as intended.” Network defense, secure computation, and email security on “The State of Security” Dr. David Archer , Galois’s Cryptography Research Lead, published three educational blog posts for Tripwire’s “The State of Security” blog. The posts introduced innovative ways to defend networks against malicious attackers, new methods to keep data encrypted and secure while in use, and what can be done to avoid spam and phishing attempts through email. Asymmetric Network Defense: It’s 1904 All Over Again Secure Computation and The Right to Privacy Killing Phish the Sumerian Way Acoustic Kitty and Zombie Home Appliances: Yesterday’s Theories Shape Tomorrow’s Technologies . Signal Magazine Dr. David Archer wrote an article for AFCEA’s Signal magazine on the potential damage from compromised IoT devices on the battlefield, and what can be done to protect the cybersecurity of the troops of tomorrow from determined adversaries. The unrealized potential of interagency total information sharing . Government Computer News Dr. David Archer wrote an article for Government Computer News on interagency total information sharing, why it can be ineffective and the path forward for total information sharing systems that benefit national security without sacrificing privacy. Other announcements and launches Galois announced a $6.3M DARPA contract to research private data as a service Galois announced a $6.3M award for our Jana project as part of DARPA’s Brandeis program, which aims to develop tools and techniques for building systems in which private data may be used only for its intended purpose and no other. The awarded project, a collaboration between Galois, the University of Bristol, Rutgers University and George Mason University, aims to provide a practical implementation of private data as a service (PDaaS), which would allow data to be protected against misuse while retaining its utility to analysts. Galois announced DARPA sub-contract to strengthen supply-chain protection of electronic components Galois announced a sub-contract by SRI International under a DARPA’s SHIELD program to protect against counterfeit electronic components and associated security concerns by introducing low-cost secure authentication components in the hardware supply chain. Building upon our 15-year history developing defensive cybersecurity technologies, Galois’s effort will focus on cryptography, secure network protocols, and authentication. Tozny and Galois announced $1.86M NIST award to secure IoT-enabled smart homes Tozny and Galois were awarded a $1.86 million NIST National Strategy for Trusted Identities in Cyberspace (NSTIC) grant to build a secure data storage system that enables next-generation IoT capabilities without sacrificing privacy. Galois’ authentication and mobile security subsidiary, Tozny, will serve as the technical lead for the NSTIC pilot program. Galois was awarded $1.7M DHS contract create DDoS defense technologies. DHS announced a $1.7M award for Galois to create technology to defend against large and sophisticated Distributed Denial of Service (DDoS) attacks. The project, called “DDoS Defense for a Community of Peers,” uses a unique collaborative model wherein multiple organizations work together to detect DDoS attacks, compute mitigations, and convince service providers to take action. For more information, visit the project page . Galois launched the Software Analysis Workbench, a toolset to formally verify code properties Earlier this year we launched the Software Analysis Workbench ( SAW ) provides the ability to formally verify properties of code written in C, Java, and Cryptol . It leverages automated SAT and SMT solvers to make this process as automated as possible, and provides a scripting language, called SAW Script, to enable verification to scale up to more complex systems. Galois launched Fuse Analyzer to help with Android permissions’ migration and app security Fuse Analyzer, a tool that resulted from a DARPA-funded SBIR, launched earlier this year. The tool provides Android developers two capabilities: Prepare for Android 6 migration by discovering and fixing unhandled permission requests Analyze Android apps for security issues, data leaks, and weak encryption Galois’s secure UAV tools were featured on 60 Minutes Galois helped demonstrate security vulnerabilities in modern automobiles and small UAVs as part of a “60 Minutes” profile of DARPA. We also demonstrated our secure UAV autopilot technology as an alternative to the currently available software systems that are prone to remote takeovers and other security vulnerabilities. Galois launched haskell-tor , a Tor client written purely in Haskell Haskell-tor is the beginning of a full-featured Tor replacement written in a high-level language. Through integration with the HaLVM , haskell-tor offers an opportunity to for large numbers of lightweight Tor nodes, each of which is free from common classes of errors, with critical properties preserved by the type system. Entrepreneurship and angel investing Entrepreneurial Expertise and the Use of Control, Journal of Business Venturing Insights 2015 Dr. Rob Wiltbank , Galois CEO, was part of a team that published a paper on the effect that entrepreneurial expertise has on control and prediction strategies to to situations which vary in environmental predictability and controllability. Results show that entrepreneurial expertise yields significant decision-making improvements in the situational use of control strategies – those strategies conceptually associated with uncertain new ventures, products, and markets. The team also included Nicholas Dew, Stuart Read, and S.D. Sarasvathy. Investment and Returns in Successful Entrepreneurial Sell-outs , Journal of Business Venturing Insights Dr. Rob Wiltbank was part of a team that published a paper examining returns to capital invested in new ventures. The research looked at 3000+ private firms that were acquired by U.S. publicly traded firms and revealed that, while new venture growth is positively related to invested capital, terminal value of the venture and entrepreneur returns see steeply diminishing returns to invested capital. The results indicate that the primary benefit of equity investment is accelerated liquidity, not terminal value of the venture or entrepreneurs returns. Dr. Wiltbank was part of a team that also included Nicholas Dew and Stuart Read. The Role of Personality in Angel Investing . International Journal of Entre. & Innovation 2015 Dr. Rob Wiltbank was part of a team that published a paper examining the relationship between an entrepreneur’s personality and angel investor evaluations of the management team of venture opportunities. The research also analyzes the influence of an entrepreneur’s start-up experience and the angel investor’s investing experience on the evaluation of the management team. Results suggest that investor ratings of management teams are influenced by the personality traits of the lead entrepreneur. Dr. Wiltbank was part of a team that also included Charles Y. Murnieks, and Richard Sudek Media coverage highlights Covering Galois projects: Engadget: The Pentagon wants unhackable drone helicopters by 2018 GCN: Galois wins DARPA funding for private data as a service GCN: Making mobile phones the authentication hubs for smart homes ZDNet: NSTIC commits $3.7 million to new round of identity pilot programs Quoting experts from Galois: Isaac Potoczny-Jones on C4ISR & Networks: DoD embraced public key infrastructure to secure tactical networks Isaac Potoczny-Jones on KGW: The Internet of Things: How safe is ‘smart’ technology? Joseph Kiniry on Washington Post: Can you vote for the next president on your smartphone? Not just yet. Joseph Kiniry on Computerworld: Internet voting isn’t ready yet, but it can be made more secure Lee Pike on Nextgov: Pentagon on Path to Launch Hacker-Proof Boeing Drone by 2018 – Nextgov.com Robert Wiltbank on Forbes: How To Tell If An Entrepreneur Will Be Effective? What Angels Need To Know – Forbes Robert Wiltbank on Geekwire: More cash for startups: Median angel investment round size increases in Q3 Lee Pike on GCN: Can tech deliver a drone defense?", "date": "2015-12-29"},
{"website": "Galois", "title": "Joe Kiniry Joins Galois as Principal Investigator", "author": "Unknown", "link": "https://galois.com/blog/2014/02/joe-kiniry-joins-galois-as-principal-investigator/", "abstract": "Joe Kiniry has recently joined Galois as a Principal Investigator. He was previously an academic in Europe for twelve years, most recently a Full Professor at the Technical University of Denmark. He has extensive experience in formal methods, high-assurance software engineering, foundations of computer science and mathematics, and information security. Specific areas that he has worked in include software verification foundations and tools, digital election systems and democracies, smart-cards, smart-phones, critical systems for nation states, and CAD systems for asynchronous hardware. Joe is really excited to be working at Galois. He has been a fan of Galois, as it is a “darling of the formal methods community,” for many years. “Galois is full of super-sharp researchers and engineers doing really interesting work on hard problems. I look forward to furthering the Galois mission of applying formal methods for good.” Read more about Joe here .", "date": "2014-02-13"},
{"website": "Galois", "title": "Fuse Analyzer: Handling runtime permissions in Android 6.0", "author": "Unknown", "link": "https://galois.com/blog/2015/10/fuse-analyzer-handling-runtime-permissions-android-6-0/", "abstract": "Galois just announced a tool to help Android developers migrate apps to Android 6, while making the best use of the new Runtime Permissions feature. The Galois tool, Fuse Analyzer: Permissions, analyzes binary Andorid APKs to find the locations where you, as a developer, need to handle permissions more carefully in Android 6. The new Runtime Permissions feature brings about a significant change to the way apps handle permissions–the access control mechanism that prevents apps from freely accessing private details or device capabilities. This change is likely to cause applications to crash or misbehave if they are not updated properly because user’s can, for the first time, say “no” to an application’s request for a permission. Previously, Android apps requested all permissions when they were installed. That’s how an app would gain access to, for example, the Internet, the camera, the microphone, and so on. If users wanted to install an app, they had to approve all the permissions. Android M will allow users to pick and choose what permissions are OK when an application actually needs access. This model is familiar to any one using iOS, and the Android user experience will probably be similar. However, this approach is entirely new for Android developers. Now, it’s not strictly required that your use the runtime permissions feature — apps can still declare the permissions in the traditional way, and require that they are approved at install time. However, either Google, or simply market expectations will eventually shift that requirement. Furthermore, users can still retroactively revoke access to so called “dangerous” permissions for apps that have already been installed. These may even be apps installed before upgrading to Android 6. When that happens, the apps get a “null” result. Android developers need to start handling every method call that is protected by a dangerous permission very carefully. These calls must be guarded by a check to see if the application currently has access to that permission, and if not, properly ask the user for that access or behave in a reasonable way without access. If your app does not make that check or it does not have access to the permission then it must at least handle the potentially null results. Updating an app to perform these checks would not be particularly difficult, but there is no public list of methods that require permissions. That makes it quite difficult for developers to find the places that they need to make changes — in practice, this is going to be extremely time consuming, and the Google advice is to test, test, and test: If your app targets the M Developer Preview, you must test that it handles permissions properly. You cannot assume that your app has any particular permissions when it runs. When the app is first launched, it is likely to have no permissions, and the user can revoke or restore permissions at any time. You should test your app to make sure it behaves properly under all permission situations. With the M Preview SDK, we have provided new Android Debug Bridge (adb) commands to enable you to test your app with whatever permissions settings you need to try. — https://developer.android.com/preview/features/runtime-permissions.html#testing You try out Fuse Analyzer: Permissions for free at http://fuseanalyzer.com . It presents a list of the locations in your application that need attention. Fuse Analyzer can do a lot more than that: the Complete version can check for a couple dozen assorted security-related problems , and if you’re interested in that level of detail, we’d really like to talk with you in detail! For now, you can try out Fuse Analyzer: Permissions on three apps for free, and buy additional scans for a few dollars each.", "date": "2015-10-28"},
{"website": "Galois", "title": "Open source elections technology: Responses to the San Francisco Elections Commission", "author": "Unknown", "link": "https://galois.com/blog/2015/10/open-source-elections-technology-responses-san-francisco-elections-commission/", "abstract": "We recently had the privilege of speaking before the San Francisco Elections Commissio n on open source elections technology and what counties stand to gain from open software. Below, you’ll find our answers to the questions posed by the Commission. How long do you think it will be before an open source voting system is certified for use in California and available for use by a jurisdiction like San Francisco? Based on our estimates for the development of similar systems, we believe that we will develop a system exceeding the requirements stipulated by San Francisco from the ground up in approximately 18 months of development effort.  The formal requirements, architecture, and design will be complete in the first four months of this process, at which point we would be able to begin the certification process, showing that our high level design meets the standards for certification. Our development methodology means that as development continues, we continuously produce traceable evidence that the high level design, and therefore the specifications for certification have been met.  The evidence we generate far surpasses anything VVSG testing centers have ever seen.  Below we reflect on the implications of such a development method; our RFI response characterizes our traceable evidence. This development process is flexible and generates traceable evidence in many ways. For example, following a traditional testing path, if the certification authority would like a set of test cases to demonstrate a certain behavior, we will provide that in a form that is readily understood and run by a third party. In excess of current requirements, we also typically produce traceable evidence that not only does our system conform to certification authority’s expectations with regards to test runs, but also is mathematically guaranteed to operate correctly in any environment, with any input, and under any adversarial setting.  This is the only acceptable form of evidence for the kinds of mission-critical systems we deal with regularly at Galois, as testing does not show the absence of design or implementation errors. This evidence and flexibility should allow certification to proceed much faster than it has on previously certified systems.  As such, the certification process should also be much less expensive than any previous certification effort at the federal or state level. We have had regular discussions this past two years with employees of the EAC, including all of its Commissioners; employees of NIST, including those responsible for defining federal certification standards; California’s certification authority (Ryan Macias in the CA SOS office); and one of the VVSG testing centers (James Long, the VSTL manager at NTS) about our development and internal validation and verification methodology at Galois.  All four parties have expressed significant interest in our capabilities. In particular, at the federal level there is interest in component-based design, development, validation, and verification—something that we have been recognized as world-class in for two decades.  And, informally, at the state level and within the testing center there is enormous interest in the strength of our evidence and the rapid means by which any third party can check its veracity.  We look forward to being the first ever elections vendor that uses formal methods to create high-assurance systems for public elections. Why hasn’t a system like this been developed and certified yet by your organization or anyone else? Galois’s focus has been on providing R&D services to the federal government and private industry.  Only recently has Galois begun working in verifiable elections technology.  As such, our main goal moving forward is to develop an open source, verifiable voting system. Open source software is always an advantage for the customer of the software, which may not always seem ideal for vendors. This is why open source voting systems have not yet been developed. Here are just a few of the ways that open source helps the customer, while (seemingly) making things harder for vendors. Illegitimate perceptions of security: Based upon numerous audits, software leaks, and FOIA responses, it is clear that existing vendors’ voting systems rely on attackers not knowing details about their implementations.  If existing systems were made open source, it is extremely likely that many vulnerabilities would be rapidly discovered.  While some of these may be simple programming errors that can be fixed, others are security properties that rely on the source remaining secret.  In general this allows for lazy design which makes it cheap and easy for vendors to create software quickly. Open source strongly discourages this sort of design. If software is built in this way, it has a frightening implication for the customers of the software. They must trust an unknown number of people who work for the vendor to keep the secret and hold it responsibly. Through careful design this fundamental flaw can be avoided, particularly with proper application of cryptography, but for existing systems this could require substantial rewriting and refactoring. It is our opinion that, were some existing vendors’ software made public and scrutinized by security and correctness professionals, few customers would continue to purchase their products. Open software can be as secure as any closed software. Developers of open source software are not tempted to rely false security from secret source, instead opting for much stronger guarantees of security, including mathematical proof.  There are many responsible researchers that will inspect open source systems, especially critical ones, reporting bugs to the developer, and often even submitting fixed when they find them. These statements are not theoretical.  In fact, for the most part, virtually all of the technology that provides some degree of security in all of our computers, smart phones, and online secure transactions is open source. Pricing models are in favor of traditional vendors: An open source system that is also free software can be used by anyone. This means that a group that does not need customization or support (e.g., a student council election or a small election jurisdiction) could effectively run an open source election for free on computers that they already own. Traditional vendors believe that this costs them revenue, and it violates their intellectual property presumptions.  After all, looking at existing vendors’ contracts, they believe that they should be able to charge large amounts of money simply for the repeated right to use, not own, their hardware and software systems.  The market has rewarded this business model by being largely structured around a supporting approach, giving no incentive for traditional vendors to change. We believe running a successful elections business is not limited to this model.  We can provide top quality software to everyone for free, while running our business by supporting and customizing the software for customers with greater needs.  Essentially, we intend to be the Red Hat of verifiable elections systems. Competitive and historical advantage: Historically, the voluminous flow of federal funds into the pockets of past and current closed source vendors—especially in the early days of HAVA when little to no certification standards existed for elections systems—means that the playing field is stacked against any new entrant.  Moreover, the vast majority of RFPs that we have reviewed stipulate preconditions on participation that prevent any new vendors from entering the market.  As such, there is no opportunity for a new vendor to generate revenue to create open source elections systems. Conservative and restrictive venture capital: Given our experience with venture capital (VC), it is also clear that raising unrestricted funding for a venture that focuses on open source elections systems is effectively an impossible task.  The first problem is that venture capital partners recoil at the prospect of funding a technology company whose primary customer is the government.  Second, the strings that are attached to such funding, over and above matters relating to ownership, mean that pursuing a public interest agenda is counter to VCs’ capitalist interests.  We believe that only a class B corporation with no such strings can ethically and morally achieve the goal of technically-assisted, low-cost, publicly verifiable elections. Many believe that the time is ripe for the creation of an open source voting system for public good.  San Francisco is only one large jurisdiction reflecting upon this idea; an idea that will enormously impact the quality, trustworthiness, and cost of future democratic elections worldwide.  Galois believes in this vision enough to spin out a company exclusively focusing on this agenda. What steps do you think need to take place for that to happen?  What are some possible ways forward? One or more large jurisdictions with a strong vision and desire to improve the quality and level of trust in elections throughout the United States must take the lead in funding the development of the first verifiable, open source voting system. We must also have at least a handful of corporations or non-profit foundations with appropriate publicly-documented expertise and professionalism, longevity, and staff to accomplish the goals of these jurisdictions.  Open source software does not write itself, and having legitimate firms to develop and, more importantly, integrate and support such software is critical.  Governments are generally not interested in developing or maintaining software systems or services “in house”.  It is not in their bailiwick, nor do they have sufficient internal capability and political will to pursue such a vision. Additionally, non-profit foundations or large corporations with significant capital and vision can also significantly impact this vision, as they can provide funding to such a venture for the benefit of the general public.  Several similar initiatives exist in adjacent areas today, ranging from public use of open government data to open source, freely software web technologies (e.g., the Mozilla Corporation and its Foundation, the Free Software Foundation, and the Apache Software Foundation). What open source license or type of open source license do you think should be used and why (e.g. OSI-approved or non-OSI-approved, permissive or copyleft, etc)? Several licenses are likely candidates for open source elections technology.  The technological foundation chosen by a system’s implementers may significantly constrain one’s choices, since some licenses such as the GPL are transitive.  We commonly develop high-assurance systems and release them to the public using very permissive licenses such as BSD, MIT, and Apache Foundation licenses.  On occasion, when warranted, we use other OSI-approved licenses.  We have also evaluated the OSET Foundation’s public license and find their arguments for its adoption compelling. We believe that there is also an opportunity for the use of dual licensing, as has been seen in numerous open source products that are available for public, research, or educational use.  For example, one of the products we use for high-assurance systems design and development, EiffelStudio, is available under two licenses: one for commercial closed source development and another for open source development. Several other organizations with which we collaborate, such as SRI International and Microsoft Research, have used similar licensing schemes. If San Francisco were to adopt an open source system, how could San Francisco be assured that the system would continue to be developed and maintained over time? One of the main contractual guarantees we provide to clients is that we will support our software systems indefinitely.  Our core license provides perpetual ownership and core technical support.  For a relatively small optional recurring fee, we will ensure that the system is maintained and evolved in accordance to the legal constraints and integration needs of our clients. A key advantage of open source software is that Galois does not need to be the company providing maintenance for a client’s software.  Any experienced software company should be able to keep the system up and running.  In fact, we predict and hope for a future where numerous local firms support and maintain our software for our clients, much like the prolific flowering of Linux systems developers and integrators we have witnessed over the past twenty years.  In an optimal future, the bulk of our customers will be using high quality third party software firms whose expertise and business is centered on supporting county and state elections organizations’ open source technology needs. Improvements to the features of the software, for example, in case of large statute changes, must be negotiated and performed on a case-by-case basis.  The same advantage to open source holds here though, as anyone can make the improvements.  Consequently, the RFPs for such work will be considerably simpler and bidding for such opportunities will be considerably more competitive than the current oligopoly of closed source vendors we witness today.", "date": "2015-10-21"},
{"website": "Galois", "title": "ICFP Programming Contest set to take place this weekend", "author": "Unknown", "link": "https://galois.com/blog/2015/08/icfp-programming-contest-2015/", "abstract": "We’re excited to be organizing this year’s ICFP Programming Contest, the annual programming contest of the International Conference on Functional Programming (ICFP).  This year, the contest starts on Friday 7 August 2015 at 12:00 UTC and ends on Monday 10 August 2015 at 12:00 UTC . There will be a lightning division, ending on Saturday 8 August 2015 at 12:00 UTC . The contest is open to everyone. To participate, follow the instructions on the official site when the task becomes available on Friday. The contest has been held annually since 1998 and is traditionally organized by academic and research institutions. Each year, hundreds of teams from across the world participate in the open contest for small cash prices, “bragging rights,” and a number of judges’ prizes. The winners of the contest are announced at ICFP on Tuesday 1 September 2015. ICFP is an annual programming language conference that offers a forum for developers and researchers to hear about the latest trends in design, implementation, principles and uses of functional programming. The conference “covers the entire spectrum of work, from practice to theory, including its peripheries.” Sponsored by the Association for Computing Machinery (ACM), ICFP 2015 will be held in Vancouver, British Columbia, Canada, Sept. 1-3, 2015. Cthulhu fhtagn!", "date": "2015-08-05"},
{"website": "Galois", "title": "Applying Cryptol and SAW to Minilock Primitives", "author": "Unknown", "link": "https://galois.com/blog/2015/06/cryptol-saw-minilock/", "abstract": "To commemorate the public release of the Software Analysis Workbench (SAW), it seemed fitting to blog about some recent work specifying algorithms in Cryptol and proving properties, leveraging SAW along the way. Cryptol, Galois’s domain specific language for describing cryptographic algorithms, has frequently been demonstrated over individual algorithms and toy problems. Our blog is covered with Cryptol posts such as ZUC , Skein , Simon, SPECK , Sudoku , and N-Queens . Complementing these small, single-algorithm, efforts we wrote a Cryptol specification for the popular file encryption tool Minilock . Minilock allows users to encrypt files such that only select few people are capable of decryption using their respective private keys. To accomplish this, user passwords and SCrypt are used to generate Curve25519 asymmetric keys. These asymmetric keys and ECDH allow each party to derive symmetric keys which are used to decrypt the Salsa20+Poly1305 encrypted file. A key-wrapping scheme is used to avoid duplicating ciphertext for each recipient. Our executable Minilock specification, called Crylock, allows us to produce encrypted files compatible with Minilock, analyze the algorithms, and formally verify functional equivalence of implementations. In building this specification we developed Cryptol implementations of Blake2s, Curve25519, HMAC, SHA256, PBKDF2, SCrypt, Salsa20, base64 and 58 encodings, and NaCl’s CryptoBox primitive. Armed with this body of specifications and evidence of functional correctness due to the interoperability testing, we can now use our SMT solvers of choice as a hammer and treat any publication or bit of code as a nail to be struck. It’s hammer time. Salsa20 and TweetNacl One issue in implementing cryptographic algorithms is knowing it is done right, without corner cases. Was shift accidentally used instead of rotate? Have all operations accounted for overflow correctly? SAW can prove equivalence of implements in a straight-forward manner. For example, using a couple dozen lines of SAW script and our Salsa20 Cryptol implementation we can quickly verify the core of Salsa20 from TweetNaCl: import \"Salsa20.cry\";\r\nlet sym = \"crypto_core_salsa20_tweet\";\r\nlet main : TopLevel () = do {\r\n    print \"Proving equivalence between spec and tweet nacl.\"; Next, we declare symbolic values of the nonce, key and output. The quoted symbol names must match what is found in the bytecode, while the (non-quoted) SAW variables can be arbitrary but match for readability sake. out <- fresh_symbolic \"out\" {| [64][8] |};\r\n    n   <- fresh_symbolic \"n\" {| [16][8] |};\r\n    k   <- fresh_symbolic \"k\" {| [32][8] |};\r\n    let allocs  = [ (\"out\", 64), (\"in\", 16)\r\n                  , (\"k\", 32), (\"c\", 16) ];\r\n    let inits   = [ (\"*out\", out, 64)\r\n                  , (\"*in\", n, 16)\r\n                  , (\"*k\", k, 32)\r\n                  , (\"*c\", {{ \"expand 32-byte k\" }}, 16) ];\r\n    let results = [ (\"*out\", 64) ]; In the above one particular variable stands out, the final ‘inits’ binding for variable ‘c’. In this verification we’re only interested in how the core function matches when used in the context of the Salsa20 stream cipher. As a result we do not need to prove equivalence for every possible 16 byte value ‘c’ and instead declare the static input. In the syntax, {{ \"...\"}} , double curly braces indicates a term in the Cryptol language; the term is a string constant from the Salsa20 algorithm. Having specified inputs and outputs, the meat of the work is loading the module, extracting a symbolic representation of the code, obtaining an And-Inverter Graph (AIG) of both code and specification, then comparing these graphs for equivalence. print \"\\tLoading tweetnacl llvm byte code.\";\r\n    tnacl <- llvm_load_module \"tweetnacl.bc\";\r\n\r\n    print \"\\tExtracting the Salsa20 encryption function.\";\r\n    nacl_salsa20 <- time (llvm_symexec tnacl sym\r\n                                        allocs inits results);\r\n\r\n    print \"\\tBit blasting the NaCl and Cryptol terms.\";\r\n    nacl_as  <- abstract_symbolic nacl_salsa20;\r\n    let cry_f  = {{ \\key nonce -> Salsa20_expansion `{a=2} (key,nonce) }};\r\n    let nacl_f = {{ \\key nonce -> nacl_as nonce key }};\r\n    naclAIG <- time (bitblast nacl_f);\r\n    cryAIG  <- time (bitblast cry_f);\r\n\r\n    print \"\\tUsing CEC to prove equivalence.\";\r\n    res <- time (cec naclAIG cryAIG);\r\n    print res;\r\n}; The ABC-backed ‘cec’ solver is too good. We don’t have time to get coffee. Proving Salsa20_encrypt equivalent between Cryptol spec and tweet nacl.\r\n        Loading tweetnacl llvm byte code.\r\n        Extracting the Salsa20 encryption function.\r\n        Time:     3.143s\r\n        Bit blasting the NaCl and Cryptol terms.\r\n        Time:     1.183s\r\n        Time:     0.204s\r\n        Using CEC to prove equivalence.\r\n        Time:     0.069s\r\nValid The exact same steps can successfully show equivalence with Salsa20 encryption. A caveat is the SAW engine works over monomorphic types, so while one might desire to show the Salsa20 encryptions from Cryptol and NaCl are identical for all possible input sizes, SAWScript requires a static size prior to validation. Cryptographic Properties The 2008 paper “On the Salsa20 Core Function” highlighted seven theorems relating to a part of Salsa20. These are exactly the type of properties Cryptol and the underlying solvers are intended to quickly verify, allowing the user to more efficiently explore the algorithm. The first few properties are about invariant inputs for transformations, for example: property theorem1 a =\r\n    quarterround [a, -a, a, -a] == [a,-a,a,-a]\r\nproperty theorem2 a b c d = rowround val == val\r\n    where val    = [a,-a,a,-a\r\n                   ,b,-b,b,-b\r\n                   ,c,-c,c,-c\r\n                   ,d,-d,d,-d]\r\nproperty theorem3 a b c d = columnround val == val\r\n    where val    = [a,-b,c,-d\r\n                   ,-a,b,-c,d\r\n                   ,a,-b,c,-d\r\n                   ,-a,b,-c,d]\r\nproperty theorem4 a = doubleround val == val\r\n    where val    = [a,-a,a,-a\r\n                   ,-a,a,-a,a\r\n                   ,a,-a,a,-a\r\n                   ,-a,a,-a,a] That is, for the Salsa sub-functions of doubleround, columnround, rowround, and quarterround there exists inputs such that f x = x . These theorems all can be handled by Cryptol directly: Salsa20> :set prover=any\r\nSalsa20> :prove theorem1\r\nQ.E.D.\r\nSalsa20> :prove theorem2\r\nQ.E.D.\r\nSalsa20> :prove theorem3\r\nQ.E.D.\r\nSalsa20> :prove theorem4\r\nQ.E.D. The seventh, and last, theorem of the paper does not terminate in a timely manner. This is unfortunate but not unexpected – it is a slightly more complex theorem that leverages the prior six. In order to make such compositional proofs painless, SAW returns proof objects which can be used to enhance future proof tactics in a simple manner. This is a middle ground between the full power of manual theorem prover and the “all-or-nothing” system exposed by Cryptol. The SAWScript is: import \"../src/prim/Salsa20.cry\";\r\n\r\nlet main : TopLevel () = do {\r\n    print \"Proving Salsa20 hash theorems.\";\r\n    let simpset x = addsimps x empty_ss;\r\n\r\n    t1_po <- time (prove_print abc {{ \\a ->\r\n              quarterround [a, -a, a, -a] == [a,-a,a,-a] }});\r\n    t2_po <- time (prove_print abc {{ \\a b c d ->\r\n              (rowround val == val\r\n                     where val    = [a,-a,a,-a\r\n                                    ,b,-b,b,-b\r\n                                    ,c,-c,c,-c\r\n                                    ,d,-d,d,-d])}});\r\n    t3_po <- time (prove_print abc {{  \\a b c d ->\r\n               (columnround val == val\r\n                     where val    = [a,-b,c,-d\r\n                                    ,-a,b,-c,d\r\n                                    ,a,-b,c,-d\r\n                                    ,-a,b,-c,d]) }});\r\n    t4_po <- time (prove_print abc {{ \\a ->\r\n               (doubleround val == val\r\n                      where val    = [a,-a,a,-a\r\n                                     ,-a,a,-a,a\r\n                                     ,a,-a,a,-a\r\n                                     ,-a,a,-a,a]) }});\r\n    let ss = simpset [ t1_po, t2_po, t3_po, t4_po ];\r\n\r\n    print \"Proving Theorem 7\";\r\n    time (prove_print do { simplify ss; abc ; } {{ \\a ->\r\n                ((Salsa20Words a == Salsa20Words (a ^ diff))\r\n                      where diff = [ 0x80000000 | _ <- [0..15])\r\n                 }});\r\n    print \"Done\";\r\n}; SAW yields the result quickly: Proving Salsa20 hash theorems.\r\nValid\r\nTime:     0.145s\r\nValid\r\nTime:     0.232s\r\nValid\r\nTime:     0.218s\r\nValid\r\nTime:     0.245s\r\nProving Theorem 7\r\nValid\r\nTime:     0.411s\r\nDone This task took SAW under two seconds while proving theorem 7 without the simplification rules, as in Cryptol, takes over a week of computation time. Download You can download SAW and many examples from our github page .", "date": "2015-06-12"},
{"website": "Galois", "title": "Announcing the Software Analysis Workbench", "author": "Unknown", "link": "https://galois.com/blog/2015/06/announcing-software-analysis-workbench/", "abstract": "We are pleased to announce a public preview of the Software Analysis Workbench. The Software Analysis Workbench (SAW) provides the ability to formally verify properties of code written in C, Java, and Cryptol. It leverages automated SAT and SMT solvers to make this process as automated as possible, and provides a scripting language, called SAW Script, to enable verification to scale up to more complex systems. SAW has been particularly tuned toward the problem of equivalence checking: proving that two implementations of an algorithm, potentially written in different programming languages, have the same functional behavior for all possible inputs. At Galois, we have used SAW primarily to verify implementations of cryptographic algorithms such as the AES block cipher, the Secure Hash Algorithm (SHA), and Elliptic Curve Digital Signature Algorithm (ECDSA), proving that the implementations are functionally equivalent to specifications written in Cryptol. We have used this to verify selected portions of existing, widely used libraries such as libgcrypt and BouncyCastle. Additional details on the project, including a tutorial, are available on the main project web site . The SAW Script interpreter, the primary user interface to SAW, is freely available for non-commercial use. Several of the supporting libraries, including the implementation of the shared intermediate language SAW uses for representing models of software semantics, are available under a standard, 3-clause BSD license. If you have an interest in using SAW in a commercial context, contact us for a license tailored to your needs. Binaries for the entire SAW system are available here , and source code is available here . The build scripts for the interpreter clone and build all other dependency repositories from GitHub. SAW is in active development, and we are currently making Alpha-quality Preview Releases available publicly. At Galois, we are passionate about improving the security and safety of critical software, and we think that verification tools such as SAW have an important role in achieving that goal. We would love feedback on how to make SAW better. Please contact us if you have any questions about SAW or high assurance development in general, and feel free to file issues on GitHub if you encounter problems.", "date": "2015-06-09"},
{"website": "Galois", "title": "On the promises of technology for elections: Joe Kiniry speaks at the Voting and Elections Summit", "author": "Unknown", "link": "https://galois.com/blog/2015/02/kiniry-voting-elections-summit/", "abstract": "Earlier this month, the Ninth Annual Voting and Elections Summit examined the most critical and persistent issues surrounding U.S. elections and voter participation. Joe Kiniry , Galois’ election systems expert, gave a talk on the promises of technology to increase the transparency and trustworthiness of elections. Dr. Kiniry discussed the trade-offs that election officials face when considering currently available election technology systems. He also outlined some of the benefits that well-built elections systems offer to voters and officials, including efficient voting, verifiability, auditing and accountability. For more, watch the complete talk below:", "date": "2015-02-25"},
{"website": "Galois", "title": "The “FREAK” TLS/SSL flaw, and related thoughts", "author": "Unknown", "link": "https://galois.com/blog/2015/03/the-freak-tls-ssl-flaw/", "abstract": "“Formal verification methods…should be considered the prime choice for verification of complex and mission-critical software ecosystems.” New vulnerabilities in the software infrastructure we all depend on for privacy are discovered frequently. Thus it was not surprising when an INRIA, MSR, and IMDEA team announced discovery of a significant TLS/SSL vulnerability. The surprise in this announcement was both the intentionally designed nature of some aspects of the vulnerability, and the length of time that the vulnerability has been in play. The team reported that OpenSSL and Apple TLS/SSL clients share a defect that allow a MITM attack to force them to handle secure sessions with weak “export-grade” (512b RSA key) security that makes factoring attacks feasible (full details at SmackTLS.com). A combination of this defect and certain intentional weaknesses in popular TLS/SSL server implementations creates a vulnerability that makes it possible to compromise privacy and integrity of secure communications between clients and servers. Three behaviors in TLS/SSL components contribute to the “FREAK” vulnerability: The OpenSSL and Apple TLS/SSL clients have a defect where a client will accept weaker, “export-grade” (512b) RSA keys (rather than today’s more secure 1024b or larger keys) from a server even if they did not request such weaker security from the server A surprising number of TLS/SSL servers (something like 36% of the roughly 14 million servers that serve browser-recognized certificates) still support “export-grade” security if requested, long after the statutory requirement for it lapsed Because RSA key generation is relatively costly, typical TLS/SSL servers generate a single export-grade key each time the server boots, and re-use that same key for all export-grade sessions until the server goes down (instead of generating a new key for each session, as good crypto practice suggests) Together, these three behaviors can be exploited to compromise privacy and integrity of a secure connection. Here’s how the exploit works in simple terms: a client such as an Android device contacts a web server and requests a standard RSA suite an attacker, perhaps on the local wireless LAN used by the client, intercepts this request and changes it to ask for the export-grade RSA suite instead and then sends it on to the server the server accepts this request, and due to behavior (2) responds to the original client with a 512b (export-grade) RSA key instead of the standard security key due to behavior (1), the client silently accepts this key and adapts to use export-grade crypto meanwhile, the attacker conducts a factoring attack against the RSA modulus in use and is able to recover the RSA decryption key. In early 2015, this attack takes under 8 hours and costs about $100 in cloud computing when the client sends its candidate pre-master secret to the server, the attacker intercepts it and decrypts it, allowing recovery of the session master secret the attacker can now see (and modify) the entire conversation between client and server as if it were “in the clear”, because it has the master key to the conversation due to behavior (3), the attacker can see and modify all export grade sessions for that server as long as the server stays up Why TLS/SSL servers support export-grade crypto The Secure Sockets Layer (SSL) and its successor, TLS, are the de facto solution for most secure communication on untrusted networks such as the Internet. These protocols use RSA public key (aka asymmetric key) cryptography to securely exchange symmetric crypto keys that are then used for the bulk of communication. RSA supports various levels of security, but its 512b security level is no longer considered secure because it can be broken in a matter of hours. When designed in the early 90’s, 512b security was already considered “weak”, while larger key sizes were considered “strong”. At that time, the US government restricted export of strong crypto (possibly for national security reasons), but allowed export of the weaker version. This strategy meant that in order to communicate with both foreign and domestic partners, US-based servers needed to support both the stronger and weaker versions, along with a protocol for negotiating the use of one or the other at session initiation. Even though the policy that created this weakness is long gone, it turns out that this functionality was not removed from many SSL implementations. Formal methods and systematic testing Discovery of the FREAK vulnerability is yet another demonstration that long-standing crypto protocols may function in unintended ways that compromise security. On one hand, validating such protocols by typical testing approaches may (even after many years) not exercise vulnerable code paths. However, formal verification methods and highly systematic testing can detect such weaknesses, as shown by the INRIA, MSR, and IMDEA team. The team first developed and formally verified correctness of a reference TLS implementation, known as miTLS. Using this formally proven reference, they systematically generated incorrect transactions and used this “fuzzing” technique to test the response of existing TLS implementations. Unexpected responses were taken as indicators of potential vulnerabilities, and where possible were developed into exploits used to communicate the nature of the vulnerabilities to the implementors of the libraries being tested. Thus a combination of formal verification and systematic test coverage of the input space led to discovery of important vulnerabilities in highly complex crypto software. Key take-away Crypto algorithms and protocols verified in this way are termed “high-assurance” crypto. Formal verification methods offer a substantial advantage in achieving the goal of high assurance, and should be considered the prime choice for verification of complex and mission-critical software ecosystems.", "date": "2015-03-09"},
{"website": "Galois", "title": "Computing on private and secure data: An article for the IEEE", "author": "Unknown", "link": "https://galois.com/blog/2015/02/computing-private-secure-data-article-ieee/", "abstract": "Dr. David Archer, our cryptography research lead, and Prof. Kurt Rolloff of the New Jersey Institute of Technology recently wrote an article for the IEEE Security and Privacy magazine on the topic of computing on sensitive, encrypted data without decrypting it. The new, groundbreaking process of computing on encrypted data has major implications for businesses that would benefit from sharing data, yet need to keep that data private. It opens up collaboration opportunities and allows for decision-making based on sharing private data without actually sharing the data. Other applications of this technology enable true end-to-end encryption even when mixing data, for example in VoIP applications. The article looks at two new cryptographic methods, linear secret sharing (LSS) and fully homomorphic encryption (FHE). The authors also present real-world application prototypes for FHE and LSS implementations: VoIP Teleconferencing with end-to-end encryption, and filtering encrypted emails without decrypting the messages. Read the IEEE article here , and explore the Galois cryptography R&D page for more information on our work on secure multiparty computation.", "date": "2015-02-10"},
{"website": "Galois", "title": "Hacking Internet Voting via Ballot Tampering", "author": "Unknown", "link": "https://galois.com/blog/2014/11/hacking-internet-voting-via-ballot-tampering/", "abstract": "Dan Zimmerman and Joe Kiniry Election Day was this week.  If you took advantage of early voting, or you live overseas, you probably used a paper ballot you received in the mail a few weeks ago.  A digital alternative, being considered across the USA, is voting-by-email. Figure 1: The Internet Voting Process Using a PDF Ballot To vote using email ( Fig. 1 ), you download and fill out a ballot on your computer and then email it back to election officials. Sending an email is meant to be like putting your vote into a ballot box. Figure 2: Digital Voting Benefits This kind of system would be convenient for voters and officials as it ensures ballots are filled out properly, permits disabled voters to vote independently, and ballot counting is quick and accurate ( Fig. 2 ). Unfortunately, this idea has serious security flaws: It permits a single hacker to remotely manipulate the outcome of any election. When you download a file—like a ballot—or send an email—such as a vote—your data flows through many untrusted computer systems ( Fig. 3 ). For example, your ballot can be intercepted on the way to you, viruses on your computer can manipulate your vote without your knowledge, or your vote can be modified while on its return trip to the government. Any of these attacks can change the outcome of an entire election, since the hacker can control ballot distribution, vote choice, and ballot submission. Figure 3: Attacking Ballot Distribution, Vote Choice, and Ballot Submission This is not just a theoretical danger. At Galois, we have demonstrated that a normal wireless router—like the one your ISP installed in your home, or that you bought and installed yourself—can be taken over from anywhere in the world.  By tweaking your router’s software, your and your family’s votes are silently changed after they leave your computer and before they reach election officials. What’s more, there is no trace of foul play, and the attack can be automated.  For example, hackers could target a critical number of voters supporting a particular candidate in a close race, thus tipping the election whichever way they—or their customers—want. Despite its presumed benefits, voting by email is deeply flawed. Our demonstration only took a few days to develop, and is very difficult to detect, even for security experts. Printing a ballot and mailing it through postal services, or putting it in a ballot drop, is still the most secure and reliable solution for early and absentee voting. Links to the video about this work: YouTube: https://www.youtube.com/watch?v=qtfiZyPca1w Vimeo: https://vimeo.com/111230880 PDF version of this post: Hacking Internet Voting via Ballot Tampering", "date": "2014-11-07"},
{"website": "Galois", "title": "Galois releases FreeRTOS port for Xen on ARM systems", "author": "Unknown", "link": "https://galois.com/blog/2015/02/freertos-xen/", "abstract": "We’re pleased to announce the open source release of FreeRTOS for Xen on ARM systems. This release is part of our research efforts in mobile security , cyber-physical systems , and security . The FreeRTOS port is one of our most recent projects in the Xen community, which include the Haskell Lightweight Virtual Machine (HalVM) and our MAC-enhanced version of the XenStore. Galois continues to work with Xen for a variety of reasons . To get started with the FreeRTOS port, check out my blog post on xenproject.org: https://blog.xenproject.org/2015/02/02/getting-started-with-freertos-for-xen-on-arm-2/ I also gave a talk on this work at last year’s Xen Developer Summit. You can watch it below: For more information, contact me at jtd AT galois DOT com if you have questions and feel free to open tickets or submit pull requests on GitHub .", "date": "2015-02-03"},
{"website": "Galois", "title": "Block Ciphers, Homomorphically, And Then Some", "author": "Unknown", "link": "https://galois.com/blog/2014/12/block-ciphers-homomorphically-2/", "abstract": "Following up on our recent post, Block Ciphers, Homomorphically , we have some new results. In our previous post, we reported on two experiments: a single block-at-a-time evaluation of SIMON 64/128 computed with the HElib homomorphic encryption library, and a parallel, 1800 block-at-a-time evaluation of the same cipher. Our results on the latter have not changed: 1800 blocks in 1 hour and 52 minutes, for 3.1 seconds per block. However, we have improved results for our single block-at-a-time solution, which we report on here. After discussing the previous single block implementation with Shai Halevi, developer of HElib, we modified our approach to take advantage of an optimization for multiplication by constants of which we were unaware. By doing so, we were able to significantly reduce the multplication overhead of each SIMON round. As a result, with L=45, we were able to reduce the single-block processing time from 14 hours to 3 hours 8 minutes. Exploiting parallelism by ciphertext packing, and choosing nSlots to be a multiple of 32 instead of our current value of 1800, would allow higher throughput by processing blocks in parallel. However, our experiment was designed to understand single block throughput, so we report only that result here. In summary, our experiments show that SIMON 64/128 implemented under homomorphic encryption using the open-source HElib library achieves performance ranging from 3 hours 8 minutes while processing a single block with no parallelism, to 3.1 seconds per block while processing 1800 blocks at a time using a bit-slice approach. Questions or comments? Feel free to contact Dave Archer .", "date": "2014-12-18"},
{"website": "Galois", "title": "(Ab)using Compiler Plugins to Improve Embedded DSLs", "author": "Unknown", "link": "https://galois.com/blog/2014/12/abusing-compiler-plugins-improve-embedded-dsls/", "abstract": "by Eric Seidel, Galois intern Embedded DSLs are a bit of a double-edged sword. They have a low start-up cost because you can defer a lot of work to the host language, but producing good error messages can be challenging. People often talk about the quality of type errors produced by the host language, but I’m going to focus instead on producing better runtime errors . A Simple Toy Language Here’s a fragment of a simple imperative language. data Lit = Integer Integer | Bool Bool deriving ( Show ) data Expr = Var String | Lit Lit | Eq Expr Expr | Lt Expr Expr | Add Expr Expr deriving ( Show ) data Stmt = Assign String Expr | While Expr [ Stmt ] | Assert Expr deriving ( Show ) With judicious use of smart constructors, we can build a nice embedded DSL for our language, turning sum10 :: Imp ()\r\nsum10 = do n <- local 0 r <- local 0 while (n <? 11 ) $ do r =: r + n\r\n    n =: n + 1 assert (r =? 54 ) into λ > runImp sum10\r\n[ Assign \"local0\" ( Lit ( Integer 0 ))\r\n, Assign \"local1\" ( Lit ( Integer 0 ))\r\n, While ( Lt ( Var \"local0\" ) ( Lit ( Integer 11 )))\r\n    [ Assign \"local1\" ( Add ( Var \"local1\" ) ( Var \"local0\" ))\r\n    , Assign \"local0\" ( Add ( Var \"local0\" ) ( Lit ( Integer 1 )))\r\n    ]\r\n, Assert ( Eq ( Var \"local1\" ) ( Lit ( Integer 54 )))\r\n] But when we actually run the program, we get λ > eval $ runImp sum10 *** Exception : assertion failed : Eq ( Var \"local1\" ) ( Lit ( Integer 54 )) which is not so great. I like my error messages to include a source location so I know where to start looking. Unfortunately there’s no way for a Haskell function to know where it was called, and for good reason as that would destroy purity. As an alternative, we could use a pre-processor to transform the original Haskell code by adding explicit references to the source locations. But that’s a bit unsatisfactory because now the code we write is no longer the same code GHC sees, which means that errors thrown by GHC will refer to incorrect locations. Luckily for us, GHC includes support for compiler plugins so users can implement their own optimization passes. So, today we’re going to implement an optimization pass that optimizes usability rather than performance. Strategy GHC allows users to write optimization passes over Core , the first of a few intermediate representations used by GHC. Core is a simple language with just a handful of data constructors, essentially 1 data CoreExpr = Var Id | Lit Literal | App CoreExpr CoreExpr | Lam Id CoreExpr | Let CoreBind CoreExpr | Case CoreExpr Id Type [( AltCon , [ Id ], CoreExpr )] | Type Type | Tick Tickish CoreExpr This makes our life a whole lot easier since we don’t have to consider the entire surface area of Haskell’s syntax when we write our plugin. Our goal is to write a Core transformation that will insert calls to a setLocation action in our monadic DSL, transforming the original Haskell code into something like sum10 :: Imp ()\r\nsum10 = do setLocation < line 3 > n <- local 0 setLocation < line 4 > r <- local 0 setLocation < line 5 > while (n <? 11 ) $ do setLocation < line 6 > r =: r + n\r\n    setLocation < line 7 > n =: n + 1 setLocation < line 8 > assert (r =? 54 ) This isn’t perfect as our language will only know about source locations with statement-level granularity, but the upside is that the changes to the language are minimal. We can just add another Stmt constructor that tells the interpreter to update the current location. To write this transformation we need to know three things: Where to insert the annotations? How to insert the annotations? How to get the source locations from GHC? Useful API Functions GHC is written as a library with a vast API, so let’s first pick out and describe a few functions that we’ll need to use. I’m going to take some artistic license with the types of these API functions in order to hide some of the necessary plumbing. I will also use angle brackets (e.g. <Imp> ) to refer to specific Type and CoreExpr values. A complete and running version of the plugin can be found here . Deconstructing Expressions and Types exprType            :: CoreExpr -> Type splitTyConApp_maybe :: Type -> Maybe ( TyCon , [ Type ]) exprType queries an expression for its type. splitTyConApp_maybe attempts to split a type into a type constructor and its arguments, e.g. splitTyConApp_maybe < Imp String > = Just ( < Imp > , [ < String > ]) Building Core Expressions mkCoreApps   :: CoreExpr -> [ CoreExpr ] -> CoreExpr mkStringExpr :: String -> CoreExpr mkIntExpr    :: Integer -> CoreExpr mkCoreApps constructs a sequence of nested applications, e.g. mkCoreApps < map > [ < f > , < xs > ] = App ( App < map > < f > ) < xs > mkStringExpr and mkIntExpr construct expressions corresponding to String (resp. Integer ) literals. Library Functions from Our DSL We’ll also need to define two more functions in our DSL for our code-generator to target. makeLocation :: FilePath -> Int -> Int -- the starting line/column -> Int -> Int -- the ending line/column -> ImpSrcSpan setLocation  :: ImpSrcSpan -> Imp () setLocation just emits a new statement in our DSL that contains the current source location, e.g. data Stmt = ... | SetLocation ImpSrcSpan I’m also using a new ImpSrcSpan type rather than GHC’s SrcSpan to emphasize that we can’t just embed the SrcSpan value directly, we have to reconstruct it at run-time. Finding Interesting Expressions Since our goal is locations with statement-level granularity, we’ll consider any expression with type Imp a interesting. Encoding this as a predicate on Core expressions is straightforward, we’ll just use splitTyConApp_maybe and check if the type constructor is Imp . isInteresting :: CoreExpr -> Bool isInteresting expr | Just (tc, _) <- splitTyConApp_maybe (exprType expr) = tc == < Imp > | otherwise = False Adding the Locations Once we’ve found an interesting expression, we’ll need to annotate it with a source location according to our scheme above. So we need a function annotate :: SrcSpan -> CoreExpr -> CoreExpr that transforms <expr> into (>>) (setLocation <loc>) <expr> . This turns out to be harder than it looks though! Core doesn’t have type-classes — it passes the dictionaries around explicitly — which means we need to somehow dig up the Monad dictionary for Imp . Rather than deal with looking up type-class dictionaries, let’s take a slightly different approach and rewrite <expr> to withLocation <loc> <expr> , where withLocation :: ImpSrcSpan -> Imp a -> Imp a is a new monadic action in our DSL. Now our target code will look something like sum10 :: Imp ()\r\nsum10 = do n <- withLocation < line 3 > (local 0 )\r\n  r <- withLocation < line 4 > (local 0 )\r\n  withLocation < line 5 > $ while (n <? 11 ) $ do r =: withLocation < line 6 > (r + n)\r\n    n =: withLocation < line 7 > (n + 1 )\r\n  withLocation < line 8 > (assert (r =? 54 )) As mentioned above, we can’t just embed a SrcSpan in the Core, so we’ll define a quick helper function that will build a call to makeLocation . mkLocExpr :: SrcSpan -> CoreExpr mkLocExpr src = mkCoreApps ( Var < makeLocation > )\r\n             [ mkStringExpr (srcSpanFile src)\r\n             , mkIntExpr (srcSpanStartLine src)\r\n             , mkIntExpr (srcSpanStartCol src)\r\n             , mkIntExpr (srcSpanEndLine src)\r\n             , mkIntExpr (srcSpanEndCol src)\r\n             ] Core is explicitly typed, so when we generate the call to withLocation inside annotate , we have to take care to instantiate withLocation s type parameter correctly. annotate :: SrcSpan -> CoreExpr -> CoreExpr annotate src expr = mkCoreApps ( Var < withLocation > ) $ map Type tys ++ [mkLocExpr src, expr] where Just (_, tys) = splitTyConApp_maybe $ exprType expr Getting the Locations I’ve ignored a somewhat crucial detail so far: GHC strips away the source locations as part of the translation from Haskell to Core! Well, it normally does that anyway… If you load your module into GHCi, or compile with profiling or hpc enabled, GHC will insert Tick s in the Core, which contain source locations among other things. So we need a function tickSpan :: Tickish Id -> SrcSpan to extract the SrcSpan . I won’t present the implementation here because, frankly, it’s just a bunch of plumbing. Tying It All Together The last piece of the puzzle is the actual expression transformer, which just needs to traverse the CoreExpr s, track the most recent valid SrcSpan , and annotate the interesting expressions. addLocationsExpr :: CoreExpr -> CoreExpr addLocationsExpr = go noSrcSpan where go ss ( Tick t expr) | isGoodSrcSpan (tickSpan t) = Tick t (go (tickSpan t) expr) | otherwise = Tick t (go ss expr)\r\n  go ss e @ ( App expr arg) | isInteresting e = annotate ss ( App (go ss expr) (go ss arg)) | otherwise = App (go ss expr) (go ss arg)\r\n  go ss ( Lam x expr) = Lam x (go ss expr)\r\n  go ss ( Let bndr expr) = Let (addLocationsBind bndr) (go ss expr)\r\n  go ss ( Case expr x t alts) = Case (go ss expr) x t (mapM (addLocationsAlt ss) alts)\r\n  go _  expr = expr\r\n\r\n  addLocationsAlt ss (c, xs, expr) = (c, xs, go ss expr) addLocationsBind :: CoreBind -> CoreBind addLocationsBind ( NonRec b expr) = NonRec b (addLocationsExpr expr)\r\naddLocationsBind ( Rec binds) = Rec [(b, addLocationsExpr expr) | (b, expr) <- binds] We can hook our pass into GHC as a plugin with the following wrapper module ImpPlugin where import GhcPlugins import Imp plugin :: Plugin plugin = defaultPlugin { installCoreToDos = install } install :: [ CommandLineOption ] -> [ CoreToDo ] -> CoreM [ CoreToDo ]\r\ninstall opts todos = do reinitializeGlobals -- GHC requires it, just do it let mypass = CoreDoPluginPass \"Add Locations\" (bindsOnlyPass (return . map addLocationsBind))\r\n  return mypass : todos and enable it at compile-time with -fplugin=ImpPlugin . Here are the results of all our hard work λ > runImp sum10\r\n[ SetLocation \"ImpDemo.hs:(9,9)-(17,19)\" , SetLocation \"ImpDemo.hs:(12,3)-(12,9)\" , Assign \"local0\" ( Lit ( Integer 0 ))\r\n, SetLocation \"ImpDemo.hs:(9,9)-(17,19)\" , SetLocation \"ImpDemo.hs:(13,3)-(13,9)\" , Assign \"local1\" ( Lit ( Integer 0 ))\r\n, SetLocation \"ImpDemo.hs:(9,9)-(17,19)\" , SetLocation \"ImpDemo.hs:(14,3)-(16,15)\" , While ( Lt ( Var \"local0\" ) ( Lit ( Integer 11 )))\r\n    [ SetLocation \"ImpDemo.hs:(14,3)-(16,15)\" , SetLocation \"ImpDemo.hs:(15,5)-(15,15)\" , Assign \"local1\" ( Add ( Var \"local1\" ) ( Var \"local0\" ))\r\n    , SetLocation \"ImpDemo.hs:(16,5)-(16,15)\" , Assign \"local0\" ( Add ( Var \"local0\" ) ( Lit ( Integer 1 )))\r\n    ]\r\n, SetLocation \"ImpDemo.hs:(17,3)-(17,19)\" , Assert ( Eq ( Var \"local1\" ) ( Lit ( Integer 54 )))\r\n]\r\n\r\nλ > eval $ runImp sum10 *** Exception : \"ImpDemo.hs:(17,3)-(17,19)\" : assertion failed : Eq ( Var \"local1\" ) ( Lit ( Integer 54 )) Wonderful! You may have noticed that the only pieces of the plugin that were actually specific to Imp were finding interesting expressions and annotating them with source locations. So I’ve extracted the rest into a generic pass that you can re-use. In fact we’re already using this plugin in the Ivory language for writing safe embedded systems. As a final note, I don’t claim to have invented anything conceptually new here, both Scala and Idris support reifying source locations in a much more principled manner than what I’ve presented. It would also be nice if GHC had similar support, perhaps via the ImplicitParams extension. But I do believe this is a nice solution that you can use today! The actual definition has two extra constructors and a type parameter which I’ve instantiated with Id , but this is not particularly relevant to our use-case. ↩", "date": "2014-12-04"},
{"website": "Galois", "title": "Block Ciphers, Homomorphically", "author": "Unknown", "link": "https://galois.com/blog/2014/12/block-ciphers-homomorphically/", "abstract": "by Brent Carmer and David W. Archer, PhD Our team at Galois, Inc. is interested in making secure computation practical. Much of our secure computation work has focused on linear secret sharing (LSS, a form of multi-party computation) and the platform we’ve built on that technology. However, we’ve also done a fair bit of comparison between LSS, garbled circuit approaches, and homomorphic encryption (HE). We recently noticed that Shai Halevi and Victor Shoup’s open source homomorphic encryption library HElib was just waiting for someone to implement some interesting block ciphers. In this post, we talk about our experience implementing and evaluating performance of the SIMON block cipher in HElib. Our implementation processes 1800 64b blocks in parallel, achieving a rate of 3.1 seconds per block. In homomorphic encryption (HE), a user encrypts data and sends it to a single untrusted server. That server, which does not hold the encryption key, computes on the encrypted data and returns an encrypted answer to the user. Each step in HE computation accumulates noise that eventually makes the plaintext unrecoverable unless extra time-consuming steps (informally called bootstrapping) are taken. When these steps are not taken, HE cryptosystems are typically called somewhat homomorphic (SHE for short). When bootstrapping is used, more complex computations can be performed. Such cryptosystems are typically called fully homomorphic (FHE for short). Unfortunately, making HE practical is challenging. HE is very much (many orders of magnitude) slower than computing the same result “in the clear”. Typical HE ciphertexts are also far (thousands to millions of times) bigger than the plaintexts they represent. Even with such challenges, the promise of HE is compelling, particularly where mobile devices may have insufficient computational power, cloud-based servers may be readily used to outsource such computation, and users are not prepared to trust those servers with their (plaintext) data. As of this posting, HElib as available on github falls into the SHE category. Shai and Victor have indicated that they plan to make bootstrapping (and thus FHE) available in a few weeks. To gain experience using HElib, we implemented a member of the SIMON block cipher family. SIMON is a new family of lightweight block ciphers released by the NSA in 2013. We implemented SIMON with 64 bit block size and 128 bit key size. The SIMON specification calls for 44 processing “rounds” in SIMON 64/128, which we were able to implement using the current (somewhat homomorphic) version of HElib. Key portions of our SIMON implementation are shown below encoded in Cryptol , a domain-specific language for expressing cryptographic algorithms developed by Galois and widely used in some government agencies. Cryptol is designed to describe cryptographic algorithms at a level of abstraction very close to mathematical specification, to minimize the likelihood of error when translating from specification to code. The Cryptol tool suite supports automated verification for some target languages that implementation matches a Cryptol description. The Cryptol suite can also automatically generate certain implementations from Cryptol descriptions. Using Cryptol’s support for SAT solvers, we have proven some properties of our SIMON implementation: absence of weak keys, injectivity of key expansion, and identity of decryption composed with encryption. -- encRound is the core of our SIMON implementation \r\n     -- It takes a key and a 64b plaintext block, \r\n     -- divided into two 32b chunks.\r\n     -- As with all Feistel ciphers, at each round we \r\n     -- swap the chunks and only manipulate one of them.\r\n\r\n     -- type signature for encRound:\r\n     encRound : [32] -> ([32], [32]) -> ([32], [32])\r\n     -- implementation of encRound:\r\n     encRound k (x, y) = (y ^ f x ^ k, x)\r\n\r\n     -- f is a helper function that performs \r\n     -- rotations and xors over a chunk of input.\r\n     f : [32] -> [32]\r\n     f x = ((x <<< 1) && (x <<< 8)) ^ (x <<< 2)\r\n\r\n     -- encrypt performs one encRound on the input \r\n     -- for each of the keys\r\n     encrypt : [4][32] -> ([32], [32]) -> ([32], [32])\r\n     encrypt k0 b0 = bs ! 0\r\n       where\r\n         bs = [b0] # [ encRound k b | b Note: find the whole Cryptol specification for SIMON in simon.cry This description specifies what we set out to implement, using HElib as a platform. Ciphertexts in HElib are composed of vectors of elements of certain rings. For our implementation, we use Ring(2). Thus each element in the ciphertext vector represents a single bit. HElib also supports the notion of \"packing\" multiple plaintexts into a single ciphertext, and computing on these in parallel, in a SIMD-like paradigm. The number of plaintexts packable into a ciphertext, which we call nSlots, is impacted by a number of parameters, including the maximum supported computation depth of the circuit, which we call L. As we vary L to allow for more computation and parallelism, we also affect the cost of the computation in the form of the size of cryptographic keys used at each level in the Boolean circuit. Our first attempt Representing SIMON ciphertext blocks. Blocks for the SIMON block cipher are 64b in size, but must be manipulated as two 32b halves (typical of Feistel ciphers). Because of this natural structure, we first implemented ciphertexts as two vectors of 32b each. In our implementation, the nSlots parameter is much larger than 32, so we padded the ciphertexts with zeroes, not taking advantage of packing. We represent these vectors as follows: simon-blocks.cpp ￼\r\n     // a plaintext block is simply two 32b unsigned integers\r\n     struct pt_block {\r\n         uint32_t x;\r\n         uint32_t y;\r\n     };\r\n\r\n     // we encrypt each half by itself\r\n     Ctxt heEncrypt(const FHEPubKey& k, uint32_t x) {\r\n         vector vec = uint32ToBits(x); \r\n         pad(0, vec, global_nslots);\r\n         Ctxt c(k);\r\n         global_ea->encrypt(c, k, vec);\r\n         return c;\r\n     }\r\n\r\n     // then, a secret block is simply two ciphertexts\r\n     struct heBlock {\r\n         Ctxt x;\r\n         Ctxt y;\r\n     };\r\n￼ Processing SIMON blocks The SIMON algorithm requires use of addition in GF(2) (that is, XOR), multiplication in GF(2) (AND), negation, and both left and right rotations. HElib provides the required addition and multiplication primitives. However, we must compose our own negation function by bitwise XOR with a vector of all ones: simon-blocks.cpp // x is the ciphertext, global_maxint is the all 1's vector\r\n    \r\n    void negate32(Ctxt &x) { \r\n        x += \\*global_maxint;\r\n    } Because HElib provides shift operations but not rotation, we create the required rotation functions. Because this is a bit tricky, we use Cryptol to specify our rotation approach and prove its correctness. rotation.cry Below is our resulting HElib code for rotation. simon-blocks.cpp void rotateLeft32(Ctxt &x, int n) {\r\n         Ctxt other = x;\r\n         global_ea->shift(x, n);\r\n         global_ea->shift(other, -(32-n));\r\n         // x |= other. must do demorgan's law manually\r\n         negate32(x);\r\n         // since we do not have bitwise OR in HElib\r\n         negate32(other);\r\n         x.multiplyBy(other);\r\n         negate32(x);\r\n     } At this point, we have all the basic functions we need to build SIMON. Next, we implement the key function on which SIMON depends: encRound. Implementing encRound is straightforward and follows directly from the Cryptol: simon-blocks.cpp void encRound(Ctxt key, heBlock &inp) {\r\n         Ctxt tmp = inp.x;\r\n         Ctxt x0  = inp.x;\r\n         Ctxt x1  = inp.x;\r\n         Ctxt x2  = inp.x;\r\n         Ctxt y   = inp.y;\r\n         rotateLeft32(x0, 1);\r\n         rotateLeft32(x1, 8);\r\n         rotateLeft32(x2, 2);\r\n         x0.multiplyBy(x1);\r\n         y    += x0;\r\n         y    += x2;\r\n         y    += key;\r\n         inp.x = y;\r\n         inp.y = tmp;\r\n     } Evaluating the first attempt We evaluated this approach by testing performance and ability to complete SIMON without exceeding the allowable circuit depth. In one experiment, the computation took unreasonable time: 14 hours for a single block at a circuit depth (L=80) that allowed the computation to finish all rounds correctly. In another experiment, the computation was much faster, but cannot complete all rounds within the homomorphic noise threshold, completing only 10 rounds of the required 44 in 500 seconds with L=16. We concluded that this first approach was unworkable in practice. Our second attempt For our next try, we adopted the concept used by Smart et al. to achieve concurrency in leveled homomorphic AES implementations. This idea, called \"bit-slicing\", interleaves individual bits of multiple plaintexts. First, we select the same bit from each plaintext, and form a vector of those bits. For example, a vector is formed by selecting the first bit of each plaintext in a group of plaintexts. Next, each vector is homomorphically encrypted. Then we form a vector of the resulting ciphertexts. This vector thus contains the ciphertexts for all included plaintexts. While this original motivation for this approach was to achieve concurrency with appropriate computing resources, we use it for a different purpose. The highest cost computational primitive in our SIMON implementation is rotation. Rotation is expensive because (as shown in simon-blocks.cpp ) it requires bitwise OR, which in turn requires multiplication. Each of the 44 rounds in SIMON requires three such rotations in addition to the other multiplications and additions used. Because addition is inexpensive and there is only a single other multiplication per round, rotation dominates computational cost. The bit-slicing approach allows us to rotate \"for free\" by simply permuting indices in the vector of ciphertexts. Thus the multiplication involved in rotation is eliminated, reducing the number of multiplications per round of SIMON from 4 to 1. See the resulting implementation at simon-simd.cpp . Results With this new approach and a selection of L=23, we were successful at completing all rounds of SIMON without the need for recryption. Our implementation achieves 126 seconds per round. Thus all 44 rounds are completed in 1 hour and 52 minutes. This compares favorably to our naive implementation that required 14 hours. In addition, L=23 (along with our choices for other parameters) allows us nSlots of up to 1800. Taking advantage of this parallelism, we process 1800 64b blocks concurrently for performance averaging 70ms per round, or 3.1 seconds per block. Block ciphers are a popular class of benchmark applications for secure computation. A linear secret sharing implementation of AES-128 on the Galois ShareMonad platform was for some time the fastest known secure computation implementation of AES, achieving 3ms per block [LAD12]). Our implementation of SIMON on HElib adds to this body of work the first known implementation of a modern block cipher using this library. Our code base is available at github . In the near future, we plan to explore the upcoming recryption capability in HElib to implement and study AES in this framework. The authors greatly appreciate the time and effort of Tom DuBussion and Getty Ritter of Galois, Inc. in helping with implementation. [LAD12] J. Launchbury, A. Adams-Moran, and I. Diatchki, Efficient Lookup-TableProtocol in Secure Multiparty Computation. In Proc. International Conference on Functional Programming (ICFP), 2012.", "date": "2014-12-03"},
{"website": "Galois", "title": "Innovation Week: Experiments, prototypes and new skills", "author": "Unknown", "link": "https://galois.com/blog/2014/10/innovation-week-experiments-prototypes-new-skills/", "abstract": "During the first week of October, Galois held “Innovation Week,” a time for everybody to explore new ideas, recharge our creativity, have fun and share what we’ve learned and done with each other. Throughout the week, Galwegians worked on a diverse set of side projects: running experiments, building prototypes, solving puzzles and acquiring new skills. Here’s a (non-exhaustive) list of the projects that took place: Hacking our office front door to open with Tozny instead of a key card Hacking our Twilight Zone pinball machine to make it self-playable Writing a ray tracer in Haskell Writing an automated story generator Enhancing Haskell natural language processing modules Hacking software-defined radio for home automation Programming FPGAs to play C64-style music Driving an Arduino robot car remotely using EEG (brain wave) signals Creating data visualization demos Experimenting with linear logic proofs Building type systems to support dimensional analysis Lots of GHC hacking Of course, innovation is not something we aim for just one week out of the year: Innovation Week is, more than anything, a celebration of how deeply the spirit of experimentation and exploration is woven into the Galois culture and how satisfying it can be to work together on projects in the context of playfulness and wonder.", "date": "2014-10-23"},
{"website": "Galois", "title": "Why Xen?", "author": "Unknown", "link": "https://galois.com/blog/2014/09/xen/", "abstract": "Over the last few months, Galois has published or spoken about a variety of technologies based on the open source Xen hypervisor: our port of FreeRTOS on Xen , our MAC-enhanced version of the XenStore , and, of course, our continuing work on the Haskell Lightweight Virtual Machine (a.k.a., the HaLVM). Based on all this activity, I get asked the obvious question: Why is Xen so compelling to Galois? For the last fifteen years, Galois has been building trustworthy solutions to meet our customers’ critical demands. When we build out some of these solutions, both as prototypes and as deliverable software, we inevitably run into the question of platform. Our designs are good, and our software is good, but what platform can we run on that provides the stability and guarantees that we require? In the future, we hope to see high-assurance, formally verified separation and real-time kernels on which we can build the truly robust systems of our dreams. NICTA’s seL4 has taken several major steps towards that goal, and we follow its development quite closely; in fact, we have used it in some of our more forward-looking projects. While we wait for these technologies to mature, however, Xen has been a great choice for Galois. Xen has many aspects of a secure microkernel that we need: it is small, it provides strong security through its XSM layer, and it can run on a wide variety of hardware platforms. Further, because Xen is open source software, we can freely inspect, modify, and remove any code that interferes with our efforts. Better yet, because Xen is a virtualization solution, it allows us to run full-featured operating systems as “applications” on our kernel. Thus, in many cases, we can provide our clients extremely secure solutions without sacrificing the user interfaces they expect. In addition, we have been impressed by the passion and openness of the Xen community. Particularly over the last few years, we have seen Xen thrive and expand into areas that match well with our research areas while embracing an open, inclusive community that we greatly admire. Most recently, we have been interested in the use of Xen on ARM devices. We believe that Xen may be uniquely situated to serve as a medium- to high-assurance platform for future mobile and automotive systems, particularly when combined with our SMACCMPilot and related efforts. In short, the fact that we combine our secure platform designs and tools — tools like Ivory and HaLVM — with an active, vibrant open source project like Xen has led to some very cool technologies for Galois over the last months and years, and we certainly see this trend continuing into the future.", "date": "2014-09-29"},
{"website": "Galois", "title": "Modifying an Off-the-Shelf Wireless Router for PDF Ballot Tampering", "author": "Unknown", "link": "https://galois.com/blog/2014/11/modifying-shelf-wireless-router-pdf-ballot-tampering/", "abstract": "A whitepaper providing a technical summary of our PDF voting hack is now available: Modifying an Off-the-Shelf Wireless Router for PDF Ballot Tampering If you missed it, you can find our bird’s eye view breakdown of the process here: http://galois.com/blog/2014/11/hacking-internet-voting-via-ballot-tampering/", "date": "2014-11-07"},
{"website": "Galois", "title": "ZUC in Cryptol", "author": "Unknown", "link": "https://galois.com/blog/2011/06/zuc-in-cryptol/", "abstract": "ZUC is a stream cipher that is proposed for inclusion in the “4G” mobile standard named LTE (Long Term Evolution), the future of secure GSM . The proposal is actually comprised several different algorithms: A stream cipher named ZUC , LTE encryption algorithm (128-EEA3), based on ZUC, LTE integrity algorithm (128-EIA3), which is a hash function using ZUC as its core. In this post, we will develop a Cryptol implementation of ZUC, providing executable reference code. In addition, we will also discuss some of the security concerns raised for version 1.4 of the algorithm: We will use Cryptol to automatically identify an IV collision vulnerability. This weakness is addressed in version 1.5 of the algorithm: We will also prove that the proposed fix is indeed valid, again using Cryptol’s formal verification tools. While we do assume some familiarity with ZUC and Cryptol, this article should shed some light into how Cryptol can be used in the cryptographic design and evaluation processes even if you skip all the ZUC specific details. Our implementation follows the latest specification of ZUC , which is at version 1.5 at the time of writing. Addition in GF(2 31 -1) One of the core operations in ZUC is addition of two 31-bit numbers, say a and b. The specification states that this operation can be done as follows: Compute v = a+b If the carry bit is 1, set v=v+1 We transliterate this algorithm to Cryptol straightforwardly: plus : ([31], [31]) -> [31];\r\nplus (a, b) = if sab ! 0 then sab'+1 else sab'\r\n    where {\r\n        sab : [32];\r\n        sab = (a # zero) + (b # zero);\r\n        sab' : [31];\r\n        sab' = take(31, sab);\r\n    }; Note how we detect overflow by doing the 32-bit addition and checking the final bit. We can generalize plus to add , which will add any sequence of numbers in GF(2 31 -1) using plus repetitively: add : {a} (fin a) => [a][31] -> [31];\r\nadd xs = sums ! 0\r\n    where sums = [0] # [| plus (s, x) || s <- sums || x <- xs |]; We simply generate the partial sums, and return the final sum by selecting the last element. A digression on plus As an interesting aside, the ZUC specification calls the plus operation we have defined above addition modulo 2 31 -1, which does not seem to be the traditional modular addition. In particular, you can prove that will never evaluate to 0 unless its arguments are both 0 , which is not quite how modular addition typically behaves. We can prove this claim using Cryptol’s satisfiability checker: ZUC> :sat ((a, b) -> (a != 0) & (b != 0) & (plus(a, b) == 0))\r\nNo variable assignment satisfies this function It appears that the algorithm has been designed with modular addition in mind, with tweaks to avoid having it generate values on purpose. The LFSR At the core of ZUC lies an LFSR (linear feedback shift register), which comprises of 16 cells, each of which is precisely 31 bits wide. Cryptol’s type-system has been designed to accurately capture such specifications: type LFSR = [16][31]; Note that we do not have to resort to using 32-bit machine integers or some other machine mandated bit-size, freeing us to give a fully faithful implementation of the specification. ZUC uses the LFSR in two different modes. In the initialization mode, it takes a 31-bit input u , and transforms the LFSR by performing the following computation, where s i refers to the i-th cell of the LFSR: 2 15 s 15 + 2 17 s 13 + 2 21 s 10 + 2 20 s 4 + (1+2 8 ) s 0 mod (2 31 – 1) ZUC adds this value to the input u, and then “tweaks” the sum to avoid a 0 result. The Cryptol code below implements the specification quite closely: LFSRWithInitializationMode : ([31], LFSR) -> LFSR;\r\nLFSRWithInitializationMode (u, ss) = (ss @@ [1 .. 15]) # [s16]\r\n    where {\r\n        v = add [| s <<< c\r\n                || s <- ss @@ [15 13 10 4 0 0]\r\n                || c <- [15 17 21 20 8 0] |];\r\n        vu = add [v u];\r\n        s16 = if vu == 0 then 0x7fffffff else vu;\r\n    }; Note how we pick elements of the LFSR and the coefficients by a simple sequence comprehension. In the work mode, there is no initializer value u , but otherwise the operation is very similar: LFSRWithWorkMode : LFSR -> LFSR;\r\nLFSRWithWorkMode ss = (ss @@ [1 .. 15]) # [s16]\r\n    where {\r\n        v = add [| s <<< c\r\n                || s <- ss @@ [15 13 10 4 0 0]\r\n                || c <- [15 17 21 20 8 0] |];\r\n        s16 = if v == 0 then 0x7fffffff else v;\r\n    }; We could have defined LFSRWithWorkMode in terms of LFSRWithInitializationMode by passing 0 for u, but the above definition follows the specification much more closely, a desirable thing to do for a reference implementation. (Also, this version of is a bit faster for obvious reasons, saving us some cycles during execution.) Bit Reorganization The middle layer of ZUC takes the LFSR and shuffles its contents as follows: BitReorganization : LFSR -> [4][32];\r\nBitReorganization ss =\r\n        [| y # x\r\n        || (x, y) <- [(hi s15, lo s14) (lo s11, hi s9) \r\n                      (lo s7, hi s5) (lo s2, hi s0)]\r\n        |]  \r\n    where {\r\n        lo, hi : [31] -> [16];\r\n        lo x = x @@ [0 .. 15];\r\n        hi x = x @@ [15 .. 30];\r\n        [s0 s2 s5 s7 s9 s11 s14 s15] = ss @@ [0 2 5 7 9 11 14 15];\r\n    }; There isn’t much to say about bit-reorganization, except to note that selecting high and low bytes of a 31-bit word comes out quite clean in Cryptol, thanks to bit-level addressability and compact selection operation @@ . Note how ZUC defines the higher 16 bits of a 31 bit number by picking bits 15 through 30; which is just as natural in Cryptol to express as any other slice of a given word. The nonlinear function F Cryptol implementation of ZUC’ s F function follows the specification almost literally: F : ([3][32], [2][32]) -> ([32], [2][32]);\r\nF ([X0 X1 X2], [R1 R2]) = (W, [R1' R2'])  \r\n    where {\r\n        W = (X0 ^ R1) + R2;\r\n        W1 = R1 + X1;\r\n        W2 = R2 ^ X2;\r\n        [W1L W1H] = split W1;\r\n        [W2L W2H] = split W2;\r\n        R1' = S(L1(W2H # W1L));\r\n        R2' = S(L2(W1H # W2L));\r\n    }; Note that we keep track of the parameters R1 and R2 explicitly. Being a purely functional language, Cryptol does not have any notion of state, and hence does not support in-place updates. However, this does not mean inefficient execution: The purely functional approach makes sure the specifications remain easy to develop and reason about, while backend tools (compilers, synthesizers, etc.) can transform the code to run efficiently on various targets appropriately, such as on FPGA’s or in software. We will skip the details of ZUC’ s S-boxes and the functions L1 and L2 , but you can see their implementation in the attached full implementation . Loading the Key ZUC receives a 128 bit key and a 128-bit IV (initialization vector), to construct the initial starting configuration of the LFSR. The following definition follows the specification (Section 3.5) literally: LoadKey : ([128], [128]) -> LFSR;\r\nLoadKey (key, iv) = [| i # d # k || k <- ks || i <- is || d <- ds |]\r\n    where {\r\n        ks : [16][8];\r\n        ks = split key;\r\n        is : [16][8];\r\n        is = split iv;\r\n        ds : [16][15];\r\n        ds = [0b100010011010111 0b010011010111100 0b110001001101011 0b001001101011110 0b101011110001001 0b011010111100010 0b111000100110101 0b000100110101111 0b100110101111000 0b010111100010011 0b110101111000100 0b001101011110001 0b101111000100110 0b011110001001101 0b111100010011010 0b100011110101100];\r\n    }; Initializing ZUC During the initialization stage, ZUC loads the key and the IV, and then repeatedly performs bit-reorganization, a run of F, and a run of LFSR in initialization mode. This process is repeated 32 times. For purposes that will become clear later, we represent this operation as a Cryptol stream function that returns an infinite sequence of ZUC configurations: type ZUC = (LFSR, [32], [32]);\r\nInitializeZUC : ([128], [128]) -> [inf]ZUC;\r\nInitializeZUC (key, iv) = outs\r\n    where {\r\n        initLFSR = LoadKey (key, iv);\r\n        outs = [(initLFSR, 0, 0)] # [| step out || out <- outs |];\r\n        step (lfsr, R1, R2) = (LFSRWithInitializationMode(take(31, w >> 1), lfsr), R1', R2')\r\n            where {\r\n                [X0 X1 X2 _] = BitReorganization(lfsr);\r\n                (w, [R1' R2']) = F ([X0 X1 X2], [R1 R2]);\r\n            };\r\n    }; Executing ZUC We need two more pieces of functionality. In the so called working stage, ZUC runs bit-reorganization, F, and LFSR in work mode, discarding the result of the call to F: WorkingStage : ZUC -> ZUC;\r\nWorkingStage (lfsr, R1, R2) = (lfsr', R1', R2')\r\n    where {\r\n        [X0 X1 X2 _] = BitReorganization(lfsr);\r\n        (_, [R1' R2']) = F ([X0 X1 X2], [R1 R2]);\r\n        lfsr' = LFSRWithWorkMode(lfsr);\r\n    }; Cryptol’s pattern-matching based definitions come out quite nicely in picking (and ignoring) results of operations. In the production stage , ZUC transforms works just like in the working stage, except the result of the call to F is returned as the next 32-bit key, after XOR’ing with the last word of what bit-reorganization returns. Again, the Cryptol code is straightforward: ProductionStage : ZUC -> ([32], ZUC);\r\nProductionStage (lfsr, R1, R2) = (w ^ X3, (lfsr', R1', R2'))\r\n    where {\r\n        [X0 X1 X2 X3] = BitReorganization(lfsr);\r\n        (w, [R1' R2']) = F ([X0 X1 X2], [R1 R2]);\r\n        lfsr' = LFSRWithWorkMode(lfsr);\r\n    }; The ZUC API We can finally give the ZUC API. Given a key and an IV, ZUC initializes itself, and then keeps calling ProductionStage to generate successive sequences of 32-bit words as key expansion. The result is most naturally captured in Cryptol as an infinite sequence of 32-bit words: ZUC : ([128], [128]) -> [inf][32];\r\nZUC (key, iv) = tail [| w || (w, _) <- zucs |]\r\n    where {\r\n        initZuc = WorkingStage(InitializeZUC @ 32);\r\n        zucs = [(zero, initZuc)] # [| ProductionStage zuc || (_, zuc) <- zucs |];\r\n    }; Encryption can now be done by taking the plaintext and XOR’ing with the successive words that come out of the above function: Clearly, decryption is the same as encryption, and the fact that they are inverses follows trivially from the fact that it’s a mere XOR operation. And this completes our development of ZUC in Cryptol. You can see the entire code here . Testing One thing about crypto-algorithm development is that it is hard to convince oneself that the algorithm is coded correctly. ZUC is no exception. Hopefully, Cryptol makes that task easier by abstracting away from many of the machine-specific details, providing a language that allows one to express idioms that appear in cryptography quite concisely, thus removing a whole class of bugs that has nothing to do with the algorithm itself but rather with how it has to be implemented. The other aspect of Cryptol is that the specification, as high level as it is, remains executable. So, we can use our implementation and test it against the published test-vectors for ZUC. Here’s the first example from the test document (Section 3.3): ZUC> take(2, ZUC(0, 0))\r\n[0x27bede74 0x018082da] (The full implementation has further test vectors from the specification, see the theorem ZUC_TestVectors.) Note that since our implementation of ZUC returns an infinite sequence, we have used the “take” function to just look at the first two outputs. Naturally, we can pull out as many outputs as we would like from that infinite stream. Security of ZUC One essential activity in crypto-algorithm design is to provide rigorous security arguments. While the current state-of-the-art in developing such arguments relies largely on human intelligence, we can use tools to attest our findings. In this section we will see how to use Cryptol to mechanically demonstrate an IV collision vulnerability found in version 1.4 of the ZUC specification, and how the modifications in version 1.5 addressed the problem. An IV collision occurs if two different IV’ s cause the algorithm to initialize itself to precisely the same state, thus losing entropy. Cryptographers seriously worry about such losses of entropy as they can lead to efficient attacks by cutting down the search space significantly. In a recent conference, Wu et al., demonstrated one such vulnerability in ZUC 1.4. In that version of the specification, ZUC had a slightly different initialization sequence. First, instead of addition in GF(2 31 -1), it performed a simple XOR when LFSR is used in the initialization mode. Second, version 1.4 XOR’ d the last byte from the bit-reorganization during initialization with the result of the call to the nonlinear function F. (You can see the precise differences between versions 1.4 and 1.5 in the attached Cryptol code , search for the occurrences of the variable version1_5, which distinguishes between the two.) As demonstrated by Wu et al., the 1.4 version of the algorithm suffers from IV collision: That is, two different IV’ s can result in the precise same ZUC state, causing loss of entropy. It is easy to express this property as a Cryptol theorem: theorem ZUC_isResistantToCollisionAttack: {k iv1 iv2}.\r\n    if (iv1 != iv2) then InitializeZUC(k, iv1) @ 1 != InitializeZUC(k, iv2) @ 1 else True; Let’s spend a moment on what the above theorem is stating. It says that for all values of k , iv1 , and iv2, the initial state of ZUC will be different so long as iv1 and iv2 are not the same. If this theorem holds of our algorithm, it would mean that there is no entropy loss due to IV collision. (We also now see why we chose InitializeZUC to return an infinite stream: This way we can simply look at the result of the first step, which will create a simpler verification problem for the backend SAT /SMT solver used by Cryptol.) Here is Cryptol’s response when we tell it to prove the above theorem, using version 1.4 of the specification: ZUC> :set sbv\r\nZUC> :prove ZUC _isResistantToCollisionAttack\r\nFalsifiable.\r\nZUC_isResistantToCollisionAttack(0x6bff61ffff8fcdffffffc996ffffff1a,\r\n0xff08fc0085e000000a0000f5008f000a,\r\n0xff08fc0085e000000a0000f5008f008a) = False The first command tells Cryptol to switch to the SBV mode, which allows for formal proofs. In the second command, we asked Cryptol to prove that the theorem holds of our implementation. Not only Cryptol told us that the theorem we have stated is false, it also provided a concrete counterexample! (Note that those two IV values are different, check the second to last digit!) Let’s verify that the vulnerability indeed does exist with the iv values Cryptol gave us: ZUC> take(2,ZUC(0x6bff61ffff8fcdffffffc996ffffff1a,0xff08fc0085e000000a0000f5008f000a))\r\n[0xa415abbe 0x673f1eb9]\r\nZUC> take(2,ZUC(0x6bff61ffff8fcdffffffc996ffffff1a,0xff08fc0085e000000a0000f5008f008a))\r\n[0xa415abbe 0x673f1eb9] Voila! We have two different IV’ s, yet we get precisely the same key-sequence. Cryptol can attest to what Wu et al. showed, providing a concrete counterexample to wit. In response to this vulnerability, the ZUC algorithm was slightly tweaked to remove the possibility of collision. (Again, you can look at the attached Cryptol code to see what those changes were, search for the word version1_5 .) Is the vulnerability really removed? While mathematicians will have their own tools to claim as such, we can use Cryptol to verify that the fix indeed does work (and is correctly implemented) in our version as well. With version 1.5 of the spec, we have: ZUC> :prove ZUC_isResistantToCollisionAttack\r\nQ.E.D. (The above proof takes a couple of seconds to complete on my laptop.) It is important to note that the above theorem does not prove that there are no IV collisions in ZUC 1.5. This is because we’ve only proved the theorem after the first run of the InitializeZUC routine. Recall that the actual implementation actually runs that operation 32 times. While we can express the full theorem in Cryptol as well, it generates quite a large verification problem, and the SAT solver running on my laptop is not quite powerful enough to tackle it. (The proof might indeed be feasible on a more decent machine with enough RAM. One can also construct an argument that the initialization step is injective for all possible LFSR configurations that LoadKey will produce, thus completing the proof in two steps. We leave that as an exercise for the interested reader!) In any case, our proof above shows that ZUC version 1.5 is at least free of “easy to find” IV collision attacks. Summary Designing cryptographic algorithms requires a deep understanding of the underlying science of cryptography, and a fair amount of the mathematics thus involved. Implementing such algorithms need not! We believe that the Cryptol toolset provides the right idioms and the tools to simplify cryptographic algorithm implementations and evaluations, abstracting away from machine specific details and platform specific concerns. Specifications remain pure, and hence easier to reason about and communicate. The executable nature of Cryptol also makes it easy to just play around with your implementations, without worrying about myriads of implementation specific concerns. (Compare how you would do a similar study of ZUC if you had to use C or Java; how much of your time would be spent on the actual algorithm, and how much on “everything else.”) Once the algorithm is developed, the compilation and synthesis tools of Cryptol can help in creating artifacts that can be deployed in software or in an FPGA. By separating the concerns of specification from implementation, Cryptol provides new means of simplifying crypto-algorithm development and evaluation. The full ZUC implementation in Cryptol can be downloaded here . Free licenses for Cryptol are available at www.cryptol.net .", "date": "2011-06-07"},
{"website": "Galois", "title": "Substitution ciphers in Cryptol", "author": "Unknown", "link": "https://galois.com/blog/2009/08/substitution-ciphers-in-cryptol/", "abstract": "Substitution ciphers are one of the oldest encryption methods, dating back to at least the 15th century. In a substitution cipher, each character in the plain-text is simply “substituted” according to a predefined map. Decryption is simply the substitution in the reverse direction. Wikipedia has a nice description of these ciphers. Obviously, you wouldn’t want your bank to use such a cipher when executing your web-based transactions! But they are fun to play around, especially when entertaining kids in hot summer days. In this post, we’ll see how to code simple substitution ciphers in Cryptol, and go a step further and actually prove that our implementation is correct. Preliminaries The simplest form of substitution ciphers use a permutation of the input alphabet. That is, each letter in the input alphabet gets mapped to another in the same  alphabet. (Strictly speaking, input and output alphabets need not be the same, but nothing essential changes by making that assumption.) For instance, you might decide that your substitution will map ‘a’ to ‘q’, and ‘b’ to ‘d’, …, etc., making sure no two letters are mapped to the same target. Once this mapping is agreed on, all you have to do to encrypt a given message is to map each character to the corresponding element according to your predefined mapping rules.Here’s our Cryptol encoding of these ciphers. First, some preliminary declarations: type Char = [8];\r\ntype String(l) = [l]Char;\r\ntype Table(n) = [n](Char, Char); We’ll simply assume that the input consist of “characters,” each of which will be 8-bit quantities (i.e., numbers from 0 to 255). We will simply use ASCII encoding for normal English characters. This is captured by the Char type declaration above, which simply gives a convenient name for 8-bit wide words. The second type declaration captures sized-strings: For any given size l , the type String(l) represents a sequence of length l, containing 8-bit words. For instance, String(16) is the type of all sequences of length 16, containing numbers from 0 to 255 as elements. Finally a Table of size n is simply n -pairings of characters that form a substitution. Here’s the example table we will use: cipherTable : Table(28);\r\ncipherTable = [| (x, y) || x <- plain || y <- cipher |] \r\n  where { \r\n    plain = \"abcdefghijklmnopqrstuvwxyz .\"; \r\n    cipher = \"oebxa.cdf hijklmnzpqtuvwrygs\" \r\n  }; Note that our table has 28 entries (the lower-case English alphabet, plus space and the dot). A simple Cryptol sequence-comprehension succinctly zips the sequences up, forming our example table. Performing the substitution Given a table and a character, the function subst returns the element that the table maps the character to: subst : {n} (fin n) => (Table(n), Char) -> Char;\r\nsubst (table, chr) = find 0 \r\n  where find i = if i == width table \r\n    then '?' \r\n    else if chr == chr' \r\n      then code \r\n      else find (i+1) \r\n    where (chr', code) = table @ i; To do the search, we simply start from index 0 and walk through the given table recursively, returning the mapped element if we have a match. If the given table does not have the corresponding element,  we simply return the character ‘?’, which will indicate failure.  (Aside: Note how the predicate \"fin n\" ensures we’re given a finite table, ensured by Cryptol’s type-system. Haskell enthusiasts can gripe about receiving an infinite list when they didn’t ask for one!) Encryption and Decryption Having defined subst , encryption and decryption are mere maps: encrypt (table, msg) = [| subst (table, c) || c <- msg |];\r\ndecrypt (table, msg) = [| subst (table', c) || c <- msg |] \r\n  where table' = [| (y, x) || (x, y) <- table |]; where we simply swap the elements in the table for decryption. Substitution in action That’s pretty much all there is to it for substitution ciphers. To illustrate, let us create specialized versions of encrypt and decrypt for our example table, together with some test data: enc, dec : {l} String(l) -> String(l);\r\nenc msg = encrypt (cipherTable, msg);\r\ndec msg = decrypt (cipherTable, msg);\r\nplainText, cipherText, decodedText : String(51);\r\nplainText = \"the quick brown fox jumped over the lazy black dog.\";\r\ncipherText = enc plainText;\r\ndecodedText = dec cipherText; Here’s Cryptol in action: SubstCipher> :p plain\r\nTextthe quick brown fox jumped over the lazy black dog.\r\nSubstCipher> :p cipherText\r\nqdagntfbhgezlvkg.lwg tjmaxgluazgqdagioyrgeiobhgxlcs\r\nSubstCipher> :p decodedTextthe quick brown fox jumped over the lazy black dog. Volia! The secret is now safe, thanks to our substitution cipher.. (Note that we’re using Cryptol’s :p command which prints its argument as a string, as opposed to a sequence of 8-bit words.) Correctness Substitution ciphers are dead-simple, but it would be nice to have further assurance that our implementation is indeed correct. This is where Cryptol’s verification tools come into play. Let us first try to write a simple theorem, stating that encryption followed by decryption does not alter the message: theorem checkEncDec: {msg}. dec (enc msg) == (msg : String(16)); Note that we have restricted the theorem to messages of size 16 only, in order to create a  monomorphic theorem that Cryptol’s verification engine can check/prove automatically. (While polymorphic theorems can be stated in Cryptol, they cannot be proven automatically.)Before attempting a proof, it’s always good to get a quick-check evidence that we’re on safe ground. Here’s what happens when I try to quick-check the above theorem using Cryptol: SubstCipher> :check checkEncDecChecking case 1 of 1000 (0.10%)Falsifiable.checkEncDec [0x15 0x3e 0xf2 0x4f 0x34 0xc4 0x69 0x5a 0x64 0x9e 0xb0 0xe2 0x6f 0xf8 0x6a 0x4a]\t= False Oops! Something went terribly wrong, Cryptol found a counter-example without even really trying. Let’s use Cryptol’s “:p” command to see what the counter-example really is: SubstCipher> :p [0x15 0x3e 0xf2 0x4f 0x34 0xc4 0x69 0x5a 0x64 0x9e 0xb0 0xe2 0x6f 0xf8 0x6a 0x4a]>?O4?iZd???o?jJ Ah, it contains characters that we have not mapped! Since our input accepts any 8-bit word, all values from 0 to 255 are valid “characters.” But we clearly have not mapped most of these to anything, causing Cryptol to rightfully reject our theorem! Conditional theorems What we need is a conditional theorem, one that has a hypothesis that says “for all good messages.” That is, we need to consider only those messages that our cipher knows how to map. Here’s a helper function to do just this: all, any : {n a} (fin n) => (a -> Bit, [n]a) -> Bit;\r\nall (f, xs) = [| f x || x <- xs |] == ~zero;\r\nany (f, xs) = [| f x || x <- xs |] != zero;\r\ncheckMessage (table, msg) = all (isMapped, msg) where isMapped c = any ((c', _) -> c == c', table); [Aside: Cryptol’s polymorphic constant zero is simply the value that is False at every point. Thus, checking against its negation (~zero) ensures all the elements are True , and checking inequivalence against it (i.e., != zero ), ensures at least one element is True.] Having defined checkMessage , we can now express our correctness theorem (again constrained to strings of size 16): theorem cipherIsCorrect: {msg}. if checkMessage(cipherTable, (msg : String(16))) then dec (enc msg) == msg else True; If you try the :check command on this theorem, you will find that Cryptol is now happy with it: SubstCipher> :check cipherIsCorrectChecking case 1000 of 1000 (100.00%)1000 tests passed OK[Coverage: 0.00%. (1000/340282366920938463463374607431768211456)] The coverage info suggests we have not even barely scratched the test state-space in this case, as one can expect. However, that’s the least of our worries in this case. More importantly, quick-check’s OK is not  satisfactory at all for conditional theorems. How do we know that the random test data generated by Cryptol will pass the checkMessage test? In fact, it is very likely that very few of the test cases actually executed the actual equality check itself, as the “randomly-generated” messages are unlikely to pass the checkMessage filter. Verification Luckily, we can do better. Using Cryptol’s automated theorem prover, we can rigorously prove that the theorem is indeed true for all possible messages: SubstCipher> :prove cipherIsCorrectQ.E.D. Cryptol proves this theorem on my 3 year old laptop in less than a second!  (We  should also note that the :prove command is available in the symbolic and SBV backends of Cryptol that comes with the full release . It uses off-the-shelf SAT/SMT solvers to prove Cryptol theorems automatically.) Now we can rest assured that our implementation of substitution ciphers in Cryptol is indeed correct! For the curious As the alert reader would have no doubt noticed, we have only proved our implementation correct with respect to our example translation map cipherTable . A more general theorem would have proved the cipher correct with respect to all possible tables. Such a theorem is indeed easy to express in Cryptol, but you’ll also need to add the condition that the table is well defined. (That is, it should be a one-to-one map and no letter should be mapped to the special invalid marker ‘?’.) We invite the curious reader to play with this variant. Note that the automated proof will be more complicated in this case, and the backend prover might need more time before returning the final Q.E.D. Download The Cryptol source file implementing the substitution cipher is available for download . The Cryptol toolset licenses are freely available at www.cryptol.net . Enjoy!", "date": "2009-08-24"},
{"website": "Galois", "title": "Solving Sudoku Using Cryptol", "author": "Unknown", "link": "https://galois.com/blog/2009/03/solving-sudoku-using-cryptol/", "abstract": "Cryptol is a language tailored for cryptographic algorithms. Sudoku is a popular puzzle the reader  is no-doubt already familiar with. We will offer no deep reason why anyone should try to solve Sudoku in Cryptol; other than the very fact that it’d be a shame if we couldn’t! Needless to say, Cryptol has not been designed for encoding search algorithms. Nonetheless, some of the features of Cryptol and its associated toolset make it extremely suitable for expressing certain constraint satisfaction problems very concisely; and Sudoku very nicely falls into this category. Representing the board A Sudoku board can be represented in a variety of ways. We will pick the simplest: A sequence of 9 rows, each of which has 9 elements storing the digits. Each digit will require 4 bits; since they range from 1 to 9. So, a good Cryptol type for a board is: [9][9][4] In Cryptol-speak, this type simply represents a sequence of precisely 9 elements, each of which is a sequence of 9 elements themselves, each of which are 4-bit words. (Technically, the type [4] also represents a sequence of precisely 4 elements, each of which are bits. But it’s easier to read that as 4-bit words. The type [4] and [4]Bit are synonymous in Cryptol, and can be used interchangeably in all contexts.) Recognizing a valid row, column, or box Let us tackle a much simpler problem to start with. How would we determine if a given set of 9 numbers form a valid Sudoku row, column, or a box? We should simply check that each number from 1 to 9 appears precisely once in the sequence: check : [9][4] -> Bit;\r\ncheck group = [| contains x || x <- [1 .. 9] |] == ~zero\r\n  where contains x = [| x == y || y <- group |] != zero; We simply iterate over the numbers 1 through 9, and check that the given group contains that number.  The function contains iterates through all the elements in the given group , and makes sure one of them is the currently looked for element.(The Cryptol primitive zero is a polymorphic constant representing all False ‘s. The operator ~ inverts all the bits. Hence, the test “ == ~zero ” makes sure all the components are True; and the test “ != zero ” makes sure at least one bit is True.) Recognizing a full board Given a full Sudoku board, checking it’s a valid solution simply amounts to identifying rows, columns, and squares; and “ check “-ing them all, in the above sense. The following Cryptol function accomplishes this task rather concisely: valid : [9][9][4] -> Bit;\r\nvalid rows = [| check grp || grp <- rows # columns # squares |] == ~zero\r\n  where {\r\n    columns = transpose rows;\r\n    regions = transpose [| groupBy (3, row) || row <- rows |];\r\n    squares = [| join sq || sq <- groupBy(3, join regions) |]\r\n  }; The function valid receives 9 rows; and calls check on all these rows, columns, and the squares. Columns are easy to compute: we simply use Cryptol’s transpose primitive. The squares are slightly more tricky, but not particularly hard. We first group all the rows in length 3 segments, and transpose these to align them, thus forming the regions. Then the squares are simply grouping of the regions 3 elements at a time. It’s a good exercise to precisely work out how the squares are formed using the above code, something we encourage the interested reader to do on a rainy afternoon.. Solving Sudoku All we have done so far is to recognize a given Sudoku board as valid; we have not written a single line of code to actually fill a partially empty board. The good news is that we do not need to! We have all the bits and pieces ready to go. Sounds too good to be true? Well, read on! Enter Formal Methods What if I told you that recognizing a valid Sudoku board is  sufficent to actually solve one that has empty squares on it, using Cryptol’s formal-methods toolbox? The idea is rather simple. But before we get there, we need to take a detour into the Cryptol toolbox. Checking satisfiability Cryptol’s formal-methods tools can perform equivalence, safety, and satisfiability checking. We have talked about the former two in an earlier post . Today, we will look at satisfiability checking only. Given a function f, the satisfiability checking problem asks if there is any x such that f x = True. Here is a simple example. Let: f : [8] -> Bit;\r\nf x = x*x - 7*x + 12 == 0; The function f returns True if its given 8-bit argument is a solution to the quadratic equation x 2 – 7x + 12 = 0.  We have: Cryptol> :sat f\r\nf 4 = True Indeed, 4 is a solution to this equation. Is there any other solution? It is easy to formulate a similar query using the lambda-notation: Cryptol> :sat (x -> f x & (x != 4))\r\n((x -> f x & (x != 4))) 3 = True Cryptol tells us 3 is a solution as well! Since this is a quadratic equation, there can be at most two solutions; let’s verify: Cryptol> :sat (x -> f x & (x != 4) & (x != 3))\r\nNo variable assignment satisfies this function As expected, Cryptol confirms that 3 and 4 are the only  8-bit values that satisfy the equation x 2 – 7x + 12 = 0.(I should mention  that the :sat command is available only in the symbolic and sbv backends of Cryptol; the two main backends of Cryptol that are capable of performing formal-verification.) Back to Sudoku Remember the valid function that returns True if a given full board is a correctly laid-out Sudoku board? With the magic of satisfiability checking, we can just use that definition to fill in the blanks for us! To illustrate, consider the board below. How do we encode a board with empty cells in Cryptol? One simple idea is to represent the board as a function: It will take the values of its “empty” cells, and return the full board. In the Cryptol encoding below I have tried to align the variables so that they correspond exactly to the empty cells, and named them row-by-row: puzzle : [53][4] -> Bit;\r\npuzzle\r\n[ a1    a3    a5 a6       a9\r\nb1       b4 b5    b7    b9\r\nc2    c4 c5 c6 c7 c8 c9\r\nd1 d2    d4    d6 d7 d8\r\ne1 e2 e3    e5    e7 e8 e9\r\nf2 f3 f4    f6    f8 f9\r\ng1 g2 g3 g4 g5 g6    g8\r\nh1    h3    h5 h6       h9\r\ni1       i4 i5    i7    i9 ]\r\n= valid\r\n[[a1  9 a3  7 a5 a6  8  6 a9]\r\n[b1  3  1 b4 b5  5 b7  2 b9]\r\n[ 8  c2 6 c4 c5 c6 c7 c8 c9]\r\n[d1 d2  7 d4  5 d6 d7 d8  6]\r\n[e1 e2 e3  3 e5  7 e7 e8 e9]\r\n[ 5 f2 f3 f4  1 f6  7 f8 f9]\r\n[g1 g2 g3 g4 g5 g6  1 g8  9]\r\n[h1  2 h3  6 h5 h6  3  5 h9]\r\n[i1  5  4 i4 i5  8 i7  7 i9]]; It might take a bit of staring at this definition; but the idea is strikingly simple.  Notice that the type of puzzle is [53][4] -> Bit , precisely because there are 53 empty cells. Also, instead of just returning the final board, I simply pass it to the function valid ; so that the function puzzle will return True precisely when it is given the correct numbers that solve it!By now, it must be obvious how we’ll solve Sudoku in Cryptol: All we need to do is to ask Cryptol to find the right input value to make the function return True , i.e., we need to find a satisfying assignment. Here’s the response from Cryptol: Sudoku> :sat puzzle\r\npuzzle\r\n[2 5 4 3 1 4 8 6 9 7 7 1 9 2 5 4 3 3 8 4 9 2 1 6 1 2 8 4 9\r\n5 4 9 2 6 3 8 7 6 3 5 2 4 8 9 8 7 1 4 1 9 3 6 2] = True If we plugin the numbers we get from Cryptol back into the grid, we get the full  solution depicted below. (I used italic for the numbers found by Cryptol.) Well; that’s what we set out to do originally; so mission accomplished! What just happened here? Apologies if you were expecting to see Cryptol code that actually searched for the values of the empty cells! Note that we have not written a single line of code that tried to deduce what must go in the empty cells, nor  have we implemented a search algorithm. We merely viewed Sudoku as a satisfiability problem, and asked Cryptol’s formal-methods tools to find the missing values for us. The necessary search is all done by the underlying formal-methods engine, freeing us from the labor. Yet another instance of telling the computer “what” to do, instead of “how.” Download Here is the Cryptol code that contains all the definitions you need.  Enjoy!", "date": "2009-03-18"},
{"website": "Galois", "title": "Equivalence and Safety Checking in Cryptol", "author": "Unknown", "link": "https://galois.com/blog/2009/02/equivalence-and-safety-checking-in-cryptol/", "abstract": "The Cryptol language comes with an integrated verification tool-set that can automatically perform equivalence and safety checking on Cryptol programs. Recently, we have presented a paper on this topic at PLPV’09 : “Programming Languages Meets Program Verification” workshop. ( Slides are also available.) Briefly, equivalence checking refers to the problem of proving that two functions have the exact same input/output behavior. Typically, these functions are versions of the same algorithm; one being a reference implementation and the other being an optimized version. Cryptol automatically establishes that the optimized version is precisely equivalent to the original. If the functions are not equivalent, Cryptol provides a counter-example where they disagree; aiding greatly in development/debugging. Safety checking refers to the problem of proving that the execution of a function cannot raise any exceptions; such as division by zero; index out-of-bounds, etc. When the safety checker says that a function is safe, you will know for sure that such conditions will never arise at run-time. (Similarly, you will get a concrete counter-example from Cryptol if this is not the case.) Cryptol uses symbolic simulation to translate equivalence and safety checking problems to equivalent problems using the bit-vector logic of SMT-Lib. Furthermore, Cryptol has built-in connections to several SAT/SMT solvers. It automatically calls these provers and presents the results to the user in original Cryptol terms; providing a seamless verification environment for the end-user. The full paper and slides on equivalence checking in Cryptol are available for download.", "date": "2009-02-05"},
{"website": "Galois", "title": "Cryptol Course: High-assurance Cryptographic Development Using the Cryptol Workbench", "author": "Unknown", "link": "https://galois.com/blog/2010/10/cryptol-course-high-assurance-cryptographic-development-using-the-cryptol-workbench/", "abstract": "Galois is offering a four‐day Cryptol course for those interested in exploring the capabilities of the Cryptol workbench.The course is highly participatory: we will work on a series of exercises for each new topic, using the Cryptol toolset interactively. Prospective participants should have experience writing programs and some knowledge of cryptography. Those who complete the course will have the skills necessary to develop high‐assurance, high‐performance cryptographic algorithms in Cryptol. A tentative outline and further information can be found in the course flyer .", "date": "2010-10-26"},
{"website": "Galois", "title": "Galois at ICFP 2012", "author": "Unknown", "link": "https://galois.com/blog/2012/09/galois-at-icfp-2012/", "abstract": "Check out these ICFP presentations by Galois team members: Efficient Lookup-Table Protocol in Secure Multiparty Computation Video Presentation John Launchbury: watch video – http://www.youtube.com/watch?v=I79PwWpUx9c Paper John Launchbury, Iavor S. Diatchki, Thomas DuBuisson, and Andy Adams-Moran. 2012. Efficient lookup-table protocol in secure multiparty computation. In “Proceedings of the 17th ACM SIGPLAN International Conference on Functional Programming” (ICFP ’12). ACM, New York, NY, USA, 189-200. Experience Report: A Do-It-Yourself High Assurance Compiler Video Presentation Lee Pike: watch video – http://www.youtube.com/watch?v=7zXhP–9axQ Paper Lee Pike, Nis Wegmann, Sebastian Niller, and Alwyn Goodloe. 2012. Experience report: a do-it-yourself high-assurance compiler. In “Proceedings of the 17th ACM SIGPLAN International Conference on Functional Programming” (ICFP ’12). ACM, New York, NY, USA, 335-340. A Meta-Scheduler for the Par-Monad Video Presentation Adam Foltzer: watch video – http://www.youtube.com/watch?v=SGMKv9DxpZs Paper Adam Foltzer, Abhishek Kulkarni, Rebecca Swords, Sajith Sasidharan, Eric Jiang, and Ryan Newton. 2012. A meta-scheduler for the par-monad: composable scheduling for the heterogeneous cloud. In “Proceedings of the 17th ACM SIGPLAN International Conference on Functional Programming” (ICFP ’12). ACM, New York, NY, USA, 235-246.", "date": "2012-09-26"},
{"website": "Galois", "title": "Rob Wiltbank Joins Galois, Inc. as CEO", "author": "Unknown", "link": "https://galois.com/blog/2013/10/rob-wiltbank-joins-galois-inc-as-ceo/", "abstract": "Portland, Oregon (October 30, 2013) – Rob Wiltbank, Ph.D. has joined Galois as its CEO. Rob is widely recognized as a world expert in angel investing performance and entrepreneurial strategy. In his new role, Rob will drive strategy for Galois’ growth, oversee business operations and development, and help commercialize its technologies. “I’m tremendously pleased to welcome Rob aboard,” said John Launchbury , Galois’ Chief Scientist and founder. “His extraordinary business insights and energetic leadership combine wonderfully with the technical strength of our team. Watch this space, because great things will ensue!” Prior to Galois, Rob was a professor at Willamette University’s Atkinson Graduate School of Management , ranked by Inc. Magazine as a “top 10” in entrepreneurship education, where he ran the Willamette Angel Fund and entrepreneurship courses. Over the years, Rob’s research has focused on strategy-making under uncertainty and entrepreneurial expertise, particularly as it relates to growing new organizations. He received the prestigious 2013 Hans Severiens Award , honoring individuals whose actions demonstrate leadership in advancing the role of angel investing in expanding entrepreneurship and the angel investment industry as a whole. He is on the board of the Angel Resource Institute and serves on the Editorial Board of the Journal of Business Venturing . Additionally, Rob was a partner with Montlake Capital , a growth equity fund, and a Co-Founder of Revenue Capital Management , an innovative revenue capital fund. Rob is co-author of the 2009 book The Catalyst: How You Can Become an Extraordinary Growth Leader selected by Business Week as one of the best books on innovation and design in 2009. He is also co-author of Effectual Entrepreneurship , a text based on 15 years of academic research into entrepreneurial expertise. Rob earned his Ph.D. in Strategy from the University of Washington, and a degree in Finance and Accounting from Oregon State University.", "date": "2013-10-29"},
{"website": "Galois", "title": "Verifying Legato’s multiplier in Cryptol", "author": "Unknown", "link": "https://galois.com/blog/2009/07/verifying-legatos-multiplier-in-cryptol/", "abstract": "Consider the following multiplication algorithm, coded in Mostek 6502 Assembler: LDX #8    ; 1; load X immediate with the 8\r\n        LDA #0    ; 2; load A immediate with the 0\r\n        CLC       ; 3; set C to 0 LOOP\r\nLOOP:   ROR F1    ; 4; rotate F1 right circular through C\r\n        BCC ZCOEF ; 5; branch to ZCOEF if C = 0\r\n        CLC       ; 6; set C to 0\r\n        ADC F2    ; 7; set A to A+F2+C and C to the carry ZCOEF\r\nZCOEF:  ROR A     ; 8; rotate A right circular through C\r\n        ROR LOW   ; 9; rotate LOW right circular through C\r\n        DEX       ;10; set X to X-1\r\n        BNE LOOP  ;11; branch to LOOP if Z = 0 This program comes from Wilfred Legato’s paper “A Weakest Precondition Model for Assembly Language Programs.” It multiplies the contents of the memory locations F1 and F2 ; each of which is 8-bits wide. The result is stored in the accumulator register A and the memory location LOW , each of which is, again, 8-bits. It holds that: F1 * F2 = 256 * A + LOW when the algorithm terminates, correctly handling the overflow. It is worth spending a moment or two pondering how this algorithm works; it is not at all obvious how the multiplication is done!Legato’s challenge  (as  referred to in ACL2 circles) is to prove a deep-embedding of Legato’s algorithm correct with respect to a Mostek simulator coded in ACL2. We do not attempt to solve  Legato’s challenge in Cryptol. We are merely interested in coding and proving that Legato’s multiplier is correct in Cryptol. Our interest stems from the fact that Legato’s algorithm is a truly interesting multiplier on its own right, and we would like to make sure that a straightforward encoding of it in Cryptol can be proven correct automatically by Cryptol’s verification tools. And of course, it’s just too hard to pass up on the opportunity to  pay respect to the Mostek chip that powered the Commodore 64 ‘s and Atari 800XL ‘s of our childhood. A shallow embedding The Cryptol solution to Legato’s problem will be a fairly shallow encoding of the multiplier, together with an automated proof of correctness. We choose to do a shallow encoding here since it allows us to focus on the multiplication algorithm itself, as opposed to the particulars of the underlying Mostek chip. Theorem proving based solutions (such as those given by ACL2 folks) will rightly pursue a deeper embedding of the algorithm and the Mostek architecture in general. Cryptol is not particularly suitable for deep embeddings. Representing Mostek assembly instructions directly as Cryptol functions is a much simpler and straightforward choice.Looking at Legato’s multiplier above, we will represent each instruction (from 1 to 11) as a simple state transformer, taking a simplified representation of the Mostek machine state as input and delivering a new one. We will only represent parts of the state that matter for our problem. The following Cryptol type declaration succinctly captures what we need: type Mostek = ( [8] // F1\r\n              , [8] // F2\r\n              , [8] // A\r\n              , [8] // X\r\n              , [8] // LOW\r\n              , Bit // C (Carry)\r\n              , Bit // Z (Zero)\r\n              ); Using this state representation, each instruction in the program can be modeled as a  state transformer: type Instruction = Mostek -> Mostek; This takes care of the data-flow aspect of the embedding; but the question of how to model control-flow remains. We will simply use the host-language’s control-flow features, using the quintessential functional idiom: by calling functions! This is actually easier done than said, and here’s our embedding of the first instruction of the program: // step1: LDX #8; load X immediate with the integer 8.\r\nstep1 : Instruction;\r\nstep1 (f1, f2, a, _, l, c, z) = step2 (f1, f2, a, 8, l, c, z); Let’s spend a minute explaining this in detail. The first step in the program loads the register X with the immediate value 8. Using our state-transformer model, our step1 function will receive a Mostek state (consisting of the “current” values of F1, F2, A, X, LOW, CARRY, and ZERO ). The “effect” of this instruction is to put the value 8 into the register X, leaving everything else the same. Once this is done, the control goes to the next instruction, which we model by calling the function step2 (which is yet to be defined).In this fashion, we can shallowly embed all the instructions in Legato’s multiplier, using Cryptol’s native functions and control-flow features. Of course, this is hardly a new idea, being the essence of the whole domain-specific embedded language saga: Using a rich host-language to “fake” other languages.Following the recipe set by step1 , it is easy to model the next two instructions: // step2: LDA #0; load A immediate with the integer 0.\r\nstep2 : Instruction;\r\nstep2 (f1, f2, _, x, l, c, z) = step3 (f1, f2, 0, x, l, c, z);\r\n\r\n// step3: CLC; set C to 0 (Note the use of Bit False here)\r\nstep3 : Instruction;\r\nstep3 (f1, f2, a, x, l, _, z) = step4 (f1, f2, a, x, l, False, z); Step 4 is equally easy in terms of control flow, but is tricky in terms of operation. After some head-scratching, one figures out that the term “rotate F1 right circular through C” means put the right-most bit of F1 in C , and put C in the first position of F1 . A bizarre thing to do indeed, but that’s the beauty of Legato’s multiplier. The Cryptol translation is almost literal: // step4: LOOP ROR F1; rotate F1 right circular through C.\r\nstep4 : Instruction;\r\nstep4 (f1, f2, a, x, l, c, z) = step5 (f1', f2, a, x, l, b0, z)\r\n  where {\r\n    [b0 b1 b2 b3 b4 b5 b6 b7] = f1;\r\n    f1' = [b1 b2 b3 b4 b5 b6 b7 c];\r\n  }; The use of pattern matching in getting the bits out of f1 , and the construction of the new value of f1 is idiomatic Cryptol. There’s one little catch though: Apparently Mostek was a big-endian machine, having a most-significant-bit-first representation. Cryptol is little-endian. So, instead of rotating the bits to right, we  rotate them left.The fifth instruction is the first time where we use Cryptol’s control-flow to model the Mostek jump instruction: // step5 : BCC ZCOEF; branch to ZCOEF if C = 0.\r\n// ZCOEF is step8 in our encoding\r\nstep5 (f1, f2, a, x, l, c, z) =\r\n  if c then step6 (f1, f2, a, x, l, c, z)\r\n  else step8 (f1, f2, a, x, l, c, z); In this case, we simply receive a state, and depending on the value of the carry bit ( C ), we either go to the next step (i.e., no jump); or go to the ZCOEF instruction, which is going to be step-8 in our model. Easy as pie!Step-6 is a replica of Step-3, clearing the carry bit: // step6: CLC; set C to 0\r\nstep6 (f1, f2, a, x, l, _, z) = step7 (f1, f2, a, x, l, False, z); Step-7 is the most compute intensive part of the algorithm. The Cryptol encoding is a bit complicated due to the need to determine if there was a carry in the addition. Since all Cryptol arithmetic is modular, we are forced to do the computation at an extended bit-size. Otherwise, the modeling of the ADC instruction is quite straightforward: // step7: ADC F2; set A to A+F2+C and C to the carry.\r\nstep7 (f1, f2, a, x, l, c, z) = step8 (f1, f2, a', x, l, c', z')\r\n  where {\r\n    // 8-bit \"modular\" result\r\n    a' = a + f2 + (if c then (1:[8]) else (0:[8]));\r\n    // Was there a carry? Check that \"real\"\r\n    // result is larger than 255\r\n    a'Large : [9];\r\n    a'Large = (a # zero) // extend a by adding zero bits\r\n            + (f2 # zero) // same for f2\r\n            + (if c then (1:[9]) else (0:[9]));\r\n    c' = a'Large > (255:[9]);\r\n    // set the zero flag\r\n    z' = a' == 0;\r\n  }; The Cryptol idiom x # zero simply represents the value x extended on the right with 0 bits. (Remember that Cryptol is little-endian, hence the addition of zero bits on the right does not change the value.) Due to the polymorphic type of the value zero , the result has any number of bits larger than equal to the original bit-size of x . (Since we only need 9-bits in this case, we could have coded the same via the expression x # [False] , but the former expression is more idiomatic Cryptol.)Steps 8 and 9 are similar to Step-4, using A and LOW instead of F1 , respectively: // step8 : ZCOEF ROR A; rotate A right circular through C.\r\nstep8 : Instruction;\r\nstep8 (f1, f2, a, x, l, c, z) = step9 (f1, f2, a', x, l, a0, z)\r\n  where {\r\n    [a0 a1 a2 a3 a4 a5 a6 a7] = a;\r\n    a' = [a1 a2 a3 a4 a5 a6 a7 c];\r\n  };\r\n\r\n// step9 : ROR LOW; rotate LOW right circular through C.\r\nstep9 : Instruction;\r\nstep9 (f1, f2, a, x, l, c, z) = step10 (f1, f2, a, x, l', l0, z)\r\n  where {\r\n    [l0 l1 l2 l3 l4 l5 l6 l7] = l;\r\n    l' = [l1 l2 l3 l4 l5 l6 l7 c];\r\n  }; Step-10 simply decrements X , setting the ZERO flag appropriately: // step10: DEX; set X to X-1\r\nstep10 : Instruction;\r\nstep10 (f1, f2, a, x, l, c, z) =\r\n  step11 (f1, f2, a, x', l, c, x'==0)\r\n    where x' = x-1; Finally, step-11 either jumps back to the top of the loop (step-4), or finishes the algorithm: // step11: BNE LOOP; branch to LOOP if Z = 0.\r\n// LOOP is step4 in our encoding\r\nstep11 : Instruction;\r\nstep11 (f1, f2, a, x, l, c, z) =\r\n  if z then (f1, f2, a, x, l, c, z) // done!\r\n  else step4 (f1, f2, a, x, l, c, z); From a control-flow perspective, we indicate the end of the algorithm by simply returning the final Mostek state. It is worthwile at this point to go through the Cryptol embeddings of the instructions to see how they match-up to the Mostek assembly given by Legato. Extracting the multiplier Having coded Legato’s multiplier as a sequence of state transformers, we can simply call the function step1 to use it with an appropriate state. The following helper function simplifies this task for us, by loading the registers F1 and F2 , and extracting the high and low bits at the end: legato : ([8], [8], Mostek) -> ([8], [8]);\r\nlegato (f1, f2, st) = (hi, lo)\r\n  where {\r\n    // get the relevant parts\r\n    // to construct the starting state\r\n    (_, _, A, X, LOW, C, Z) = st;\r\n    // Run legato multiplier;\r\n    // final A is hi; and final LOW is low\r\n    (_, _, hi, _, lo, _, _) = step1 (f1, f2, A, X, LOW, C, Z);\r\n  }; Note that legato still takes the starting machine state st as an argument. Legato’s claim (which we will shortly prove) is that the algorithm works correctly no matter what the initial state is, hence it is important to be explicit about the starting state.To see legato in action, let’s just run it on a simple input: legato> legato (12, 93, (9, 42, 3, 8, 1, False, True)) (4, 92) where I just made up the initial state by plugging in some random values. If Legato is right, then it must be the case that 12 * 93 = 256 * 4 + 92 correctly computing the high and low bytes. And voila! Both sides equal 1116. Magic! Correctness If you do believe in magic,  you can stop reading now. But I suspect most readers of the Galois blog will be looking for something more concrete. Surely, we must be able to give a better argument than claiming witchcraft for the correctness of our implementation.Let us first formally capture what we mean by “correct,” by writing a Cryptol theorem that expresses our intuitive expectation: theorem legatoIsCorrect: {x y st}. x' * y' == 256 * hi' + lo'\r\n  where {\r\n    (hi, lo) = legato (x, y, st);\r\n    hi', lo', x', y' : [16];\r\n    hi' = hi # zero;\r\n    lo' = lo # zero;\r\n    x' = x # zero;\r\n    y' = y # zero\r\n  }; Here’s the English reading of this theorem: “For all values of x , y , and st , if we run legato on these values and get the results hi and lo , then, it’ll be the case that x * y = 256 * hi + lo .” The only caveat is that we have to do arithmetic operations over 16 bit values (instead of 8), to make sure the theorem statement correctly captures the intended mathematical meaning. (Recall that all Cryptol arithmetic is modular with respect to the bit-size involved.) Hence, we simply add extra zero ‘s at the end to enlarge the arguments to 16 bits. Note that, we do not have to assert that the value of lo is at most 255; this is automatically guaranteed by the fact that it is an 8-bit value. Cryptol’s bit-precise type system saves the day! Verification Here’s what happens when I run cryptol on the file containing the above theorem: $ cryptol legato.cry\r\nCryptol version 1.8.5, Copyright (C) 2004-2009 Galois, Inc. www.cryptol.net\r\nType :? for help\r\nLoading \"legato.cry\".. Checking types.. Processing.. Done!\r\n*** Auto quickchecking 1 theorem.***\r\nChecking \"legatoIsCorrect\" [\"legato.cry\", line 147, col 1]\r\nChecking case 100 of 100 (100.00%)\r\n100 tests passed OK\r\n[Coverage: 3.47e-14%. (100/288230376151711744)] When Cryptol sees a theorem declaration in a loaded file, it automatically performs a quick-check run to provide feedback on its validity. In this case, Cryptol automatically created 100 random test values for the theorem and checked that each one of them satisfied the statement. This is a quick way of getting feedback on the correctness of theorems, courtesy of Cryptol at no additonal cost to the user!While the quick-check run is promising, the coverage info indicates that we’ve barely scratched the surface. The entire state space in this case has 58 bits (8 each for x and y , plus the starting arbitrary state of the Mostek machine costing us an extra 42 bits; for a total of 58). The total number of possible inputs is, therefore, 2 58 or 288230376151711744. This is a huge number: If you had a computer that run 1-billion (10 9 ) test cases every second, it’d still take you over 9 years to go through all possible inputs!Of course, we can do better. Cryptol’s theorem proving environment uses modern equivalence-checkers to prove such theorems automatically, at the push of a (virtual) button: legato> :prove legatoIsCorrect\r\nQ.E.D. And there, we’ve proved that our implementation of Legato’s multiplier is indeed correct for all possible inputs! (The above proof takes about 2.5 minutes to complete on my 3-year old MacBook Pro, using abc as the underlying equivalence checker in Cryptol’s symbolic mode. I should also note that the symbolic mode is only available in the full Cryptol release, for which free licenses are available.) Closing thoughts I must emphasize that we are not advocating Cryptol as a platform for doing proofs of algorithm correctness. Modern theorem provers such as ACL2, Coq, or Isabelle are the leading tools in this regard. (In particular, the logic behind Cryptol’s automated theorem prover is much less expressive, for starters.) Where Cryptol shines is in its restricted attention to bit-vectors and data-flow algorithms (cryptography being a prime application area), and it turns out that automated equivalence-checking based techniques do perform rather well for such problems. Our shallow embedding of Legato’s multiplier and the automated proof-of-correctness is a case in point.There is one more important point to make. While push-button provers are indispensable in industrial practice, the final Q.E.D. you get from an interactive theorem prover such as ACL2 or Isabelle is much more satisfactory. For instance, we can hardly claim that the above proof increased our understanding of Legato’s algorithm in any sense, it just made us really believe it. I’m willing to bet that anyone who goes through a similar proof in ACL2 or Isabelle would have a much higher chance of having their “ah a!” moment, where everything just sinks in…On the practical side, however, nothing beats the fully-automated Q.E.D., especially when your boss is breathing down your neck! Download The Cryptol file containing Legato’s multiplier and the correctness theorem is here . The Cryptol toolset licenses are freely available at www.cryptol.net .", "date": "2009-07-08"},
{"website": "Galois", "title": "Ukraine Election Spotlights eVoting Vulnerabilities", "author": "Unknown", "link": "https://galois.com/blog/2014/06/ukraine-election-spotlights-evoting-vulnerabilities/", "abstract": "In an interview with The Christian Science Monitor , Joe Kiniry , Galois’ digital voting systems cyber-security expert, weighs in on the narrowly missed catastrophe of a hacked election in last month’s Ukranian presidential election. To learn more, read the article .", "date": "2014-06-18"},
{"website": "Galois", "title": "John Launchbury to Join DARPA as Program Manager", "author": "Unknown", "link": "https://galois.com/blog/2014/06/john-launchbury-join-darpa-program-manager/", "abstract": "John Launchbury, Galois’ founder and former Chief Scientist, will be joining DARPA’s Information Innovation Office this summer as a program manager. In this position, Launchbury will be overseeing the existing High-Assurance Cyber Military Systems (HACMS) and Programming Computation on Encrypted Data (PROCEED) programs, as well as new projects still under development. Read more about the move in the Portland Business Journal’s interview with Dr. Launchbury here .", "date": "2014-06-09"},
{"website": "Galois", "title": "Galois’ Work for DARPA HACMS in the News", "author": "Unknown", "link": "https://galois.com/blog/2014/05/galois-work-for-darpa-hacms-in-the-news/", "abstract": "Galois continues to advance building secure, hack-proof critical flight control software in its work on SMACCMPilot, part of DARPA’s High Assurance Cyber Military Systems (HACMS) program. We demonstrated technology developed to-date under this program at DARPA I2O’s Demo Day on May 21 at the Pentagon. Read more about the program and what our team is doing in this article recently published on Signal Online . All of the software behind SMACCMPilot is open source and documented on the project web site . We welcome collaboration with programming languages, formal methods, and flight control researchers! For more information, contact Lee Pike and Pat Hickey .", "date": "2014-05-30"},
{"website": "Galois", "title": "A Cryptol Implementation of Skein", "author": "Unknown", "link": "https://galois.com/blog/2009/01/a-cryptol-implementation-of-skein/", "abstract": "Following on from the MD6-in-Cryptol posting , let’s consider another very interesting candidate from the (deep) pool of SHA-3 submissions; Skein http://www.skein-hash.info/ http://www.schneier.com/skein.html by the merry band of Ferguson, Lucks, Schneier, et al.The expression of their reference implementation comes out, we think, fairly cleanly in Cryptol . The digest output size is a variable parameter to the algorithm, but we’ll focus on the 512-bit version here — the submission’s primary candidate for SHA-3.In order to avoid duplicating the introductory material on Cryptol, we suggest the reader go through the MD6 writeup to get a grounding in Cryptol, its idioms, and syntax. The structure of Skein Skein refers to a family of hashing functions, differing in the size of their internal state. We’ll look at the 512-bit version here. Skein is built up out of three main components: A tweakable block cipher, Threefish. The Unique Block Iteration(UBI) chaining mode, defining the mode-of-operation by the repeated application of the block cipher function. Optional arguments to the hashing function. Extra functionality and input to the hashing function can be accommodated via Skein’s optional argument system. There is also input, like key material and randomized-hashing via nonces, etc. (see spec for details). We won’t consider any such additional inputs in our implementation of the basic hashing functionality. We’ll take the same tack as with the MD6 presentation – starting at the top by showing the mode-of operation function, working our way down to the tweakable block cipher that the Skein team developed as part of Skein. The Skein hashing function The pure/simple Skein hashing function (512 bit) transforms an arbitrary length byte sequence into a 512-bit output: hash512 : {a}\r\n// type constraints\r\n( fin a // finite input\r\n, 32 >= width (8*((8*a+7)/8))\r\n, 32 >= width (8*a)\r\n, 64*(((8*a+7)/8+63)/64) >= (8*a+7)/8\r\n, 8*((8*a+7)/8) >= 8*a\r\n) => [a][8]   // input message\r\n  -> [64][8]; // 512-bit result The Cryptol type signature captures that (and more!), with the [64][8] result packaging up the result into a 64-element wide sequence of 8-bit bytes. The type constraints look involved, but capture the pre-condition that the input message size has already been padded out to the desired width. (Writing Cryptol functions that automatically perform padding based on input sizes is possible, but would be a distraction here.)The definition of hash512 closely mirrors the specification (Section 3.5.4): hash512 m = output512 g1\r\n  where {\r\n    k = (zero : [64][8]);\r\n    c = mkConfig(512); // config string, see Section 3.5.2 of spec.\r\n    g0 = ubi512 (encrypt512, k,join c, t_cfg);\r\n    g1 = ubi512 (encrypt512,g0,join m, t_msg);\r\n  }; i.e., it is the double application of the chaining mode UBI, followed in the end by the computation of the result by the output512 function. As the internal size has been fixed here to 512, the innermost UBI computation is actually all over constant inputs and could be folded/optimized away. This optimization can be done manually or by the Cryptol tools, but we won’t bother with the optimization here.The output function is simply another application of the UBI: output512 : [64][8] -> [64][8];\r\noutput512 g = ubi512 (encrypt512, g, (zero:[64]), t_out); i.e., a straight UBI computation of the internal state argument g to the null message and a special output type value.Regarding t_out , the various t_X values in the above represent the type values that Skein defines — t_out : [128];\r\nt_out = ((0x3f: [6]) # zero) << 120;\r\nt_cfg : [128];\r\nt_cfg = ((0x04: [6]) # zero) << 120;\r\nt_msg : [128];\r\nt_msg = ((0x30: [6]) # zero) << 120; i.e., padded out to 128-bit widths so as to fit with subsequent use as basis for Skein’s tweak values.That’s the toplevel driver for the Skein hashing function. Let’s consider next the chaining mode that it builds upon. UBI: the Unique Block Iteration chaining mode The chaining mode employed by Skein is parameterized over the following values: G – (chained) internal state / starting value. M – the message string. T – a 128-bit starting value for the tweak (the type value from the above.) As a Cryptol type signature, its external interface would be ubi512 : {a}\r\n( fin a\r\n, 32 >= width (8*((a+7)/8))\r\n, 32 >= width a\r\n, 64*(((a+7)/8+63)/64) >= (a+7)/8\r\n, 8*((a+7)/8) >= a\r\n) => ( (([64][8],[16][8],[64][8]) -> [8][64]) // block cipher function\r\n     , [64][8]       // initial (chained) value / state.\r\n     , [a]           // input message\r\n     , [128]         // tweak base value\r\n     ) -> ([64][8]); // 512 bit result The type constraints all involve the type variable a , which is the size of the input message. Together they express the padding assumptions made or introduced over that bit string.The function takes four arguments, the first being a function value — the block cipher function to apply for each of the blocks that the input message is divvied up into. We’ll have more to say about its type and properties in the next section when we show how the Threefish cipher is expressed in Cryptol.The other three are the G, M, and T parameters to the UBI, which we can now define as follows: ubi512 (encryptor,g,m,t) = last hs\r\n  where {\r\n    hs = [g] # [| m ^ split(join(encryptor(h, groupBy(8,mkTweak(t,width(m1),nb,width ms,i,b)),m)))\r\n               || h Like before, let’s start with the result value and work ourselves inwards from there — the result being the last element of the hs sequence. hs represents the result of processing each block (512 bits) of the input message. The definition of hs expresses how to compute block N’s digested output: hs = [g] # [| m ^ split(join(encryptor(h, groupBy(8,mkTweak(t,width(m1),nb,width ms,i,b)),m)))\r\n           || h The iterative nature of the chaining mode is captured as a recursive sequence comprehension in Cryptol, with each of the arms of the comprehension providing input to the UBI’s result computation (e.g., m <- ms selects each block in turn.) That result computation is a bit of a mouthful, but easy enough to pick apart a bit: m ^ split(join(encryptor(h, groupBy(8,mkTweak(t,width(m1),nb,width ms,i,b)),m))) i.e., XORing the message block with the application of the block cipher encryptor — encryptor(H,Tweak,MsgBlock) where Tweak is a 128-bit value made up out of a range of parameters, globally-constant, per-UBI-specific and per-round, all contributing to diffusing the output. The h is the output from the previous invocation of the block cipher, i.e., to compute element we need to have access to the previous UBI result only.We hope it is relatively straightforward to map the definition of hs back to the recurrence relation that defines the UBI in Section 3.4 of the Skein specification . With tweaks and message blocks in place, it is time to consider the block cipher that Skein uses. Threefish, a tweakable block cipher This block cipher is parameterized over the following values: K – block cipher key (512 bits / 64 bytes) T – tweak (128 bits / 16 bytes) P – plaintext (equal to key) Deriving the Cryptol type signature from that is straightforward: encrypt512 : ([64][8],[16][8],[64][8]) -> [8][64]; with the result being 8 64-bit words. This simple type hides many a clever detail though: encrypt512 (key,tweak,pt) = vn + kn\r\n  where {\r\n    vn : [nw][64];\r\n    vn = last vss;\r\n    kn : [nw][64];\r\n    kn = last kss;\r\n    // ...more below... The result is the element-wise addition of two 64-bit word sequences of width 8 (cf. the definition of the ciphertext C in Section 3.3 of the specification). kn is the last value from the key schedule of the cipher, and vn is the last value from the round computation. The key schedule is a Cryptol sequence of values, splitting up the input key and tweak into round/4 sub-keys: kss : [19][nw][64];\r\nkss = [| keySchedule_8(tw_words, key_words, d) || d We won’t show the implementation of the keySchedule_8() function here, but the reader is encouraged to download the sources and look it over in Skein/Threefish.cry .The subkeys are combined together with the per-round values: vss : [73][nw][64];\r\nvss = [pt_words] # [| fs @@ pi_8 || fs Again, we won’t go into further details on the internals of the cipher, but it is worth highlighting the use of mutually recursive sequences values — vss is computed in terms of fss , which is defined in terms of ess , which ties the knot back to vss in its definition. The recursive nature works out by being initialized with pt_words as the result of round 0. The MIX function Threefish uses the MIX function to perform its permutation and mixing; encoded in Cryptol as follows: mix8 : ([8],[8][64]) -> [8][64];\r\nmix8 (d,xss) = join [| mix_8(d,j,xs) || j  [2][64];\r\nmix_8 (d,j,[x0 x1]) = [y0 y1]\r\n  where {\r\n    y0 : [64];\r\n    y0 = (x0 + x1);\r\n    y1 = (x1 <<< (rs_8 @ j @ ((d%0x8)#zero))) ^ y0;\r\n  }; Included here for completeness, the round-dependent permutation of its 512-bit input maps relatively cleanly onto the specification of MIX in Section 3.3.1 . The built-in groupBy operator perform useful function here in dividing up its per-round input: groupBy : {a b c} (b,[a*b]c) -> [a][b]c i.e., if the second argument is a multiple of the first ( b ), we can divide it up into a values of width b . Use it here to split up the 512-bit input into 4 pairs of 128-bit values. Concluding remarks Skein has an appealingly clean structure and composition, something we hope to have maintained some in its Cryptol rendition. The use of recursive sequence definitions to express the chaining and iterative nature of the algorithm is one place which helped in maintaining the clear mapping back to the specification. Having a clean reference implementation like this has considerable value, but using it with Cryptol and its toolchain, you may take advantage of its definition in a number of ways. Please see the concluding remarks for the MD6 posting for an outline of what they are. Downloading Cryptol Skein If you want to try out the implementation of Skein in Cryptol, it’s available from download as a separate archive . Load it into your Cryptol interpreter , and verify its sanity by running some of the known-answer tests: Cryptol> :load Skein.cry\r\n...\r\nSkein> ts_1\r\nTrue\r\nSkein> ts_4\r\nTrue\r\nSkein> To have a closer look at the underlying code and experiment with it, edit the .cry files followed by :reload from the Cryptol interpreter prompt. Want more? If you’d like to see more examples of Cryptol, maybe other SHA-3 candidates, please let us know. Or, better still, have a go at implementing some of them yourself. The CubeHash submission by D.J. Bernstein is perhaps a good place to start? Author (\"Sigbjorn Finne\" # \"Galois, Inc\" # \"2009-01-23\") : [35][8]", "date": "2009-01-24"},
{"website": "Galois", "title": "Shuffling a deck of cards, Cryptol style", "author": "Unknown", "link": "https://galois.com/blog/2009/12/shuffling-a-deck-of-cards-cryptol-style/", "abstract": "I can never shuffle cards properly. They seem to go every which way when I try, and a perfect random shuffle seems nigh-impossible to achieve, even though the experts claim it takes a mere 7 moves . (The mathematical argument is surprisingly quite technical .) Luckily, we shall concern ourselves with a much simpler problem today: How many perfect out-shuffles does it take to restore a deck back to its original order? We’ll throw in a couple of variants of the problem for fun, but rest assured that we’ll let computers do the work. And, of course, we’ll use Cryptol to help us along the way. What is a riffle shuffle? According to wikipedia , a riffle (or dovetail) shuffle goes like this: … half of the deck is held in each hand with the thumbs inward, then cards are released by the thumbs so that they fall to the table interleaved. Many also lift the cards up after a riffle, forming what is called a bridge which puts the cards back into place… Well, I read that a couple times, and watched a couple of videos on the internet showing how to do it, but no luck so far. Luckily, this sort of shuffling is quite easy to express programmatically, and Cryptol has the right abstractions to code this in a couple of lines. Bisecting the deck The first step in the shuffle is bisecting the deck into two equal halves: bisect : {a b} (fin a) => [2*a]b -> ([a]b, [a]b);\r\nbisect xs = (take (w, xs), drop (w, xs))\r\n  where w = width xs / 2; We simply compute the mid-point, and divide the given sequence xs into two, by take ‘ing and drop ‘ping the correct amounts from the input sequence. In fact, the type of bisect is more interesting than its definition: It succinctly captures the following four facts: The input has to be of even length ( 2*a ), The input has to be finite ( fin a ), The output has two components, each of which has precisely a elements, that is, half the input, The actual contents of the sequence can be of any type ( b ), i.e., the function bisect is shape-polymorphic in the contents. The ability to express precise size/shape-polymorphic properties using types is one of the strengths of Cryptol. Out-shuffle vs. in-shuffle Once the deck is split into two, we proceed by picking the cards alternatingly from each half. We have two choices: We can either start with the first half, or the second. If you start with the first half, that’s called an out-shuffle. If you start with the second half, then it’s an in-shuffle. These two functions are actually quite easy to code in Cryptol: outShuffle : {a b} (fin a) => [2*a]b -> [2*a]b;\r\noutShuffle xs = join [| [x y] || x <- fh || y <- sh |]\r\n  where (fh, sh) = bisect xs;\r\n\r\ninShuffle : {a b} (fin a) => [2*a]b -> [2*a]b;\r\ninShuffle xs = join [| [y x] || x <- fh || y <- sh |]\r\n  where (fh, sh) = bisect xs; The definitions are almost identical, except for the order in which we put the cards from the halves ( fh and sh ) together. In the outShuffle , the first card in each pair comes from the first-half. In the inShuffle , it comes from the second half. Easier done than said! Let’s make sure they behave as we expect: Cryptol> bisect [1..8] ([1 2 3 4], [5 6 7 8])\r\nCryptol> outShuffle [1..8] [1 5 2 6 3 7 4 8]\r\nCryptol> inShuffle [1..8] [5 1 6 2 7 3 8 4] Good! It’s interesting to see what happens when we apply bisect to an odd-length sequence: Crytpol> bisect [1..9]\r\nIn a top-level expression: with inferred type: {a} ([a][4],[a][4])\r\nencountered the following unresolved constraints: fin a 2*a == 9 Cryptol is basically telling us that there is no a such that 2*a is 9 , resulting in a type-error. Note that this is a static-check before you run your program! In other words, if your program type-checks, then you can rest assured that whenever you call bisect , it is guaranteed to get an even-length sequence as its argument. Strong static typing and size-polymorphism of Cryptol really pays off in this case! Sequences of shuffles Before proceeding to the properties of shuffles, we need one last notion: The application of a shuffle repeatedly to a given input, yielding an infinite sequence of transformations: iterate : {a} (a -> a, a) -> [inf]a;\r\niterate (f, x) = [x] # iterate (f, f x);\r\noutShuffles, inShuffles : {a b} (fin a) => [2*a]b -> [inf][2*a]b;\r\noutShuffles xs = iterate(outShuffle, xs);\r\ninShuffles xs = iterate(inShuffle, xs); The high-order function iterate gives us the infinite sequence of results of applying a function to a value over and over. We simply use this helper to define outShuffles and inShuffles to apply the corresponding functions indefinitely to their input. Note that the resulting type shows that we get an infinite sequence as output, as indicated by the size inf . Properties of shuffles It turns out that if one applies 8 out-shuffles to a deck, a remarkable thing happens: Nothing! The deck goes back to its original order! This is a bit hard to believe, and harder to realize using a real deck of cards. (A friend of mine says he saw it done at college once by hand, but I’m yet to meet anyone who can do this successfully so far!)Well, the good thing about programming is that we can manipulate the sequences at will, without fear of messing up the cards. Even better, we can assert the above claim as a theorem in Cryptol: type Deck = [52][6];\r\noutShuffle8 : Deck -> Bit;\r\ntheorem outShuffle8: {deck}. outShuffles(deck) @ 8 == deck; We have defined a Deck to be a sequence of 52 things, each of which is 6-bits wide, which is more than enough to cover all the 52-unique elements that appear in an ordinary deck. (6-bits can encode 64 values, so we have 12 unused elements.) The theorem simply states that the 8’th element of the infinite sequence of outShuffle applied to an arbitrary deck gives us back the original deck.Let’s ask Cryptol to prove this theorem: (Cryptol’s symbolic and sbv backends can perform these proofs, so we first set our mode accordingly below.) Cryptol> :set sbv\r\nCryptol> :prove outShuffle8\r\nQ.E.D. Voila! The proof completes instantaneously, with almost no time elapsed. (This might be surprising at first, since the input space to the theorem has 52*6 = 312 bits, which is quite large. However, we note that the theorem is actually fairly easy to prove since all shuffling does is a mere re-ordering of things with no specific computation; which is easy to manipulate symbolically for Cryptol’s proof engine.) Reversing the deck Can we reverse a deck of cards using outShuffle ‘s? Turns out that this cannot be done. In particular, an outShuffle never moves the first element of the deck anywhere: outShuffleFirstCard : Deck -> Bit;\r\ntheorem outShuffleFirstCard: {deck}. outShuffle deck @ 0 == deck @ 0; We have: Cryptol> :prove outShuffleFirstCard\r\nQ.E.D. Since the first card remains stationary, there is no way to reverse a deck of cards by just using outShuffle s.How about with inShuffle ? Turns out the magic number is 26 for reversing a deck of cards in this particular case: inShuffle26Rev : Deck -> Bit;\r\ntheorem inShuffle26Rev : {deck}. inShuffles(deck) @ 26 == reverse deck; Again, the proof is immediate: Cryptol> :prove inShuffle26Rev\r\nQ.E.D. If 26 in-shuffle’s reverse the deck, then 52 of them will restore it back. Here’s the corresponding theorem: inShuffle52 : Deck -> Bit;\r\ntheorem inShuffle52: {deck}. inShuffles(deck) @ 52 == deck; Again, the proof is immediate. The Mongean Shuffle There is one more variation on the shuffle that we will consider. The mongean shuffle picks the even and odd numbered elements, reverses the odds and adds the evens at the back. For instance, given the sequence: 0 1 2 3 4 5 6 7 8 9 , we first construct two sub-sequences: The even index elements: 0 2 4 6 8 , and the odd ones 1 3 5 7 9 . We then reverse the latter to get 9 7 5 3 1 , and append the former, obtaining: 9 7 5 3 1 0 2 4 6 8 . Luckily, the Cryptol definition is much easier to read: monge xs = reverse odds # evens\r\n  where {\r\n    w = width xs;\r\n    evens = xs @@ [0 2 .. (w-1)];\r\n    odds = xs @@ [1 3 .. (w-1)]\r\n  };\r\nmonges xs = iterate(monge, xs); With a monge shuffle, it takes 12 rounds to restore a deck: monge12 : Deck -> Bit;\r\ntheorem monge12: {deck}. monges(deck) @ 12 == deck; We will leave it to the reader to construct the argument that no sequence of monge shuffles would reverse a deck. (In particular, one can prove that the 18th element from top will never move in a deck of 52. Proving this theorem in Cryptol is again quite trivial.) A note on theorems The attentive reader might worry that our Deck type does not quite correspond to a deck-of-cards. This is indeed the case. There are two discrepancies. First, as we mentioned before, our decks can represent 64 elements, while a deck of cards has only 52 distinct cards. On the plus side, this just makes our theorems “stronger,” since we allow for more cards then possible. More importantly, the properties are intended for decks that have no-repeating cards in them. (That is, every card occurs precisely once.) But our theorems apply to arbitrary deck ‘s, even those that have repeating elements in them. Again, this just makes our theorems stronger, as the unique-sequence cases directly follow from them. We can rest assured that our proofs are conclusive, even though our model of playing-cards is not perfect. Download Free evaluation licenses of Cryptol are available at www.cryptol.net . The Cryptol source code for shuffling cards is also available as well.", "date": "2009-12-26"},
{"website": "Galois", "title": "Solving n-Queens in Cryptol", "author": "Unknown", "link": "https://galois.com/blog/2010/04/solving-n-queens-in-cryptol/", "abstract": "The eight queens puzzle asks how to place eight queens on a chess board such that none of them attacks any other. The problem easily generalizes to n queens, using an nxn board. In this post, we’ll see how to solve the n-Queens puzzle in Cryptol, without lifting a finger! Representing the board It is easy to see that any solution to the n-Queens puzzle will have precisely one queen on each row and column of the board. Therefore, we can represent the solution as a sequence of n row numbers, corresponding to subsequent columns. For instance, the board pictured below (taken from the wikipedia page ), can be represented by the sequence 3    7    0   2   5    1   6   4 recording the row of the queen appearing in each consecutive column, starting from the top-left position. (And yes, we always count from 0!) Recognizing a valid solution Let us start by asking a simpler question. How can we recognize that a given sequence of n row indices constitute a valid solution? We have to verify that the followings hold: The numbers must be between 0 and n-1. (Sanity checking.) The numbers should not be duplicated. (Ensures that there is exactly one queen per row.) For any pair of numbers in the sequence, their row-value difference should be different than their column-value difference. (Ensures that there are no diagonal conflicts.) The first two conditions are fairly trivial. The last one simply says that if two queens are positioned such that their vertical and horizontal displacements are the same, then they are on the same diagonal: A situation we must avoid for all pairs of queens given. Writing a Cryptol predicate Having described how we will recognize an alleged solution, let us now consider how we can code this in Cryptol.First, we will need a helper function that applies a given predicate to all the elements of a sequence and returns True if all elements satisfy the predicate. Naturally, we call this function all : all : {n a} (fin n) => (a -> Bit,[n]a) -> Bit;\r\nall (f, xs) = [|f x || x <- xs|] == ~zero; The type of this function is worth spending a few moments looking at, as it demonstrates some crucial aspects of  Cryptol’s type system that sets it apart from other languages. In particular, it says that the function all takes a sequence of n elements, each of some arbitrary size a . However, it also restricts n to be  finite, i.e., the type system will complain if you pass all an infinite sequence. Then, we apply the predicate f to each element in the sequence, and check that the result consists of all True bits. (The polymorphic Cryptol value zero represents a value with an arbitrary shape with all bits set to False . The complement operator ( ~) flips all those bits to True .)The second utility function we will need is a predicate that checks whether the elements of a given sequence are all distinct: distinct : {a b} (fin a,fin b) => [a]b -> Bit;\r\ndistinct xs = diff == ~zero\r\n  where {\r\n    n = width xs;\r\n    diff = [|check (x, i) || x <- xs || i <- [0 .. (n-1)] |];\r\n    check (x, start) = walk (start + 1)\r\n      where walk cur = if cur == n then True else if xs @ cur == x then False else walk (cur + 1);\r\n  }; The function distinct is fairly simple: For each element in the sequence, it walk ‘s through the rest to make sure that none of the remaining elements are the same as that particular element. Note how Cryptol’s width function allows us to determine the size of the input sequence, and recurse properly.Having done the heavy-lifting above, we can now write the predicate that recognizes a valid n-Queens solution in Cryptol: type Solution(n) = [n][1+width n] -> Bit;\r\nnQueens : {n} (fin n) => Solution(n);\r\nnQueens qs = all(inRange, qs) & distinct qs & all(checkDiag, ijs)\r\n  where {\r\n    n = width qs;\r\n    inRange x = x < n;\r\n    ijs = [| (i, j) || i <- [0 .. n-1] , j <- [0 .. n-1] |];\r\n    checkDiag (i, j) = (i >= j) | (diffR != diffC)\r\n    where {\r\n      qi = qs @ i;\r\n      qj = qs @ j;\r\n      diffR = if qi >= qj then qi-qj else qj-qi;\r\n      diffC = j - i;\r\n    };\r\n  }; The nQueens function simply executes our checks as we described above. It first makes sure that all the elements are inRange . (Note that we do not have to check for negative numbers since all Cryptol numbers are non-negative.) Then, we check that all the elements are distinct . Following this, we generate the pairs of indices ijs , and call checkDiag on all these pairs to make sure that the row and column differences do not match.We can test this function in Cryptol, by providing sample input: NQueens> nQueens [3 7 0 2 5 1 6 4] True\r\nNQueens> nQueens [3 7 0 2 5 6 1 4] False In the second example, I swapped the elements 1 and 6; effectively putting the 6th queen on row 6 and the 7th on row 1. This creates a diagonal conflict  as the reader can easily verify. Solving n-Queens It appears that all we have done so far is to write a Cryptol program to recognize whether a given solution to the n-Queens problem is valid. But, how do we actually solve the puzzle?Remember that I promised to solve n-Queens without lifting a finger, and this is where Cryptol’s formal methods based tools come into the picture. Given any predicate (like nQueens above), Cryptol can find inputs that will satisfy it automatically, at the push of a button! (We have briefly described how this works in our previous post on Sudoku , so I shall not go into any details. Suffice it to say that one can exploit modern SAT/SMT solvers to generate automatic solvers for validity problems, and Cryptol provides just the right framework for doing so.)Without further ado, here is how we solve n-Queens in Cryptol, without writing any additional code on top of what we have already seen: NQueens> :set sbv\r\nNQueens> :set base=10\r\nNQueens> :sat nQueens : Solution(8) (nQueens : Solution(8)) [2 7 3 6 0 5 1 4] \t = True The first command puts Cryptol in the sbv mode, which allows for the use of SAT/SMT solvers. The second command tells Cryptol to print results in base 10. Finally, the :sat command finds satisfying assignments for predicates. The type-signature on the :sat command indicates that we are interested in solutions for 8-queens, for which we are given a solution almost instantaneously!If you look at the wiki-page for n-queens, you will see that they claim there is always a solution when n=1 and n>=4 . We can indeed verify that there are no solutions when n is 2 or 3, using Cryptol: NQueens> :sat nQueens : Solution(2)\r\nNo variable assignment satisfies this function\r\nNQueens> :sat nQueens : Solution(3)\r\nNo variable assignment satisfies this function While these two properties are easy to see, it’s quite valuable to get independent verification! In practice… We would be remiss if we didn’t mention some of the actual uses of the satisfiability checker in the Cryptol tool chain. The most important application is in verifying functional equivalence of two functions. If f and g are two functions, then they are functionally equivalent exactly when the predicate (x -> f x != g x) is not satisfiable. (Conversely, if this predicate is satisfiable then the satisfying value is where f and g disagree, indicating a potential bug.) More importantly, f and g need not be both written in Cryptol. The toolchain allows performing equivalence checking between functions written in VHDL, C, and Java (with varying degrees of “seamless” integration!). Furthermore, this is also how we make sure our compiler produces correct code: The function g can be generated code, for instance in one of Cryptol’s intermediate languages as we compile Cryptol to FPGA descriptions. In summary, we can check the equivalence of 3rd party code (generated or hand-written) against “gold” Cryptol specifications, increasing assurance in the correctness of crypto-implementations. Download You can download the Cryptol solution for n-Queens . Cryptol licenses are also available free of charge at www.cryptol.net , although I should note that the SAT/SMT based backends are only available in the full-releases of Cryptol, which requires a simple form to be filled before downloading. Enjoy!", "date": "2010-04-12"},
{"website": "Galois", "title": "Cryptol Version 2 Released (and open sourced!)", "author": "Unknown", "link": "https://galois.com/blog/2014/04/cryptol-version-2-released-and-open-sourced/", "abstract": "We are pleased to announce the open source release of Cryptol version 2. Bugs in crypto code have been in the news lately – Cryptol helps developers detect (or avoid) correctness errors in cryptographic code. What Cryptol does is reduce the gap between the reference specification of a cryptographic algorithm and an executable version which can be used for testing and verification. This is the first fully public release of Cryptol, but earlier versions have been under development at Galois, and in use around the world, for almost 15 years. We look forward to working with the cryptography and verification communities to make Cryptol more expressive and powerful — towards the goal of reducing the number of bugs in critical cryptographic implementations in software and hardware. Visit http://cryptol.net to learn more about the language, to download the software, or to check out the source code.", "date": "2014-04-25"},
{"website": "Galois", "title": "Galois is Hiring!", "author": "Unknown", "link": "https://galois.com/blog/2011/07/galois-is-hiring/", "abstract": "Do you want to lead the development of the next generation of embedded systems that transform how we interact with the physical world? Do you want to make secure cloud computing a reality? Can you help us develop and exploit secure, ubiquitous networked devices? Galois has a position open for a senior computer scientist in our Portland office.  This individual will support existing research programs and internal research and development efforts and provide technical leadership in the development of new capabilities and business opportunities.  Such leadership may include development of new R&D efforts and expansion of existing efforts.  The candidate should be an experienced and recognized researcher in the field capable of envisioning, designing and leading new R&D efforts and large, complex programs. Click here for more information.", "date": "2011-07-20"},
{"website": "Galois", "title": "Galois’ Open-Source Projects on GitHub", "author": "Unknown", "link": "https://galois.com/blog/2012/04/galois-open-source-projects-on-github/", "abstract": "Galois is pleased to announce the movement of our open source projects to GitHub! As part of our commitment to giving back to the open source community, we have decided that we can best publish our work using GitHub’s public website. This move should provide the open source community more direct access to our repositories, as well as more advanced collaboration tools. Moved repositories include the widely-used XML and JSON libraries, our FiveUI extensible UI Analysis tool, our high-speed Cereal serialization library, our SHA and RSA crypto packages, the HaLVM, and more. For a list of our open source packages, please see our main GitHub page here: https://github.com/galoisinc We are very excited to interact with the GitHub community and utilize all the great tools there. On the other hand, if you’re not a GitHub user, please feel free to continue to send us any patches or suggestions as per usual. For those currently hacking on projects using our old repositories at code.galois.com, we apologize for the inconvenience! The trees on GitHub hold the exact same trees, however, so you should be able to add a remote tree (git remote add) and push without too much difficulty. As always, we would love to hear your feedback. Been waiting for this change? Hate it? Wonder how to push your changes to us? Please email us at github@galois.com .", "date": "2012-04-04"},
{"website": "Galois", "title": "Galois Internship Available", "author": "Unknown", "link": "https://galois.com/blog/2012/08/galois-internship-available/", "abstract": "Galois, Inc.  has one or more internships available in Portland, Oregon, USA. PROJECT OVERVIEW: The project is a 4+ year research project on high-assurance autonomous vehicles. Galois will be working on three aspects of this problem: Synthesizing software components from Haskell-based embedded DSLs. Building/porting a hardware platform for testing our prototypes. Performing static/dynamic analysis on C/C++ code to detect vulnerabilities. We intend to release open-source most (if not all) source code developed on the project and we will be publishing on our research results. Being an intern for repeated terms is a possibility. LOGISTICS: The length and start date of the internship are all negotiable: anytime from this fall through next fall is acceptable.  Ideally, you can be at Galois for at least 3 continuous months.  The internship is paid competitively, and the intern will be responsible for her own living arrangements (although we can certainly help you find arrangements).  Galois is located in the heart of downtown, with multiple public transportation options available and world-class bicycle infrastructure, so living here without an automobile is a viable option. QUALIFICATIONS: MUST-HAVES: The ability to be geographically located in Portland during the internship. Good knowledge of C/C++. Some experience with low-level/embedded design. Excellent software engineering ability and aptitude. NICE-TO-HAVES (not necessary, but let me know if you have these qualifications!): Experience with Haskell and particularly embedded DSLs. Experience with microcontrollers (particularly ARM Cortex M). Experience with control systems. Interest in/experience with real-time systems and RTOSes. Interest in/experience with software security. Interest in/experience with static analysis. Experience with ArduPilot or other autopilot systems. Good writing skills/experience in writing technical papers. DO NOT NEED: a specific degree (we’re interested in hearing from anyone from post-docs   to undergrads). ABOUT GALOIS: Galois, Inc. is located in Portland, Oregon with a mission to create trustworthiness in critical systems.  We’re in the business of taking blue-sky ideas and turning them into real-world technology solutions. We’ve been developing real-world systems for over 10 years using Haskell. To get a sense of life at Galois, one of our previous interns documented his internship here . TO APPLY: In one email, Please attach a C.V. (PDF, plain text, or markdown only). In the body of the email, include a brief plain-text note stating your interest and experience and any other relevant details. Send this to Lee Pike with the subject line “Internship 2012”.  If you follow these directions, you’ll get a confirmation from me.", "date": "2012-08-21"},
{"website": "Galois", "title": "Rapid, Consistent Web Development is Coming with HTML5", "author": "Unknown", "link": "https://galois.com/blog/2011/12/rapid-consistent-web-development-is-coming-with-html5/", "abstract": "HTML5 is coming, and it’s not just the next version of HTML. HTML began as a lightweight mark-up language for linking documents on the web, with some rendering hints. As new versions have come along, support has been added for new kinds of content (images, video, interactive content). More recently, interest has grown in understanding documents and web applications on a deeper level. The most prominent example of this is the semantic web , which seeks to move from a “web of documents” to a “web of information”. All previous versions of HTML make this an extremely challenging task, akin to trying to understand a philosophical text presented in terms of its typography. HTML5 will change that. The designers of HTML5 have taken great care to separate semantic content (the information a document is intended to convey or represent) from the process of rendering (how a document should appear in a browser). Through this “separation of concerns”, HTML5 is equipped to revolutionize how we think of the web, how we work with it, and how we create new content. Our interest is in the potential for HTML5 to change how we specify, design, build, and analyze user interfaces – wherever they may appear: on the web, mobile devices, or desktop. With consistent user experience as our guiding motivation, we survey the state of the art and practice of tool support for semantic reasoning about HTML5. Galois was recently awarded a Phase II SBIR contract by the US Army to develop automated tools capable of checking a user interface against a set of UI Guidelines, such as the Apple Human Interface Guidelines , Usability.gov’s Web Design and Usability Guidelines , and the Associated Press Stylebook . One of the key challenges with evaluating user interfaces is understanding the interface description in the first place. Choosing a common description language to support is therefore critical to success. An ideal language would support the ability to add semantic meaning to the UI description (to assist with reasoning about semantic guidelines) as well as build a vibrant community of developers and users. HTML5 is a natural fit on both of these counts. Support for microdata , microformats , and/or RDFa will extend the already rich set of semantic annotations in HTML5. The language also caters to one of the most prolific development communities around.  Furthermore, HTML5 is on the cusp of flooding user interfaces on the web, on mobile, and on the desktop. In fact, it is mostly here already: all of the leading the browsers support many proposed aspects of HTML5 . Although the specification is not finalized (at the time of this writing), it is clear that the future of the web is HTML5. Web development tools cover a wide spectrum: editors, debugging consoles in browsers, headless test environments, lint tools, and other validators. When the W3C asked their community what they needed and wanted from web development tools, the results unsurprisingly included the whole spectrum of current tools. However, developers also wanted tools that could analyze their work for desirable but subjective properties, like ease of maintenance, forwards compatibility, and cross-platform compatibility. HTML5 is more than just the next version of HTML. It opens up genuinely new possibilities, like realizing the semantic web . As HTML5’s use expands into new domains, developers will be interested in new kinds of analysis, tailored to their use-cases. For example, the design criteria for Windows 8 Metro-style applications will differ significantly from those used to target iPhone-based browsers—we can only guess what other platforms will arise in the next five to ten years. What does this mean for the working web designer, developer, or content creator? What tools are available now that support HTML5 development? What tools do we need? We can begin to answer these questions by compiling a list of the primary tools available now for HTML5 development. We begin with a look at what makes HTML5 so different from its predecessors. Then we will discuss why HTML5 has something to contribute to the world of user interface design 1 . We will continue with a brief survey of the current state of analysis tool support for HTML5, and will close with a discussion of where we see gaps. Separation of Concerns HTML5 , when it is finalized, will be the fifth revision to the core language of the web. In our view, it is the most significant revision made to date, and not just because it will subsume (or make obsolete) XHTML 1 and all prior versions of HTML, while maintaining backwards compatibility (read more on the differences between HTML 4 and HTML5 ). The designers of HTML5 have taken great care to separate the description of semantic content (i.e., what a given element of page is intended to convey to user, the action it is intended to perform, or the role it is intended to fulfill) from the process of rendering (such as how a browser should display a given element, or how that element should appear when printed). For example, using HTML5’s video tag instead of embedding a Flash player, the consumer sees the video as played by his/her browser’s default player (the configuration of which is under the user’s control). The HTML5 tells the browser what the content is (and other information, like its URI); the browser decides how to display it 2 . Apart from empowering the user, this provides some measure of forwards-compatibility: video players are certain to continue to improve over time, and those in use today are by no means guaranteed to work correctly five years from now. The video tag – by not specifying a player, but merely the desired functionality – allows for renderers to change over time. HTML5 for User Interfaces This separation of concerns, the “what” from the “how”, is also a guiding principle of good GUI design (and good design in general). Keeping this principle in mind leads to cleaner design (not polluted with premature commitment to a particular low-level rendering), which has a myriad of benefits: easier maintenance, easier extension, and simplified design-level debugging, to name a few. That this principle is exemplified in HTML5 is no accident: web-based applications are becoming increasingly indistinguishable from their desktop or mobile counterparts, and this trend will continue as browsers look more and more like complete operating systems 3 . If we can describe enough of the intended user experience and look and feel in HTML5, then we have a hope of providing consistent and familiar user interfaces across platforms. When one of those platforms is a browser being used as a rendering engine, the distinction between “web-app” and “app” is no longer relevant. Indeed, Microsoft is saying as much with their—somewhat controversial —plan to grant HTML5 (with JavaScript) the status of a fully supported Windows 8 development language (for developing metro style applications , Microsoft’s desktop, mobile touchscreen, and Xbox application framework). Survey of Existing Tools for HTML5 Editors and Debugging Aids Many tools that work for any earlier version of HTML will work fine for HTML5: text-based editors, browser-based debugging aids, etc. Support for creating valid HTML5 documents may be found in several general-purpose integrated development environments (versions of Visual Studio , Eclipse , and NetBeans , to name but three). Adobe Dreamweaver also supports HTML5. All of the popular browsers that support HTML5 have developer consoles (either built-in, or available as plug-ins), where a web developer can browse detailed error and warning messages (generally pertaining only to JavaScript), and even edit local copies of a page’s HTML, CSS, and JavaScript to test potential fixes. These can help find what we think of as surface bugs – such as having misspelled a link or having failed to initialize a JavaScript variable – but are less than helpful when it comes to finding design bugs (where bugs arise from an incorrect or ambiguous description of the intended behavior) or semantic bugs (where bugs might arise from a misunderstanding of the intended behavior, or from unintended behavior). Validators Validators check that a given document (usually HTML or XHTML) is well-formed according to some fixed schema or semi-formal specification. This is more than a simple syntactic validation, as a schema may impose structural constraints and some simple semantic constraints. HTML5 validator.nu : Validates a document against the current draft HTML5 specification. W3C’s Validator : Validates a document according to its stated DOCTYPE; if HTML, then it validates against the latest draft of the HTML5 specification. This service can also generate a corrected version of the document. However, it appears the W3C validator is based on the tool from validator.nu. Thus, there is in essence only one standalone 4 HTML5 validator readily available at the time of writing. Static Analysis Tools In general, a “static analysis tool” is any tool that provides feedback on a document’s static form. Any validator is also a static analysis tool, but we make the distinction here because, for the community at large, a validator performs a very specific analysis: checking conformance to a specification. We will use static analysis tool to refer to any tool that gives feedback about higher-level and often subjective properties of a document, such as “approved coding style”, “pleasant visual design”, or “conforming GUI”. The most familiar static analysis tools in web development are lint-like tools. Intended to analyze only well-formed documents (i.e., that pass validation), lint tools highlight anything that experience has shown can lead to bugs, portability problems, and maintenance issues. HTML Lint , while a work in progress, is the first tool of its kind that supports (or even claims to support) HTML5. More are sure to follow, such as an updated version of HTML Tidy or TidyLib , perhaps. Web accessibility addresses equal access to the web for all people, whatever their hearing, movement, sight, and cognitive ability. HTML5’s semantic separation is hoped to make this easier. The W3C is setting standards for accessibility and has a task force set to review the HTML5 specification for its impact on web accessibility, and to suggest changes. This is a challenging task, as accessibility is a subjective property. WAVE (Web Accessibility Evaluation Tool) is an HTML5 analysis tool focused on accessibility. Interestingly, WAVE integrates accessibility feedback into the original web page, making the feedback itself much easier to absorb. Additionally, the tool is intended to aid humans in evaluating the accessibility of web content, not to proscribe a particular style. This is a sensible approach, given the subjective nature of accessibility, and it is a pattern we are likely to see repeated for other subjective properties (like “good user experience”, or “conforming GUI”). Indeed, there seems to be a growing consensus in the community that validation is not sufficient for HTML5, that static analysis tools are going to be crucial. We concur. What Does the Future Hold? HTML5 opens up many possibilities and grants web designers and developers more freedom and powers than they have had before. However, with that expressiveness comes ample opportunity to shoot oneself in the foot. Tool support, particularly that which goes deeper than syntax and schema, will be needed. We can already see a need for tools that enforce properties more expressive than validator guidelines or linter rules. For example, many user interface guidelines exist in human-readable formats; these guidelines cannot all be checked automatically, but we believe many of them could. This article also has not touched on the topics of JavaScript-enabled interfaces, template languages such as Microsoft’s Razor syntax , or dynamically generated content in general—more on those topics will be coming soon. For now, we hope this survey is valuable to you, and we welcome your feedback and suggestions to fill any gaps you see. Web Designers and Developers! Did we miss any HTML5 tools that you use, love, know of, and/or developed? Or did we get something wrong? Please let us know! What is your use-case for HTML5? Is it supported by the tools you use? Where do you think you will need tool support for HTML5? Footnotes 1 Much has already been written about the connection between HTML5 and the semantic web , so our focus here will be on a different but equally disruptive use of HTML5: specifying user interfaces. 2 More accurately, the browser decides how to render based on its own defaults and any designer-specified styling (through, e.g., CSS3). 3 One could argue that the trend is for the converse: that desktop applications are becoming more like mobile and web applications. 4 It might be argued that the WYSIWYG IDEs/editors effectively perform validation, by showing syntax errors where present.", "date": "2011-12-12"},
{"website": "Galois", "title": "HTML5 is Paving the Way for Semantically Aware Tools", "author": "Unknown", "link": "https://galois.com/blog/2012/03/html5-is-paving-the-way-for-semantically-aware-tools/", "abstract": "Rich semantics are the Holy Grail for automated analysis tools; combined with extensible, familiar, and reusable tools and techniques we can seriously cut the costs associated with robust user interface development and testing. Previously , we discussed the set of tools available for validating and linting HTML5-based user interfaces; (eg: the W3C , numerous HTML/CSS editors, and tools like HTML Lint ). These tools help to identify syntactic issues, but what else is possible? The syntactic (and limited semantic) checks that these tools perform are necessary, but they aren’t sufficient to cover the body of intricate failures that can occur while creating the rich user experiences we’ve come to expect from interactive web applications and mobile devices. Linters and Validators can’t, for example, find bugs relating to the visual layout, and with good reason: Checking a UI is hard; it’s repetitive, monotonous, and more importantly, subjective work. However, there is still room for improvement. Surely we can push the envelope to do more. What’s next, and how can we automate tasks that still challenge human analysts? The first important insight is that many general guidelines for creating a good user interface have quantitative approximations . For example, the Windows 7 guidelines state: Use title-style capitalization for titles, and sentence-style capitalization for all other UI elements. and: Write the label as a phrase or an imperative sentence, and use no ending punctuation. In the words of Richard Anderson: We have the technology! Which brings us to the first of a few key areas or techniques that could improve the tools that help ensure UI Consistency: Extensibility We may have the technology, but we can’t easily put it into play. Advances in practical natural language and image processing algorithms can be (and have been!) applied to web design analysis and verification, but these techniques are still only available separately. Many one-off tools check a small handful of important guidelines (such as Michael Tamm’s image processing techniques ), but there aren’t any concerted efforts to unify the work that is going into these tools into one deployable and reusable system. The HTML5 analysis tools that are well integrated (primarily IDEs and linters) lack the facilities to implement or integrate with the processing logic needed to check arbitrary UI guidelines. Most existing analysis tools simply weren’t designed to be extended with new techniques, to incorporate new libraries, or to take into account external tools to generate visual renderings for testing purposes. We view extensible tools as the first, and most important, step towards creating a unified toolchain to ensuring user interface consistency. Extensibility is about empowerment, efficiency, and community: extensible tools allow you to learn the intricacies of one tool and then either watch it grow through community contributions, or jump in and add the features you need without starting from scratch. Most importantly, extensibility provides a path for integrating quantitative guidelines in a uniform testing and debugging interface. Semantic Reasoning However, many guidelines are inherently qualitative and subjective: To wit, read over the Design Concepts for confirmation dialogs in Windows 7 , which starts with: Unnecessary confirmations are annoying While no one will take issue with the intention, it is quite difficult to come to consensus on which dialogs are unnecessary. Thankfully, the Microsoft guidelines present many examples, justifications, alternate solutions, and explanations to support the guidelines. Taken on a whole, the document provides a sound body of advice to apply to your interfaces. Combine that document with human intuition and semantic reasoning, and we can manually create user interfaces that meet the specification. We have an edge over automated tools because we’re able to reason about the semantics of user interfaces with ease. With that in mind, let’s consider another, similar situation: the W3C Web Accessibility Initiative , and the ARIA specification: This specification provides an ontology of roles, states, and properties that define accessible user interface elements and can be used to improve the accessibility and interoperability of web content and applications. These semantics are designed to allow an author to properly convey user interface behaviors and structural information to assistive technologies in document-level markup. The ARIA specification specifically enables automated systems to better understand the semantics of user interfaces. Role attributes exist to differentiate form elements, dialogs, tooltips, etc… Many of the semantic annotations necessary to enforce common UI Guidelines already exist in the ARIA specification. Furthermore, these semantic annotations are beginning to appear in common widget toolkits for HTML, such as Dojo . It is only a matter of time before every web application has semantic annotations as a matter of course. Checking properties on all the dialog widgets will become a triviality, but only if the tool support exists to perform heuristic analyses based on these (and other) semantic annotations. If the tools were fully extensible, then the control over these heuristics would also be at hand: Disable or modify the checks that don’t apply to your applications, or write your own heuristics that do. Then share your contributions to perpetuate the use of rich semantics. Familiarity Galois has a long history of applying Domain-Specific languages to make programming in a specific context easier. We’re working on the same general idea on this project, but the language of choice is not a new creation. Rather, we think that the language of your testing and build system should be as closely related to the actual project as possible—in the case of HTML5, JavaScript is the natural choice. So far, we’ve been discussing the use of human interface guidelines as a source for criteria to check. However, we also believe that an extensible tool should be able to accept arbitrary checks, written in a rich, Turing-complete language. This is one point where our approach differs from similar tools, such as SeleniumIDE . Selenium IDE is extensible through “Selenese”, a simple language of 0-2 parameter commands for automating web applications and performing simple checks. Automation is, without a doubt, a critical aspect of UI testing, but the expressiveness needed to check complex properties is beyond the capabilities of Selenese (and indeed, many UI Guidelines are complex enough to require a Turing-complete language as well). Reusability We’ve made the decision to trade simplicity for expressiveness by selecting JavaScript as our language for guidelines, which increases the importance of reuse. Selenese scripts would have been simpler to create, but they would not be as general, and therefore, more difficult to share and reuse. As a result, Selenese scripts are easier to use for simple tests; however, guidelines are more general, offsetting the increased encoding cost. Where tests only serve a single purpose, for a single application, guidelines are of value to a vast community of developers. It’s easy to imagine, for instance, that the Windows Metro-Style UI Guidelines would include an executable specification that ensures that your applications conform to the look and feel of the platform. Where can we find these capabilities now? The features of HTML analysis tools we’ve talked about above aren’t new requirements; developers have had a need for extensible, reusable, familiar, and semantically-rich tools for years, but the stepping stones were not in place yet. Today, we have a large body of examples (in the form of linters, validators, and automation tools) to build on, each one contributing to one aspect of the problem. There is a progression of tools and languages that is culminating in documents such as the HTML5 specification and tools like Selenium WebDriver and Selenium IDE. We, as a community, are on the cusp of a new generation of extensible, semantic, reusable, and pragmatic tools to ensure consistency in rich interfaces; it’s just a matter of connecting the dots and collaborating to bring all the pieces together.", "date": "2012-03-29"},
{"website": "Galois", "title": "FiveUI: Extensible UI Analysis in your browser", "author": "Unknown", "link": "https://galois.com/blog/2012/03/fiveui-extensible-ui-analysis-in-your-browser/", "abstract": "Galois is excited to announce the Open-Source release of FiveUI ! FiveUI is a framework and tool for checking web-based user interfaces against codified UI guidelines. It is the first step towards an extensible, semantically aware, reusable and pragmatic toolchain for checking aspects of user interfaces against arbitrary guidelines. FiveUI currently works as a browser extension for Google Chrome and Mozilla Firefox, but we are hard at work on a batch system for running guidelines in a non-interactive, headless environment, such as the Jenkins continuous integration system. For now, you can load FiveUI in your browser and navigate around web sites by hand. We think it’s a pretty useful tool, as-is, even if you still have to do some clicking to trigger guidelines that check web pages. The real strength of FiveUI is its extensibility. Anyone can encode guidelines as rules and rulesets, which are just literal javascript objects (much like JSON; in fact, they would be JSON, but rules require actual functions). Once you’ve written a set of rules, we would love it if you would add them to the growing collection of rule sets available for FiveUI. Because guidelines are general-purpose, the rules should be written to apply to any web site. This makes it trivial to take collections of rules and run them on any web page or web app you create, any rules you share can be used by others, and you’ll be able to take advantage of the rules contributed by everyone else as well. Take a look at the Install Guide , the Getting Started guide and the FiveUI Prelude to learn more about using and writing Rules and Rule Sets . Last, but not least, let us know what you think! Send comments, email us, submit pull requests and file issues. We’re listening for everything, and we’ll do everything we can to make the tool and the community work for you.", "date": "2012-03-31"},
{"website": "Galois", "title": "SIGPLAN Programming Languages Software Award", "author": "Unknown", "link": "https://galois.com/blog/2011/06/sigplan-programming-languages-software-award/", "abstract": "We are pleased to be able to relay the following announcement from ACM SIGPLAN: The SIGPLAN Programming Languages Software Award is awarded to an institution or individual(s) to recognize the development a software system that has had a significant impact on programming language research, implementations, and tools. The impact may be reflected in the wide-spread adoption of the system or its underlying concepts by the wider programming language community either in research projects, in the open-source community, or commercially. The award includes a prize of $2,500. For 2011, the winners of the award are Simon Peyton Jones and Simon Marlow of Microsoft Research, Cambridge, for GHC. The award winners are donating the entirety of the prize money to haskell.org. Citation: Simon Peyton Jones and Simon Marlow receive the SIGPLAN Software Award as the authors of the Glasgow Haskell Compiler (GHC), which is the preeminent lazy functional programming system for industry, teaching, and research. GHC has not only provided a language implementation, but also established the whole paradigm of lazy functional programming and formed the foundation  of a large and enthusiastic user community. GHC’s flexibility has supported experimental research on programming language design in areas as diverse as monads, generalized algebraic data types, rank-N polymorphism, and software transactional memory. Indeed, a large share of the research on lazy functional programming in the last 5–10 years has been carried out with GHC. Simultaneously, GHC’s reliability and efficiency has encouraged commercial adoption, in the financial sector in institutions like Credit Suisse and Standard Chartered Bank, and for high assurance software in companies like Amgen, Eaton, and Galois. A measure of GHC’s influence is the way that many of the ideas of purely functional, “typeful programming” have been carried into newer languages and language features. including C#, F#, Java Generics, LINQ, Perl 6, Python, and Visual Basic 9.0.Peyton Jones and Marlow have been visionary in the way that they have transitioned research into practice.  They have been role models and leaders in creating the large and diverse Haskell community, and have made GHC an industrial-strength platform for commercial development as well as for research. Note: See also the nomination announcement from January, 2010 and the thread on the Haskell-Cafe mailing list.", "date": "2011-06-07"},
{"website": "Galois", "title": "Call for Proposals: CUFP 2009", "author": "Unknown", "link": "https://galois.com/blog/2009/03/call-for-proposals-cufp-2009/", "abstract": "Commercial Users of Functional Programming Workshop 2009: Functional Programming as a Means, Not an End Sponsored by SIGPLAN Co-located with ICFP 2009 Edinburgh, Scotland, 4 September 2009Galois is excited to promote this sixth annual event and encourages any interested in speaking at the workshop to send in a presentation proposal !  Whether you’d like to offer a talk yourself or you’d have someone in mind you’d like to nominate, please submit a proposal by 15 May 2009 via e-mail to francesco(at)erlang-consulting(dot)com or jim(dot)d(dot)grundy(at)intel(dot)com. Include a short description (approx. one page) of what you’d like to talk about or what you think your nominee should give a talk about. Do I have a presentation idea? If you use functional programming as a means rather than as an end (or could nominate someone who does), we invite you to offer to give a talk at the workshop. Talks are typically 25 minutes long but can be shorter and aim to inform participants about how functional programming plays out in real-world applications. Your talk does not need to be highly technical, and you do not need to submit a paper! What is the goal? The goal of the CUFP workshop is to act as a voice for users of functional programming and to support the increasing viability of functional programming in the commercial, governmental, and open-source space. The workshop is also designed to enable the formation and reinforcement of relationships that further the commercial use of functional programming. Tell me more! CUFP 2009 will last a full day and feature a keynote presentation from Bryan O’Sullivan , co-author of Real World Haskell . The program will also include a mix of presentations and discussion sessions varying over a wide range of topics.This will be the sixth CUFP;  for more information, including reports from attendees of previous events and video of recent talks, see the workshop web site: http://cufp.galois.com/ .", "date": "2009-03-05"},
{"website": "Galois", "title": "Cabal and Licenses", "author": "Unknown", "link": "https://galois.com/blog/2010/09/cabal-and-licenses/", "abstract": "﻿When writing software that uses open source libraries, the license of a dependency is a real concern. It becomes necessary to watch for license compatibility, as well as ensure that the terms of the license are satisfied when doing a source distribution. As a first attempt at license compatibility checking, we have added some extra checks in the configure step for Cabal, so that warnings will be generated if any direct dependencies have licenses that conflict with that of the configured package [1] . However, there are some limitations to this approach. First, this doesn’t rule out the possibility that a dependency of a package that is deemed compatible will conflict with the license of your executable. Second, it doesn’t allow for a BSD3 library to depend on a GPL library, where the conflict is only produced when an executable is produced from the combination. Some licenses place requirements on how a source or binary distribution can happen. For example, the BSD3 license requires you to include its copyright notice in any distribution you make.In order to speed up this process, we decided to try to extract this information from the GHC package database. According to the GHC manual, the license file should be tracked by the package database, though upon closer inspection, that field doesn’t seem to be tracked. In order to address this shortcoming, we developed a small patch to add this functionality in GHC and Cabal [2] . Using this patched version of GHC and Cabal, we’ve developed a small tool to walk the dependencies of a cabal package, and collect the license files that they have registered in the package database.Both of these patches are available for you to try out, attached to the tickets below, though they have been accepted and are expected to make it into the next release of Cabal.[1] http://hackage.haskell.org/trac/hackage/ticket/481 [2] http://hackage.haskell.org/trac/hackage/ticket/710", "date": "2010-09-07"},
{"website": "Galois", "title": "FMCAD’08 is coming to Portland!", "author": "Unknown", "link": "https://galois.com/blog/2008/09/fmcad08-is-coming-to-portland/", "abstract": "Formal Methods in Computer Aided Design ( FMCAD’08 ) is the preeminent conference in formal methods for hardware and systems, and this year, it’ll be held in downtown Portland, November 17-20. The advance program has been announced, and the lineup of technical papers, invited tutorials, invited speakers, and panel discussion looks awesome . Registration is open, so be sure to get your spot soon!Galois is sponsoring this year’s conference, along with Cadence, IBM, Intel, NEC, and Synopsis.  If you attend, stop by Galois; we’re only a few blocks from the conference hotel.", "date": "2008-09-12"},
{"website": "Galois", "title": "Update: Bike Commute Challenge", "author": "Unknown", "link": "https://galois.com/blog/2008/09/update-bike-commute-challenge/", "abstract": "With only a week to go in the 2008 Bike Commute Challenge , it’s looking as if Galois will pass its 2007 results. Last year ( PDF ), 17.1% of our September commmutes were by bicycle. This year, our commute-by-bike rate is 19.1%. N.B. If last year’s statistics ( PDF ) hold true for this year, Galois employee Sigbjorn Finne will finish in the Top 10 Riders By Distance category, and most likely in the top five. Friday, Sept. 26 update: Folks must have caught up on their riding logs, because the Galois commute rate has risen to 21.6%!", "date": "2008-09-25"},
{"website": "Galois", "title": "Nice interview with Simon Peyton-Jones in Australian Computerworld", "author": "Unknown", "link": "https://galois.com/blog/2008/09/nice-interview-with-simon-peyton-jones-in-australian-computerworld/", "abstract": "Here’s a nice interview with Simon Peyton-Jones in the Australian version of Computerworld. It’s got some nice history, interesting insights (I enjoyed hearing how eye-opening Conal Elliot’s Functional Reactive Animation work was), and Simon’s usual wit and wisdom.", "date": "2008-09-26"},
{"website": "Galois", "title": "Real World Haskell: Intel Parallel Programming Podcast", "author": "Unknown", "link": "https://galois.com/blog/2009/01/real-world-haskell-intel-parallel-programming-podcast/", "abstract": "Don Stewart did an interview with Michael Wrinn and Aaron Tersteeg from Intel’s Multicore Software Development podcast about Haskell , multicore and parallel programming, and the use of functional programming at Galois and in industry in general. Listen to the full interview! (15 minutes).", "date": "2009-01-13"},
{"website": "Galois", "title": "Galois at POPL", "author": "Unknown", "link": "https://galois.com/blog/2009/01/galois-at-popl/", "abstract": "The Principles of Programming Languages conference, POPL 09 , and its surrounding workshops is kicking off this week in Savannah, Georgia. Galwegians will be attending most of the conferences: you might be able to find Levent at VMCAI or the Twelf Tutorial, or Iavor at TLDI or POPL, and Jeff Lewis (now at Signali ) will be giving a keynote at PADL . Step up and say “hello!”.", "date": "2009-01-18"},
{"website": "Galois", "title": "FMCAD and AFM Submissions Open", "author": "Unknown", "link": "https://galois.com/blog/2009/03/fmcad-and-afm-submissions-open/", "abstract": "Lee Pike is on the program committees for two upcoming formal methods conferences: Formal Methods in Computer-Aided Design ( FMCAD ), the preeminent conference on formal methods in hardware and systems, and Automated Formal Methods ( AFM ), a workshop on the application, usage, and extension of formal methods tools, particularly focusing on SRI’s tool suite (including a theorem prover, model-checkers, and SMT solver).Please consider submitting papers!  The deadline for FMCAD is May 22 (with abstracts due May 15); the deadline for AFM is April 30.  FMCAD will occur in Austin, Texas November 15-18, and AFM will be colocated with CAV in Grenoble, France.", "date": "2009-03-30"},
{"website": "Galois", "title": "PADL/PEPM 2010, Day 1", "author": "Unknown", "link": "https://galois.com/blog/2010/01/padlpepm-2010-day-1/", "abstract": "Here are some papers which caught my imagination at this year’s PADL and PEPM conferences in Madrid. O Partial Evaluator, Where art thou? Lennart Augustsson (PEPM 2010) In this invited talk, Lennart walked us through his personal engagement with PE-like code transformations that he has confronted directly in his career, which has consisted of Haskell programming in a wide variety of commercial and industrial settings. The examples included optimizing airline scheduling code for Lufthansa, eliminating unnecessary hardware elements in Bluespec compilation, and generating efficient Monte-Carlo computations in investment banking.In Bluespec, Lennart needed to introduce a ‘tabulate’ function which produces a table-driven implementation of its function argument. It is a powerful idea, but it requires a sufficiently powerful set of transformations for its boilerplate to get simplified away. In this case, Lennart needed to introduce a term ‘_’ which means “don’t care”, i.e. any convenient result can be returned. During unfolding and partial evaluation, ‘_’ could be replaced with any term that would help the partial evaluator make good progress on simplification. Semantically, this is a form of refinement of non-determinism performed during code transformation (in fact, I’m still not sure what the correct denotational approach to its semantics would be). Lennart then explored using ‘tabulate’ directly in Haskell, but found it next to impossible to get the GHC simplifier to do enough transformation.The Paradise ESDL is like Bluespec in that it uses the Haskell framework to bolt together primitive elements from a lower level language. In this case, the efficiency opportunities arise from, say, 18-argument functions being called repeatedly with 15 known arguments. Lennart introduced a ‘compile’ function which is semantically the identity function, but which invokes a run-time compilation. Yet again, Lennart found himself writing essentially the same kind of code he had previously written in a different setting. Each time it is fairly simple partial evaluation.Where oh where is the partial evaluator for Haskell? And don’t worry about self-application or anything fancy like that. Just something that is solid and reliable. Explicitly Typed Exceptions for Haskell, Jose Iborra (PADL 2010) Java gives you safe exceptions, in that if you don’t handle an exception that could be raised, the compiler will complain. Currently Haskell does not. This paper builds on Simon Marlow’s work of providing an exception library with existentially-quantified exceptions, that provide access to the exception through class methods. Marlow’s exceptions work very nicely with the type system, allowing exception and non-exception code to be intermingled. If only there was a way still to know which particular exceptions could be raised …Iborra to the rescue! He adapts Marlow’s exceptions with additional class constraints that track exactly which exception could be raised, fulfilling those constraints when a handler for the exception is provided. Unhandled exceptions show up as missing instances (of handlers), pinpointing the code that is at fault. It all works very beautifully. The downside? He needs to use overlapping instances to be able to ‘subtract’ that constraints. Hmmm. Normally I’m very down on overlapping instances: it seems really fragile to rely on details of the type-inference engine to select what code should run. But this is a particularly benign case: here the overlapping instances are over phantom type variables, so the same code will run in either case. Maybe Haskell should allow that in general; overlapping instances are fine if the same run-time code is produced however the instances are resolved. Conversion by Evaluation, Mathieu Boespflug (PADL 2010) Proof tactics in theorem provers often require large lambda terms to be normalized. For example some Coq tactics perform reflective computation over other Coq terms. This reduction can be quite inefficient when done explicitly, because of the interpretive overhead, yet the result of evaluation needs to be in a form where the final lambda term can be examined.This paper shows the how to interpret explicit lambda terms efficiently by mapping them into a underlying evaluation mechanism of the host language (e.g. Haskell). The approach is deceptively simple and consists of a set of straightforward optimizations (higher-order abstract syntax, currying, de Bruijn indices etc). Astonishingly, the result is that the evaluation incurs only a 10-30% overhead compared with using the underlying evaluator directly! A must-read for anyone interested in reflective evaluation. Optimizing Generics Is Easy! Jose Pedro Magalhaes et al (PEPM 2010) Generic programming is a way to provide a programmable version of the deriving concept that arises in Haskell. The problem is that the current libraries for implementing generics introduce performance overheads from 50% to 16x compared with writing the original by hand. This paper presents a framework for doing generics using type families to represent the components of algebraic datatypes, together with overloaded operators for mapping between the generic datatype and any user datatype.GHC does a good job of rewriting much of the overhead away, but needs to be encouraged to do the best it can. There are GHC flags to control decision thresholds for inlining etc that turn out to enable GHC to completely remove the overhead of the generic code, producing in some cases exactly the code that would get written by hand. The open problem is that increasing the threshold over the whole program might have negative effects elsewhere in the compilation, so a mechanism for localizing the effect of increased thresholds would be valuable.", "date": "2010-01-19"},
{"website": "Galois", "title": "PADL/PEPM 2010, Day 2", "author": "Unknown", "link": "https://galois.com/blog/2010/01/padlpepm-2010-day-2/", "abstract": "Again, here are a few talks that caught my attention and I thought I would share my impressions. Enjoy! An Ode to Arrows, Hai Liu & Paul Hudak (PADL 2010) Representing the infinite tower of derivatives of a function as a lazy list has become popular in the Haskell world, the most recent example being Conal Elliott’s paper on Beautiful Differentiation at ICFP 2009. This work explores taking the same ideas and using them to express systems of Ordinary Differential Equations.A natural translation of these ideas into Haskell requires recasting the ODEs in an integral form, rather than a purely differential form, leading to a shallow embedding of the equations as recursive equations in Haskell. Unfortunately, this simple translation leads to quadratic computational complexity, in both time and space. Memoization can address this moderately well, except that one is left with the problems of managing (and freeing) the memo-tables.Moving to arrows leads to a better solution. The recursion is expressed using Paterson’s ‘loop’ construct, which puts it in the control of the programmer. When combined with Causal Commutative Arrows (http://lambda-the-ultimate.org/node/3659) the circuits can be optimized into tight iterative loops, with dramatic improvements in performance. A DSL Approach to Protocol Stack Implementation, Yan Wang & Veronica Gaspes (PADL 2010) Implementations of network code are very hard to connect with the specifications, leading to major challenges for maintenance. This is significant for embedded devices which need implementations that appropriately trade off power, speed, and memory usage. To that end, IPS is a DSL for generating network code. It allows packet formats to be defined using dependencies between fields, handles the interaction of protocol and packet, and provides a framework for constructing the protocol stacks.In a comparison exercise, IPS was used to generate code for the Rime protocol stack. Compared with the published hand-written version in C, the IPS code was 1/4 of the size of the C, but produced an executable 25% larger. The performance on sending packets was 10% worse in the IPS version, but both versions were equivalent for receiving packets.No measurements were given for ease of maintenance or design exploration between the two versions, but I know which one I would prefer to have to work with… I/O Guided Detection of List Catamorphisms, Martin Hofmann & Emanuel Kitzelmann (PEPM 2010) Having the computer write its own programs has always been appealing. You provide some input/output pairs and the machine comes up with a generalization expressed as a program that has the same behavior. Broadly, there are two ways to do this: analytical (where the structure of the data is examined to build the program), and generate & test (where many programs are produced, and their behavior improved, perhaps by evolutionary combinations).This work uses the idea of catamorphisms (also known an fold or reduce functions) as a template to explore, when the i/o pairs comes from a recursive data type (just lists at the moment, I think). Using the fact that if a function g satisfies ‘g [] = v’ and ‘g (x:xs) = f x (g xs)’ for some ‘f’ and ‘v’, then ‘g = fold f v’, the system figures out what the i/o pairs for the sub-functions would be, and then tries to deduce the definitions. It includes specific smarts that notice when the form of the function corresponds to a ‘map’ or ‘filter’. Bridging the Gap Between Symbolic and Efficient AES Implementation, Andrew Moss & Dan Page (PEPM 2010) Different implementations of AES, the standard for block encryption, run at very different speeds. The original reference implementation takes about 840 cycles per round, the Open SSL implementation takes 30, and a top performing assembly code version takes 21.6 cycles per round. The CAO DSL and compiler described in this paper takes a high-level spec and compiles it, producing code that takes 23 cycles per round. Impressive.CAO is a sequential language, designed to be easily related to the pseudo code that crypto specifications often use. A significant amount of effort in the compiler then goes into deducing what parallelism is possible and how best to balance the work. CAO has matrices as first class objects, to allow the compiler opportunity to deduce good representations. There are also optimizations to convert references from the matrices in their entirety to references to the appropriate sub-portions, so as to eliminate unnecessary additional sequential dependencies. The compiler also has some optimizations that are specific to AES. Clone Detection and Elimination for Haskell, Christopher Brown & Simon Thompson (PEPM 2010) I liked this talk partly because it reminded me to go and play with HaRe (https://www.cs.kent.ac.uk/projects/refactor-fp/hare.html). The Haskell Refactorer is an Emacs and Vim tool for manipulating Haskell 98 programs, providing structural transformation (like fold/unfold), altering data types (like adding or eliminating arguments), slicing, and now, clone elimination (cue Star Wars music).The clone eliminator finds repeated code forms above a threshold size, and deduces the least-general generalization of the code to invent new functions if necessary. Clone detection is entirely automatic, but it is up to the programmer to decide which ones to act upon — sometimes adding abstraction helps the structure of a program, and sometimes it obscures it. It works within monadic code too.HaRe works mostly at the AST level, though it does use the raw token stream for some of its discovery. It also works across modules. Making “Stricterness” More Relevant, Stefan Holdermans & Jurriaan Hage (PEPM 2010) The old approaches to strictness were all denotational, but to actually use strictness within the compiler it is better to have a syntax-driven formulation, i.e. in logic. There is a nice approach which uses the concept of ‘relevance’, where ‘x’ is relevant to ‘e’ if every evaluation of ‘e’ demands ‘x’. Clearly, relevance is equivalent to strictness.But actually it doesn’t work so well in the presence of ‘seq’. The original formulation of relevance assumed that the only time a function would be evaluated was at its point of application. Then there is no way to distinguish ‘undefined’ from ‘x->undefined’. ‘Seq’ changes all that. The paper shows how to fix relevance by tracking which lambdas are used applicatively (i.e. applied somewhere in the program in a place that will be evaluated). The definition is circular, but the least solution is the one intended.", "date": "2010-01-20"},
{"website": "Galois", "title": "POPL 2010, Day 1", "author": "Unknown", "link": "https://galois.com/blog/2010/01/popl-2010-day-1/", "abstract": "Here are some talks that caught my attention on the opening day of POPL 2010. Reconfigurable Asynchronous Logic Automata, Neil Gershenfeld In this invited talk, Neil proposed that we throw out the sequential model of computation from Turing and Von Neumann, and re-imagine computing from the ground up, more along the line of physics as it is manifested in the world. This might be the way forward given the huge power demands that will arise from traditional architectures as they become more and more powerful. Rather than imposing a top-down structure on the machine, Neil propose we consider systems built up from cellular automata. In ALA each cell is able to do a basic logic operation or, in RALA, reconfigure other cells. Built around 2D grids, and computing in parallel without any global clock, the automata are able to compute many basic functions in linear time, including multiplication and sorting (of course, they also take a linear number of cells to do so).What I liked about this talk is that it called on me to think more broadly about the nature of computation. I don’t think I buy the line that how we do computing today is wrong. But I do believe that computing and information theory is going to become more and more important in the development of many other subjects, including physics and biology. I also believe that we will need to harness many more structures to do computing rather than simply relying on gates burned in silicon. Coincidentally, at lunch today Luca Cardelli was telling me about his explorations in computing with DNA. Fascinating stuff!At the lowest levels, the primitive components of computation reflect the computational substrate, so they are very different from one instantiation to another. As primitive computational elements become combined, however, the different descriptions become more abstract, and start to look more and more alike. The same mathematical operations may arise in each form, for example. That makes me wonder what the space of truly computationally-neutral specifications looks like: how might we program in such a way that we really don’t have a preference for what substrate we map the computation onto. We already consider FPGAs, GPUs and CPUs as standard targets for languages like Cryptol. Let’s conceptually add DNA and RALA to the list, and see if that would have us change anything. A Simple, Verified Validator for Software Pipelining, Jean-Baptiste Tristan & Xavier Leroy Software pipelining is a compiler transformation that reorders loop code to make more efficient use of the CPU and memory accesses. Code from many different iterations of the loop might be drawn together and overlapped to execute out of order, and perhaps in parallel. The question is how to verify that the pipelining has been done correctly.The paper proposes using symbolic evaluation. It describes an equivalence principle which requires proving two separate commutativity properties. These may both be shown by symbolic evaluation of the instruction code, being careful to handle the small differences (such as different temporary variables in the two paths). Overall the process is simple enough that it could be a standard component of any compiler, even if the compiler is non-verifying overall. A Verified Compiler for an Impure Functional Language, Adam Chlipala Handling object-level variables in proofs is a real pain, one that is hard to eliminate. This paper has an interesting way of dealing with them. It describes a Coq verification of a compiler for Untyped Mini-ML with references and exceptions, compiling to an idealized assembly code.Now, using explicit object variables leads to lots of lemmas about substitution. On the other hand, full higher-order abstract syntax (HOAS) would lead quickly to non-termination, and hence unsoundness. So instead, the paper introduces a closure semantics in which variables are just numbers pointing into a heap. Many operations that would reorder substitutions (and hence require big proofs) don’t affect the closure heap, so the proofs go through easily.The paper also uses a high degree of proof automation: it has a generic proof script that looks at the hypotheses and goals, and decides what approaches to try. The proof script is a bit slow because the evaluation mechanism of Coq wasn’t designed for this particularly (but see my blog post from PADL about accelerating normalization). However, because the proof is highly automatic, it is not hard to evolve the compiler and proof simultaneously. In fact, the compiler and proof were developed incrementally in exactly this way. Verified Just-in-Time Compiler on x86, Magnus Myreen JIT compiling has become standard for accelerating web pages, amongst other things. Good JIT compilers can take into account the input to the program as well as the program itself. But it is hard to get them right, as witnessed apparently by a recent Firefox bug.An aspect that makes verification tricky is that code and data are mixed: a JIT compiler essentially produces self-modifying code. The paper provides a programming logic for self-modifying code by adapting Hoare triples so that there is both “before” and “after” code. Some practical issues also need to be handled: for example, the frame-property has subtleties regarding the instruction cache, and code-updates can sometime happen too recently to show up in the current instruction stream. The x86 documentation is a little vague about how soon code-modifications can be relied on to be present.The end result is a verified JIT compiler from a toy input byte-code language, but mapping to a realistic semantics for x86. The compiler produces comparable code quality to C for a GCD example.", "date": "2010-01-21"},
{"website": "Galois", "title": "Instilling Morality in Machines", "author": "Unknown", "link": "https://galois.com/blog/2011/02/instilling-morality-in-machines/", "abstract": "Our own David Burke gave a talk on Wednesday at Portland State University as a speaker in the ‘ Nuts and Bold Ideas ‘ seminar series.  David described work done on multiagent simulations of morality during strategic interactions.  He explained how various agents in the simulations make choices about whether to cooperate based on each agent’s weighting of five moral attributes (reciprocity, harm avoidance, loyalty, authority, purity).  Not only do these simulations reflect how the population evolves over time, they provide insights into how large numbers of distributed, autonomous systems might be programmed with respect to moral decision-making and behavior. Instilling Morality in Machines", "date": "2011-02-11"},
{"website": "Galois", "title": "Announcing: Internship Available at Galois, Inc.", "author": "Unknown", "link": "https://galois.com/blog/2011/06/announcing-internship-available-at-galois-inc/", "abstract": "Galois, Inc. has a Fall 2011 internship available in Portland, Oregon, USA. PROJECT OVERVIEW: The project is a research project investigating security in the domain of embedded software in robotic vehicles. We are investigating techniques in which runtime monitoring can detect and mitigate attacks. This is a research project, and directions are open-ended. You will have influence on the technical direction and your specific work. Your work may result in publications. LOGISTICS: This is nomialy a three month internship, but other durations will be considered (no less than two months, though). Ideally, we are looking for an intern for the October – December timeframe, but earlier start dates are negotiable. The internship is paid, and the intern will be responsible for her own living arrangements (although we can certainly help you find arrangements). Galois is located in the heart of downtown, with multiple public transportation options available, so living here without an automobile is a viable option. QUALIFICATIONS: MUST-HAVES: The ability to work in the United States. The ability to be geographically located in Portland. Some experience with writing C/assembly. Some experience with operating systems concepts. NICE-TO-HAVES (but not necessary): Interest in/experience with Haskell. Interest in/experience with real-time systems, RTOSes, and scheduling. Interest in/experience with WCET analysis. Interest in/experience with software security. Interest in/experience with static analysis. Experience with the ARM and/or AVR architecture/assembly. Interest in embedded systems and particularly flight-control software. Good writing skills/experience in writing technical papers. DO NOT NEED: A specific degree (we’re interested in hearing from post-docs, graduate students, and undergrads). ABOUT GALOIS: Galois, Inc. is located in Portland, Oregon with a mission to create trustworthiness in critical systems. We’re in the business of taking blue-sky ideas and turning them into real-world technology solutions. We’ve been developing real-world systems for the past 10 years using Haskell. To get a sense of life at Galois, one of our interns documented his internship on his blog . TO APPLY: Please email a C.V. (PDF or plain text) and a brief (plain text) note stating your interest and experience to Lee Pike <leepike@galois.com>. ********************************************************** Application due date: ASAP, but no later than July 1st **********************************************************", "date": "2011-06-06"},
{"website": "Galois", "title": "Schrödinger’s CRCs (Fast Abstract)", "author": "Unknown", "link": "https://galois.com/blog/2010/10/schrodingers-crcs-fast-abstract/", "abstract": "Dr. Lee Pike’s ﻿short abstract revisiting fault-tolerance of cyclic redundancy checks (CRCs), expanding on the work of Driscoll et al.. It introduces the concepts of Schrödinger-Hamming weight and Schördinger-Hamming distance, and argues that under a fault model in which stuck-at-one-half or slightly-out-of-spec faults dominate, current methods for computing the fault detection of CRCs may be over-optimistic. Paper (PDF) Slides (PDF) Haskell simulation Paper home", "date": "2010-10-06"},
{"website": "Galois", "title": "Monitoring Distributed Real-Time Systems: A Survey and Future Directions", "author": "Unknown", "link": "https://galois.com/blog/2010/10/monitoring-distributed-real-time-systems-a-survey-and-future-directions/", "abstract": "Monitoring Distributed Real-Time Systems: A Survey and Future Directions Alwyn Goodloe (NIA) and Lee Pike (Galois, Inc), NASA Langley Research Center, 2010. Paper download: .pdf Paper home Runtime monitors have been proposed as a means to increase the reliability of safety-critical systems. In particular, we explore runtime monitors for distributed hard real-time systems, such as fault-tolerant data buses and control systems for avionics and spacecraft. This class of systems has had little attention from the monitoring community. We motivate the need for monitors by discussing examples of avionic systems failure. We then describe work in the ﬁeld of runtime monitoring. We present potential monitoring architectures for distributed real-time systems, and then we discuss how those architectures might be used to monitor properties of real-time distributed systems.", "date": "2010-10-15"},
{"website": "Galois", "title": "Galois Selected to Develop UI Consistency Analysis Tools", "author": "Unknown", "link": "https://galois.com/blog/2011/11/galois-selected-to-develop-ui-consistency-analysis-tools/", "abstract": "Creating consistent User Interfaces (UIs) is a time consuming and error prone process, but consistency and conformance with guidelines is becoming increasingly important for software developers. For example, Apple has raised the bar for UI Consistency by requiring that iOS applications conform with their Human Interface Guidelines (HIG) . Non-conforming applications can be removed from the App Store: “10.6. Apps must comply with all terms and conditions explained in the Apple iPhone Human Interface Guidelines and the Apple iPad Human Interface Guidelines” — App Store Review Guidelines, Apple Inc. ( pdf ) Despite support for creating user interfaces through graphical tools such as Visual Studio and XCode, developers and designers are left largely on their own when it comes to checking for conformance. Unfortunately, documents such as Apple’s HIG are not suitable for automated processing–a critical part of any serious software development workflow.  Often, these concerns are left unaddressed, or inadequately addressed, because it is prohibitively expensive to manually examine a user interface after each software update. Automated tools could check for UI consistency and conformance, moving checks for User Interface Semantics into traditional testing processes. Galois has been awarded a Phase II SBIR (Small Business Innovative Research) contract with the United States Army to develop tools that can automatically check for conformance with user interface guidelines.  The technologies we develop under this project will reason about user interfaces on a semantic level, enabling complex documents such as Apple’s Human Interface Guidelines to be enforced automatically. The Phase II SBIR project will be led by Rogan Creswick .", "date": "2011-11-30"},
{"website": "Galois", "title": "Galois is hiring!", "author": "Unknown", "link": "https://galois.com/blog/2012/09/galois-is-hiring-2/", "abstract": "We are currently seeking software engineers/researchers to play a pivotal role in fulfilling our mission of creating trustworthiness in critical systems. Galois engineers/researchers participate in one or more projects concurrently, and specific roles vary greatly according to skills, interests, and company needs. Your role may include technology research and development, requirements gathering, implementation, testing, formal verification, infrastructure development, project leadership, and/or supporting new business development. Skills & Requirements Education: Minimum of a Bachelor’s degree in computer science or equivalent. MS or PhD in CS or a related field desirable but optional, depending on specific role. Required Technical Expertise: Must have hands-on experience developing software and/or performing computer science research. Demonstrated expertise in aspects of software development mentioned above. Desired Technical Expertise: Fluency in the use of formal or semi-formal methods such as Haskell or other functional programming languages. Direct experience in developing high assurance systems and/or security products. Experience with identity management, security risk analysis, systems software, or networking. Required General Skills: Must work well with customers, including building rapport, identifying needs, and communicating with strong written, verbal, and presentation skills. Must be highly motivated and able to self-manage to deadlines and quality goals. Our engineers/researchers develop in programming languages including functional languages, designing and developing advanced technologies for safety- and security-critical systems, networks, and applications. Engineers/researchers work in small team settings and must successfully interact with clients, partners, and other employees in a highly cooperative, collaborative, and intellectually challenging environment. We’re looking for people who can invent, learn, think, and inspire. We reward creativity and thrive on collaboration. If you are interested, please send your cover letter and resume to us at careers@galois.com .", "date": "2012-09-26"},
{"website": "Galois", "title": "Galois to Help DARPA PROCEED to Change the Game", "author": "Unknown", "link": "https://galois.com/blog/2011/04/galois-to-help-darpa-proceed-to-change-the-game/", "abstract": "Portland, OR (April 11, 2011) – The Defense Advanced Research Projects Agency (DARPA) has awarded up to $4.7M to Galois, Inc., as research integrator for the PROCEED program (Programming Computation on Encrypted Data) whose goal is to make it feasible to execute programs on encrypted data without having to decrypt the data first. DARPA Program Manager Dr. Drew Dean has assembled a diverse group of researchers on PROCEED with the challenging goal of making fundamental progress in the science and mathematics of computing on encrypted data, while at the same time increasing the efficiency of implementations of the new techniques by several orders of magnitude. The researchers are working at many different levels of abstraction: on the design of programming languages that support encrypted data; on building efficient libraries of operations over encrypted data structures; on compilation techniques that exploit programmable hardware; and on fundamental breakthroughs in the cryptographic approach itself. Over the next four years, Galois will draw the many threads of research together into a coherent whole. Galois brings extensive existing infrastructure and technological support for multi-use cryptography compilation and analysis, and a decade of experience supporting and connecting cryptographers in research, government, and industry. To meet the critical technical challenge of a shared technical infrastructure, Galois offers the Cryptol® tool suite, leveraging the existing framework for specifying, designing, implementing, and verifying cryptographic algorithms for a variety of hardware and software platforms. The toolset will be extended to showcase the breakthroughs in homomorphic encryption produced across the PROCEED research team. About Galois : Galois (http://www.galois.com/) was founded in 1999 to provide a unique R&D capability for government and commercial clients. Galois applies revolutionary mathematical, computer science and engineering approaches to solve critical problems in software security, safety, privacy and performance. Galois has been instrumental in bringing cutting edge research into practice for the DoD, DoE, Intelligence, pharmaceutical and aerospace communities. Contact: Leah Daniels leah@galois.com 503/808-7152 Approved for Public Release, Distribution Unlimited", "date": "2011-04-11"},
{"website": "Galois", "title": "Galois awarded Navy/ONR project in binary instrumentation and monitoring", "author": "Unknown", "link": "https://galois.com/blog/2011/04/galois-awarded-navyonr-project-in-binary-instrumentation-and-monitoring/", "abstract": "Galois has been selected by the Office of Naval Research for a Phase 1 Small Business Innovative Research (SBIR) award, to develop a viable real-time software execution monitoring system to protect programs against errors, regardless of the programming language the software is written in. The approach will be based on instrumentation of binaries via the LLVM compiler framework . This effort builds on Galois’ expertise in runtime monitoring and program analysis (such as the ASA tool and the CoPilot monitoring language ). Contact Leah Daniels at ﻿503-808-7152 for more information.", "date": "2011-04-06"},
{"website": "Galois", "title": "Galois CEO Testifies Before U.S. Congress", "author": "Unknown", "link": "https://galois.com/blog/2011/03/galois-ceo-testifies-before-u-s-congress/", "abstract": "Galois’ CEO, Laura McKinney, was asked to testify before the U.S. Congress Subcommittee on Technology and Innovation on the role of small business in innovation and job creation. The hearing was specifically assessing the Small Business Innovation Research (SBIR) and Small Technology Transfer Research (STTR) programs . Laura provided background on Galois as a small business that transforms computer science research into practice to address urgent problems with safety and security software. She shared with the committee our experience as a technology transition company: Expect the unexpected in technology transition . It is extremely difficult to predict when and where ultimate value of technology invention will be realized. Relevance and value comes from being strongly connected with the mission and needs of operational entities. Technology transition comes incrementally , and is built through a series of contributions by an entire eco-system of collaborators . Laura went on to highlight the impact of the SBIR program on Oregon and the nation specifically from Galois’ participation: Increased Oregon access to broader US government business. Technology and market opportunities generated for new ventures. Exposure for companies like Galois to real and current government needs. Increased commercialization capability within Galois. Research developed for one agency spread to impact other agencies. Global cybersecurity research capabilities brought to bear on national needs. She ended her testimony by providing the following suggested improvements: Augment success metrics for Phase-III to include evaluation of successful open source release. Incrementally increase Phase-I award size to enable better assessment of results in consideration of Phase-II. Accelerate Phase-I to Phase-II selection to match the pace of software technology change. Provide more support to Technical Points of Contact in the administration and guidance in SBIRs. Encourage TPOCs to provide connections with interested acquisition programs. Laura did a great job representing Galois’ belief that the SBIR program is successful, both for fostering the innovation and jobs engine of small businesses, and for nurturing breakthrough technologies to the benefit of the government and wider economy. Click here to view the archived webcast of the hearing and click here to read Laura’s entire written testimony .", "date": "2011-03-31"},
{"website": "Galois", "title": "Quick authentication using mobile devices and QR Codes", "author": "Unknown", "link": "https://galois.com/blog/2011/01/quick-authentication-using-mobile-devices-and-qr-codes/", "abstract": "Isaac Potoczny-Jones February 18, 2014: This project has recently been spun-out into a new startup company, Tozny – read more about this world-class, secure login technology at www.tozny.com . Introduction In this blog post, we propose an authentication scheme using QR codes and Internet-connected smart phones to allow a user to quickly sign into a web site without having to memorize or type in a username and password. The user only has to prove that they are in possession of their mobile phone. We’ve developed a demonstration app and web site for this approach which you can try if you have an Android smartphone. Or you can watch the video demonstration . We have also started work on a draft REST protocol , and welcome feedback. This work is preliminary, so we are very interested in feedback on the concept and prototype. In general, authentication can be done using multiple “factors”. The more factors that are used, the more confidence a web site can have that they have truly identified the user: something a user knows , such as a password something the user has , such as a smart-card or cryptographic key something the user is, such as the user’s fingerprint the user’s location and probably many more Many web sites currently use a single factor: a password. Our scheme can use a mobile phone as a second factor, or as a single factor: something the user has . In fact using a mobile phone as a single factor may be more convenient for the user and in some cases more secure than a password. One distinguishing feature of this approach is that it is not only a second factor but also a second channel . Unlike systems like Google Auth, the user does not input their second credential through their computer, but rather directly through the phone’s network connection. About QR Codes QR codes are two dimensional bar codes that can contain a significant amount of information such as a shared key or session cookie. As in the following photograph, it is possible to disp lay a QR code on a computer screen and to scan that code with a mobile phone. This is an extremely common thing for Android users to do when they want to download apps that they have discovered on their computers. We utilize this capability to securely share secret information between the web site and the user. User Experience In this scheme, there is a single step for both account creation and for subsequent log-in: The user scans a QR code. Edit: We have revised this workflow significantly. Please see the draft of the REST-based protocol . Account creation: When a user visits a web site for the first time, the site generates and displays a QR code for login, and the user scans it. An account is created for them. They have no need to generate and record a username or password or any other information. Log in: When a user subsequently visits a web site and needs to log in, the site displays a QR code that the user scans with the same mobile phone. The user is logged in without having to remember a username or password, or even remember whether they have visited that web site before. The user can choose to increase security by locking their phone and encrypting its data. Since the web site and the phone can exchange complex data, a strong password can be generated and stored without the user having to memorize it. In the following sections, we expand on this exchange by detailing the workflow, what is stored by each party, what attacks are mitigated, and what attacks are not mitigated. Account Creation Workflow The user visits a web site on their computer for the first time. The web site generates and displays an Authentication Code (AC), which is a QR code. The web site must generate a new session cookie to prevent against session fixation attacks. The AC encodes the web site URL and a random secret . This will be the shared secret . (EDIT: There are trade-offs for this to become the shared secret, and that increases the trust in the QR code and the user’s computer. In some circumstances, it may be better to have the app generate the shared secret.) The random secret is tied to the session cookie stored in the computer’s browser. The user scans the Authentication Code with the “ Animate Login App” (ALApp) . The ALApp decodes the AC and looks up the web site in the ALApp password table. Since the web site is not in the ALApp password table, the ALApp creates a new entry and stores the random secret.(EDIT: Instead the App should generate a new random secret. This will become the shared secret. ) The ALApp also generates a random user identifier , or chooses a preferred username. The ALApp uses the mobile phone’s Internet connection to transmit the shared secret, the random secret, the session cookie, and the user identifier to the web site. The web site verifies that the session cookie corresponds to the random secret. This random secret can only be used to authenticate this session cookie. The web site creates an account for the user and adds the user identifier, along with the random secret to its user database. The web site marks the session cookie as authenticated and redirects the browser into the authenticated portion of the web site. User Login Workflow The user visits a web site on their computer. The web site generates and displays an Authentication Code (AC), session cookie, and random secret as above. (EDIT: Using both the session cookie and random secret is unnecessary. We have clarified this in the protocol draft .) The user scans the Authorization Code with the Animate Login App (ALApp). The ALApp decodes the AC and looks up the web site in its password table. Since the web site already has an entry in ALApp password table, the ALApp looks up the shared secret and the user identifier. The ALApp uses the mobile phone’s Internet connection to transmit the random secret, the shared secret, and the user identifier to the web site. The web site looks up the user identifier and verifies the shared secret. The web site verifies that the session cookie corresponds to the random secret. This random secret can only be used to authenticate this session cookie. The web site marks the session cookie as authenticated and redirects the browser into the authenticated portion of the web site. Message Format Notes Since no one has to memorize the shared secret, it can be long and complex, protecting against brute-force attacks and simple guessing. The shared secret can be generated by the web site, and so follow that site’s password complexity policy. However, if it’s included in the QR code, then the code is much more sensitive. If the user’s phone does not have a signal for an Internet connection, the user has a backup option of having the ALApp display the shared secret so the user can type it in. All messages must use HTTPS to authenticate the web site to the user and the smart phone. User identifiers can be random numbers and can be generated by the user or by the web site. Alternately, the user might set a preference on the ALApp for their favorite usernames, and the ALApp can negotiate with the web site to choose a username. User identifiers can be an email address. During account creation, the ALApp can be instructed to share or not share information with the web site depending on user preferences. For instance, the ALApp can share the user’s email address, real name, photo, etc. On the other hand, the ALApp could only share a randomly generated username that can’t be tied to user names on other web sites. Of course, some sites might require more information, and if so the user might decline to create an account on that web site. Improving Security with Another Factor This scheme is most interesting (to us) as a single factor authentication for web sites which currently only use username and password combinations. This scheme makes logging into such sites quick and easy. However, this scheme can be used as a single factor or as a part of a multi-factor login. There are a variety of ways to add the second factor: The web site can maintain a username and password as before. The web site can enforce multi-factor authentication this way. The user can keep their phone locked, requiring a login password, unlock pattern (as on Android), or other method to unlock the phone. In this case, the user is accountable for deciding whether to use a second factor. Similarly, the user can store all of the shared secrets encrypted on their phone. They will need a master password to encrypt and decrypt these secrets, so the login process will be slightly slower, but they will still only have to memorize a single password. (EDIT: The newest version of the code in the git repository implements this.) Alternately, the user can choose which shared secrets they value most highly, and only encrypt those passwords, allowing them to log in to low-value web sites quickly, and higher-value web sites only by decrypting those passwords. Attacks Mitigated & Other Benefits Since the shared secret (the password) does not have to be memorized, or even typed in by a human, it can be long and complex. This mitigates against brute-force password crackers like John the Ripper (Peslyak, 2010) and Cain and Abel (Montoro, n.d.) both on the user’s side and on the web site’s side. This would prevent against attacks such as those used to crack so many users’ passwords in the Gawker password database spill described in (Kennedy, 2010). Since the user does not type their password into the computer, a virus-installed keylogger or shoulder-surfer cannot capture their password. Similarly, the user can use an untrusted computer (such as one in an Internet cafe or hotel) without revealing their password. A phishing web site cannot capture the user password by tricking them into typing it in. The phone sends the shared secret, and will only send it to the web site in its database. Since the password is randomly generated, the user will not re-use passwords on different web sites, so a password crack on one web site will not lead to escalation of privileges on another, again as happened in the Gawker password database spill (Pompeo, 2010). If the user chooses to use a randomly generated username, the user’s account on one web site cannot be associated with the user’s account on another web site, again as happened in the Gawker password database spill. Users have more privacy options since it is easier to generate and recall random passwords. The user will not lose access to a web site because they cannot remember a password. Since the authentication code is sent encrypted, and the web site authenticates itself to the user via HTTPS, the random secret can’t be intercepted to authenticate another user’s session. In several respects, this approach is similar to a browser storing passwords on behalf of a user. The major advantage this approach has is that one can easily move identities between machines. Finally, the login process is quicker and easier than typing a username and password. Vulnerabilities This scheme does not prevent man-in-the-middle attacks; these need to be mitigated by HTTPS. Edit: A vulnerability pointed out by Michael Tschannen is a variant of session fixation that requires a phishing attack. An attacker generates an AC for a target site and therefore knows the session cookie. The attacker tricks a user into visiting a less-trusted site and trying to log into that site. The attacker puts the AC for the target site into the (fake) less-trusted site. The user scans the AC, authenticating the attacker to the target site. This can be mitigated in two ways: 1) require that the user select the site they are logging into on the ALApp, or 2) confirm with the user the site they are logging into before sending the shared secret. If the phone is lost or damaged, the user cannot access their web sites. This can be mitigated by storing the user’s email address for password reset or authorizing a new phone. Another option is to encrypt the phone’s password database and store it in the cloud or otherwise backing it up. If the phone is stolen, the attacker can impersonate the user; therefore it is most likely desirable to encrypt the shared secrets on the phone and to authenticate the user to the phone with a single password, as above. This may not be necessary for web sites that are of low value to the user. If the phone is stolen, it may be desirable to issue a revocation of all related passwords at once, rather than individually logging into different web sites. When using an untrusted computer (one with a virus or in a hotel lobby), the user’s account is still vulnerable as long as the session is active. Many of these vulnerabilities are equivalent to any system which stores a user’s passwords on their phone. Related Authentication Systems The ALApp can be integrated with an InfoCard/CardSpace client on the phone. As with any authentication mechanism, this can be used to authenticate to an OpenID provider. The workflow can be modified to use a Public Key Infrastructure instead of shared secrets. This might allow smoother revocation by issuing a revocation certificate if the phone is stolen. Demonstration System Notes We have implemented a demonstration system which you can try out to experiment with this method of logging in. It has a number of limitations, the most obvious of which is that it can only be used to log into the demonstration web site; it will only remember one username and password. We implemented the web site login by creating a Drupal module in the hopes that it will eventually be possible to allow this type of login by installing the module. Not all of the features discussed in this paper are in the current module version. Our plan is to release the module and the app open source. One attractive feature of this scheme is that web sites don’t have to move away from using cookies, usernames, and passwords so their back-end functionality does not have to change, only the login process. Zebra Crossing (ZXing) is a QR-code reader on Android that can easily be integrated with other apps such as ALApp. OI Safe is an encrypted password store on Android that has an API allowing other authorized apps, such as the ALApp, to store and retrieve passwords (Potoczny-Jones, 2009). Related Work There is a lot of work in using mobile phones as a factor in authentication. Google web applications can be configured to use a second factor, either an app installed on a phone, or a text message sent to a phone ( Feigenbaum, 2010). In each case, the user is presented with a code that they type into the web site. Our proposed scheme does not require the user to type anything into the web site. It also uses a separate channel, and so mitigates “man in the browser” attacks to some extent. Liao & Lee (2010) propose a QR-code authentication system for generating one-time passwords. Their system is more complex since it provides for mutual authentication (we use HTTPS) and yet still requires some secure channel between the web site and the mobile app. Safelayer describes a similar authentication system using asymmetric encryption (Safelayer, n.d.). However, this is described as a multi-factor system, and requires web sites to modify their back-end systems to use public/private keypairs. Our proposed system still uses simple username / password combinations. A system for authenticating transactions on untrusted terminals using QR codes is described in (Starnberger, Froihofer, and Goeschka, 2009) but also uses PKI and requires the user to enter a code into the computer after the smart phone performs a computation. Conclusion We are seeking feedback on this approach. If you see any security issues, please inform us. EDIT: We have received a lot of good feedback. There was a good discussion on Reddit’s netsec that was mostly positive. We have outlined a scheme whereby a mobile phone can be used as an authentication mechanism using QR codes. This scheme could allow users to log into a web site using a single step: scanning a QR code from their mobile phones. Alternately, this scheme can be used as one factor in multi-factor authentication. QR codes, mutli-factor authentication, and Internet-connected smart-phones are “in the air” and others have likely come up with similar schemes. We have written this paper because we haven’t found any other description of such a system, nor seen one in the wild. Mostly, we would like to use such a system since it would improve security and convenience on the Internet, so please implement this and release it open source, or help us to do so 🙂 References Feigenbaum, E. (2010). A more secure cloud for millions of Google Apps users. Official Google enterprise blog. Retrieved from http://googleenterprise.blogspot.com/2010/09/more-secure-cloud-for-millions-of.html Kennedy, D. (2010). The real lessons of Gawker’s security mess, The Firewall. Forbes. Retrieved from http://blogs.forbes.com/firewall/2010/12/13/the-lessons-of-gawkers-security-mess/ Liao, K., & Lee, W. (2010). A Novel User Authentication Scheme Based on QR-Code . Journal of networks, vol. 5, no. 8. Retrieved from http://www.academypublisher.com/ojs/index.php/jnw/article/viewFile/0508937941/2055 Montoro, M. (n.d.). Cain & Abel user manual. Retrieved from http://www.oxid.it/ca_um/ Peslyak, A. (2010). John the Ripper user manual. Retrieved from http://www.openwall.com/john/doc/CREDITS.shtml Pompeo, J. (2010). Leaked Gawker passwords cause trouble on GMail, Twitter [web log post]. Retrieved from http://news.yahoo.com/s/yblog_thecutline/20101213/bs_yblog_thecutline/leaked-gawker-passwords-cause-problems-on-twitter-gmail Potoczny-Jones, I. (2009). CryptoIntents, A discussion of the cryptography and keystore intents in OI Safe. Retrieved from https://code.google.com/p/openintents/wiki/CryptoIntents Safelayer. (n.d.) QR-Scan OTP: ergonomic authentication. Retrieved from http://sandbox.safelayer.com/index.php?option=com_content&view=article&id=466%3Aqr-scan-otp-ergonomic-authentication&catid=1%3Asemantic-web-trust-portal&Itemid=2&lang=en Starnberger G., Froihofer L., and Goeschka, K. M. (2009) . QR-TAN: Secure Mobile Transaction Authentication . IEEE Computer Society. Retrieved from http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.149.2315&rep=rep1&type=pdf", "date": "2011-01-05"},
{"website": "Galois", "title": "Galois awarded AFRL/OSD project in hardware security", "author": "Unknown", "link": "https://galois.com/blog/2010/12/galois-awarded-afrlosd-project-in-hardware-security/", "abstract": "Galois has been selected by AFRL / OSD for a Phase I Small Business Innovative Research (SBIR) award to develop countermeasures against malicious hardware. In this project, Galois will address the class of hardware threats known as “deterministically triggered trojans”, and develop tools that inhibit malicious hardware activation by applying attack incompatibility techniques. This effort builds on Galois’ experience in both the Active Defense and Domain Specific Language research programs. For more information, please contact the lead investigator, David Burke", "date": "2010-12-23"},
{"website": "Galois", "title": "Galois chosen for DARPA project in Android security", "author": "Unknown", "link": "https://galois.com/blog/2010/12/galois-chosen-for-darpa-project-in-android-security/", "abstract": "DARPA has selected Galois, Inc for a Phase 1 project to develop software tools to enforce inter-application security on the Android operating system. The goal of the project is to prevent untrusted applications from accessing sensitive data or capabilities (such as GPS), whether directly, or through intermediary applications on a device. The proposed tools will address two classes of security threats to mobile devices: execution of dangerous code; and inter-application information flows that violate privacy or confidentiality. This project builds on Galois’ expertise in static analysis and information flow analysis, conducted under the Evaluator Tools and Program Analysis research programs. For more information contact lead investigator, Dr. Joe Hurd.", "date": "2010-12-13"},
{"website": "Galois", "title": "Galois, Inc. Wins Two United States Army Research Awards", "author": "Unknown", "link": "https://galois.com/blog/2010/12/galois-inc-wins-two-united-states-army-research-awards/", "abstract": "Galois, Inc . has been awarded two 2010 Small Business Innovation Research Awards by the United States Army Research, Development and Engineering Command , to investigate new approaches in the construction of high assurance microkernels, and, separately, tools for portable, consistent user interfaces based on domain specific languages. This work will be conducted under Galois’ Systems Software and Programming Languages technical areas, and will be led by Dylan McNamee and Rogan Creswick .", "date": "2010-12-09"},
{"website": "Galois", "title": "Galois wins NASA award for formal methods in machine learning", "author": "Unknown", "link": "https://galois.com/blog/2010/12/galois-wins-nasa-award-for-formal-methods-in-machine-learning/", "abstract": "NASA has awarded Galois, Inc. a Small Business Innovation Research award to conduct research into the application of formal verification to machine learning systems. From the abstract: Automated tools are quickly making inroads into casual computing environments, solving progressively more complex tasks. However, these advancements still require trading reliability for convenience. Frequent minor failures are acceptable in casual environments, but critical systems cannot make the same exchange. The software systems that NASA develops could greatly benefit from machine learning technologies that have been applied to casual computing, if the software developed by learning algorithms could be verified. The work will be conducted under Galois’ Formal Methods research program, and seeks to demonstrate increased verification capabilities through the application of model checking to aid the construction of machine learning tools. For more information about the project, contact Rogan Creswick or John Matthews.", "date": "2010-12-08"},
{"website": "Galois", "title": "John Launchbury named ACM Fellow", "author": "Unknown", "link": "https://galois.com/blog/2010/12/john-launchbury-named-acm-fellow/", "abstract": "Chief Scientist and founder of Galois, Inc, John Launchbury , has been named a 2010 ACM Fellow by the Association for Computing Machinery (ACM) . The awardees, … ACM Fellows, from the world’s leading universities, corporations, and research labs, achieved accomplishments that are driving the innovations necessary to sustain competitiveness in the digital age … [and] celebrates the exceptional contributions of the leading members in the computing field. These individuals have helped to enlighten researchers, developers, practitioners and end-users of information technology throughout the world. John has been recognized for “contributions to the development of functional programming”. Galois is proud to join Google, IBM, Microsoft Research, AT&T and Xilinx in being recognized for contributions to computing from the corporate sector.", "date": "2010-12-07"},
{"website": "Galois", "title": "Galois releases the Haskell Lightweight Virtual Machine (HaLVM)", "author": "Unknown", "link": "https://galois.com/blog/2010/11/galois-releases-the-haskell-lightweight-virtual-machine-halvm/", "abstract": "Galois, Inc. is pleased to announce the immediate release of the Haskell Lightweight Virtual Machine (or HaLVM), version 1.0. The HaLVM is a port of the GHC runtime system to the Xen hypervisor, allowing programmers to create Haskell programs that run directly on Xen’s “bare metal.” Internally, Galois has used this system in several projects with much success, and we hope y’all will have an equally great time with it. What might you do with a HaLVM? Pretty much anything you want. 🙂 Explore designs for operating system decomposition, examine new notions of mobile computation with the HaLVM and Xen migration, or find interesting network services and lock them inside small, cheap, single-purpose VMs. The HaLVM is the result of many years of effort, by many people inside Galois.  Although it is not yet totally bug-free, we have decided that broad adoption wins over perfection and thus we are releasing it for general review. As such, there will be some rough edges, and we urge you to read the documentation to understand the platforms we test on. We are releasing the HaLVM under a non-restrictive BSD3 license. You can find it here: http://halvm.org We welcome user feedback, feature requests, bug notices, patches, and feature additions; see the page above for guidelines on getting involved. Finally, we’d like to give many things to the GHC and Xen communities, without which this work would not be possible. If you have any questions or concerns, please don’t hesitate to contact the HaLVM’s maintainers at halvm-devel@community.galois.com . Have a lovely day!", "date": "2010-11-30"},
{"website": "Galois", "title": "2010 Bike Commute Challenge", "author": "Unknown", "link": "https://galois.com/blog/2010/10/2010-bike-commute-challenge/", "abstract": "Galois once again participated in the Bicycle Transportation Alliance’s Bike Commute Challenge , an annual September event that encourages people to bike to work.Galois finished 25th out of 256 teams in the Businesses and Non Profits with 25 – 99 Employees category. 26.4% of employee commutes to the office in September were by bike, Galois’ highest participation rate ever!", "date": "2010-10-12"},
{"website": "Galois", "title": "Copilot: a DSL for Monitoring Embedded Systems", "author": "Unknown", "link": "https://galois.com/blog/2010/09/copilot-a-dsl-for-monitoring-embedded-systems/", "abstract": "Introducing Copilot Can you write a list in Haskell? Then you can write embedded C code using Copilot. Here’s a Copilot program that computes the Fibonacci sequence (over Word 64s) and tests for even a numbers: fib :: Streamsfib = do \"fib\" .= [0,1] ++ var \"fib\" + (drop 1 $ varW64 \"fib\") \"t\" .= even (var \"fib\") where even :: Spec Word64 -> Spec Bool even w = w `mod` const 2 == const 0 Copilot contains an interpreter, a compiler, and uses a model-checker to check the correctness of your program. The compiler generates constant time and constant space C code via Tom Hawkin’s Atom Language (thanks Tom!). Copilot is specifically developed to write embedded software monitors for more complex embedded systems, but it can be used to develop a variety of functional-style embedded code.Executing > compile fib \"fib\" baseOpts generates fib.c and fib.h (with a main() for simulation—other options change that). We can then run > interpret fib 100 baseOpts to check that the Copilot program does what we expect. Finally, if we have CBMC installed, we can run > verify \"fib.c\" to prove a bunch of memory safety properties of the generated program. Galois has open-sourced Copilot (BSD3 licence).  More information is available on the Copilot homepage .  Of course, it’s available from Hackage , too. Flight of the Navigator Copilot took its maiden flight in August 2010 in Smithfield, Virginia. NASA rents a private airfield for test flights like this, but you have to get past the intimidating sign posted upon entering the airfield. However, once you arrive, there’s a beautiful view of the James River.We were flying on a RC aircraft that NASA Langley uses to conduct a variety of Integrated Vehicle Health Management (IVHM) experiments. (It coincidentally had Galois colors!)  Our experiments for Copilot were to determine its effectiveness at detecting faults in embedded guidance, navigation, and control software.  The test-bed we flew was a partially fault-tolerant pitot tube (air pressure) sensor.  Our pitot tube sat at the edge of the wing.  Pitot tubes are used on commercial aircraft and they’re a big deal: a number of aircraft accidents and mishaps have been due, in part, to pitot tube failures .Our experiment consisted of a beautiful hardware stack, crafted by Sebastian Niller of the Technische Universität Ilmenau.  Sebastian also led the programming for the stack.  The stack consisted of four STM32 ARM Cortex M3 microprocessors.  In addition, there was an SD card for writing flight data, and power management. The stack just fit into the hull of the aircraft. Sebastian installed our stack in front of another stack used by NASA on the same flights.The microprocessors were arranged to provide Byzantine fault-tolerance on the sensor values.  One microprocessor acted as the general, receiving inputs from the pitot tube and distributing those values to the other microprocessors.  The other microprocessors would exchange their values and perform a fault-tolerant vote on them.  Granted, the fault-tolerance was for demonstration purposes only: all the microprocessors ran off the same clock, and the sensor wasn’t replicated (we’re currently working on a fully fault-tolerant system). During the flight tests, we injected (in software) faults by having intermittently incorrect sensor values distributed to various nodes.The pitot sensor system (including the fault-tolerance code) is a hard real-time system, meaning events have to happen at predefined deadlines. We wrote it in a combination of Tom Hawkin’s Atom , a Haskell DSL that generates C, and C directly.Integrated with the pitot sensor system are Copilot-generated monitors. The monitors detected unexpected sensor values (e.g., the delta change is too extreme), the correctness of the voting algorithm (we used Boyer-Moore majority voting , which returns the majority only if one exists; our monitor checked whether a majority indeed exists), and whether the majority votes agreed. The monitors integrated with the sensor system without disrupting its real-time behavior. We gathered data on six flights.  In between flights, we’d get the data from the SD card. We took some time to pose with the aircraft. The Copilot team from left to right is Alwyn Goodloe, National Institute of Aerospace ; Lee Pike, Galois, Inc. ; Robin Morisset, École Normale Supérieure; and Sebastian Niller, Technische Universität Ilmenau. Robin and Sebastian are Visiting Scholars at the NIA for the project. Thanks for all the hard work!There were a bunch of folks involved in the flight test that day, and we got a group photo with everyone. We are very thankful that the researchers at NASA were gracious enough to give us their time and resources to fly our experiments. Thank you!Finally, here are two short videos. The first is of our aircraft’s takeoff during one of the flights. Interestingly, it has an electric engine to reduce the engine vibration’s effects on experiments. Untitled from Galois Video on Vimeo . The second is of AirStar, which we weren’t involved in, but that also flew the same day. AirStar is a scaled-down jet (yes, jet) aircraft that was really loud and really fast. I’m posting its takeoff, since it’s just so cool. That thing was a rocket! Untitled from Galois Video on Vimeo . More Details Copilot and the flight test is part of a NASA-sponsored project ( NASA press-release ) led by Lee Pike at Galois.  It’s a 3 year project, and we’re currently in the second year. Even More Details Besides the language and flight test, we’ve written a few papers: Lee Pike, Alwyn Goodloe, Robin Morisset, and Sebastian Niller. Copilot: A Hard Real-Time Runtime Monitor . To appear in the proceedings of the 1st Intl. Conference on Runtime Verification (RV’2010) , 2010. Springer. This paper describes the Copilot language. Lee Pike. Schrödinger’s CRCs (Fast Abstract) . 40th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN 2010) , 2010. Byzantine faults are fascinating.  Here’s a 2-page paper that shows one reason why. Alwyn Goodloe and Lee Pike. Monitoring distributed real-time systems: a survey and future directions . NASA Contractor Report NASA/CR-2010-216724, 2010. At the beginning of our work, we tried to survey prior results in the field and discuss the constraints of the problem.  This report is a bit lengthy (almost 50 pages), but it’s a gentle introduction to our problem space. Lee Pike, Geoffrey M. Brown, and Alwyn Goodloe. Roll your own test bed for embedded real-time protocols: a Haskell experience . In Haskell Symposium , 2009. Yes, QuickCheck can be used to test low-level protocols. Alwyn Goodloe and Lee Pike. Toward monitoring fault-tolerant embedded systems (extended abstract) . In International Workshop on Software Health Management (SHM’09), 2009. A short paper motivating the need for runtime monitoring of critical embedded systems. You’re Still Interested? We’re always looking for collaborators, users, and we may need 1-2 visiting scholars interested in embedded systems & Haskell next summer.  If any of these interest you, drop Lee Pike a note (hint: if you read any of the papers or download Copilot, you can find my email).", "date": "2010-09-22"},
{"website": "Galois", "title": "Galois, Inc. Wins Three Department of Energy Small Business Research Awards", "author": "Unknown", "link": "https://galois.com/blog/2010/08/galois-inc-wins-three-department-of-energy-small-business-research-awards/", "abstract": "Galois, Inc ., a Portland, Oregon computer science R&D company, has been awarded two 2010 Phase I SBIR research awards, and one 2010 Phase 2 award from the US Department of Energy Office of Advanced Scientific Computing Research , to conduct research into high performance computing infrastructure. A Deployable, Robust File System for Parallel I/O When considering high-performance parallel computers, it is easy to overlook the importance of disk storage. In this research, Galois will address the topic of disk storage for parallel computers, and create a deployable, robust file system that will reduce downtime due to faults and increase productivity through improved system performance. Galois’ will take a synthesis approach, combining several strands of existing research on the subject of file systems and transitioning it into a robust, fully-featured product. In doing so, we will utilize modern formal methods research, in the form of model checking , to validate our design and improve the reliability of our implementation. The benefits of this research will be to improve the efficiency and decrease the cost of large, parallel file systems. This work will be applicable to Department of Energy laboratories, as well as to commercial users of massive parallel or distributed storage, such as online storage and backup providers or grid storage providers.This project builds on Galois’ experience with industrial model checking, and our prior work on file system design and implementation via formal methods. Improved Symbol Resolution for Portable Build Systems Modern High Performance Computing utilizes a variety of different hardware and software platforms. These differences make it difficult to develop reusable components, which leads to a significant decrease of productivity. This project will investigate the design of portable build systems that are simple, yet sufficiently robust with respect to symbol resolution, so that they are able to adapt and build software across many different platforms. This project will result in increased productivity for software developers who design portable software components. In particular, we anticipate significant benefits in the area of High Performance Computing, where the multitude of different hardware and software platforms make the problem of reusing software particularly acute.This work takes advantage of Galois’ background in domain specific language design, and build systems, in particular, Cabal, and other system configuration software. Collaboration and Sharing on the Grid The goal of the “Grid 2.0” project is to improve the ability of a distributed team of researchers to collaborate on research using grid middleware computing infrastructure. In Phase I of this project, we developed a prototype integration of a typical collaboration-oriented web application with an open source data grid middleware system, establishing that such integration is feasible. In Phase II, we directly address the weakest point for collaboration applications on grid systems: open, standardized protocols for identity management , authorization, and delegation on the grid, via a federated identity management system providing support for software authorization and delegation on the Open Science Grid . The intent is to provide a secure, open, and flexible identity management system for use on grid infrastructure projects, portable to other grid middleware systems, and interoperable with existing identity management schemes. The open source results of the research will form the basis for applications of identity management systems in commercial cloud and grid systems.This project builds on Galois’ experience with cross-domain collaboration tools and secure identity management systems (including OpenID, OAuth, SAML and X.509) developed for several clients over the past decade.For more information about these projects, contact Don Stewart (dons@galois.com).", "date": "2010-08-10"},
{"website": "Galois", "title": "Galois Tech Talks, now on Vimeo!", "author": "Unknown", "link": "https://galois.com/blog/2010/06/galois-tech-talks-now-on-vimeo/", "abstract": "For a number of years, Galois Inc. has been organizing technical seminars presented by visiting researchers, Galois engineers, and members of the vibrant Portland technical community. The seminars span a wide variety of topics, ranging from functional programming, formal methods, and compiler and language design, to cryptography, and operating system construction. The talks are free and open to the interested public. Announcements of upcoming talks are posted to this blog about a week in advance.Over the last few months we have received a number of requests to share videos of the talks with the wider community. As a result, we are very pleased to announce the Galois tech talk channel on Vimeo. Recent Galois talks should become available over the next few weeks, followed by future presentations.Enjoy!Galois tech talk channel: http://vimeo.com/channels/galois", "date": "2010-06-14"},
{"website": "Galois", "title": "Signali: A Custom IP-Design Company", "author": "Unknown", "link": "https://galois.com/blog/2009/01/signali-a-custom-ip-design-company/", "abstract": "Signali Corp is the latest technology commercialization spinout from Galois, chartered with commercialization of hardware IP core design technology aimed at the FPGA and ASIC markets.  Engineers at Galois and Signali have used the proprietary technology to deliver to government prime contractors the highest performing FPGA implementations in the world for a set of common cryptographic algorithms.With this technology, Signali is well-placed to make a significant impact on the IP core market with their ability to re-tune their cores to meet the customer’s design constraints, whether speed, or power, or area. The technology is especially well suited for optimizing hardware designs of computationally complex functions such as those common in digital signal processing and cryptographic systems.Galois enlisted the experience of Brian Moore, a seasoned design engineer and lab director from Intel, to lead Signali. Moore brings over 25 years of experience in the semiconductor and energy research industries. Galois co-founder Jeff Lewis, is leading the technology development as Chief Technology Officer. Signali is currently co-located with Galois in the historic Commonwealth Building in downtown Portland, Oregon. The company is engaged with Achronix Semiconductor to develop a portfolio of very high performance IP cores for their next-generation FPGAs. Sample performance and utilization numbers for IP cores running on the Achronix Speedster FPGA can be found on the Signali website.", "date": "2009-01-13"},
{"website": "Galois", "title": "Cryptol, the language of cryptography, now available", "author": "Unknown", "link": "https://galois.com/blog/2008/12/cryptol-the-language-of-cryptography-now-available/", "abstract": "Galois is pleased to announce that Cryptol, the language of cryptography, is now available to the public!Cryptol is a domain specific language for the design, implementation and verification of cryptographic algorithms, developed over the past decade by Galois for the United States National Security Agency. It has been used successfully in a number of projects, and is also in use at Rockwell Collins, Inc. Domain-specific languages ( DSLs ) allow subject-matter experts to design solutions in using familiar concepts and constructs. Cryptol, as a DSL, allows domain experts in cryptography to design and implement cryptographic algorithms with a high degree of assurance in the correctness of their design, and at the same time, producing a high performance implementation of their algorithms.Cryptol allows a cryptographer to: Create a reference specification and associated formal model. Test the specification against published test vectors and formal assertions about state. Quickly refine the specification, in Cryptol, to one or more implementations, trading off space, time, and other performance metrics. Compile the implementation for multiple targets, including: C/C++, Haskell, and VHDL/Verilog. Equivalence check an implementation against the reference specification, including implementations not produced by Cryptol. The Cryptol site has further documentation and the full language specification. In this release, Galois has made a implementation of the Cryptol language available free of charge for non-commercial uses. The trial version is available for Linux, MacOS, and Windows installations and can be downloaded at the Cryptol site . The trial version is meant for language exploration. It includes a Cryptol interpreter with QuickCheck capabilities, documentation, and examples. The open version does not compile to VHDL, C/C++, or Haskell, and does not produce the formal models used for equivalence checking.Cryptol is implemented in Haskell. Contact Galois to obtain a full-featured version for evaluation.", "date": "2008-12-24"},
{"website": "Galois", "title": "Galois, Inc. Wins Two Small Business Research Awards from Federal Agencies", "author": "Unknown", "link": "https://galois.com/blog/2009/06/galois-inc-wins-two-small-business-research-awards-from-federal-agencies/", "abstract": "Galois, Inc ., a Portland, Oregon research and development company, has been awarded two Phase I Small Business Innovative Research contracts. Galois will be engaging with the Department of Energy and the Department of Homeland Security on innovative technology solutions. DHS Topic: Highly Scalable Identity Management Tools Galois has been granted a Phase I SBIR from the Department of Homeland Security to develop a reusable identity management metasystem which will be designed foundationally to support government certification for deployment across agency boundaries, focusing on open standards, secure development, and a cross-domain design.The Department of Homeland Security’s charter has a fundamental requirement to collaborate with other government agencies. Secure collaboration on this scale requires strong identity management which can “vouch for” DHS personnel working with other agencies and makes it possible to provide DHS resources to individuals in other agencies whose work requires it. Anticipated Benefits : This work will provide an opportunity to deploy standard trusted components in a variety of agencies, each of which can continue to maintain its own method of managing identity and authorization. Agencies can share information based on this layer, which will evolve to support a wide variety of needs. Potential commercial applications : Compliance with government standards of trustworthiness in software used for critical purposes, along with a user-centric approach to identity management, can enable Internet users to merge their many usernames and passwords, allow critical transactions to be executed with a higher degree of trust, and help bring about an environment where e-voting increases voters’ trust in the validity of the outcome of elections. DOE Topic: Grid 2.0: Collaboration and Sharing on the Grid Galois has been granted a Phase I SBIR from the Department of Energy to implement a Web 2.0 collaboration system based on Grid technologies . Galois’ system will allow dispersed scientific teams to collaborate effectively on large amounts of data produced by collections of networked computers.Grid computing makes accessible significant computational and data resources to distributed teams of scientific researchers. In doing so, it also poses a challenge: How do distributed teams collaborate effectively with these resources?The problem is determining how best to apply social and collaboration software techniques to improve the efficiency of collaboration between distributed teams working on grid systems. Potential Commercial Applications : Grid computing is inherently social in the sense of involving multiple, loosely connected parties. Social collaboration in the area of large datasets is relevant to industrial and academic scientists. About Galois, Inc. Galois is a research and development company with a strong drive to transition technology from research into practice in the commercial and government sphere. Located in downtown Portland, Galois is a company of around 35 employees, including software developers, project managers, and business development personnel. Galois has experience in programming language design and compiler implementation, secure web application development, secure operating system development, and several other fields. Since its founding in 1999, Galois has been funded for R&D by members of the Intelligence Community and the DoD.  Read more about Galois’ research and technology on their web site: www.galois.com .", "date": "2009-06-29"},
{"website": "Galois", "title": "Galois Open House", "author": "Unknown", "link": "https://galois.com/blog/2008/09/galois-open-house/", "abstract": "Please join us for an open house to celebrate our new office space in downtown Portland’s historic Commonwealth Building. Located on SW 6th Avenue between Stark and Washington streets, we’re easily accessible via MAX or TriMet buses. We’re up on the third floor.Parking will also be available in the Alder Street Star Park parking garage located at 615 SW Alder, just one block from our building; validation will be provided at the event. What: Galois Open House When: Thursday, September 18 Time: 4:00 pm – 6:00 pm Where: The Commonwealth Building421 SW Sixth Ave., Ste. 300 RSVP: Anne Marie @ ph. 503.626.6616, x153 or email anne at galois.com", "date": "2008-09-02"},
{"website": "Galois", "title": "Achronix and Signali: High-performance 128-bit AES cores for Speedster FGPAs", "author": "Unknown", "link": "https://galois.com/blog/2009/05/achronix-and-signali-high-performance-128-bit-aes-cores-for-speedster-fgpas/", "abstract": "Achronix Semiconductor , maker of the world’s fastest FPGAs, today announced (.pdf) the availability of new, high-performance AES IP cores for its Speedster TM 1.5 GHz family FPGAs. These high-performance 128-bit key size AES core are targeted at 10 Gbps, 40 Gbps, and 100 Gbps applications have been designed and built by Signali , a Galois spinoff focusing on custom cores targetting computationally intensive algorithms, fixed-function DSP and cryptographic applications. Signali uses their Quattro™ compiler suite to transform high-level descriptions of data-intensive functions, such as AES into high-performance RTL. Read the full story.", "date": "2009-05-07"},
{"website": "Galois", "title": "One Million Haskell Downloads…", "author": "Unknown", "link": "https://galois.com/blog/2009/03/one-million-haskell-downloads/", "abstract": "Galois engineers write a lot of Haskell (in fact, our technology catalogue is built pretty much entirely on it). We find we’re able to build systems faster, with fewer errors, and in turn are able to apply techniques to increase assurance, helping us deliver value to our clients. We’ve successfully engineered large systems in the language for nearly a decade. We also use and write a lot of open source Haskell code. Since 2004 we’ve been investing in improving packaging and distribution infrastructure for Haskell code, and since 2007 Galois has been hosting hackage.haskell.org : the central online database of open source Haskell libraries and applications. These packages are built via Cabal (dreamed up by Galois’ own Isaac Potoczny-Jones ), and distributed via cabal-install . Hackage now hosts more than 1100 released libraries and tools, and has been growing rapidly (and, incidentally, Galois employees have released or been significant contributors to just shy of 10% of all Hackage projects). We’ve wondered for a while now just how busy Hackage was becoming, and in turn, what other interesting information about Haskell were buried in the Hackage logs. This post answers those questions for the first time. We’ll see Total, and growing, Haskell source downloads The most popular Haskell projects hosted on Hackage The most popular development categories The most popular methods for distributing Haskell source and speculate a little on where Hackage is heading. Background We’ve known for a while that uploads to Hackage were growing. You might have seen this graph elsewhere (it’s derivable from the RSS logs of package uploads ): There’s a pretty clear trend upwards. Average daily Hackage releases have increased 4-fold since Hackage was launched, and it’s now averaging 10 packages a day released. The question is: was anyone using this code? Measuring Downloads To measure downloads, we processed the apache logs for Hackage going back to its launch (incidentally, the log processing script – in Haskell of course – uses the Haskell zlib , bytestring , filepath , containers , bytestring-csv libraries). This generates a two dimensional map of downloads per project, per month. (You can find links to the raw data at the end of the article).We can now play with the data to see some interesting trends.Some cautionary notes interpreting this data: we only process Hackage package downloads (i.e. “GET binary-0.5..tar.gz” requests). We are only able to measure source downloads – that is, someone downloads a package they will build from source, with GHC. We cannot measure downloads from open source mirrors (such as those provided by the major unix distributions), nor can we measure users of binary packages (such as on Debian, Ubuntu or Fedora), nor can we measure downloads of packages not hosted on Hackage (such as gtk2hs , pugs , darcs or ghc) . So this doesn’t represent all Haskell downloads, only downloads of source packages.We have complete data for Hackage, from the initial alpha tests in July 2006, through to launch in January 2007, until March 2009. Total Downloads To begin with, here’s the cumulative downloads from Hackage, over time: As you can see, we’re just shy of 900 thousand package downloads, and from January 2008 to December 2008 – the first complete year of live operation – there were 500 thousand downloads, with a further 150 thousand downloads in the first 2 months of 2009. To visualize the growth trend, here is the same cumulative download line on a logarithmic scale: In the alpha-testing period from July 2006 to July 2007, downloads grew exponentially (4 orders of magnitude in 4 quarters) as existing developers started to use the system. Since the middle of 2007, the rate of growth has slowed, increasing by an order of magnitude in a 15 month period. Hackage is on target to reach its 1 millionth download next month. We’ll have a party. Downloads by Month Next up is the downloads per month, over time. I dropped a bezier curve on top to give a sense of the trend. As we only have partial data for March 2009, I’m excluding that. This graph essentially confirms the same trend as we see in the cumulative graphs. Interestingly, download spikes roughly correspond with upload spikes in our first graph (presumably as people scramble to get the new code). Hackage is currently seeing 100 package downloads an hour, and that value has been doubling every 4 months for the past year and a half. Package Popularity Besides overall downloads, there’s a wealth of per-package information. In the following graphs we extract total downloads for each package (ignoring version numbers). The popularity graph displays a classic “ long tail “, where the download frequency of any package is inversely proportional to its rank in the frequency table. This suggests that a good interface to a large Hackage database should behave something like the “long tail” sites like Amazon – where we rely on recommendations and other interlinking to ensure visibility of projects in the tail. The frequency of downloads is even more visible on a double log scale, where the popularity pretty much matches Zipf’s law : The download frequency doesn’t quite match the classic distribution at the top and tail of the curve. There are two reasons for this (and maybe other factors at play). Firstly, the tail of the curve drops off, as the bottom 10% of popular packages tend to be the newest packages, and so are unde-represented in the “market”. The other interesting part of the popularity curve is at the top. The top 10 to 50 packages are, to varying degrees, less popular than we might predict. Why is this? The Distribution Effect Remember that Hackage is a source-only repository. So it is of primary interest to developers. As a Haskell package becomes more popular, it tends to get picked up by Linux and BSD distributions such as Debian or Ubuntu (and also distributed in binary form for Mac and Windows), removing the need to download the source. Popular packages are doomed to become less popular in source form if the distributions are doing their work! This is particularly apparent for libraries distributed with GHC (the “extra libs”). Libraries such as containers, arrays, bytestring, parsec and network rarely need to be downloaded in source form, as they’re bundled with GHC forming a platform base. They should thus be under-repesented in source downloads. You can see this “distribution effect” in this overlay of xmonad and its Debian package installs where source installs decline dramatically as soon as the binary packaging takes off. Popular packages are doomed to be distributed through other channels. Most Popular Packages And here – for the first time – are the per-package popularity statistics for Hackage. First, the top 25 packages sorted by their cumulative total downloads. Executable applications are marked in blue. 1 xmonad 35428 2 HTTP 26203 3 zlib 24431 4 Cabal 23691 5 X11 21563 6 binary 15752 7 utf8-string 12633 8 mtl 12517 9 cabal-install 12274 10 regex-posix 11351 11 X11-extras 10509 12 xmonad-contrib 9794 13 haddock 9209 14 parsec 8468 15 bytestring 7473 16 regex-base 7438 17 HaXml 6307 18 network 6285 19 xmobar 6272 20 yi 6268 21 hscolour 6264 22 QuickCheck 5697 23 hslogger 5434 24 regex-compat 5266 25 ghc-paths 4653 And the next 75 Haskell packages, in order: filepath, X11-xft, alex , happy , vty, cgi, terminfo, unix, GLUT, chunks, fingertree, OpenGL, time, pureMD5, regex-tdfa, xhtml, bzlib, Crypto, syb-with-class, hxt, tagsoup, HDBC, MissingH, SDL, haskell-src-exts, plugins, Stream, frag , curl, pcre-light, unix-compat, uniplate, wxcore, hinstaller, stm, html, Diff, polyparse, leksah , HUnit, hmp3 , haskell-src, RJson, fastcgi, pandoc, arrows, YamlReference, parsedate, HGL, GLFW, process, extensible-exceptions, zip-archive, iconv, HDBC-sqlite3, TypeCompose, cpphs , hmatrix, HPDF, HAppS-Server, haskell98, hspread, HAppS-Util, rosezipper, gd, dlist, array, yi-gtk, haskeline, HStringTemplate, HAppS-Data, fgl, haskelldb, xml, cabal-rpm Congratulations to authors of these packages – you made the top 10% most popular releases. Most Popular Downloads in February The previous table looked at the cumulative most popular projects. But that doesn’t necessarily reflect what is popular at the moment to download in source form. This table compares January downloads against February downloads, for the top 25 packages in Feburary: Package Downloads Rank Change HTTP 2926 zlib 2345 Cabal 2148 cabal-install 1490 utf8-string 1352 xmonad 1280 binary 1174 regex-posix 901 +8 parsec 842 +2 X11 834 -1 xmonad-contrib 754 +1 hscolour 739 -2 terminfo 713 +1 haddock 669 -6 ghc-paths 630 +2 HaXml 600 +12 extensible-exceptions 596 +16 QuickCheck 584 +9 regex-base 558 -4 time 529 -1 darcs 501 1 leksah 500 +18 regex-tdfa 496 +24 hslogger 441 -2 Most Popular Applications The 25 most popular Haskell applications hosted on Hackage, to download in source form are: xmonad, cabal-install, haddock, xmobar, yi, hscolour, alex, happy, frag, leksah, hmp3, pandoc, cpphs, cabal-rpm, darcs, c2hs, hoogle, lambdabot, cabal2arch, hpodder, monadius, lhs2tex, mkcabal, pugs, ghc-core Note pugs and darcs have been primarily distributed separately to Hackage, until recently. Most Popular Libraries by Category We can also determine the most popular libraries and tools in each semantic category on Hackage: Task Library Downloads Client-side HTTP HTTP 26203 Database HDBC 3098 XML HaXml 6307 Control mtl 12517 Parsing parsec 8468 Binary Parsing binary 15752 Logging hscolour 6264 Testing QuickCheck 5697 Regex regex-base + regex-posix 7438 Lexing alex 4360 Codec zlib 24431 Unicode IO utf8-string 12633 Sockets network 6285 Build System Cabal 23691 Documentation haddock 9209 Syntax hscolour 6264 3D Graphics GLUT + OpenGL 7345 2D Graphics SDL * 3016 Hashing pureMD5 3460 HTML xhtml 3391 Cryptography Crypto 3243 Generics syb-with-class 3230 IDE leksah 2408 JSON RJson 2222 Markup pandoc 2210 Numerics hmatrix 1844 Web Framework HAppS-Server * 1759 Graphs fgl 1658 Parallelism parallel 1370 Charting chart 1300 Code generation llvm 970 RSS feed 726 Wiki gitit 759 Note that SDL is represented here as gtk2hs (which provides many cairo-based 2D graphics functions) isn’t distributed on Hackage. Also, HAppS-Server has been superceded by happstack. Honorable Mentions These packages didn’t quite take first place, but still have significant user support. I include happstack, although it is only a month old, as it replaces the previously popular HAppS-Server. Parsing happy, polyparse 6685 Regex Regex-tdfa, regexpr, pcre-light 8791 Codec bzlib 3275 XML hxt, xml 4871 HTML tagsoup 3141 Client-side HTTP curl 2678 Generics uniplate 2675 2D Graphics wxcore 2601 Testing HUnit 2325 Database haskelldb, hsql 3164 Network Network-bytestring 1210 Control monadLib 1081 Web Framework happstack 549 Future Finally, we can speculate on what would happen if the current download growth rate continued for a couple more years (projecting forward 18 months, using the trend of the last 18). We’d reach a cumulative total of 10 million source downloads around the end of 2010 (continuing the order of magnitude growth of the last 18 months). Of course, a lot is unknown in this scenario. If everyone starts installing all their code via cabal-install, downloads will rocket, as does increasing reuse, by using more libraries.However, if the top Haskell applications and libraries become an order of magnitude more popular, the distros will take them up, slowing growth. Growth will also slow if we run out of resources in some form or another: no more easy libraries to bind to, for example, just as we ran out of existing things to cabalize in 2007. Get the Data Yourself You can play with the data set yourself here: Monthly downloads per package ( CSV , HTML ) Packages by download frequency ( CSV , HTML ) You can also get the full data in a sqlite database , courtesy of mmorrow on #haskell.", "date": "2009-03-23"},
{"website": "Galois", "title": "Galois awarded NASA research contract", "author": "Unknown", "link": "https://galois.com/blog/2008/11/galois-awarded-nasa-research-contract/", "abstract": "NASA has awarded Galois, Inc. together with the National Institute of Aerospace (NIA), a research contract to investigate monitor synthesis for software health management (here is NASA’s press release ). The research team includes myself, Lee Pike as the Principal Investigator, Cesar Munoz as the Co-PI (NIA), and Alwyn Goodloe as a Research Scientist (NIA). The award runs through the end of 2011, and we are investigating the formal synthesis of online monitors from requirements specifications. The research will focus on safety properties and real-time properties of distributed systems. Here are some slides I gave as part of an invited panel kicking off the project, and here’s the press release from Reuters. If you’re interested in finding out more about the research or are interested in collaborating, don’t hesitate to contact me , or leave a comment!", "date": "2008-11-11"},
{"website": "Galois", "title": "Galois @ ICFP: See you there!", "author": "Unknown", "link": "https://galois.com/blog/2008/09/galois-icfp-see-you-there/", "abstract": "ICFP is next week, and as usual, Galois will be involved, sponsoring workshops, chairing sessions, presenting papers, and generally talking to people about functional programming and the future. We’re particularly excited about the expanded Haskell Symposium , the line-up for the Commercial Users of Functional Programming , and the all-new DEFUN developer tracks on functional programming (watch Oleg hack live!).If you want to catch up, keep an eye out for Andy , Don , Eric , Iavor , Joe , Joel , John , Levent , Magnus and Trevor , or follow us on Twitter . Happy hacking!", "date": "2008-09-19"},
{"website": "Galois", "title": "Parsing the Linux kernel with Haskell: experience with Language.C", "author": "Unknown", "link": "https://galois.com/blog/2008/09/parsing-the-linux-kernel-with-haskell-experience-with-language-c/", "abstract": "At Galois, Aaron Tomb has been experimenting with the new Haskell Language.C libraries recently (a Summer of Code project by Benedikt Huber, mentored by a Galois engineer, Iavor Diatchki ), and he’s been impressed by what it can do. Here are his thoughts on parsing the Linux kernel with Haskell, with an eye to future static analysis work:My interest in the library is for use in static analysis of very large bodies of legacy C code, which means two issues matter a lot to me: 1) rock-solid support for all of GCC’s numerous extensions, and 2) speed. I have used CIL , and tools based on CIL in the past, but have been disappointed with its speed.As a simple scalability and robustness experiment, I decided to see how well Language.C would do on the Linux source tree. It doesn’t yet have an integrated preprocessor (depending on GCC’s for now), but I happened to have an already-preprocessed set of sources for Linux 2.6.24.3 sitting around (configured with defconfig). Could Language.C handle the Linux kernel? I wrote a little wrapper around the C parser to essentially just syntax-check all of the code. import Language.Cimport Language.C.System.GCCimport System.Environmentprocess :: String -> IO ()process file = do putStr file stream <- readInputStream file putStr (take (20 - length file) $ repeat ' ') either print (const $ putStrLn \"Pass\") (parseC stream nopos)main :: IO ()main = do files <- getArgs mapM_ process files It prints the filename followed by “Pass” if the parse succeeds, or details about a syntax error if the parse fails. When I ran this on the Linux code mentioned above, I was amazed to find that it processed it all successfully! All 18 million lines of pre-processed source without a hitch .Since I also care about speed, I wanted to compare it with GCC. GCC has a handy flag, -fsyntax-only, which tells it to just check the syntax of the input file and quit. I ran both the Language.C wrapper(compiled with GHC 6.8.3 and the -O2 option) and GCC on all that code, on a 2.2GHz/4GB MacBook Pro. The result: Language.C parsed all of the code in about 6 minutes, while GCC managed it in a little over 2. GCC is still faster, but I’m happy to take a 3x speed hit for the benefit of being able to write all the subsequent analysis in Haskell.The following table shows the precise time and memory statistics for Langugage.C and GCC, both on the entire source collection and on the single largest file in the tree, bnx2.i, the driver for the Broadcom NetXtreme II network adapter. For the Language.C tests, I compared the performance when the garbage collector used 2 generations (the default) to 4 generations (specified with the +RTS -G4 option). Increasing the number of generations helped slightly. User Time System Time Memory Use L.C, all 5:59 0:09 144MB L.C, all, -G4 5:27 0:08 131MB L.C, bnx2.i 0:02.15 0:01.89 133MB L.C, bnx2.i, -G4 0:01.96 0:01.76 85MB gcc, all 2:02 0:17 ???? gcc, bnx2.i 0:00.56 0:00.07 33MB", "date": "2008-09-17"},
{"website": "Galois", "title": "The bike commute challenge – status", "author": "Unknown", "link": "https://galois.com/blog/2008/09/the-bike-commute-challenge-status/", "abstract": "The Bike Commute Challenge is a wonderful Oregon tradition that Galois has participated in for the past 3 years. This year was a bit disruptive for Galois commuters, because we moved offices from Beaverton to downtown Portland. I think quite a few West-siders haven’t yet figured out the best way to get downtown by bike. Nevertheless, we’re holding steady at an overall 15% commute rate, with a few folks standing out from the crowd: Sigbjorn Finne at 360 miles and Paul Heinlein at 250 miles.The challenge web site has had a few ups and downs (er, mostly downs), but it seems to be back on-line, so I’m hoping folks are able to log their trips without troubles. One weird thing is I think they’re miscomputing the commute rate – it says Paul and Sigbjorn are around 80%, but I’m pretty sure they’re both at 100%, so perhaps there are still a few kinks left to work out. (and once they are worked out, I suspect our overall rate will be well-above 15%)Anyone reading this, please commend any of your bike-commuting colleagues, and I’ll take this opportunity to thank everyone for participating (Galwegians and everyone else!)", "date": "2008-09-15"},
{"website": "Galois", "title": "FMCAD Conference in Portland, OR: October 20 – 23, 2013", "author": "Unknown", "link": "https://galois.com/blog/2013/10/fmcad-conference-in-portland-or-october-20-23-2013/", "abstract": "This year’s Formal Methods in Computer-Aided Design (FMCAD) conference is being held from October 20 – 23 here in Portland, OR. Galois is proud to be one of the sponsors of this annual event – we’re excited to be having it in our own back yard! Dr. Lee Pike is on the program committee, and he’s also giving a keynote address at the co-located MEMOCODE conference on October 18. We hope to see folks there!", "date": "2013-10-17"},
{"website": "Galois", "title": "Lee Pike Giving Keynote at MEMOCODE", "author": "Unknown", "link": "https://galois.com/blog/2013/10/lee-pike-giving-keynote-at-memocode/", "abstract": "For those registered to attend MEMOCODE 2013 this week in Portland, OR, Dr. Lee Pike will be presenting the keynote address titled “Building a High-Assurance Unpiloted Air Vehicle” on October 18 at 11:00 a.m. Abstract A drone autopilot is a complex software artifact that includes operating systems, networking, and sensor systems.  With support from DARPA, Galois is addressing the challenge of building an open-source high-assurance autopilot that is resistant to security attacks and software faults.  We are tackling the problem by borrowing from a suite of formal-methods-inspired technologies such as strongly-typed domain-specific languages for embedded control systems, software model-checking, and runtime-verification. Just over one year in, we have designed two new languages and compilers and have a provisional autopilot developed.  I will describe how we have achieved low-cost high-assurance software, the challenges ahead, and the open problems we do not yet know how to address. The autopilot and more information is available at smaccmpilot.org .", "date": "2013-10-17"},
{"website": "Galois", "title": "Automated Tools for Binary Analysis & Optimization", "author": "Unknown", "link": "https://galois.com/blog/2013/10/automated-tools-for-binary-analysis-optimization/", "abstract": "Galois was awarded a contract through the Office of Naval Research – we’re partnering with SRI to build automated tools for binary analysis and optimization to minimize software bloat and reduce costs and complexity. Read more about the effort here: http://bit.ly/1fG7S45 .", "date": "2013-10-02"},
{"website": "Galois", "title": "Understanding Changes to Software", "author": "Unknown", "link": "https://galois.com/blog/2013/10/understanding-changes-to-software/", "abstract": "We have developed a technique to make sense of change information from a typical software project’s history. The core of our approach is to treat the program text as a tree, to find differences in the tree structure, to group similar differences together, and then finally to extract a pattern that represents each group. Jason Dagit presented our work at the DChanges workshop in September, part of the DocEng conference .  The paper is available from the workshop site, along with the full workshop proceedings . The slides from the talk are also available. The problem we looked at is simply stated: What does the change history of a piece of software as represented in a source control system tell us about what people did to it over time? Anyone who has worked on a project for any substantial amount of time knows that working on code isn’t dominated by adding new features — it is mostly an exercise of cleaning up and repairing flaws, reorganizing code to make it easier to add to in the future, and adding things that make the code more robust. During the process of making these changes, we have often found that it feels like we do similar things over and over — add a null pointer check here, rearrange loop counters there, add parameters to functions elsewhere. Odds are, if you asked a programmer “what did you have to do to address issue X in your code,” they would describe a pattern instead of an explicit set of specific changes, such as “We had to add a status parameter and tweak loop termination tests.” We started with some work Matt Sottile had developed as part of a Department of Energy project called “COMPOSE-HPC” where we built infrastructure to manipulate programs in their abstract syntax form via a generic text representation of their syntax trees. The representation we chose was the Annotated Term form used by the Stratego/XT and Spoofax Workbench projects . A benefit of the ATerm form for programs is that it allows us to separate the language parser from the analyzer — parsing takes place in whatever compiler front end is available, and all we require is a traversal of the resulting parse tree or resulting abstract syntax tree that can emit terms that conform to the ATerm format. To show the idea at work, we used the existing Haskell language-java parser to parse code and wrote a small amount of code to emit an ATerm representation that could be analyzed. We applied it to two real open source repositories — the one for the ANTLR parser project and the Clojure compiler. It was satisfying to apply it to real repositories instead of contrived toy repositories — we felt that the fact the idea didn’t fall over when faced with the complexity and size of real projects indicated that we had something of real interest to share with the world here. What can you learn from your software history?", "date": "2013-10-02"},
{"website": "Galois", "title": "11+ Years of Formal Methods at Galois", "author": "Unknown", "link": "https://galois.com/blog/2011/11/11-years-of-formal-methods-at-galois/", "abstract": "A month or so ago, I  gave talks at SRI and NASA Ames on 11+ Years of Formal Methods at Galois ( pdf ).  Though I haven’t been around the whole time, it was fun to reminisce on the projects I’ve helped with and to highlight my colleagues’ work!", "date": "2011-11-11"},
{"website": "Galois", "title": "Formally Verified Chess Endgames", "author": "Unknown", "link": "https://galois.com/blog/2011/05/formally-verified-chess-endgames/", "abstract": "On May 10 Joe Hurd gave a guest lecture at Portland State University , as part of Bart Massey ‘s Computer Science course on Combinatorial Games . The topic of the guest lecture was “Formally Verified Endgame Tables” , and Joe showed how Formal Methods can be used to prove that endgame tables used by computer chess programs are correct with respect to the laws of chess. The slides of the guest lecture are available for download .", "date": "2011-05-26"},
{"website": "Galois", "title": "Merging SMT solvers and programming languages", "author": "Unknown", "link": "https://galois.com/blog/2011/01/merging-smt-solvers-and-programming-languages/", "abstract": "Galois is in the business of building trustworthy software. Such software will have well-defined behavior, and that behavior is assured in some way, whether via model checking, testing, or formal verification. SMT solvers — extensions to SAT solvers with support for variables of non-boolean type — offer powerful automation for solving a variety of assurance problems in software. We use them, for example, in Cryptol, to prove the equivalence (or otherwise) of algorithm implementations. For a while now, Galois has been interested in connecting automated solvers to our programming language of choice, Haskell, to make it possible to prove automatically some properties of our functions (rather than just testing, e.g. with QuickCheck). We’ve pushed two efforts out this week, as previews of what we’re thinking in this space: SBV ; and yices-painless . Both are embedded DSLs for representing propositions to an SMT solver via Haskell functions and values. They take different approaches (a compiler from Haskell to the SMT-LIB format, versus an interpreter for the Yices SMT solver). SBV is the more mature package, while yices-painless emphasizes a type-preserving translation from a minimal core language. SBV was built by Levent Erkok , yices-painless by Don Stewart . Documentation for the design of yices-painless is available , as is documentation on SBV . Both are ready for experimentation and feedback, and we welcome your comments.", "date": "2011-01-18"},
{"website": "Galois", "title": "Copilot and the Arduino", "author": "Unknown", "link": "https://galois.com/blog/2010/12/copilot-and-the-arduino/", "abstract": "Copilot is an embedded domain-specific language designed by Galois, that allows you to generate assured, embedded C code from programs written essentially as Haskell lists (using Atom as a backend for the C code generation). Lee Pike has written a tutorial on how to use Copilot to program an Arduino controller to play “Jingle Bells”. Read the full tutorial on Lee’s Critical Systems Blog …", "date": "2010-12-20"},
{"website": "Galois", "title": "Concurrent Orchestration in Haskell", "author": "Unknown", "link": "https://galois.com/blog/2010/10/concurrent-orchestration-in-haskell/", "abstract": "John Launchbury presented the Orc language for concurrent scripting at the Haskell Workshop, 2010 in Baltimore. Concurrent Orchestration in Haskell John Launchbury Trevor Elliott The talk slides are available in PDF or online. We present a concurrent scripting language embedded in Haskell, emulating the functionality of the Orc orchestration language by providing many-valued (real) non-determinism in the context of concurrent effects. We provide many examples of its use, as well as a brief description of how we use the embedded Orc DSL in practice. We describe the abstraction layers of the implementation, and use the fact that we have a layered approach to establish and demonstrate algebraic properties satisﬁed by the combinators.", "date": "2010-10-01"},
{"website": "Galois", "title": "White Paper: High Assurance Software Development", "author": "Unknown", "link": "https://galois.com/blog/2010/08/white-paper-high-assurance-software-development/", "abstract": "Galois is pleased to announce a new white paper entitled High Assurance Software Development , written by David Burke , Joe Hurd and Aaron Tomb . The purpose of this paper is describe how to make software assurance a part of a science of security. Software assurance as practiced is a grab-bag of techniques, heuristics, and lessons learned from earlier failures. Given the importance of software to critical infrastructures (electricity, banking, medicine), this is an untenable situation; the smooth functioning of our society depends on this software, and we need a more rigorous foundation for assessments about the trustworthiness of these systems. In this paper we present an evidence-based approach to high assurance, in which diverse development teams can communicate in a common language to tackle the challenges of developing secure systems. Furthermore, this framework supports formal inference techniques (in particular, a trust relationship analysis ), so that we can use automated reasoning to deal with scalability issues. Perhaps most importantly, an evidence-based approach lets us tailor the tools that we bring to bear on each claim: formal methods: testing; configuration management; and so forth all have their place in an assurance argument. In the end, it’s all about deploying systems where the residual risk has been minimized, given finite resources and time. Understanding this and managing it effectively is what the science of security is all about.", "date": "2010-08-12"},
{"website": "Galois", "title": "Domain Specific Languages for Domain Specific Problems", "author": "Unknown", "link": "https://galois.com/blog/2009/10/domain-specific-languages-for-domain-specific-problems/", "abstract": "We have a new position paper on the use of EDSLs and Haskell for tackling the “programmability gap” of emerging high performance computing architectures — such as GPGPUs. It will be presented tomorrow at LACSS in Santa Fe. ( Download ) :: PDFSlides for the talk, including a 10 minute guide to EDSLs in Haskell, and a 10 minute guide to multicore programming in Haskell, can be found here :: PDF. Domain Specific Languages for Domain Specific Problems Don Stewart, Galois. Workshop on Non-Traditional Programming Models for High-Performance Computing , LACSS 2009. As the complexity of large-scale computing architecture increases, the effort needed to program these machines efficiently has grown dramatically. The challenge is how to bridge this “programmability gap”, making the hardware more accessible to domain experts. We argue for an approach based onexecutable embedded domain specific languages (EDSLs)—small languages with focused expressive power hosted directly in existing high-level programming languages such as Haskell. We provide examples of EDSLs in use in industry today, and describe the advantages EDSLs have over general purpose languages in productivity, performance, correctness and cost. Thanks to Magnus Carlsson, Dylan McNamee, Wouter Swiestra, Derek Elkins and Alex Mason for feedback on drafts.", "date": "2009-10-13"},
{"website": "Galois", "title": "Tech Talk: A Taste of DDT", "author": "Unknown", "link": "https://galois.com/blog/2009/06/tech-talk-a-taste-of-ddt/", "abstract": "The June 9th Galois Tech Talk will be delivered by Jim Grundy titled “A Taste of DDT.” Date: Tuesday, June 9th, 2009 Time: 10:30am – 12:00 noon Location: Galois, Inc.421 SW 6th Ave. Suite 300(3rd floor of the Commonwealth Building)Portland, OR 97204 Abstract : DDT is a partial implementation of the directed testing approach to test generation. The presentation will likely interest you if you are interested in how directed testing works, or what it is like to use in practice.This seminar presents a rational reconstruction of an experience of using DDT to test a rather rich FIFO/list module implemented in C. The module in question is about 1500 lines of code with a dozen or so entry points. The presentation walks through the user experience of writing and running a first naïve test harness for the module, finding and correcting issues in the code, up to a final declaration of victory.The presentation is rather long, about 1.5 hours, but takes the form of a gently paced walk through a user experience, and as such is rather less taxing on the concentration that you might expect for a talk of its duration. Bio : Jim Grundy is a research scientist with Intel Corporation.  His interests include functional programming, mechanized and interactive reasoning and their application to establishing the correctness of hardware and software systems. Galois has been holding weekly technical seminars for several years on topics from functional programming, formal methods, compiler and language design, to cryptography, and operating system construction, with talks by many figures from the programming language and formal methods communities. The talks are open and free. An RSVP is not required, but feel free to contact the organizer with questions and comments.", "date": "2009-06-01"},
{"website": "Galois", "title": "EDSLs for Unmanned Autonomous Verification and Validation", "author": "Unknown", "link": "https://galois.com/blog/2009/05/edsls-for-unmanned-autonomous-verification-and-validation/", "abstract": "We have a new position paper on the use of EDSLs (LwDSLs) for verification and validation of unmanned vehicle avionics, written jointly with John van Enk of DornerWorks , recently presented at a mixed-criticality architecture conference. ( Download ) :: PDF Lee Pike, Don Stewart, John Van EnkCPS Week 2009 Workshop on Mixed Criticality Roadmap to Evolving UAV Certification We outline a new approach to the verification and validation (V & V) of safety-critical avionics based on the use of executable lightweight domain specific languages – domain-specific languages hosted directly in an existing high-level programming language. We provide examples of LwDSLs used in industry today, and then we describe the advantages of LwDSLs in V & V. We argue the approach promises substantial automation and cost-reduction in V & V.", "date": "2009-05-15"},
{"website": "Galois", "title": "Portland Next Week: ICFP PC Functional Programming Workshop", "author": "Unknown", "link": "https://galois.com/blog/2009/04/portland-next-week-icfp-pc-functional-programming-workshop/", "abstract": "The ICFP 2009 PC team will be in Portland next week, and PSU is holding a free one day functional programming workshop to conincide with the meeting: the ICFP PC Functional Programming Workshop . The program has talks from leading researchers in language design and functional programming: Algebra of Programming using Dependent Types. Shin-Cheng Mu (Academia Sinica) Realizability Semantics of Parametric Polymorphism, General References, and Recursive Types. Lars Birkedal (IT University of Copenhagen) A Compiler on a Page. Kristoffer Rose (IBM Thomas J. Watson Research Center) A Proof Theory for Compilation. Atsushi Ohori (Tohoku University) Data Parallelism in Haskell. Manuel Chakravarty (University of New South Wales) Push-down control-flow analysis of higher-order programs. Matthew Might (University of Utah) Slicing It: indexed containers in Haskell. Conor McBride (University of Strathclyde) The event is on the PSU campus. See the workshop home for directions.See you there!", "date": "2009-04-23"},
{"website": "Galois", "title": "Tech Talk: Fun with Dependent Types", "author": "Unknown", "link": "https://galois.com/blog/2009/03/tech-talk-fun-with-dependent-types/", "abstract": "The March 24th Galois Tech Talk was delivered by Aaron Tomb , titled “Fun with Dependent Types.” Date: Tuesday, March 24, 2009 Time: 10:30am – 11:30am Location: Galois, Inc.421 SW 6th Ave. Suite 300(3rd floor of the Commonwealth Building)Portland, OR 97204 Here are Aaron’s slides . Further material on this topic can be found on Kenn Knowles’s site . Abstract : A number of dependently-typed programming languages exist, but many either restrict expressiveness or require extensive user input to deal with the undecidability of type checking. Languages such as Cayenne, lambda-H, and Sage have instead used a “best-effort” attempt to deal with this undecidability by attempting to type check programs, but potentially failing to prove valid programs type-correct.One powerful (and undecidable) form of dependent typing is based on what are variously known as contract types, refinement types, or predicate subtypes. The lambda-H language uses refinement types alone, and Sage includes them as part of a “pure” type system that uses the same syntax to describe both terms and types.An interesting recent result (by one of my friends from Santa Cruz) shows that while type checking for refinement types is undecidable, a form of type inference is decidable. It has the interesting property that if the input program is well-typed, then it has the inferred type. However, the algorithm does not determine whether the input program is, in fact, well-typed. Because it only decides one part of the type inference problem, the authors refer to it as “type reconstruction” instead.I will talk about refinement types, existing techniques for checking them, and the basics of decidable refinement type reconstruction. Galois has been holding weekly technical seminars for several years on topics from functional programming, formal methods, compiler and language design, to cryptography, and operating system construction, with talks by many figures from the programming language and formal methods communities. The talks are open and free. An RSVP is not required, but feel free to contact the organizer with questions and comments.", "date": "2009-03-17"},
{"website": "Galois", "title": "Rosetta feature in IEEE Computer", "author": "Unknown", "link": "https://galois.com/blog/2009/01/rosetta-feature-in-ieee-computer/", "abstract": "If you get IEEE Computer , check out the article on page 108 of the January, 2009 issue: Rosetta: Standardization at the System Level .  The author, Perry Alexander , is a professor at the University of Kansas.  Perry describes Rosetta , a language for designing and modeling systems.  The language is undergoing IEEE standardization , and there’s even a book describing the language.Perry collaborates with me and others at Galois, Inc. and has used Rosetta on one of our joint formal methods projects.", "date": "2009-01-22"},
{"website": "Galois", "title": "Formal Methods in Use at Galois", "author": "Unknown", "link": "https://galois.com/blog/2008/12/formal-methods-in-use-at-galois/", "abstract": "This summer I attended the International Joint Conference on Automated Reasoning (IJCAR 2008) in cold, cold Sydney, to give a tutorial on Formal Methods in Use at Galois . The overview slides of the tutorial are available for download , for people interested in seeing some industrial applications of formal methods. Incidentally, while I was at the conference, I entered the automatic theorem prover competition with my ML prover Metis , and finished respectably mid-table .", "date": "2008-12-11"},
{"website": "Galois", "title": "Beautiful Parallelism: Harnessing Multicores with Haskell", "author": "Unknown", "link": "https://galois.com/blog/2008/11/beautiful-parallelism-harnessing-multicores-with-haskell/", "abstract": "Don will be giving a talk SC’08 in Austin, Texas on Monday 17th November, as part of the Bridging Multicore’s Programmability Gap workshop (see the schedule here ), talking about programming mainstream multicore systems with Haskell, now. Here’s the abstract, Haskell is a general purpose, purely functional programming language. If you want to program a parallel machine, a purely functional language such as Haskell is a good choice: purity ensures the language is by-default safe for parallel execution, (whilst traditional imperative languages are by-default unsafe).This foundation has enabled Haskell to become something of a melting pot for high level approaches to concurrent and parallel programming, all available with an industrial strength compiler and language toolchain, available now for mainstream multicore programming.In this talk I will introduce the features Haskell provides for writing high level parallel and concurrent programs. In particular we’ll focus on lightweight semi-explicit parallelism using annotations to express parallelism opportunities. We’ll then describe mechanisms for explicitly parallel programs focusing on software transactional memory (STM) for shared memory communication. Finally, we’ll look at how Haskell’s nested data parallelism allows programmers to use rich data types in data parallel programs which are automatically transformed into flat data parallel versions for efficient execution on multi-core processors. See Simon Peyton-Jones and Satnam Singh’s recent tutorial for more background on multicore Haskell, on which this talk is based.", "date": "2008-11-13"}
]