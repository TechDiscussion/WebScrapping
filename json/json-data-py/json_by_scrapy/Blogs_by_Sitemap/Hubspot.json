[
{"website": "Hubspot", "title": "What Does a Product Designer Do at HubSpot?", "author": ["Tim Merrill"], "link": "https://product.hubspot.com/blog/what-does-a-product-designer-do-at-hubspot", "abstract": "Product designers design how HubSpot works. We collaborate with our teams to produce an interactive experience that solves the needs of the customer and the business. Our role is more architect than interior decorator – meaning we spend more time thinking about how customers will use the product than making it visually attractive (although this is also important). By spending time defining the problem and understanding our users, we're able to conceptualize solutions that get at the heart of the challenges our users face and the progress they are trying to make. And by leveraging expertise in human factors, behavioral psychology, and visual design, we're able to create an experience that is highly usable, effective, efficient, and delightful. The Eye in “Team” The team is everything in HubSpot’s product organization, and product designers are but one member of a triumvirate. We work tightly with product managers (PMs) and engineers, each with our own area of responsibility and core skill set. We aren’t lone wolves, disappearing into the night and returning with a fresh design in our maws. We often say “the PM owns the problem, and the PD + TL (tech lead) own the two sides of the solution” (i.e., the visual interface and the technical execution). That’s because it’s important to have someone act as a key decision maker for each side of the equation. It doesn’t mean everyone works independently though – quite the opposite. It means the PM uses her unique expertise and understanding of business and customer goals to present a challenge to the team that is aligned with the team’s mission. The team then works together to further define the problem and brainstorm potential solutions. Working in this way, the entire team shares a sense of understanding and ownership throughout the lifecycle of the project. Keep It Lean Once we have an initial sense of the challenge and a few ideas about how to solve it, we work quickly to create an artifact to test out the team’s ideas. The UX research team helps us get it in front of actual customers and gather greater insight into 1) how they think about the problem, and 2) whether our ideas are on the right track to solve them. This artifact could be a survey, hand-drawn sketches, a wireframe, or a prototype (mockups linked together to simulate an experience, sometimes with animation/transitions). The key is that this process will quickly move our confidence level in any given solution forward, or invalidate our ideas. This methodology is called “ Lean UX ” (which is based on Lean Startup , which is based on Toyota’s lean production ), and it involves rapid cycles of trying to understand, create, evaluate as follows: Understand the problem Brainstorm and quickly create something we can test as a potential solution Evaluate our hypothesis by putting it in front of actual customers I can’t stress enough the (literally financial) value of invalidating a big idea. At many companies, when a business stakeholder has an idea, they design it down to perfect pixels, spend months developing it, and launch it without a shred of proof that it will be a success. All too often, the idea flops as soon as real customers get a hold of it. If you can confidently invalidate an idea early, you’ll save many thousands of dollars and a lot of heartache. The Design Process As we move from problem to solution and increase in visual fidelity, we go through these high level phases: Problem Definition Einstein is quoted as having said something like, “If given an hour to solve a problem, I’d spend 55 minutes understanding the problem and 5 minutes on the solution.” As designers, it’s crucial that we spend time truly understanding (or identifying assumptions about) the customer’s goals, motivations, anxieties, context, and struggle. It’s also important that we understand the product’s lifecycle stage, and the business drivers behind the decision to tackle this challenge. Are we trying to improve retention? Activation? The knowledge shared in the Problem Definition phase directly informs the solution. Discovery We may need to dive in deeper before we’re ready to generate a solution. Surveys, analytics data, competitive analysis, and customer interviews can help fill the gaps in understanding. Ideation Now that we’ve dug into the problem, it’s time to generate ideas. There are several great methods for this, including Scenario Mapping, and lateral thinking techniques. Doing these exercises as a team increases diversity of ideas, and a great feeling of ownership in the process. At this step, you want folks inspired to imagine solutions that are elegant and powerful, taking advantage of everything the system may know about a user and their context, available datasets, the latest technology, machine learning, etc. Now is the time to dream big and save the feasibility discussions for later. After you have a pile of great ideas, then a team can work to prioritize them. We often use a matrix of effort (or risk) vs. impact, and test the riskiest assumptions first. Information Architecture A key first step in designing a solution is nailing the organization and flow necessary to facilitate the desired outcome. So many experiences fail simply because the designer didn’t spend time considering a user’s mental model (their understanding and conceptualization of how something works and fits together as part of a larger organizational structure, and the words and concepts they’d use to describe it). The artifacts from this stage may take the form of a flow diagram, a copy inventory, or a complex site map. Interaction Design Now that we have a sense of the high level organization, we can think about individual screens and the elements that comprise them. What information does a user need to make progress towards their goal? Which components will best facilitate the manipulation of the information on the screen? What’s necessary, and what can we strip away to increase clarity and focus? What copy and visual signifiers will best increase comprehension? What are the various states and use cases we should accommodate? This all comes together in a wireframe, mockup, or prototype. Visual Design Sometimes we’re able to combine this step with the last, especially when we have a comprehensive, up-to-date visual language and component library, which allows us to create high fidelity mockups much faster. We bring our wireframe to life with color, fonts, truer spacing and alignment, illustrations, and other visual elements. Key considerations in this phase include brand alignment, visual hierarchy, and refining the tone of the copy. QA As we move through the process, we’re ideally working hand in hand with our developers and copywriters, who are building out and refining the parts of the experience in which we have a high degree of confidence. As the design is translated to code, it’s important to get a quick gut check that everything looks as intended. At HubSpot, we’re comfortable releasing design to customers that may need a few tweaks here and there. Our process encourages us to refine after release. The real goal is getting things in front of customers for validation as quickly as possible. How is Product Design Different at HubSpot? We're Decentralized At many companies, designers are centralized, meaning they sit together as a team and are \"contracted\" out to work for other teams and stakeholders. At HubSpot, designers are embedded on small product teams, alongside a PM and several engineers. This makes collaboration quick and easy, and reduces the need for documentation. It also increases the feeling that we’re all part of a team, rather than the “us vs them” mentality of yore. We're Cross-functional At many companies, designers are specialized. They are often divided into UX designers and visual designers. Here, our PDs are cross-functional. They manage the design process on their team all the way from problem definition to polished pixel. Often they have deep knowledge or skills in a particular area, but are still able to go wide (the famous T-shaped employee ). This requires a diverse set of design skills and experience, and the ability to work with a high degree of autonomy. It’s facilitated by our “living” UI Library and results in a faster, more efficient process with fewer handoffs. Traits and Skills of a Successful HubSpot Product Designer Empathy We need to be able to put ourselves in our customer's shoes and consider their anxieties, motivations, and context. Humility Hubris limits learning, and in an environment where we need to rapidly make and test assumptions, we need to be comfortable with being wrong. Like, often . We need to be open to input from diverse stakeholders, team members, and other designers, in the spirit of getting to the best possible solution. Curiosity and Analytical Ability Designers need to be inherently curious about how humans think, behave and interact with technology. And synthesizing this understanding of human cognition and behavior, our software and personas, research data, the domains of SMB marketing and sales into a smart solution requires clear thinking and the ability to reduce complexity down to essential components. It also requires a healthy dose of skepticism, without a trace of cynicism. Creativity, Vision, and Divergent Thinking Design is imagining a better future. So it’s important for designers to think boldly and escape the confines of what’s been done before. Practicing divergent thinking (generating many possible solutions and avoiding getting attached to the idea of one “perfect” solution) is one way we stay open to diverse possibilities. Drive and Grit There are always constraints and tradeoffs. That’s why an essential skill for designers at HubSpot is working with engineers to find ways to bring ideas to life. It’s one thing to lounge around on a beanbag chair dreaming, but another thing entirely to collaborate with others to Get Shit Done. Communication and Collaboration PDs are in constant communication with their teams: working with PMs and TLs to understand the problem, sharing early ideas and sketches, working with researchers to analyze the results of a test, discussing functionality with engineers, collaborating on copy with our copywriter, and reviewing UI that has been coded. It’s essential for designers to actively listen, and articulate ideas crisply. Results Oriented PDs strive to have true impact on the success of our customers. That’s why it’s important to define success and establish appropriate measurements of the effectiveness of the solutions we design. Committed to Craftsmanship Designers at HubSpot care deeply about the quality of the interactive experience. This means sweating the details, sanding the edges, and making time to polish. This isn’t vanity or OCD – every detail adds up to a cumulative perception of quality by customers. Strong Visual Design Skills The ability to use classic design elements such as composition, visual hierarchy, balance, typography to direct the eye, establish importance, tone and meaning. Human Factors and Behavioral Psychology An understanding of how humans think, behave, and interact with systems. These fields of study have yielded many useful heuristics for designing experiences that help people find the information they’re looking for, make better decisions, and persuade them to take action. Staying Sharp In a field that changes rapidly, we have a number of practices that help us continue to grow and improve. (Interestingly, we've found that this culture of learning is one of the top reasons design candidates cite as the reason they'd like to join us.) Here's our secret: Design Review every Tuesday #design-feedback on Slack Study Hall (every day in the lounge there's time blocked off to work together) Wake.io : a stream of our latest mockups Individual mentorship Events & Conferences Free book program and a UX library Subscriptions to online training How does product design work at your company? Let us know in the comments.", "date": "2016-07-20"},
{"website": "Hubspot", "title": "Rethinking HubSpot's Record Design With Usability in Mind", "author": ["Julia Gron (She/Her)"], "link": "https://product.hubspot.com/blog/rethinking-hubspots-record-design-with-usability-in-mind", "abstract": "One of HubSpot’s core values is usability, of which visual design is a key component. Some of the visual design patterns we use include exposing and grouping information, allowing plenty of whitespace to separate distinct sections of data, and using indicators like icons to assist with scannability and information recognition. However visually pleasing these patterns may be, though, they are only truly successful when they help meet users’ needs. On the CRM record, we found that by overusing patterns like these we were actually perpetuating significantly slower workflows for sales and support reps who rely on speed in order to meet their competitive performance metrics. Sales reps are evaluated by number of deals closed, the amounts of deals closed, and engagement activity. Support reps, on the other hand, are rated by average response times and tickets closed, in addition to CSAT (customer satisfaction score) and NPS (net promoter score). Rushing through their tasks can lead to sloppy interactions, missed deals, and low customer satisfaction. If these reps don’t meet their goal metrics, they’re passed up for rewards, bonuses, and promotions ⁠— or, in some cases, they could even lose their jobs. In order to provide them with a successful interface, we knew we needed to respect the time they spend on our platform and give them more control of their focus. As a result, we’ve redesigned and re-organized almost every section of the record page to favor data density in an effort to let them get their jobs done, faster than ever. The Before To begin this work, we had to take stock of our current state. In addition to more obvious data density concerns regarding whitespace and unnecessarily exposed information, we found some significant pattern discrepancies. We ran an audit of almost 40 activity types available on our record timelines ⁠— here’s what we found: Several different presentations of people involved in the activities Links with the same treatment leading externally, to panels on the page, or internally within HubSpot Varying levels of information indiscriminately shown or obscured Timestamps stored and rendered in several different ways Twenty-three unique icons among our various activity types, and several activity types represented by the same generic placeholder icon Taking a closer look at the purpose of icons, we thought a bit more about the role a more niche icon ⁠— for example, a scroll representing our Quotes activity ⁠— plays in terms of quick recognition. If icons aren’t easily identifiable, they begin to act solely as decoration and have little functional purpose. On a page meant to help users move through many varied data sources and take quick actions, these decorations easily add up and contribute to noise. Additionally, we found some fundamental issues regarding the lack of responsiveness and low level of functionality that we were providing to our users with smaller screens. This problem was exacerbated by the 11% decline in users using desktops or larger window sizes from November 2019 to June 2020, presumably due to the widespread work-from-home catalyzed by COVID-19 shutdowns. Standard laptop customers could only see an average of 1-3 activities on our timeline at once, and limited information on the page’s sidebars: Presenting only small pieces of information at a time, including some redundant details, requires reps to spend inordinate amounts of time scrolling and processing unnecessary data. For example, it took users a median of almost eight minutes to respond to a call or email after opening a record. And for our customers, time is everything. We knew we had to simplify, reduce clutter, and reduce whitespace to speed up our reps’ workflows and let them see more at once. The After Our main strategy with this redesign was to give users more agency over where they put their focus through a simpler, more scannable presentation of data with less noise. We started with our timeline. We simplified and gave each activity an easily scannable collapsed state, so that reps could survey across many data points at once and decide where to spend their time. Less time spent digging, more time spent doing. Showing activities in their collapsed state means that customers get a dramatic increase in visible activities,  especially those working on small screens. If users need more information to complete whichever task they’re working through, they can expand their chosen activity on an individual basis or expand all activities at once with a single click. To give users a more direct way of finding something specific, we moved search into an open input field and brought it up to the top left of the timeline. With these changes, we’re giving users more efficient ways to both scan for general understanding and to hunt down an exact match of what they need to reference. In hiding the majority of activities’ body content and removing activity icons, we cleared out many differing components, controls, and uses of color from the timeline’s initial presentation so that users can keep their focus on the task at hand. Additionally, fewer uses of color on the record means that shown alerts or visual status indicators are more recognizable and hold more weight. For example, overdue task check marks are now encircled with red in their compact state and brought up to the top of the timeline in our ‘Upcoming’ section. For sales users who run their workflows based on task queues, this makes it much easier for them to recognize urgent items and prioritize their time accordingly. Less time spent digging, more time spent doing On the record sidebars, we found that no more than 4% of users were initiating calls or emails from association card links, so we lowered the visual prominence around that action and added quick-copy buttons to let users easily grab and utilize their contacts’ information to use in other tools. Only 2% of users were regularly expanding or collapsing the right sidebar, so we removed that functionality and gained back vertical real estate – in addition to significantly speeding up page load time. In our right sidebar association cards, we took the same action as in the timeline to take away icons to reduce noise and made further efforts to enforce consistent patterns in regard to the amount of data presented and the components used to do so. As part of these changes, we also removed a lot of white space. We took it from the margins within and between our timeline activities and association cards. We reformatted our profile highlight cards to be left- rather than center-aligned, and saved a lot of white space there as well. We enforced consistent font sizes and weights, and in doing so also saved substantial line height. In hiding unnecessary information, enforcing consistencies, and removing redundancies, we not only made it easier for reps to scan and action on data on the record, but also decreased load time on the page, adding up to a noticeably faster experience across the board. Interested in working with a team that's just as interested in how you work as what you're working on? Check out our open positions and apply .", "date": "2021-04-21"},
{"website": "Hubspot", "title": "Kafka at HubSpot: Critical Consumer Metrics", "author": ["Ze'ev Klapow"], "link": "https://product.hubspot.com/blog/kafka-at-hubspot-part-1-critical-consumer-metrics", "abstract": "Apache Kafka is an integral part of our infrastructure at HubSpot. We often have long pipelines of workers that consume from and publish to Kafka topics. A great example of this is our Sidekick product which delivers real-time notifications to users when a recipient opens their email. Much of the infrastructure for creating and delivering these notifications is built on top of Kafka. The Sidekick notification pipeline looks roughly like this: Having many Kafka consumers chained together like this raises some important questions: How do we monitor performance of each consumer, and for the system as a whole? How can we tell if our consumers are healthy, and if they aren’t, how can we quickly track down issues in the system? I’ve found two metrics that are crucial to answering these questions. Delta We have a concept at HubSpot called “delta” which we use to determine if a consumer is keeping up with data on the topic. So what is delta? In Kafka, each message is sent to a partition on the topic. Messages on a partition are given increasing offset numbers as they are written. As a consumer consumes data it tracks the offset of the last message it has consumed. Delta is the difference between the consumer’s checked in offset, and head (latest offset) of the partition: Simply put, this number represents how far behind a consumer is. For every Kafka consumer, we track two different delta numbers: max delta and total delta. Max delta represents the single highest delta for any partition, and total delta is the sum of the deltas for each partition. What is each good for? Total Delta Total delta tells you a lot about your consumer group as a whole. If your total delta is continually increasing, then your consumer isn’t keeping up with traffic on the topic. It’s either too slow or the volume of data is too large. In the example above, by far the slowest worker is the “Activity Writer”, it handles writing all of our Sidekick activities to HBase, so when we have issues with HBase, processing slows for all workers in a group, the total delta increases, and our monitoring system generates an alert. If you are having total delta problems, think about scaling up your consumer, or parallelizing it to get higher throughput. Max Delta Max delta is slightly harder to interpret, but generally points to a more contained issue with a single worker or partition in the consumer group.  If max delta is increasing, you may have a problem in just one worker, or you may have unbalanced partitions causing one worker to receive too much data. Lag In addition to delta we have a concept called “lag” which helps us monitor delay in our systems when processing messages. Lag monitoring is slightly more complex (and much more application specific) than delta monitoring. A quick Google search defines lag as: \"a period of time between one event or phenomenon and another.\" The events you want to measure lag between is very much up to you. In the Sidekick example above, we monitor a few different kinds of lag by storing timestamps on all of our messages. We monitor total lag, which is the time between when an event was created and when the notification is sent. Total lag helps us monitor the whole pipeline: (Note: These numbers are made up for the purpose of this example.) But we may also want to monitor lag for just one consumer, in this case we attach a “processed” timestamp to our messages to get a result more like this: Total lag tends to be a more useful metric for alerting on, and monitoring, while more granular processing lag is helpful for debugging purposes when your total lag starts going off the chart. Lag is very personal because you have to figure out what numbers are important for you and your system. If it isn’t time-sensitive you may decide to not alert on lag at all. The One-Two Punch Neither delta nor lag alone can provide a complete picture of the health of your system. However, combined lag and delta make a really powerful tool for debugging complex Kafka set ups. When something goes wrong with a consumer, the first thing I do is refer to is this beautiful chart: This framework is very useful for pointing you in the right direction when debugging issues. When the total lag for Sidekick notifications is spiking and you are being woken up to fix it, being able to quickly eliminate possible causes can be hugely helpful. Trust me, I know. Systems like this can get complex and hard to debug quickly, and it’s important that we have the knowledge and tools to help us understand them. Monitoring delta and lag (and you already have a monitoring system, right?) are simple ways to be confident that your application is reliable and performant, and help you fix issues when it isn’t. If you are interested in Kafka or real-time data processing in general, stay tuned by subscribing to the blog as we'll be taking a deeper dive into our Kafka infrastructure in future posts. If you're local to Boston, make sure to sign up for The Data Metamorphosis: Boston Kafka Night here at HubSpot on Monday Oct. 5th, 2015.", "date": "2015-10-02"},
{"website": "Hubspot", "title": "Making Leaked Credentials Useless for Attackers", "author": ["Steven Brzozowski (He/Him)"], "link": "https://product.hubspot.com/blog/making-leaked-credentials-useless-for-attackers", "abstract": "How to safely prevent your AWS users from making calls outside of your ecosystem. Building a secure environment revolves around making incremental improvements targeted to thwart specific types of threats. A common way in which an intruder can infiltrate your network is through obtaining credentials which grant access to a restricted system. Credentials can leak in a myriad of ways, from developers accidentally committing them to source control, to services logging them in a widely accessible location, to users leaving them unencrypted on a compromised host. They could even leak through being sent over a channel incorrectly assumed to be secure. Fortunately, there are several ways to combat these sorts of mistakes. The most common of these attempt to limit the window in which a leaked credential could be used by an attacker, either through frequently rotating credentials or by regularly scanning through source code and logs. But what if you could make the credentials effectively worthless outside of the environment in which you expect them to be used? And arguably more importantly, how can you enable such a restriction without causing pain to existing automation and users who may use their credentials in ways you hadn’t anticipated? This guide will dive into some technical examples, so with that, we expect it to provide the most value to system administrators looking to improve their security posture. Before we begin: Preparing your systems Before starting this IAM credential lockdown, you'll need to setup the following: All AWS resources must be running inside of one or more VPCs ( Virtual Private Clouds ) VPC endpoints must be accessible to every host on which your services are running. Here are details on configuring them . A CloudTrail Trail needs to be enabled for all API activity on your account Already, we’ve thrown around quite a few AWS service names. This overall strategy can be adapted to work on other popular cloud providers like Google Cloud Platform or Microsoft Azure. Some service name mappings can be found in the table below: Amazon Web Services (AWS) Google Cloud Platform (GCP) Microsoft Azure Virtual Private Cloud Virtual Private Cloud Azure Virtual Network CloudTrail Cloud Audit Logs Azure Audit Logs Athena BigQuery Azure Synapse Analytics Identity and Access Management (IAM) Identity and Access Management Azure Identity Management Simple Storage Service (S3) Cloud Storage Azure Storage With the above satisfied, the level of effectiveness and success of this strategy will depend on the percentage of IAM users calling out resources in the same region as the request’s origin. We’ll dive more into that limitation later. Building the policy AWS allows access control to be configured through policies attached to the user making a request or through policies attached to the target resource directly. In this case, it makes the most sense to apply this restriction via a policy assigned to IAM users given that if you limit power at the source, you don’t have to worry about limiting it at every destination. Say you’re in a scenario where you have a user with the S3 buckets they have permission to manage defined through a regex. In this case, it’s much easier to apply this restriction to the user itself than to apply the same restriction on every current and future bucket matching that regex. We’ll dive right in by introducing the most basic version of the policy we wish to enforce, then gradually add elements as we try to account for more cases. The primary function of this policy is to deny all requests not originating from a trusted VPC. On line 11, we take advantage of the aws:sourceVpc metadata AWS passes along with requests made through a VPC endpoint. The second condition beginning on line 17 allows us to quickly and easily maintain an allowlist of users who are exempt from this policy. We simply check for the presence of a boolean tag on the caller, and if not present or explicitly set to false, we enforce the first condition as usual. 1 So now we’re ready to apply this policy to every user in our account right? Not quite. Obtaining and assessing usage patterns of your IAM users Before enforcing this rule on a given IAM user, you first want to be confident that you are not going to block an existing workflow and suddenly cause their requests to return 403s. Here’s where having a CloudTrail configured to record AWS API activity comes in handy. To recap, CloudTrail is AWS’s audit logging service that pipes logs into S3. Athena provides a way to make queries against S3 buckets. Together, they provide a powerful way to increase visibility into the events that take place in your account. More details, including how to partition CloudTrail logs for performance and scalability can be found in these AWS docs . Using Athena to query CloudTrail’s dataset, we can determine with a level of confidence whether a given user is likely to be making its requests exclusively through a set of VPCs. If that is the case, they are a good candidate for the policy defined above. Querying Athena The table name can vary based on your CloudTrail and Athena configuration, as I mentioned earlier, but the basic idea is to query Athena for the specific fields needed to fully understand how users are calling out to AWS services: We created an automated job to run these queries hourly against the previous hours' data, and store the results in a database. This gave us the ability to quickly answer questions like: Does user x exclusively make calls through VPC endpoints? When was the last time user x made a call from outside of our tracked VPCs? If user y is making calls from outside our tracked VPCs, which IP addresses or VPC endpoints are the requests originating from? Current limitations of CloudTrail At the time of this writing, CloudTrail only logs control plane calls for most services. This means that, with some exceptions like S3 for which CloudTrail logs both data and control plane actions, only a subset of calls to all other AWS services will be logged. Details on what events CloudTrail records can be found in the official documentation . In practice, this does not pose a real concern to our approach, given that if a user makes a control plane request to service A through a VPC endpoint, and their request is logged via CloudTrail, all data plane requests from the same user and client configuration can be expected to go through that same VPC endpoint for service A. Safely locking down users As data accumulates using the process highlighted above, the confidence in gauging how a user generally behaves will also increase. After defining a threshold at which to lock down a user, applying the policy is as easy as: Attaching the policy to an IAM group In batches, adding users as members to the group once deemed safe It’s essential to roll the first few users into small batches with extensive monitoring before ramping up the lockdown rate. Digging into special cases What would an engineering blog post be without highlighting some edge cases we came across? No doubt every organization will use different sets of AWS services in slightly different ways, but the following were some of the use cases we considered. Adding an additional dimension: Trusting VPCs across your organization’s AWS accounts and regions There are use cases in which you may want to allow IAM users belonging to one account to be used from within another. The VPC metadata passed with each request (i.e. aws:sourceVpc ), with which the policy constructed above is concerned, is passed along in calls made from VPC endpoints within the same region as the target resource. In practice, it appears AWS even passes along aws:sourceVpc for calls made from one account to another, as long as they are owned by the same underlying organization and the calls are made within a single region. Due to the number of differences in how organizations manage their AWS accounts, we decided to omit solving for cross-region calls in this guide. Considering local development? Developers often need to be able to run code locally that makes calls out to their AWS account. Unless they are doing so from an SSH session in an EC2 instance placed within one of their VPCs, they will be blocked by our policy in its current form. The simplest way we found to solve this was to direct our locally running AWS clients to route their requests through a proxy we created within our VPC. Properly restricting access to this proxy is essential to not introducing an unintended backdoor through this policy. Making S3 objects publicly accessible It may be desirable in some cases to allow public access to S3 objects directly. This can be accomplished through the use of presigned URLs . The current policy just needs a tweak to account for this specific type of request: Here, we want to have different logic depending on whether the user is calling s3:getObject using presigned URL auth or not. To break down how we did this, we split our policy into these two cases ⁠— the first of which (on line 8) denies all actions except s3:GetObject , and the second (line 26) denies s3:getObject exclusively. Besides the substitution of NotAction for Action , the second statement looks for a third condition to avoid getting denied for s3:getObject calls ⁠— that is, the s3:authtype of the request being REST-QUERY-STRING which evaluates to true for presigned URL authed calls. Proxying API calls through other AWS services Through experimenting with the above policies, we found that some Athena calls were still being denied despite having a properly configured Athena VPC endpoint in the region. Upon inspecting the metadata of these requests in CloudTrail, we found that they were actually being proxied through the public Athena AWS endpoint. Simply adding the additional condition on line 9 below allowed us to avoid hitting the deny condition on calls made on behalf of Athena. Alternatively, you may want to use the key aws:ViaAWSService with a value of true to generalize this rule to allow any calls made on behalf of another AWS service. Conclusion: Continuing to add layers of security These safeguards alone will not magically solve all of the threats that can arise from leaked credentials. They instead act as another step that when taken, minimizes the risk credentials pose when they fall into the wrong hands. Going beyond the strategies already discussed, it’s equally important to consider how one can limit the options for attackers inside of a set of VPCs. This policy, for example, would not block an attacker from executing calls from a compromised host with unencrypted credentials, so practicing least-privilege on your IAM users can limit the potential impact of a compromised user. One should also consider whether hosts within a VPC all need access to the public internet given that if an attacker is able to break in and access sensitive data, preventing them from exfiltrating it could make a significant difference in the severity of the impact. While it may seem daunting to consider every vector of attack, it’s important to remember how security is a layered objective where every level built upon the next has a meaningful impact on protecting your customers and their data. Figures/References Figure 1: How several conditions and/or condition keys are evaluated. Source: the official AWS IAM policy documentation. 1 As a recap of IAM policy evaluation, when multiple keys are specified under one condition, they are evaluated with logical OR , so in this case, both conditions must evaluate to false for this policy to deny the request. For more details, see Figure 1 at the end of this post, or refer to the official IAM policy documentation . Want to work on a team that's just as invested in how you work as what you're working on? Check out our open positions and apply .", "date": "2021-05-25"},
{"website": "Hubspot", "title": "How Medium is Engineering Holacracy [Q&A with Daniel Pupius]", "author": ["Eric Richard (He/Him)"], "link": "https://product.hubspot.com/blog/qa-with-medium-engineering-daniel-pupius", "abstract": "The only thing as important as building product, in the engineering world, is building product culture. Structuring a team, figuring out the right development process, and scaling that processes is a science. A hard science. I’m always curious to learn how other engineering organizations operate for this reason. Especially when that organization is building the world’s favorite publishing platform: Medium . The company is pioneering a relatively new type of management system called Holacracy. Medium’s Head of Engineering, Daniel Pupius, wrote an interesting post about how they’ve designed a holacratic organization and how it's providing them with a new kind of manager. He wrote that a “common misconception about Holacracy is that it’s a flat organization structure” when in practice, their organization is built around a hierarchy of circles and roles. I had the opportunity to ask Dan the questions below about what this structure means for their engineers and how it shapes their product culture, team, and development process. How does Medium's engineering team prioritize what to build next, and how do they decide when it's good enough to ship? (Does the circle lead decide? Is it A/B tested?) At various stages in the product’s evolution we’ve operated differently, but in all cases the teams are mission-driven. Sometimes the missions are tightly scoped (“improve the on-boarding experience”) while at other times they are more open ended (“connect people with the content that matters to them”). The teams are cross-functional circles, and as a circle they are responsible for deciding how to fulfill their mission most effectively. We don’t have specific criteria on when something is “good enough to ship.\" It’s a conversation between product, design, and eng on the given team, but we strongly favor iterative, visible progress over large launches. We do A|B test a lot of changes, but we’re not beholden to the results. As an example, we ran a test for a change to the Recommend button that drastically increased the click-rate. It was a controversial change, but after lively debate we ultimately decided it didn’t feel right and concluded that the increased click-rate corresponded to a devaluing of the Recommend signal. As products mature, there’s a shift from the exciting projects to a need to drive more of the “less interesting stuff.\" How do you ensure you have equally motivated and passionate developers working in those areas? In terms of product there will be new and exciting things to work on for a long time to come; ideally forever. We should always be pushing the product forward, innovating in service of our mission. Even so, as you grow you inevitably start dealing with scaling concerns, spam, technical debt, and things like improving the build system to handle more developers. While I think these are still interesting challenges, you need to make sure projects are tied back to company priorities. If you understand the importance and impact of your work, it’s much easier to stay motivated, even if it might be unglamorous. We do want to avoid the same people tackling these types of issues over and over again. So we make sure that the team structure is dynamic and flexible, making it very easy for people to move around. How does recruiting and hiring work with Holacracy? Is it the responsibility of the circles to grow their own teams or is that a function of some centralized group? Ultimately it is the responsibility of the circle to fill roles and take care of the people within the circle. In Engineering we developed a system for professional development and mentorship, and we’ll continue to iterate and evolve as we grow. We do have central functions though, the best way to think of it is a series of circles that act as service organizations: for example, Talent Acquisition does sourcing and recruiting, and People Ops develop tools and processes that circles can adopt. One of Medium’s key tenants is “Make everything explicit — from vacation policies to decision makers in each area.” In contrast, HubSpot has one key policy: Use Good Judgement (which then translates into an Unlimited Vacation Policy.) How do you think about having explicit policies vs. giving individuals autonomy to figure out how to apply very broad rules? The problem with implicit systems is that organizational lore builds-up, which is hard for new people to learn and becomes open to interpretation. This unwritten lore includes implicit authority that may then reside in the person who’s been there longest, the person who is loudest, or the person who is most opinionated. And over time you are susceptible to unintentional shifts in culture. So I favor explicitness. The explicit nature of Holacracy’s policies and roles aren’t in contrast to autonomy; in fact the whole system is designed to create distributed authority and autonomy. Explicit roles have a number of benefits. Let’s take a recent role created for Email Delivery as an example. That role now makes it clear who on-call should talk to about a DKIM issue, who Legal should talk to about email policy, and who has the final call on selecting a mail provider (MessageBus is shutting down). The role makes it clear what is expected of you, so you can easily know whether you’re doing a good job. And the role empowers you to make decisions without approval or consensus. This allows us to give degrees of authority to people early-on in their careers because organizational guard-rails exist. Having explicit roles also makes it easier to identify where your time is going and what to prioritize. In terms of policies, they shouldn’t constrain, they should liberate. Explicit policies reduce anxiety because people don’t have to stress over what “good judgement” means; they let you know the rules of the road, so you can operate autonomously within a safe framework. A policy might say you can deploy code whenever you want during the week, but if it’s the weekend you should get approval from on-call first. For what it’s worth, we also have an Unlimited Vacation Policy, the policy says to take what you need but to check-in with your Lead Links first, and encourages 2–4 weeks spread over the year — we often have to encourage people to take time off. How do your engineering teams create safe space to innovate and try new things without having to explain themselves to the whole organization? Experimentation and failure should be baked into the culture. If you never fail you’re not trying hard enough; you’re not being bold enough. We should celebrate failures as much as successes. No one will criticize you for a reasonable hypothesis failing, but you might get criticized for not trying. Holacracy also helps. One of the core philosophies is that you are the arbiter of your own time. So as long as you are fulfilling the accountabilities of your various roles, there is nothing to constrain what else you do; no permission you need to seek (domains notwithstanding, which are like property rights, but that’s probably another interview.) I want to thank Dan for talking to us about Medium's engineering culture and sharing an inside look at Holacracy. Be sure to follow Dan on Medium here .", "date": "2015-07-13"},
{"website": "Hubspot", "title": "Building Products Across Multiple Teams", "author": ["Ethan Kopit (He/Him) and Dylan Sellberg (He/Him)"], "link": "https://product.hubspot.com/blog/building-products-across-multiple-teams", "abstract": "Unless you work on a very small Product team — anything less than 10 people — you’ve experienced the need for cross-team collaboration. Here at HubSpot, our Product team is growing rapidly. This growth provides an immeasurable amount of benefits, but as these hundreds of small autonomous teams (2-10 people) build software, a challenge is introduced: how can we collaborate effectively across teams? This post is designed to present a simple framework to help people work better together. By implementing some of the tactics mentioned here and keeping an eye on cross-team collaboration, we believe that organizations can be more effective. First, let’s talk about single-team projects and what makes them relatively simple. In single team projects, there is one owner, the team is familiar with one another, priorities are clear, and projects are relatively easy to technically scope. Single-team projects are almost “automatic” to well-functioning product teams and are some of the simplest to execute on. As an organization’s product grows, though, the balance starts to shift from mostly single-team projects to almost exclusively cross-team projects. Teams become more interconnected and depend on one another to succeed. As the HubSpot Product team has grown, this has certainly been the case. What makes cross-team projects challenging are, not coincidentally, the same things that make single-team projects simple. Teams have less rapport with one another than they do within their own team, which can cause a lack of trust and overall effectiveness. Multiple owners are introduced, each with unique expectations of how they want the project to succeed. Finally, priorities outside of the cross-team project can be unclear. We’ve found that in order to make a cross-team project successful, you need: Basic trust between the teams involved Clearly articulated project management roles Clearly articulated priorities and timeline upfront for all parties involved Download: Cross-Team Alignment Kickoff One-Pager Earning trust More than anything, trust is the foundation of the kind of partnerships that are required for cross-team collaboration. Each participating team needs to believe that the others are approaching the project with goodwill and a shared understanding of how success benefits the customer. However, many people misunderstand trust. Here’s what we’ve realized when it comes to building trust across teams: Confrontation is good! It’s better to understand a mismatch in urgency (for example) upfront and use prioritization tools or a creative engineering solution to resolve it, rather than stumbling upon it when both participants have different expectations. In order to earn this trust early, it’s important that both teams are asking the hard questions, diving headfirst into potential areas of conflict, and even mapping out how and where the project has the potential to fail. Come prepared. As best you can, answer pre-meeting questions and come with clear answers. You’ll save both sides time. This isn’t just for the team initiating the project, it’s for the collaborator as well! For the initiator of a cross-team project, it’s critical to identify exactly what type of preparation you expect from the other team before the kickoff meeting. And, for the collaborating team, it’s up to you to deliver on these asks and come prepared. If there isn’t enough lead time to prepare before a kick-off meeting, ask for it to be moved so that you can arrive with exactly what is needed to succeed. If possible, invest in a relationship. This becomes harder as teams grow in size, grow across time zones, or work in multiple locations. But, if at all possible, start a major cross- team project with a social event, not a planning meeting. Make sure the social event is at an equal scale to the project being delivered. If you’re working together on something for a full year, host an offsite. For a full quarter, host an after-work event. For two weeks, have lunch together. All of these events will provide team members an opportunity to get to know one another, which will lubricate cross-team interactions for the entirety of the project. Understanding roles Finally, the project needs a \"lead team\" and a \"follow team\". If there are five teams involved, there needs to be one \"lead team\" and four \"follow teams\". Usually in a cross-team project, there are usually two groups of people: (1) the group that initiates the conversation and the idea and (2) another team whose collaboration is required. If we want to set the project up for success, there are a number of questions that need to be answered and roles that need to be filled. The initiating team is the ultimate decision maker and should control speed, scoping, and own the release. For what it's worth, we have seen a \"follow team\" effectively take over as the lead mid-project. It works. It just needs to be communicated clearly and understood by everyone involved. Between the lead and follow teams, make sure the following roles are filled by at least one directly responsible individual (DRI): The Project Manager : Who’s responsible for making sure that the work continues to move along and manages any inevitable shake ups? The Researcher : Who provides answers to questions that arise throughout the process? The Communicator : Who is responsible for communicating changes or new features to customers? If the project touches even more teams, who is responsible for communicating with those teams? Specific Project DRIs : Each discrete aspect of a project should have a single dedicated DRI. This individual is responsible for the overall delivery of that piece of work from beginning to end. Oftentimes, these are the technical owners but can also be the design or product team members in certain cases. Understanding priorities No team works within a vacuum. There are constantly things that arise that can delay or potentially even enhance the delivery of a project. It’s critical for each team, whether they are the initiator or the collaborator(s), to understand their own priorities/roadmap clearly. Without a clear understanding of priorities, teams can unintentionally over-commit, avoid any type of commitment, or develop resentment if they don’t understand how a cross-functional project fits into their overall mission. One of the best ways to communicate priorities is to carve out a meeting early on — it can be short (20 - 30 minutes) — for each team to share their roadmap at a high level. Think months and quarters, rather than weeks or sprints. It may not seem important to inform the other team about the work you are taking on outside of the project at hand, but it is. Understanding the context that others teams are working in helps each team involved empathize when something is taking longer than expected, when teams may seem distracted from the cross-team project at hand, or when there’s a mismatch of urgency. Having shared team priorities, it’s important for the initiators to make sure that everyone is on the same page about two major questions: 1. Does each team clearly understand the scope, impact, and value of the project? The onus is on the initiator to help the collaborators make sure that everyone involved in the project has the basic information they need to prioritize their contributions and communicate to their other stakeholders why participating in this project fits within their larger vision/mission. It may seem redundant, but many projects fall apart because of simple miscommunications at the earliest stages of the project. 2. Does each team actually want to collaborate actively on the project? In the same vein as the previous question, just because a kickoff has gone well doesn’t necessarily mean that each team is whole-heartedly committed. It’s up to the initiators to make sure that collaborators are actively bought in, rather than just assuming that because another team likes the idea that they are on board with the entire project plan. More than likely, they aren’t! And that’s ok. Uncovering mismatched expectations, unbalanced priorities, or disagreements/confusion around implementation upfront is common and healthy. Conclusion Cross-team projects aren’t easy, and as organizations scale they grow even more complex. In order to set up a project for success, it’s paramount to dedicate focus and energy on the process even more than the project. Trust, a unified understanding of roles within the project, and a shared empathy for priorities will help make these tricky projects easier to execute.", "date": "2020-01-24"},
{"website": "Hubspot", "title": "4 Ways to Get Into Product Management", "author": ["Christopher O'Donnell"], "link": "https://product.hubspot.com/blog/4-ways-to-get-into-product-management", "abstract": "There's never been a more exciting time to be a product manager. Leading tech companies have written strong playbooks over the past decade on how to successfully market and sell new products, sites like Product Hunt share developments in web and mobile applications every single day, and the tech industry is booming with more access to venture capital than ever before. If there were ever time to learn, grow, and innovate in the product world, it’s now. Not surprisingly, all of this energy has left a lot of people wondering, “how can I get into product management?” The good news is, you don’t need to have a technical background to be an amazing product manager. Some of the best PMs at HubSpot came from marketing, support, and beyond. The only real requirement is that you’re passionate about building something from nothing and evolving it into a product that users depend on. If that sounds like you, then you’ve come to the right place. If you’re thinking about kickstarting a career in product management, these four ideas will help you think outside the box on getting there: 1. Build Something The first way to get into product is simple: build something yourself. All too often people say they’re interested in product management but can't point to a URL of a project they worked on. This might sound daunting at first if you aren’t a designer or developer, but anyone with a computer and an internet connection can learn to build a web or mobile application. There are countless resources out there (free ones, too) to learn how to code, design, tackle customer development, validate your idea, and ultimately launch a living, breathing product. Even if your product only reaches a handful of users, building something from scratch sets you apart drastically. Don’t worry about how complex or marketable the end product is- the goal is to get your hands dirty with product development. The advice that I often give people, particularly those who want to learn to code, is that you must start with something you’re passionate about building. Without some North Star, learning new skills will feel like a chore and eventually your drive will fizzle out. Focus on finding a problem that’s important to you. Maybe it has to do with travel, cooking, or sports; wherever your passions lie, let that spark your project and start building. 2. Work With Makers You can’t launch a product without inspiring people to build it first. That’s why being a great PM largely depends on how well you work with developers and designers. Learning how to communicate with creative makers is key, so even if you don’t work with product talent in your current role, find ways to start flexing those muscles. Reach out to developers and designers at your company to start a dialogue or keep an eye out for local events where you can network or collaborate with makers. By spending time with people behind products, you’ll develop your own perspectives on problem solving and understand the process better. You might even discover a project to work on together; collaborating will help you understand first-hand how PMs empower developers and designers to make the biggest impact possible. When you are ready to roll up your sleeves, hackathons are one of the best places to experiment with leading a group of makers. The resources and timelines are constrained, putting a lot of pressure on you to inspire the team, clearly define the goals, and navigate them through challenges. Not only will you learn a ton about what it’s like “on the job”, but you’ll build valuable relationships for future opportunities. Whether you go to an event or grab coffee with a Tech Lead from your company, connect with makers to start opening new doors into product. 3. Make (Internal) Moves The third way to get in product management is near and dear to my heart. When I was trying to get my first job out of school, my sister gave me great advice: focus on the company, not the role. I listened to her and ended up becoming a junior marketer at a company in my hometown that looked like a fun place to work. After awhile, the CEO decided to take a chance on me and let me try my hand at the product side of things. The rest is history. Recruiting from the outside is a tried and true way to fill a position, but a lot of companies will look for candidates internally first. If you’re driving results and have built trust across the organization, you have a good chance of being considered for a role in a new department. Even product. Roughly half of the PMs at HubSpot came from other departments; this route has worked well for us because they bring a well-developed perspective of the customer and product to the table. Your product team might think of you for a new role right off the bat because they’ve worked with you in the past, but often times, you’ll need to reach out to the hiring manager to let them know you’re interested. Either way, keep your eyes and ears open for PM openings within your organization. 4. Find an APM Program Some companies have an Associate Product Manager program for folks who are entirely new to the world of software development but eager to dive in. Google started doing this awhile back and we’ve developed a similar playbook at HubSpot that’s resulted in some of our leading PMs. Employees that demonstrate key qualities of a PM, like being results-driven and adaptable to a fast-paced environment, have the opportunity to become APMs; think of it as an apprenticeship in the product realm. They get to own real parts of the product at HubSpot and have access to 1-on-1 coaching to help them navigate the process. APM programs are an incredible way to jumpstart a career in product. If you’re company has this available, sign up (right now!) If not, think about how you can learn these skills and get access to PMs at your organization to give you a glimpse into their world. My guess is they’d be happy to do it. And of course we'd love to hear from you as well. These are just a few ways to think about finding your spot as a product manager. Whether you build something, learn from makers, or connect with your own product team, it’s important to get your hands dirty first and foremost. If you have more questions about product management (or want to share how you became a PM), feel free to leave a comment or check out more information here .", "date": "2015-03-03"},
{"website": "Hubspot", "title": "The New HubSpot Nav Bar Design: A Web App Usability Study", "author": ["Brian McMullin"], "link": "https://product.hubspot.com/blog/bid/86560/the-new-hubspot-nav-bar-design-a-web-app-usability-study", "abstract": "Now that we've started doing a better job on this blog of providing you a glimpse at how our development and design processes work here at HubSpot, it's time we shed some light on the design half of the equation. We've recently overhauled our product navigation menu, so we thought this would make an excellent case study for looking at how customer research and testing have helped us move in the right direction, and move quickly. Rapid, Customer-driven Development At HubSpot First off, let's be clear. \"Customer-driven\" and \"rapid\" development can and should work together. An argument that you often hear against taking the time to do user interviews and testing is that it slows down the development process. As folks like Steve Krug have been preaching for quite a while now, you can get great, directional results from user testing very quickly and from just a few sessions. And taking the time to confirm your direction early on will save you a lot more time than rewriting the application after the fact when you realize your customers simply don't want what you've built. In this case, we needed to examine the basic organization of our applications and the way navigation worked in the product. This had historically been an area of great debate; back in the distant past, the decision was made to organize the applications based on the Inbound Marketing methodology. This style of organization within the product helped to communicate the benefits of Inbound Marketing, but it increasingly made organizing our growing menu of applications much more difficult. You Gotta Have Goals The goal of the navigation redesign project was to make the product more usable. In the user testing lab, we'd measure this with things like completion rate and the amount of time it took users to complete key tasks. In the wild, we'd be looking at how we could increase overall app usage, how we might increase our NPS score , and how we might decrease the number of customer support cases related to finding applications and moving around within the product. As a development team, we already spend a lot of time speaking with our customers to help drive our development decisions. We also rely heavily on feedback from our internal stakeholders -- our very own supercharged Marketing team and the Support and Services folks who work hand-in-hand with our customers every day. Our User Experience team, led by the illustrious Josh Porter ( @Bokardo ), organizes these interviews and tests, and then quickly transforms what we've learned into flows and designs for rapid iteration. In the case of our navigation menu, we knew that there was plenty of room for improvement, so we started with... Support And Services As The Front Line Our Support and Services teams are awesome. No, really. They are awesome. These are *not* the folks that you talk to when you dial up your favorite cable or mobile companies for support. We hire a very special type of talented, charismatic person for these roles, and they consistently receive massive kudos in our surveys and NPS polls. They are also our best source of feedback for the wants and needs of our customers. For the navigation question, we just walked over to the Support and Services teams here in the office in Cambridge and asked what their experiences had been with customers using the old navigation. Did customers get lost easily in the product? Were there support cases logged due to the issue? Was there general confusion when trying to navigate the product? In this case, it was \"yes,\" \"yes,\" and \"yes.\" In roughly thirty minutes of conversation with these teams, we confirmed that we had a real product usability problem, which led us to look at… Our Marketing Team As Lead Customer Okay. So our marketing team is kind of a big deal. They put up some pretty huge numbers every month when it comes to lead generation. And they are generally the experts when it comes to things like website design , social media , and email marketing . So naturally we listen to them when they say they want something in the product. Or, more precisely, we beg them for their feedback when we have a new product idea. For this navigation design project, our first stop was figuring out what our own marketing team would expect in the product. To do this, we employed an open card sorting test , letting our guinea pigs on the Marketing team organize the product applications and app components in a way that would make the product most useful to them. From this exercise, we got a much clearer sense of how many app units we had on our hands, as well as some initial direction on overall groupings. This important, directional step took about thirty minutes each, for about four separate tests. Our next step was to confirm our Marketing team's inclinations with some actual customer data, so… Let's Talk To Some Customers! To constrain things a bit further, we cut the number of cards down to about twenty and focused more on the higher level groupings. Using screenshare conference calls, we tested four customers remotely for roughly thirty minutes each, asking them to organize the twenty cards into groups that would be the most intuitive and useful to them. From this testing, we looked at how frequently items were grouped together (darker blues in grid below) and saw some key groupings arise: task-based groupings, object-based groupings, and hub-oriented groupings. Now which grouping is actually most \"usable?\" From those three layouts (plus the existing product navigation), we quickly created some low-fidelity mocks and scheduled some final usability testing. For this round of testing, we wanted to get both customer and prospective customer feedback. This would help us allow for the fact that our customers had been \"trained\" on the product and had most likely become accustomed to the layout. Again using remote conferencing, we tested three customers and three non-customers by asking them where they would go to complete some key tasks within the product, taking roughly twenty minutes per test. The result of this last test pretty conclusively suggested that an object-based approach would yield the most intuitive design. What was fascinating was that none of the test subjects, even existing customers who had been using the product and had embraced inbound marketing, organized the applications by the methodology. This confirmed our intuition and helped guide our thinking of how to organize the product applications as a whole. Fast and Furious Customer-Driven Development From soup to nuts, the testing process took about 6.5 hours of testing time to give us new and actionable information about a pretty darn important user experience decision in our product. We feel confident that the change will have a positive impact on usability, and will reduce customer support cases related to finding applications in the product. As of today, we're launching this new navigation to a handful of beta customers and will be gathering feedback. If all goes well, we'll open up the change to our entire install base in a couple of weeks. Since data is part of our DNA here, we'll continue to monitor our metrics against our stated goals to make sure we're moving in the right direction.", "date": "2012-05-25"},
{"website": "Hubspot", "title": "How We Helped Users Set Their Notification Preferences Faster", "author": ["Pearly Jawal"], "link": "https://product.hubspot.com/blog/how-we-helped-users-set-notification-preferences-faster", "abstract": "Notifications are all around us ⁠— we interact with them every day. They're how we get the right information at the right time, and for HubSpot customers that's no different. We deliver an average of 6.8 million notifications to customers every single day, so every tiny improvement goes a long way to improving customer experience and satisfaction. This time around, though, we're not talking about a tiny improvement, but a huge one. Up until recently users struggled to find and understand their notification preferences. We analyzed the data, and through design iteration and experimentation, allowed users to find their preferences at a 95% higher rate and update their preferences at a 9.16% higher rate . Read below to find out how we got there. Identifying the problem When I first joined the Notifications team, my first 30 days revolved around understanding customer pain points. So I did what all product managers love to do: I went through 400 support tickets to identify the main pain points our customers were facing when it came to notifications. Quickly the picture became clearer. Most of them were related to the notifications preferences page and indicated discoverability as well as usability issues. To be more specific, most users didn’t even know they could change their notifications settings, and those who knew they could do it still didn’t know where and how to do it. Even when they knew where to go, it was impossible for them to find what they were looking for on that page for a few reasons: There were way too many options (see image in the following section). The labels and copy description were not clear at all and were not using vocabulary that resonated with users' mental models and representations. The layout of the page was too complex. Users looking to set up their conversations notifications had to know that some of the conversations notifications were under the “assign” section at the top of the page, while the others were under the “reply” section that was at the very bottom of the page. They had to scroll down for a few seconds and then click on “advanced preferences” to be able to find them. Hear from Pearly firsthand about how she and her team members solved for the customer. Exploring solutions In order to fix the discoverability problem, we thought about moving the notifications preferences page under Settings, as is the case for almost every other platform or app in the world. To validate this, we conducted a concept test with customers based on one of our product designer Lara Tacito’s proposals, which introduced designs meant to improve discoverability and usability. During this research we were able to validate that customers expected to find their notifications preferences under Settings and we were able to validate the usability issues we’d identified in the support cases analysis. Then our product designer Thomas Castro revisited the whole information architecture and layout of the page and came up with some designs that we tested during usability research. The goal of this research was to test the usability of two design prototypes by asking general questions to understand participants’ mental model and comprehension of the page (information architecture, findability, copy and labels, delivery methods, etc.). Once they were on the page, we asked them to perform five tasks to test the usability of the design. The final prototype was 25% the length of the original page! The old page and new page length when all accordions were closed. We also worked with UX writer Natalie Rohrer, who did an amazing job to make sure we had a really clear copy for users in the delivery channels, the notifications categories labels, and the actual notification description. In addition to that, the product designer organized a card sorting exercise so we could have a deeper understanding of how users categorized and grouped different types of notifications together. Here's what the current page looks like: Defining our KPIs To measure our success, we established some key performance indicators (KPIs) to track: Qualitative metrics: Decrease in support tickets related to findability and copy clarity of notifications on the page. Feedback and comments left on the feedback survey. Quantitative metrics: Conversion rate (conversion here refers to any interaction on that page: switching a toggle to turn on/off a delivery channel, checking or unchecking a box to turn on/off a notification option). Time to convert. Why does it matter? We believe that customers were so overwhelmed by the old page that they took too much time to find what they were looking for and make edits to their notifications settings. The new page should tell us whether: Users are finding the notifications settings faster (time to convert) Users find it easier to update their notifications (conversion rate) Conducting the experiment Everything was ready, but before launching the Beta we wanted to make sure our new design would truly have an impact on customers, besides the fact that it looked better and it followed UX best practices. That’s why we decided to run an experiment and test the performance of that new design. Our objective with this experiment was to reduce the number of support tickets related to the Notifications Preferences page and improve conversion rate on this page for users who wanted to set their notifications preferences by testing our new information architecture. We believed that the old Notification Preferences page architecture didn’t match users’ mental models because our previous research and support tickets analysis showed that users were struggling to find what they were looking for on the page and they didn’t always understand what each notification referred to. We predicted that if we changed the appearance of the Notifications Preference page for 50% of users, there would be an increase of at least 1% in the conversion rate of users modifying their notifications preferences. The sample criteria was simple: we would target users who visited the notifications preferences page. We wanted to have one control group who would see the old page and one variant group who would see the new page. We decided to test this with only 20% of customers (20/20 split: this means we tested the new version with 20% of customers and as a result we had a corresponding control group that was an additional 20% of customers) to reduce the number of users who would be exposed to the new page and mitigate the risk of having to roll back to the older version. The data in Amplitude told us that the old page had a conversion rate of 24.9%. Our goal was to improve on that original percentage. We used an internal tool designed for product experiments to help us decide how long the experiment should run. Taking into account several factors such as the daily traffic for that page,  the fact that we wanted to have 95% significance, and that we were aiming for at least a 1% increase in the conversion rate, we set an experiment duration of at least 14 days. After 14 days, the results were conclusive: the new designs had a higher conversion rate and the time to convert was shorter. Results Conversion rate: Old page: New page: Time to convert: (control = old page; variant = new page) We started the Beta on March 9th and released it to all on April 13th. Analyzing the results Here are the results we’re seeing so far: Qualitative data: We added an in-app feedback survey on our new page and we received a majority of positive comments. Customers thought this new layout was “easy and powerful”, “quite friendlier”, “so much simpler and easier to follow”; and the page has “great UX”. Support cases: In November, we had 81 tickets related to findability and copy clarity on the notifications preferences page. In May, we had 61 tickets related to these issues. That’s an 24.6% decrease! Quantitative data: Conversion rate = 27% Median time to convert: 46 sec Of course, there is still a lot of work to be done to improve this page and it will be an ongoing iterative process based on the feedback we get as well as the data we see on Amplitude. But for now, we’re pleased to have made the process of setting notification preferences smoother for our customers. Helping them focus on the right things to be more productive and get better results is always our goal. Want to work for a team that's committed to solving for the customer? Check out our open positions and apply .", "date": "2020-08-20"},
{"website": "Hubspot", "title": "The HubSpot App Marketplace (Part 2): The Story of To-Do List", "author": ["Adrian Mott"], "link": "https://product.hubspot.com/blog/bid/70623/the-hubspot-app-marketplace-part-2-the-story-of-to-do-list", "abstract": "The story of the To-Do List app starts with the first HubSpot Hackathon -Hackathon0.  When the team here at HubSpot first started thinking about the Hackathons that we wanted to put together, an idea that came to the forefront immediately was the BarCamp-style white board session at the beginning of each Hackathon to pitch ideas to the assembled and let folks decide what they might want to work on for the evening. Brian McMullin, a product manager here at HubSpot got up and put the idea for To-Do List on the board and pitched it to the 50 or so folks in attendance.  The basic idea that Brian brought to the table was to make a list-like app that would allow folks to keep track of their Marketing and other tasks from right within the HubSpot product.  From that moment, To-Do List went from a simple pitched idea on the whiteboard to an app that had life and was being worked on. The app was picked up by a Matt Pirkowski, Christopher O'Donnell and Jonathan Kim , who recently joined HubSpot from Performable and one HubSpotter who had recently made the move from the consulting team to the development team. In around 4 hours total development time, they mocked up the front end of the app and wrote most of the the Python back-end with the assistance of the Google App Engine framework.  Each team member (mostly) focused on a different side of things: the core Python (Christopher), the JQuery functionality (Jonathan) and the front end and UI (Matt). In speaking with the team, a really key part of their success for getting the app into a state where they could take it live to all users in the HubSpot App Marketplace was to keep the app's functionality simple at the outset.  This wasn't a big, feature-rich To-Do List application by any means.  The first functionality of the app was to let people enter things to do, categorize them and then keep track of when they were due.  That's it, nothing fancy, but a totally useful and effective app. Just over a month later, the app already has over 320 users and has gotten some great traction from HubSpot customers and other folks in the community.  If you want to try the To-Do List or another HubSpot app, check out the App Marketplace (under the Community tab) in any HubSpot portal.  If you don't have access to the portal, you can get a Free Trial or use the developer Demo portal . We're hosting another Hackathon - Hackathon1 around the middle fo September and are trying to get as many people as possible interested in coming, collaborating and building some awesome new apps.  If you're interested in attending Hackathon1, please register here: (Admission is free of course, and pizza, beer and sodas will be provided) http://hackathon1.eventbrite.com/ Hope to see you there!", "date": "2011-08-10"},
{"website": "Hubspot", "title": "Making Hundreds of Developers More Efficient by Creating a Frontend Platform Team", "author": ["Julie Nergararian (She/Her) & the HubSpot Frontend Platform Team"], "link": "https://product.hubspot.com/blog/frontend-platform", "abstract": "Every organization holds certain values and belief s that shape their culture. In the HubSpot Product org, we believe in moving quickly and iterating to constantly evolve with our customers’ needs. We’ve found , for example, that a small team empowered to make decisions and relentlessly drive toward their goals will deliver results and insights much more quickly than a larger group. That said, we also know that any organizational decision — like having these small, autonomous teams — will both solve problems and introduce new ones that require effort to solve. The primary challenge in this small team model is continually driving design and technical consistency across the organization for a quality customer experience and efficient development cycles. Conway's Law poses an obstacle that requires teams to collaborate and communicate effectively to avoid silos and diverging user experiences. With this organizational structure in mind, we have 200+ frontend developers who must be able to efficiently create consistent user experiences in our product while maintaining fast-paced iteration cycles, shipping to production multiple times a day. While these teams are autonomous, they still need to work closely together. Over the years, HubSpot has organized a Frontend Platform team to provide a strong foundation for our frontend stack . This keeps HubSpot frontend developers as productive and efficient as possible in continuously creating value for our customers, and help s those small autonomous teams operate together. Frontend Platform Principles The goal of Frontend Platform at HubSpot is to create the most efficient and productive team of frontend developers possible. Here are the principles we hold: Optimize for small, autonomous teams. The tools are optimized for tons of focused apps that teams can own themselves. A single team owns several repositories of separate apps and libraries. Our microservice architecture has over 500 applications and over 500 libraries. With teams owning their own apps and libraries, they are completely empowered to make iterative changes for their piece of the product, when a monolith would only slow them down. Many teams, one stack. We believe in the benefits of shared knowledge between teams, and a fractured stack means a fractured org. Additionally, developers shouldn’t have to relearn everything when they change teams — where’s the efficiency in that? Pick one and stick with it. When it comes to stack decisions, the Frontend Platform opts into picking one technology and sticking with it. It’s better to have an organization of developers built around being excellent at one technology than mediocre at a bunch of different technologies. By picking only one UI framework, or only one acceptance test framework, we’re able to create opinionated support, tooling, and guidance around them, making all teams more efficient in getting their jobs done. Continuous delivery. We build a platform that lets teams deploy confidently, several times a day. Since we believe in the learnings gained from iteration, this empowers us to continue to support our customers in a rapidly changing problem space. By creating teams around foundational areas of our stack and development process, we’ve been able to elevate the problems that hundreds of our frontend developers are working on every day. Only four developers need to think about the datepicker component, not 45. Only three developers need to think about frontend build tooling, not 300. Additionally, these specialized platform teams are able to provide the rest of organization with tooling, guidance, and real-time support on Slack, in-person, and on Zoom on their areas of expertise. Focus Areas within the Frontend Platform Build tooling and core infrastructure One group in the Frontend Platform focuses specifically on frontend build tooling, from the moment developers commit their code to the moment that code is in front of thousands of customers. Our core infrastructure team dedicates their time to JavaScript bundling, minification, and dependency management so the rest of the teams don’t have to. They’re also responsible for managing how we publish our assets and get them behind the CDN (content delivery network), and offer support with low-level tooling to the other parts of the Frontend Platform. Monitoring and performance Building and deploying applications is just the first step: we need to make sure they’re performant and reliable. We strive to make frontend monitoring tools (such as New Relic and Sentry) top-level citizens at HubSpot in the same way we invest in our backend tools. Our frontend performance and reliability group supports all product teams with guidance on how to make and keep their apps fast. They’re advocates for product quality , and will dig into the code of our hundreds of applications to help kill tech debt, remove deprecated dependencies, and make recommendations on how to meet our various SLAs. Testing infrastructure Testing automation is a critical component to ship ping software quickly and often. The HubSpot Product team doesn’t have a traditional quality assurance department, and instead heavily i n vests in continuous integration. Our frontend testing infrastructure team does not write tests: they build the infrastructure all other frontend engineers within our product organization rely on to build those tests themselves. While tools such as Selenium are notorious ly flaky and hard to use, t hey also have a near monopoly in the cross-browser automation space. By investing heavily in libraries and documentation around this browser automation software , we ensure each team has the tool they need to ship reliable software without relying on expensive manual testing. Common components and patterns The HubSpot Canvas Design System comes with a standard library of React components to allow product designers and developer to create consistent, fast, accessible customer experiences. This team focuses on creating an evergreen component library that can adapt and evolve with changes in the frontend ecosystem, in customer workflows, and in the HubSpot Canvas design language. When a change is shipped to this library of components, the next time an application builds and deploys, customers are interacting with that change. This team works hard creating, documenting, maintaining, and supporting these building blocks so everyone else can focus on using those components to create new value for HubSpot customers. Internationalization tooling HubSpot helps millions of small businesses grow better , so it’s imperative that our software be localized and accessible in a wide variety of languages and locales. However, it’s unrealistic to expect every frontend developer to be a cultural expert in all of our marketed regions. Our frontend internationalization team is responsible for building infrastructure that connects our developers with localization specialists and translators. They also maintain an extensive set of libraries and components that make it easy to optimize the experience for our supported locales without needing to think about t he nitty gritty . For example, s hould the given name come first or last? Is it acceptable to omit the last name altogether? How should phone numbers be formatted? The in ternationalization team makes sure our frontend developers get it right without too much trouble. Developer experience tooling With hundreds of frontend applications and libraries (and new ones being created regularly ), there are many efficiencies to gain from streamlining and standardizing our development experience. First, e very new developer goes through a frontend onboarding workshop where they learn the basics of using our stack and our core dependencies , such as React. Then, in their day-to-day work, our developers use our internally maintained wrapped versions of static code analysis tools such as ESLint and Prettier. Additionally, in order to support our developers as close as possible to the code, we have a custom internal extension for our primary supported editor, VSCode , with features like autocompleting our internationalization string keys and showing their translations on hover . (That said, our developers are free to use whichever editor they're most comfortable with . ) Finally, w hen it comes time to spin up a new application, developers can quickly create one that's ready out-of-the-box to be pushed to GitHub and deployed to production using our frontend application and library generator. Higher-level, HubSpot-specific building blocks Frontend applications at HubSpot have common needs for foundational features and infrastructure. Another focus area of Frontend Platform is building these higher-level building blocks that an app will likely need, but that a given small team shouldn’t need to reinvent themselves. For example, a library of prebuilt UI components that can be plugged into an app and can invoke endpoints to search for and select various types of HubSpot objects managed by other app s in the HubSpot product. Or, a component that lets HubSpot customers opt into (and out of) new features that a team is rolling out. This focus area also includes providing patterns and practices for using technologies like GraphQL. By providing opinionated solutions to these common problems, we ensure consistency across the frontend and allow teams to focus their time solely on creating new value for our customers by solving new problems. Frontend Platform, Small Autonomous Teams, and Continuous Delivery The Frontend Platform teams are dedicated to owning and supporting core pieces of our frontend stack. However, it’s another thing to fit those teams’ maintenance work within the greater organization’s culture. We already have a strong culture around small, autonomous teams that own their own pieces of product, so we need to think carefully about rolling out changes to our core stack — it’ll affect hundreds of developers. If the Frontend Platform were to make a change to a core library without careful testing, we would break the build of just about every app and library at HubSpot! If the Frontend Platform were to make a breaking change to a core library alongside a major version bump, that would put a “ to-do item” on all of the 100+ teams to migrate all 500+ apps and all 530+ libraries to the new major version as soon as possible. In addition , that single breaking change would fracture the HubSpot customer experience and the HubSpot frontend developer experience. In this scenario, the Frontend Platform would not be a positive force multiplier — instead, it would create a situation where everyone was burdened in learning and completing endless upgrades. In the spirit of small team code ownership, moving quickly, and crafting a consistent user experience to fight against Conway’s law, HubSpot’s Frontend Platform works toward having every project on the latest of any given library, always. This means our organization can avoid the associated costs of major version bumps. In order to make this work, the Frontend Platform team has developed an internal tool called Mothership. Mothership is a tool designed to make it easy to programmatically test and roll out changes to a large number of repositories and projects. Mothership combines different ways of target ing the various repositories across the organization that may need a specific set of changes, clones those repositories, runs individual modular scripts within the context of that repository, pushes changes to a branch, and creates PRs for teams to review. By automating these types of changes, frontend developers still don’t need to know all the nuances of stack upgrades and maintenance, and don’t need to carry the burden of tech debt associated with trying to keep up with endless major version bumps. Instead, the work to migrate all microservices onto the latest and greatest is a task for the Frontend Platform team, with Mothership in tow. Conclusion Solving for developer efficiency is solving for your product’s customers. A frontend infrastructure team can make developers more efficient by taking core problems off of their plate. With these foundational solutions in place, developers can spend their time solving novel customer problems that bring new value . HubSpot’s dedicated Frontend Platform team has become extremely knowledgable on specific focus areas, and actively supports hundreds of developers in their ongoing projects. By building and supporting a shared frontend stack, the Frontend Platform team has crafted a shared foundation for all projects in our microservice architecture, making it easier for HubSpot’s small, autonomous teams to work together seamlessly. Interested in working on or with our Frontend Platform team? Check out our open positions .", "date": "2019-12-16"},
{"website": "Hubspot", "title": "Quick Recap: The First-Ever Tech Talk at Night", "author": ["Hannah Fleishman (she/her)"], "link": "https://product.hubspot.com/blog/tech-talk-at-night-recap", "abstract": "Last night, we hosted the first Tech Talk at Night here at HubSpot HQ.  Over 100 product and engineering gurus came out to hear from our very own Ben Anderson on React.js and Wayfair's Andrew Rota and Matt DeGennaro on Tungsten.js. Two hours, three dynamic speakers, and dozens of carefully-crafted Pimm's cups later, we all had learned a few new names and front-end tips. Every week, we have internal Tech Talks on interesting problems our team is solving. There's always a completely new perspective and topic on the table, from chrome extensions to microcopy . We wanted to take this beyond our team and create a platform for Boston's engineering community to share the problems they're working on and hear what other companies are working on.  Cue Tech Talk at Night. For this inaugural event, we focused on front-end frameworks. Andrew and Matt from Wayfair walked us through how and why they built Tungsten.js to turn on efficient DOM updates, and fast client and server-side template rendering. Wayfair is a highly scaled multi-page site that supports a broad range of browsers. They have recently open sourced their framework, and the slides from the talk are here . The second talk of the evening was given by Ben, on our Platform-as-a-Service team, who presented on thinking like React and why \"going with the grain\" is beneficial. Having spent time in the trenches building React apps, Ben had 3 tips -- prefer functional idioms over OO, prefer stateless over stateful components, and chose clarity over brevity. His slides are available on \"React - Going with the Grain\" . Behind the scenes, HubSpotters were whipping up summer cocktails (thanks to our MC Anthony's artistry) and serving up \"yummy and healthy noms\" (thanks, Lisa!) In true inbound marketing fashion, here's a recap of the evening as told by social media. lining up the bevvies for @hubspotdev #techtalkatnight A photo posted by anna (@atperko) on Jun 9, 2015 at 4:17pm PDT . @AndrewRota + @TheDeeg of @WayfairEng kicking off Tech Talk at Night with a #tungstenjs overview to a packed house! pic.twitter.com/z35wcZ08zS — HubSpot Product Team (@HubSpotDev) June 9, 2015 We went with modularity - backbone, virtual-dom, mustache #techtalkatnight #tungstenjs pic.twitter.com/EWHbGloqR5 — Dan (@danieluhl) June 9, 2015 \"Relay - the 800lbs gorilla in the room...and it's not even born yet.\" - @ben_anderson at #techtalkatnight pic.twitter.com/dVC7AccVtW — Andrew Rota (@AndrewRota) June 10, 2015 Really impressed with the noms and bevs at Tech Talk at Night @HubSpot . Yummy & healthy! Missing @bethdunn ...le sigh pic.twitter.com/NAv3M3Hy9x — Lisa (@thislisaperry) June 9, 2015 @HubSpotDev #techtalkatnight is my new favorite thing. Can’t wait for round 2! — Colby Rabideau (@colbyrabideau) June 10, 2015 Stay tuned for the next Tech Talk at Night! Until then, let us know in the comments which topics you'd be interested in hearing about at the next event and check out our upcoming design meetup, Tuesdays by Design, here .", "date": "2015-06-10"},
{"website": "Hubspot", "title": "My favorite kind of Subversion commit - removing dead code", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/34165/my-favorite-kind-of-subversion-commit-removing-dead-code", "abstract": "There are only a few things that make me happier than removing old, dead code. One of them is when a colleague beats me to it! I always feel like dead, unused, old code is like a heavy coat around my body on a warm summer day.  I get this overwhelming desire to ditch it, throw it aside, get rid of it. Unfortunately, it's not always easy to find or spot dead code.  As the amount of code grows large, and some of it moves into \"legacy\" or \"just barely maintained\" mode, this gets more challenging. Even though HubSpot has only been around a little more than three years, we have some such code.  We're fairly productive at cranking out code, and not bad at refactoring when we need to (which is regularly, as in most agile organizations).  But we haven't been great at removing old / dead / unused code. Which is why yesterday's Subversion commit, by @katzj , made my day: Remove some old code that isn't at all relevant any more As Patrick said \"The last remnants of the original business model. And code I wrote my senior year in college.\" (Fri, 22 Jan 2010 18:11:25 GMT)", "date": "2010-01-23"},
{"website": "Hubspot", "title": "Expanding HubSpot’s Product Ecosystem", "author": ["Nancy Riley (She/Her)"], "link": "https://product.hubspot.com/blog/expanding-product-ecosystem", "abstract": "At HubSpot, we believe that how you sell is why you win ⁠ — disruptive, exceptional customer experiences are the key to growing better for the millions of organizations that HubSpot seeks to serve. And we know that extraordinary customer experiences are built by teams of people and connected software applications working together with a common understanding. The data proves it out — organizations of all sizes are using more SaaS apps than ever before to run their businesses, and they are feeling the pain of integrating and managing it all. They need a clear, orchestrated tech stack that makes their lives easier, not harder. Source: 2019 Annual SaaS Trends Report , Blissfully What does that mean for Product Teams? Product folks love to develop innovative solutions to meet customer needs. In this case, it’s not one solution, it’s an ecosystem. My team at HubSpot is the Ecosystem Product Group (EcoPG) — we empower external products and services to connect to the HubSpot platform, and help our customers find solutions that will drive their growth. To create a winning customer experience (for their own customers) and grow better, HubSpot’s customers need three things: Software that removes friction and accelerates their flywheel — enabling them to attract, engage, and delight their growing customer base. A system of record that provides a common understanding of each customer and all of the interactions they’ve had with the organization. Skilled humans to help the organization lean into their strengths and shore up their weaknesses. Let's break it down… Customer Need #1:  Software solutions that remove friction and accelerate the flywheel This reflects the prime directive of all HubSpot Product teams — understand our users’ needs and build them valuable, usable software tools that will help them grow better. We acknowledge that we are never going to build everything for everyone—there is awesome innovation happening outside our orange walls. Valuable, delightful, tightly integrated software solutions start with the developers who build them. And they need extensibility — APIs that flow data in and out, plus UI real estate to bring their value inside our platform. All while ensuring the security and privacy of our customers’ data. By giving external developers all the tools and access they need to develop Really Cool Things that our users desperately need, it’s as if we’re growing the capacity of our Product team. Exponentially. Embracing platform thinking like this allows us to solve for our customers better and faster. And we know that extensibility alone won’t make developers love us (and more importantly, encourage them to develop on our platform). We’re continuing to invest end to end, creating a sense of community and backing up our commitment to an open HubSpot platform. Customer Need #2:  System of record Ah, the center of the flywheel — the system of record. Yes, that’s our CRM , and it’s getting more powerful every day. It can only be a true system of record, a single source of truth, if it brings together ALL of the data that an organization has about a customer. Every integration contributes to that in some way, but bi-directional synchronization is at the heart. With our world-class Salesforce connector and the addition of PieSync (which is already growing from contacts to companies and will continue to expand), we are well on our way to unmatched sync capabilities that a mere mortal (read: non-developer) can understand and configure. I can’t overstate the importance of this – in a world where data drives a connected experience, sync is the lifeblood. Customer Need #3:  Expert help While all of HubSpot’s customers are smart and creative and incredible, much like ourselves they can’t be masters of all things. They need help, not just from software but from people. HubSpot’s evolving partner community stands ready to meet that challenge in a mind-boggling variety of ways, and it’s the job of our Marketplace to match the right customers with the right providers of the right products/services at the right time. No small task! The Marketplace today serves up Apps, and in 2020 we’ll add Solutions Partners and CMS Assets to the same framework. Beyond that who knows? Well, we’ve got some ideas, but the sky’s the limit. HubSpot is helping millions of organizations grow better — but they don’t have to grow it alone. The expanding ecosystem is here to empower their success in a myriad of ways, with the HubSpot platform as the foundation. Want to join the party? Learn about building on our platform , or read the latest news on our Solutions Partner program . Check out our Chief Strategy Officer’s view on the HubSpot ecosystem and its growth over time.  Together, we make anything happen.", "date": "2020-02-06"},
{"website": "Hubspot", "title": "Designing for Anxieties", "author": ["Kevin Kupillas"], "link": "https://product.hubspot.com/blog/designing-for-anxieties", "abstract": "Anxiety sucks. Sure, some of it’s okay, like when it helps us stay alive in moments of life or death. But beyond that it's generally terrible. Not only can it cause some serious health issues, it can affect our ability to think clearly and quickly, our ability to retain and recall information, our ability to progress in our goals, and it can paralyze us to the point of complete inaction. As product teams, we think about the motivations of our customers and what their outcomes, goals, expectations and needs are. We also think about our business goals and metrics for activation, retention, etc. and then we try to design and build products to make all of those outcomes a reality. However, sometimes there isn't enough focus given to the anxieties that surround these motivations and outcomes, and the impact they have on our customer’s behavior and perception. We might do a great job building the right functionality and clearly lighting the path forward for people, but they might not progress down that path if there are overpowering anxieties surrounding the next step that we’re not designing for. How Anxiety Impacts Behavior and Perception The more anxiety we experience when trying to accomplish something, the less likely we are to continue to do it, and the less likely we are to perceive it as a positive experience. In some cases, there might be so much anxiety that we don’t even make an attempt in the first place. Here are just a few examples of product-centered anxiety, the designed response to them, and some potential outcomes of not addressing them. “I’m worried that my personal information, like age and weight, is going to be shared with everyone.” Microcopy to the rescue! - Adding a “Don’t worry, this will only be visible to you” or “We’ll never post without your permission” can be used to alleviate the anxiety around sharing personal information. If not addressed, users might skip providing data that helps build a more personalized experience. “Why do you need my location when I’m just trying to accept credit cards at my food truck?” Permission primers (the messages before the messages) can be more effective at getting access to data because they provide an opportunity to explain why you need a particular bit of data before the system dialogue is presented (and rejected). Depending on your product, denying these permissions could make the experience less effective or render the product completely useless like denying location data for a mobile payment app or denying camera access for a photo sharing app. “Is my credit card info going to be safe?” PayPal was built around this anxiety. Beyond trusted brand equity, seeing one of those little secure badges on a website can help people feel more comfortable filling out purchase data. If they feel enough anxiety around entering their info, you’ll lose business because they’ll just seek out another source that feels, or appears to be, safer. “Uhhhh what do I do next?” A clear call-to-action, and a solid signal-to-noise ratio can reduce the anxiety of not knowing what to do next. This might seem small, but people don’t enjoy feeling confused and lost, and any amount of time spent in the ol’ cognition realm can be taxing when added up together. In some cases, people will just seek an alternative that makes them feel smarter and more in control of their own destiny. “What’s the cost of switching to this new product? Is this product going to be really hard to use? Is this product going to be better than the one I already paid for and know really well?” When you first communicate with customers through initial marketing touch points, consider mentioning how you’ll make the transition from what they know and use today, easy. Is their existing data easily imported so they’re not starting from zero? How is this product going to make their lives better? Are you filling in solution gaps not available in other products? Without addressing these anxieties, you might have a hard time getting customers to even try your product out to begin with, especially if it requires a purchase. These are just a few of a kazillion examples, but you can see that anxiety appears in all forms and all levels of severity, and sometimes communication might be the only tool we need to relieve it. The real common thread, however, is that anxieties are always present and anxieties will always have a degree of impact on customer behavior and perception . Frameworks That Acknowledge Anxiety There are three frameworks, or customer lenses, that have influenced me the most as a product designer: jobs-to-be-done, B.J. Fogg’s Behavior Model, and onboarding journeys. Although they were created without consciously relating to one another, they are extremely complementary in how they view anxieties and their influence on behavior. I encourage you to take a deeper look at each of these outside of this post to witness their full magic and glory (links provided at the end), but for now I’ll briefly explain what they are and how they relate to this topic. 1) Jobs-to-be-done Customers hire products and services to get jobs done. True statement. What’s also true is that customers will choose and judge a product based on its ability to help them achieve their desired outcome for that job. The beauty of the JTBD framework is that it allows us to understand how and for what reasons people choose, one product over another. Armed with this type of information, we can build more attractive solutions that focus on their outcomes and that aim at getting them to hire our products instead of our competitor’s. When I started learning about JTBD, one thing that really stood out was the focus on the customer’s anxieties around new solutions, and specifically, what is referred to as the four progress-making forces that can make or break adoption and retention. The four forces are divided into two groups: those that promote new choice , and those that block change . Promoting new choice: The push of the current situation : What problems in their current solution are pushing them to seek a new one? What anxieties exist that they wish didn’t? The pull of the new solution : What is it about the new solution that pulls , or attracts them to it? What sounds appealing about the new products and what anxieties does the new solution promise to eliminate or address? Blocking change: The anxieties around the new solution : What uncertainty around the new solution is causing them to resist adoption? Are there concerns about learning curves and not being able to accomplish their goals with the new solution? The habits in place from the present solution : What about the current solution is keeping them from seeking a better way? What things do they really like about the current product? What are they worried about missing? These forces play an important role when customers are choosing which products to hire. And even when they take a chance on a new solution, there are still the ongoing measuring sticks they use over the lifecycle to determine whether a particular service or product is providing more or less value than the alternatives. Should I keep using the product, or fire this product and hire a new one? How can we, as marketing and product teams, identify the jobs they’re looking to get done and help relieve any anxieties surrounding them in our communications and product offerings? What is it about their current product that’s pushing them to seek something better, and what is it about our product that is going to pull them towards us? 2) Dr. B.J. Fogg’s Behavior Model The good doctor is all about understanding behavior and behavior change. Within the world of behavior change there are anxieties that can make change harder for people. The Fogg Behavioral Model talks about three elements that must come together for a behavior change to occur. Whether it’s a behavior they want to do themselves (quit smoking, eat better, exercise more) or a behavior we want them to do for us (buy stuff, sign up, come back and see us again), these three elements are key. Motivations : The three main motivational pillars are pleasure/pain , hope/fear , and social acceptance/rejection . These are the reasons we do, or don't do something (there is no try, Yoda taught us that), and they seem to have anxiety written all over them. Ability/Simplicity : The six simplicity factors are time , money , physical effort , brain cycles , social deviance , and non-routine . Reducing these factors is generally the goal - make it take less time, make it cheaper, make it easier to understand, etc. Increase simplicity and you will increase a person’s ability to do something. Triggers : Things like cues, prompts and calls-to-action are types of triggers, and the timing and placement of these is crucial. Tapping someone on the shoulder to do something at the wrong moment is pretty useless, like reminding someone in the middle of the work day to take their medicine that night. Putting triggers off to the side for the sake of this post, it’s the three motivational pillars and six simplicity factors that stood out to me as being directly connected to anxiety. Take a second to think about all the times and ways things like pleasure, pain, fear, social acceptance, money, or physical effort have affected your behavior or perception. Now, think about the products you work on and the various moments these factors might impact your customer's behavior, both positively and negatively. What motivations and ability/simplicity factors are present in your customer’s world? Are they anxious about the time it takes to do something, and just not doing it? How can you make things take less time and how can we increase simplicity and ability overall to help relieve these anxieties? 3) Onboarding journeys Last, but not least, are onboarding journeys. Onboarding journeys span across the length of the entire customer lifecycle, from discovery to advanced usage, and are beyond filling out a signup form or swiping through a walk-through. Like any journey, they can also be sprinkled with little crappy bits of anxiety here and there that are blocking people from progressing down the path to a better, more successful self and customer. Samuel Hulick ’s The Elements of User Onboarding gives examples of addressing some anxieties during marketing’s “let’s get to know each other” phase. He writes, “If your product is project management software and you find out your customers are concerned with administrative overhead, acknowledge the nightmare that group emails can cause.“ This type of connection to our customers let’s them know that we understand their anxieties and concerns, and that we care about making their lives better. How can we be sure we understand our customer’s anxieties and how can we acknowledge that we understand them in a meaningful way? How can we identify the steps and phases of the journey that cause the most anxiety, and how can we help them become successful? Solving for Anxieties in Your Design Process To start answering the questions above and solving for anxieties in your product process, a relatively easy first approach is going through the exercise of matching your customer’s anxieties to the bits of value that currently exist in your product. Start by talking with customers and prospects Understanding what people do and what solution(s) they use today to reach their desired outcomes is the key to this process. Knowledge is power, for real, and even if you sort of think you know, it’s worth taking a little time to validate your knowledge and assumptions, so that you can focus your efforts in the right places. Without knowing the outcomes, anxieties, and the steps in the process that cause the most anxiety or pain, we can’t build a better solution or even begin to articulate why people should make the switch to using our product. Reach out to potential and existing customers, on the phone or in person, and ask them to walk you through how they go about accomplishing their job-to-be-done. Write down the steps you hear in their process and also try to explore what I call “bookend” moments, or the moments immediately before and after their process. Dig a little bit when you hear something even remotely resembling anxiety, and mark the steps or moments that are affected. If you’re super lucky, having the chance to observe your customers in their own environments is the best way to see and feel what it’s like beyond the screens we build for, and get insight into any additional anxieties their environment may bring to the table. There’s always going to be outside forces that our products have little or no control over, but knowing what customers do in the moments immediately before and after using our products can help highlight ways that we can add more value. Again, the main things you’re trying to understand are: The steps taken to accomplish their job-to-be-done, including the bookend moments immediately before and after The steps that cause the most anxiety How they feel in those moments of anxiety, and why The impact that these anxieties have on what they think, feel and do Write all of the juicy details down so you can reflect and discuss with your team, especially for those that weren’t able to join the interviews. Mapping out the steps in the customer’s process can also help your team visualize the moments that these anxieties occur and help identify if the anxieties are stacking up from step to step. Next, play the anxiety/solution match game Take the list of the anxieties you heard from your customers and then write down all of the ways that you design for them today. What elements, like copy or bits of functionality, do you think help relieve the anxieties you heard? Draw lines to connect the anxiety with your solution, talking through each one to make sure there’s a shared understanding as you go. If an anxiety is left without a solution match, then you know you have a value gap in your product that you can work on filling in. Next, think about the value these existing solutions provide (in terms of solving for the anxiety), the awareness of these elements (using things like discoverability and traffic), and the future potential for some of these elements (or what you imagine might be valuable if done well). Rate the value, awareness, and potential on a low/medium/high scale. Your ratings are not going to be 100% accurate of course, but go with what you heard from customer interviews, historical usage and historical knowledge to get you through the exercise. See the messy whiteboard session pic below from when my team was thinking about the anxieties our first-time experience might need to address. This anxiety/solution match game helps: Identify opportunity/value gaps (missing solutions to the anxiety) Identify areas for improvement (solution “x” is ok , but it could be better) Highlight things in a way that can prioritize work based on value and simplicity. If something was thought of as a low value solution with low awareness and low potential, you know not to concentrate on that at the moment (and maybe even investigate whether it should remain in the product or not). If something was currently low value but high awareness and thought of as having high potential, you might want to focus on that to see how you can bump up the value. Cheap wins and the ability to quickly test something can factor into this prioritization, too. Below is another crappy whiteboard pic showing the list of things that we identified for exploration. Finally, design experiments to test your solutions With your refined list of areas to focus on, start thinking, sketching, mocking, circulating, and discussing ideas that you and your team come up with. Get everyone on the same page of intent and purpose, and discuss how you’ll go about testing these ideas with customers. The fidelity of the designs and the types of experiments depend on what you want to learn and from who, but the important part is to focus on one thing at a time so you can measure the impact more effectively. When asking for a piece of personal info, are 50% of people skipping over it, and does providing some microcopy explaining why it’s needed help people feel comfortable enough to provide it? How will you know that your solution relieves the targeted anxiety? What methods, tools, signals or user actions can help your team understand if it’s having a positive impact? Take it Away! Anxieties relate directly to customer experiences, communication, adoption, engagement, retention, win-backs, and basically everything else under the product sun. Consider researching and discussing the relationship between your customers’ anxieties and the experiences you’re looking to provide. In the end, I think we can take comfort in knowing that if we understand and design for their anxieties, we’ll have a better chance at making the product experience delightful and memorable. Here are some links that helped me get started with thinking about anxieties and ways to work them into my product design process: Jobs-to-be-done and outcome-driven design: http://jobstobedone.org/ - The mothership for all things JTBD. Bob Moesta and Chris Spiek are champions. http://hbswk.hbs.edu/item/clay-christensens-milkshake-marketing - Clayton Christensen is a founding father of JTBD. Here’s a great video of him explaining it using the famous “Milkshake” story. https://blog.intercom.io/podcast-tony-ulwick-on-jobs-to-be-done/ - Tony Ulwick of Strategyn talks about JTBD and outcome-driven innovation. So good. https://medium.com/@alanklement - Alan Klement’s articles have provided many a-ha! moments for me on this subject. For that, I thank you sir. BJ Fogg’s behavior model: http://www.behaviormodel.org/ - Amazing content, forgive the site design :). This man changed the way I think about life, to be overly dramatic about it. Onboarding: https://www.useronboard.com/ - Samuel Hulick helped me understand what onboarding really was about and why it’s so important to think about and build a strategy for. Check out the teardowns too! Hilarious and insightful. Thanks for reading. I hope it was helpful. Any thoughts, questions, comments, and hoorayers or naysayers are more than welcome. Discussion and thought helps me refine my ideas and communication so thanks in advance!", "date": "2016-04-25"},
{"website": "Hubspot", "title": "Paying Developers Like Sales People", "author": ["Patrick Fitzsimmons"], "link": "https://product.hubspot.com/blog/bid/35159/paying-developers-like-sales-people", "abstract": "The other night I was talking to a co-worker about the difference between developers and sales people. My co-worker said, \"I think developers and sales people are different by nature. Developers do their job for the love of coding, sales people work for the money.\" I disagree. I think the difference is incentives and measurement. The output of a sales person is easy to measure. Because the output is easy to measure, we can pay them in accordance with production. Because a sales person making money is directly aligned with HubSpot making money, we actively seek sales people who are motivated by money. Greedy sales people are good sales people. Measuring the output of a programmer is very difficult. So instead we find developers who love programming, pay them competitively, seduce them to fall in love with the company, and then hope their intrinsic motivation will produce good results. It works, more or less, but it could be a lot better. I wonder myself, how much more could I do if my output was accurately measured? Would I spend less time dawdling over that email, and more time pumping out code? Would I spend less time over-engineering that theoretically perfect solution, and more time building stuff that delivered customer value? Would I spend less time playing with that shiny new development toy? Or would I spend more time relentlessly improving my developer environment to improve my own productivity? After thinking some more, I started scheming out an actual system for paying developers based on performance. Here it is: Defining a bounty for new features and improvements The management team and/or the product team must write up a wish list and put a price on each item. An example list might read: Build the minimal, working implementation of a survey application (a description would follow with five or ten bullet points defining the minimal implementation). $220,0000 Improve the success rate of trials from 10% to 15% (success rate being defined as contacting a sales person or logging in a second time). $75,000 per percentage point improved. Improve the median load time performance of a given page from 1.5 seconds to .5 seconds. $10,000 Develop a new application that will be used by 500 users a week. $400,0000 Improve usage of a given application from 100 weekly users to 200 users a week. $50,0000 Reduce support calls for a given application from 60 calls a week to 30 calls a week. $1,000 for every 10 calls reduced. Build small feature x. $1,000 Nailing down a set of requirements The team of developers (2-4 developers) then pick a project to work on. It is key that the developers get to choose the project, otherwise the whole system breaks down. After the dev team picks a project, the developers work with the product team to nail down a fuller specification. This spec includes various requirements, mockups, and wire frames. There would be some room for haggling over which features would be included. The spec must leave room for iteration. Instead of reading, \"Put this button exactly at 240px\" it should read: \"build this screen, and do up to two iterations of the UI\". Finally, the group will nail down the rough spec, and the developers will agree to deliver the product at the given price. The spec should be broken up in a way that there are measurable deliverables presented within one month. The developer team should receive payment for meeting these deliverables. Measuring results For some bounties, the measurement would be straight forward. Measure how much the conversion rate increased, or support calls fell, and base pay on that. The \"build a new application\" bounties are more difficult. The best way would likely be scoring matrix. The components would be: 10% usability testing. During the specification stage, the product owners would write a script for usability testing. If five users get through the script without needing assistance, the app scores a 10. 20% customer feedback. Before development begins, a set of beta customers should be found. These customers will grade the app when it is done. Developers should consult the customers as they build the product. 20% product owner grade. The original management team/product team sponsor of the app would grade the application based on its meeting or exceeding expectations. 20% Usage stats. During the specification stage, a usage target should be set ( 200 users within one month of launch). Based on that target the application will get a grade. 20% Defect density. Based on the number and severity of bug reports the application generates after launch, the score would go up or down. Based on total feedback the developer team would receive anywhere from -30% to +30% of the original bounty. In order for the application to be accepted, the app must meet the company's coding standards. A non-team member reviews the code. Backups, redundancy, and monitoring need to be in place. Unit test coverage must exceed 60%, etc. Dividing the Bounty The bounty is awarded to the team as a whole. But the team must divide up that bounty among its members. I can imagine two possible methods. Method 1) the shares of the bounty are based on the developers current salaries. So if Alice makes $100K and Bob makes $80K, the shares of the bounty would be divided 55/45. Method 2) before each sprint or iteration, the team collectively assigns hour estimates for each task. Developers then get credit based on the total hours of the tasks they complete. If the developer finishes the case faster than the original estimate, he gets credit for the original hours. If he is slower than the original estimate, then he gets credit for the hours worked. But if he goes over the original estimate the team lead may re-assign him to a different task. If extra, non-bug tasks, need to be added during the sprint, those tasks must get hour estimates. How should the management team price features? The Unscientific Method Most product/management teams have some sort of road map. The road map lists various features or applications that need to be developed and allocates developer time toward those user stories. This road map can be turned into a price. Take a feature on the road map. Then ask yourself, would we still do this if the time it takes runs over by a month? Two months? Four months? Then add up the cost of the developers that would be assigned to work on it for that many number of months. That is your indifference price. But of course, management does not want to break even, it wants to make money. So knock 25% off of that price, and that is the bounty for the feature. Based on usage Most SAAS companies have numbers that link application usage to customer retention. Customers that use the app regularly rarely churn. Customers that do not find it valuable stop using the app and churn. For each new part of the application, usage can be measured. That usage number can actually be turned into an expected impact on the churn rate, and a dollar value to the company. Conversion Rate A project to improve the setup or trial process could be measured in increased conversion rate or success rate. The management team knows how many leads are coming in, the costs of a customer, so can calculate how much an increase in the conversion rate is worth to the company. Sales Team Demos If your company uses sales people to sell its wares, you could measure how often each feature is shown off in a demo. If a new feature gets shown off by all the sales people, it's a smashing success. Decreased Support Costs Calls and emails to support kill you two ways. First is the direct cost of the support team salaries. Second is that for every call there is someone else who gets frustrated and stops using the feature. The first is easy to quantify the second is much harder. Pitfalls Confounding variables For any performance based metrics, confounding variables are killer. Let's say that the bounty offered to pay a team for every 5% it improved the conversion rate. Now imagine marketing starts a new campaign that drives tens of thousands of low quality leads. The conversion rate will plummet, but at no fault of the developers. Conversely, if marketing starts a new campaign and drives much higher quality leads, conversion rate will rise, and the team may be unjustly rewarded. If your measuring how much a project reduces support calls, then perhaps a person on another team might make a large mistake that drives calls up. There are a couple ways to deal with this problem. 1) Choose measurement variables that have been predictable for at least several months. If the measurement variable is highly unpredictable, you are essentially rewarding developers based on the roll of a die. 2) Give developers complete control of the variable space. If you are measuring support calls, exclude calls on pieces of the product that other teams are currently overhauling. If you are measuring conversion rates, give the team actual control of the home page for the duration of the project. 3) Control for other factors. If there is a steady trend in the variable, then the bounty should be based on improvement over the existing trend. Haggling over the application's grade Once a coin operated culture takes hold, the pressure to game the system becomes intense. Sales seems straightforward, the number of customers you sold is a very hard metric. But even here there is a lot of room for haggling. What if the customer cancels? What if the sales person misleads the customer? What kind of end of month discounts are allowed? What happens if two sales people are on a call? Our CFO spends no small amount of time dealing with sales people fighting for that extra $500 in commission. The problem is much worse for figuring out compensation for a new feature. If the feature is graded by other people at the company, developers may place a lot of pressure to get a good grade, and there could be ill will if the grade is poor. Some of this can be mitigated by good communication. The developer and the product management team should be constantly talking. The developers should know where they stand at each iteration, and what the grade will be if they release at any point. Losing on the iterative approach - dangers of coding to spec In many cases the entire problem space is undefined. Let us take the case of an email application. If you are paying someone based on getting something out the door, then will code of the most basic application possible, they will code to the exact specification and not any more. But if you pay them a simple salary plus equity, and then expect them to do their best, the developers may have an idea that will make a far, far better application, even if it takes more time. They may spend the extra month to make it fast and ajaxy, because they are able to make trade-offs in his head and make the right decision about time allocation. The consignment based coding will work best in two cases a) you have a lot of separation between your product team and development team, and so the development is mostly implementing, not designing. While perhaps not ideal, this is already the reality at many companies. Or b) there is a lot of trust and cooperation between the product team and the developers. The developer could say, \"hey, we could do X, but we have to add to the price. We think it is really worth it, here is why. What do you think?\" And of course, bounty programming based on achieving metrics (like usage or conversion) rate, will allow far more developer initiative and iteration as the developers will try a number of approaches without having to cycle through a planning and specification stage. Developer Risk Developers assume much more risk with bounty based pay. What if no one uses the app simply because it was a bad idea? What if it takes far more hours to produce than expected? Or if it is simply impossible to produce at all? One group of developers might make a valiant effort redoing an app to improve conversions but to no avail. They might end up making half the salary of other developers despite their efforts. Other salaries might make a few simple changes and blow out their numbers. Developer pay has the potential to become very erratic. To mitigate this risk, developers must be able to pick and choose their user stories. Developers must work with the product team to develop the spec. If one aspect of the spec has a great deal of technical risk, the developer might force the product manager to price it separately, and then choose whether or not to implement that add-on. Overall, the development team has incentive not to make features which are a really bad idea, or a that will end up in a twisted rat hole. That's a good thing. Unintended Benefits Forcing management to price improvements When I first thought of this plan, I worried about how much work it would take to figure out a value to the company for each possible feature. But then I realized that requiring a deeper analysis was a feature, not a bug. In the early stages of a startup, a product team needs to work furiously and throw a lot of things against the wall and hope that something sticks. But in the middle stages the company has a lot of data about customer wants and needs, and the major bottlenecks hindering growth. Spending the effort to systematically judge the relative value of all possible initiatives is hugely valuable when directing a several million dollar engineering budget. Forcing developers to work closely with product management and customers One initial worry was was that animosity could grow between the developers and the product managers, since the product team's grade of the app will determine the dev team's salary. But a side benefit of it is that will force developers to much more closely with the product managers. For this plan to work, developers should be in contact daily with the product team, and always know where the current version of the app stands with them. Diving under water for a month and coming up with an app would be a recipe for disaster. Thoughts? Comments? Tomatoes? So what do people think? Has anyone tried a system like this? Can the impossible be done? Can a dollar a value be placed on developer productivity? Or would this plan collapse into a rancorous mess. Please offer your thoughts.", "date": "2010-02-09"},
{"website": "Hubspot", "title": "Key Learnings From Designing Social Reports: A Reporting Tool with Context", "author": ["Adam Darowski"], "link": "https://product.hubspot.com/blog/lessons-from-designing-a-reporting-tool-with-context-social-reports", "abstract": "Last year, our customers used HubSpot’s social software to share over 6 million posts on social media. Creating and publishing social content was a breeze but their feedback made it clear that gauging the impact of that content was more of a challenge. Customers didn’t just need data, they needed a tool to help them be better marketers, so we set out to build a social reporting solution. We launched Social Reports a few months ago and I wanted to share some insights from that process since data visualization can be a particularly tricky design challenge. The first thing we took from our user research was that our customers needed social reporting that was immediately useful. Before Social Reports, there were a few ways customers could measure their social efforts with HubSpot. Inbox gave users real time updates on how their content was performing, Publishing showed how many clicks and interactions each message was getting, and Reach tracked how their social following was growing over time. All of this information was useful, but it was disjointed. Customers didn’t have a great solution for assessing their performance at a glance or showing their superiors, “Look, this is the impact our social efforts had this month.” Many spent hours combining multiple data sources into a spreadsheet and not surprisingly, this was a huge time suck. Research told us that whether a customer was a data-savvy marketer or had a phobia of numbers, both needed a faster way to compile and digest their social metrics. The other challenge was that customers weren’t getting much actionable insight by looking at ton of chart junk. Were they getting fewer clicks because only a handful of messages have links? Were overall numbers down because they weren’t posting as often? Social reporting is about a lot more than numbers, it’s about context. Customers needed reports that would help them understand what’s working, what’s not, and what they should be striving for, so that they could use that information to improve their strategy. These pain points led us to one key ingredient that we kept top of mind while building Social Reports: context. We were able to design a simple and intuitive—yet powerful—user experience by relying on a few contextual features that may come in handy next time you’re tasked with displaying data: 1. Default Compare View: We designed the default view of Social Reports to illustrate how customers’ social efforts are doing this month compared to last month. Now, instead of wondering “is 112 interactions good?” or “is 88 clicks a lot?”, customers have context around their metrics. They can easily change the time span, but this feature instantly puts numbers up against a relevant baseline. The user experience is much smoother now with Compare Time Frames because customers can assess their performance without touching a single filter or toggle. 2. Plain English: To make the reports more immediately useful, we added straightforward explanations of customers’ results. If a customer is outperforming their metrics from the previous month, “Your messages are performing better” makes that crystal clear. Of course, defining “better” is a whole other issue. Do total clicks and interactions need to increase? What if total clicks are up, but only because more content was published? All of this goes into how we frame their written explanation. 3. Percentiles: We introduced percentiles to show customers how their social media efforts compare to those of other HubSpot customers with a similar reach. This added yet another layer of context. Here’s an example: “Your messages have had 112 interactions.” That’s just a number. We still don’t know how good that is. “Your messages have had 112 interactions. That’s 2.5 interactions per message.” That adds a bit more context, but not enough to be actionable. “Your messages have had 112 interactions. That’s 2.5 interactions per message, up from 2.1 at this point last month.” With this, we can at least see that we’re improving on last month. “Your messages have had 112 interactions. That’s 2.5 interactions per message, up from 2.1 at this point last month (and better than 53% of HubSpot customers with a similar number of fans and followers).” Now we know how we compare against ourselves and against others. The more context we can provide, the more insight our customer has when defining their social goals. With these key features, we launched Social Reports into an extended beta for a couple months. During that time, we checked in with beta users (both those who were using the feature and those who were not), made updates based on user feedback, added polish based on our own usage, and fixed bugs. It was our largest team-wide effort since launching Social Inbox . Now that Social Reports is available to our entire customer base, we can ask: did we create a social reporting solution that empowers our customers to be better marketers? Early returns point to yes. We’ve gotten feedback from customers that it’s now much easier for them to diagnose problems and fix their strategy accordingly, and that they have a high-level view of their performance that’s easy to grasp quickly. One customer said: “I basically wanted one view that can answer, ‘How is our social media working for us this month?’ I don’t want lots of detail. I want to know if our follower base is growing (and by how much) and whether people are engaging with the stuff we post. That’s it. Simple. And this report does that for me.” Of course, like with every area of our app, the work is never done. Next, we’re focusing on showing customers which individual messages are contributing to social success. We’ve also heard feedback that users would also like to know what the best time of day is for them to publish content. As we collect more and more data, we can help our customers become even more successful by keeping context at the core. How have you created a better user experience using context? Tell us in the comments!", "date": "2015-03-10"},
{"website": "Hubspot", "title": "Categories, Associations, and Navigation Design", "author": ["Darrell Penta, PhD"], "link": "https://product.hubspot.com/blog/categories-associations-and-navigation-design", "abstract": "What's the best way to organize the information in your company's main website menu? One of the gold standard approaches for tackling questions about navigation design, or information architecture (IA) more generally, is to run a card-sorting study . I won't dive into the particulars of how to run these kinds of studies, but I will note that card sorting is a well established, versatile methodology with a variety of applications for IA research. Card sorts are powerful enough to provide researchers with valuable insights into users' mental models, but uncomplicated enough that they can be run with nothing more than some paper and a pencil. Categorical thinking The card sorting methodology has its roots in experimental psychology. Many cognitive scientists (including me!) are interested in understanding how the information in our minds is structured and organized. As early as Plato (~320 BC), scholars have assumed that categories and taxonomies play an important role in terms of how our knowledge is structured, and card-sort experiments have become a standard approach for exploring questions in this domain because they provide evidence of our categorical thinking. For example, 50 years ago, the psychologists Battig and Montague (1969) gave hundreds of research participants the name of a category like FURNITURE and asked them to list as many items belonging to the category as possible in 90 seconds. They found that about 90% of people will include Chair in their list, but only about 15% will include Lamp , suggesting that lamps are probably only loosely related to this category in our minds, while chairs are prototypical exemplars. I'll get back to why this matters shortly, but the point is that, as humans, we're really good at categorizing the information we encounter, and card sorting capitalizes on this fact. Limitations of card sorting While IA research is usually focused more narrowly on understanding how a specific user group organizes information from a specific website, practitioners are still dealing in the currency of categorization. This is conveyed quite clearly in the title of Spencer's (2009) classic UX reference, Card Sorting: Designing Usable Categories . All things considered, card-sorting is great way to learn about your navigation structure, which will almost always end up incorporating some form of categorization. Yet I believe there are some limitations to this approach that all researchers— especially those at SaaS companies—should take into account. To illustrate: Imagine being an information architect or researcher at an online furniture retailer like Wayfair . Given what we already know about people's opinions about the category FURNITURE, we might predict the results of a card sort with some degree of accuracy. If we look at Wayfair's website, we would in fact find that 8 of the top 10 items given by Battig and Montague's participants do appear under the Furniture tab. What's missing? Lamp and Television . Recall that Lamp is the last item in the researchers' list (and presumably a weak fit in the FURNITURE category). This item was put into a separate Lighting tab on Wayfair's website, which I think is a good UX call. And considering what televisions looked like 50 years ago, we might understand why they made it onto the original list, but why they're excluded in Wayfair's Furniture tab. Nearly all of Battig & Montague's (1969) top FURNITURE responses are listed under the Furniture tab on Wayfair's website. Now, imagine that you're doing IA research for a SaaS company like HubSpot , which offers its customers nearly a hundred different tools designed to help small and medium-sized business grow. Just as the needs of business are diverse and wide ranging, so is the set of tools our users require to do great work. Here, some of the limitations of card-sorting studies become clear. Variability For one thing, categorization tasks are affected by the amount of variability in the set of things to be organized. We can probably get people to agree that tables and desks are more alike than are tables and lamps, but if we look across the set of all potential items in a FURNITURE category as a whole, we can see that there's a fair degree of uniformity. In contrast, we don't expect there to be a lot of uniformity in function or purpose between an email editor, an SEO tool, and a sales report, and our research finds that participants tend to need many different groups to contain all of HubSpot's offerings. Variability makes sorting more difficult, and SaaS companies often provide tools or features that are very different from each other. Arbitrariness There's also the issue of arbitrariness, which corresponds to how \"natural\" the categories are. This may be determined by our past experiences with a category, our impression of how cohesive the set of members is, or even how informative the category label is. Despite being a highly subjective construct, we know that people do have converging expectations about a category like FURNITURE, which implies that it is a rather natural category in people's minds. For business software, however, we can be reasonably sure that we'll end up with some categories that are more arbitrary than natural. After all, SaaS companies are often inventing the categories and the items they contain in real time. Task sensitivity There are two points about task sensitivity that warrant mentioning. Although they're related, they refer to two different kinds of tasks. Card-sorter's task . Scientists don't agree entirely on what people are analyzing when they're creating categories, but one line of thinking is that we look for commonality among to-be-grouped items on the basis of their shared features (e.g., for FURNITURE, is made of wood , has legs, etc. ). Sorting studies usually instruct people to create categories that make sense to them, and I would argue that this engages our default tendency to create groups based on similarity. This is not always a bad thing—especially not if you're selling furniture. But similarity represents only one way in which information can be related, and it may not always be the optimal relationship to highlight in your IA. Navigator's task. There's also a related concern that categories work well when your users need to act on categorized data, but they work less well when your users need something else: On average, a Wayfair customer probably visits the company's website looking to purchase a product, like a chair, and arguably, they expect to find an organized taxonomy of furniture items to help them track down the exact chair they want. In contrast, a HubSpot customer might come to product with the goal of contacting a sales lead, writing an informative blog post, or setting up a chatbot for automating customer support interactions. In these cases, an optimal navigation experience through HubSpot is tied critically to context, and might be based on complex workflows. Card-sorting data is not necessarily well equipped to capture these nuances. Enter: Word-to-word association While research from psychology has left a permanent mark on the UX industry in the form of card-sorting studies, there's been surprisingly little recognition of another line of research that I believe has the potential to provide researchers with useful data about users' mental models: word-to-word association (or simply, association ). For the past 40 years, cognitive scientists have also explored questions about the structure of conceptual knowledge in terms of associations as a complement or alternative to categories. Rather than explain what association is, I'll demonstrate by showing how the research works. I'll give you a word prompt, and then you take a few seconds to write down the first five words that come to mind. Ready? Here's the prompt: BEE Did you come up with a list? If so, then read on... The psychologists Nelson, McEvoy, and Schreiber (1998) conducted a similar task with hundreds of participants more than 20 years ago and determined that the most probable responses to this prompt are, in order: sting > honey > hive > insect > wasp . That is, these five words are taken to be the most common associates of the word bee. Because associations can differ from person to person, you may not have the same five items in your list. However, if we asked 100 people to create a list, we can be reasonably confident that these items will still be the most frequent to appear. Clockwise from the top, these are the most frequent responses given to the prompt BEE in Nelson, McEvoy & Schreiber's (1998) well-known study. What's important to notice here is that we've generated a list of associates that reflect a variety of different relationships between the items in the set, only one of which is based on similarity ( wasps are similar to bees ), and one that calls out the bee's category specifically ( insect ). So while associative relationships may be categorical relationships, they need only reflect patterns of co-occurrence in the participant's mind. What I care about as an IA researcher is that these patterns often reflect meaningful information: Bees sting , they make honey , and they live in hives. Moreover, the differences between association and categorization are not merely theoretical. Rather, scores of studies have shown that, on cognitive or language-based tasks, things like processing efficiency can vary as a function of whether people interact with associated information versus categorized information. I'm not suggesting these findings would predict measurable differences in how users engage with site navigation when menu items are organized associatively versus categorically, but I do think the data suggests the need for careful consideration. What's next I believe the association studies can help IA research in at least two important ways: First, they can provide evidence of non-categorical relationships between candidate navigation items that might be missed in a card-sort study. At a minimum, such insights can provide researchers more information about users' mental models. Second, they can provide additional validation for groupings that might emerge in card-sorting data, indicating potential alternatives for splitting the data in a way that more closely matches users' expectations. Here at HubSpot, we're looking at how to incorporate association research into our IA research program. In doing so, we're heading into uncharted UX territory, and we expect we'll have to update our thinking accordingly. As we refine the methodology and collect some instructive data, we'll be sure to share our findings here again. Readers are encouraged to review Nelson and colleagues' original research to learn the finer points of how to conduct an association study (which, like card-sorting, is simple and can be done with just a pencil and paper) and of how to compute association strength between words (which requires little more than addition and division). And as always, check back with us for updates. References Battig, W.F. and Montague, W.E. (1969) \"Category Norms for Verbal Items in 56 Categories: Replication and Extension of Connecticut Category Norms.\" Journal of Experimental Monograph , 80, 1-46. Nelson, D. L., McEvoy, C. L., & Schreiber, T. A. (2004). \"The University of South Florida free association, rhyme, and word fragment norms.\" Behavior Research Methods, Instruments, & Computers , 36(3), 402-407. Penta, D. (2019) Reflections on Card Sorting for SaaS Navigation Research . Invited talk, Emerge Event Series #1: UX Research Team Building & Tactics: Wayfair Headquarters, Boston, MA. Oct. 8. https://emergeseries.splashthat.com/", "date": "2019-12-03"},
{"website": "Hubspot", "title": "Three Key Ingredients to Make Your Business Experiments Better", "author": ["Klajdi Turlla (He/Him)"], "link": "https://product.hubspot.com/blog/running-business-experiments", "abstract": "Experimentation can be scary for business teams. That is why a lot of business experiments end up being multi-year projects that are followed by very heavy change management processes. While that can give a sense of security and risk mitigation, it makes it very hard to predict, , measure, and control the success of the changes. On the Flywheel Product team we are always tweaking HubSpot’s go-to-market operating model to get desired business results. We apply a product and engineering approach together with a business approach to increase the productivity of our sales, marketing, and services team and help our customers grow better. In order to do that we constantly need to balance business experimentation with the needs of an increasing go-to-market team and customer base. Businesses of HubSpot’s scale need to keep a sense of predictability, as well as an ability to forecast revenue and reduce disruption on the go-to-market team. So, how can you constantly keep experimenting with your go-to-market operating model to get the desired business results as your company continues to scale? These are some of the main lessons we’ve learned from our experience with business experiments: 1. Experiment design For a business experiment to be successful, you need clarity and alignment. A lot of complexity and issues stem from not having a good understanding of the problem, the goal, and the experiment itself. That is why it is crucial to have a clearly articulated problem statement, objective, hypothesis, north star metric, and KPI breakdown. Having a good north star metric, though, is not enough. North star metrics drive alignment but they don’t provide clarity on what the experiment is about. That is because north star metrics are lagging indicators and impacted by many factors. For example revenue might be impacted by a recent change in quotas, and at the same time the marketing team might change their advertising spend for the quarter. So it is essential to have a good breakdown of that high-level outcome indicator to input metrics you can control and influence with the experiment. Here are some steps you can take to clearly communicate your experiment and align teams around it: Build a Business Experimentation Framework: This doesn’t have to be a rigid process but rather a collection of steps and artifacts that incentivize healthy discussion, clarity, and alignment. Some main items the framework could have: Initial Research (Quant/Qual): This should be mix of qualitative and quantitative insights that highlight the problem and opportunity area. Experiment Template: This is the main artifact and the heart of the experiment. It includes the objective, hypothesis, prediction, etc. While simple, this tool is a very powerful way of incentivizing conversations and alignment. Questions: This is the greatest strength of the template. It's not only about filling the template, it's how you do it. It's the discussions you have with the team, the questions you ask to get you where you want to go. A few examples of powerful questions: What is the problem here? What are we trying to achieve? Is that really our objective? What evidence do we have of this problem? These questions should lead to the sections below: Clear Objective and Hypothesis: Agreeing on a clear objective and hypothesis for your experiment is critical. It will drive most of your decisions down the line. North Star Metric: This is the main outcome we want to drive. It’s usually a high level KPI like revenue, productivity, or acquisition rate. While this can be easy to agree on, the difficulty is in the next step: KPI Breakdown and Proxy Metric: This is crucial for an experiment to be successful. This should lead to a collection of input metrics that are more controllable and that we can experiment with to quickly see impact. Here are a few experiment templates you can use: HubSpot Flywheel Product Business Experiment Template Ash Maurya's Experiment Canvas Ben Yoskovitz, Lean Analytics Takeaway: There is much more to the Experiment Framework, but building and testing an experiment template is a good start. The template itself should then drive and highlight most other areas of the process. 2. Project management: Start small Business experiments tend to be more complex and require some level of project management. This gets harder the bigger your change and experiment is. But instead of trying to nail project management, we asked ourselves if we can start smaller. Starting small might be more applicable than you think at the beginning. There are multiple ways to define small. For example, the number of regions you are running the experiment in, the number of users in the experiment, or the size of the change being implemented. We found that in most cases we were good at starting small on the region and users aspect, but we didn't always start with the smallest change in the product. Here are some steps you can take to make sure you are starting small: A. Start with the smallest change possible: This shouldn’t be limited to the region or people impacted but also to the product changes. Mockups: This is the first potential change that should be considered. This could be a simple product design, a simple dashboard or sales process, a Looker report, etc. Anything that can give an indication of the change and that can solicit feedback from users. Manual changes: When mockups can’t do the job, try to use the tools you already have in place with some manual steps is an option. Small changes with limited user base: Implementing the most impactful and riskiest change to a small user base is another option. B. Define small: While the above might sound fine, the difficulty is how to define if a planned change is small enough and what the smallest change for a given project is. List and rate your assumptions: Identifying the riskiest and highest impact assumption will force you to focus and build the smallest thing to validate that assumption, versus building something that validates multiple assumptions. Ask \"Is this small enough?\": Making sure we ask this question is a good start. It's easy yet powerful. The higher the uncertainty, the smaller and lower fidelity the change should be. This graphic from Sam McAfee illustrates this: Here are a few tools you can use to start small: Riskiest Assumption Canvas Sam McAfee on Identifying your Riskiest Assumption Dan Olsen's legendary MVP Framework Takeaway: Starting small is crucial. When your level of uncertainty decreases and you've got lots of learnings from your experiments, you may be ready to implement change globally. This is when you start using your Project Management toolkit. 3. Stakeholder and strategy alignment When you change the go-to-market operating model, there is a good chance a lot of people in the business will get interested in it. Whether they are curious about the opportunity or trying to make sure on how they are impacted, they will want to get involved. While high interest is great, it may lead to a working group which is too big to manage effectively, making it difficult to make decisions. You will need a lot of pizzas in those meetings. Worse, it could make it unclear who the decision makers are, leading to even less clarity. Here are some steps you can take to avoid this: Create a small decision-making group: While you cannot avoid involving a lot of people in a business experiment, it’s crucial to have a small group that can make decisions independently and quickly. As former COO JD Sherman wrote of HubSpot , “If we want to really make a difference, and truly achieve our mission of helping millions of organizations grow better, we have to be both big AND fast! That requires us to constantly evolve HubSpot’s operating system, and it requires a bunch of smart folks who get fired up about data and dashboards.” Make it clear who has the final say: Having a small decision-making group is a good start. As the need to make final calls and trade offs is always there, having someone whose job it is to make those decisions is helpful. Communicate what is being experimented: The Experiment Template can help a lot here. What's most important is knowing who we need to communicate our process to. It’s important to note here that the smaller you start, less disruptive the experiment will be, which should ease the need for communication to a wide audience. Takeaway: Starting small and having the experiment template filled should help with stakeholder and strategy alignment, as well as communication. Otherwise, when enlarging the scope of the experiment, having a small decision-making group who has the final say will make things go faster. These steps will help your product team and business move faster in improving the go-to-market operating model. It will also help foster an environment of learning and a thirst for experimentation. If you are excited about solving complex business challenges and optimizing go-to-market strategy through product, head over to our product careers page . At HubSpot we are constantly learning and improving our product craft. I’d love to learn how you run business experiments in your company. You can connect with me on LinkedIn . I’d love to connect and continue the discussion.", "date": "2020-09-17"},
{"website": "Hubspot", "title": "Architecture of a Java Agent to Inject Chaos", "author": ["Clayton Stout (He/Him)"], "link": "https://product.hubspot.com/blog/architecture-of-a-java-agent-to-inject-chaos", "abstract": "Chaos testing at HubSpot came from the needs of our site reliability (SRE) team. We needed to test fault tolerance in the face of service to service call failures. Our main concern was upgrading our core databases from legacy MySQL to Vitess. We were skeptical about the failure mechanics of Vitess. We wanted to ensure they would be compatible with legacy MySQL mechanics. To test, we needed to inject failures into many calls between services in our stack. Though we’ve previously undergone failure testing efforts , we recognized an opportunity to provide reusable tooling for future engineering efforts. Our SRE team could not intervene with every team that wanted to set up failure injection. We landed on the decision to write a custom java agent. Several HubSpot-specific environmental conditions led to this solution. HubSpot is a monoglot ecosystem, and we write all backend services in java. Thus we could write a single java agent and use it throughout our backend system. We maintain our own custom HTTP client wrappers that handle all internal requests. Existing wrappers provide features such as rate limiting, circuit breaking, and automatic retries. Adding failure injection capabilities to this list was thus straightforward. We use common deployment tooling, which makes it very easy to attach java agents to APIs. You can read more about the choices that allow HubSpot to manage our thousands of microservices here. One quick point ⁠— one might well conclude that we could skip over the java agent route. Instead, we could include some code in our existing shared HTTP client implementation. We did consider this route but two things stopped us from proceeding further. We want to inject failures as close as we can to the socket connection point. This is to ensure that failure injection mirrors reality as closely as possible. HTTP client decorators, however, execute much further up the network stack. Besides the common HTTP client, we also maintain separate application-specific clients. We use these clients to connect to things like MySQL, Vitess, and Memcached. We want to use a common framework for failure injection in all these places as well. We will discuss several architectural choices made when implementing our failure injection framework. Specifically, we will cover: Java Agents : What they are and why we chose to use javaassist. Failure configuration : How we define the different failure scenarios we want to support. Thread State : How we maintain state in the various thread contexts of service calls. Also, how we propagate that state across async boundaries. Java Agents Overview Java agents provide a powerful API for intercepting class loading. They allow us to inject custom byte code into the JVM. Profiling applications, exporting metrics, and adding logging are typical use cases for java agents. HubSpot's Use Case We used the ability to inject bytecode for two general use cases: Storing service to service call metadata Injecting failures into the networking call stack To store metadata we pull out variables passed to specific methods. We then store those values in the internal state of our failure injection library. To inject failures, we add code around the boundaries of all network calls. This added code in turn calls our failure handling logic. The handling logic reads the previously written state. It matches that state with failure configuration. The logic then determines what particular failure if any, to inject. Deployment Strategy We chose to deploy our agent by packaging a jar and publishing via RPM. This allows our puppet code to manage versions and install the jar on all our machines opaquely. The size of the jar was incredibly important since all running services would load it. While we have tackled issues with large jars for application use cases , it is still a problem for our RPM artifacts. To help, we decided to additionally package a separate failure injection library. We then add this library as a runtime dependency of any service using the agent. Thus, the agent can rewrite byte-code by adding hooks that call out to static methods in the library. This strategy allows us to adequately balance concerns. We keep the agent's packaged jar size very small. The library, though, is still robust and well-tested. It contains the code to handle all the actual failure injection mechanics. Why Javaassist There are other more robust technologies for manipulating byte code ⁠— namely byte-buddy. We, however, chose to pursue the more lightweight javaassist library. It does not have the benefit of type safety, but it still provides a powerful API for injecting custom byte code. The type-free nature of javaassist means that we can limit our dependencies. In practice, our agent only depends on org.javaassist:javaassist. It has a total packaged jar size of roughly 32Kb. Failure Configuration Introduction We began by thinking about the mechanics of how failure injection would work in practice. There were a few considerations that would influence the final product. First, we needed to decide which failure types to support. Next, we had to consider the proper level of granularity on which to define failures. This included how exactly to specify targets in our configuration. Finally, we decided how we would allow users to update the failure configuration. We will explore the options we considered. We will also discuss how our choices influenced the final implementation. Different Failure Scenarios When writing our failure injection agent, we began by enumerating scenarios to replicate. We started with the simplest failure event — a request flat out failing. The next ability we considered was adding latency to API calls. We soon realized that we also want to combine these two. A combination would look like added latency before eventually failing a call. The final scenario we considered was a bit more subtle but very interesting. We had seen issues when POSTing to endpoints on a poorly behaving external service. Particularly, we considered the case where a client POSTs data to a service. Then, that service is slow to respond, causing our client to timeout its request. Finally, the service continues processing, eventually succeeding. We illustrate this series of events below. To simulate this scenario we needed a way to define where to inject failures or latency. The injection point itself needed to be configurable. We needed to place it either before or after making the request. How to reference a service Our next consideration was what level of granularity we wanted to support. Our deployments run a given service as two different deployables — userweb instances that handle all user traffic and web instances that handle all internal API requests. This split lets us maintain low latency SLAs for our user-facing APIs. Our internal backend services call an entirely separate deployment. Each of these deployables runs many instances behind a common load balancer. This gave us the option of defining failures at a service level, a deployable level, or an instance level. We opted to support failures for deployables. This gives us a high level of granularity but simplifies configuration for users. It allows us to specify failures differently for user vs service-facing deployments. However, we can still do so in a human-readable format. Types of config Finally, we needed to decide how exactly to update this configuration. Our general configuration model at HubSpot involves a tiered key-value store . Deployments read from the config store and apply matching values to populate config. They also poll to update values so that service reboots are not required. Generally, we apply new config values within minutes. We discovered an issue with the longer latency (on the order of minutes) config updates. That failure injection config is not as useful for unit tests as it is for long-running services. To clear this hurdle, we added a second method of driving config. We allowed users to set failure injection values via code, storing values in memory. We could thus define the configuration for a single unit test. Afterward, we would clear the configuration following the test run. These two approaches work well for scenarios following a common pattern: Add configuration Run some tests Remove configuration The problem with this approach is limiting the scope of impact when running a live service. To target at a more specific level, we decided to support a similar configuration via a REST header. This choice allows us to set the failure conditions we want to see for a particular request. We can then issue the request and witness the response returned. To handle any conflicts with config values, we process from the most to least specific values. We give first priority to headers that define config for a given request. The next priority is the dynamic in-memory value that defines it for a given instance. Finally, we process the configuration value defining failures for the entire deployable. Example The java representation of our failure config looks like this: Examples of the configuration representation in json: Thread Context Background We want to inject failures as close as possible to where we establish a socket to another service. This causes an interesting problem when reconciled with the actual code structure. Our HTTP client wrapper maintains the metadata about the service we are calling. By the time we are in the java networking code, we lose this context. At the socket level, we only have access to the literal InetAddress. We therefore introduce state management to manage this discontinuity. The state keeps metadata available to the actual failure handling code. Our java agent initiates this failure handling code in the low-level networking stack. Thread Locals For state management, we rely on thread locals. Thread locals are a java wrapper type with special properties. Every time code accesses the variable, each thread will have its own copy. Essentially the wrapper stores a map of thread ID to value. It then sets and returns the value depending on the calling thread's ID. This construct is useful for maintaining thread-specific state ⁠— exactly what we need. Example of thread locals in practice: Thread context followers Thread locals run into problems when we use async HTTP clients. Async clients often put work onto a separate thread pool. We lose all our state we initially stored. Luckily, at HubSpot, we already solved this problem when implementing request tracing. For that use case, we need to supply and propagate a trace ID. Each request would get a unique ID and forward that value across any async boundaries. We manage this by implementing the interface ThreadContextFollower. This interface has methods for getting and setting thread context. Our in-house executor service factory implementations maintain a hook that invokes the interface. With the pattern already formalized, it was simple to solve our problem. We could create a new implementation of the ThreadContextFollower interface. This implementation is specific to the failure injection use case. It allows seamless transfer of all the state we need. Putting it all together When we add up all these individual pieces we end up with a robust failure injection agent. Users can define failure config to add latency and/or fail requests. This failure can occur either before or after making those requests. Our java agent injects code that stores call context for external requests. We store this context in a ThreadLocal variable. Our ThreadContextFollower then forwards that state across async boundaries. When we start the socket connection, we call our failure handling code. The code matches the current state with the supplied failure injection config. If we find a match we introduce a failure depending on the particular configuration. The failure consists of either added latency, outright failure, or both. This architecture provides a full-featured failure injection agent. This agent allows HubSpot to begin with Chaos testing across our fleet of services. Interested in working with a team that's just as invested in how you work as what you're working on? Check out our open positions and apply .", "date": "2021-05-19"},
{"website": "Hubspot", "title": "How to Build Sustainable Word-of-Mouth Demand Through Your Users", "author": ["Eric Peters (He/Him)"], "link": "https://product.hubspot.com/blog/how-to-build-sustainable-word-of-mouth-demand", "abstract": "“How do I build a product that sells itself?” This is a question that I’ve thought a lot about ⁠— I’ve studied companies that have seemingly answered it, and my team and I have made it a priority in our work. As the product team working on the HubSpot Academy application, our job is to create an experience that teaches new users business topics grounded in the inbound methodology, enables them to build their expertise in both theoretical and technical subjects, and hopefully, become advocates for HubSpot and the inbound methodology. Still, I can’t say that I have the answer to that question quite yet, but I have consolidated my observations into a few principles that are the basis for this post. The flywheel model that we teach in HubSpot Academy describes our ideal user cycle well. In this model, we “attract” new users, “engage” them to build trust, and if they’re a fit, sell them our product. If we can “delight” them  enough with that product, then they’ll become promoters and recommend it to their peers. Simple enough, right? All too often, product teams don’t see the potential value in activating their customer base to attract more customers, or if they do, they have a difficult time executing on measurable, product-led experiences that enable it to occur naturally. My intentions for this post are to help you create user experiences that turn your customers into your biggest marketing team, your most helpful support reps, and your most efficient and consultative sales team ⁠— all of which are hallmarks of product-led companies. In this post, we’ll cover three principles of driving product-led word of mouth demand. These principles are ways in which we can somewhat predictably build digital experiences that make our users not only want to tell their peers about our product, but also support their peers in the onboarding and use of our product, which is equally important. Three principles of product-driven word of mouth demand 1. Exceed expectations with delight moments Your prospects are coming to your business with different perceptions of what your product does. Some may have clicked through a targeted ad and only read a few lines of ad copy, others searched on Google and read reviews written by your customers, and others heard about it from a trusted friend or colleague who is currently a happy customer. These example traffic sources come with varying levels of understanding and different degrees of perception for how your product will solve their problem. Take those three traffic sources for example: The ad copy users were shown a problem that they may or may not have, or know that they have. Only if they recognize and agree that they have that problem, are they likely to even click through. You’re going to really need to build up their trust to get them through signup and onboarding after that click. The Google search users are at least defining their own problem for themselves and trusting Google to sort solutions by popularity. There is some inertia behind that search because they’ve already decided to seek out solutions to their problem, but they’re still climbing an uphill research battle to motivate themselves to sign up and get started. The referral user has the massive benefit of a human who can identify the problem well enough to suggest a solution to them. Therein lies the incomparable magic of word-of-mouth referrals: a trusted human to identify the problem, and suggest its solution. Perception is key here, because until our users are active and engaged, that’s all your product really is to them: a perception. Their perception of our product is a combination of all the details they’ve heard about it, and not rooted in any experience of their own. As a product team, it’s up to us to figure out what that perception is, and what they expect when they sign up and start using our products. Managing expectations is our first principle of product-driven word of mouth demand. We need to exceed the user’s expectations and activate them through “delight moments.” We’ve all heard about “Aha Moments.” Aha moments are activation points for new users that tend to predict whether the user will retain long enough to get continued value from the product. Delight moments are the same, but for existing customers. They are activation points for existing users that tend to predict whether the user will refer the product to a peer. What’s happening in the mind of an already-satisfied customer who gets an extra dose of excitement about your product? I think it’s baked directly into our evolutionary DNA. We are programmed to tell our ‘pack’ when we’ve found something good (like a new source of food) or something bad (like an animal that sees us as a new source of food.) The “good” is really only worth talking about if it’s unexpectedly good , right? That instinct plays out in all of the products we interact with. When you read a great book, you’re not always going to tell your friends or colleagues about it. It might have been good, but when you got to that chapter that really resonated with you, you just had to tell someone about it. Better yet, when it resonates with a challenge a friend is having, you’re doing them a service in telling them about it. That little extra bump in motivation to share is what we’re aiming to create. The trick here might actually be throttling expectations up until the user hits a delight moment. Other times, you’re building something particularly exciting that purposefully goes beyond the expectations set by earlier interactions. These delight moments come to life in all kinds of features and interactions. Let’s take Zoom virtual backgrounds, for example. Zoom Virtual Backgrounds Long before Zoom and its virtual backgrounds became somewhat mainstream, this feature was hidden in the Settings menu. It only worked for some high performing computers, but when activated, it certainly grabbed people’s attention. If you are not familiar with it, Zoom’s Virtual Backgrounds feature creates a green screen effect that hides the user’s background and allows them to add a custom image or even video behind their face, hiding their background from view. When I first saw someone using this feature, I immediately wanted to try it out myself. I didn’t pay very much attention in that meeting, because I was Googling how to enable this feature. Maybe that’s just me, but I have to imagine I’m not the only one. After that, I would spend the first few minutes of every meeting having to explain to people how to activate the feature for themselves. It made me feel like an insider for knowing about it, and it certainly exceeded my expectations for what a video conferencing application should be able to do. The resulting impact of this feature is rapid adoption within an organization, and an army of users showcasing Zoom’s tech to meeting attendees who may or may not be Zoom customers. It broke through a barrier for what is the expected feature set of a video conferencing app, much like Snapchat had done in the consumer space a few years earlier with its early augmented reality lenses. The feature sparks an immediate conversation where the Zoom user is happy to discuss their nifty virtual background with the non-Zoom user. A true example of making a customer feel like an insider, and in doing so, activating them through a prideful delight moment to be your marketers, salespeople, and customer success team all in one. 2. Extend core functionality to enable social interactions This next principle is pretty simple, yet commonly ignored. In order for our users to naturally become advocates of our products, becoming advocates of our products needs to come naturally to them. This principle is the one I see most growth teams fail to realize in their products. There is a history of ‘viral links’ from the early days of growth hacking that still permeate many of our products. Simply adding a signup link to public parts of your product is not extending core functionality, and it could hurt the perception your users and prospective users have about your product. It may have worked for HotMail in the late 90s, but we as a society have moved past viral signup links and are generally well aware when we’re being forced to push products onto our peers. I think the reason this tactic has been used so much is that it’s relatively cheap to implement, so even a slow trickle of demand generated is seen as cost-effective. What most teams fail to see is how it can decrease trust in the product. There is no hard rule to adding viral links - it comes down to understanding what your users care about. If they want to tell their peers about your product, they’ll go ahead and do that, and they’ll probably sell it better than a signup link that tells the world they’re using the free version of your product. When it comes to freemium versions, you could rationalize that this viral “tax” is a form of payment for the user of the free product, or a motivator to upgrade, and some companies wield this friction amazingly well. The trick is to know your users and their perception of your product well enough to balance “value for the user” and “value for the business.” The way I see it, the freemium version of your product has one job: build enough trust and value for free users to enable them to make a case to upgrade to the premium version. You can do that by actively making the premium version notably better than the freemium version, or by actively making the freemium version notably worse than the premium version. Your users and I much prefer the former, and in the meantime, let us create as much value for ourselves with the free version until the cost-benefit of the paid version makes cents (pun intended.) 3. Create value for your user and their peers The user interactions that drive word of mouth demand need to add tangible value for both the referrer and the referee in order to work. Network effects, wherein the network or community as a whole becomes more valuable as more people join it, is a macro example of this principle. Inviting more users to a community makes the community more valuable to everyone in it. In our products, we can design interactions that play out in a similar way, but at a much smaller scale. Ask yourself: “How can I increase the value of my product to User A in order to motivate them to share it with User B?” You might notice that this third principle is a combination of the first two ⁠— where we manufacture a delight moment that exceeds the user’s expectation in order to motivate them to share, and then create a very natural way to do so that results in value generated for both the existing user and the new users. We can’t just force our users to share our product, we have to give them a legitimate reason to do so. Fare splitting features in a ride-sharing app are a great example. Rideshare Fare Splitting At first glance, a ride sharing app’s fare splitting feature seems like a pretty basic part of any ride sharing application, right? Therein lies the cleverness of this feature. A ride sharing service’s job is to make it as easy as possible to get from point A to point B. More often than not, it’s not just you in the car, though, and therefore splitting payment with your guest under the time constraint of your ride is the perfect opportunity to invite a new potential user to the app and get them through the highest friction point in the onboarding journey: adding payment details. In this case, fare splitting is not necessarily introducing user B to the concept of ride-sharing (the car showing up magically would have likely done that), but requiring User B to download the app and add payment information while driving to the destination , with another person in close proximity really motivates User B to sign up. The value for User A is that they pay half the cost of the trip, and the value for User B is the easy calculation and payment of the split bill. If User B wasn’t a user when they entered the vehicle, they are when they exit it. The fun thing about this feature is that it gets more psychologically motivating with more users in the vehicle. If there are three people in the car in addition to User A, who called the ride, and two of those people have the app and have accepted the request to split the fair, the chances that the third rider is going to sign up and join the squad are much higher. Final thoughts If you are currently working on a product and looking to answer the question “how do we make this thing sell itself?” then you may consider asking yourself how your product stands up against these three principles: Is there a moment in the user journey where users tend to share it most? Why are the users who are advocating for it doing so? Is sharing a natural part of your product’s core functionality, or are you asking users to go out of their way to become advocates? And finally, does your product become more valuable to your users when they tell their friends about it? If you can check off all of these boxes, you’re on your way toward a product that can propel its own flywheel and generate its own demand. Want to work with a team whose products sell themselves? Check out our open positions and apply .", "date": "2020-12-15"},
{"website": "Hubspot", "title": "HubSpot Development's New Digs", "author": ["Samuel Siskind"], "link": "https://product.hubspot.com/blog/hubspot-developments-new-digs", "abstract": "The HubSpot Dev Team has grown tremendously in the past two years, going from a team of 40 engineers and designers to over 100. We had the opportunity to create an entirely new space for the team when some offices opened up in our building, so we decided to go for it: to build a space that we could call our own. Check out our new space with us in the video below:", "date": "2013-06-18"},
{"website": "Hubspot", "title": "An Insider’s Guide to the Grace Hopper Celebration", "author": ["Rose DeMaio"], "link": "https://product.hubspot.com/blog/an-insider-s-guide-to-the-grace-hopper-celebration", "abstract": "The 2015 Grace Hopper Celebration is less than a month away and women from all over the country are getting ready to take over Texas, see as many talks as possible from speakers like Sheryl Sandberg, and meet a ton of new people that are passionate about product development. If that sounds awesome, it’s because it is. I’ve been to GHC a few times with Northeastern’s Women in Tech group, and am lucky to be leading a Student Lab Opportunity discussion this year and attending with a few coworkers. If this is your first time heading to GHC, with all that there is to do and see, knowing what to expect is key. (Hanging out with me, Jen , Ollie , and Danielle at the HubSpot booth in the Exhibitor Center is, too, but I might be a little biased.) So as we’re all preparing and packing over the next few weeks, I wanted to share some tips with first-timers for making the most of your time at GHC. Caffeinate Early and Often I’ve done the important research, ladies. There is only one Starbucks in the entire conference center. You know what that means: lines on lines on lines. You don’t want to miss out on a session because you couldn’t keep your eyes open or were waiting for coffee, so grab your morning cup of joe before you get there. There will be thousands of people at GHC who will be hitting up the nearby coffee shops, so if you need an afternoon pick-me-up, factor a few extra minutes into your travel time. Charge Up Most conferences have pretty sweet apps that provide session agendas, maps, and tons of other information you’re going to want on-hand. If you plan out your day in the app (which you definitely should, so download it here ) and your phone dies, it’s going to be a pain to flip through the conference booklet while you’re on the move. Plus, if you’re rolling in with a great crew of co-workers, friends, or classmates, you don’t want to be the one person who missed out on the details of a pop-up event by Google later that night. (Follow the #OurTimeToLead stream on Twitter to follow updates and conference play-by-plays.) I recommend carrying your charger in your bag at all times, using charging stations throughout the conference center when you get some downtime, and if you want to get really crazy, buying a chargeable case. Layer It On Though you’re flying to Houston for GHC, remember that you won’t actually be out in that Texas heat for most of your trip. Conference centers like to blast the air-condition so pack your favorite sundresses but make sure to grab some sweaters or scarves to layer on during the events and sessions. It's so much easier to focus on what speakers are saying when you’re not counting the goose bumps on your left forearm. Have an Agenda There will be a lot going on at GHC so having a plan for each day is important. You don’t want to find out there’s a talk that’s right up your alley ten minutes before it ends. Set aside half an hour ahead of time to go through the GHC schedule , pick out which events you absolutely don’t want to miss, and make your own agenda either in the app or on your Google calendar. I recommend showing up 20 minutes early for talks that are high on your list just in case there’s a line. If you’d rather not wait, choose backup sessions to go to in case your original plan doesn’t work out. Break the Ice Whether you’re waiting in line, sitting in a session, or walking around the convention floor, make an effort to meet the people around you. GHC is a magnet for bright women in CS from all walks of life so you could learn as much from conversations with attendees as you will from sessions. I know “networking” always sounds a little intimidating, so just remember that you already share common interests with pretty much everyone there. All you have to do is break the ice with a simple “Which speakers have you seen so far?” or “Who’s giving out the best swag?” Have Happy Feet Conference centers are huge and since GHC has a deep bench of noteworthy speakers and topics, you’re probably going to spend most of the week booking it from session to session. So pack comfortable shoes. If you’re dressing up for interviews, consider wearing black flats that are practical and appropriate. Otherwise, stick to your trusty Chucks. Be R ésumé Ready Hundreds of great companies will be at GHC’s Career Fair looking to meet new talent. So if you’re in the market for a new opportunity, make sure to print a bunch of copies of your résumé before the conference. Even better, bring them in a folder and make sure that whatever bag you bring has enough space to store said folder. It’s frustrating to carry around multiple bags and you don’t want to worry about handing a crumpled résumé to a company you're trying to impress. Keep in mind you’ll probably have a swag bag full of stuff to carry, too. (Pro tip: swag bags are identical so tie something unique to the handles so you don’t lose yours or take the wrong one.) Stay Hydrated Drink water. And then drink some more water. It sounds obvious but sometimes travel or a new routine can make it easy to forget the little things we do to take care of ourselves. Chances are, you’ll be heading out for some late evenings, so stay hydrated throughout the day to keep your body primed for long days of learning, networking, and being on your feet. (Luckily, conferences are great for free swag so if you can, snag a water bottle from the Exhibitor area to fill up throughout the week.) Step Away From the Laptop If you *really really* need to do some work, bring your laptop. Otherwise, try to minimize the extra weight and let yourself get totally immersed in the event. You’re there to meet people, hear about their experiences, and enrich your own academic and career path. When you get back to normal life and people ask about GHC, you don’t want to talk about the project you finished but about the talks you loved, interesting discussions you had, and new people you met. Get Some Air Though they’re a blast, action-packed days can feel pretty long. So every now and then, or when there’s some downtime between sessions, get outside. Dipping out of the convention center for a breath of fresh air will recharge you and remind you that you’re in a cool new city. A quick Google Maps search tells me there are a ton of restaurants within a few blocks of GHC. Pick one for lunch one day or grab something quick and eat outside in some green space nearby. Take It All In This one is sappy but remember to stop and take it all in. At my first GHC, I remember feeling so overwhelmed by how awesome it was to be surrounded by so many people who weren’t surprised by the simple fact that I am a software engineer. These are your people, this is your community. So bask in it and enjoy the fantastically good vibes flowing at GHC. If you have any other GHC tips, or have a question about the conference, please let us know in the comments. We hope to see you in Houston! Big thanks to Allison Ventura, a fellow Northeastern alumni and HubSpot software engineer, who shared her GHC experience here, too.", "date": "2015-09-21"},
{"website": "Hubspot", "title": "Jordan Smith is a HubSpotter", "author": ["Elizabeth Dunn (She/Her)"], "link": "https://product.hubspot.com/blog/bid/86225/jordan-smith-is-a-hubspotter", "abstract": "Name: Jordan Smith Role: Developer at HubSpot Superpower: Milkshakes Jordan Smith is on the Partner Products team at HubSpot, where he's building a closed-loop analytics app for paid ads (Facebook, AdWords, et al). It's a HubSpot Marketplace app built with the standard HubSpot Django / mySQL stack, and it helps customers figure out how much their paid leads are really costing them. It's insanely useful, in other words. Jordan hails from what we Northerners insist on referring to somewhat vaguely as \"the South.\" You can tell he's from \"the South\" (he says) because he loves biscuits and gravy, hates wearing shoes, and dreams of opening a Chik-fil-a, Waffle House, or a Krispy Kreme restaurant in Cambridge. Possibly all under one roof. On the other hand, he doesn't have any sort of a definable accent and considers college football to be merely \"tolerable,\" so we're not really sure what to make of him. HubSpot is Jordan's second startup after a brief stint as a blackjack dealer in Lake Tahoe. His hobbies are chocolate milkshakes, trying to read the entire Internet every day, playing ultimate frisbee, and rock climbing. Follow Jordan on Twitter at @jodansmif .", "date": "2012-05-01"},
{"website": "Hubspot", "title": "Cheap videoconferencing for our daily standup, part deux", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/70630/cheap-videoconferencing-for-our-daily-standup-part-deux", "abstract": "We like to release early and often.  Start with a minimally-viable product (MVP), get feedback on it, and improve it rapidly. Yesterday I put up a short blog post on how we're using the Google Plus \"Hangout\" feature to have a daily Scrum standup with remote team members.  Today I want to post three more fun pictures, showing multiple remote attendees, and the fun we can have when we project the Hangout onto one of our IdeaPaint walls. First, this is @ojrac painting a face on the IdeaPaint wall, where @skastel is currently delivering his standup: Next, we have @skastel stopping for a coffee break, while Parker waits patiently... Finally, note that standup is not just for humans.  Tena, one of our developer's dogs, joined today's standup as well.  She's on the small screen in the middle.  Sorry for not getting her on the main screen.  On the plus side, you get a bonus shot of \"The Real\" Ben Smith .", "date": "2011-08-05"},
{"website": "Hubspot", "title": "Our Platform Ecosystem Is Becoming a Platform Economy", "author": ["Hugh Durkin"], "link": "https://product.hubspot.com/blog/our-platform-ecosystem-is-becoming-a-platform-economy", "abstract": "Platform companies like Facebook and Shopify are the product of fascinating evolutionary stories. Mark Zuckerberg wasn't thinking of AR/VR when he set up Facebook in his dorm room. He started with a simple directory to find college students on campus. Tobi Lutke probably didn't ever imagine spending $450 million dollars for an AI-powered fulfillment network when he started Shopify. All he wanted to do was figure out an easy way to sell snowboards online. Yet both founders created companies ⁠— platforms ⁠— that grew far beyond anything they ever imagined. That’s because platforms are never designed upfront. They evolve organically over time. And because true platform companies don’t just build products ⁠— they create entirely new economies. Zuck and Tobi aren't just product builders — they're economy builders. Platform economies accelerate the global economy A 2020 study by Copenhagen Economics estimated the economic impact of Facebook Apps in Europe at €208 billion. Separately, Analysys Mason evaluated the impact of Facebook’s investments in connectivity across Africa and ASEAN. It estimated these investments to deliver over $200 billion in economic benefits . Today, Facebook’s market capitalization is just over $800 billion. Add the impact of Facebook across other major economic regions in the world — including the Americas — to Europe, Africa, and ASEAN.  The value of the economy around Facebook is worth far more than Facebook itself. That’s economic impact in the financial sense. Let’s talk about job creation. In 2019 Shopify made $1.5 billion of revenue. That same year, Shopify estimated their partner ecosystem generated $6.9 billion . Over 80% of Shopify merchants use apps built by 3rd party developers. It took Shopify nine years to pay the first $100m to these app developers, but just one more year to reach $200m. If developer revenue growth is impressive, job creation growth is beyond impressive. Shopify employs over 5,000 people. The Shopify Partner Economy employs over 2.1 million people . For Facebook and Shopify, their evolution from single product companies to platform economies is pretty much complete. Though it’s still early days, signs from this year suggest we're on a path toward building a similarly impactful platform economy around HubSpot. According to a white paper from IDC , the global HubSpot partner ecosystem is projected to grow from $4.8 billion in revenue in 2020 to $12.5 billion in 2024. 34% of that revenue will come from add-on software. By 2024, $4.2 billion worth of add-on software will be purchased from the HubSpot ecosystem. HubSpot has created a new, fast-growing software economy. Fast-growing economies create fast-growth companies, built by fast-moving entrepreneurs. Platform economies need Ecosystem Entrepreneurs In early 2019, just a handful of what we now call “Ecosystem Entrepreneurs” had a place in the HubSpot App Partner program . Ecosystem Entrepreneurs are specialist creators building products that may not exist if HubSpot did not exist. They help us expand our “ collective brain ” beyond our core team at HubSpot, to understand customers and create niche solutions for them. Today, more than 110 apps and integrations listed in the App Marketplace have been created by Ecosystem Entrepreneurs. These creators are increasingly diverse and increasingly global. In February 2021, the majority of newly-listed apps and integrations in the App Marketplace were built by partners based outside the United States. Ecosystem Entrepreneurs are building tools to help customers grow better with HubSpot, from all over the world. These Ecosystem Entrepreneurs understand our customers incredibly well. Many take a friction-free, “try before you buy” approach to selling their products⁠ — by providing an “always free” tier or free trial. These new Ecosystem Entrepreneurs sell the way our customers like to buy ⁠— and customers are buying what they're building. Why are Ecosystem Entrepreneurs so good at understanding what customers need? Because many of them start their journey with HubSpot as customers. OrgChartHub is one of my favorite examples of an Ecosystem Entrepreneur. In late 2019, Dan and Austin ⁠— OrgChartHub’s two founders ⁠— quit their day jobs to focus entirely on building apps for HubSpot customers. Those day jobs helped them learn about HubSpot ⁠— they’re power users ⁠— and this experience helped them understand innovation opportunities. Dan and Austin didn’t need to be sold on HubSpot, or the App Partner opportunity. In fact, they saw a multitude of opportunities to create value for HubSpot customers. Their second app, GeoMapper , has already earned over 2,000 installs. That’s in addition to the 3,000 customers who have already installed OrgChartHub. Each app has earned mostly 5 star reviews. Each app has pricing plans and tiers that feel similar to ours. Both apps have “forever free” pricing plans. Ecosystem Entrepreneurs are specialists Economies need entrepreneurs to grow and prosper. For example, in Ireland, around 15% of people employed in the country are employed by public services ⁠— by our government. Another 15% of people employed in Ireland are employed by multinationals, like HubSpot. The remaining 70% are employed by or own small and medium-sized businesses. We wouldn’t have an economy without them. In many ways, Facebook and Shopify share similarities with traditional economies like that of Ireland. Their employees lay the foundations of the economy, ensure services are run efficiently (most of the time), and ensure policies are equitable and fair. For Facebook and Shopify, “strategic partners,” like Stripe and Apple, are akin to multinationals. Relationships that create incremental value for everyone, but with an upper limit to the number that can be attracted to join the economy. It’s the Ecosystem Entrepreneurs ⁠— the 70% ⁠— that pour fuel on the fire of economic growth, and help create better experiences and outcomes for everyone. The 2.1 million people directly or indirectly employed in the Shopify Partner economy are not all that different from those who work in coffee shops, hair salons, farms, and retailers across Ireland. They’re all specialists, and each one of them understands the needs, quirks, and nuances of their customers better than anyone else. From citizens to entrepreneurs In the same way that citizens of Ireland create small businesses within the country, Shopify and HubSpot’s app partners increasingly start out as customers. Customers of today are Ecosystem Entrepreneurs of the future. And each will experience a founder's “magic moment.” When I started my first business in 2004, the biggest hurdle was the process of opening a merchant account. Getting to that “magic moment” ⁠— being able to collect money from customers online ⁠— took time. A visit to my bank, a meeting with the manager, sharing my business plan, and a long wait for approval. Today, that “magic moment” happens minutes after visiting Stripe.com. For developers on Shopify, that “magic moment” is when an app is finally accepted into their marketplace. Because Shopify accepts payments on behalf of these creators, they're quite literally providing merchant accounts and removing friction from the process of creating an entirely new business on their platform. Even better, those “magic moments'' are shared on social channels like Twitter and Facebook, which, in turn, attracts more creators. The flywheel spins ⁠— and speeds up. HubSpot’s Ecosystem Entrepreneurs share their “magic moment” with others on social channels like Twitter and Facebook, too. Earning attention⁠ — through the HubSpot App Marketplace⁠ — from over 100,000 HubSpot customers is clearly something worth shouting about. With almost 700 apps and integrations listed today on the HubSpot App Marketplace, we're far closer to the beginning than the end of our journey to grow the HubSpot platform economy. And, though we can’t predict the innovative solutions our next 5,000 Ecosystem Entrepreneurs will create, there's one thing we can be hopeful about ⁠— that our platform economy will be as diverse tomorrow as our global customer base is today. Interested in working with a team that's just as interested in how you work as what you're working on? Check out our open positions and apply .", "date": "2021-03-30"},
{"website": "Hubspot", "title": "The Four Minds of a Product General Manager", "author": ["Lou Orfanos"], "link": "https://product.hubspot.com/blog/four-minds-of-a-product-general-manager", "abstract": "Two years ago HubSpot made the decision to create General Manager roles that would be accountable for each of our three product lines (Marketing, Sales, and Service Hub).  The rationale was quite simple: it turns out we didn’t have a single DRI for an individual Hub, how it could and should be growing, how it competed in the market, etc. I was lucky enough to be the first external GM brought in (the other GM roles were filled by a few well-deserving internal superstars). Now that we are looking to expand the product portfolio, I wanted to shed some light on what it’s like to be a Product GM, both at HubSpot and beyond. In the most obvious sense, a good GM has to be of two minds, considering both Product and Go-to-Market in their day to day. The trick to being great is in your ability to overlay these considerations on top of both a near and long term horizons. This means you’ve got to divide your efforts across four different disciplines.  Here’s a handy 2x2 to help articulate it: Let’s talk about what a GM might have to consider in each quadrant: Mind 1:  Near Term GTM In this state, it’s pretty obvious that a GM needs to spend their time making sure that the current product and the current positioning is being executed through the business in the right way. That means partnering with sales, marketing, and services leadership to help validate, reinforce, and improve the messaging and the way it’s brought to market. Additionally, it’s helping to make sure that the existing go to market motion, whether it be freemium or enterprise direct sales or other, is working effectively and whether there are levers that can be pulled to improve them. At HubSpot we execute on a freemium motion with a dash of enterprise selling sprinkled in, so you’d be right to assume that I spend a lot of my time digging in to make sure that the freemium funnel is working the right way and that the sales team is able to execute effectively.  GM’s should spend loads of time with front-line sales and service reps on everything from message testing to competitive intel to closing deals. At HubSpot we have the additional benefit of an incredible partner community to engage with. Partners are often one of the first places I go to dive deeper into an issue or brainstorm a new approach. Mind 2:  Near Term Product On the “product” side of the near term horizon, having some product management chops becomes really valuable in order to help guide and empower your product teams. In HubSpot’s case product management reports up to the GM and we have general accountability and oversight of the product delivery. However, one of the things that makes HubSpot great is that the product teams (along with engineering and design counterparts) are highly autonomous. So the role of the GM ends up being to provide a set of goals and guardrails to those teams so that they can execute independently.  The role of the GM is not to “seagull” in and make product recommendations or bring their pet rocks to the team to prioritize over other things. My team is probably reading this and laughing because sometimes it’s hard to resist—if they only knew how often I DON’T do that! Luckily when it does happen our teams feel empowered to push back. The other key part of the near term product mind is to focus on team health. We want to make sure that the team triads (the PM/Eng/Design leads) are working the right way together.  I view my main job here as ensuring that everyone is crystal clear on what the goals are and where we’re headed (we use a high level product “Compass” and OKR’s). The best thing you can do as a product leader is to clearly articulate and reinforce the vision, make sure your teams understand it, and then get out of their way. Mind 3:  Long Term GTM Now, on the long-term go to market side you can imagine that the role the GM is quite an interesting one. It’s not about setting quotas or marketing budgets--we have incredible teams at HubSpot that take ownership of those things. The role of the GM is to determine where to play and how to win.  Determining where to play requires deeply understanding your market dynamics, target customers, and competitors. How to win is about unlocking growth in the markets you choose. Sometimes this requires thought leadership (e.g. HubSpot’s use of Inbound Marketing), other times it’s introducing new business mechanics (freemium, channels, etc.) to the mix to better capitalize on a market. Unsurprisingly, many parts of this job come down to pricing and packaging. Some would argue that everything comes down to bundling and unbundling and pricing and packaging. I personally spent a fair amount of my time here because it’s so important for us to get right.  What I’ve learned is that pricing and packaging goes far beyond what you put on your website--it impacts internal teams, customers, partners, competitors and sometimes entire markets. Given the complexity, this part of the role is intellectually stimulating and often where you partner the most with the other leaders in the organization. One interesting example we run into a lot at HubSpot (given the large product surface area) is whether we should be charging for certain features or not.  Is this product being commoditized and do customers expect it to be free? Would it provide further differentiation for our free products? These are all decisions a GM is empowered to make. If a product line doesn’t have a freemium motion, you may want to consider ways to introduce ways to put that in place.  For example, HubSpot has a great free Meetings tool that our customers love. We could have easily added that into a paid edition, but thinking more holistically about how that product could potentially drive demand and virality was a key factor in keeping it free. Mind 4:  Long Term Product The final piece is the long-term product vision and strategy. This is the one that most product leaders love to sink their teeth into because it feels most comfortable. Product leaders must be both storytellers and pragmatists, and this is where those two pieces come together. I’ve seen plenty of great approaches to product vision, and have narrowed them down to a set of principles that have helped guide me through the years.  As a GM and product leader it’s on you to connect the dots between today and what will be an incredible future state, and these principles provide the framework to do so. Here’s how I think about it: Tangibly define the thing you want to create.  Write it down and describe what it could be, with some specificity.  It will change, but it’s important to have a guidepost. It’s amazing how so many teams can’t do this. Overlay that definition onto existing (or new) TAM.  If you can match your clear product definition with a clear landing spot in the market, you’ve already got an advantage.  Poke and prod to make sure your plan holds up, and you’re on your way to product market fit. Provide scaffolding to win from a technology and GTM standpoint by setting achievable milestones that help connect the dots.  Elon Musk’s Master Plan is an amazing example of connecting the dots between today and a future vision. Have wide guardrails to allow for iteration and course correction.  Your initial vision won’t be perfect, so your team needs the autonomy to find their own path.  Provide the guardrails (e.g. product performance, target market) that keep things pointing at the goal without dictating every step of the journey. Use the customer as your compass, with their feedback underpinning all of the above.  HubSpot is the most customer-centric company I’ve ever been a part of, and we’ve created a product culture where not thinking this way would be unimaginable! Does this sound like the kind of product management team you’d want to come work with? Check out our latest open roles.", "date": "2019-10-15"},
{"website": "Hubspot", "title": "Java 11 Upgrade Tip: Don't Rely on Generated serialVersionUID", "author": ["Jonathan Haber (He/Him)"], "link": "https://product.hubspot.com/blog/java-11-dont-rely-on-generated-serialversionuid", "abstract": "At HubSpot, pretty much all of our backend services are written in Java. As part of keeping our Java stack up-to-date, we've been working on the upgrade from Java 8 to Java 11 for a long time. Doing this sort of upgrade smoothly and safely across a codebase as large as ours, while not disrupting the workflow of our hundreds of backend engineers, is no small feat. This post will cover a snag we hit when we thought we were finally done. We'd been building all of our apps with Java 11 for over a year (but still targeting Java 8 bytecode). We'd been running all of our apps on Java 11 in production for five months. We'd been targeting Java 11 in all of our leaf modules (ie, not libraries) for three weeks. We upgraded ASM, CGLIB, and ByteBuddy everywhere. We fixed all of the dependency issues with jaxb. We forked Spark 2.4 to make it work on Java 11. We thought we had done our due diligence and were ready to target Java 11 everywhere. Targeting Java 11 So we went ahead and made the change to target Java 11 globally (which we announced far in advance). Services picked up this change throughout the day as they rebuilt and redeployed. A few hours later, a report came in of an issue in our QA environment, with this stacktrace included (class names replaced for brevity): The InvalidClassException suggests that the error is related to Java serialization. Before this, if you asked me whether HubSpot uses Java serialization to persist data, I would've said \"Of course not, it's not 2009 anymore!\" But it turns out that a relatively important service was accidentally using Java serialization to store data in HBase, and the class it was serializing did not declare a serialVersionUID . And for some reason, the Java 11 upgrade changed the computed serialVersionUID , meaning that this service could no longer read data out of HBase. Luckily, our automated monitoring and alerting detected the issue in our QA environment, so there was no impact to our production environment. In response, we rolled back the upgrade and started to investigate. Investigation As a sanity check, we first confirmed that the Java 8 and Java 11 versions of the class did in fact have different serialVersionUID s. We checked this using the serialver tool included with the JDK. So, targeting Java 11 is changing the serialVersionUID , but why? To be fair, the Javadoc for Serializable makes it clear that serialVersionUID can break across compiler implementations: \"[I]t is strongly recommended that all serializable classes explicitly declare serialVersionUID values, since the default serialVersionUID computation is highly sensitive to class details that may vary depending on compiler implementations, and can thus result in unexpected InvalidClassExceptions during deserialization. Therefore, to guarantee a consistent serialVersionUID value across different Java compiler implementations, a serializable class must declare an explicit serialVersionUID value.\" But looking at the specification for computing a serialVersionUID , it wasn't clear why it would be different. The source code hadn't changed, so the class name, modifiers, interfaces, fields, constructors, and methods should have all been the same. However, we were able to see the problem using javap , the class file disassembler included with the JDK. At HubSpot, we generate immutable data classes and builders at compile time using a library called Immutables . However, the generated code isn't very pretty to look at, so I crafted a heavily simplified version: First, we compile this class targeting Java 11 and then run it through javap : Next, we do the same thing targeting Java 8: And here we see the problem; when targeting Java 8, an extra package-private constructor is included. And the specification for Java serialization says that all non-private constructors are included in the serialVersionUID calculation. So now we're starting to see what's going on; when targeting Java 11, a package-private constructor is removed, which changes the computed serialVersionUID . But what's the deal with this constructor? Where is it coming from and why doesn't it appear in the Java 11 class file? Synthetic Constructors The first thing to note is that SomeClass has a builder, which is an inner class. And this inner class calls the private constructor of SomeClass . But the builder is compiled to a separate class file, which won't be allowed to access this private constructor at runtime. In order to support this, the Java compiler (before Java 11) generated a synthetic, package-private constructor. The builder class can then use this package-private constructor, rather than invoking the private constructor directly. In Java 11, however, JEP-181 landed. This JEP enhanced the class file format and JVM to directly support these inner class accesses, which eliminates the need to generate a synthetic constructor. And now we fully understand why our serialVersionUID changed when targeting Java 11. Fixing the Issue In the short term, we plan to use our tooling for automated refactoring to find serializable classes that don't declare a serialVersionUID and set an explicit value (equal to the current computed value). Next, we will start failing the build if any serializable classes are detected that don't declare a serialVersionUID . These changes should allow us to finish rolling out Java 11 safely. In the longer term, we plan to find and remove any lingering usages of Java serialization, as there are almost always better options available.", "date": "2020-06-24"},
{"website": "Hubspot", "title": "Remote Productivity Hacks for Engineers", "author": ["Robert Campion"], "link": "https://product.hubspot.com/blog/remote-productivity-hacks-for-engineers", "abstract": "Many of us have been remote for a long time now, and some are choosing a hybrid work schedule even after the pandemic. In light of that, using productivity hacks to stay on top of things no matter where you're working from is the perfect new year's resolution for 2021. Here, we talk to HubSpot engineer Rob Campion about what he's learned over the last couple of years about staying productive in a world of distractions. What is your role, what team are you on, and how long have you been at HubSpot? I'm Rob Campion, the Engineering Lead of Growth Onboarding and I started at HubSpot in March 2015. What has your remote productivity level been like compared to the in-office experience? What are the factors at play that can take you off track? Honestly, my productivity has now leveled-out to similar or higher than office levels. Getting and remaining focused at the office can be difficult, but with the right set up at home, and by turning off distractions (notifications, phones, etc.) I find it easier to get into a flow state . Factors that take you off track → solutions: Long-running slack thread → start a quick zoom Notifications overload → go into do not disturb (more below) Too many meetings → block off your calendar Outside work distractions → get great headphones, enable do not disturb on your phone Even more so when you're WFH/remote, Slack can be all-consuming. How do you make sure you optimize how you use Slack to your benefit? Biggest tip: don’t be afraid to go into Do Not Disturb mode, either on your laptop or on Slack itself: Slack supports this via the ‘/dnd’ command. The best thing about it is your teammates know you’re busy, and they can override it for urgent questions. Mac supports a “turn off all notifications” do-not-disturb mode which I find better, as everything is muted. Be sure to let your team know if you’re going to be in this mode for a sustained period (in case they’re trying to reach you). Leave channels that don’t offer you value. Slack is non-stop. There’s always interesting content somewhere. However, if a channel doesn’t provide me with work value (with a few exceptions), I leave. Learn slack shortcuts. The latest Slack client allows you to group channels, collapse them, keep them muted etc. I group related channels and mute certain groups that I only check on infrequently. How are you using Zoom meetings effectively, without fueling Zoom fatigue? Have ‘no video’ meetings, e.g. 1:1s. Take calls outside your home. E.g. for meetings that allow it, I’ve cycled to the nearest park to take them. Block off GSD time in your calendar, ensuring you get breaks and have heads-down peace. Schedule a ‘No-Meetings Day’ every so often Make a clear ‘start time’ and ‘end time’ in your calendar (e.g. 9 am - 5 pm) Be honest and let someone know if the conversation needs to move on (thereby speeding up your meetings). Take lunch breaks daily (e.g. 12 - 1). What are your favorite shortcuts to being more effective with your time? It's hard to point to a specific one. Ensure you learn shortcuts for every tool you (regularly) use. Look at areas that slow you down (e.g. places you use your mouse a lot), and see if you can speed it up with keyboard shortcuts. Improving shortcut knowledge Be proactive with whatever tool you’re using and look for a shortcut cheat sheet (e.g. gmail , github , slack , mac , your editor). Create a ‘Shortcuts’ bookmark folder in your browser and add cheat sheets to it. Once created, right-click the folder and select ‘Open All in New Window.’ Leave the window open in the background and reference it. It’s a gradual process, you won’t master them straight away. What resources would you recommend someone checks out if they are looking for ways to be more productive with their time? Ask your team, or an individual you know has great output: What do they do to improve their productivity levels? Would they be open to pair-programming to solve a problem? Check out this great book on how to improve your engineer skills and efficiency. Interested in working with a team that's just as interested in how you work as what you're working on? Check out our open positions and apply .", "date": "2021-01-14"},
{"website": "Hubspot", "title": "Opportunities for Developers: Scaling with HubSpot", "author": ["Adrian Mott"], "link": "https://product.hubspot.com/blog/bid/84121/opportunities-for-developers-scaling-with-hubspot", "abstract": "\"Traditional marketing is going to get obliterated in the next ten years. The whole industry is just going to get ripped apart.\" -- Brian Halligan This week, a great article came out from Forbes magazine detailing HubSpot, and how the world of marketing is shifting toward a more \"Inbound\" model.  It's the very idea that drove Brian Halligan and Dharmesh Shah to start HubSpot in 2006.  Since then, HubSpot has generated a ton of new customers and revenues, and when Halligan talks about this being only the \"first inning\" of the shift that we're seeing to the marketing industry, it speaks to the future of HubSpot as well. It's one of the major reasons that I get so excited about the opportunity of developing on the HubSpot platform and why it's an exciting time to think about bringing apps and services to the HubSpot platform: we're going to be scaling the comany a huge amount ofver the course of the next few years.  It's one of the primary reasons we took the cash that we did in 2011 from Sequoia, Google Ventures and Salesforce.com. Some of the exciting ideas that we're playing with are launching a \"community edition\" of HubSpot, which would basically give free access to a limited edition of HubSpot, as well as the HubSpot marketplaces ( App and Service ).  This would be a great way for us to scale our user base, and also provide many more users for app developers and service providers in our marketplaces. The bottom line is that now is a great time to develop and provide services on the HubSpot platform.  If you're interested and want to learn more about the HubSpot platform, please head on over to the developers site and register (you'll need a HubSpot login through some portal). If you fancy yourself as more of a service provider, head over to the Services Marketplace and register to become a provider. As the Platform Evangelist here at HubSpot, I field multiple questions daily from sales reps and consultants that are working with prospects and customers who are looking for integrations, apps, services, etc... that don't exist yet.  Some requests are new, but many are repeat, and the new requests have the tendency to pop up again and again, as we grow from 6,000 customers, add in users, and scale our business. “Human beings are sick and tired of being marketed to,” says Halligan. “This is just the first inning of that massive shift.”", "date": "2012-03-16"},
{"website": "Hubspot", "title": "PM Lessons I Learned from the Sales Floor", "author": ["Flora (Yuan) Wang (She/ Her)"], "link": "https://product.hubspot.com/blog/product-management-lessons-i-learned-from-the-sales-floor", "abstract": "This post is for anyone looking to break into the PM field, no matter your background. Before I even interviewed for a product manager (PM) role, I was hungry for information on how to be the best PM. Luckily for me, there was an endless list of blogs, Medium posts, books, podcasts, and people who were excited to share that information with me. When I sat down with a PM to learn about their career, I would always end the coffee chats with “Where do you learn and keep up with product news and strategy?” I would always expect people to follow some hot shot VC blog or sage words of an all star podcast , but some PMs gave surprising answers : “I try and read fiction to broaden my thinking.” “I pursue hobbies to stay creative.” “I look at other roles and see how they improve their skills.” This opened my mind to some other avenues where I could learn how to be a great PM. After a year and a half into my PM career, for example, I realized some of my biggest insights came from my previous role as a Solution Engineer on our sales team. Whether you’re interviewing to be a PM, you’ve already been hired, or you’re a seasoned product leader ⁠— I encourage you to learn from different industries and leaders of different backgrounds. 1) Negotiating isn’t just for money⁠: PMs negotiate for time, priority, and resources Negotiating gets a really bad rap ⁠— it’s not always haggling at un trustworthy car sales people for a better price. The worst myth is that negotiations only happen when money is involved ⁠— we typically think about negotiating for a raise or better price. However, negotiations are key for other resources that matter in product work , such as time, priority, and resourcing . How sales negotiations translates to PM work : Sales teaches negotiation strategies for reaching true alignment ⁠— this is done through asking a series of well - thought - out questions to figure out what your prospect actually cares about . As a PM you negotiate all the time with : teams you’re collaborating with for your tech lead for a more customer - centric solution your designer for an easier to build design product execs for more resourcing external vendors l egal and security What PMs can learn from sales: F igur ing out what other teams a re motivated by and do the research to understand their initiatives and the metrics they want to move B uilding alignment ⁠— making sure you map out who the decision makers are and what their needs are Being open to change ⁠— what can you budge on so that everyone ends up with something that will help them advance? L ist ing out risks and what you can do to minimize them Anchoring actions in a clear timeline and in the context of customer need 2) Focus on what you can control: creating a productive and focused environment for you and your team Sales is famous for the ups and downs of sales cycles ⁠— whether it is in the highest highs of exceeding quota or lowest lows of ending the month without hitting your goal, it takes a strong of emotional stability to thrive in a sales career month after month. As a PM, you will face unexpected setbacks: A project get ting reprioritized by stakeholders Needing to slow down your roadmap for emergencies and tech debt I ssues with external vendors People l e aving your team Not being on the same page as collaborators These are some of the most difficult moments as a PM ⁠— evaluating a situation , recover ing , and steer ing your team in the direction of building the most customer value possible when everything fees like it is working against you. I’ve seen masterful sales managers take a team of sales reps from under quota to over quota within the last couple of days of the month , building success out of a positive attitude and the belief that every piece of effort matters . What PMs can learn from sales in terms of focusing on what you can control: How to get customer feedback How to build up the quantitative and qualitative data to convince others H ow to help your team iterate quickly from feedback How to pivot if needed 3) It’s not just quotas and deadlines: generating and working with urgency The nature of sales is to do things efficiently and quickly ⁠— constantly juggling between different tasks and deciding which account to focus on to help hit quota as the end of the month looms ever closer. Luckily, in product the deadlines aren’t as cyclical , but it benefits PMs and product teams to move with a sense of urgency . Not that the best product teams are shipping at a break neck pace that feel like a death march ⁠— it’s more that we are constantly able to honestly answer the question: “Are we shipping customer value?” The trick is pace yourself and bring a consistent urgency to the team, so that it feels like you are moving at a brisk comfortable jog — not a slow crawl and not a cheetah-like sprint. What PMs can learn from sales: How to c onstantly ask yourselves and others what the next step on the project is How to make sure there is clear division and ownership of tasks How not to get bogged down in a specific framework or design principle , or any of the many other rabbit holes that delay product teams How to future - proof without slowing down development How you and your team know and are driven by the mission and goals of the team and company You never know where your most valuable lessons will come from… The biggest lessons don’t always come from the experts of your industry. While these are the learnings of a green PM wh o’s only 1.5 years into the job- I know I definitely have a lot more to learn from both PMs and non-PMs alike . But these are the lessons I steer my ship by now, and I didn’t learn them from a traditional PM training course (if there is such a thing!). So keep your eyes open — you never know what you’ll learn, or where.", "date": "2020-11-12"},
{"website": "Hubspot", "title": "A Theory of Beautiful Code", "author": ["Dan Milstein"], "link": "https://product.hubspot.com/blog/bid/8027/a-theory-of-beautiful-code", "abstract": "E.M. Forster, in his essay Aspects of the Novel , draws a distinction between \"flat\" and \"round\" characters in literature (two types that I suspect pretty much all of us can intuitively identify from our own reading lives), in the following deceptively simple manner: \"The test of a round character is whether it is capable of surprising in a convincing way.\" I love that quote.  It's so concise, but it gets at the heart of something profound about the reading experience (and also at the challenge of creating such characters). Recently, it occurred to me that maybe there's an analogous way to describe the notion of \"beauty\" in code.  Here's my bid: Beautiful code is code that surprises us with its simplicity Meaning: you've been working in some problem space, and have built some complex solutions, which, you feel, are about as good as can be done.  Then, someone comes along, and shows you a solution that somehow makes all the complexity go away.  Those moments are electrifying -- that's beauty in code, I think. (Side note: I think you could counter-define \"clever\" code as that which surprises us, but not by simplicity). Once that occurred to me as a general statement, all sorts of examples came to mind: My very first paid programming job involved parsing some dates out of a text file. Which, of course, I did with C, which I had just learned that year in school.  The logic was pretty complex, but I was proud that I mostly got it right.  Then, someone showed me regular expressions, and it was like the scales fell from my eyes.  All that complexity, just gone, and in its place this concise, elegant description of a pattern.  What an incredibly beautiful idea. Yoav and I were recently talking about how we both have this very specific, vivid memory of sitting in front of our computers watching the original Ruby on Rails screencast -- the one where David Heinemeier Hansson builds a blog server from scratch in 15 minutes.  I'd been creating database-backed websites for years, but he had somehow come up with this way that was just so insanely concise and simple.  It was like magic. List comprehensions (for me, in python) -- I remember telling a friend how great they were, and excitedly writing out on a nearby blackboard something like.. [ transform(x) for x in lst if is_valid(x) ] ...and just staring at it and thinking about how much was going on for each small piece of that line.  I'm so used to that idiom now, but what a lovely, simple thing. The \"Road to the Generic Server\" section in Joe Armstrong's Programming Erlang .  Just lifted the top of my head off and put it back on in a different way.  He approaches writing a server from this (to me) odd angle, and then goes on to show how incredibly powerful it is, again, in this amazingly simple way. I could go on, but I'm curious for other people's takes.  What do you think of that proposed definition of beautiful code?  Are there examples of surprising simplicity that you find particularly exhilarating?", "date": "2009-07-08"},
{"website": "Hubspot", "title": "4 Mistakes New Product Managers Make", "author": ["Matt Schnitt (He/Him)"], "link": "https://product.hubspot.com/blog/4-mistakes-new-product-managers-make", "abstract": "Starting out as a product manager, you constantly oscillate between feelings of total elation and complete dejection - occasionally, multiple times a day. Over time, you learn to manage the ups and downs of releasing a highly requested feature and being burried under a mountain of bugs, but that feeling never completely goes away. Truthfully, I would never want to lose it completely because I've learned more from it than I could from anything else. The work also teaches you a tremendous amount about humility, agility and persistence. While a lot of product management has to be learned through experience, there is much I wish I'd known when I started my PM career. With that, I'd like to share a few common mistakes new and aspiring PMs make (all of which I've also made), in the hopes of helping them manage their own ups and downs while wading into the art of product management. THAT'S NOT OUR USER Stop me if you've heard this one before: You've just gotten slammed through feedback - a user, colleague or friend tells you they couldn't use your product because of something dealbreaking. A feature is missing that they can't live without. They have an established process now and couldn't justify moving over to use your tool. They don't see the value. And then someone in the room (maybe you) chimes in, \"They're not our user.\" In other words, you can totally live without solving for their very pressing needs because they are a different persona than those you've created your product for. And so you write their feedback off. This is dangerous for a variety of reasons. The biggest lesson here is that you cannot be selective with the feedback that you choose to adhere to. Every opportunity you have to talk about your product with someone, use it as an opportunity to get actionable feedback, and to grow your knowledge of how your product is likely to be received when you bring it to market. The truth is, great products almost never solve for a single persona or need. They are nimble, accessible, and agile enough to be broadly applicable. If you're writing someone's feedback off because they don't mesh with your ideal user, you're missing the point entirely. Because in the market, there are a lot more prospective users that don't fit your ideal user than those that do. WE CAN'T KILL IT Be brave and humble enough to acknowledge when a feature isn't working. Your user doesn't care that it was an incredible technical challenge implement. Your user doesn't care that it took 4 weeks and 3 full-time engineers to build. And they certainly don't care that you may lose some respect among your team for admitting defeat. What your user cares about is that their experience using your app is degraded because a feature isn't what they need it to be. Solve for your user. If a feature isn't working and you're talking to users early and often, you'll know when something isn't working. Further, you should be able to measure everything that goes on in your app, so you'll have data to back up your assessment that a feature isn't cutting it. Des Traynor, VP Product at Intercom.io, has a nice post describing exactly how to think about this data when you have it. Source: Intercom You might also think that so long as someone is using a feature, you couldn't possibly kill it. How could you take something away from a loyal user? The truth is that the incremental value of that feature is likely lower than the increased cognitive burden it has on your userbase as a whole. After all, you're not in the business of building everything that everyone wants. When considering whether or not to push on a feature with low adoption or kill it, a helpful way to think about the problem is to ask yourself, \"Am I sure that my hypothesis was right?\" If you're sure that the underlying hypothesis that drove you to create the feature was right, push on it. Otherwise kill it. As Traynor says, \"If you want a well defined product, you must be comfortable killing features.\" THINKING ONLY ABOUT SOLUTIONS Odds are that if you're a PM or thinking about becoming one, you love to solve problems - it's in your genes. But it is problematic to think only in terms of potential solutions. It closes you off from thinking about the problem itself. There is inherent danger in this because you end up constraining your thinking to a certain subset of solutions. Instead, really think about what the problem you are trying to solve for the user is - make sure you understand not only their pain, but what causes it, to deliver the optimal solution. This concept, problem space vs. solution space , has been around forever, but it makes an incredible amount of sense for a product manager. A classic example of tackling customer pain from the problem space instead of the solution space is TurboTax. When TurboTax was going to market, their product was informed by the realization that solving for the problem of \"prepare my taxes\" made for a radically different product than creating a \"software for your taxes\" solution. The result was a far superior product than their competitors (this example comes from Lean Product Management, an awesome seminar by Dan Olsen . If you're interested in product management, this is a great place to start). Source: Intercom Another important dimension of this problem is that you as a product manager are really the owner of problems more than solutions. Your engineers are the ones who should really propose and own the solutions. If you've gotten attached to a solution too early, you haven't fully leverage your engineering team for all of their many talents. IT'S NOT READY YET Early in a feature's lifecycle, your instinct is to polish it. You've thought so much about it, there are so many additional tweaks that could exponentially increase the value of it. It'd be unfair to yourself, the engineers, and the user to release it, right? Wrong. This is the single biggest mistake you can make as a product manager. None of those additional features can replace the value of getting your feature or product in the hands of real users. Nothing. In many cases, worse is actually better . Be relentlessly aggressive to onboard your first user. Early in a product's lifecycle, that has to be one of your milestones. Source: Busy Building Things This thinking is a lot of what drive's product roadmaps at HubSpot - we get features in front of beta tolerant customers early and let them drive the roadmap. Obviously this doesn't mean a customer tells you they need Clippy in the righthand corner of your app and you build Clippy in the righthand corner of your app, but it sure beats dreaming up features that no one will use. Let the market and your users validate your thinking. The only way to do that is to put your product in front of them and ask them what they think. A simple heuristic to live by here is: do you know when the next time you're going to ship is? Always be shipping or planning for the next time you will ship. HUMILITY, AGILITY & PERSISTENCE There are three commonalities that empower product managers to overcome or altogether avoid these mistakes - humility, agility and persistence. The great product managers that I've seen all possess these qualities. They empower them to singularly solve for their customer, with a vision and voice that inspires their team along the way to building great products.", "date": "2014-07-01"},
{"website": "Hubspot", "title": "Slacking hard, or hardly Slacking: Automating infrastructure at scale", "author": ["Elias Szabo-Wexler (He/Him)"], "link": "https://product.hubspot.com/blog/slacking-hard-or-hardly-slacking-automating-infrastructure-at-scale", "abstract": "Here at HubSpot, automation is king. If you’ve got a bug, all you have to do is fix it once and it’s gone. But if you try to ignore a human error? Get ready — you’ll definitely see it again. This preference drives our team’s worldview, and you can see it in our organizational structure (we don’t have any teams that we’d consider to be DevOps). Instead, we have a Platform as a Service model, meaning that a substantial fraction of our engineers are devoted to providing services to enable the whole engineering team. Our mission as platform engineers is simple: we want to provide HubSpot’s engineers with superpowers. On the infrastructure team, we’ve bought or built a variety of systems that maintain a large fleet of cloud instances running a heterogeneous mix of hardware and offer a variety of datastores. We attempt to optimize every step of the development pipeline, from a seamless deployment experience to the initial setup of a new hire’s laptop, from lightning-fast build times to intuitive monitoring (and more). We aim to reduce the complex operational functions of running a business at scale to easy-to-handle tasks that are safe and offer minimal operational overhead. As our team has expanded, and as our automation has expanded in lockstep, we’ve started to experience some growing pains. Our team’s strength — our willingness to buy or build systems to fix problems — is also its fundamental weakness. As we scale, we encounter more and more problems, and as we encounter problems, we buy or build more and more systems. Eventually it becomes difficult for any single engineer to know everything our platform can offer, or to know where to look for a specific service. This situation can be even worse for new hires, since that context (much of which can feel like institutional knowledge that everyone else automatically knows) is staggeringly large. For us, this reached a breaking point as we hit 40 product teams. We started hearing feedback loud and clear from our bewildered coworkers: knowing where to go had become a real issue. Luckily, we use Slack for communication. It’s one of the few constants at HubSpot; every employee is on Slack and easily reachable. In an effort to help support our team, we started operating a lightweight support channel through Slack where anyone on the team could ask questions and get answers. This worked quite well for a while, allowing our team to present a responsive and human front to our fairly autonomous systems. But that, too, has started to scale poorly, as the load on our platform engineers grows more or less linearly with the size of the organization (and our team is growing quickly). Unsurprisingly, we tackled this issue as we often do — with automation. Fortunately, Slack isn’t just an instant messaging service; it’s also a platform. As we started digging in, we found that their API was well-crafted, and it was surprisingly easy to build sophisticated workflows. We started by addressing a simple issue — which channels are for which kinds of questions? We set up bots to provide users with a clear message when they entered a channel to try and cut down on irrelevant posts. This turned the institutional knowledge of which channels should be used for which subjects into knowledge that could be easily found or verified. These messages were such a simple change, but they were extremely effective. We quickly realized that there was a vast, untapped potential in building our automation and tooling directly into Slack, since this single system powered essentially all of our communication and collaboration. As we started to invest more time and effort building on top of Slack, we identified three specific problems that most needed solving. First, engineers had trouble knowing exactly where to go and who to talk to in order to find answers about a specific system. Second, too much time was wasted polling systems for asynchronous tasks to complete. And third, context switching is hard. Engineers often have to switch contexts when, for example, a job finishes while they are working on something else. We wanted to minimize the time it took for engineers to switch between tasks and gather the information they need. While all three of these look like quite different problems, Slack’s platform made it easy for us to build effective solutions for each. To tackle the first issue, we focused on automating the routing of questions or requests in our internal support channel. Now, when engineers post anything in that channel, the text of their post is analyzed and a bot posts a reply offering routing options. The logic is deeply integrated with our internal team management software, so we can route questions to teams based on what they own. This eliminates the need to know who to ask (or even where to go) beyond one Slack channel. To tackle the second issue, we began generating unique IDs for long-running tasks. Now, users can choose to receive a Slack notification when their tasks are complete, letting them avoid having to sit and poll for updates. And finally, to tackle the issue of context switching, we began experimenting with custom-built Slack integrations that pack meaningful information and actions into our alerting platform. This minimizes the work that engineers need to do to gather context when interrupted. The possibilities for building on top of Slack are infinite, but we already feel like we’ve made a big impact on some of the biggest issues that impact developer productivity. In our most recent developer survey, these were some of the responses we got from members of the team: Love the addition of the slack bot that suggests on call aliases based on question keywords. Really nice feature. PI Bot routing questions automatically in #platform-support and encouraging threading of questions is absolutely brilliant. The new slack bot in platform support to direct to the correct on-call person is awesome. I really like the platform support question/inquiry router. These efforts have gotten other internal teams excited about building on top of Slack: our Build and Deploy team is working on allowing teams to deploy code directly from Slack, and our Infrastructure Security team is exploring how they could allow engineers to manage permissions and do audits directly from Slack. And these have all been relatively easy to accomplish — Slack is a helpful, clear, and capable partner. We’re excited to announce that we’re open sourcing our Java client for Slack. Check out our endorsement on Slack’s community page here: https://api.slack.com/community , and the code on our Github here: https://github.com/HubSpot/slack-client . We’ve invested heavily in offering a straightforward API for an asynchronous Netty-based http client, with robust utilities for rate limiting, debugging, and auditing built in from our deep experience building clients internally. It’s extensible, battle tested, and we’d love to hear what you think and see what you build with it. Happy Slacking!", "date": "2018-04-26"},
{"website": "Hubspot", "title": "Leaving the Agency World: Advice for New Product Designers", "author": ["Jonathan Meharry (He/Him)"], "link": "https://product.hubspot.com/blog/leaving-the-agency-world-advice-for-new-product-designers", "abstract": "Most designers don’t dream about working on one brand, one website, and one UI. They crave variety. That’s why I joined an agency right out of school and didn’t think twice about going into product design. Nobody really did; agencies were where all the cool kids were. Designers could breath life into so many different (and sometimes sad) corners of the internet at an agency. They could work on Nike one day and BMW the next. Exposed brick, thick-rimmed glasses, and a portfolio full of big brands: That was the dream. I worked at various agencies for about five years and for the most part, I loved it. But I started to feel like something was missing after a while. The colorful variety and revolving door of projects became less and less fulfilling. I realized that making things beautiful is a passion of mine, but so is understanding how design actually impacts the people using it. Were my designs improving someone’s day-to-day or did I inadvertently make it harder with what I thought was an amazing redesign? It’s hard to know what kind of impact your work has (if any at all) when you’re focused on solving for the client, not the customer. So I decided to leave the agency world a few years ago to become a product designer. Product companies are invested in their customers’ success and happiness. That means designers are tasked with crafting the best possible user experience not just because it’s pretty, but because it will actually help someone. When customers use software every single day to do their jobs, one little UI improvement can save them a ton of time. That kind of opportunity was what drew me to the product world. Now I’m part of a team that’s maniacal about what customers are thinking and feeling, and is on a mission to solve for them. Transitioning from agency designer to product designer wasn’t a simple flip of a switch, though. Most design skills and talent are transferrable, but there’s a huge learning curve in switching from an agency setting to a product environment. Everything from working with engineers to managing timelines is different. For anyone new to product design or thinking about making the move, knowing what to expect makes a big difference. So to help with the initial culture shock, here are a few things I would tell myself if I could go back in time to my first few months in product design. Work With What You (and Other Designers) Know When I first joined HubSpot, it quickly became clear how much I didn’t know. I was used to being part of an assembly line at agencies; UX designers would hand me wireframes and I would pass my designs off to engineering. Product designers, on the other hand, are part of the entire process, from researching user flows to shipping the final product. There was so much to learn: What was a flow? Is editing in place better or should you use a form? What are best practices for user settings? Is it wrong to use a modal here? I had intuition about things but no framework to help me apply it in the product world. Combine that with the fact that UX is a relatively young field where best practices can feel like a moving target, and I was lost. Not surprisingly, impostor syndrome was tough to shake for the first few weeks. Instead of obsessing over everything I didn’t have experience with, I decided to work with what I knew, and with what my team knew. I leaned on my own visual design background, sketching constantly and getting feedback quickly. I made high fidelity mockups and when something didn’t work, I went back to sketching. I remember looking up a lot of patterns (once I had learned what a pattern was) and using that as a starting point. To really get caught up though, I had to look outside myself and ask for help. I was lucky to be paired with a veteran product manager who gave me guardrails to work with and helpful designers who are experts in the areas I’m not. At the end of the day, no designer has mastered everything there is to master. Design is too broad of a skill set. That’s why it’s important to leverage your area of speciality and keep an open dialogue. Getting feedback from your team, showing them your designs early and often, and never being afraid to ask for help will make a world of difference in your first few weeks. Focus on Iteration, Not Deadlines Anyone who has worked at an agency knows the adrenaline rush of deadlines. Working under pressure is business as usual and the biggest question driving a project is, “When do you need this by?” You go from deadline to deadline with pockets of time in between, waiting for crunch time to start again. At a product company, iteration is the most important thing. Designers are focused on staying several steps ahead of engineers so they can put the necessary infrastructure in place. That means the pace is fast, but it’s steadier and less influenced by outside forces. Instead of deadlines, product people talk in terms of who will be “blocked” if they don’t have a design direction within an approaching timeframe. This is all internal team pressure. It can still be stressful but designers have more control over what gets out the door when and how priorities get shaped. You’ll probably feel some tension at first not knowing when people expect deliverables from you. Am I taking too long? What if I spend too much time researching this problem and not showing actual designs? You might have a strong urge to show something tangible as quickly as possible. That’s great  but remember that as a product designer, your most important step in the process is defining the problem. If you don’t take the time dig deep into the core problem, every line you draw and pixel you nudge won’t matter. You’ll just be going full speed in the wrong direction. Getting to the root of a problem can take some time, and that’s okay. They key is to communicate and set expectations. Collaborate with your team by sketching out ideas, whiteboarding scenarios, or talking to users together. When everyone is engaged in the process and you’re solving the problem together, there’s less worry about deadlines or blocking. Your team and colleagues like to see progress, and if they don’t have to ask, even better. Take Feedback with the Future in Mind One of the best parts of working for a product company is that feedback comes from the end user, not a client. As soon as your design gets shipped out into the wild, it’s time for the ultimate stress of hearing how it was received and how users are interacting with it. You’ll get all kinds of comments and a variety of user scenarios, and because you empathize with users, you’ll want to jump on them. For example, maybe there’s a button several users can’t find and your instinct is to fix it immediately. My advice here is simple: Don’t. As much as you want to squash everyone’s pain points, it’s best to just wait. Let the feedback roll-in and start looking for patterns. There might be a hundred different comments that end up pointing to the same underlying issue. That’s the one problem you want to solve. Otherwise, you’ll end up chasing a million tiny surface requests that will make a few individuals happy but compromise the experience at large. Being so close to user feedback has made me realize that product designers have to help people manage change. Parsing the difference between bad design and a user who’s stuck in their ways is hard, but it’s an important distinction. If what you’re designing is drastically different, be prepared for a lot of people to hate it. Just remember that no design will ever be perfect because designs solve specific problems, and those problems evolve over time. So don’t let fear of change stifle progress. Design with the future in mind, not the past. Design with Empathy Working on one brand, one website, and one UI used to sound crazy to me. But if you care about the humans you’re designing for, product design makes perfect sense. Making the switch from the agency world to a product company doesn’t happen overnight, but remember that solving for the customer is what you, your team, and your company have in common. So lean into that. There’s going to be an initial culture shock but it wears off faster when you know how to navigate it. Identify your strengths and find ways to use them to your advantage. Ask a lot of questions and lean on others who are stronger in areas you need help in. Channel your speed into fast, proactive iteration, and learn how to digest feedback. At the end of the day, it’s all about empathy. I became a product designer because I care about the impact my designs have on people. There are a lot of tools, processes, and UX practices out there. They all come down to the same thing: finding ways to walk in a customer’s shoes and hopefully make their journey a little easier, and little happier.", "date": "2015-11-17"},
{"website": "Hubspot", "title": "What Does It Mean to Be a “Good” Engineer?", "author": ["Whitney Sorenson (He/Him)"], "link": "https://product.hubspot.com/blog/good-engineering-behaviors", "abstract": "At HubSpot, we first defined and published our company values in 2013 with the Culture Code . Last year we published our Product Values to be more transparent, internally and externally, about what we value as a product and engineering organization. But one thing that’s become clear as we’ve grown (both in terms of size, scope, and global reach) is that candidates and employees alike want more clarity on what behaviors support those values on a daily basis. There’s a lot of noise out there about the importance of holding onto the fabled “ 10x engineer ,” who exhibits superhuman levels of productivity (and subhuman levels of empathy). But we want to combat the notion that there’s only one way to be an effective engineer, and that traits like proactivity, kindness, and teamwork don’t contribute to making an impact. Our values are only as real as the degree to which they are personified in the code we ship, the individuals we hire and promote, and the leaders we value and reward, so the more context we can provide for people on the front line about the behaviors that are meaningful to our team, the more likely it is that we bring our values to life every day in the work we do on behalf of our customers. The initial internal draft for this post riffed off an old post by Ben Horowitz on good and bad product managers. While useful and illustrative in its contrast, it reinforced the idea that there are “good” engineers and “bad” engineers and that those are either badges of honor (in the case of good engineers) or shame (in the case of bad engineers). The reality is a bit murkier--all of us, at some point, have embodied behaviors that we describe as effective or ineffective on the list below. The goal of this post is to keep all of us (including me) focused on demonstrating positive behaviors that help us become a better product team every day. Value #1: Customer First At HubSpot, our mission is to help millions of organizations grow better, so it’s imperative that our engineers and tech leads demonstrate customer-centricity in their approach. Effective behaviors: Interacting with customers in order to better understand how they use the product. Striving to understand the problem we’re solving and building solutions that delight customers. Building with empathy. Testing the product with customers’ use cases and workflows in mind. Understanding that code that doesn’t provide value to customers or make HubSpot better isn’t worth writing. Ineffective behaviors: Caring more about using a new technology or approach than the value it adds for our customers. Sitting out of user calls and research sessions. Not using the product—and maybe not even being sure of what the product does. Value #2: Complacency Equals Failure In our original Culture Code deck, one of my favorite slides illustrated that as organizations grow, they regress to the mean. I want our team to push relentlessly against complacency in our approach, our philosophy, and our execution. Why? Because your customers have no time for your complacency. In a market where customers have thousands of options for their tech stack, our team needs to feel that just perpetuating the status quo to avoid ruffling feathers or owning meaningful change is failure, not success. Effective behaviors: Leaving things better than you found them. Questioning the status quo. Seeing when systems are no longer adequate and identifying where and how to adapt them. Caring about your team’s mission and goals. Understanding team strategy, developing your own perspective, and giving feedback and suggestions. Being passionate about the team and sharing that passion with others. Ineffective behaviors: Writing code, but not connecting it to outcomes. Not testing your code. Trying to pass off laziness as keeping it simple. Following known patterns blindly, and failing to adapt to changing needs or requirements. Complaining about what’s going wrong—but not working to fix it. Assigning blame instead of charting a path forward. Ignoring problems. Seeing the existing culture, technology, and process as permanent. Not pushing yourself and others to grow. Value #3: Think Like an Owner It’s easy when you’re part of a bigger team to think of problems as something you don’t have an obligation, permission, or time to solve, and as a result to pass that issue along to the next engineer, tech lead, or worse yet—customer or user. The behavioral goal is not “if you see something, say something,” but rather “if you see something, do something.” Effective behaviors: Proactively taking ownership of problems and creating solutions. Knowing the backlog and developing your own sense of priority. Being able to work autonomously without explicit daily direction. When things go wrong, thinking \"it may not be my fault , but it is my problem,” and addressing alerts and customer issues without being asked. Seeing a job all the way through. As you come up with solutions, ask questions and verify your approach. Sharing what you’re working on and how it’s going on issues—especially if there’s a problem. Addressing code review comments, getting your work merged, deploying and testing your changes, releasing the feature to customers, and validating that there are no issues. Knowing that you are the master of your own growth. Watching what more senior engineers do and emulating their behavior. Continuously and proactively asking for and accepting feedback from your peers and leads, and working on areas of improvement. Building trust, autonomy, and social capital over time, knowing those things must be earned. Thinking long term, setting goals for your own progress and learning. Ineffective behaviors: Thinking “that’s not my job”. Waiting for your lead to assign you work. Never taking alerts or addressing customer issues and bugs without being asked. Assuming someone else will handle problems. Focusing only on the discrete tasks that are assigned to you instead of developing a holistic view of your team’s work. Thinking that your product’s direction and roadmap comes only from leadership. Dropping the ball. Needing constant check-ins to make sure you’re focused on the right tasks. Starting to code immediately without thinking through or validating your approach. Failing to consistently discuss possible solutions or solicit feedback from your team or peers while working. Not communicating about how your work is going unless someone asks you. Needing someone else to remind you to update issues or share a project’s status. Not letting anyone know when you’re stuck. Wasting time going in circles without asking for help. Not trying to solve a problem on your own before asking others. Not proactively addressing code comments or pushing your code unless someone reminds you. Letting others stumble upon code problems in production. Not caring about the overall mission of the product and team. Not understanding the goals and not engaging leadership to understand them better. Not asking questions or showing curiosity about customers and competitive products. Ignoring the wider context and focusing only on your island of ownership. Believing you are owed career progression. Waiting for wake up calls to push you to grow. Ignoring the behaviors that have helped those more senior to you advance. Not wanting to hear how to improve. Never asking for help. Thinking you should already know the answer to every question or that you should always be able to work things out by yourself. Not planning your work in advance. Not setting goals and reflecting on whether you’ve met those goals. Value #4: Move Quickly & Iterate One of the reasons engineers come to work at HubSpot to this day is because we move quickly. We commit code hundreds of times of day to help our customers succeed, so if you’re someone who wants to launch just one big product per year or who wants an instructional manual for daily tasks, we likely aren’t the best fit. Effective behaviors: Knowing that no one gets things perfect on the first (or even second) try, but doing what you can to make things better with every iteration. Knowing that complex systems evolve from simple systems. Not designing complex systems from scratch—but starting over from simple systems. Identifying ways to test concepts with customers without building an entire application. Knowing when to let a project go if it’s just not working. Building out something that works and provides value to customers, even if dependent teams are still catching up. Ineffective behaviors: Trying to create a perfect system, then getting bogged down in complexity and details. Coming up with reasons why your system is special and can’t be built iteratively. Working for weeks without committing code or getting feedback from customers. Getting attached to a project and insisting on seeing it through to completion, even when the tide has shifted from customer feedback or lack of interest. Demanding perfection from other teams, and being reluctant to let other teams iterate on problems for fear that it will make your life harder. Value #5: Keep it Simple We want to grow people who infuse simplicity into our product and systems with everything they do. Often the boldest actions in our team are deleting code, choosing not to build something new, and removing steps or processes to help our customers save valuable time. We want to create an environment that values and rewards simplicity for our team and for our customers. Effective behaviors: Taking as much pleasure in deleting code as you do in writing it. Solving one problem at a time, instead of trying to solve 100% of use cases. Starting simple, looking for opportunities to deliver 80% of the value with 20% of the solution. Writing code as if someone else will one day read it. Chances are someone will. Implementing things when you actually need them, rather than when you think you might. Ineffective behaviors: Writing code that’s needlessly complex or difficult to debug. Failing to appreciate the value of consistency; introducing new technologies or libraries for minor benefits. Using technologies or frameworks meant to solve much larger problems when you could have used something simple or well-known. Value #6: Embrace Organizational Change At HubSpot, we are constantly refactoring pretty much everything. So rather than being precious about your team, your tech lead, your reporting structure, or your approach, we want folks who live and breathe our company value of adaptability. We look for leaders who don’t just tolerate change, but actively embrace it. Effective behaviors: Being excited to take on new challenges as needs and requirements change, even if it means giving up your old work. Welcoming the opportunity to work with new people or see your peers move on. Ineffective behaviors: Spreading rumors and fear about upcoming organizational changes. Value #7: Scale Each Other Our success as a team is predicated on scale, and that means systems that scale, but also people who do too. As a result, documentation becomes even more critical to our success as a company and as a team, as does our commitment to sharing what we know or learned from an approach so others can benefit directly versus having to replicate learnings, mistakes, and failures as we grow. Effective behaviors: Acknowledging that you don’t have to be a lead to be a leader. Working to become a partner and peer to your lead and a technical leader on the team. Constantly thinking about how to share what you know to the community at large in blog posts and speaking engagements. Helping your new team members out during onboarding. Looking for opportunities to give feedback to members of your team and the organization. Pitching in to answer questions from other engineers not on your team. Reviewing other team members’ code and pull requests, even if you’re not an expert. Documenting solutions to difficult problems and make them easy to find. Creating automation instead of just resolving things manually. Ineffective behaviors: Thinking your job is to keep your head down and write as much code as possible. Being too busy to help onboard new team members. Not thinking about the long term value or impact of building the team, and instead focusing only on your own productivity. Not reviewing your team members’ code. Assuming that’s only the lead’s job. Part of the reason we post these values is to hold all of us accountable to these behaviors and to create a common language for challenging each other to live them. Said differently, these values shouldn’t be something engineering leadership “enforces,” but rather something that everyone on the team feels a responsibility to hold each other accountable for on a daily basis. When I first shared a draft of these behaviors with my team, I got pretty bold and candid pushback on one of my assumptions from one of our tech leads. I view that kind of pushback from peers as very much a feature of the process, not a bug. The goal here is to keep iterating on these values and how they are lived daily, and to create an environment that is psychologically safe enough so that anyone on the team can challenge, discuss, or make suggestions to change them or how they are built into our operating system daily. Finally, no list of behaviors is ever exhaustive, unconditional, or applicable in every situation. Cultural context and situational context are critical here. But our goal in sharing this is to give our candidates, engineers, customers, partners, and leadership team a clear picture of how we think about success as a team, and the choices, big and small, that drive what we view as high impact behaviors in our organization.", "date": "2019-08-15"},
{"website": "Hubspot", "title": "How building a design system empowers your team to focus on people — not pixels.", "author": ["Mariah Muscato (She/Her)"], "link": "https://product.hubspot.com/blog/how-building-a-design-system-empowers-your-team-to-focus-on-people-not-pixels", "abstract": "This post is the first in a series about HubSpot Canvas, our new Design Language. There’s an old comedy skit about a mailman who decides he’s no longer passionate about delivering mail - he’d rather deliver tacos instead. In the skit, a man waits by his mailbox to confront the mailman about the lack of actual mail in his mailbox. Despite loving tacos, the resident says, “If I had to choose between the tacos and the mail, I’d have to choose the mail.” Tacos are much more exciting than bills, but the man doesn’t need tacos. He needs his mail. HubSpot customers need a product that’s consistent, highly functional and delightful. So the HubSpot Design team needed to create a design system that would help us fullfil those needs on a continual basis. Over the last couple of years, we’ve: Created a new design language (called HubSpot Canvas; more on that later) Redesigned the HubSpot platform and refreshed the visual identity of our brand Built a living, breathing design system that can scale with our growing business In order to accomplish all this, we needed to invest in our talent. We’ve scaled our UX team from 14 product designers,  2 researchers, and 1 writer to more than 34 product designers, 8 researchers, 3 writers, and 1 product illustrator ( and we’re still hiring ). This is the story of how we committed to delivering the mail (while still managing to sneak some tacos in, too). Why we redesigned We needed to redesign the HubSpot platform for two reasons. First, to do a better job on delivering the promise of our brand. Our customers love the HubSpot brand. It’s fun, vibrant, and full of personality. But the product, well, wasn’t. It just didn’t reflect the energy our customers were putting into growing their businesses. Second, to eliminate the inconsistencies that had crept into our UI. Our interface had inconsistencies across the platform, which made it harder to use and navigate the tool. Take these two modals in the Marketing Hub as an example: Notice the inconsistencies in button placement, tab design, and interaction patterns? These inconsistencies increased the cognitive load on our customers, making it difficult for them to perform simple actions like saving their work or closing a dialog, which ultimately slowed them every day. So we decided to start by gathering user feedback about our current design. The feedback wasn’t pretty, but it was valuable: “Seems more complex than it needs to be.” “Too many options. My eye isn’t drawn anywhere specifically.” “Dense and busy. No white space.” “The color combinations are out of date and not pleasing.” “Too much grey and everything seems to be tucked away in it’s own little box.” “Uninteresting.” We knew we needed a complete refocus and rededication to the customers we serve — to their personalities, quirks, motivations, aspirations, and even (or especially) their anxieties. Ultimately, we wanted to craft a new design for our product that would be as delightful and easy to use as any of the consumer apps our customers used every day. But with that came the realization of a universal truth: Redesigning our platform meant we would need to disrupt 40 product teams across two continents. It meant we would need to divert some design and engineering resources away from creating new experiences so we could fix existing ones. And during the rollout, it meant our support and services teams and our customers would need to continuously adapt to ongoing product changes. We started this process knowing that we weren’t setting out to redesign just our product — we needed to entirely rethink the way we designed and built products. We needed to understand what inefficiencies in our organizational structure and workflows had led us to create a fragmented user experience in the first place, and replace them with practices and systems that worked. So the first part of this story focuses on how we identified those challenges, how we approached the redesign of our product, and the tools we’ve created to empower our design team to be as consistent, efficient, and autonomous as possible. The root of the problem Last year, my parents decided to sell my childhood home. I was roped into helping them clean out the attic — an attic that has accumulated twenty years’ worth of stuff. As you can imagine, there were a lot of WTF moments during that cleaning session. Some moments were along the lines of: WTF: We saved this thing!? Cool! But most were more like: WTF: Why do we still have 87 Beanie Babies? Well, in much the same way, our design team first needed to audit every component that was ever imagined, coded, and shipped into production over the previous ten years at HubSpot. We needed to get down to this granular level to better understand what the current product experience was. Every designer was asked to go through their respective apps and find every component, take a screenshot, name it, and file it away for review. Pop quiz: How many date pickers is too many? Three? Maybe four? Well, we had eight. Here are some of the other things we found in our attic: 100+ shades of the color gray 40+ text styles in 3 different fonts 16 different styles of modals 6 different primary buttons (which means we really had no primary button) 5 different ways to filter a table Modals with confirmation actions on the left Modals with confirmation actions on the right Thousands and thousands of lines of custom CSS Here’s a visual of all the buttons that existed in the HubSpot platform at the same time: So how did this happen? How did we end up with so many buttons? How did we end up with so many date pickers? Here’s an actual Slack conversation from those old, darker days: Putting the sass back in SaaS The truth is, no designer or developer at HubSpot really wants to spend their time reimagining the date picker. We identified that the reason teams had created so many variations of essentially the same styles and components was because our organizational structure created visibility issues. In short, it was very hard to discover what was already in play, and easier to just build something new. The HubSpot product team consists of small, autonomous teams that are structured around solving for specific customer needs. This allows us to move quickly as a product development organization and be highly responsive to our customers’ changing needs. But it also presents challenges when it comes to keeping different product teams aligned. When you have 40+ product teams rapidly building, shipping, and iterating, it’s actually pretty easy to lose sight of the overall customer experience. Being tightly focused on a specific problem often means you’re putting on blinders to everything else. Because of these blinders, our designers and developers were unknowingly recreating existing elements, components, and patterns across our user interface. This led to a fragmented user experience and compounded design and tech debt. Our small, autonomous team structure isn’t going to change — it’s part of our DNA. So it was clear that we needed to put more effort into creating tools and systems to better align our product teams. By connecting everyone to one centralized design system, we could ensure that we’d have a unified user experience even as we continued to grow. This would free our designers and developers from obsessing over pixels so they could spend more time obsessing over people. Getting principled The audit helped us identify problems in our design process and understand what aspects of our development culture had created inefficiencies. But before the mood boards could be created, before the typography could be explored, before we could have heated discussions over the perfect hue of orange, we needed to get principled . We needed to agree on our core beliefs, the ones we could lean on when decisions were hard. And we needed to uncover which ideals our teams felt the responsibility to uphold. So the design team ran a few ideation exercises to establish the foundation of our new design language. We debated, we stack-ranked, and we landed on five core design principles, ones that have guided us through a million micro- and macro-design decisions since. These principles are: These principles helped us stay aligned and focused as we worked through the many details of redesigning our product. You can change the color of a button, the thickness of a line, and the size of a header. But you shouldn’t change the things you fundamentally believe in. In those aspects of the design, you should be firm. A new visual direction Our design team ran a few sessions to redesign some of the core screens in our product, then elected a group of four product designers to spend a full, uninterrupted week ideating, designing, and ultimately testing a few different visual directions with our customers. These sessions produced some wildly different design directions that felt really new and exciting. Here’s a taste of some very early design concepts from two members of the design language team, Drew Condon and Jackie Barcamonte: Former HubSpot design Wild, right? Different. Exciting. Definitely not boring, stiff “business software.” The design language team ultimately tested three different design directions with our customers through multiple rounds of surveys and interviews. Once we heard the following statements, we knew we’d found a winning direction: “Makes me feel productive.” “I feel capable. I feel like I know exactly what to do.” “This is fun. This is what I would expect from HubSpot.” “Next generation of web.” (someone actually said that) “Doesn’t look like business software.” “Makes me feel in control.” Here’s a peek into the evolution of the design direction that was preferred most by the customers we interviewed: Former HubSpot design Design preferred during first round of interviews Evolved design for second round of interviews Once we validated our design direction with actual users, it was time to apply that visual style to all of our core UI components. And I’m talking about hundreds of components: buttons, links, selects, tables, breadcrumbs, modals, inputs, popovers (the list goes on). This is where the redesign got a lot less fun and a lot more meticulous and exhausting. But that meticulous, exhausting work was a long-term investment in our company and our customers. I remember one Friday afternoon that the design language team and I spent in a two-hour long meeting. We were in the trough of sorrow. Our job that day was to decide on the margin and padding of some of our most atomic components (buttons, controls, inputs, etc.) — the building blocks of our user interface. There were five of us in that meeting and we spent probably fifteen minutes carefully considering the margin of all our new buttons. This means that HubSpot was paying the salaries of five designers to sit in a room and debate something as mundane as the space that surrounds text in a box. But. Not one of our front-end engineers, product designers, researchers, writers, or product illustrators has needed to think about the margin of a button since that decision was made two years ago. That’s the beauty of building a design system. By deciding on a detail once, you free up your entire product development team to focus on solving actual customer problems. We put all of our shiny new components, as well as some guidance on how to use them, into Sketch (our design tool of choice). This created an immediate explosion in our team’s productivity, while also (suddenly) keeping our design work closely aligned. Keeping teams aligned Before this process started, we didn’t have one centralized place designers could go to understand which elements or components already existed, and no place where they could go if they wanted to use those elements or components in their own work. Designers and developers were trying their best to make good decisions about which components or patterns to use, but their main reference point was the existing product — which was decidedly inconsistent. To combat inconsistencies (while speeding up our workflow) we built a robust style and component library for our new design language. This thirty-page Sketch file is organized by “component families” and houses every single element or component that comprises our products user interface. It’s updated weekly and is shepherded by a small, rotating task force of product designers and a dedicated front-end development team. Need an icon? Come right this way. Icons by Josh Mulvey, Sue Yee, and Chelsea Bathurst Need data visualization? You got it. Data visualization by Drew Condon Need a button? As you wish. There's only one primary button this time around. It's orange. We like the color orange. Need literally anything else? HubSpot Canvas has you covered. All components are shown here on one page for dramatic effect Each component that exists in the Sketch kit also exists as a React component, making it easy to translate any mockup into a code the same way you assemble legos. That means our designers don’t spend their days pushing pixels, drawing up spec sheets, or worrying about the responsiveness of their layouts. It means our developers don’t spend hours tweaking custom CSS (in fact, they write almost none at all). It means our developers spend more time building. And it means our designers spend more time researching, ideating, and iterating, quickly and in high fidelity. Here’s a peek at the average HubSpot designer’s workflow, using Sketch libraries and the Runner and Craft (by Invision) plugins. And to keep pace with the HubSpot product, our component library continues to grow and evolve. It’s maintained by a core group of designers and developers, but everyone on the product team contributes and weighs in. Whenever a new component is built or improved, it’s rolled back into the Sketch library and is accessible to all. This vastly reduces the number of rogue components or duplicate components. Building out the system Our Sketch kit is just one piece of a larger design system. In order for it to be truly effective in the long term, we needed to create tools that worked just as effectively for developers. We learned that the best way to create consistent, functional, and delightful product experiences is to make the lives of those who build those experiences much easier. In the next several posts we’ll share how we tightened the relationship between designers and developers through the construction of our UI Library and the processes we’ve put in place to streamline the ongoing expansion and maintenance of our design system. In closing: People over pixels. Mail over tacos. Tacos are delicious. But people need their mail. Credits: Illustrations by Sue Yee Resources we found helpful: Atomic Design by Brad Frost Designing The Perfect Date And Time Picker by Vitaly Friedman Finding the Right Color Palettes for Data Visualizations by Samantha Zhang", "date": "2018-01-09"},
{"website": "Hubspot", "title": "Video: What Is the HubSpot Coding Challenge?", "author": ["HubSpot Product Team"], "link": "https://product.hubspot.com/blog/hubspot-coding-challenge", "abstract": "Learn from Lorcan O'Neill (Staff Software Engineer at HubSpot Dublin), about the ins and outs of the HubSpot Coding Challenge. A useful session for anyone preparing to complete the challenge for our recruitment process. Lorcan covers frequently asked questions like : What does the assessment involve? Are there any special requirements? What do I need to know to perform well? What are the rules of the assessment? How are the assessments evaluated? How do I find out more? If you have any questions, please feel free to reach out to Steph Byrne (Senior European University Recruiter) at sbyrne@hubspot.com or Bridget LeMon (Team Lead, Technical Campus Recruiting - North America) at blemon@hubspot.com. This session was recorded on August 19, 2020.", "date": "2020-08-21"},
{"website": "Hubspot", "title": "Introducing ‘Building Your First Web App’, an Online Course Built by HubSpot Engineers", "author": ["Zoe Sobin (She/Her)"], "link": "https://product.hubspot.com/blog/building-your-first-web-app-free-coding-course", "abstract": "Not long after I became a senior software engineer at HubSpot, I started running technical interviews. I was instantly floored by how much experience some of the students applying had. Academic computer science education generally stays in a theoretical world. Although the high level concepts are relevant to the problems faced in a professional setting, few classes are teaching the specific technologies that are used at tech companies. And, recruiters often notice this gap in experience when they review candidates applying to tech jobs. I had no idea when I was in school that there were students who were finding ways to gain experience in these technologies and present them to potential employers—and it was making them stand out. After reading more resumes and talking to applicants, it quickly became clear to me that these (generally male) students had a huge leg up by the time they were ready to join the workforce. They had created communities where they were sharing ideas, helping each other, and raising the bar in a way that you wouldn’t realize if you weren’t a part of it. To be totally honest, this made me really angry. I was angry at myself for not realizing what I could have done differently while I was in school and angry that there could be people, just like me a few years ago, who were missing out on opportunities just because they didn’t know what was valued by the industry. I felt confident that there were large groups of people who were smart, capable, ready to learn and even graduating with computer science degrees but who just didn’t have the kind of experience that tech companies were screening for. I brought this up to the HubSpot recruiting team and together we came to the conclusion that something had to be done. The facts were right in front of us. The percentage of women in computer science has rapidly declined, and according to recent research , only 18% of computer science graduates are women. The absence of women has been linked to non-inclusive cultures and a lack of confidence. Developing a Resume-Ready Application So, how could we encourage more undergraduate women to pursue careers in tech, and, better yet, help to give them the skills needed to succeed in this field? What we knew for sure was that we couldn’t approach this with another predictable “class” or “seminar.” Tech is an innovative, constantly changing industry, and one of the best indicators that someone is going to succeed is their experience creating living, breathing projects, rather than their grades in the classroom. It's not always easy to get started with a project from scratch. The frustration of running into error messages alone can lead to lack of confidence and self-doubt. What we developed was HubSpot’s Web App Workshop , aimed at toppling the initial barrier to building a resume worthy application: outside experience with tech projects. Our hope was that it would not only help women (and men) see how important outside projects are (and arm them with the tools to continue making more), but also help them land a job in the tech workforce. The response and feedback was overwhelming. The workshop was not only providing hands-on experience to add to resumes, but also offering attendees a look into what a career in tech or computer science looks like, complete with real-life examples of women role models excelling in an oftentimes male-dominated world. So far we’ve run this workshop and variations of it around 15 times, in Ireland and in the US at our office locations, and at about five different schools. The original GitHub project has been used by over 400 individuals wanting to learn how to build their first web app. Introducing “Building Your First Web App”, A Free Online Course on HubSpot Academy Because of the success of the workshop, the impact it has had, and the communities it’s helped to create, I'm excited to share that the “Building Your First Web App” workshop is now available online, for free . You can take the course on HubSpot's Academy Learning Center so that no matter where you are or what your background is, you can get a helping hand with building your first web application. The online workshop will mirror the successful format of the in-person workshop with interactive videos, interviews with HubSpot product leaders, and tutorials. While the online workshop won’t replace our in-person events, the hope is that we can reach the masses and create a movement for the future generations of tech workers. This course was inspired and built by women at HubSpot, but it's designed for anyone, anywhere, who's passionate about coding and is ready to build something great. If interested in taking the workshop, you can find it here . For those looking to join us at HubSpot, either as an intern, co-op or in a full time position, we’re always hiring in product and engineering. Check out careers available here.", "date": "2019-08-13"},
{"website": "Hubspot", "title": "A New Content Platform For A New Dev & Design Site", "author": ["Elizabeth Dunn (She/Her)"], "link": "https://product.hubspot.com/blog/the-new-cos-blog", "abstract": "Welcome to the new HubSpot Development & Design site! We’ve made a bunch of changes around the place. Take a look around. For instance, there’s now a short video on the home page that tells you a little bit about what it’s like to work on the product team at HubSpot. There’s also a pretty sweet People Page that lets you get to know some of the individuals that make up the team here at HubSpot Dev & Design. But what we’re most excited about is the fact that we’ve built this whole new site on the brand new HubSpot Content platform. In fact, it’s the very first site ever to be built on this new system for managing your content online, and we’re psyched to take it out for a ride and see what this baby can do. We're calling our new platform a Content Optimization System (COS) because it's much more than a CMS. And let’s face it, as a bunch of developers and designers, we’re usually too focused on building stuff to ever really be able to spend much time using what we’ve built. It’s always just as important to move on to the next thing, you know? Always something else needing to be built. You know the drill. But this new HubSpot COS is something really special. It’s a whole new way of managing your content online. This blog, for instance, is running on the new COS, just like the rest of the site. And just like with any great blogging platform, the HubSpot COS makes it easy for you to create and manage your posts, comments, modules, authors, templates, and on and on. Naturally, we’ll be improving and iterating on our new COS in the days and weeks to come. But we’d love to hear what you think. Got feedback? Lay it on us.", "date": "2012-12-14"},
{"website": "Hubspot", "title": "5 Rules for Better Backbone Code", "author": ["Gabriela Lanza"], "link": "https://product.hubspot.com/blog/5-rules-for-better-backbone-code", "abstract": "Backbone is a hugely popular MV* framework because it gives you a ton of freedom of implementation. There is no one \"Backbone way\" to accomplish most coding tasks. This freedom is wonderful when you need it, but when you don't, Backbone's lack of official guidance makes it easy to stray into some bad patterns. When writing new code, try following these rules, and you'll likely find that your code will be far more modular and easier to understand. Note that these rules assume that you're not using any advanced Backbone extensions. Projects like Marionette attempt to solve these issues in different ways. Rule 1: Views may point to one and only one Model Views which need to reference more than one Model are warning signs that you're trying to do too much with one class. Instead, break your large View into two or more Views. The View's model should always be stored as this.model . Similarly, Views should point to no more than one @collection. Rule 2: State must be kept in Models - not Views, and not the DOM Don't store extra attributes like \".addressHidden\" on your View - attributes stored this way don't fire change events and are difficult to persist. Instead, find a way to express the state at the Model level - as \"hasAddress\", for example. Don't wait until a \"submit\" user action occurs to store Form data. While you're waiting, you're leaving precious user-entered state in the DOM. Instead, take the data out of the DOM as quickly as possible and store it in a Model, even if it isn't validated yet. It isn't a View's job to validate data, anyway. Rule 3: Objects may not be stored in Model attributes Setting any of the keys of objects nested in this way will not trigger a \"change\" event, and nullifies the biggest benefit of using Backbone Models. Data should always be stored in a way that's reliable to watch for changes. Rule 4: Models may point to other models This is a reasonable alternative to storing objects inside of model attributes. You can override toJSON() and parse() in your Models to convert between nested objects and Model pointers. Rule 5: Models may not have more than ten attributes Models with more than ten attributes are unlikely to be cohesive. Smaller, more cohesive Models reveal their intention more clearly when they are passed into a function. Do you really need the whole \"User\" Model, or just a \"UserContactInfo\" Model, to accomplish this task? If your API has resources with more than ten keys, don't be afraid to split the data into separate Models in your parse/toJSON implementations. Just because data is stored together doesn't nessesarily mean it needs to be manipulated together. Conclusion It's important to be able to notice early warning signs of bad code before it has morphed into spaghetti. What are your tips for designing Backbone systems?", "date": "2013-09-13"},
{"website": "Hubspot", "title": "Sprint planning at HubSpot", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/7875/sprint-planning-at-hubspot", "abstract": "The Sprint Planning Meeting is an important part of Scrum , our agile product development framework.  You can read more about the purpose of the meeting online, e.g. on ScrumMethodology.com. The main goals are is to finish prioritizing user stories, to talk about their details, and for the teams to commit to delivering a certain set of user stories in the coming sprint. Formally, we call this moving the stories from the big, all-encompassing Product Backlog, to the specific, locked-down Sprint Backlog. At HubSpot , we do this almost entirely by the book.  In reality, we do much of the prioritization before this meeting.  The product owner(s) gets feedback from business stakeholders as well as developers to help estimate and prioritize all the user stories.  We also play a game of Planning Poker the day before the sprint planning meeting, to help us come up with better estimates. Nonetheless, we do some detailed task creation and analysis during this meeting, and we definitely do the public commitment of what we'll deliver to the rest of the company.  This creates a powerful internal drive to deliver. Below are some pictures from today's sprint planning process.  They are shared just for fun, not because they're particularly informative. If you use Scrum, how do you do your planning meetings?  Have you diverged a lot from the basic Scrum framework, and if so, how / why?", "date": "2009-07-07"},
{"website": "Hubspot", "title": "Sharing the Load: Where to Go for Help as a New Product Manager", "author": ["Angela DeFranco"], "link": "https://product.hubspot.com/blog/where-to-go-for-help-as-a-new-product-manager", "abstract": "You just got asked to Product Manage a sweet new piece of software, and you're pumped! And why shouldn't you be? Product management is one of the most rewarding, challenging, and, at times, exhilarating jobs a person can get. But it is also one of the most difficult ones. Let me get a little middle-school-paper-y for a second. Wikipedia defines Product Management as: ...an organizational lifecycle function within a company dealing with the planning, forecasting, or marketing of a product or products at all stages of the product lifecycle . A bit vague and a lot there. So I have to forecast, plan, market, and (unmentioned by wikipedia) develop some product at ALL stages in its lifecycle? Is it possible for a new product manager to do that alone? Not really. As with most high responsibility jobs, product management also leans on people you can turn to in order to achieve the goals you set for yourself and the product. Having the ability to harness these relationships early on is crucial, but can always be developed over time. As a new product manager myself, I'm still learning the ropes when it comes to responsibility Venn Diagrams, but I've got the following people down as those who are willing to help: The Technical Lead The Tech Lead is your go-to for the actual \"building\" of the product you've been graced with. If you're anything like me, leaning on someone whose technical abilities eclipse yours is a wonderful thing. Get to know him or her. Take the time to ask the right questions and don't be afraid to ask basic ones, too. Invigorate your product knowledge, especially in  the beginning, about the technology stack, tests, and plans for future technical tools from this person. Not only will you find their opinion and decision help invaluable, but you will also reach high productivity levels through this collaboration. The (Interaction) Designer Do you think you have a knack for art? Maybe you're a business student who always secretly wanted to get involved in making things look pretty? Or maybe you're an engineer who thought design was just a lot of CSS. No matter what your preconception of design is, I suggest scrubbing your mental cache and starting fresh with your UX Designer. A designer is one of those people who helps you balance what you think you know about user interfaces with what you need to learn about UI. Not only will they help you put into visuals what you have stuck in your head, but they'll also keep you in-tune to the way your users think, down to the button click. Give them an idea, and draw it out together to get started. There's nothing more helpful than having a professional work through an idea with you visually. The Product Marketing Manager A product marketing manager is typically in charge of getting the word out about your product and help train the rest of the organization. Whether it's a fancy new feature or an overdue UI update, they help get the messaging down solid. In my case, the PMM provides a much needed boost of \"this is cool\" while building seemingly mundane product features. Part of your job as a product manager is to effectively sell this tool to all stakeholders, and the PMM is the one to lean on if your sales and marketing skills are a bit lackluster. The Usability Tester This person is responsible for keeping you in touch with what your users are asking for and where they're currently struggling in the product. A UX expert has a good handle on your customer base, and if you're coming to this position from an external role, it's incredibly valuable (necessary even) to know your customer. Lean on this person for advice on how and when to test ideas with real-live customers! It's also a great way to jump right in as a beginner, since you'll likely have some action-items after your first few user tests. Depending on how your Product team functions, this person will likely help you plan out beta periods for your app as well, so be sure to work with him or her and ask the right questions when it comes down to figuring out the validity of your idea. The Customer Service Professional If you're lucky enough to have a dedicated UX person, you're already on your way to keeping customer concerns front of mind. But what if you need to know what customers are having trouble with without being asked? This is where a tech support teammate, customer service person, or general boots-on-the-ground guy comes to the rescue. Being in one of these positions is like being a lifeguard,  you see some people swimming around enjoying themselves in the sun, but most of the time you're looking out for the poor swimmers. You're trained to help out someone in need, and you're generally wary of the dangers of the water. As a PM, this pain-point information is incredibly valuable for the success and adoption of your product. Or, to continue my amazing analogy, as the owner of the pool you're not going to close down if someone starts drowning in the deep end, but you are going to asses the risk factors that led that event to happen. Point being: get this persons input on the current points of friction in your product. The Boss When you get started as a PM, there's one person that can understand the trials and tribulations more than most other people. This person will likely be your boss. When dealing with difficult situations, especially in the beginning, it can be helpful to get input from someone who has years under their belt. In my case, I'm lucky enough to work with a team of amazing PM's that all have very unique styles, and observe how they make decisions. My boss, being the VP of Product at HubSpot, is a great resource for information on past product decisions that have been made, \"beginner\" questions about functionality, and all around future guidance. No matter where you are in confidence levels for product decisions, having a more experienced PM to run something by is an amazing benefit to take advantage of. The Friend Last but certainly not least, we come to the Friend. This person is, you guessed it, a friend to you! This doesn't have to be a product person, or a technical person, or even someone familiar with the problem. This person simply needs to be someone you trust, and can go to for general advice on decision making. For me, there are many people that fit this role, and it helps a lot when I run things by friends I have in the company. They give me unadulterated feedback, simply because they're not as familiar with the ins and outs of the decision. It's a \"shortest distance between two points is a straight line\" type thing, because sometimes you need to take a couple steps back to see the simplest thing to do. Of course, decision making isn't the only strength a friend has to you as PM. They also remind you that you're doing good work, that you are making an impact, that you need to enjoy the small things once in a while too. If you've learned anything from this, I hope it's that building products is not a one-person job. It takes a team of invested, intelligent people to make the right decisions to get shit done. It is not easy, and these relationships won't be built overnight. There's no sugar coating the confusion a PM feels when she or he is in the middle of a difficult and important decision, but leveraging the advice from those around you is the best way to take a step in the right direction.", "date": "2014-03-05"},
{"website": "Hubspot", "title": "How We Deploy 300 Times a Day", "author": ["Zack Bloom"], "link": "https://product.hubspot.com/blog/how-we-deploy-300-times-a-day", "abstract": "Part of my job at HubSpot is to meet and welcome new potential HubSpot engineering hires. One of the most surprising things I get to tell them is that we deploy 200-300 times a day. Let's look at what makes that possible: Small Teams and Projects As we grow, we do it by letting our teams focus on smaller chunks of the product (and by having more product), not by throwing more people at the same problems. No matter how much we grow, there is always a single team of three or four developers who own and are deploying any part of the product. Through this, we have avoided having to create numerous staging environments. Most importantly, each of our projects can be ran locally and deployed individually. Libraries One reason a team might not be able to move towards smaller projects is a need to share code. We work around this by creating common libraries to nurture shared utilities. One lesson we've learned is the danger of allowing these libraries to become collection points for every random bit of code a developer wants to hang on to. In what we build now we are very careful to make each project do a single thing in a way that can be easily understood and documented. Our open-source projects are good examples of this philosophy. Automated Builds When a commit gets made to master, a build kicks off in Jenkins. When the build is done, a developer can send it to qa or prod from the terminal, or the web UI. For most of our frontend projects a 'deploy' just means bumping a static pointer on our CDN, and only takes a few seconds. It stands to reason that you can't deploy a lot if each deploy isn't fast and easy. For backend projects this is accomplished by a fabric task connecting to each server hosting that application, and to each load balancer that application is behind. The build is pulled down from S3 and spun up on it's own port using monit . Once the new process has passed a health check, the port numbers are swapped in the load balancer, and the old processes are killed. All of our builds live forever as tarballs on S3. So we can deploy any build at any time, or rollback to a previous build at any time. Having our deploy system fully standardized lets anyone do a rollback, even someone not familiar with the project in question if need be. Versioning When a build runs it locks in the versions of every dependency. This means that if that build is deployed today, or in a year, it will still point to the correct dependencies. Our static build system gives us the ability to lock our projects into specific dependency versions, similar to npm. With locked versions, we can upgrade libraries and change projects without fear that downstream projects will break. All of our services communicate over versioned APIs, allowing different versions to coexist simultaneously. This also means that a part of the app can only change when it itself is deployed; other projects getting changed or deployed won't have any effect. With this we can ensure that a project can only break when a member of the team that maintains it is at their keyboard. Black-box Deploys Taking a page out of Heroku's playbook , we have adopted a Procfile based deploy system. What this means is that every type of project has a set of files which explain how they are built and ran. Our deploy system only needs to know what it should run, what environment variables it should set, and how to make sure it's working. Beyond that, everything is generic. This means that any service can be deployed to any of our EC2 instances at any time. We can deploy Java, Node.js, even Go. It also makes debugging easier: Every machine is configured with one of a handful of configurations, every process logs to the same places, is restarted the same way and is deployed the same way. We try to extend the idea that each project should build it's own environment as far as we can. With Node, for example, we use nvm to allow each project to define its own Node version and package the binary with the built files. While we do use puppet for machine-level config, only a handful of people have to touch puppet config files day-to-day. Gates Fucking Ship It Already: Just Not to Everyone At Once - http://t.co/h1273a2RpM #shipit — David Cancel (@dcancel) October 28, 2013 That quote is courtesy of David Cancel, our former Chief Product Officer, and it accurately describes our attitude towards getting code to production (including the profanity) . Every minute code lives in a branch, it is aging and dying. We do everything we can to get it onto master and into the product as quickly as we can. One tool is the 'gate'. A gate is a switch we can turn on or off for a specific set of customers. Gates let us test new features or changes on our internal account, then with a subset of users, before rolling it out sitewide. Features can live behind gates for months while we work through feedback and make revisions, or just for a few hours while we send out notifications to the team. Notifications One of the biggest issues we've faced as a B2B company moving quickly is learning how to effectively communicate with our customers about changes. For us this means posting big changes to a notifications page, adding a notifications bug to our nav bar, and sending emails with these changes to the HubSpot team so we could all be on the same page. We also had to learn how to communicate these changes and time releases such that people could have enough warning to make them comfortable. We also learned to give people time to make big changes. When we reengineer a big part of the app, we do everything we can to allow people to switch in their own time. Testing As I've said we deploy 300 times a day, but we only have 85 engineers. This means that any given engineer is pushing the deploy button four times a day. Without some amount of automated testing, each engineer would spend the bulk of his or her day just clicking links and making sure he or she didn't break anything. We try to cover critical libraries well with unit-level tools like Jasmine , as no one wants a library change to break half the site (although, nothing can break if it itself is not deployed). One thing we don't do is TDD. We write Selenium-style tests after things have broken the first or second time and we want to make sure it never happens again. If an issue does occur, we can fix it in another deploy in just a few minutes.  This ability to correct mistakes quickly means we can tolerate small bugs and issues which are only around long enough to effect a tiny group of customers.  This leaves our testing more focused around preventing whole apps or systems from being taken down. Pull Requests HubSpot engineers open an average of 78 Github pull requests a day. Although using them is not required or enforced, they are critical in catching errors and misunderstandings before they make it to production. Some PRs get merged immediately by the engineer who opened them, others can accumulate dozens of comments and edits before being merged. The general practice is to @-mention interested engineers on your team and any other team which might be effected by the change. Those mentioned will reply with comments, or just a quick . Integrations If a commit includes a ticket id, it is associated with that JIRA ticket. When that commit gets deployed, the ticket is automatically updated. This allows engineers to close tickets when an issue gets fixed without having to wait for the full deploy process to finish. It also keeps stakeholders informed so they don't have to wonder when their change will really show up. Deploys also post HipChat messages in the relevant team's room, helping team members to figure out what's up if an issue appears. Configuration Every company goes through an evolution in how it manages configuration information. First it's inline with code, then in dedicated config files, and eventually, in a distributed system. We use a webapp on top of ZooKeeper to synchronize the 2500 configuration bits and pieces and distribute them to our 1500 EC2 instances. Configuration values can be updated and distributed to our whole network in about sixty seconds, allowing config to be changed on running instances without redeploying. Monitoring We have an internal tool called Rodan which gathers metrics from all of our services. Based on rules, the service can alert us with PagerDuty when something goes wrong. The balance between under and over alerting is something we've had to learn over time. It is very easy for engineers to get alert-fatigue and begin to ignore critical notifications. One thing we've done is to only allow our QA systems to alert during working hours, to ensure that non-critical systems aren't waking up anyone in the middle of the night. Metrics One of the first things we did when it came time to improve our reliability is figure out what metrics we could track to let us know if we're moving in the right direction. We built tools like Bucky , and adopted ones like OpenTSDB . We use this data to ensure both that individual changes don't cause performance or reliability issues, and that we are improving in the long-term. With Bucky we track timing data from every page load and API request, as experienced by our users. We also get a Sentry alert if any part of our app fails to render certain elements in a reasonable amount of time using an internal tool called Reagan. Once we have that alert, we can use another tool called Waterfall to track the request all the way down to our databases. Process One theme you'll notice is that we try not to operate with hard-and-fast rules or process. We leave it to the individual engineers to decide how much PR review, how much testing, and how much waiting they need to do. We can provide metrics, tools, advice and experience, but at the end of the day, it's the individual engineer's responsibility to build quality software. This model works if you only hire smart people you trust, and if you can take the occasional screw up in stride.", "date": "2013-11-18"},
{"website": "Hubspot", "title": "The HubSpot App Marketplace (Part 1): HubSpot App Lifecycles", "author": ["Adrian Mott"], "link": "https://product.hubspot.com/blog/bid/68218/the-hubspot-app-marketplace-part-1-hubspot-app-lifecycles", "abstract": "Yesterday, we were happy to announce the creation of the world's first marketing app marketplace .  The HubSpot App Marketplace will allow developers to build application on top of the HubSpot Platform using our API's and have them run right within the HubSpot code product.  This gives any apps in the Marketplace fantastic visibility to over 15,000 customers, trial users and partners. I wanted to take a few minutes to talk about how the Marketplace is setup to let developers register, test and take their apps live.  Because the App Marketplace is very young, this whole process may change, but setup as it is today, here's the rundown on how to get your apps into the HubSpot App Marketplace: Develop the idea for your app and build it! - Your app can be literally anything, but the apps that are going to be used and offer customers the most amount of value are going to be those that utilize the HubSpot API's .  Our API's let you manipulate core HubSpot data, including Leads, Blogs, Marketing Events and Lead Nurturing Campaigns.  If you're not a HubSpot customer, you can still get access to the API's by either creating a free trial or using the API demo portal . Test your App Locally - You will host your app yourself.  This means that you should build and test it locally in your own environment before registering it with us. Register and Test your app within HubSpot - Once your satisfied with your app and want to see what it looks like within HubSpot, register it .  Once registered, your app will be \"In Development\" within HubSpot so you can test it as much and for as long as you'd like.  Only when you change the app's status to \"Submitted\" will we look at it, make sure it works as designed and take it live for you for all to use. There are different types of HubSpot apps: External, Canvas and Widget (for now). External apps run completely outside of the HubSpot core product, Canvas apps run inside of the core HubSpot product and also get their own menu item under our \"Community\" tab, Widget apps allow you to populate a small area of a page with information. We're really committed to getting as many apps as possible written, in the marketplace and being used by our customers.  If you're interested in writing an app, please see the HubSpot API documentation (there's a section about the App Marketplace on the front page there), get a free trial to check out the product and make a killer app!", "date": "2011-07-13"},
{"website": "Hubspot", "title": "The Hard Part About Creating New Teams Within an Engineering Organization", "author": ["Eric Richard (He/Him)"], "link": "https://product.hubspot.com/blog/the-hard-part-about-creating-new-teams-within-an-engineering-organization", "abstract": "Part of continuous innovation means we’re constantly spinning up new teams with new missions within our product organization. One of the key challenges here is ensuring that team has the core HubSpot DNA that will allow it to be fully successful on its mission. Growing that DNA in isolation is possible, but slow. Finding a way to quickly infuse our core values and culture into those teams can really accelerate their ramp. As our team and product grows, we’ve been investing more energy into finding that solution, and we think we might be onto something. We’ve considered a number of different options for structuring new teams and almost made what could have been a few big mistakes. Not because the people we were looking to put on certain teams aren’t talented -- to the contrary, we considered putting some absolutely amazing rising stars on new teams. But because we would have been ignoring one key lesson we’ve learned the hard way: put new people on established projects and established people on new projects. Here’s the basic premise. If someone is new to the organization, they need to focus their energy on becoming a great HubSpot engineer -- learning our stack , culture , and everything else that goes along with that. The best way to help them succeed is to put them in a world that is reasonably well-defined and surround them with team members who can help them grow. In contrast, if we have a greenfield opportunity, like a new team or product function, where there is a high level of uncertainty around the path it might take, the best thing we can do is put an established HubSpot veteran on that project. They don’t have to think twice about culture or stack, but instead can focus on solving the problem at hand, move quickly, and share that DNA with the rest of the team. When you put those two things together, it leads to the simple conclusion that we should be putting new people on established projects and established people on new projects. Sounds easy, right? In practice it actually isn’t because it involves change and, change is hard. The easiest thing to do (from an organizational perspective) is to just hire new people and throw them on this new project. They don’t have an existing team so you aren’t creating any friction; just drop them in and set them loose. That way there’s no need for lots of meetings, transition plans, worries about hurting feelings, etc. This might work in the short term. But ultimately, it does a disservice to the team. They’ll have a harder time doing things in a HubSpotty way and won't get to benefit from all of the playbooks that we know work. That’s why the right decision is to find an established person (meaning they are already on a team and presumably have a good thing going there) and give them the opportunity to move to this new project. What this should look like then is a constant cycle where the new people we are hiring today become the foundation for existing teams tomorrow, freeing up the existing members of the team to jump to the “next big thing” at HubSpot in the future. This doesn’t mean that we can never put a new hire on a new team. But the key is making sure new people have the right anchors in place to make them successful. For example, if we have an established HubSpot tech lead paired with an established HubSpot senior software engineer, they could probably take on a new hire and keep running on a greenfield mission. We tend to be very reluctant to hire people in as tech leads for exactly this reason and only do so in very exceptional situations. Instead, we regularly hire people who have been tech leads at other companies but bring them in as individual contributors first. It lets them ramp up on the culture and tech stack without expecting them to do that while leading a team. We've found that this maximizes their long term success by giving them a safe environment to learn in. This \"put established people on new projects\" rule of thumb saves us a lot of time (and headaches) in the long run, but it takes a village to do a team migration well. We know we have succeeded when all interested parties were a part of the decision and are on board with the change and it doesn't feel forced or rushed. Often times, that’s the case, but we need to keep getting better at this. Here are a few things we’re thinking about as we scale new teams and work on improving our migration process: We need to find the right balance between stability and change. My goal here has been to ensure that within a team there is a sense of stability so a new team can feel established over reasonable time periods (let's say 12-18 months.) But, in aggregate, across all of engineering, there is a fairly constant set of changes happening. Say, for example, we had 40 teams within product. If we made one migration per team every 18 months, that would mean nearly two migrations per month across the organization. That's a lot of change, even if it is a small amount of friction for any specific team. We need to make sure we are not being chaotic but are also not being stagnant as the team grows. We need to keep rewarding both exciting and existing work. There are some people who want to jump on the next greenfield opportunity and create the next Sidekick or Leadin. And there are others who are more interested in optimizing, scaling, and solidifying our existing systems. We need to make sure we are providing exciting challenges for and rewarding both types of people as they each play extremely important roles in our success. It can be easy to focus on the shiny, sexy work of new projects and miss the importance of the plumbing work. But it is that plumbing work that drives our performance, our ability to scale the company, our reliability, etc. We should always be looking to optimize for the individual and EV (Enterprise Value) over the team. This is a tricky one (and why things can get hard), but our migration decisions should be driven by what is good for the individual and for the company, and less by the team itself. Optimizing for the individual allows us to keep growing and giving people new opportunities to stretch and grow. Optimizing for EV ensures that we are continually driving the business forward. Optimizing for the team can lead to calcification and can actually hurt both EV and individuals. We believe that putting new people on established projects and established people on new projects will help us scale that HubSpot DNA as we continue to grow. But only if we do it the right way. Keeping these three learnings (and others we discover as we grow) top of mind is critical in making migrations a success.", "date": "2015-07-08"},
{"website": "Hubspot", "title": "Why We're Excited About HubSpot's Latest Acquisition, Rekindle", "author": ["Brad Coffey (He/Him)"], "link": "https://product.hubspot.com/blog/why-we-acquired-rekindle", "abstract": "Welcome to HubSpot, Rekindle! We announced today that we acquired Boston-based social graph company, Rekindle. We’re beyond excited to welcome their team, talent, and innovation to HubSpot. Here’s why. At its core, our software has always been about connecting people. By transforming their marketing and sales approach, our 13,500+ customers have been able to reach their audiences to build relationships and ultimately fuel growth. Without the right tools and products, it can be a challenge for businesses to make those connections. We were drawn to Rekindle from the get-go because they share this vision of connecting people. Co-founder, Matt Grace, saw an opportunity to use contact graph technology to introduce new friends or colleagues and reacquaint with old ones. The platform aggregates the most updated contact info from across a variety of networks to reduce the noise and amplify the data that will ultimately connect one person with another, meaningfully. There are a ton of technologies out there that were designed for people to interact; Twitter, LinkedIn, Gmail, and Slack are open in my browser right now. Rekindle stood out from the pack because it’s not just about connecting, but connecting in a more human way. We are in the early innings with our sales products and Rekindle is the kind of muscle we need need to fuel customers’ growth through the CRM and Sidekick . But even with a great product, technology, and vision, there’s one key factor that tipped the scales on this acquisition: the team. We take culture incredibly seriously here. We believe in hiring people that we can learn from, have a good time with, and trust to make the right product decisions. Not surprisingly, top talent that fits that bill can be hard to find. We got to know Matt, Cappy, Alex, and Gigi over the past couple months and our teams clicked quickly. They showed a commitment to solving for the customer, the ability to move quickly, a GSD (get shit done) attitude, and a curiosity to learn- all ingredients we look for in good culture fit candidates. We were lucky to find a team that would seamlessly integrate into our product organization and help us raise the bar. Rekindle was born and raised in Boston, just like HubSpot. We’ve always been excited by all the tech innovation happening right here in our backyard; there are constantly big ideas, new technologies, and top talent coming out of schools like MIT, Northeastern, and more. We have strong roots here and are thrilled to add local talent to our team as we continue to build a pillar tech company in Boston. Please join me in welcoming Rekindle to HubSpot!", "date": "2015-03-24"},
{"website": "Hubspot", "title": "Who Loves the Magic Undocumented Hive Mapjoin? This Guy.", "author": ["Dan Milstein"], "link": "https://product.hubspot.com/blog/bid/30170/who-loves-the-magic-undocumented-hive-mapjoin-this-guy", "abstract": "So, I've got this nice Hive join statement, joining a tiny little partition from one table against a sizable set of partitions from another.  And I'm running it, and it's taking a while.  And I can tell,from looking at the job, that it's doing the join reduce-side --meaning, it's generating the cross-product in the mapper, and then sending it over to the reducer to filter it down. But, clearly, this is a perfect fit for a map-side hash join (meaning, hold the entire tiny partition in memory in each map task + run no reducers at all).  If I was coding it myself, I could make this happen via a bunch of coding +some configuration trickery.  But, surely, Hive will make it easier, no? The docs had little to tell me, but I saw Jira tickets about adding this ability, and finally found a mailing list message which had the magic incantation.  It's a hint within the statement, just convert this: SELECT t1.portal_id, t2.lead_id, t1.visit_time, to this: SELECT /*+ MAPJOIN(t2)*/ t1.portal_id, t2.lead_id, t1.visit_time, Done, and now my entire job is running in the mapper and is taking about 30% of the time it used to.  Woo.  Big points for Hive, for damn sure.", "date": "2009-11-06"},
{"website": "Hubspot", "title": "Meet the Movers and Makers: Jen Huang, Tech Lead", "author": ["Hannah Fleishman (she/her)"], "link": "https://product.hubspot.com/blog/meet-the-movers-and-makers-jen-huang-software-engineer", "abstract": "Name: Jen Huang Role: Tech Lead, Sidekick for Business What are you reading right now? The Count of Monte Cristo How do you like your coffee? With as much milk and sugar as I can put in it. Now, on to the good stuff. A few years ago, we started a snapshot series introducing HubSpotters like Paul , Anthony , and Laura . We're back at it and are excited to keep profiling the makers behind HubSpot, starting with Jen. (Her adorable dog and team mascot, Cody, made it to our Q&A session, too. We'll be sharing his valuable insights later on). How did you get to HubSpot? I studied computer science with a minor in digital arts at Dartmouth, and worked in New York for about 2 years after school. At the time, I wasn’t thrilled with my job, and my family and a bunch of friends lived in Boston so I was always thinking about moving back. I’m pretty sure I googled “Startups in Boston” and that was how I first found HubSpot. I did some digging and saw they were on a best places to work list and decided to apply. I had never done web development before and had never heard of inbound marketing, so I didn’t have high hopes but figured I could use the interview as practice. Fortunately for me, everything went really smoothly and I had an offer the next day. I really liked the people I had met and the engineering team felt small and collaborative, so I accepted and the whole thing happened pretty quickly from there. Now here we are, four years later. What’s been your most challenging project at HubSpot? I’ve worked on a few teams at HubSpot and have had the opportunity to work on some pretty cool projects here. The most challenging was probably when our engineering team made the decision to rewrite the majority of the product, and my team (of two) was tasked with completely re-architecting the analytics pipeline. It was a daunting project for someone who had to wikipedia Hadoop on her first day at HubSpot. We spent the following year overhauling our old analytics pipeline to a brand new stack (Java and HBase) that was able to support our rapidly growing analytics traffic. I learned more in that year than in the entirety of my time at my previous job, and it really cemented how much ownership HubSpot gives each developer. Tell me a little bit about your team and what it's like working with them. I really love the people I work with. They are among the smartest people I’ve met, and incredibly helpful. People here want to share their knowledge, and they hold everyone to a high standard which keeps our quality of work high. There’s always somebody willing to brainstorm with you or help you debug something or just explain how their piece of the product works. We have weekly Tech Talks where a developer will share some piece of tech they find interesting, ranging from new frontend frameworks to the inner workings of HBase. That’s been happening since my first week here at HubSpot and it’s incredible that it’s been going on (weekly!) for more than four years. What’s one thing that you think is unique to building products at HubSpot? How fast things move here. Deploying code is second nature; you do it so many times a day it feels like business as usual. It’s only when you talk to people at other companies that you realize not every place works like that. To get code to production at my last job, I had to commit my code by Friday, wait for it to get to QA on Monday, and then gradually see it rolled out to production by Thursday. Not only that, everything I did there needed approval, whether it was committing code or ungating people for features. HubSpot on the other hand, gives me complete freedom to make my own decisions with the expectation that I will make mistakes and learn from them. Anything else? You’d be surprised at how interesting the problems we solve here are. It’s not just marketing software, it’s marketing software at a pretty large scale so there’s a huge range of cool projects. Take our COS for example, that team is facing a completely different set of challenges than what our Contacts or Analytics team is tackling, and our PaaS team is behind some of the best products I’ve ever used as a developer. No matter what you’re interested in, you will easily find something awesome here to work on. Last but not least, what’s your favorite part of the Culture Code ? Probably the fact that everyone has a GSD (Get Shit Done) attitude. What’s important here is building product, that’s it. The culture of wanting to build the best product for the customer is pervasive across every team, and there’s an expectation that you’re delivering something cool every day. I'm afraid we couldn't get to more questions because Jen was busy getting shit done. But if you want to connect with her, say hey in the comments below and stay tuned for our next Mover and Maker profile!", "date": "2015-05-08"},
{"website": "Hubspot", "title": "Meet the Movers and Makers: Steve Purcell, Tech Lead", "author": ["Hannah Fleishman (she/her)"], "link": "https://product.hubspot.com/blog/meet-the-movers-and-makers-steve-purcell-tech-lead", "abstract": "Name: Steve Purcell Role: Tech Lead, Leadin Hometown: Dublin, Ireland Last book you read: The Innovator’s Dilemma . In the early stages of Leadin we spent a lot of time reimagining inbound marketing and exploring how we could make it accessible to everyone. This book is all about disruption so it was a great resource along the way. What made you want to become an engineer? My aunt works in Germany and she would bring her laptop back to Ireland with her over the holidays. That was the first computer I ever touched and she could tell I was enamoured with it. She encouraged my parents to get me one so when I was about seven, they bought me a used computer from an internet cafe. I spent a tremendous amount of time on it and quickly became the kid everyone on our street came to when they couldn’t log in. I started a computer repair side business, the whole works. Then when I was 15, one of our neighbors offered me a summer job doing internal tech support at a nationwide bank where he was the head of IT. I ended up working there over a few summers and on some weekends, and became more and more adept with how their systems worked. The best part was that this was the only bank in Ireland that was open on Saturdays and when I was 17, they gave me the responsibility of handling all internal support for 10 branches. I was the only tech support available on Saturdays for the whole country. That was my first taste of working in tech and the autonomy that’s possible, and when it was time to look into universities, I knew I wanted to study computer science. So, I applied to Trinity College and went there for my undergraduate and masters. How did you get to HubSpot? I had been working at Microsoft for about two and a half years when I found HubSpot (or, when HubSpot found me). At the time, I was on a team that built the marketplace for Microsoft Office and it was an interesting team: About half of us were fresh out of college and the other half were seasoned veterans. I liked working at a big respectable company with decades of tech history, but the team moved slower at shipping product than I wanted. I started going to tech meetups in Dublin to get a sense of what else was out there. I met Whitney (our VP of Platform Infrastructure) at an event and he invited me to HubSpot’s office for a beer. That beer turned into an interview and we ended up having dinner a bunch of times while he was in town from Boston. Talking to him about how much HubSpot cares about engineering and the type of people I’d be working with got me hooked. I knew it was the only company I’d leave Microsoft for. I was HubSpot’s first engineering hire in Dublin so before getting started, Whitney and I needed to build out a team. I referred some friends, one from IBM, one from Microsoft, and another from Trinity College, and the four of us started together in 2013. What types of problems are solving in your current role? I’m the tech lead for Leadin, a light, freemium version of HubSpot. The biggest challenges we’re working on have to do with scalability of the app. We run JavaScript on all of our customers’ sites so we can collect information about their visitors, but it’s not just any JavaScript, it’s smart Javascript. Our API (built with Java/Dropwizard) dynamically returns different JavaScript for different sites and visitors. For example, Leadin has a lead capture popup form and if a visitor has already filled out the form, then we don’t run that code on the site. We’re currently serving 30 requests per second and get a form submission every 5 seconds. So, a big focus for my team is processing that data in our Kafka pipeline and scaling those requests. What has it been like working on a startup within a startup project at HubSpot? It’s been pretty wild. My team had about 8 months to rewrite the entire Leadin app on HubSpot’s infrastructure . Then at INBOUND , our CEO launched it at the keynote to huge applause. We could not believe that 15,000 professionals were going crazy over an app that a handful of 20-somethings built. We were just looking at each other in disbelief. Tell me a little bit about the engineers on your team. I’m extremely lucky to work with Kevin , Cian , and Graham . Kevin has this unending passion for tech and the product. A few months ago, he was frustrated by one of the key pieces of our form scripting tech so he reworked it over the weekend and then came in on Monday, showed it to me, and asked if he should keep working on it. I thought: You better keep working on this, this is incredible. Cian started on the support team at HubSpot but quickly became driven to get into product development. After taking a Harvard programming course online, he worked on my team one day a week fixing bugs. You could tell immediately that he had the skills and passion to become an engineer so we gave him a full-time trial. He absolutely crushed it and we made him a permanent offer. Then there’s Graham. I’ve never met another engineer who cares so much about the customer. He’s always asking questions about the customer experience and he refuses to ship bad UX, no matter how much I rush him sometimes. What’s your favorite part of the Culture Code ? On one of the first slides, there’s a table that shows what the workplace used to be like and what it’s like today. Of the entire deck, the part that stood out most to me was the idea that employees used to focus on pension but now they’re focused on purpose. That struck a chord with me and I remember thinking HubSpot must be a great place to work if they recognize the pension vs. purpose shift and are actually using it to build their culture. Learn more about our engineering opportunities in Dublin here .", "date": "2015-11-12"},
{"website": "Hubspot", "title": "HBase tutorial: 5 tips for running on low memory EC2", "author": ["Bryan Beaudreault"], "link": "https://product.hubspot.com/blog/hbase-tutorial-5-tips-for-running-on-low-memory-ec2", "abstract": "When running on EC2 , you often can't win when it comes to instance types. One of the more cost-effective types available is the c1.xlarge. It has enough CPU to handle compactions, a decent amount of disk, and high network I/O. However, we've found that the relatively low memory of 7GB on the c1.xlarge often leads to stability issues in highly concurrent HBase clusters. While there are other more expensive options, this HBase tutorial will help you make the most of your c1.xlarge RegionServers. 1. Reduce the number of regions per RegionServer Ideally you should have less than 100 regions per RegionServer . The memstore is divided for use by all active regions, and each region adds (by default) 2MB of memory for the MSLAB . Cutting this number down will help things run smoothly, and not just from a memory standpoint. 2. Steal memory from other services You definitely shouldn't be running a TaskTracker with your RegionServer on these instance types, but you are most likely running a local DataNode.  A typical configuration calls for 1GB of memory for a DataNode, but we've found that you don't need that much in a lot of cases.  Verify your metrics before rolling this out, but we were perfectly safe cutting DataNode heap down to 400MB . This nice 624MB chunk will help HBase get a little further. 3. Tune or turn off MSLAB If after stealing memory and cutting back regions you are still having issues, you can go a step further. Like I mentioned, the MSLAB feature adds 2MB of heap overhead by default for each region. You can tune this buffer down with hbase.hregion.memstore.mslab.chunksize . The lower you go the less effective it is, but the less memory overhead as well. Turn it off altogether with hbase.hregion.memstore.mslab.enabled . 4. Be aggressive about caching and batching Caching ( Scan#setCaching(int) ) and batching ( Scan#setBatch(int) ) are great for limiting the effect of network latency on large scans. Unfortunately they also require more memory on both the client and server side. Keep in mind the speed trade-off, but enjoy a bit more stability by tuning these down , as close to a value of 1 as necessary. The RegionServer also has to have enough memory to handle all of your concurrent writes.  If you are heavily batching your writes, or sending a few very large cell values, you are likely to run into OutOfMemoryExceptions. Lower your batching here as well, or otherwise find a way to shrink the size of your cell values. 5. Control load from Hadoop If you are running hadoop jobs against your HBase data, you are basically running a lot of large scans.  In an HBase MapReduce job, each region becomes a mapper.  If you have more than 1 region per RegionServer, chances are that you are going to have a few mappers scanning the same RegionServer concurrently at some point.  Each of these scans is taking memory, disk, and CPU resources and when multiple build up it can cause some pain. Lowering hbase.regionserver.handler.count will help limit the number of active connections taking memory, but you could still have an issue if all handlers are handling large full-region scans. Using our extension of TableInputFormat , you can easily control how many concurrent mappers run against a single RegionServer , providing more predictable memory usage. If you are writing to HBase from a reducer, you are going to want to control partitioning there as well.  This is easily implemented using Hadoop's Partitioner interface, with HBase's HBaseAdmin interface providing the region to RegionServer mappings. Running HBase on low memory is hard, but not impossible With these tips in hand, you should be well on your way to surviving operations in your low memory environment. It can be frustrating to fight for every megabyte of memory in an age of extremely cheap, fast RAM. But follow these tips and your CFO will thank you for making the most of this cost-effective instance type. For those with a little more financial freedom, we will explore the impact of Amazon's new I2 instance types in a future post . So stay tuned!", "date": "2014-04-14"},
{"website": "Hubspot", "title": "Tech Talk: Getting Started with Chrome Extensions", "author": ["Erik Munson"], "link": "https://product.hubspot.com/blog/tech-talk-chrome-extensions", "abstract": "We've built our share of web apps at HubSpot. Web apps are awesome. They provide users with an accessible and portable experience through a tool they already know how to use: their browser. But what if you want your app to work alongside the web apps users are spending their time on? How do you give your users the experience they want, where they want it? Those are precisely the questions we asked when building Sidekick and a Chrome Extension turned out to be the way we could achieve the experience our users wanted. Chrome Extensions allow developers to build apps that enhance and extend both the web apps' users' visit and the browser itself. Extensions make some features possible that users have come to expect from built-in app platforms — like real-time notifications — without many of the downsides of built-in app development. Best of all, extensions are written in the same languages we use every day to build web apps — HTML, CSS, and JavaScript. In this talk, I explain what a Chrome Extension is and why you might want to build (or use) one. I also show some simple examples of how they can be utilized to provide a positive user experience; many of which might not be possible with a standard web app. Some resources: Google’s Getting Started Docs for Chrome Extensions : This page will give you a head start on creating your first extension, and point you in the right direction. Not too much architectural info, but a good place to start if you like to jump right into coding. Chrome Extension Architectural Overview : This will walk you through how Chrome Extensions are architected at a high-level. Not much detail on API usage or specific code, but great for understanding the bigger picture and how your extension actually interacts with the browser. Chrome Extension Sample Gallery : A full-featured example gallery with the ability to search for specific features or API usages to look at how they can be built in a real-world context. A fantastic resource for getting ideas and inspiration when trying to decide how to make use of the Chrome Extension APIs. Chrome Platform API Reference : A complete run-down of all the JavaScript APIs available to extensions. Great for when you need info on a particular API and want it straight from the authors.", "date": "2015-04-20"},
{"website": "Hubspot", "title": "Cheap videoconferencing for our daily standup", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/70504/cheap-videoconferencing-for-our-daily-standup", "abstract": "A couple of our dev teams are distributed, with remote members outside our Cambridge (MA) office.  My team has one developer in San Francisco, and while we could do phone conferences easily, we want to make that developer feel more like part of the team, so we're trying video. At the same time, we don't want to spend a lot of time or money on fancy videoconferencing equipment.  Enter the \" #GhettoFabulous \" method of Google Hangout on a rotating office chair. We take a standard chair, put it up on the desk in the middle of our standup conference room, put a laptop on it with a Google Hangout, and spin it around ;)  Sometimes we maliciously spin it fast, making the people on the other end dizzy, but most of the time we just rotate it gently from person to person as they speak. It's been working really well.  We had a day earlier this week where half the team worked from home.  During that standup, we had 5-6 live concurrent video streams in the Google Hangout, with no trouble at all.  Good video and sound quality, and a great help overall. Have you tried out something similar?  What worked, what didn't?", "date": "2011-08-04"},
{"website": "Hubspot", "title": "New: HubSpot Blog Client for Android!", "author": ["Stephen Huenneke"], "link": "https://product.hubspot.com/blog/bid/60805/new-hubspot-blog-client-for-android", "abstract": "Today we published the first version of the HubSpot Blog Client for Android to the Market. The app allows HubSpot users to post draft blog posts to their HubSpot blogs from their Android devices anywhere in the world!  Stay tuned for new features and future releases as we get feedback and fix bugs! Screenshots:", "date": "2011-03-09"},
{"website": "Hubspot", "title": "How to Crush a Backlog: Frontend Hack Night", "author": ["Jonathan Kim"], "link": "https://product.hubspot.com/blog/frontend-backlog-hack-night", "abstract": "Every team, engineering or otherwise, eventually accrues a backlog of todos, and the HubSpot Frontend team is no different. Over the past few months, we've been organizing a list of things that could help improve the stability of the product. Last Wednesday night, we ordered pizza, fired up music and split up into small groups to finally crush those tasks. Here is what we ended up with: Best Practices: David Simpson reorganized our internal Style Guide documentation to help us scale it out, and added a new section called \"Tone\" to help us standardize how we implement copy within the app. Adam Schwartz and Zack Bloom teamed up to create BestJS, a repository for frontend best practices at HubSpot. It's a searchable directory of standard libraries and resources in use at HubSpot. Test Coverage: Tim Finley wrote Selenium tests for the style guide docs to help us identify breaking changes in the style guide before they make it to production. It also uses the new jquery_chain library, written by Greg Sabo. More on that in a second. Lincoln Bryant and I added several hundred lines of unit tests to our core app components. These tests will now abort builds when they fail, so users don't run into those problems. Test Infrastructure: The one and only Michael Mintz added automatic IE tests for Selenium. Now newly deployed apps will automatically run integration tests in the three major browsers. Everyone hates flapping tests. Greg Sabo and Diane Yang added some configuration options to Selenium that will retry a test before notifying you of a failure. Greg also created jquery_chain, a Python helper that lets developers write Selenium tests in a jQuery-like syntax. Speed and Performance: Bryan Ash and Anthony Roldan released version 2 of HapiJS, a library we use to make authenticated API calls directly from the browser. This new version let's us directly hit our backend APIs in just two lines of code. Boom. The new hotness, Breakfast, is now being served thanks in part to Ryan Berdeen and Matt Furtado! These types of apps are fully static and talk directly with our APIs. The newest version of the HubSpot dashboard is built with Breakfast, and more apps are making the switch. Problems happen, and we need a way to quickly notify our customers of interruptions. Jess Scott and Marc Neuwirth wrote Fire Alarm, a Javascript library that let's anyone on our team show an alert message to a customer without the need to change code or redeploy the application.", "date": "2013-06-24"},
{"website": "Hubspot", "title": "Today we did our quarterly desk shuffle", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/6806/today-we-did-our-quarterly-desk-shuffle", "abstract": "Most of the HubSpot dev team is physically co-located in the same area of our office.  We do have a few great folks who are out of the office, but most of the people are here. A while ago we started a habit of doing a random desk shuffle every 3 months.  We have a map of our space, and we number the desks.  We put folded notes in a wizard hat, like the one below, one note for each desk.  Each notes has one number, corresponding to its desk.  Then each person draws a number, and voila ;) Trades are allowed.  We routinely have multiple trades, but the overall distribution is fairly random, except a couple of people who are adamant about staying in the same desk.  Those people go through multiple rounds of trading and debate.  Most other people are happy to try a new location. We do this for a couple of reasons.  First, it's fun.  Second, it encourages getting to know more people better.  By sitting next to someone, it's more likely that you will talk more.  Thirdly, it discourages tons of clutter and messy desks. Finally, it reminds everyone that change is the one constant we can rely upon.  Everything is always changing, from requirements, to technologies, to people.  This is a nice physical, concrete reminder. Do other people do something similar?  Or do you more or less stay in your own office / cube / desk for a long time once settled?  Do you think the principle of changing seats often is good, bad, meaningless, or something else?", "date": "2009-06-30"},
{"website": "Hubspot", "title": "How HubSpot's product analysts transform the customer experience", "author": ["Kelsey Dietz (She/Her)"], "link": "https://product.hubspot.com/blog/how-hubspots-product-analysts-transform-the-customer-experience", "abstract": "It takes a village to build a product. Not literally, of course; but the sentiment is the same. You need many different people in many different roles in order to get a successful product off the ground. Without everyone’s individual skills and perspectives — their special piece of the puzzle — product decisions can easily fall prey to bias and missed opportunities. HubSpot relies heavily on this village model for virtually all of our product teams. For each team, there’s a core group of people who do most of the heavy lifting when it comes to building their product. Engineers bring their deep understanding of constraints and technical tradeoffs. Designers use their deep knowledge of the user, her experience, and design standards across the product. And product managers contribute their broad and varied insights about the business. This core team is supported by a number of other people who are integral to a product’s success: UX researchers, UX writers, expert support reps, and, of course, product analysts. Most product analysts exist in a world of rows and columns; functions and models. And while that’s certainly true at HubSpot, product analysts here don’t exist just to run the numbers. Here, we tell stories with data and influence outcomes. We are partners in the success or failure of a product. And we use our insights to drive product strategy. Why? It’s simple: having highly collaborative product analysts who have some skin in the game makes for better products. The Devil’s in the Data Often, core product teams (the Product Manager, Designer, and Engineers) have a strong intuition about how customers are using their products and what those customers want us to build. And they should; they spend a huge amount of time listening to customers in research sessions, reading customer feedback, and synthesizing information from our support, sales, and services teams. And very often, that intuition is based on solid data they’ve gleaned from the qualitative research they’ve done. But without a clear picture of the user base as a whole, it’s difficult to be totally confident in a decision after a mere handful of user research sessions or NPS responses alone. That’s where having an expert to delve into the data and back that intuition up with numbers can make a world of difference. At HubSpot, we’re steered by our instinct but driven by the data. Telling a story with data is one of the most powerful tools at our disposal — users might say one thing about an app or feature during a UX research session or a survey, but the data shows us what they actually do. And while it can sometimes be tempting to write off the results of a user test due to certain variables or factors, behavioral data often presents a much clearer picture of how users actually act. This data helps us evaluate our products in an unbiased way. User sentiment can be a tricky thing, but the numbers don’t lie. This data is even more important if considering a decision that would change the course of our company, like a new product. Having data to back your idea up, and the ability to communicate that data effectively, can be the difference between making a decision confidently or not making it at all. Asking all the right questions When working with a team to figure out how data can better guide their decision-making, I start by teasing out a hypothesis based on the information the team already has about how users interact with the tool or what the team is trying to accomplish with their product. This hypothesis gives us a great starting place to figure out which metrics we should measure. It almost goes without saying, but picking good metrics is important; we want to use the data to either prove or disprove our hypothesis, and data that isn’t founded is useless. We recently had a great example of well-chosen metrics that decidedly proved out a hypothesis. One of the teams I work with was looking to sunset an outdated tool in our product. They had a hunch that the tool just wasn’t providing as much value as it once had to our users, and did a few rounds of qualitative feedback in order to validate their instincts. But in testing, there emerged a small but very vocal group of users who desperately wanted the tool to stick around — vocal enough to give the team cold feet about sunsetting it. So we went back to basics. We took the hypothesis that our tool just wasn’t cutting it, and decided to do a deep dive into the data on how and when our customers used the tool. The data was spot on. We found that the user base had been rapidly declining for a while, and dug up some solid behavioral evidence that the tool was no longer providing the value it once had. This understanding gave the team the confidence to remove a tool that otherwise would have stuck around because of a small (but influential) cohort of qualitative data. Culture of trust All these things — making hypotheses, presenting information, supporting teams — are table stakes for product analysts. And at many companies, that’s where it stops. Product analysts are service providers. They respond to requests and provide data. They might make a recommendation or two. And that’s it — their work is done. On to the next request. Back to the spreadsheets and SQL queries. But product analysts at HubSpot operate under a different model. Each product analyst is assigned to a product family, meaning that they get to build a deep understanding of their area of the product, and develop very strong ties with the people who build it. Our culture of quick iteration and learning means that there is a baseline trust in the insights we provide, because teams understand that knowledge is power, and more data leads to better decisions. This means that our teams don’t just trust their product analysts to come up with the answers — they trust us to figure out the questions we should be asking. We can only do this because we spend a lot of time working with teams, understanding users, and learning where the team is headed and why. By grasping the value proposition for each tool, we can help teams set achievable (yet ambitious) goals and measure their success. We’ve seen this time and again — at the end of the day, the best way to build a successful product is to create something, measure the heck out of it using both qualitative feedback and quantitative data, and then build something better. In fact, sometimes asking the right questions allows us to build not just a better tool or feature, but a better experience entirely. This happened recently at HubSpot. When looking from a 10,000-foot view, things seemed great. Our qualitative feedback and NPS was showing a fairly happy, growing user base. But we had some additional questions about how users in different circumstances felt about HubSpot. And as we were slicing the data into groups of users that entered the product at different times and used it in different ways, we uncovered a pocket of really unhappy users. If a user’s first actions in the product took place more than 30 days after the account was created, they typically used the product less, and had a much lower NPS. This made sense — these were users who hadn’t experienced the in-depth onboarding process that the initial users at their company had gotten. This discovery spurred a huge, company-wide initiative to improve the experience for all new users — data that substantially shifted the focus of our whole organization. Without data, teams miss an essential part of the picture. By providing a unique perspective into how people are using the platform, we product analysts have a lot of opportunities to drive product strategy where the data guides us, and a lot of ability to influence product decisions based on facts. And that amount of influence means that we have not just the ability, but the responsibility to guide product decisions with data. If this sounds like a team you’d like working on, please get in touch. We’re looking for Product Analysts and a Head of Product Analytics who are passionate about the numbers and about working with teams to build the best products they can.", "date": "2018-08-01"},
{"website": "Hubspot", "title": "How to Go From “Minimum Viable” to “Most Valuable”: The Evolution of the HubSpot Knowledge Base", "author": ["Graham O'Connor (He/Him)"], "link": "https://product.hubspot.com/blog/the-evolution-of-the-hubspot-knowledge-base", "abstract": "Launched in 2018 as part of Service Hub , HubSpot’s Knowledge Base has come a long way. What started out as a very minimal product is now at a point where it is almost fully featured. This post gives an outline of how the product has matured from its infancy to today, as well as tips on how to evolve a product into the most valuable version of itself. Use an MVP as the Starting Point Like any new product at HubSpot, our first release was very much a Minimal Viable Product (MVP). At its core, a knowledge base should do two things: Allow users to publish answers to their customers’ questions online Allow customers to be able to find answers to their questions online Our aim for the MVP was to allow our customers to do these two things as simply as possible. The MVP consisted of: A simple editor, providing users with a focused writing experience Article categories to provide information architecture Basic insights (article views) to allow users to see the value that it was providing to their customers Basic design (colors and logo) to allow users to align the knowledge base with their brand The MVP was well received by our early customers, with many launching their knowledge bases within a couple of weeks, but one common question we would hear from prospects/customers was, “Why would I use a Knowledge Base instead of a Blog or Website Pages?” It was a fair point — we had grand plans for the future of this product, but as it stood, our customers could not see its value. Inbound Help Center was the first live knowledge base (We love to eat our own dog food) Differentiate the Product The next step was to really address this question and differentiate Knowledge Base from our other content products. We decided to address this question in two ways: Double down on article categories Deliver key insights that would improve the performance of a knowledge base Double down on article categories The information architecture of a knowledge base plays a huge role in its performance and the value that it provides to end customers. Most of the time when customers land on a knowledge base, they’re trying to troubleshoot an issue they’ve run into. They can be stressed and under time pressures — the quicker they find their answer, the better an experience they’ll have. Categories play a key role in optimizing the browsability and findability of answers in a knowledge base by grouping together related articles. We decided to double down on helping our customers visualize this information architecture and providing an easy way for them to adjust it. We achieved this with the release of the drag-and-drop organize editor. Drag and Drop Organize Editor Deliver key insights We wanted to deliver insights that really matter to our users to help them understand what areas of the Knowledge Base add value to the customer and what areas need to be improved. The insights that we decided to focus on were: Article Health Demonstrating the value of a knowledge base can be tricky. Unlike in marketing content, there is no conversion point such as filling out a form, clicking a CTA, or subscribing. Ultimately, value is provided if the customer has solved their problem. To demonstrate value, we added a feedback module to each article allowing customers to indicate if they found an article helpful or unhelpful. This not only contributed to demonstrating value, but it also surfaced articles that needed to be improved. All of these feedback insights are presented to users in the Article Health report. The report appears front-and-center in Knowledge Base to encourage users to track these important insights. Search Insights The second insight we delivered focused on search. We wanted to show our users what their customers were searching for and highlight the search terms that were not delivering helpful information. This insight has been hugely successful for encouraging customers to create new content for weak areas of their knowledge base. By focusing on these two areas, our customers now realized the benefits of publishing help articles on the Knowledge Base as opposed to publishing this information on a blog. Knowledge Base Insights Improve Adoption With our customers now understanding the value of the Knowledge Base, the next area we wanted to focus on was adoption. We spoke to countless customers, as well as internal teams within HubSpot (such as Implementation Specialists and Sales and Support), to figure out the roadblocks early on in the adoption process. We found there were two main barriers to people adopting the Knowledge Base: Moving over from an existing knowledge base was time-consuming and this was delaying adoption. Many users were fearful of their competition having access to their help content and only wanted their customers to have access to it. Import We tackled the migration issue by introducing an import feature allowing users to import a knowledge base from the most popular platforms in just two clicks. Users can now simply enter the URL of their existing knowledge base and we handle the rest. Restricted Access For the second issue, we extended the new Content Membership feature to Knowledge Base. This allows businesses to securely share their help content with their customers. Controlling access to Knowledge Base articles Clean House At this stage, our adoption numbers increased — we had removed two big roadblocks for our users. We decided to take a breather from building features and instead focused on improving what we already had. We spent a substantial amount of time improving the performance of the entire product — in particular, the Organize and Insights screens. As well as improving performance, we also spent a lot of time digging into our users’ biggest pain point: the article editor. Rebuilding the Article Editor Unsurprisingly, writing articles is where our users spend most of their time in Knowledge Base. For quite a while, we had been hearing about different areas in this experience causing our users pain. Examples include users being unable to: Paste images into the editor Indent items in lists Add images to ordered lists Add code formatted areas Embed 3rd party videos Add tables Add anchors Given the amount of pain that our users were experiencing, we took a long, hard look at our editor stack and evaluated whether we should persist with our current stack or move toward a more mature stack that would eliminate a lot of these pain points. In the end, we decided to make the change and moved from Draft.js to TinyMCE. We completely rebuilt the editor from the ground up, moving toward an editing experience more consistent with other content tools within HubSpot. Moving to TinyMCE eliminated a lot of these issues. Taking the Writing Experience to the Next Level We wanted to build upon this new foundation and focus on some natural next areas of improvement. Our users were happy with the improved editing experience but there were still some outstanding issues that had to be solved: Tables Anchor links Code formatting Highlighting Over time we added these features to the editor, creating new experiences for tables and anchors as well as introducing callouts to allow writers to highlight important areas to their readers. Callouts help to highlight important areas of an article Improving Design Options From day one, one of our users' biggest pain points had been the lack of design control. Many users were frustrated that they were unable to represent their brand on the Knowledge Base in a way that was consistent with their website. We repeatedly heard users express a need to choose fonts and their own imagery for categories. When digging in deeper with our users, many presented us with a design they had in mind for their knowledge base. After a number of interviews, some very clear patterns began to emerge. For example, a very common template we saw was the Tiles pattern used on many company help pages, such as the Slack Help Center . Thinking through how to solve this problem, we considered simply opening up Knowledge Base’s template code. But we saw that a large proportion of our users didn’t possess the skills needed to create a beautiful knowledge base through coding. Opening up the code at this point would leave a lot of our users behind. We set about creating an experience that would allow any user (technical or nontechnical) to implement a beautiful knowledge base in minutes by giving them all of the popular Knowledge Base templates straight out of the box. This new experience was released as Customize Template in October 2019. Template editor using Tiles design Acknowledge That No Product Is Ever Finished The release of the new template experience was a complete game-changer for the product. Larger businesses that had once passed on using the Knowledge Base were now adopting the product in high numbers. But of course with larger businesses come new problems to solve. These large businesses have more complex needs. They want to be able to support their customers in multiple languages, support multiple brands within their business, and have developers and designers that want full design control over the look and feel of their knowledge base. Solving these more complex needs is where we are headed next. Quite recently we released a multiple language feature and in the not too distant future, we plan on solving more of these large business problems. Creating the Knowledge Base product from scratch alongside a fantastic team of engineers and designers has been one of the most enjoyable experiences of my career and the most exciting thing is that we are just getting started. No product is ever finished and Knowledge Base certainly has a lot more runway!", "date": "2020-06-18"},
{"website": "Hubspot", "title": "\"Hire People Bothered By Suck\" And Other Insights From GitHub", "author": ["Dharmesh Shah"], "link": "https://product.hubspot.com/blog/hire-people-bothered-by-suck-and-other-insights-from-github", "abstract": "GitHub is an amazing company and an amazing startup story.  We're not only customers of the product, we're huge fans. Recently, we had Zach Holman ( @holman ), an engineer at GitHub come and give a HubTalk at HubSpot.  HubTalks are regularly scheduled events where we have internal or external speakers give a talk on a variety of topics at the HubSpot headquarters in Cambridge, MA.  (We have a brand-spankin' new meeting space that's perfect for these kinds of talks). The title of Zach's talk was \"Product us The Byproduct\" -- but he chatted about a lot of different topics. A video of the talk is included below, along with a full transcript (for those of you like me, that like to read/scan instead of watch). Here are some of my favorite bits from the talk. Insights from Zach Holman of GitHub 1. I think you should worry more about building the damn thing and worry less about what you’re actually building. A product should be a byproduct of the people, process, and technology of your company. 2. There are thousands of developers who are extremely smart and talented, all of whom I would never, ever hire here 3. One thing we try to figure out at Github is to try and hire people bothered my suck. 4. “Any time you interview a potential hire, you need to ask yourself not only if they’re talented or collaborative but also if they’re capable of literally running the company, because they will be.” ~Valve Employee Handbook 5. Cox and Blake in 91 concluded that groups exposed to minority views were more creative than the more homogeneous, majority groups. 6. The overall median proportion of female executives in successful companies is 7.1%, compared to 3.1% at unsuccessful companies. ~VentureSource 7. “increases in masculine wording were sufficient to decrease women’s job appeal ratings and their anticipated belongingness in specific occupations.” 8. I want to get to know my co-workers families because their kids are almost always more interesting than their parents. 9. once you've launched everything, it’s time to get the reaction of people. Which is problematic for one reason, people on the internet are dicks. 10. Any sort of small feature that we launch, we’ll blog about it. Because it’s good, you get people talking about it. And it’s the whole long tail effect where you fix some small bug that’s been eating away at some people and most people don’t care but they’ll be some people that say “yes! I’ve been looking for this for two years.” 11. Nothing great was ever not shipped. Full Transcript Dharmesh: So Zach’s - the reason he’s here. I traded emails and he’s awesome by association, someone I respect who is awesome said, “Zach’s awesome. He’s going to be in Boston, you should do something,” I’m like, “sure”. So with that let me introduce Zach. Applause Zach: That’s probably my favorite introduction of all time, that’s hilarious. I need a microphone, hold on. Cool. Everybody hear me? All right, the title of my talk is - “Sure”, no ha ha. The title of my talk is - “The Product is the Byproduct” and by that, ya know, I think you can create really great product but it’s better to promote a great product. Wait, I should stop talking like that. I hate when people get up on stage and start talking about a product like it’s some amazing, angelic thing. Here’s what I actually mean, I think you should worry more about building the damn thing and worry less about what you’re actually building. By that I also mean a product should be a byproduct of the people, process, and technology of your company. So focus less on the actual thing and more on the stuff surrounding what you’re building. I really think if you foster a really good environment, you’re more likely to create a good product. If you look around at really good companies, people with a really good culture behind them, more often than not they tend to be successful. There’s a lot of companies with horrible culture that still are successful but that is America. So I’m Zach Holman, this is a picture from a charity dodgeball tournament in the Fall. This is great because you put pictures of yourself in small shorts and since it’s for charity everyone thinks it’s awesome. Dodgeball is amazing, I was just happy about that. I do work for Github, I am a Developer there and I talk a lot about how we work, about how open source works, that’s kind of tangential. All of this talk sort of stemmed from looking around about how Github sort of does stuff, and we’ll just start from there. Team. Team is a critical part of your company. Everyone gets on stage and says people are important, so I’m going to do that as well, and say that people are important. People are extremely important. (points to presentation) This is my team, this is my team circa a year ago, we probably added them on 70 or 80, we’re at 153 total right now. And this team is really important to me. Kyle Neath, our Director of Design at Github said something in Campfire, just off-handedly which I thought was really interesting. He said there are thousands of developers who are extremely smart and talented, all of whom I would never ever hire here. And I think that’s really indicative of what we try to find at Github. It’s not just about smarts anymore, it’s about how you think about things, how you come to things. How you deal with problems, you know, it’s not necessarily I.Q. points anymore, it’s the whole spectrum of stuff. One thing we try to figure out at Github is to try and hire people bothered my suck. By that I mean, basically you want fixers, you want somebody who, if they deal with a certain application on a day to day basis, they’re bothered by stuff that sucks, they’re bothered things that isn’t quite designed as well as it could be, isn’t quite as fast as it could be. There’s a lot of developers or designers who will just, you know, if that not necessarily their 100% priority, they’re just not going to fix it because that’s not in their job description. We don’t want those types of people. We want fixers. We’re big fans of Valve. Valve “leaked” their handbook last year. Fantastic marketing for them, I love that, but we’re really excited about this handbook because we found that Valve was working, ended up working the same way that we have over the years and they’re twice the size of us. So that’s really interesting to see them, sort of confirm the way that we’re working. And in their handbook they said this, “Any time you interview a potential hire, you need to ask yourself not only if they’re talented or collaborative but also if they’re capable of literally running the company, because they will be.” I think more often than not people don’t recognize that fact. Even like the low level developer on your team, they end up making of ton of small decisions that impact you down the line. And people think, oh, it’s not that critical but they tend to be, like these very small decisions, like oh, should this code be this way. And if feel like you can trust everyone to say, ok everyone else is dead and now you have to run the company, that changes the amount reliability you feel in letting people make those small choices. So I hire broad people, just like that in general, rather than just hiring the smart and the best and brightest, it’s just kind of silly. I like really broad, interesting people. Diverse people is also a side of that. This room is better than most, a lot of white dudes my age in here, which is basically all I ever talk to which is really sad. But diversity really matters, and there’s some really interesting studies surrounding this. Cox and Blake in 91, they concluded that groups exposed to minority views were more creative than the more homogeneous, majority groups. And I think that makes sense anecdotally too. If somebody comes from different backgrounds or different values than you, and you recruit them on your team, you’re going to end up with a more interesting solution that will tackle more peoples view points. For more up to date stuff, VentureSource looked at a whole bunch of different startups and looked at the success of those startups over time. And they found that the overall median proportion of female executives in successful companies is 7.1%, compared to 3.1% at unsuccessful companies. All of this sort of stems from this idea that this really impacts your bottom line. There’s just some people in life that you just have to go back to money, and say yes, this will make a better product, this will make...more diversity in your company will make you more profitable. I think that’s definitely really true. Building a company that’s friendly to everyone is not as valued as highly as it should be in our industry. There’s a lot of different ways you can sort of deal that, building this company that you want to work at. One is Tone, just how do you talk about yourselves to other people. There’s another study that was really fascinating, they just talk about wording. They said, “increases in masculine wording were sufficient to decrease women’s job appeal ratings and their anticipated belongingness in specific occupations.” Bunch of academia words. Basically what I mean is stuff like this, like “Badass” “Killer” “Rockstar” “Dominant Force in the Industry”. You see those all the time and you compare those jobs posting that will talk about “Happiness in the workplace, honest, or working stuff, building stuff together. I would much rather work there, and that’s the critical point stuff because it works for men too. I would much rather work at some place talking about happiness than talking about badass beasting on code or something like that. It’s, it’s, it comes down to this for me, it’s like if you’re building a company and it appeals to more people, then go in that direction. So basically just consider your approach, also really hate brogrammers, I just want to underline that, I hate all that. Cool, Team is important, Culture is also really important. All of this is just no! (referring to a slide) Crushing code and all that stuff, it’s just not a culture you really want to have. Good culture attracts really good people. And I believe that a billion percent, that doesn’t work with math but I believe it a billion percent over. Turns out like once you have really good people, they like mate and have kids and offspring and stuff like that. And it’s weird how industry in particular forgets that point, families are critical, you know. So being family friendly is really important for us at Github. We have, we usually get together twice a year to have these big company wide summits. And we try to make a really big point to have these sort of family friendly outings because I want to get to know my co-workers families because their kids are almost always more interesting then their parents. So consider that, how do you build your actual events in a way to make your company more interesting for everyone. There’s a lot of ways that Github does it ourselves, this idea of flexibility. One is just location, we’re about two thirds remote employees at Github, which I think is interesting, and of those we maybe a third that live in San Francisco and of those, maybe half end up coming to the office every single day. It’s just a really weird but its really flexible way of work. And I think that really helps us in attracting a really family friendly-centric focus. Hours are really important for us, we let people work any sort of hours because, man have you ever had... if you’re not a morning person and you have this guy say you gotta come in at 9 in the morning for this stand-up meeting, and you’re just like, no. Like, I’m going to be asleep in my head until 2pm and just dragging me in is not going to help. So we have very flexible hour perspective of work at Github. We let people work when they want to work. And finally just a sane workload, this whole idea of doing 140 hour weeks, especially like the Gaming industry where they thinks that’s a healthy way to work, that sucks. We much prefer the idea that if you work reasonable hours that you’re going to be much more creative, you’re going to be much more...you’ll produce really good work if you work not-crazy hours. So basically you limit yourself with all of these things, you limit yourself by saying you have to be in an office, you limit yourself by saying you have to have set work hours, or work a billion hours a week. One of my favorite stories that relates to all of this is the notion of OS X on Intel, and all of this happened because a self-demoted engineer wanted his son Max to be able to live closer to Max’s grandparents. The story is, this engineer’s like, he’s living out in Cupertino and he’s like, man I really want to go to Boston or something like that because my family is near there. My kid wants to be with his grandparents and all that. And he talks to his boss, he’s like, you know I kinda want to move out there but is there a project I can work on, I kind of want to see if I can get OS X on an Intel platform and see what goes on, and the boss is like yeah, just go away just work on that. And they forget about him for like 16-18 months because you know big companies and stuff like that, then finally somebody is like, oh man we gotta figure out what this guy’s been doing out there on the East Coast the whole time. So they bring him in and he runs OS X on his Intel Windows box type of deal. And his boss is like, alright alright, then he goes and gets his boss, and he gets his boss, and he gets his boss and then there was like, Steve Jobs is on the next flight to Tokyo or something to talk to... to figure out ways to deal with all this stuff. Because it was awesome and really exciting and it all stemmed from the boss’ ability to let this really smart engineer work on what he wanted to, work on something that he found was interesting and work form a place that he wouldn’t of otherwise been able to work at. This all stemmed because they were very flexible. I don’t know the guy personally but, I feel like if his manager would have said no you can’t move, he would have been like, alright bye. And then we wouldn’t have had OS X on Intel and maybe we wouldn’t have had the iPhone and then obviously we wouldn’t have Android without the iPhone (laughter). It weirdly all stemmed from one specific person. So that stuffs really important. I want to talk about a little bit about desire and building desire. Marketing is not a bad word, and I feel like that’s probably nothing crazy to say here in this room. But a lot of other places, like Developers like to say, “ugh the Marketing people, they’re all just idiots”. But it’s not a bad word because I think instead what what we hate is the disingenuous. This idea that someone’s trying to sell you something that they just don’t want themselves. So this guy goes up to you and he’s like, oh I really want you to buy my distributed social cat network. And you’re like wait, hold on let just ask you a couple of questions first. Like one, do you even have a cat? And you just know he’s going to be like, no well you should do it anyway. And you’re like alright. Don’t we want to centralize cats? Because their hard enough when they start darting around all over the place, you want to centralize cats not distribute it. Would you even use this yourself? And I think that’s the most critical question, that’s why we don’t inherently like Marketing is you just feel like people are trying to shovel this crap on you that they don’t actually want. So being genuine about this is the most fascinating part about all of this. A really good example recently, I gave this talk a month or so ago and I gave a shout-out to OnePassword and there was a OnePassword dude in the audience and he was just like, “yeah this is amazing!” and he wasn’t even listening to what I was saying, but it was good. The story with OnePassword is funny because I use OnePassword for all passwords and it’s awesome and I love the app. They sent me an email like last Summer or something, check out a new point version. And you know, I skimmed the features and I didn’t care. I like the app but it wasn’t something that I was really fascinated with but I’m reading through and it’s like the founder or the CEO or something and he’s talking about these really incremental improvements that I don’t care about, and he’s talking about them with such enthusiasm. He’s like, we got the whole team together, we’re working on this, we’re so excited about what we got coming. And even though I didn’t really care about what he was trying to market to me at that point, I came away really impressed with how excited he was about the product. And I went from somebody who really liked the product into someone who really sort of admired and thought that they genuine, what they were trying to sell to me. And I thought that was really just important, because you see that much anymore, strangely enough. Being vocal is not bad. I think it’s interesting to have people vocally talk about what they’re working on. Blogging small improvements is really interesting, I think Github does that a lot more than anyone else. Any sort of small feature that we launch, we’ll blog about it. Because it’s good, you get people talking about it. And it’s the whole long tail effect where you fix some small bug that’s been eating away at some people and most people don’t care but they’ll be some people that say “yes! I’ve been looking for this for two years.” Then they share to all their friends and some of those people are really excited about it, you don’t get that unless you blog about these small incremental changes. All to often a lot of companies just say, alright we’re only going to blog our 1.0 launch or 2.0 launch, we’re only going to do press for these special events. You don’t have to be that way. Leveraging regular press is a really powerful thing in general. This is one of the most interesting things I’ve seen in Tech. Steve Jobs went on the stage in January and gave this Keynote where he introduced the iPhone and then on June 29th they launched it, and people tend to dis-remember that they go back and say, he went on stage did an awesome Keynote and people started buying it a whole bunch. The truth is a lot more interesting, there was a lot of stuff that Apple did in between those, February 26th they released the first TV ad which didn’t even show the iPhone, it was just a bunch people picking up a phone saying hello. June 3rd they had TV ads, June 6th they had another ad, WWDC was on June 11th where they announced the iPhone SDK. Then they talked about and improved battery that they were putting into it a week later. The same day they announced a new glass screen for the iPhone. June 20th they announced the YouTube app was going to be on it. Then there was another TV ad. There was a guided tour they announced, then they published all of the press reviews and all of the old school journalistic endeavors. Then on June 26th, AT&T announced the plans for the iPhone. When you look at all of this together, it becomes much more clear that this is a very concerted effort. Especially in the last month leading up to the iPhone. The Apple PR was every single day, week whatever, was announcing something new which got the headlines almost every single day. I think that’s fascinating, all these things, to their credit are interesting things at least. So people are talking about it, it’s not disingenuous. So talking about stuff regularly I think is important and amazing. Ok, once you’ve launched everything, that’s cool and then it’s time to get the reaction of people. Which is problematic for one reason, people on the internet are dicks. Man they’re just really assholes. I sometimes frequent Hacker News, and I see this all the time where someone, “I just spent six months on this, it’s an open source project, it’s awesome, it’s totally free. You’re going to love it.” But then someone comes in and they’re like, “Fuck Youuuuuuuuu”. It’s the saddest thing of our industry. It’s probably this one guy, had like one table in html or something, and somebody dug into source and was like, “aww now I hate you’re whole product for this, like I hate you”. It’s terrible, that’s Hacker News for you. But’s it’s our whole industry. So the question I feel, is how much should you care about this? How much should you worry about the reaction that you’ll get from people when you push stuff out? And the answer is obviously, zero. But that’s really hard, it’s really hard to sort of ignore all this feedback from people, and ignore people saying, “fuck you that was a dumb idea”. So I’ve sort of started thinking about this a lot and I sort of developed an informal thing called Care Theory, basically saying, should I care, theory. How do you respond to feedback? I think there’s a bunch of different ways to look at this. Mostly, I think there are three specific groups that you should worry about when somebody is reacting to something that you’ve built. One is fans, one is skeptics, and the other are haters. And these percentages are really relative. So it depends on the product launch, sometimes you can have a lot more skeptics and haters. Sometimes you can have a whole bunch of fans. Sometimes you’re going to launch something and it’s all just haters. But it’s important to recognize who these people are. Fans I think are the users, people that are using your stuff, and that’s all great. Skeptics are people that could be users of products, and haters are not users, typically. Should you worry about what they’re saying? Fans I think, yes. Skeptics I think, maybe you should worry about it. Haters I think, maybe you should worry about it. Skeptics you gotta be worried about sometimes because they always say, if. So I mean they’re like, “I’ll use it IF you add cats to your product”. Why would I put cats in here, but alright I’ll add cats. Then they’ll say, alright, I’ll use it if you add cats and ajax to it. Then you’re like, ok I’ll just add ajax. Then they’re like, now I’ll only use it if we use websockets, too. And just like, this is silly. So be wary of “if”. Github experienced this a lot earlier on before I joined three years ago. Because when they were just getting started, Github got all this stuff from really larger established open source projects. Where they’d say well, you look good but you’re not doing this and we’d use Github “if” you added this. And to their credit the founders were like alright that’s interesting. And then they just didn’t usually add it unless it seemed like a really good idea. And then people ended up going anyway. We found this to happen a lot, in a lot of different things we would work on. People think that they desperately need something because that’s how they’ve always done it and they end up coming around. So just be wary about “if”. Be wary about (when) somebody says, we will definitely use you only if you add “X”. I don’t even know what that slide is talking about. (laughter) I want to talk about haters, that’s what I really want to talk about. Because haters are also really interesting. I think haters are also broken up into three separate groups. One is just unreachable people, this is totally fine. People might hate on your stuff because they aren’t ever going to use your product. You know a ‘social distributed cat network’, maybe you don’t have a cat. You’re going to be unreachable and that’s fine, they’re just never going to use you. So don’t worry about them too much. There’s another group that may come around when you succeed, there’s always this whole, you know, the iPod left space (in-audible) lame. But they end up buying one anyway, four years later. And there is finally, assholes who are just assholes on the internet. This is the group you should worry about (high-lighting the may come around group). These are the people that they may come around once you hit market penetration, once you’ve demonstrated that your product is actually worth while, so worry them. Don’t worry as much about the assholes and the unreachable people because it’s just not worth your time. Not all feedback is really equal, and that’s important. The thing kills me the most, is seeing somebody that is doing awesome, creates a really great product and they’re just really worried about thousands of people yelling over Twitter for something you said, or something like that. Try not to worry to much about reaction, and when you do, worry about who is specifically saying that. Who is, identify what audience they’re from because not all feedback equal. And remember that “Nothing great was ever not shipped”. It’s important to realize that everything goes through these steps, every single thing that has ever been shipped by anybody has gone through haters, and people who love it, and people who are uncertain about it. So overall, I mean, building products is really hard. I think we all sort of inherently know that, it’s a difficult problem but I think you can really build it indirectly, I think you can build really great products just by building a really good environment. And that involves a whole bunch of different stuff. It involves people, culture, building desire, managing reaction. You can’t just say, I’m going to have a great culture then just never market your product. People need to see your product. You have to be able to realize when to throw down into battle, just don’t attack the haters all the time because you think you have to do that. Recognize where the hate is coming from and then just work on building a really good product that way. So thanks, that’s what I’ve got. (applause) I ended kind of early, so if you folks have questions and stuff, I’d be happy to talk forever Question 1: so you’ve been about three years now, in those three years Github has raised like a ton of capital, talk about how the culture has changed as a result of growth and having access to cash, or are you folks buying small planets, what’s going on? Zach: What was the last part? Question 1: Are you buying small planets? Zach: Not publicly, so the money thing is really fascinating I think, as an employee who just digs Github and what the founders have done over the years. We went 4 years or so without taking any financing at all because we’ve been profitable pretty much since day one. Which really changes your perspective on stuff. So we had 4 years of doing whatever we wanted and not having to answer anybody because we were profitable and we didn’t have to answer to anybody. When we took money, that changed the game because we could take money on our own terms. We could just say, no, and then go off and make money. That’s different because you end up being able to take really good terms and still take that money but still be able to retain a lot of culture, like I don’t feel beholden to anyone. I can go on stage and talk shit about Andreessen Horowitz because, you know, whatever we have good terms and we still own the company and stuff like that. So I don’t feel like it’s a culture thing at all for us, I think we’ve done a really good job at both identifying our own culture, which I think is the... a big first step to figure out what you actually value, and then it’s...it’s, I think a lot of the part of it is just hiring the right people too. If we had something where like somebody said alright, now we have to change everything and go back this really weird way of working, we wouldn’t be able to do that because everyone would quit because people are passionate about how we work. So that’s been really nice for us because we’ve just not had to deal with culture change at all. Question 2: So, if I’m correct you 153 people now and you’ve hired about half of them in the last year. Zach: Yeah, sounds about right. Question 2: Two thirds are working from home, so how do you teach that culture to 50 (workers) in the office? Zach: It’s, it’s... so I get that question fairly frequently and a lot harder to go from a company that everybody works in the office, to going really distributed, for us it was really nice because we spent two years without an office. So, and we were very small at that point. When we got an office, we were about 9 people so from that point we had very ingrained culture of letting people work from home, meaning we have a huge emphasis on chat, a huge emphasis working via email rather than...that’s why we don’t have any meetings and stuff at the office because you know nobody is in the office. So for us it’s been a matter of just building a culture and going from that point. I think it’s a lot harder to say, we have a...everyone’s in the office today, how do we start being more remote? But I think it’s just identifying what we do that requires being physically in the office and then just start removing that. If it’s a lot of meetings, start asking, can we do this on an email thread, can we do this over chat rather than having to be in the office. And then just, piece by piece going from there I guess. Question 3: What’s the demographics like at Github? Zach: Demographics how? Question 3: (Like the diversity pool and like ages and stuff)? Zach: I have no idea on the age anymore, that’s gotten a lot more diverse faster than other statistics I think. I know we’ve doubled female engineering staff in the last month, which has been good but it still a lot lower. (crowd mumbles inaudibly) What is it like 6 or something like that? Our problem is...the problem I have with a lot of companies that say their diverse in terms of gender is that they tend to stick their females in specific roles. So like the stereotypical is secretarial and stuff. Which I’m saying is bad by any stretch of the imagination, I’m saying that if you look at the development teams, they’re like 100% male. And they’re still saying, we’re very diverse and stuff. For us it’s a little bit trickier because we don’t have managers, we don’t really have all these other areas. So we’re such a... I don’t know, 120 technical workers or something like that of the 150. So it’s a different pool to sort of hire from. So it’s something that we still suck at and we’re trying to improve dramatically, it just takes a long time. Question 4: So you’re obviously very passionate about the culture of Github, is everyone there as passionate about it as you? Zach: I believe so, there’s a... yeah people get angry about stuff, which I think is really good. This idea that people tend to really hate process in general, and every now and then there will be somebody suggesting something that maybe will add some sort of process for good reasons. And people will jump on that right away and say, you know do we actually need this? And I think Github, more than anyone else, is able reflect upon that better, like, I have to do this every day, can we just automate this away? And we’re really good at doing that sort of stuff. We’re good at hiring people that worry about that stuff, too I think. Question 5: What are some examples of processes’ you actually (run)? Zach: So, the (pool request?) in general, the ability to merge code into the primary branch is kind of central to everything. The process there very generally is, you open the (pool request?), you get +1’s or thumb’s up from people that are responsible for that code and then you merge it. And the...kinda the good process beyond that is we force responsibility on you to A.) merge it and B.) make sure the tests are written for that and you also support that feature as well. I think we have a good emphasis in our product, in our processes’ in general about responsibility. Putting the responsibility on you to be responsible for your code, rather than saying alright, I push it to Key Way, Key Way is going to make sure their systems and I don’t have to worry about it anymore. So that’s one side of things, we also do...we have an internal team app which is sort of like a Twitter / Way to collect ideas for what it takes stuff long term. Again, not really much of a process, just kind of post when ever you have either done something or posted an idea for a longer term change, or something like that. Question 6: You said you like Valve, the thing that my mind can’t handle is, that everyone works on what ever they want and they just move the (desk?) to the next group and now they’re working on that team and they get up to the next floor any time they want to, are you folks like that? Zach: Yes. It works fairly well, we tend to say it’s the land of best argument I guess, and one benefit of the way that it works is that things tend to go down in pairs, a natural back-end, front-end pair. You want someone to do the design, some one do the back-end of a specific feature. Most features will include a dozen people but it’s usually two people driving it. And to get to that point we usually have a back-end guy saying, I really want this feature, some one work on it with me please. And you have to do a really good argument of saying, check this out, this is going to be really great and for a designer to come work with you on it is at least saying the designer thinks it’s a good idea. So from there it’s sort of a good way of saying, well if no one wants to work on this with me, it’s probably not a good idea. As an aside, I think we do a really good job at allowing people to not work on stuff too. Which I think is almost as important as letting people work on what they want to work on. Specifically I’m thinking about, there’s been a lot of side projects at Github that have started out really dumb and small, and ended up being really critical to what we do. One of which is Hubot, another one is Boxen, another one is all of our deployment and testing infrastructure. Those all stem from somebody saying, I don’t really want to work on my day to day stuff because it’s tiring for me right now or I just want to work on this new technology stack or whatever. And letting people do that sort of thing, saying work on what you want to work on, ends up building some really interesting stuff, you know I don’t want to work at a company without a Hubot anymore because it’s that mission critical to how we work. So I think that’s been really good for us. Question 7: Can you talk about your deployment infrastructure? Zach: Yeah so, it’s kind of tied to testing a lot. Where if you push a commit, like the very basic example, I push a commit right now to getup/Github, our main dot com repository, if I push that to the primary branch the tests will run automatically and as soon as they’re run they’ll all push...they’ll deploy the code. Usually everything is done on a branch, and once the branch is ready to go all the tests are green and merged in to deployed again. I mean, it depends on what specifically you want to talk about I guess. All of our tests are Jenkins related infrastructure. Deployment is handled from this (ruby app), it’s called Heaven which is just Capistrano wrapper, it’s just an API that Hubot can talk to. And then that knows...you say like Hubot deploy get up to production. Hubot talks to this Heaven API, Heaven knows all of the boxes that we deploy to, all of the hundred boxes or whatever, and then it actually runs all of the commands. So basically we have all these automated steps tied onto one simple command that everyone can deploy from. Does that help anything, I don’t know. It’s complicated. Question 8: I guess I’m kind of curious what happens when things sort of go off the rails organizationally speaking, like you have all this independence and flexibility and a very flat sort of management, if any management at all. What happens when you get a pair of people who are off on some totally hair-brained scheme, is that cool? Do they get six months? Zach: Umm, it depends, sometimes hair-brained schemes are amazing. But there are times when you want some level of control I guess. One of the interesting things we’ve realized as we’ve grown bigger and we sort...we realized we sort of modeled ourselves after open-source. We’re sort of an open-source company, and by that I mean, we have a...there are natural maintainers of an open-source project and they are sort of the spiritual leaders / in charge of the bare metal, bare bones, like yes I want your code in my project. And in that case those are the people who I would feel like should be in charge of saying, you’ve gone too long down the rabbit hole on this one, come up for air and figure out a way to ship this immediately or can you figure out some way to take this where you can get out the door and work on some stuff. Usually there’s some level of friction that appears at some point where either you’re getting upset because you’re six months down and you haven’t actually shipped anything yet, or someone else is getting upset because you haven’t shipped anything yet. I think...we have a really strong culture of like we want people to ship stuff, we want people to keep pushing out new code and I think if it gets down to that...if it gets that far down where nobody’s shipping, you just start having conversations. Comment from person asking question: Is this all peers looking at their peers? Zach: Yeah, yup and I think that’s really...it’s worked very well for us. People tend to know how they’re...who’s pulling their own weight or if they’re just...you know the product they’re working on, the feature just doesn’t make any sense. And I think along side that we have a good culture of people saying no. And we try with the team app internally, pushing ideas and stuff out. You want to get people to say no as soon as possible, so people don’t spend six months on something that won’t ultimately ship. Question 9: Along the lines of that same note, it strikes me that you folks have very focused products and you know who your user is and your customer is, how are you folks, from a product perspective, my guess is that you’re really good at saying no to features and functions that’s just not going to happen. (rest of question inaudible) Zach: One of them is just hiring people who say no, like literally there...sometimes they’re jerks. In a nice way, but you want people who are very comfortable with that, I guess the other part of that is just building steps along the way to make people...to say no early. Like I was saying earlier. But other than that...I guess really no secret or magic formula, I guess, just say no. Question 10: After the culture, do you folks have any job titles or has that (evolved?) Zach: No, we have the mandated, CEO, CTO and stuff like that. We used to have directors but we kind of dropped those titles, like Director of Design and stuff. Because it’s...for us it’s mostly come down to project oriented leadership rolls, again like this idea of an open-source project. The spiritual leaders to a project tends to be the ones with the final say on something. But usually there are very few times where it escalates to the point where we need somebody external of that project to say...just to come in and put their foot down, and say like no do this some other way. Question 11: Github seems to be synonymous with open-source software, (rest of question inaudible) Zach: Yes. (laughter from audience) No. (more laughter from audience) We tend not to talk about future stuff to much. Question 12: What are the kind of challenges faced by how you (inaudible)? Zach: So one is technical, I came on 3 years ago to work on Github FI which would eventually become Github Enterprise. And dealing with this idea of...back then it was way more extreme, it was me versus ten developers who were coding ridiculous amounts every day and I would have to try and figure out, does this code work in our installable product, how do I have to change it, and it’s just like...the balance between all of that became really difficult but that something we wanted to consider and once we ended up launching Github Enterprises, could we build a model where we can kind of easily ship both products at the same time. Because they are the same product, they are the same code base except, Github Enterprises affected the super-set of features (inaudible) L-Dap, all stuff like that. So a lot of it was figuring out the best ways to deal with that, we ended up doing it...we solved that by doing the same thing we do with dot com, like we have staff features in dot com all over the place. The last time I counted we have like 40 or 50 staff only features that I have that you folks don’t have yet. We used that same sort of idea that, well you know if this is Enterprise, do this other code path, and stuff like that. So that was part of it, the other part of it is non-technical inherently. One is just sales people, that’s always been the concern is that you bring in people that aren’t douches. I don’t know how many sales people are here but, stereotypically, not you folks who ever are the sales people here. But they tend to be a lot more focused on the money, which is their job and stuff, but we still want people to be focused on the product. And I talk about our developers being able to say now, our sales people are really good at saying no, because they get the “If” question all the time, like we’ll add it only if you add ‘X’ and we’ll pay you X-hundreds of thousands of dollars, and they’re just like, no. And it’s weird when big enterprise companies, they’ll usually just be like, my boss just made me ask that, we’re just going to buy it any way. So that’s been good. That’s probably been the biggest fear I’ve had for enterprise, like they’re going to...like just because it’s such a different market it would end up adding a whole bunch of (cruff?) to the app, but because both the sales people and the technical developers on Github Enterprise have been able to say no we’re not going to add that or no we’re going to take that idea and make it more focused, it’s been able to make that side of the code base, not crazy at all. So it’s a bunch of stuff, culture and the tech side of things. Question 13: Could I ask a follow-up question? So you have two funnels, right? Is one more important or strategic than the other? How do you manage that tension? Zach: Umm, not really. It’s really a matter of just...because they both bring in money and they both have varying long term ideas of money. We’ve usually try to persuade people to post on dot com just because it’s easier and it’s going to be less headaches and it’s a better product idea for you folks. But I mean, if people still want this idea of hosting on their own, we’ll support that too. So it’s a matter of...umm, I think that was a fear that we were going to have this split in the company and I think almost to my surprise we’ve been able to say it’s just one product, and figuring out ways to make it one product rather than divert. Because diverging is really much harder. Question 14: You said you folks don’t like to talk about future things, why is that (rest of question inaudible)? Zach: Umm, it’s a number of things. One of the classic...you folks can probably remind me...it’s the computer in the ’80’s (answer from crowd The Osborne), yes, the Osborne, when they announced the next version and no one bought the current version so they had no money to develop the next version. So it’s very low level stuff like that. It’s also umm, if I say we’re going to add ponies or something at Github, you end up setting expectations, like, I want ponies, I’ve had unicorns forever but now I want ponies. And it sucks for us because we are so...work on what you want...and it’s, it’s...the phrase we usually say is, “it’s not shipped until it’s good”, type of deal. Sometimes the ponies may not arrive until 6 months from now or sometimes a year from now. And even...we’d had stuff that are definitely going to ship next week and it ends up slipping 8 months because that’s just how the cards played out. So we’d rather...instead of setting expectations, just don’t set any expectations and surprise and delight and it ends up being. And it ends up being people are super excited, like the stuff that we’ve had that have been really big ships, like when we did Issues, two or three years ago because the old one was so horrible. It was weird because we we’re using it internally for 6 months and I was just like, this is so awesome but I can’t tell everyone but I really want to. But when we finally shipped it people were like, this is amazing. I’m so happy that you finally fixed this and stuff. Question 15: How do you determine when something is right? (rest of question inaudible) Zach: Yeah it’s...so I’ve been asked that question a couple of times now and I still don’t necessarily know how to answer it, because I think it’s kind of weird because we have these two sides of things. One we’re really shipping ‘culture company’, we want to ship stuff, ship stuff, ship stuff, that’s really important. On the other hand we don’t want to ship stuff unless it’s ready to be shipped. So these are kind of odd ends and to be honest I don’t know how it works. I don’t know how we end up shipping stuff at all. But it’s...I think it’s both of those things, and there have been a few people we’ve had at Github were I don’t think they had as much fire under their feet to ship stuff. I think it’s not necessarily a matter their skills or anything like that, it’s just they didn’t operate in such a clear open atmosphere like that. And it becomes a problem, you have to have people ready to...like I want to get this out there as much as possible. I think along side that, something we do pretty well is celebrating ships, and I think that important because once you ship you get to write the blog post yourself, so you get some fame and glory or whatever, it’s a way of saying, yeah I did this. And we try and celebrate, you shipped this thing to Github.com today, and we’ll have a team update and we’ll say like, yeah I and you can post that. And just getting that sort of celebration from the rest of the team is really kind of contagious. So I think that end of things is just like getting people to get really excited about shipping stuff is sort of that side of stuff. Question 16: Here at Hubspot, we work in teams of 3 people (inaudible) but they own that kind of (API?) or that project, are they responsible for the engineers as well. How do you folks deal with the operations the reliability (inaudible)? Zach: So we have an Ops Team which...their ultimately in charge of all the Up-Time and Scalability and stuff at Github.com, it’s...like I was saying earlier...we operate in much the same way, where you own that feature, and owning is not just deploying the production. Owning is...you deploy the production and it’s also on you to realize the scale and implications of what you’ve done. So we have a lot of tooling around, data base cores and stuff. That’s a very simple one. If the data base is dying under the load, and it’s probably your fault...you have to fix that basically. There’s a side of that and also just the Ops Team, their good at telling you if...this is crumbling under the load you have to get on this and start working on it and they start working together and dealing with all that. Question 17: So you talked a lot about feedback and kind of how you have the breakdown of (inaudible), how do you think that correlates to (rest of question inaudible) Zach: I think the (Bride?) groups are kind of similar...you may have different...it’s weird because Github is like...we’re both blessed to have developers as our audience and cursed, just because we have stuff were, you know, we’ll get dissed for our CSS and say if you fix this, this will fix this browser. And we’re like, that’s awesome. And then we have the same people who are like, yeah I can fix this in an hour, why can’t you just add me to the repo? And we’re like, it’s not that simple. But I think...people still have the same motivations and stuff regardless of the industry they happen to be in. So I think if you can still identify the same type of people, there’s still grumpy people in Sales and Marketing. I think it’s just much more a matter of identifying what their state in the marketplace is. Is their feedback something I need to be worried about or not? Question 18: (most of question is inaudible) (basically asked if certain products would be for the masses or not) Zach: That’s an interesting question, I think umm...developers get all the cool stuff, at least a decade ahead of time, like Git is amazing. And if you talk about the high level too, like my mom’s a lawyer, and I talk to her partners and stuff, they’re always like, that sounds amazing, like, I want that. And then you just think like, yeah then you tag this (blob as a tag and here’s the shot-one?), and does not work. People have been trying to come up with a more user friendly way...not even Github in particular, just all version control systems and it’s difficult. I think TimeMachine is a really good example of using really powerful underlying technology and making it more accessible to most people. So I think like, yeah I really think like developers do get the cool stuff early and I think that proves that this is a really good way to work. The real question is how do you make it just digestible by the masses. And that’s going to be really difficult. Question 19: I really liked it when you said that, something doesn’t ship until it’s good. Do you ever have difficulty on people agreeing what “good” is? Zach: Yeah! A lot, and it depends like, usually...it really depends on the context, sometimes you paint the shed and you have to step back and say like, wow this doesn’t really matter at all. Sometimes there are cases where people get really into in-depth conversations about stuff, and that alone is usually a good sign that it’s not right. If there’s any discussion on it at all, if it’s really passionate discussion. It’s probably a good sign that something is wrong and at least take a step back and say, is there another way to do this or what do we want...how do we want to take it from here? But it really depends on the situation I think. Question 20: What’s your favorite staff feature on Github? Zach: (laughter) Man, if I brought up Github.com right now I’d blow your minds. It’s got (dash) -next at the end of it on the branch name. It’s like all of our features I guess, but it’s awesome. That’s all I can say. (laughing) Question 21: How deep do your designers need to be in the software? Who’s responsible for the code? Zach: Yeah we do, I think almost all of our designers...we have a couple of illustrators now who aren’t really code oriented at all, but of our designers...they at least know HTML, CSS, mostly JavaScript too. Which I think...that’s definitely been a conscience decision of who we’ve hired because we want people to be able to...you know you end up building designs differently when you actually know how they’ll end up being created. And it’s....like I was saying earlier, we tend to do 2 person teams at least for dot com for designer and back-end, so at least on that one I’ve teamed up with some designers before who I know can do the (ruby?) to do that. But it’s nice to say, alright, you handle that, you’ll probably do it better and stuff like that. We have a lot of designers who’ve picked up (Ruby?), this is the first time they’ve used (Ruby?) before, and even though they don’t necessarily throw down on (Ruby?) in the app, it’s been super helpful for them to actually understand the background of things. We’ve been trying to figure out better ways to sort of do in-house training of each other just because, even though you won’t ship on it, it’s still interesting to learn and stuff like that. Question 22: How do projects get open-sourced, like how did Hubot get open-sourced and why, for example is the deploy infrastructure not open-sourced? Zach: It really needs a winner...umm not a winner, a champion. Because people have asked stuff like that before and it’s just like, open-source is not just a switch, because if it is, we would have open-sourced a ton of stuff in the past. But you have to have open-source documentation, figuring out like what the best way to deal with like peoples weird environments and stuff like that. And then the biggest part is just supporting all the bugs and issues and stuff like that. Which has bitten us in the past after like...year two, somebody becomes less interested in that project and they move on to other things and you have stale open-source project and that makes everyone upset. So for Hubot, that was sort of designed from the beginning because we were, we liked how that changed our company. We were really...we could end up doing...it transformed how we chatted basically. So that perspective was like yeah, we want to have other people working that way as well, same with Boxen. It was like, this changed how we set up computers, let’s open-source this and let’s let everyone set up their computer just as well. But the deployment stuff and the testing stuff...umm well our testing stuff is open-source under (Jenky?), but our deployment stuff is more...that’s really difficult because that’s tied to Github.com stuff, that’s weird, finicky app related stuff that maybe we only run into. And then everybody’s got weird deployment stuff too. So it just really depends on somebody wants to do the work to do all of that stuff. And usually we end up with people that would rather just ship products, rather than dealing with open-source issues that doesn’t directly relate to Github.com and stuff like that so. Question 23: Alright, related closing question. I’m going to put you on the spot a little bit, talking about...you folks are an open-source powered company, you think a lot about culture, you love the Valve document. Would you consider open-sourcing your culture code and publishing things that you use internally to run the company essentially? Zach: Yeah, but it’s, it’s...that’s the reason why I give a lot of these talks. Is just because that’s sort of...because a lot what we do is not necessarily a document or something like that or an application or anything like that. So... Dharmesh: You gotta have something though, let’s say when you have 20 new people join in the next 2 or 3 months, like osmosis is not that useful, right? Zach: We’re starting to figure out...we’re always trying to figure out the best way to deal with all that stuff is. For a long time we had a really detailed guide for like...this is how this is all run and stuff like that. Then came the update and we had some different opinion, like it changed a whole bunch. So like we never really had a document that we can point to and say this is how we do stuff. It think the credit to Valve is that they figured out how that’s what they wanted their document to look like. Dharmesh: I have an idea, what if you just documented the first 3 days of a Github employee, like all the things I went through, how they acquire stuff, what kind of questions they have, their email threads, what they looked at...and publish that, that would be cool. Anyway, thanks so much for your time!", "date": "2013-04-25"},
{"website": "Hubspot", "title": "Java 6 Compressed Oops", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/36021/java-6-compressed-oops", "abstract": "A friend brought this up on a mailing list earlier today, and it looks cool: J ava 6 has a \"hybrid\" or \"compressed\" 64-bit JVM option , to use less memory than a full 64-bit. Has anyone used this?  What did you think?  Did it work well?", "date": "2010-02-26"},
{"website": "Hubspot", "title": "I Ran My First UX Workshop and Survived (and So Can You)", "author": ["Judy Xu"], "link": "https://product.hubspot.com/blog/my-first-ux-workshop", "abstract": "Earlier this year, I ran my first workshop with my product team at HubSpot. The goal was to uncover themes and questions they had — and there were quite a few — around improving users’ experience navigating and finding correct tools. The project was a big one that affected navigation, the interaction flows across tools, and how users interact with the tool. So, did I succeed in what I set out to do? Sure. Was it the smoothest experience? Not really. I’ve split this post into two sections to share my experiences running a workshop, and the lessons I’ve learned that might help you do the same. My experience running the workshop Think of a workshop as an opportunity to hear your team in a non-structured meeting space. It aids in uncovering themes and questions you might not have thought of, finding interesting trends, or maybe generating data points about the workshop attendees. For me, this workshop worked on the former: uncovering themes and questions. I was super excited when I first got buy-in to do it, but as the day grew closer, a sense of being woefully underprepared grew. This was the first time I had ever run a workshop. I’ve done focus groups, academic seminars, and other group-type activities, but workshops didn’t map onto those activities the same way. Partially due to focus, but mostly because I wanted to facilitate divergent thinking — a fancy word for brainstorming — to find common threads across questions. I found my teammates asking “what is the workshop about?” or “what are we going to do in the workshop?” — not in a mean way, but out of genuine curiosity. It was great knowing everyone was on board and wanted it to be successful, but those questions only increased my nervousness. I knew what I wanted to achieve, but how to get there? That took some thinking. I have to thank my colleagues on the HubSpot UX team for sharing their ideas for exercises and activities, so I could go from 0 to 100. Or try to, at least. The result was a workshop that involved sticky notes, sharing, some discussion, and a whiteboarding/categorization exercise. Awkward silences and one slide hiccup aside, I did achieve what I set out to do. It  wasn’t the most fun or engaging workshop, but we discovered many unspoken questions that the team had. The best part was that both veterans and newer folks on the team had questions that were focused on similar themes, which told me that we really needed to dig in and answer them. More importantly, the questions we raised turned out to be similar across team members in different roles. While the framing and wording of our questions might differ, it highlights the importance of involving different stakeholders and communicating with them. Even if engineering comes at or after the end of the UX design process, they likely also have the same high-level questions about your users, who they are, and how they use the product. I’ll be honest: My first workshop wasn’t perfect. There were small bumps and odd silences that detracted from the experience, and that unnerved me a bit. But I didn’t let them derail me from my goals. Despite the hiccups and kinks, it was a valuable experience. Not only was running a workshop a great way for my team to get involved in the research process, it also allowed various team members to hear the questions and gaps in knowledge their peers had. I don’t know when I might run another, but the thought of it is certainly on my mind. I feel like I’ve learned a lot from the experience, and I know I’ll only get better with practice. Tips for your own workshop So what makes a workshop successful? Is it the findings? The team aligning on some common theme? Or something else? I’ll leave that up to you. But here are a few things I’ve learned that’ll help make any workshop successful. Make it fun . Try adding whiteboards, sticky notes, or some kind of interaction outside of discussions and conversation. Food, music, and the occasional joke can also go a long way. In longer venues, short breaks and stretching is a nice way to break up sitting for a long time. Build rapport . Whether it’s a warm-up or some other activity, this is essential. Just because you’re familiar with everyone in the room doesn’t mean everyone else is. Breaking the ice can make sharing awkward things less awkward. A little discomfort is natural, but you don’t want people to be scared of speaking, either. Have a plan. And then plan for some awkward silences, questions, and things going off the books. Activities can end early, but try not to make them drag on. Practicing the plan or sharing what you’re planning, and getting feedback from peers will help turn ‘meh’ into amazing. Moderate it . Make sure someone doesn’t take over the conversation. We’re pretty good with this at HubSpot, but sometimes there’ll be someone who takes over. As a moderator, it’s important to step in when necessary so everyone has a voice. Be prepared . Make sure you always have some writing utensil or something to take photos/recordings. You never know when someone will have to jot things down, sketch something, or say something meaningful. Think of a workshop as a way to share ideas. And documenting it only makes it that much more successful. Seek feedback . This is the only way to get better.. It’s also one of the great things about running your own internal workshop. Making a Google Form or short survey asking your peers to give anonymous feedback can be helpful in targeting areas to improve. Share findings. Make sure you communicate out what was found. Particularly with those who attended. On one hand, they’ll know their input was valued and be that much more interested in sharing next time. And on the other, it’ll also increase your credibility and help gain you buy-in from your team. I encourage you to try running your own workshop. It's a great way to inform the next couple of stages of research, design, or product, and align your team. Treat it as one step in the process and not just a one-off or endpoint. The findings you glean will provide new avenues for exploration. Maybe you’ll converge on some common threads or maybe you’ll find more things to chase down. As your products evolve, so will your users, and the questions you might have surrounding them.", "date": "2019-10-09"},
{"website": "Hubspot", "title": "Premature Flexibilization Is The Root of Whatever Evil Is Left", "author": ["Dan Milstein"], "link": "https://product.hubspot.com/blog/bid/7271/premature-flexibilization-is-the-root-of-whatever-evil-is-left", "abstract": "Okay, so you know how they teach you, in Computer Science school, that lovely quote: \"premature optimization is the root of all evil\"? (variously attributed to Donald Knuth, or Tony Hoare, or other CS luminaries).  Well, in my more recent experience, there's another programmer habit which is in hot competition for the evil-rooting title.  I don't think it has as catchy a name, so I'm going to propose one here: Premature Flexibilization . And here's what I mean: the practice of adding complexity to your code to make it more \"flexible\", in anticipation of future change. Why would this be so bad? I hear you saying.  I mean, we all know that software requirements change, so isn't it good to make your code future-proof, by making it flexible, able to handle those changes that are inevitably going to come?  Most of the classic expositions of the glories of Object-Oriented programming are rife with this -- look, we're using abstract classes, so now the subclasses can vary, thus our code will be flexible and reusable, isn't that great? Here's why this fails so badly in real life: it's not just that requirements change, it's that they almost always change in ways which the initial programmers didn't expect. E.g. you've got your nice abstract base classes, all set to add more variants, but it turns out you just need the one variant... but you need to add a whole bunch of features to it.  Or you have to make it thread-safe.  Or connect it via RPC to Javascript code running in a browser.  Or auto-generate it via a script.  But, because you've made it flexible in one direction (adding more variants), you've also made it harder to vary in other directions (features, thread-safety, connecting-to-a-browser-ness, auto-generability).  This is a near iron-clad rule: flexibility comes with attendant complexity, and complexity makes things harder to change in unexpected ways. Or, to put it another way: if you make something as absolutely damn simple as possible , then extending it along any axis is at least doable.  But that's the only way. Take a careful look at Design Patterns, that classic text of OO design.  Notice how so many of the patterns are about making your software flexible, about making it adaptable to change.  Then notice that all their lovely real-world examples are for frameworks which no one uses anymore.  They've been replaced by other \"flexible\" frameworks (actually, they've usually been replaced by several generations of \"flexible\" frameworks, each of which turned out to be the wrong kind of flexible) In contrast, consider the C standard library.  It wasn't designed to be flexible, it was designed to be as simple as possible. And, lo, these 35 years later, it's still being used.  Sure, it's been wrapped by other layers, improved this way and that, but it's still a live thing. Also, note that \"simple\" is a very subtle idea.  It doesn't necessarily mean \"crude\".  Sometimes, the simplest way to do something is to, e.g. write a Domain-Specific Language--which is in no way trivial.  But, and here's the key distinction, it's a solution to the problems you have right now .  It's not a solution to problems you think are coming later.  If you can train yourself into the deep habit of only solving today's problems, you'll be far better prepared for tomorrow than if you tried to look ahead. What do you think?  Agree? Disagree?  Any examples that loom large in your experience?", "date": "2009-07-03"},
{"website": "Hubspot", "title": "HubSpot Visits Launch Academy", "author": ["Gabriela Lanza"], "link": "https://product.hubspot.com/blog/hubspot-visits-launch-academy", "abstract": "Every week at HubSpot we hold a Tech Talk where one of our developers teaches something cool to the rest of the development team. A few weeks ago gave a brief overview of TCP/IP networking and I enjoyed it so much that I decided that I wanted to share it with more people. Launch Academy in Boston was gracious enough to allow me to visit their headquarters, so I stopped by and gave the presentation to the students. (Thanks to @HeroicEric for the picture.) What a great crowd! The students at Launch Academy are a highly motivated group and I had a blast discussing How The Internet Works with them.", "date": "2013-05-22"},
{"website": "Hubspot", "title": "HubSpot App Marketplace (Part 5): Ratings, Reviews and Public App Pages", "author": ["Adrian Mott"], "link": "https://product.hubspot.com/blog/bid/77407/hubspot-app-marketplace-part-5-ratings-reviews-and-public-app-pages", "abstract": "It's pretty much common knowledge that a marketplace is a place where parties take part in the ancient ritual of exchanging goods or services. As part of this exchange, feedback has proven to be an intrinsical part of the exchange, letting providers learn from the use of their products and services so that they can improve over time. So as a natural progression of our Marketplace here at HubSpot, we're implementing ratings and reviews that will give users more interaction with the apps that they're using everyday. As the HubSpot App Marketplace grows over time, it's important for us to provide HubSpot customers ad customers with the best overall experience within the product. Reviews and ratings help users understand what sort of experience they're in for should they decide to use an app. To make it possible for users to imput these ratings and reviews, we're also giving each app it's own public page in the HubSpot Marketplace, accessible to anyone without having to be logged into HubSpot. App promotion is something that we care deeply about, and hope that these new public pages will help us and our development community promote their apps with greater success. We're working really hard to improve the Marketplace, thus we'll be working to add some other features in the near future. If you are interested in writing an app for HubSpot, these links are a good place to start.  Please let us know if you have any questions! Guide to Creating a HubSpot App API Documentation Developer Support Google Group", "date": "2011-10-25"},
{"website": "Hubspot", "title": "Inclusivity Is a Design Principle", "author": ["Erin Couse (She/ Her)"], "link": "https://product.hubspot.com/blog/inclusivity-is-a-design-principle", "abstract": "Words matter, and how we use them matters. According to the Linguistic Society of America , inclusive language “acknowledges diversity, conveys respect to all people, is sensitive to differences, and promotes equal opportunities.” It makes concepts more understandable, copy more readable, and products more usable. That’s why we made it part of the design system at HubSpot. Identifying a gap Our product is built on a design system called HubSpot Canvas . It’s home to our design components, patterns, and voice and tone guidelines . Among other things, the voice and tone section outlines the core mission of our product voice: to be clear, helpful, human, and kind. However, until recently, there wasn’t much information about designing for inclusivity — especially when it came to designing with words. Along with brief instructions to avoid jargon and use they/them pronouns, this is about as far as it went: “We use humor to include, not exclude. We use inclusive language and the singular they. We don’t demean anyone, or refer to differences in any way that could cause people to feel excluded or unwelcome. We convey a sense that we’re all in this together. We assume that our users are good people who want to do good.” While that was a start, it was vague and lacked actionable guidance. An update was overdue, and HubSpotters across multiple teams started collaborating to make it happen. After a few weeks of research, drafts, and feedback from our P roduct Diversity, Inclusion, and Belonging manager, we published a new Inclusive Content page to our internal Canvas site. Which was great… but it’s easy to talk the talk in a style guide. How do you walk the walk and put words into practice? Putting words into practice Next, we turned our attention to BethBot , HubSpot’s automated copy checker. When added to a Github repo, BethBot flags any copy that doesn’t follow its grammar and style rules . To apply our inclusive language guidance to product copy, we created new rules, changed old ones, and identified where we were using language that didn’t meet our standards. With the help of multiple engineering teams, we were able to quickly correct our code and copy. These changes mean that going forward, non-inclusive language will be flagged before it goes into the product. While our design org is continuously evaluating and updating our guidelines, we also created a new BethBot update process so anyone at HubSpot can request a change or new rule. Making our product more inclusive is an ongoing effort that doesn’t belong to any individual or team — everyone can contribute. What we added to our design system Use plain language The average reader can easily read and understand content written in plain language . It makes concepts more understandable, copy more readable, and products more usable. Using plain language doesn’t mean oversimplifying. It means you’re making ideas available to a wider audience. Here are the most important things to remember about plain language: Write for the average reader. The average adult reads at a U.S. eighth-grade level (about 12-14 years old). Literacy standards for different ages may vary by country. Write in the second person (you) Use the active voice Use the present tense Use simple verbs (i.e. “use” instead of “utilize”) Write in short sentences (15 words or less) Don’t use jargon Check your content’s readability using tools like Hemingway App or BethBot. Remove bias Bias isn’t always obvious. \"Implicit bias\" describes the attitudes or stereotypes that affect our understanding, actions, and decisions in an unconscious manner. Keep the following things in mind to combat bias: Use neutral pronouns Use “they” or “their” when the gender of the subject is unknown or unimportant. Use “a,” “the,” or “you/your” instead of pronouns in generic product copy. Content about issues facing women, the LGBTQ community, and real people should use the subjects’ pronouns. Do Don’t they he/she, (s)he, he or she their his or her a document, the document his document, her document When a new user is added, they'll be able to edit their password. When a new user is added, he or she will be able to edit his or her password. Once the user creates a document, they can upload it to HubSpot using the files tool. Once the user creates his or her document, he or she can upload it to HubSpot using the files tool. Select a user’s name Select his name, select her name Don’t make assumptions Content must be inclusive of all ages, races, genders, sexual orientations, abilities, and socioeconomic levels. Our customers are all over the world, and the way we talk about our product should reflect that. References and examples must be diverse, culturally sensitive, and avoid appropriation. Don’t use references that won’t make sense to a global audience Don’t say something is simple or easy — what’s easy for one user may be difficult for another Do Don’t Use HubSpot’s email tool to send reminders about special discounts and promotions. Use HubSpot’s email tool to send reminders about your Fourth of July sale. Write for the average reader. Write at an eighth-grade level. Use HubSpot’s new ABM tools to create a personalized buying experience for your top accounts. HubSpot’s new ABM tools make it easy for anyone to create a personalized buying experience for important accounts. Hi everyone, welcome all Hey guys Don’t generalize or stereotype This includes individuals, groups of people, cities, countries, regions, and cultures. Common workplace examples include stereotyping women as administrators and men as executives or engineers. Do Don’t Ask your Super Admin for access. Contact your Super Admin and ask her for access. Don’t use content that doesn’t translate HubSpot software is available in English, Dutch, French, German, Japanese, Portuguese (Brazil), and Spanish. Avoid content (including video, audio, or screenshots) that can’t be easily translated into all supported languages. Don’t use slang, idioms, or acronyms Don’t use phrases that won’t make sense across regions, countries, cultures, or languages. Some U.S.-based examples include: Do Don’t You're right. You've hit the nail on the head. Keep going. Hang in there. Because of In light of Aware In the loop Doing better than others Ahead of the curve In a short time, quickly In no time Take shortcuts Cut corners Good job, success You've hit it out of the park! As soon as possible ASAP Don’t use ableist language No person or group should be defined by a disability, and disabilities shouldn’t be mentioned unless they are relevant to the subject. If a disability is relevant to your content, don’t use euphemisms or phrases suggesting victimhood. Do Don’t Has Suffers from, challenged by People with disabilities Differently abled, disabled, handicapped People without disabilities Normal, healthy, able-bodied, standard Turn on/off Enable/disable Use inclusive terms and phrases Many common industry terms have racist or otherwise problematic origins or implications. Use these replacements instead.* Do Don’t blocklist blacklist allowlist whitelist core feature/built-in/top-level first-class legacy, exempt grandfather parent, primary master helper, secondary slave lunch & learn, tech talk brown bags folks, everyone guys hours of effort, effort man hours, manpower huddle, standup, discussion pow wow, powwow institutional knowledge tribal knowledge blocked days, restricted days black/gray days full disclosure open the kimono shortcoming blind spot *This is not an exhaustive list and will be updated as needed. Make it accessible Accessibility isn’t a want, it’s a need. About 15% of the world’s population — a staggering one billion people — lives with a disability. Seven out of ten users with a disability will immediately leave a website if it isn’t accessible. Inaccessible content creates a bad user experience, and it also creates legal liabilities. Improving accessibility improves the overall user experience — it’s a win-win. Readability is a big part of accessibility, but it goes beyond that. Audio/Video Include captions and transcripts on all audio and video content. Images Attach alt text to all images. Avoid using images with text in them unless you’re going to create versions for all supported languages. Organization Use headers and bulleted lists to provide structure Write descriptive page titles Create clear navigation and functional search capabilities Use legible fonts and font sizes Provide context for links and CTAs. Instead of saying “Learn more here,” try “For more of HubSpot’s guidelines on everything from character counts to capitalization, check out the Written Style Guide.” Visual elements Include non-text visual elements ( icons , illustrations, etc.) Use high-contrast colors, especially for text and important interactions Check everything off the list Before you publish or share your content, use this list to make sure it’s ready to go. Test your copy’s readability using Hemingway App or BethBot. Review your pronoun usage. If you’re writing about or quoting real people, ask them their pronouns. Assess your references and examples for assumptions, generalizations, slang, and other non-inclusive language. Use one of these five accessibility tools to see how users with a variety of disabilities will experience your content. More resources for inclusive language and accessibility Hemingway App Readability Guidelines Legibility, Readability, and Comprehension Accessibility, Usability, and Inclusion HubSpot blog and Medium posts A Human Approach to Product Content How to Use & Promote Inclusive Language at Your Organization Gender Neutral Pronouns: What They Are and How to Use Them Web Accessibility Guidelines 5 Web Accessibility Tools & What They Test For The Ultimate Guide to Web Accessibility How to Identify Web Accessible Colors for Products & Websites Why You Should Prioritize Web Accessibility (& What You’re Missing if You’re Not) Your 10-Minute Guide to the Web Accessibility Initiative (WAI) How to Make Your Web Icons Accessible to Users With Disabilities How to Identify Web Accessible Colors for Products & Websites", "date": "2021-03-18"},
{"website": "Hubspot", "title": "Update: How We're Building iOS Apps Today", "author": ["David Langley"], "link": "https://product.hubspot.com/blog/update-how-were-building-ios-apps-today", "abstract": "Back in 2014, we wrote a post about how we were using CocoaPods to Modularize our iOS app. With our latest iOS app we released a few months ago, we went in a different direction - here's why. The modular app approach proved very useful early on when we had multiple independent tools that we wanted to find product-market fit for. Each engineer was given a clear mission to focus on. They had to think less about the pieces that glued the overall application together and just provide a clear interface via routes where there were integration points between sub-apps. For a team like ours that was quickly iterating on a product and building mobile versions of a variety of independent tools, this approach proved very useful. There have however been a few caveats and learnings we have had along the way with this approach: Firstly, splitting the app into sub-apps didn’t prevent us from having to synchronize dependencies when bringing the app together to ship. In the case there were breaking changes across dependencies, we’d still need to resolve those manually. Secondly, there is an overhead associated with maintaining multiple Xcode workspaces for each sub-app (multiple project level settings, multiple podfiles, multiple Xcodes open on your desktop). When code changes happen to span more than one of your sub-apps, to test the changes locally, you have to set your pod to resolve locally. To avoid this overhead we moved to using a single XCode workspace and a single podfile, both of which had multiple app targets (one for each sub-app). This meant that developers only ever had one workspace they needed to work from and no more setting up of local pods. It also meant you were managing your pods from a single file, also mitigating somewhat the pain of synchronizing dependencies across sub-apps. As you can see in the above screenshot, we still have the separate apps, that we can build, run and deploy independently. Finally, and most importantly, we underestimated the number of cross-app user flows there would be. We ended up having a lot of cases where users wanted to navigate across sub-apps and each instance there would require a lot of communication and collaboration across developers. Independent sub-apps tacitly encourage slightly different approaches that created a bunch of friction for us as we integrated the apps. Three years has passed since we adopted that approach and HubSpot has evolved. There are now three products rather than one, each with its own set of tools. Those tools are also a lot more integrated and the integrations are much richer. They are very valuable individually but are even more valuable when all used together . Given that tight integration, it didn’t really make sense to keep that approach. Our customers think about the HubSpot Growth Stack as a single entity and only a limited set of the tools in the platform really make sense on mobile. We now have a single app that provides just the tools that the users need and none of the ones they don’t. As our app came together in a much more integrated way, we needed to re-evaluate and adopt an approach to match how the business was changing. A lot of apps with more integration means more state and a lot more complexity. We now use a Redux -like architecture which provides a single source of truth (a “store”) for the large quantity of data we now have in the system. The advent of reactive technologies like ReactiveX and Anvil really complement this kind of architecture. Redux means our application scales in a very sane and predictable way and makes it much easier to think about the state of the system. While the reactive UI tools mean we can still move really quickly building new features and UI, we can avoid odd data issues by keeping everything in the single Redux store. So what approach is right for you? Maybe it’s a modular approach with clearly defined interfaces? Maybe it’s Redux style architecture with a single state tree? One also doesn’t preclude the other – you could imagine a Redux style architecture where the modules of your application each contribute to part of the state tree. The important point is the approach you take should match the mission of your team and your business.", "date": "2017-02-06"},
{"website": "Hubspot", "title": "How We Solve Big Problems By Thinking Small", "author": ["Jeff Boulter"], "link": "https://product.hubspot.com/blog/how-our-product-team-thinks-small-to-solve-big-problems", "abstract": "Over the past few years, HubSpot has grown our team, product, and business to a global level. We have over 13,500 customers in over 90 countries, serve millions of requests, and deploy 300 times a day . As you grow to that scale, one of the biggest challenges of building software is how you maintain the nimbleness you have as a younger company. When I talk to people about how product development works here at HubSpot, a common theme emerges: we keep things small. Our software is complex and has many moving pieces - the only way to stay fast is to give our teams autonomy and make it easy for them to tackle problems. That’s why we think big when it comes to our vision for the product, but small day-to-day. Here's a look at some of the things we focus on keeping small: Teams: Most of our engineering teams have one Tech Lead and one or two engineers. Keeping teams small makes it easier to execute and communicate, and gives engineers the autonomy to really own a part of the product and drive it forward. Communication: Email often becomes a high-latency, long-form communication method that wastes a lot of energy both when writing of reading. For quick questions and 1:1 conversations we use HipChat as our go-to communication tool. Meetings: Large meetings usually end up being a big waste of time; you spend more time catching up and talking around a problem than actually diving into actionable outcomes. We prefer frequent and casual “pick-up” meetings as needed. Code Repositories: Our 1,400+ GitHub repos (about 100 of them are public ) are the canonical homes for each component (frontend, backend, or library) and are where all the code, tools and relevant documentation live. Commits: Our convention is to make each code commit atomic, contained and logically meaningful on its own. Pull Requests: Concise pull requests are more digestible and provide good fodder for open, productive discussion and suggestions for improvement. Deployables: Each repo’s builds produce at most a couple of deployable packages which can be independently verified and upgraded as often as necessary. Services: We create small, discrete services that have specific roles. They fit into an ecosystem of microservices that work together to power the entire product. Soft Launches: With so many customers, testing every possible configuration is impossible. That’s why we start small with early releases to a limited group of customers who are happy to help us test out new software. By using feature toggles , we can iterate on their feedback to get ready to launch to our entire customer base. Iteration Cycles: We ask for our customers’ feedback early and often so that we can act on it quickly and keep moving the product forward. By implementing their feedback frequently, we keep our iteration cycles short making it easier to tackle problems and make that process a constant one. We've found that when you think small and build on daily successes, you can solve some really big problems. How do you keep things small so your team can move fast?", "date": "2015-03-05"},
{"website": "Hubspot", "title": "Eric Ries Spotted at HubSpot: 5 Lean Startup Insights", "author": ["Joshua Payne"], "link": "https://product.hubspot.com/blog/bid/86093/eric-ries-spotted-at-hubspot-5-lean-startup-insights", "abstract": "Eric Ries of Lean Startup fame came to visit HubSpot yesterday, and we soaked up his input like a sponge. If you're not already familiar with him, Eric's opinions are pretty well documented. Reading his blog or buying his book would serve as a good introduction. Or you could follow @ericries on Twitter. He's been and continues to be hugely influential in the startup world, and we're big fans. We invited Eric to spend the day with us at HubSpot because, as we've found product-market fit and continue to grow aggressively, we wanted to hear his thoughts on how we can keep applying the principles of the lean startup as we go along. Once you have a successful product, you need to fanatically serve the needs of your installed base Pretty obvious, right? One way to view the lean startup principles is as a logical extension of Clayton Christensen's work on disruptive innovation , which emphasizes protecting against attacks on your installed base by remembering to serve their needs first, and to innovate upwards only when it's not at their expense. Meeting Eric in person underscored the similarities between Christensen's work and the philosophy of the lean startup. If anything, it seems like Eric advocates many of the same very ideas that Christensen does, but does so in a way that is more geared toward the engineer than the CEO. The combination of these complementary philosophies ensures that everyone is on the same page, both strategically and tactically. Innovation is cheap This is not to say that you don't also need to innovate. Eric suggests that you invest some consistent percentage of your efforts towards disruptive innovation. It doesn't have to be a lot -- 10% or so was the number he suggested offhand. And you don't need a huge team to innovate, either. It's a straight percentage, so whatever size team you've got, take 10% of their time and apply that. Protect your 10% allocation towards innovation aggressively and maintain discipline around truly dedicating it to disruptive innovation. Remember: innovation also serves your installed base, too. Use your technical debt as an asset Try to think of your technical debt as a good thing. After all, if you have technical debt, that at least means that you have real customers who are relying on this code. That's great! Now you can borrow time against thatexisting asset to invest in something else.  For instance, you could invest in new features (a good idea) or use that debt to invest in tools and infrastructure that allow you to iterate more rapidly and learn even faster (an even better idea). At the end of the day, if your technical debt isn't getting in your way, don't focus on it.  A system of 5 Whys analysis and continuous deployment can root out the things that are truly getting in your way. Make customer interaction routine This was a message especially targeted to the engineers in the room. It's easy for programmers to get their only customer interactions exclusively via bug reports. And even those are typically filtered to some degree through technical support. Eric advocated instituting a simple rule: Every engineer has to seek out some kind of customer interaction regularly, something like once a month. Watch user tests, sit in on support calls for a full day, visit a customer in their own workplace -- anything to get more direct customer feedback, more often. Validated is better than done At one point when we were disucssing the lean startup approach and how it related to the agile development methodology, the conversation wandered to kanban . In kanban, there are commonly at least three columns representing the lifecycle of a user story: backlog, doing, and done. Eric advocated for having a fourth: validated. Forcing product owners to own a validation step in which the measurable goal is assessed can act as a nice forcing function for increasing the likelihood that you'll learn something from each piece of work.", "date": "2012-04-26"},
{"website": "Hubspot", "title": "Debugging Hadoop Core Dumps", "author": ["Eric Abbott"], "link": "https://product.hubspot.com/blog/debugging-hadoop-core-dumps", "abstract": "A long time pain point for HubSpot Engineering has been intermittent core dumps with Hadoop jobs. The issue wasn't destructive; all jobs are idempotent and missing processes are restarted and rerun. Occasionally, however, the resulting queue processing delay would be enough to trigger a PagerDuty alert in the middle of the night. Having tried several times to resolve the issue, engineering was unhappily resigned to living with it -- until our recently-formed SRE team decided to take a shot at resolving the issue. Tl;dr As expected, java is pretty flexible with minor versions in regards to compiling and runtime even with JNI involved. The -Xcheck:jni command line option can cause Hadoop seg faults if built-in libs are used. Don't use obscure 3rd party libs in production. Workaround The known workaround was to rename a hadoop directory containing *.so dynamic libraries such that they weren't found upon jvm startup. The built-in *.so libraries are optimized compression algorithms to be used in favor of their java equivalents. mv /usr/lib/hadoop/lib/native /usr/lib/hadoop/lib/native.disabled That’s good, bad and awful. Good because there is a workaround. Bad because using the workaround adds minutes to jobs and is not viable long term. Engineers end up using the workaround for an hour or so then undo it once they think the job queue has been unclogged. Awful because its generally considered fruitless to debug 3rd party built-in C jni code. On the plus side the hadoop code is open source and available. Information Gathering Ok, so the workaround is insufficient and we need an actual fix. What are the facts on the ground? Disabling the built-in libs allows the job to work, albiet slower. Job failures are intermittent and quite often clustered. Happens to hadoop jobs for multiple teams (not isolated one-off code usage of a random barely supported feature). An experienced engineer already spent a week on the issue several months ago. Recompiling the built-in .so files did not resolve the issue. The trace files left behind as the jvm crashed were varied and mostly implicated the linux loader. One would assume the linux loader above reproach. # C  [ld-linux-x86-64.so.2+0x17412]  short+0x2 hs_err_pid4967.log A typical thread dump on jvm failure is shown below. Traces such as these are most useful if they can pinpoint the problematic code. #\n# A fatal error has been detected by the Java Runtime Environment:\n#\n#  SIGSEGV (0xb) at pc=0x00007fec8f7e7412, pid=4967, tid=140653696374528\n#\n# JRE version: 6.0_39-b04\n# Java VM: Java HotSpot(TM) 64-Bit Server VM (20.14-b01 mixed mode linux-amd64 compressed oops)\n# Problematic frame:\n# C  [ld-linux-x86-64.so.2+0x17412]  short+0x2\n#\n# If you would like to submit a bug report, please visit:\n#   http://java.sun.com/webapps/bugreport/crash.jsp\n# The crash happened outside the Java Virtual Machine in native code.\n# See problematic frame for where to report the bug.\n#\n \n---------------  T H R E A D  ---------------\n \nCurrent thread (0x00007fec80124000):  JavaThread \"pool-7-thread-1\" [_thread_in_native, id=6973, stack(0x00007fec7d8bd000,0x00007fec7d9be000)]\n \nsiginfo:si_signo=SIGSEGV: si_errno=0, si_code=1 (SEGV_MAPERR), si_addr=0x0000000000000706\n \n….\nStack: [0x00007fec7d8bd000,0x00007fec7d9be000],  sp=0x00007fec7d9b8d18,  free space=1007k\nNative frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code)\nC  [ld-linux-x86-64.so.2+0x17412]  short+0x2\n \nJava frames: (J=compiled Java code, j=interpreted, Vv=VM code)\nj  java.lang.ClassLoader$NativeLibrary.load(Ljava/lang/String;)V+0\nj  java.lang.ClassLoader.loadLibrary0(Ljava/lang/Class;Ljava/io/File;)Z+300\nj  java.lang.ClassLoader.loadLibrary(Ljava/lang/Class;Ljava/lang/String;Z)V+347\nj  java.lang.Runtime.loadLibrary0(Ljava/lang/Class;Ljava/lang/String;)V+54\nj  java.lang.System.loadLibrary(Ljava/lang/String;)V+7\nj  org.apache.hadoop.util.NativeCodeLoader.()V+36\nv  ~StubRoutines::call_stub\nj  org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.()V+4\nv  ~StubRoutines::call_stub\nj  sun.reflect.NativeConstructorAccessorImpl.newInstance0(Ljava/lang/reflect/Constructor;[Ljava/lang/Object;)Ljava/lang/Object;+0\nj  sun.reflect.NativeConstructorAccessorImpl.newInstance([Ljava/lang/Object;)Ljava/lang/Object;+72\nj  sun.reflect.DelegatingConstructorAccessorImpl.newInstance([Ljava/lang/Object;)Ljava/lang/Object;+5\nj  java.lang.reflect.Constructor.newInstance([Ljava/lang/Object;)Ljava/lang/Object;+92\nj  org.apache.hadoop.util.ReflectionUtils.newInstance(Ljava/lang/Class;Lorg/apache/hadoop/conf/Configuration;)Ljava/lang/Object;+46\nj  org.apache.hadoop.security.Groups.(Lorg/apache/hadoop/conf/Configuration;)V+29\nj  org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Lorg/apache/hadoop/conf/Configuration;)Lorg/apache/hadoop/security/Groups;+32\nj  org.apache.hadoop.security.UserGroupInformation.initUGI(Lorg/apache/hadoop/conf/Configuration;)V+80\nj  org.apache.hadoop.security.UserGroupInformation.initialize(Lorg/apache/hadoop/conf/Configuration;Z)V+1\nj  org.apache.hadoop.security.UserGroupInformation.ensureInitialized()V+16\nj  org.apache.hadoop.security.UserGroupInformation.isSecurityEnabled()Z+0\nj  org.apache.hadoop.security.UserGroupInformation.getLoginUser()Lorg/apache/hadoop/security/UserGroupInformation;+14\nj  org.apache.hadoop.security.UserGroupInformation.getCurrentUser()Lorg/apache/hadoop/security/UserGroupInformation;+28\nv  ~StubRoutines::call_stub\nj  sun.reflect.NativeMethodAccessorImpl.invoke0(Ljava/lang/reflect/Method;Ljava/lang/Object;[Ljava/lang/Object;)Ljava/lang/Object;+0\nj  sun.reflect.NativeMethodAccessorImpl.invoke(Ljava/lang/Object;[Ljava/lang/Object;)Ljava/lang/Object;+87\nj  sun.reflect.DelegatingMethodAccessorImpl.invoke(Ljava/lang/Object;[Ljava/lang/Object;)Ljava/lang/Object;+6\nj  java.lang.reflect.Method.invoke(Ljava/lang/Object;[Ljava/lang/Object;)Ljava/lang/Object;+161\nj  org.apache.hadoop.hbase.util.Methods.call(Ljava/lang/Class;Ljava/lang/Object;Ljava/lang/String;[Ljava/lang/Class;[Ljava/lang/Object;)Ljava/lang/Object;+13\nj  org.apache.hadoop.hbase.security.User.call(Lorg/apache/hadoop/security/UserGroupInformation;Ljava/lang/String;[Ljava/lang/Class;[Ljava/lang/Object;)Ljava/lang/Object;+6\nj  org.apache.hadoop.hbase.security.User.callStatic(Ljava/lang/String;)Ljava/lang/Object;+4\nj  org.apache.hadoop.hbase.security.User.access$400(Ljava/lang/String;)Ljava/lang/Object;+1\nj  org.apache.hadoop.hbase.security.User$SecureHadoopUser.()V+7\nj  org.apache.hadoop.hbase.security.User$SecureHadoopUser.(Lorg/apache/hadoop/hbase/security/User$1;)V+1\nj  org.apache.hadoop.hbase.security.User.getCurrent()Lorg/apache/hadoop/hbase/security/User;+11\nj  org.apache.hadoop.hbase.client.HConnectionManager$HConnectionKey.(Lorg/apache/hadoop/conf/Configuration;)V+78\nj  org.apache.hadoop.hbase.client.HConnectionManager.getConnection(Lorg/apache/hadoop/conf/Configuration;)Lorg/apache/hadoop/hbase/client/HConnection;+5\nj  org.apache.hadoop.hbase.client.HTable.(Lorg/apache/hadoop/conf/Configuration;[B)V+42\nj  org.apache.hadoop.hbase.client.HTableFactory.createHTableInterface(Lorg/apache/hadoop/conf/Configuration;[B)Lorg/apache/hadoop/hbase/client/HTableInterface;+6\nj  org.apache.hadoop.hbase.client.HTablePool.createHTable(Ljava/lang/String;)Lorg/apache/hadoop/hbase/client/HTableInterface;+12\nj  org.apache.hadoop.hbase.client.HTablePool.findOrCreateTable(Ljava/lang/String;)Lorg/apache/hadoop/hbase/client/HTableInterface;+18\nj  org.apache.hadoop.hbase.client.HTablePool.getTable(Ljava/lang/String;)Lorg/apache/hadoop/hbase/client/HTableInterface;+2\nj  com.hubspot.hbase.utils.AbstractHBaseDataStore.getTable(Ljava/lang/String;)Lorg/apache/hadoop/hbase/client/HTableInterface;+62\nj  com.performable.contacts.hbase.ContactsHBaseDataStore.getContactListsMetadataTable()Lorg/apache/hadoop/hbase/client/HTableInterface;+3\nj  com.performable.contacts.lists.BaseContactListSegByListTask.doWork(Lcom/hubspot/taskserviceapi/client/PullTask;)Z+40\nj  com.performable.contacts.lists.BaseContactListSegByListTask.executeTask(Lcom/hubspot/taskserviceapi/client/PullTask;)Z+2\nj  com.hubspot.taskserviceapi.client.pull.PullTaskRunnable.run()V+94\nj  java.util.concurrent.Executors$RunnableAdapter.call()Ljava/lang/Object;+4\nj  java.util.concurrent.FutureTask$Sync.innerRun()V+30\nj  java.util.concurrent.FutureTask.run()V+4\nj  java.util.concurrent.ThreadPoolExecutor$Worker.runTask(Ljava/lang/Runnable;)V+66\nj  java.util.concurrent.ThreadPoolExecutor$Worker.run()V+33\nj  java.lang.Thread.run()V+11\nv  ~StubRoutines::call_stub Another with: Current thread (0x00007f3fe25d1800):  JavaThread \"ContactListSegByListTaskWorker\" [_thread_in_native, id=7333, stack(0x00007f3fd64ce000,0x00007f3fd65cf000)]\n \nJava frames: (J=compiled Java code, j=interpreted, Vv=VM code)\nj  java.lang.ClassLoader$NativeLibrary.load(Ljava/lang/String;)V+0\nj  java.lang.ClassLoader.loadLibrary0(Ljava/lang/Class;Ljava/io/File;)Z+300\nj  java.lang.ClassLoader.loadLibrary(Ljava/lang/Class;Ljava/lang/String;Z)V+347\nj  java.lang.Runtime.loadLibrary0(Ljava/lang/Class;Ljava/lang/String;)V+54\nj  java.lang.System.loadLibrary(Ljava/lang/String;)V+7\nj  org.apache.hadoop.util.NativeCodeLoader.()V+36\nv  ~StubRoutines::call_stub\nj  org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.()V+4\nv  ~StubRoutines::call_stub\nj  sun.reflect.NativeConstructorAccessorImpl.newInstance0(Ljava/lang/reflect/Constructor;[Ljava/lang/Object;)Ljava/lang/Object;+0\nj  sun.reflect.NativeConstructorAccessorImpl.newInstance([Ljava/lang/Object;)Ljava/lang/Object;+72\nj  sun.reflect.DelegatingConstructorAccessorImpl.newInstance([Ljava/lang/Object;)Ljava/lang/Object;+5\nj  java.lang.reflect.Constructor.newInstance([Ljava/lang/Object;)Ljava/lang/Object;+92\nj  org.apache.hadoop.util.ReflectionUtils.newInstance(Ljava/lang/Class;Lorg/apache/hadoop/conf/Configuration;)Ljava/lang/Object;+46\nj  org.apache.hadoop.security.Groups.(Lorg/apache/hadoop/conf/Configuration;)V+29\nj  org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Lorg/apache/hadoop/conf/Configuration;)Lorg/apache/hadoop/security/Groups;+32\nj  org.apache.hadoop.security.UserGroupInformation.initUGI(Lorg/apache/hadoop/conf/Configuration;)V+80\nj  org.apache.hadoop.security.UserGroupInformation.initialize(Lorg/apache/hadoop/conf/Configuration;Z)V+1\nj  org.apache.hadoop.security.UserGroupInformation.ensureInitialized()V+16 Another with: Current thread (0x00007f30cc307800):  JavaThread \"ContactsFutureListSegEnqueuerTaskWorker\" [_thread_in_native, id=6602, stack(0x00007f30c16ba000,0x00007f30c17bb000)]\n \nC  [ld-linux-x86-64.so.2+0x17412]  short+0x2\n \nJava frames: (J=compiled Java code, j=interpreted, Vv=VM code)\nj  java.lang.ClassLoader$NativeLibrary.load(Ljava/lang/String;)V+0\nj  java.lang.ClassLoader.loadLibrary0(Ljava/lang/Class;Ljava/io/File;)Z+300\nj  java.lang.ClassLoader.loadLibrary(Ljava/lang/Class;Ljava/lang/String;Z)V+347\nj  java.lang.Runtime.loadLibrary0(Ljava/lang/Class;Ljava/lang/String;)V+54\nj  java.lang.System.loadLibrary(Ljava/lang/String;)V+7\nj  org.apache.hadoop.util.NativeCodeLoader.()V+36\nv  ~StubRoutines::call_stub\nj  org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.()V+4\nv  ~StubRoutines::call_stub\nj  sun.reflect.NativeConstructorAccessorImpl.newInstance0(Ljava/lang/reflect/Constructor;[Ljava/lang/Object;)Ljava/lang/Object;+0\nj  sun.reflect.NativeConstructorAccessorImpl.newInstance([Ljava/lang/Object;)Ljava/lang/Object;+72\nj  sun.reflect.DelegatingConstructorAccessorImpl.newInstance([Ljava/lang/Object;)Ljava/lang/Object;+5\nj  java.lang.reflect.Constructor.newInstance([Ljava/lang/Object;)Ljava/lang/Object;+92\nj  org.apache.hadoop.util.ReflectionUtils.newInstance(Ljava/lang/Class;Lorg/apache/hadoop/conf/Configuration;)Ljava/lang/Object;+46\nj  org.apache.hadoop.security.Groups.(Lorg/apache/hadoop/conf/Configuration;)V+29\nj  org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Lorg/apache/hadoop/conf/Configuration;)Lorg/apache/hadoop/security/Groups;+32\nj  org.apache.hadoop.security.UserGroupInformation.initUGI(Lorg/apache/hadoop/conf/Configuration;)V+80\nj  org.apache.hadoop.security.UserGroupInformation.initialize(Lorg/apache/hadoop/conf/Configuration;Z)V+1\nj  org.apache.hadoop.security.UserGroupInformation.ensureInitialized()V+16 The traces all pointed to the linux dynamic loader -- which is stock Centos 6 and does not have any issues of this type reported against it. The currently executing java thread varies, implying there are multiple ways to get to the failure situation. The java stack traces shown end after loading a built-in library. Somewhere inside the built-in code something blew up, we'll have no opportunity to debug on the java side. With no corrosponding core dumps, the trail ended here. Built-in libraries With the utility lsof we can examine the open files of a running process. Here's a partial list of open *.so files for one of our hadoop processes. $ sudo lsof -p 5521 | grep \"\\.so\"\njava    5521 root  mem    REG              202,1    110960    132442 /lib64/libresolv-2.12.so\njava    5521 root  mem    REG              202,1     27424    132430 /lib64/libnss_dns-2.12.so\njava    5521 root  mem    REG              202,1     65928    132432 /lib64/libnss_files-2.12.so\njava    5521 root  mem    REG              202,1     88600    132811 /lib64/libz.so.1.2.3\njava    5521 root  mem    REG              202,1    234934    160387 /usr/java/jdk1.6.0_39/jre/lib/amd64/libjava.so\njava    5521 root  mem    REG              202,1      8236    160386 /usr/java/jdk1.6.0_39/jre/lib/amd64/libjaas_unix.so\njava    5521 root  mem    REG              202,1     78856    153875 /usr/lib/hadoop/lib/native/libhadoop.so.1.0.0\njava    5521 root  mem    REG              202,1    991112     12839 /tmp/snappy-1.0.4.1-libsnappyjava.so\njava    5521 root  mem    REG              202,1     48338     12653 /tmp/libjansi-64-1.9.so\njava    5521 root  mem    REG              202,1     43832    132444 /lib64/librt-2.12.so The built-in libs converge to four major groupings: linux system libs, jvm libs, hadoop libs and some libs in /tmp. The system (/lib64/) libs and jvm libs are expected and seem normal. The hadoop libs are certainly expected. What do stand out are the /tmp libs. It's unexpected that a library would be stored there, however snappy compression is used and ansi certainly doesn't raise any red flags. The files exist in the filesystem and have appropriate permissions. $ ls -altr /tmp/*.so\n-rwxr-xr-x 1 root root 991112 Aug  5 18:15 /tmp/snappy-1.0.4.1-libsnappyjava.so\n-rwxr-xr-x 1 root root  48340 Oct 11 15:24 /tmp/libjansi-64-1.9.so Running objdump on the libs confirmed all requirements/dependencies were present and accounted for. -Xcheck:jni, and bugs in -Xcheck:jni In addition to enabling core dumps we hoped the command line option -Xcheck:jni would provide some insight. Unfortunately changing the system in two ways caused a minor amount of confusion since the -Xcheck:jni feature exposed a different bug in Hadoop. It took awhile to sift through the data and determine there were two types of core dumps. One type of core dump was similar to what the devs have been seeing all along, and the other a new one associated with the -Xcheck:jni feature. The -Xcheck:jni core dumps were basically identical: (gdb) bt\n#0  0x00007fe11032f8a5 in raise () from /lib64/libc.so.6\n#1  0x00007fe110331085 in abort () from /lib64/libc.so.6\n#2  0x00007fe10fdfaa37 in os::abort(bool) () from /usr/java/jdk1.6.0_39/jre/lib/amd64/server/libjvm.so\n#3  0x00007fe10fc0be03 in jniCheck::validate_class(JavaThread*, _jclass*, bool) () from /usr/java/jdk1.6.0_39/jre/lib/amd64/server/libjvm.so\n#4  0x00007fe10fc27809 in checked_jni_GetStaticObjectField () from /usr/java/jdk1.6.0_39/jre/lib/amd64/server/libjvm.so\n#5  0x00007fe0ff0d5f79 in Java_org_apache_hadoop_io_compress_zlib_ZlibCompressor_deflateBytesDirect () from /usr/lib/hadoop/lib/native/libhadoop.so.1.0.0 Paired with the core dumps were java exceptions and stack traces in the hadoop logs. FATAL ERROR in native method: JNI received a class argument that is not a class\nat org.apache.hadoop.io.compress.zlib.ZlibCompressor.deflateBytesDirect(Native Method)\nat org.apache.hadoop.io.compress.zlib.ZlibCompressor.compress(ZlibCompressor.java:362)\nlocked <0x00000000f8eb10e8> - locked <0x00000000f8eb10e8> (a org.apache.hadoop.io.compress.zlib.ZlibCompressor)\n(a org.apache.hadoop.io.compress.zlib.ZlibCompressor)\nat org.apache.hadoop.io.compress.CompressorStream.compress(CompressorStream.java:80)\nat org.apache.hadoop.io.compress.CompressorStream.finish(CompressorStream.java:90)\nat org.apache.hadoop.io.SequenceFile$BlockCompressWriter.writeBuffer(SequenceFile.java:1418)\nlocked <0x00000000f8eb0e58> - locked <0x00000000f8eb0e58> (a org.apache.hadoop.io.SequenceFile$BlockCompressWriter)\n(a org.apache.hadoop.io.SequenceFile$BlockCompressWriter)\nat org.apache.hadoop.io.SequenceFile$BlockCompressWriter.sync(SequenceFile.java:1433)\nlocked <0x00000000f8eb0e58> - locked <0x00000000f8eb0e58> (a org.apache.hadoop.io.SequenceFile$BlockCompressWriter)\n(a org.apache.hadoop.io.SequenceFile$BlockCompressWriter)\nat org.apache.hadoop.io.SequenceFile$BlockCompressWriter.close(SequenceFile.java:1456)\nlocked <0x00000000f8eb0e58> - locked <0x00000000f8eb0e58> (a org.apache.hadoop.io.SequenceFile$BlockCompressWriter)\n(a org.apache.hadoop.io.SequenceFile$BlockCompressWriter)\nat com.performable.contacts.imports.csv.ContactsImportJobInputWriter.reallyWriteInputToPath(ContactsImportJobInputWriter.java:136)\nat com.performable.contacts.imports.csv.ContactsImportJobInputWriter.writeInputToPath(ContactsImportJobInputWriter.java:93) This mapped back to the following function in the Hadoop source code: public synchronized int compress(byte[] b, int off, int len) throws IOException {\n  ...\n  // Re-initialize the zlib's output direct buffer\n  compressedDirectBuf.rewind();\n  compressedDirectBuf.limit(directBufferSize);\n  // Compress data\n  n = deflateBytesDirect();\n  compressedDirectBuf.limit(n);\n  // Check if zlib consumed all input buffer\n  // set keepUncompressedBuf properly\n  if (uncompressedDirectBufLen <= 0)\n  ...\n  return n;\n} There are no line numbers for the ZlibCompression.c code. However we are happy to observe there is only one reference to GetStaticObjectField. JNIEXPORT jint JNICALL\nJava_org_apache_hadoop_io_compress_zlib_ZlibCompressor_deflateBytesDirect(\nJNIEnv *env, jobject this) {\n  // Get members of ZlibCompressor\n  z_stream *stream = ZSTREAM((*env)->GetLongField(env, this, ZlibCompressor_stream));\n  if (!stream)\n    { THROW(env, \"java/lang/NullPointerException\", NULL); return (jint)0; }\n  // Get members of ZlibCompressor\n  jobject clazz = (*env)->GetStaticObjectField(env, this, ZlibCompressor_clazz);\n  jobject uncompressed_direct_buf = (*env)->GetObjectField(env, this, ZlibCompressor_uncompressedDirectBuf);\n  jint uncompressed_direct_buf_off = (*env)->GetIntField(env, this, ZlibCompressor_uncompressedDirectBufOff);\n  jint uncompressed_direct_buf_len = (*env)->GetIntField(env, this, ZlibCompressor_uncompressedDirectBufLen);\n  jobject compressed_direct_buf = (*env)->GetObjectField(env, this, ZlibCompressor_compressedDirectBuf);\n  jint compressed_direct_buf_len = (*env)->GetIntField(env, this, ZlibCompressor_directBufferSize);\n  jboolean finish = (*env)->GetBooleanField(env, this, ZlibCompressor_finish);\n  // Get the input direct buffer\n  LOCK_CLASS(env, clazz, \"ZlibCompressor\");\n  Bytef* uncompressed_bytes = (*env)->GetDirectBufferAddress(env,\n  uncompressed_direct_buf);\n  UNLOCK_CLASS(env, clazz, \"ZlibCompressor\");\n  if (uncompressed_bytes == 0)\n    { return (jint)0; } Locating the jni method docs we find the signature for GetStaticObjectField Built-in Type GetStatic<type>Field (JNIEnv *env, jclass clazz, jfieldID fieldID); The value for jfieldID is staticly stored in field ZlibCompressor_clazz JNIEXPORT void JNICALL\nJava_org_apache_hadoop_io_compress_zlib_ZlibCompressor_initIDs( JNIEnv *env, jclass class)\n{\n  ...\n  ZlibCompressor_clazz = (*env)->GetStaticFieldID(env, class, \"clazz\", \"Ljava/lang/Class;\"); That looks like a real issue. The fieldID ZlibCompressor_clazz is pulled from the Class object, while the call to get the field is against the object instance 'this'. Does the call always return the class object? Also, all sync in the java class is done on the instance. Syncing in the C code on the Class objects broadens the lock. All in all this seems like a potential problem. We spent some time altering this code to properly pass the Class object through to the C code. After hacking in what appeared to be a functional replacement the original core dumps persisted. While this may be an issue, it's not the one we're after. Version(s) Compatibility Back when core dumps were being enabled I poked around and determined that CDH has a recommended java version of jdk1.6.0_31 and that we were on a mixture of jdk1.6.0_27 and jdk1.6.0_39. Our java code was all compiled with jdk1.6.0_27, the CDH code was all compiled with their certified version jdk1.6.0_31. We spent some time compiling our code on jdk1.6.0_31 and running the code on jvm _31. Still no luck, core dumps kept happening. We had also lagged a bit on updates to our Linux distro. Presumably an OS upgrade will involve an upgrade to libc, which is certainly in the the picture and implicated by the non-Xcheck:jni core dumps. We installed a newer distro, recompiled where needed, and still encountered issues. This did have the positive side effect of proving that our relatively lax adherence to specific versions wasn't hurting us. Libc based core dump analysis The non-Xcheck:jni core dumps were a bit more varied and didn't follow as precise a pattern. While they all died in the linux linker, the originating calls from java came from all over the place. There really wasn't a pattern as to what java/hadoop code could be triggering some kind of buffer overflow or other hard to find C error. The last thing we could do is to track down as closely as possible what exactly happened via gdb and hope something comes out of it. (Un?)fortunately my previous experience with gdb never made it further than ‘bt<enter>’, so there was a good deal of thrashing around to get even rudimentary information like function parameters, register values and local variables. The gdb stack traces all had the following pattern to them, and as is evident to your average linux hacker there are no debug symbols. (gdb) \n#0 0x00007ff98eb9b8a5 in raise () from /lib64/libc.so.6\n#1 0x00007ff98eb9d085 in abort () from /lib64/libc.so.6\n#2 0x00007ff98e66c317 in os::abort(bool) () from /usr/java/jdk64_1.6.0_27/jre/lib/amd64/server/libjvm.so\n#3 0x00007ff98e7bf898 in VMError::report_and_die() () from /usr/java/jdk64_1.6.0_27/jre/lib/amd64/server/libjvm.so\n#4 0x00007ff98e7c0411 in crash_handler(int, siginfo*, void*) () from /usr/java/jdk64_1.6.0_27/jre/lib/amd64/server/libjvm.so\n#5 \n#6 0x00007ff98ec8f044 in _dl_addr () from /lib64/libc.so.6\n#7 0x00007ff98e67021f in os::find(unsigned char*, outputStream*) () from /usr/java/jdk64_1.6.0_27/jre/lib/amd64/server/libjvm.so\n#8 0x00007ff98e669667 in os::print_location(outputStream*, long, bool) () from /usr/java/jdk64_1.6.0_27/jre/lib/amd64/server/libjvm.so\n#9 0x00007ff98e6735ff in os::print_register_info(outputStream*, void*) () from /usr/java/jdk64_1.6.0_27/jre/lib/amd64/server/libjvm.so\n#10 0x00007ff98e7beee3 in VMError::report(outputStream*) () from /usr/java/jdk64_1.6.0_27/jre/lib/amd64/server/libjvm.so\n#11 0x00007ff98e7bf775 in VMError::report_and_die() () from /usr/java/jdk64_1.6.0_27/jre/lib/amd64/server/libjvm.so\n#12 0x00007ff98e672cb5 in JVM_handle_linux_signal () from /usr/java/jdk64_1.6.0_27/jre/lib/amd64/server/libjvm.so\n#13 0x00007ff98e66efde in signalHandler(int, siginfo*, void*) () from /usr/java/jdk64_1.6.0_27/jre/lib/amd64/server/libjvm.so\n#14 \n#15 0x00007ff98f334392 in strcmp () from /lib64/ld-linux-x86-64.so.2\n#16 0x00007ff98f3258d7 in _dl_map_object () from /lib64/ld-linux-x86-64.so.2\n#17 0x00007ff98f32f9b4 in dl_open_worker () from /lib64/ld-linux-x86-64.so.2\n#18 0x00007ff98f32b196 in _dl_catch_error () from /lib64/ld-linux-x86-64.so.2\n#19 0x00007ff98f32f46a in _dl_open () from /lib64/ld-linux-x86-64.so.2\n#20 0x00007ff98eefcf66 in dlopen_doit () from /lib64/libdl.so.2\n#21 0x00007ff98f32b196 in _dl_catch_error () from /lib64/ld-linux-x86-64.so.2\n#22 0x00007ff98eefd29c in _dlerror_run () from /lib64/libdl.so.2\n#23 0x00007ff98eefcee1 in dlopen@@GLIBC_2.2.5 () from /lib64/libdl.so.2\n#24 0x00007ff98e66c87f in os::dll_load(char const*, char*, int) () from /usr/java/jdk64_1.6.0_27/jre/lib/amd64/server/libjvm.so\n#25 0x00007ff98e4c9a54 in JVM_LoadLibrary () from /usr/java/jdk64_1.6.0_27/jre/lib/amd64/server/libjvm.so\n#26 0x00007ff98d7a7c94 in Java_java_lang_ClassLoader_00024NativeLibrary_load () from /usr/java/jdk64_1.6.0_27/jre/lib/amd64/libjava.so\n#27 0x00007ff985010d6e in ?? ()\n#28 0x00007ff97f4e5508 in ?? () With a new test server as a playground, we grabbed the glibc debug info package. With flags like that it's hard not to come to the conclusion someone was trying to hide the debug symbols. sudo yum --nogpgcheck --enablerepo=debug install glibc-debuginfo Now here's a trace with the debug symbols. Arguments to functions, and even the occasional line number! (gdb) bt\n#0  0x00007f7aceca28a5 in raise () from /lib64/libc.so.6\n#1  0x00007f7aceca4085 in abort () from /lib64/libc.so.6\n#2  0x00007f7ace76da37 in os::abort(bool) () from /usr/java/jdk1.6.0_39/jre/lib/amd64/server/libjvm.so\n#3  0x00007f7ace8c1f28 in VMError::report_and_die() () from /usr/java/jdk1.6.0_39/jre/lib/amd64/server/libjvm.so\n#4  0x00007f7ace8c2aa1 in crash_handler(int, siginfo*, void*) () from /usr/java/jdk1.6.0_39/jre/lib/amd64/server/libjvm.so\n#5  \n#6  0x00007f7aced96044 in _dl_addr () from /lib64/libc.so.6\n#7  0x00007f7ace77195f in os::find(unsigned char*, outputStream*) () from /usr/java/jdk1.6.0_39/jre/lib/amd64/server/libjvm.so\n#8  0x00007f7ace76ad87 in os::print_location(outputStream*, long, bool) () from /usr/java/jdk1.6.0_39/jre/lib/amd64/server/libjvm.so\n#9  0x00007f7ace774d3f in os::print_register_info(outputStream*, void*) () from /usr/java/jdk1.6.0_39/jre/lib/amd64/server/libjvm.so\n#10 0x00007f7ace8c1573 in VMError::report(outputStream*) () from /usr/java/jdk1.6.0_39/jre/lib/amd64/server/libjvm.so\n#11 0x00007f7ace8c1e05 in VMError::report_and_die() () from /usr/java/jdk1.6.0_39/jre/lib/amd64/server/libjvm.so\n#12 0x00007f7ace7743f5 in JVM_handle_linux_signal () from /usr/java/jdk1.6.0_39/jre/lib/amd64/server/libjvm.so\n#13 0x00007f7ace7706fe in signalHandler(int, siginfo*, void*) () from /usr/java/jdk1.6.0_39/jre/lib/amd64/server/libjvm.so\n#14 \n#15 strcmp () at ../sysdeps/x86_64/strcmp.S:136\n#16 0x00007f7acf42c8e7 in _dl_map_object (loader=0x410817a0, name=0x7f7ac04e6460 \"/usr/lib/hadoop/lib/native/libhadoop.so.1.0.0\", type=2, trace_mode=0, mode=-1879048191, nsid=0)\n   at dl-load.c:2016\n#17 0x00007f7acf436a34 in dl_open_worker (a=0x7f7abe2218c0) at dl-open.c:227\n#18 0x00007f7acf4321a6 in _dl_catch_error (objname=0x7f7abe221910, errstring=0x7f7abe221908, mallocedp=0x7f7abe22191f, operate=0x7f7acf436910 <dl_open_worker>, args=0x7f7abe2218c0)\n   at dl-error.c:178\n#19 0x00007f7acf4364ea in _dl_open (file=0x7f7ac04e6460 \"/usr/lib/hadoop/lib/native/libhadoop.so.1.0.0\", mode=-2147483647, caller_dlopen=0x7f7ace76df9f, nsid=-2, argc=23,\n   argv=, env=0x7f7ac8082090) at dl-open.c:569\n#20 0x00007f7acf003f66 in dlopen_doit (a=0x7f7abe221ae0) at dlopen.c:67\n#21 0x00007f7acf4321a6 in _dl_catch_error (objname=0x7f7ac06c5270, errstring=0x7f7ac06c5278, mallocedp=0x7f7ac06c5268, operate=0x7f7acf003f00 <dlopen_doit>, args=0x7f7abe221ae0)\n   at dl-error.c:178\n#22 0x00007f7acf00429c in _dlerror_run (operate=0x7f7acf003f00 <dlopen_doit>, args=0x7f7abe221ae0) at dlerror.c:164\n#23 0x00007f7acf003ee1 in __dlopen (file=, mode=) at dlopen.c:88\n#24 0x00007f7ace76df9f in os::dll_load(char const*, char*, int) () from /usr/java/jdk1.6.0_39/jre/lib/amd64/server/libjvm.so\n#25 0x00007f7ace5cac94 in JVM_LoadLibrary () from /usr/java/jdk1.6.0_39/jre/lib/amd64/server/libjvm.so\n#26 0x00007f7acd8a6d34 in Java_java_lang_ClassLoader_00024NativeLibrary_load () from /usr/java/jdk1.6.0_39/jre/lib/amd64/libjava.so In a perfect world, the cause of the failure would be the top line of the stack trace. However raise(), abort(), os::abort() don't sound like causes but symptoms. Scanning through the entire trace, there are two signals raised. On the assumption that signals are for special occasions only, it's reasonable to assume whatever raised the signal is where a failure happened. There are two signals raised, which one should we target? The first signal could only have happened because of our error, the second could be our error or a complication from our error. Starting with the first signal should get us closest to a clean view of the error. So what's going in in frame 15 that raises a signal. (gdb) f 15\n#15 strcmp () at ../sysdeps/x86_64/strcmp.S:136\n136 cmpb (%rsi), %al Strcmp() takes two char arrays as arguments and returns an integer. Vegas odds would be on strcmp() only raising a signal if one of the passed in arguments was bad. As confirmation, the line of assembly shows the failure was on instruction cmpb (compare bytes). To find the arguments and where they came from we head to frame 16. (gdb) f 16\n#16 0x00007f7acf42c8e7 in _dl_map_object (loader=0x410817a0, name=0x7f7ac04e6460 \"/usr/lib/hadoop/lib/native/libhadoop.so.1.0.0\", type=2, trace_mode=0, mode=-1879048191, nsid=0)   at dl-load.c:2016\n2016  if (strcmp (name, soname) != 0) Showing the frame in gdb with 'f 16' prints a mess of information including the method name, it's arguments, the file its from and the last executed line number in that frame. The other piece of data shown is this example, '2016 if (strcmp(name, soname) != 0)', shows the particular line of code that triggered the next frame on the stack. Lets have a look at that method. internal_function\n_dl_map_object (struct link_map *loader, const char *name,\nint type, int trace_mode, int mode, Lmid_t nsid)\n{\n  int fd;\n  char *realname;\n  char *name_copy;\n  struct link_map *l;\n  struct filebuf fb; \n\n  assert (nsid >= 0);\n  assert (nsid < GL(dl_nns));\n\n  /* Look for this name among those already loaded. */\n  for (l = GL(dl_ns)[nsid]._ns_loaded; l; l = l->l_next)\n  {\n    /* If the requested name matches the soname of a loaded object,\n       use that object. Elide this check for names that have not\n       yet been opened. */\n    if (__builtin_expect (l->l_faked, 0) != 0\n            || __builtin_expect (l->l_removed, 0) != 0)\n      continue;\n    if (!_dl_name_match_p (name, l))\n    {\n      const char *soname;\n\n      if (__builtin_expect (l->l_soname_added, 1)\n                || l->l_info[DT_SONAME] == NULL)\n        continue;\n\n        soname = ((const char *) D_PTR (l, l_info[DT_STRTAB])\n                + l->l_info[DT_SONAME]->d_un.d_val);\n      if (strcmp (name, soname) != 0)\n        continue; The code is a little on the dense side, but the method is called _dl_map_object and the comment before the loop is 'Look for this name among those already loaded'. 'this name' is probably referring to the name argument passed in, \"/usr/lib/hadoop/lib/native/libhadoop.so.1.0.0\". The things already loaded are probably the other stuff in the built-in libraries. So far so good. The strcmp line takes the name argument to the method along with soname. Soname appears to be generated from the stuff being looped through. So lets see what the value of soname is. (gdb) info locals\nsoname = <value optimized out>\nfd = <value optimized out>\nrealname = <value optimized out>\nname_copy = <value optimized out>\nl = 0x7fba082bd670\nfb = {len = 140436846644544, \nbuf = \"7}\\306\\r\\272\\177\\000\\000\\200\\340\\240\\375\\271\\177\\000\\000@\\215[\\000\\272\\177\\000\\000\\000\\b?\\n\\272\\177\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\260\\340\\240\\375\\271\\177\\000\\000s\\374\\306\\r\\272\\177\\000\\000\\000\\b?\\n\\272\\177\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\300\\340\\240\\375\\271\\177\\000\\000\\357\\372\\306\\r\\272\\177\\000\\000\\330\\363\\036\\016\\272\\177\\000\\000\\000\\020\\323\\016\\272\\177\\000\\000\\360\\340\\240\\375\\271\\177\\000\\000s\\374\\306\\r\\272\\177\\000\\000\\000\\b?\\n\\272\\177\\000\\000\\330\\363\\036\\016\\272\\177\\000\\000\\340X\\036\\016\\272\\177\\000\\000\\000\\020\\323\\016\\272\\177\\000\\000P\\341\\240\\375\\271\\177\\000\\000$.\\307\\r\\272\\177\\000\\000\\000\\b?\\n\\272\\177\\000\\000'\\000\\000\\000\\000\\000\\000\\000\\000\\b?\\n\\272\\177\\000\\000 \\000\\000\\000\\272\\177\\000\\000\\340\\210\\257\\t\\272\\177\\000\\000'\\000\\000\\000\\000\\000\\000\\000@\\215[\\000\\272\\177\\000\\000\\000\\000\\000\\000\\272\\177\", '\\000' \"\\272, \\177\\000\\000\\060\\362\\240\\375\\271\\177\\000\\000\\320\\t?\\n\\272\\177\\000\\000\\220\\t\\030@\\a\\000\\000\\000\\360\\210\\257\\t\\272\\177\\000\\000\\000\"...}\nfound_other_class = <value optimized out>\nstack_end = <value optimized out>\n(gdb) print soname\n$1 = <value optimized out> Soname's value is <value optimized out> and according to a question on stackoverflow <value optimized out> means the value resides in a register. Printing out the registers didn't reveal much, but then again we're not really looking for the value soname which we know caused strcmp() to blow up. We want to see the structures and data that soname was created from. Looking back at the C code soname was generated from l and l_info. Gdb seems pretty smart and will do a great job of printing out the structure of l for us. (gdb) print l\n$1 = (struct link_map *) 0x7fec89ba3ad0\n\n(gdb) print *l\n$2 = {l_addr = 140165160083456, l_name = 0x7f7ac9d52210 \"/tmp/libjansi-64-1.9.so\", l_ld = 0x7f7abeb3ade0, l_next = 0x7f7ac9db7a50, l_prev = 0x7f7ac9d94920, l_real = 0x7f7ac9e836f0, l_ns = 0, l_libname = 0x7f7ac9e83b60, l_info = {0x0, 0x7f7abeb3ade0, 0x7f7abeb3ae80, 0x7f7abeb3ae70, 0x0, 0x7f7abeb3ae30, 0x7f7abeb3ae40, 0x7f7abeb3aeb0, 0x7f7abeb3aec0, 0x7f7abeb3aed0, 0x7f7abeb3ae50, 0x7f7abeb3ae60, 0x7f7abeb3ae00, 0x7f7abeb3ae10, 0x7f7abeb3adf0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x7f7abeb3ae90, 0x0, 0x0, 0x7f7abeb3aea0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x7f7abeb3aef0, 0x7f7abeb3aee0, 0x0, 0x0, 0x0, 0x0, 0x7f7abeb3af10, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x7f7abeb3af00, 0x0 , 0x7f7abeb3ae20}, l_phdr = 0x7f7abe93a040, l_entry = 140165160085632, l_phnum = 5, l_ldnum = 25, l_searchlist = {r_list = 0x7f7ac9d523a0, r_nlist = 3}, l_symbolic_searchlist = {r_list = 0x7f7ac9e83b58, r_nlist = 0}, l_loader = 0x0, l_versions = 0x7f7ac9c85dc0, l_nversions = 3, l_nbuckets = 17, l_gnu_bitmask_idxbits = 1, l_gnu_shift = 7, l_gnu_bitmask = 0x7f7abe93a168, {l_gnu_buckets = 0x7f7abe93a178, l_chain = 0x7f7abe93a178}, {l_gnu_chain_zero = 0x7f7abe93a1a4, l_buckets = 0x7f7abe93a1a4}, l_direct_opencount = 1, l_type = lt_loaded, l_relocated = 1, l_init_called = 1, l_global = 0, l_reserved = 0, l_phdr_allocated = 0, l_soname_added = 0, l_faked = 0, l_need_tls_init = 0, l_auditing = 0, l_audit_any_plt = 0, l_removed = 0, l_contiguous = 1, l_symbolic_in_local_scope = 0, l_free_initfini = 1, l_rpath_dirs = {dirs = 0x0, malloced = 0}, l_reloc_result = 0x0, l_versyms = 0x7f7abe93a722, l_origin = 0x7f7ac8ac9310 \"/tmp\", l_map_start = 140165160083456, l_map_end = 140165162184664, l_text_end = 140165160087552, l_scope_mem = {0x7f7acf645440, 0x7f7ac9e839a8, 0x0, 0x0}, l_scope_max = 4, l_scope = 0x7f7ac9e83a48, l_local_scope = {0x7f7ac9e839a8, 0x0}, l_dev = 51713, l_ino = 12837, l_runpath_dirs = {dirs = 0x0, malloced = 0}, l_initfini = 0x7f7ac9d52380, l_reldeps = 0x0, l_reldepsmax = 0, l_used = 1, l_feature_1 = 0, l_flags_1 = 0, l_flags = 0, l_idx = 0, l_mach = {plt = 0, gotplt = 0, tlsdesc_table = 0x0}, l_lookup_cache = {sym = 0x7f7abe93a328, type_class = 0, value = 0x7f7ac9e836f0, ret = 0x7f7abe93a328}, l_tls_initimage = 0x0, l_tls_initimage_size = 0, l_tls_blocksize = 0, l_tls_align = 0, l_tls_firstbyte_offset = 0, l_tls_offset = 0, l_tls_modid = 0, l_relro_addr = 0, l_relro_size = 0, l_serial = 15, l_audit = 0x7f7ac9e836f0} And now we've got a view of the struct and the field names and values/addresses. At first glance its all a bit incomprehensible, except for the char array l_name = \"/tmp/libjansi-64-1.9.so\" sticking out. So while looking for a built-in hadoop lib, it loops through all built-in stuff loaded and seg faults on a non-hadoop built-in library? What is that ansi lib for anyway? Google finds the library at jansi.fusesource.org, and it isn't some internal jvm ansi lib as originally assumed. According to the website jansi is for \" Eliminating boring console output\". Why would a java library to eliminate boring console output have a built-in dynamic shared object? More practically, how could a java jar have a packaged shared object? A quick look at the other core dumps verifies they all died in the _dl_map_object method while examining the libjansi.so object. A bit more research turns up the pattern for including built-in code in a .jar file. Our codebase had two such libraries, snappy compression and jansi. During static initialization a java class will reach into the jar file with the class loader and extract an appropriate dynamic library dropping it onto the file system, typically in the tmp directory. After extraction the java code will run System.load() or System.loadLibrary() making the built-in code available. One integral part of the pattern that jansi appears to have missed is to only extract the binary if it's not already present on the filesystem. Looking at /tmp we note the time differences in the two *.so files. The libjansi timestamp being younger than the libsnappy is a clue the jansi code overwrites its binary each time its loaded. $ ls -altr /tmp/*.so -rwxr-xr-x 1 root root 991112 Aug 5 18:15 /tmp/snappy-1.0.4.1-libsnappyjava.so -rwxr-xr-x 1 root root 48340 Oct 11 15:24 /tmp/libjansi-64-1.9.so So at this point the working theory is that the linux dynamic loader gets fatally tripped up because a built-in library loaded by the jvm is overwritten with a binary duplicate of itself. The failure would appear to be triggered by the hadoop library attempting to load/access it's own built-in routines. Almost certainly there is a race condition involved, and the longer a server is unchanged the more likely it is to be stable and vice versa. While my education of shared objects and linking in linux is more than a decade out of date, I was pretty firm in my belief that once an object was loaded you couldn't get rid of it, kind of like how you can delete a file from the file system but the file will stick around and be visible with lsof if there is an open filehandle. In this case however verification was straightforward; on a system that hasn't been cored in several hours overwrite the file with itself and wait. Since there's also a race condition involved, we'd probably have to run the test several times w/o causing a core dump to be confident this theory was incorrect. On a server running w/o incident for 8hrs the libjansi binary was copied over itself; 15m later there was a core dump. Boom we have our culprit. It took an hour to remove jansi and redeploy, and the core dumps were gone. Jansi's Purpose Jansi was originally added to provide colored consoled output in a developers IDE. Adoption never made it past the initial use case of identifying the origin source for configuration parameters. On ly useful in development and never used after container startup, no one complained after it was removed. (ZK) abemail.variant.delete.error.output=true (ZK) abemail.wait.on.missing.metadata.millis=5000 (DEF) addons.cache.prefix=aA (DEF) addons.memory.expiry.millis=60000 (DEF) airbrake.apikey=**(REDACTED)** (DEF) airbrake.notice.api.url=https://airbrake.io/notifier_api/v2/notices (ZK) analytics.api.batchSize=100000 (ZK) analytics.api.cache.endpoints=true And for a bit of HubSpot color, there was a spirited debate as to the merits of the original PR, with the cons argument now getting the last laugh. Conclusion Don't include obscure third party libraries in production. Since QA and development will often mirror production, unnecessary libs are right out. All the time spent tweaking different compilation and runtime java minor versions had no noticeable effect. Overall that's a good thing to have a positive experience with java's Compile Once, Run Anywhere claim. This held true even with the complication of third party built-in C libs. And finally we learned that built-in jni C libs are pretty scary when compared to/combined with the java world. The addition of the jvm command line arg -Xcheck:jni showed that several year old built-in C code was not written correctly according to the jni spec. Yet the code has been battle tested in the field and is working well enough.", "date": "2013-11-07"},
{"website": "Hubspot", "title": "Working on the HubSpot Mobile Team", "author": ["Samuel Siskind"], "link": "https://product.hubspot.com/blog/working-on-the-hubspot-mobile-team", "abstract": "The Mobile Team at HubSpot is looking for engineers that want to help us rewrite the playbook on how mobile apps are made for B2B software.", "date": "2013-04-12"},
{"website": "Hubspot", "title": "Upgrading to Java 8 at Scale", "author": ["Jonathan Haber (He/Him)"], "link": "https://product.hubspot.com/blog/upgrading-to-java-8-at-scale", "abstract": "The vast majority of HubSpot's backend code is written in Java. We have over 350 separate Java deployables including Dropwizard APIs, Kafka consumers, Hadoop jobs, cron jobs, and more. So when we saw the features that Java 8 brings to the table (lambdas, streams, method references, CompletableFuture , and more ) we couldn't wait to upgrade and start using it. A lot of companies our size don't make these types of upgrades, it's too hard or too risky is usually the thinking. But as you fall further behind, it just becomes harder and riskier, and eventually you end up stuck with no upgrade path. This accumulation of technical debt slows down the entire development organization so keeping our stack current is a top priority at HubSpot. In our case, the upgrade took nearly 5 months to complete and it was full of hurdles, roadblocks, and other surprises. We kept notes on our migration strategy and all of the potholes we hit to hopefully make the process a little bit easier for the next brave souls. Step 1: Make JDK8 available everywhere The first step is to install JDK8 everywhere you run Java. This includes build servers, application servers, and developers' machines. At this point JDK8 isn't used for anything, but you want to make sure that it is available in all of these environments. Thankfully, we use puppet to manage our production servers and boxen to manage our development environment which make it easy to push out this type of change. We installed JDK8 and made the Java 8 executable available as java8 , which will come in handy later. Step 2: Start building with JDK8 The next step is to start building with JDK8. We use Maven to build which reads the JAVA_HOME environment variable. Building with JDK8 just involved updating our Java buildpack to set JAVA_HOME to /usr/java/jdk1.8.0_40 (or wherever you put JDK8 in the previous step). It's important to note that you're not building Java 8 class files at this point, and you can't start using Java 8 features. You're still compiling Java 7 class files - you're just using JDK8 to do it (we control the language level via the source/target properties on the maven-compiler-plugin). Step 3: Start running with JDK8 Next you want to start actually running Java applications with JDK8. At HubSpot our Java apps invoke a command called java-wrapper to start up instead of calling java directly. This is just a small shell script we wrote that adds a bunch of JVM settings (memory settings, GC settings, tmp dir, etc.) and then calls java . Since java-wrapper is managed by puppet, we can just change the script to invoke java8 instead of java . We rolled this out to our test environment first and let it run for a few weeks before changing production. We noticed that some of our apps were occasionally OOMing after this change. We're still in the process of tweaking memory and GC settings for Java 8, but decreasing the ratio of heap to off-heap memory has helped (probably because Java 8 moves a lot of data to MetaSpace which uses built-in memory). Step 4: Find incompatible dependencies So now you're ready to start compiling as Java 8 and writing lambdas, right? Not so fast! Now comes the hard part: making sure all of your dependencies are compatible with Java 8. We started by googling around to find incompatible dependencies ( guice java 8 , jersey java 8 , etc.). After sifting through a bunch of bug reports, the good news is that the incompatibilities all boiled down to a single library: ASM . The bad news is that ASM is used all over, making it very difficult to upgrade. ASM is a bytecode generation library; it lets you read, write, or modify Java class files at runtime. The latest version (5.0.3) works well with Java 8, but unfortunately older versions don't play well with some Java 8 bytecode. ASM is pretty low-level so libraries often use a more user-friendly wrapper, most commonly CGLIB . Unfortunately, the latest released version of CGLIB (3.1) still depends on ASM 4.2. However, they did merge our PR into master, so if you want a Java 8 compatible version of CGLIB you can build and run master for now. UPDATE: CGLIB 3.2.0 has been released! You will need to identify all of your dependencies that rely on ASM or CGLIB. To do this we wrote a script to build the Maven dependency tree for each of our projects and write it to a single file. It looked something like this: #!/bin/bash for d in $JENKINS_HOME/workspace/*/ ; do (cd $d; [ -f pom.xml ] && mvn -B dependency:tree -Dverbose=true -Dexcludes=com.hubspot -DoutputFile=/deptrees.txt -DappendOutput=true) done You can then grep this file to see where you have transitive dependencies on ASM or CGLIB. However, many libraries bundle and relocate ASM and CGLIB using JarJar or Maven shade plugin . You also need to find libraries in this category, but the previous strategy won't work because the bundled dependencies don't show up in the Maven dependency tree. Instead, we used a script that copied all of our dependencies into a single folder. It looked something like this: #!/bin/bash for d in $JENKINS_HOME/workspace/*/ ; do (cd $d; [ -f pom.xml ] && mvn -B dependency:copy-dependencies -Dmdep.prependGroupId=true -DoutputDirectory=/jars) done Once you have all of the JARs in a single folder, use the jar tf command to explode the JARs using a script like this: #!/bin/bash for j in /jars/*.jar ; do jar tf $j | grep -e .class$ | nl -s \"$j \" | cut -c7- done This prints the name of every class as well as the JAR file containing it. You can grep this output for ASM or CGLIB class files, which will reveal which libraries have bundled ASM and/or CGLIB. ClassVisitor.class is a pretty good search term for ASM, and Enhancer.class works well for CGLIB. If you copy the previous snippet into a file called explodejar.sh, the command to find JARs that bundle CGLIB would look like ./explodejar.sh | grep -E '/\\$?Enhancer.class' (the optional $ match is needed because some libraries, such as Guice, prepend a $ character to bundled class names). Step 5: Upgrade incompatible dependencies Now that you've found all of the dependencies that use ASM or CGLIB, you need to make sure they're using ASM 5.0.3 and CGLIB 3.2.0. The best way to accomplish this needs to be determined on a case-by-case basis for each library (this turned out to be the most time-consuming part of the Java 8 migration). Some libraries can simply be excluded completely. For example, some of our projects had dependencies on jruby 1.6.5 (which bundles ASM 3.3.1). Before trying to upgrade this dependency, we noticed that it was being brought in transitively by HBase. We knew that our HBase clients didn't use the jruby features, so it could safely be excluded, avoiding the need to upgrade it. Of course, many libraries need to be upgraded. One example is jersey-server , which in our case needed to be upgraded from 1.17.1 to 1.19. Given the number of Java projects we have, a big concern when upgrading libraries is backwards-compatibility. There are three types of compatibility: source, binary, and behavioral (covered in detail here ). Because many of our libraries were already compiled against jersey-server 1.17.1, source compatibility isn't strong enough. We need to ensure binary compatibility, otherwise we will get exceptions at runtime. There is an excellent tool for this called the Java API Compliance Checker . You give it the old and new JAR files and it tells you whether they're binary or source compatible. An invocation to test jersey-server compatibility might look something like this (ironically it won't run with JDK8 so we set the jdk-path to JDK7): perl japi-compliance-checker.pl -lib jersey-server -jdk-path $JAVA7_HOME -old jersey-server-1.17.1.jar -new jersey-server-1.19.jar When it finishes you will see some output like this: creating compatibility report ... result: COMPATIBLE total \"Binary\" compatibility problems: 0, warnings: 0 total \"Source\" compatibility problems: 0, warnings: 0 see detailed report: compat_reports/jersey-server/1.17.1_to_1.19/compat_report.html In this case the new version was fully binary-compatible with the previous version, but if it wasn't you could look at the compatibility report it generated to see exactly which methods and classes were removed or mangled between versions. This is an awesome tool for checking binary and source compatibility, but unfortunately it doesn't get you anywhere with behavioral compatibility. Some libraries make detailed release notes for each version which can be very helpful. And depending on how active the project is, it might also be feasible to go through the commits on GitHub since the previous version and check manually for any changes in behavior. Ultimately, however, it's very difficult to spot behavioral changes between versions ahead of time, so the best approach is usually to upgrade the dependency in some of your non-mission-critical services to test the waters before rolling it out everywhere. In some cases, the latest version of a library still depended on an old version of ASM. In this case, you could open an issue suggesting that the library upgrade its version of ASM to 5.0.3 for Java 8 compatibility (or even better, send a PR). For projects that fall in this category, our approach was to run our own fork until the library released a Java 8 compatible version, and then upgrade to that. Step 6: Compile your code as Java 8 Now you're ready to actually compile your code as Java 8. At HubSpot we have over 1,000 POM files, so managing dependency versions and build plugins can be a challenge. To help with this, all of our Maven projects extend from a shared HubSpot parent POM. This allows us to centralize dependency information using a dependencyManagement section, configure build plugins using pluginManagement , and add validation plugins to enforce best practices. To start compiling at a Java 8 language level, we updated the configuration of the maven-compiler-plugin to set source and target to 1.8. We also added the -parameters flag to turn on parameter name reflection . Then we crossed our fingers and rebuilt all of our Java projects. Because we put in so much work up front, this step went pretty smoothly. There were a few unit test failures due to the change in HashMap ordering in Java 8 (documented here ), but our tests shouldn't have been relying on HashMap ordering and were easily fixed. Once we got everything building successfully, we used the maven-enforcer-plugin to make sure dependencies incompatible with Java 8 didn't sneak back in to any of our projects by adding a configuration like this to our base POM. Step 7: Profit! Now that you're compiling as Java 8, it's time to enjoy all those new features! At HubSpot, we're taking full advantage of lambdas, streams, and method references to make our code more concise and readable. So far it's been great, the only pseudo-gotcha we hit was with the new Optional class. Previously we were using Guava's Optional , but started shifting to the built-in Java 8 version going forward. As we started doing this, we ran into cases where we had custom handling of Guava Optionals that needed to be ported to the Java 8 version. Specifically, we needed to add Optional handling to Jackson, jDBI, and Jersey to bring it to feature-parity with the custom handling of Guava's Optional. Other than that, it's been smooth sailing and clear skies. Did you hit a different roadblock upgrading to Java 8? Did it go smoothly? Let us know in the comments below.", "date": "2015-04-06"},
{"website": "Hubspot", "title": "How We're Hacking Email at HubSpot", "author": ["Jonathan Kim"], "link": "https://product.hubspot.com/blog/bid/82218/how-we-re-hacking-email-at-hubspot", "abstract": "This was first posted on Jonathan Kim's blog. If you find the topic of email tantalizingly enjoyable, you might like to read the first half of this two-part series: Quirks in Email Design . Isn't Email Old News? Email has been around for a while, so all the good tricks would have been found by now. False. There is still much hacking to be done in email, not just by providers, but also by consumers and third-party vendors. Here's a quick list of things we're doing to make email better at HubSpot: Programmatically changing email content Converting images to HTML (where appropriate) Cleaner, more elegant preview text Better environment detection (e.g. mobile vs. webmail) A better email boilerplate Let's get right down to business and take a look at the code. Programmatically Changing Content I'm not going to dive in deeply on this one since I already wrote about this technique in November. However, I've made a small update to it that make it more reliable. Here's the latest: Converting Images to HTML Sometimes, you just really really want to get around those pesky image blockers to entice people to see more. To do that—but mostly to see if it was possible—my coworker Keith Barrette wrote a little script that takes an image and converts it to email-safe HTML. That's right, we're talking tables. In fact, you can see an example of the outputted HTML, live in your browser, here: http://dl.dropbox.com/u/2977827/logo-html.html . This isn't for every case, and I definitely don't recommend it for use on large images. However, this experiment would be really useful on small images, like logos, which render with higher fidelity than larger, curvy images. This lets us keep a subtle reminder of the HubSpot brand in the email, even when images are blocked (which happens 52% of the time according to this Campaign Monitor blog post ). It's Keith's code, so I'll let him share it with the internet when he's ready. Elegant Preview Text One thing that's often overlooked is the preview text. Even Campaign Monitor (sorry folks) seems to overlook this in their own marketing emails. It's not a huge deal, especially if you have a long email subject, but it can sometimes make a noticeable difference. Besides, sweating little things like that are what make your emails memorable and polished. There are two main ways people will see your preview text: 1. As a desktop popup/notification (mostly desktop clients): 2. After the subject line (almost all clients): Don't get caught with \"Hi Jane,\" or a \"View This Email in Your Browser\" link as your preview text. Instead, you can simply insert a 1x1px image immediately after the body tag and assign it some alt text. The alt text will get picked up by email clients as the preview text, but it'll still be properly hidden. In order to play nicely with all clients, your pixel should look like this: If you're looking for bonus points, you can use that same image as your tracking pixel! Just fill the source attribute with a link to your data collection endpoint (we're doing this at HubSpot). Environment Detection Sometimes it's useful to do different things based on the environment you're working in. For instance, you'll probably want to have a mobile version of your email when it's being viewed on an iPhone, and this should be different from the printed version of your email, which should have it's own set of styles. It's also important to note that these environmental detectors can be used to trigger tracking pixels, so you can record actions, environments, device types, etc. Huge hat tip to the innovators at Litmus for inspiring me to go down this path. Those folks are doing so much email voodoo that it'll probably be years before anyone else catches up. Forwarded message: your content will be wrapped in a <blockquote> tag. Printed message: do a @media query for a print style sheet. Mobile: use @media queries. You can even use these to figure out the device's exact make and model. Non-Gmail: you'll probably never need this, but you can use the <style> block since Gmail doesn't support it. Microsoft: surprisingly, you can use conditional comments, much like you would in an HTML web page. A Better Email Boilerplate Much of the above has been rolled, in some fashion, into an improved email boilerplate here at HubSpot. It's still pretty new, but I'm hoping we can use this as a baseline for future emails we send to customers. It'll also be something we offer to customers who send email through HubSpot and use our in-house email templates. I don't yet feel comfortable about disclosing the code, but here's a summary of my favorite boilerplate features: Rock-solid wrapper. I've done 90% of the work necessary to make sure your email looks the same (and beautiful) across all email clients. Fixes for the iPhone. This makes sure fonts, phone numbers, addresses, etc, are rendered nicely. A \"remove from mobile\" CSS class. If there's something you think will clutter the mobile version of your email, just assign class=\"hide\" to it, and poof! Drop-shadows and rounded corners. This will intelligently fall back to loading images when CSS 3 isn't available. Litmus-style tracking pixel (for internal use). We use this to track opens, forwards and prints. We also do our own click-tracking in-house. Preview text (rolled into our tracking pixel). Some features that I'm looking forward to adding eventually: More specific fixes for the different email clients. Better hover- and click-state support. More CSS 3 effects and smarter fallbacks. I've been diving pretty deeply into making amazing emails at HubSpot, and I plan to upload some screenshots next week of what those emails look like. I think they're some of the best summary emails being sent by any SaaS company today (I've been keeping count). If you have any awesome ones, please share!", "date": "2012-02-10"},
{"website": "Hubspot", "title": "Avoid Design Debt with Design Review and QA", "author": ["Kizi Arezi (She/Her)"], "link": "https://product.hubspot.com/blog/avoid-design-debt-with-better-design-qa", "abstract": "Consistency and quality are central to a good user experience. But despite your — or your product team’s — best intentions, inconsistencies and unintended consequences will inevitably crop up. And if you're not careful, you'll end up with a poor user experience and a lot of design debt. We all know it takes a lot longer to dig yourself out of debt than it does to avoid it in the first place, so we try to avoid design debt from the start by explicitly including design review and design QA in our process. Design Debt affects the integrity of the user experience. This is what happens when a bunch of incremental changes collect over time and yield a disjointed, inconsistent, and patched-together experience. — Austin Knight, Design Debt By incorporating design review and QA into our process, we’re able to check and recheck that we’re staying on track and delivering on the original intent of the experience. But what do we mean by those different terms? Design review is what we do at regular intervals during the design process. Design QA is the final, more rigorous check. We approach the whole process as a team sport. Everyone’s role — research, design, content, engineering — affects the customer experience. So we run design review and QA on individual issues on GitHub, so everyone can participate in the conversation in a centralized place. This is also a great practice for distributed teams, since the conversation can be asynchronous, and anyone can join in, get caught up, and explore the full context on their own time. Design Process Guidelines The process that leads up to the final design QA step is as important as the last stage itself. Because if you’re collaborative and communicative throughout the whole process, the final QA piece can be a relative breeze. Here are the guidelines we try to follow throughout the whole design and development process. Design is a conversation Good design is a conversation, not a series of episodes of individual work. Just as it's best for designers to show their ideas to engineers early in review meetings, it's better for engineers to show designers their work early, too. We encourage engineers to share their work with their designer in GitHub long before it’s ready to ship. If there are inconsistencies between design and what has been coded , the designer can easily chat with the engineer to explore how to address it. Design is a process, not an event Each development process involves several touchpoints during which a design can be evaluated for adherence to intent and consistency with Canvas, the HubSpot Design System. Each of these touchpoints offers a chance for the engineer and designer to check in with each other and make sure everything’s going according to plan. So before anything gets passed into the next stage of the process — whether it’s just a review or into production — a designer gets called in to take a look at what’s there. This responsibility goes both ways, of course. Engineers are asked to take that moment to get a designer to review something, so designers need to make themselves available when called. Nobody’s expected to drop everything, of course. But a response within a reasonable amount of time is necessary to keep things moving, and to maintain a tightly knit collaboration on a small, fast-moving team. A shared definition of what quality means Usually a team will define their quality acceptance criteria together, before anything gets built. Then, when specifications for the design are provided to the engineer, everyone has the same expectations for how precisely it will translate into reality. It is the whole team’s responsibility to ensure that the software is rendered as the designer intended, which is why ongoing communication and collaboration are so important. Design Review So what happens at those various touch points along the way when a team gets together for a review? Basically, it’s a short presentation and feedback session of potential design issues at various levels of fidelity. And the meeting should be with a diverse group of role representatives, so that different priorities have their own voice in the room. User desirability ‐ Usually represented by a designer Business viability ‐ Usually represented by a product manager Technical feasibility ‐ Usually represented by a tech lead or senior engineer The review session is where all those important but sometimes conflicting needs are aligned and any potential tradeoffs are discussed. The objective is to ensure that everybody comes to a high level of agreement that the design solution meets the business requirements, is technically feasible, and accurately reflects the needs of the user. A design review isn’t a backlog or catch-up meeting. Not everyone on the team should attend. But it is important to make sure the three viewpoints above are all in the same room. Elements of a Good Design Review A lot has been written over the years about how to run a good design review. We don’t set out to reinvent the design review wheel, but we’ve found that adhering to the following guidelines help us make sure our design reviews are conducted, attended, and effective. The designer organizes the design review, making sure all the right people can come. Reviews are fixed events on the calendar, which tends to make it easier for everyone to attend. Design review meetings require three (or more) participants. It's not just for the product manager and designer to go over things alone. The technical input is fundamental. The first review should happen early, often at the stage when there are only sketches and user flows to review. Finished designs are also be discussed at later stages. The designer takes notes and records the findings from the review. Feedback from the design review should be incorporated into the design before the next design review meeting. Design QA Checklist While it may be challenging to address 100% of inconsistencies all of the time, doing Design QA is a big step towards combating design debt. — Jess Eddy Here’s a sample checklist of what we’ll look for whenever we need to review a design: Does this match the HubSpot Canvas guidelines? Check especially the colors, spacing, text styles, and content Interactions and behaviors Have we accounted for any edge cases? How are we handling any error states? Is this ready for localization and translation? Are all the language strings externalized? Is currency treated in a way that will translate? Are there any images or illustrations with text within them? Are any strings broken up by UI elements that will present difficulty when translated? How does a desktop feature render on a smaller screen? On a tablet? How will this work in different browsers? If this is designed for mobile, does it work on a small phone as well as on a larger phone? Is this design accessible? Are the color contrasts good for those with colorblindness? What about other forms of visual impairment? Is the text at a 7-9 grade reading level? Does it work when a screen reader is used? The Final Design QA Process Once the conversation of the design process has taken its course, and the team agrees that it’s time to see if a thing is ready to ship, it’s time for the final Design QA piece. Your process may vary depending on the tools that you use. The important thing is to establish a clear, step-by-step process that you follow each time. The engineer determines that the issue they’re working on is ready for Design QA. They create a staging build and move the GitHub issue to the Design QA board on the ZenHub workflow. The designer gets a notification from GitHub that the issue has been moved to the Design QA board and it’s been assigned to them. The designer goes through the design QA checklist above once more. If there are no bugs, the issue passes design QA and is moved to production. If there are bugs, the designer logs those bugs and assigns them a severity. If the issue is returned to the engineer, the issue remains in Development. If the issue is not returned to the engineer, the issue is moved to QA and the bugs raised by the designer go into a parallel \"bug triage process\" for later consideration. The Issue is now on QA and follows the overall QA process. The engineer adds a gif or recording screenshot so that the designer can check what’s being built. The designer gets a notification via GitHub that the issue is in production. The designer performs the final design QA on the live website or platform. By following a shared process of regular review and QA, we’re able to make sure that our designs are delivering on our original intent. Not only does this allow us to deliver a great result to our users, it keeps our teams working happily and healthily together, and helps keep us from digging ourselves into a hole of design debt.", "date": "2019-10-29"},
{"website": "Hubspot", "title": "HTML5 Resource Performance", "author": ["Zack Bloom"], "link": "https://product.hubspot.com/blog/webkit-resource-performance", "abstract": "There is a little known portion of the HTML5 performance API which has made it into Chrome: performance.getEntries() It returns performance information for every resource and request the page has made: Use it to include performance information in your error reports, or log it to your server to better understand what your users are experiencing.  You can do that logging with Google Analytics, or stay tuned, HubSpot will be releasing our own open-source metrics collection tool in the next few days.", "date": "2013-10-03"},
{"website": "Hubspot", "title": "Josh Levinson is a HubSpotter", "author": ["Elizabeth Dunn (She/Her)"], "link": "https://product.hubspot.com/blog/bid/86785/josh-levinson-is-a-hubspotter", "abstract": "Name: Josh Levinson Role: Developer at HubSpot Superpower: Flight Josh Levinson has joined HubSpot as a developer on the applications team, so he'll be working on our suite of product emails as well as a host of new features to support the growing HubSpot community. Josh came to us from Raybeam, Inc., a small software engineering consulting company, where he spent time working on web application development for Google, Facebook, Expedia, and One Kings Lane. Josh's superpower is no joke -- dude flies planes. He also plays the piano. He does not, as far as we are aware, do both at the same time. Although we're sure he could if he wanted to.", "date": "2012-05-16"},
{"website": "Hubspot", "title": "A Product Manager’s Secret Sauce", "author": ["Christine Yoon (She/Her)"], "link": "https://product.hubspot.com/blog/product-managers-secret-sauce", "abstract": "Hint: I'm trying to make it not so secret. As product managers, we’re constantly communicating. Furthermore, we’re communicating to drive action. Whether that action is getting your team on board with a new vision, getting stakeholder buy-in for a shift in product strategy, or finally getting around to writing that Medium post that’s been in your head, it takes a lot of brainpower. When your job is to “influence without authority” it can be emotionally and intellectually exhausting thinking about what you’re going to say, and how to say it, especially when there is a lot on the line professionally and personally. via GIPHY Who’s ever felt this way? 🙋🏻‍♀️ I decided to write this post after doing a lot of self-reflection on the type of communicator that I want to be as a product manager. I’m getting clear on how to tell my stories to influence my audience. This post comes in the form of a journal entry to myself to serve as a reminder of what my core values are; something that I can revisit when I feel the need for grounding, or whenever I’m feeling overwhelmed. I hope this inspires you to do the same (especially if you’re a BIPOC queer woman in tech). I know for a fact that there are other product managers out there who share the same sentiment and motivations that I do, so I wanted to share some of my thoughts with the product community. There are a few foundational themes in the “do” and “don’t” categories that I want to reflect on that I feel passionate about, not just within the scope of product management, but also in terms of how I’d like to live my life. I feel brave and excited to share these thoughts with you. I hope some of these themes resonate and you can weave them into your work! (Spoiler alert: these themes all tie into one another.) Perfectionism (don’t think perfection is attainable) This is one of the biggest hurdles to navigating through our professional and personal spheres. It can literally lead to a “freeze” response, suppressing feelings of creativity, innovation, and self-assurance. Centering perfectionism in our daily work prevents us from putting ourselves out there to speak on our gut or weigh in with an unpopular opinion. It stops us from pushing the “send” button for fear of being wrong, looking uncollaborative, or whatever story we're are telling ourselves. Don’t let perfectionism hold you back from getting feedback and input to strengthen your story. Saying something is better than saying nothing at all. Just do it. Vulnerability (do be vulnerable) The definition of vulnerability that Brené Brown gives is “uncertainty, risk, and emotional exposure.\" She adds, \"vulnerability is not weakness; it’s our most accurate measure of courage…” Being a product manager requires vulnerability . We are constantly putting our thoughts, stories, visions, “out there” and are constantly faced with the uncertainty of how people will react and receive our message. But we have to have faith in the fact that vulnerability = bravery. And acts of bravery strengthen trust and relationships, and will help us grow beyond our greatest imaginations . We need more vulnerable product managers out there, and it is a true measure of leadership to make decisions even in uncertain climates. “Vulnerability is the birthplace of innovation, creativity, and change.” - Brené Brown Authenticity (do show your whole self) For over a year now, I’ve been grappling with the question “what is authenticity?” Based on a few google searches, you’ll find something along the lines of: Knowing yourself Being compassionate with yourself and with others Looking inward, and being comfortable to show who you really are To me, in its simplest form, authenticity is not wearing a “mask” or “armor.\" It’s being brave enough to show your work self as your home self . You’re probably thinking “what if they don’t like home me?” or “I don’t sound smart.” Practicing authenticity is risky, it’s exposing, and it’s vulnerable. But this will truly invite others into who you are and the story you are telling, and will make your story and influence much more compelling. One principle that I’m especially passionate about is skipping the business jargon and ditching acronyms. Using them creates an unnecessary mental load for your audience and makes it more difficult for them to be receptive to what you're trying to say. I truly believe that these themes are foundational to working and living wholeheartedly. Spending precious brainpower trying to attain external validation or praise can slowly and silently get in the way of the creativity and risk-taking that product managers dream of. The most important thing I want to leave behind is that if we’re able to ditch perfectionism, be vulnerable and authentic, the dividends of praise and career growth will organically follow. Just remember that it’s the long game, so the more you can practice, the easier and more natural these guideposts will feel in your day-to-day work as a PM. Thanks for reading, and stay saucy. This post originally appeared on Medium . Want to work with a team that cares about training the next great product managers? Check out our open positions and apply .", "date": "2021-01-07"},
{"website": "Hubspot", "title": "On Killing It by Killing Features", "author": ["Daria Marmer"], "link": "https://product.hubspot.com/blog/on-killing-it-by-killing-features", "abstract": "There’s a lot less written about killing features than about building them. That’s because building features is fun. It’s easy. It’s exciting. You get to go out into the world and say, “Behold! Here’s the feature that will solve all your problems, forever.” And if there’s one thing customers love, it’s having all their problems solved, forever. But killing features is seldom exciting, easy, or fun. It’s something, like exercise, that we know we need to do to prevent feature bloat - but often, it's easier to put it off. Maybe it’s because it doesn’t seem like a priority compared to all the new things that need to be built. Or maybe it’s because there’s a risk that removing the feature could backfire and frustrate customers. Often it’s both. And that means that deprecating features is not something many of us have a lot of practice with. At HubSpot, we’re no experts at this - it’s a muscle that we, too, have been learning to exercise. But even if saying goodbye to features will never be exciting or fun, here are some tips to at least make the process a little bit easier. 1. Make the decision These are four helpful questions to ask when thinking about whether a feature should be deprecated. The easier it is to answer these questions, the easier it will be to decide on a course of action. How many people are using the product? It’s easy to make the decision to deprecate a feature that no one uses. For example, in the case of Spotify’s in-app messaging feature , the low usage coupled with the multitude of popular messaging apps that integrated with Spotify made retiring the feature an easy choice. But what if the feature is used by lots of people, but shallowly? Or by only a few people, but it’s a major part of their workflow? Both of these situations pose their own challenges, and merit their own plans of attack. Who are these users? If the feature's users are in a company's target market, or if they’re paying a lot of money, deprecating it might not always be the best decision. But if the functionality in question doesn’t serve the people you’re building for, it’s probably a good candidate for the guillotine. What does it cost to support it? If costs of keeping a feature afloat are minimal, there might not be a pressing reason to remove it. But the costs of keeping seldom-used software running, like server costs and the salaries of the folks who need to occasionally help customers use it or fix bugs, quickly add up. Those costs should be kept in mind when balancing the trade-offs. Can we fix it or make it better? Sometimes, giving a feature the axe isn’t always the right move, especially if there are ways to increase usage and adoption, or if it's worth fixing the underlying tech. Look at the data and do some research. If those indicate that taking the time to make the feature a bit more useful, usable, or desirable will pay off (and there are resources to do so), investing in the feature might be better than removing it. It's often difficult to figure out the right time to remove a piece of functionality from your product. Keep in mind, however, that there’s usually opportunity cost for not killing a feature that's dragging a product down, because product debt can quickly turn into a quagmire that slows down the team and increases the complexity of the codebase. HubSpot's VP of Marketing Products, Nicholas Holland, has a useful framework for identifying and prioritizing product debt below: 2. Get comfortable with the decision Okay, so the team has decided that killing a feature is the right thing to do. To keep the negative effects to a minimum, most solutions will fall into one of these two buckets: Give customers something better instead Help customers gradually wean themselves off The first option is the best (but of course, not always possible). When Microsoft launched Windows 10, it announced that its long-running and much-maligned web browser, Internet Explorer, would be discontinued. But this was actually good news for Windows users, who would be getting Microsoft’s new, much more modern web browser, Edge, as part of the update. And while there was certainly some resistance to change on the part of longtime Internet Explorers, there’s no arguing that getting a new tool for your trouble is a pretty sweet deal. Alternately, if a feature’s being deprecated because of tech debt or product bloat and there’s nothing better to offer, it’s sometimes easier to de-emphasize the feature before sending it to the gallows. One of the easiest ways to do this is to remove it altogether for new users, since they won’t know the difference. Similarly, it can be de-emphasized in the UI or the team can slowly remove little-used functionality over time. Weaning users off the tool will make the transition much easier. 3. Measure key metrics When we overhauled our social media tools, we had the old version and the new one running in parallel for several weeks. This let customers check out the new tools and start getting used to using them, but also allowed them to switch back to the old UI if, for example, they needed to send out a tweet immediately and were more comfortable doing it in a familiar interface. Of course, we didn’t want to keep the product in that state forever. So we measured our user opt-out rate, or the rate our users switched from the new interface back to the old one, week by week: We really wanted to get to a single digit opt-out rate before removing the option to switch back to the old version. Why single digits? Because it made sure that we’d addressed most of the concerns our users had with the new interface. It also meant that most users were comfortable using the new tools before we took the option to use the old ones away. There might be a different key metric that helps determine when the right time is to pull the plug. Maybe it’s page views or the number of clicks on a certain button - only your team will know the right number to track. But exploring data will provide a huge amount of insight into the right time to take action. 4. Over-communicate the change One of my biggest learning moments as a PM was when the cross-functional team I was leading at a previous company decided to deprecate a piece of functionality that was old, hardly used, and had a similar purpose as another part of the product. It seemed like a slam dunk. As it turned out, there was a company that relied on this data and they had no idea that this feature would be going away until it was too late. They were unhappy and ended up taking us to the court of public opinion. We just weren’t as well prepared to communicate the change as we should have been and three days after we took the feature away we had to press the big “undo” button. Lesson (painfully) learned. Of course, a good communication strategy will be based on the size of the change being made. It’s not necessary to tell everyone in the world about the deprecation, but all of the key constituents need to know. This can include internal employees, like other development teams, support and account management teams, sales, marketing, PR, and finance. It can also include external stakeholders like agencies, integration partners, and of course, users. Keeping the lines of communication open can increase how long it takes to get to the finish line, but it’s truly critical. Front line support and services have to bear the brunt of angry customers. Internal development teams and external integration partners might need to change their APIs to keep things running smoothly. Sales and marketing might need to know that this feature no longer exists in case they have to change their positioning. The product manager needs to make sure that everyone is armed with the facts. Knowing the timing and the reasoning behind the change will go a long way towards building trust with those stakeholders and helping the change run more smoothly. And it goes without saying that it’s absolutely crucial to communicate changes to the users who will be affected by it. Rdio, a music streaming service that shut down in 2015, did a good job of this, letting users export their library and playlists so they could later import them into other music services: Killing features will almost never be easy. Users will almost always feel some pain when the product they've gotten used to changes under their feet - but if a feature needs to go, it needs to go. With data, some considered thought about the user experience, and a solid communication plan, it’s entirely possible to minimize that pain. So be brave. Cut away the cruft. You’ll be killing it in no time.", "date": "2017-10-24"},
{"website": "Hubspot", "title": "My Best Moment at Work, Lately", "author": ["Dan Milstein"], "link": "https://product.hubspot.com/blog/bid/26090/my-best-moment-at-work-lately", "abstract": "Working on our spiffy new Analytics app (soon to be released to customers), ran into a severe bottleneck getting our summarized data out of Hadoop and into MySQL (which we use to hold, essentially, a bunch of precomputed reports). More or less immediately jumped into my usual approach to this kind of problem: Google + reading various tech blogs.  And this is something I feel quite proud of: give me a random tech problem, and I can figure out some decent approaches pretty quickly.  But, then, somehow, I caught myself, and, instead, I wrote an email to the HubSpot devteam, basically saying \"This is something I don't know much about, anyone have any idea how to help out?\" Cue to the next morning, as I sat down with Drew Hite and Alex Alexander, and got an incredibly helpful walkthrough of my.cnf.  A few config changes, and a MySQL restart, and the bottleneck was good and totally gone. I think this may have been my best moment at work, lately, as the title above says.  It's somehow so easy to just try to solve problems on your own (and to measure your own sense of self-worth by how good you are at such solitary work).  But, finding the right moment to ask for help is about the best possible thing you can do, sometimes. I love, love, love what Kent Beck says: \"I'm not a great programmer, I'm a pretty good programmer with great habits.\"  This all felt like I took a step towards the great habit of asking for help when I need it.", "date": "2009-09-28"},
{"website": "Hubspot", "title": "HubSpot Partner Spotlight: Ryan Burkett and Alex Moore, Senior Partners at Stratagon", "author": ["Francesca McCaffrey (She/Her)"], "link": "https://product.hubspot.com/blog/hubspot-partner-spotlight-ryan-burkett-and-alex-moore-stratagon", "abstract": "Some of the best perspectives on HubSpot's product come from those who use it every day. In this new interview series, we profile HubSpot partners and customers, and ask their thoughts on what our product team should keep in mind while solving for them, and where the future of the industry lies. In this installment, we chat with Stratagon's Ryan Burkett (left) and Alex Moore. You're both senior partners at Stratagon , an integrated marketing firm based out of Charlotte and High Point, NC. What's the most interesting challenge you're working on right now? Finding a balance between a systematic approach to service delivery and providing custom solutions to meet individual client needs, all while not sacrificing the ability to scale. Further, in a knowledge capital service business, where the ability to deliver bespoke, right-sized solutions is a differentiator, the challenge of scaling becomes that much more intense. What keeps you a HubSpot partner? The HubSpot platform has continued to grow, itself, following the same model that drew us to the platform, that being an emphasis on people, process, and technology. a) The technology in platform, and its trajectory toward being a true full-service growth engine is real, b) the processes in place, including the service and training avenues for customers, are unique and effective, and c) the people at HubSpot are a key differentiator to its customers' success. In your opinion, what's the most important thing for HubSpot's product team to keep in mind when solving for customers today? As the platform continues to grow and expand on up-market opportunities and functionality to support those opportunities, do not lose focus on usability nor fail to make the investment in access to H/S resources that are able to provide assistance on both intermediate but also very complex challenges and questions. What's your favorite feature within the HubSpot product? Tough to respond... features that we discussed in choosing one included the overall automation engine, the feature set in the CRM, and even multivariate testing, but we landed on the integration suite as our favorite differentiator. Both the library of integrations available, and the ease of integration with platforms is a favorite for a martech professional. What's one prediction you have about the future of marketing? She who has the most data wins, but it's not just about having it. Being able to effectively gather, manage, and maximize the strategic use of first party data becomes critical in a future where third party data is under scrutiny and the channels and mechanisms for access and utilization of third party data will likely decrease in options and in usage. Want more profiles of tech industry leaders? Check out our Name Dropping series .", "date": "2020-12-04"},
{"website": "Hubspot", "title": "UMass Boston Web Application Challenge Starts Today!", "author": ["Timothy Downs"], "link": "https://product.hubspot.com/blog/bid/58605/umass-boston-web-application-challenge-starts-today", "abstract": "HubSpot is very excited to announce our second web application challenge. Starting today, UMass Boston students will be able to enter their Facebook/Flickr mash-ups to win awesome prizes, not to mention a shout out on HubSpot.tv! Our last contest featured students from Northeastern and they set the bar pretty high. But, I'm sure the UMass students are going to step up and wow us. Our parameters are purposely vague. A user should give the application permission to access their shared Facebook information and the app should use that information to show the user pictures they may find interesting. We want the pictures to be accurate, the interaction to be creative and for your app to fast and stable. Our last contest had profile picture mosaics, \"living\" grids, and some just flat out fast processing. For those unfortunate souls that can't enter to win an iPad, check back here in a few weeks to find out who won! More information about the contest is available here .", "date": "2011-01-24"},
{"website": "Hubspot", "title": "When to Build a Mobile App (or Not)", "author": ["Jonathan Chesney (He/Him)"], "link": "https://product.hubspot.com/blog/when-to-build-a-mobile-app", "abstract": "In this post we look at why HubSpot built a mobile app, but these are lessons that could be applied to anybody considering building an app ⁠— particularly in the SaaS or B2B space. In truth, there are many reasons to build an app — from market expectation (do you know any banks that don’t have a mobile app these days?) to a paradigm-shifting behavioral change (I’ll never print a boarding pass again) but first, we’ll look at the number one (wrong) answer people give for building an app... The #1 wrong answer: We want to make more money When I previously worked in an app development agency, we spent almost as much time telling people not to build an app as we did encouraging others to invest in the space. Why? When we asked potential clients what their goal was for the app, many simply said, we want to MAKE MORE MONEY. If this is your sole motivation, the odds are not in your favor. Gartner , rather infamously, predicted that less than 0.01% of apps would be considered a financial success by their developers. Instead, your first worry should be, will anyone actually use your app? Data from Statista shows that 25% of mobile apps were only accessed once after being downloaded. Sensor Tower estimates that there were 115 billion downloads in 2019, marking a 9% year-over-year increase. Users have countless choices, competition is intense, and finding your audience has never been tougher. App analytics firm Adjust estimates that 83% of apps do not appear in the Top 300 lists for the 23 app store genres, essentially making them undiscoverable from an organic search perspective. These apps simply exist in the app stores but have almost no signs of life... they are the walking dead. Fortunately, for any established B2B company making their first move into the mobile space, they likely have an established user base. In HubSpot, three out of four of our Mobile Weekly Active Users (WAUs) are also WAUs of our desktop product. But while we offer free sign-up via our mobile app, making money through subscriptions has never been the goal, so why do HubSpot have a mobile app? Create value before you extract value At HubSpot, we believe you should look to create value before you extract value. This is something that our CEO, Brian Halligan, talks about a lot , and it’s the foundation of our mobile app. Overall, almost half of our app users are on free HubSpot accounts. When we look at this in closer detail, 45% of mobile users work for a startup business (one with less than 10 employees) and of these startups, 70% are using HubSpot for free. Our internal research shows that it is these startup businesses who have employees that are carrying out multiple roles (a bit of sales, a bit of marketing etc.) and it doesn’t take any research to know that when starting a new company, every penny counts. That’s why our app provides a 100% free CRM and delivers the free tools users need to build up their contacts and deals. We’re unique in offering a free Business Card Scanner — no limits, no gotchas, along with other key sales tools like Caller ID and HubSpot Keyboard . Our app's core focus is to create value for our users. To be clear, HubSpot has also benefited from having a mobile app. Whether it be in software, sales, or life, the best relationships are ones where the benefits go both ways. Our data shows that users of HubSpot’s Sales Hub who are also active on Mobile have a higher revenue retention. In addition, our monthly recurring revenue per sign-up almost doubles when a Sales Hub account also uses the mobile app. In short we’ve found that what’s good for our users is invariably good for HubSpot . Mobile drives delight We’ve also discovered that Sales Reps who use the mobile app (relative to those who only access HubSpot on a computer) are more likely to recommend HubSpot to a friend or colleague. We collected this data through a Net Promoter Score (NPS) survey, which is a strong indicator of loyalty and growth . The results of this survey also showed that the more you use the HubSpot mobile app, the higher your overall NPS rating for HubSpot is. The idea of mobile being a driver of loyalty is somewhat supported by a paper from Zogby Analytics which showed 30% of consumers would consider leaving a brand solely due to a poor app experience. As of January 2021, we have an Apple App Store rating of 4.6 and a Google Play Store rating of 4.6. We really do care about delighting our users — we track this regularly to see how we’re doing and learn how we can do better. Customer happiness decreases the risk of cancellation (attrition) and increases the likelihood of upgrading (monetization) to some of the more powerful versions of HubSpot. Again we’ve found, what’s good for our users is invariably good for HubSpot . HubSpot using HubSpot It is common for software companies to eat their own dog food (otherwise known as dogfooding ). In other words, a company using its own product. At HubSpot, using our product is a key part of doing business. Our Sales Reps, Marketers, and Service Reps use HubSpot every day. For our mobile app, we’ve discovered an additional benefit: our app helps HubSpot sell HubSpot. We analyzed six months’ worth of sales data and found that HubSpot Sales Reps who use our mobile app MAKE MORE MONEY. 28% of our own Sales Reps use the app several times a week and those reps have a sales attainment rate that is 12% higher than those who never use the app. This connection between usage and attainment holds true for those that are Low, Medium, and High users of the app. In this case, what’s good for HubSpot is good for our users and what’s good for our users is good for HubSpot . We’ve shown mobile can be a driver in setting up you and your company for happiness and success. This is why HubSpot built a mobile app , and we believe we’re just getting started in this exciting space — there’s plenty more to come. You can download the HubSpot mobile app for free today by scanning the below QR Code or pressing on the App Store or Play Store badges. Want to work on a team tackling cutting-edge mobile challenges? Check out our open positions and apply .", "date": "2021-01-15"},
{"website": "Hubspot", "title": "5 Reasons Your Product Doesn't Look Like the Mockup", "author": ["Christopher O'Donnell"], "link": "https://product.hubspot.com/blog/5-reasons-your-product-doesnt-look-like-the-mockup", "abstract": "One of the most common frustrations in software product development is the disconnect between what a designer envisions and what a development team delivers. As a product manager, I am certainly not alone in my experience of repeatedly trying to untangle why the product that our team shipped deviated so much from the original concepts we saw come from the designer(s) on a project. Sometimes a mockup can be a very high-level suggestion or illustration of the basic data elements and intended user stories. In other team workflows the design is meant to be implemented literally, perhaps even down to the pixel. From what I understand from conversations with Kayak founder, original CEO and product visionary Paul English, he would work with designers to create exactly what the product should look like and do, and deviation from that was viewed as incomplete work. But for most of us, things won't always turn out pixel perfect so understanding what happens between design and production is important. Over the years I have dived deep on various occasions when this has happened, and come up with a handful of common and very different reasons for this disconnect to arise. Here we will discuss each reason, as well as strategies for addressing the different scenarios, should they arise in your work. 1. The Idea Itself Changed While working on a feature lots of things can change. In the best case scenario you'll have the designer embedded with the developers and a close relationship between these folks drives collaboration which leads to a terrific result. That means that throughout the process the designer might iterate and create more mockups and/or the designer and developer might work on the feature together in real time, leading to a productive and healthy deviation from the original idea. Along these lines the development team may learn from user testing that the design has some deficiencies or stumbling points and as a result iterate on the original idea to improve it based on these learnings. What To Do: Changing the idea as you go is healthy as long as the designer is involved every step of the way so the y're not surprised when they see the final product. That's why it's important to be clear on what is changing and why the team decided to pivot. Your team should be documenting what they learn and sharing their rationale along the way so that everyone is on the same page when it comes time to ship the final product. 2. Real Data Changed the Story The tendency for designers to mockup screens and features using data they make up as they go is overwhelmingly common. The danger here is very real: the real (production) data can present a host of unforeseen challenges. These challenges range from the severe to the more mundane. Perhaps the mockup turned out to be actually impossible or highly impractical to implement; for instance it is not uncommon these days that there are search or sort features that the datastore is not prepared to deliver. Less severe but still a speed bump would be text content being longer or shorter than the designer had expected. An example that has stuck with me, having been a product manager for many versions of the timeless \"contact detail page,\" is the reality that the data a CRM system has for a given contact is often disparate (data for some fields and not others) and various (countless possible fields). When these screens were initially designed it was easy to assume that each contact would have a small number of key/value pairs populated, but we quickly realized this wasn't the case. We handled that at HubSpot by a) allowing \"favorite\" properties so each user can easily see the data they care about (common for sales reps) and hide the other data and b) show all the fields on a separate screen intended for the debugging/integrating/etc use cases (common for marketers or Ops folks). What To Do: Design with production data! It takes more time and effort, but it is well worth it. It's also a great excuse to keep the design folks close to the engineers early in the process. 3. The Details Didn't Seem Important Details, details, details. Not everyone is a detail-oriented person; some people write the essay before completely reading the question while others digest the question and make an outline before diving in. Not surprisingly, the way these two types of people approach projects, vision, and ownership varies. As a result, disconnects can arise when work crosses from one discipline to another, carrying the expectation that details of all sizes will be recognized, respected, and implemented. It's not hard to believe that developers who are deep in the details of \"left-brain\" work may approach the visual implementation with a drastically different attitude than those who created the mockups or prototypes. In these cases it's imperative for the designer to have a close relationship with any of the engineers implementing the designs, and to feel comfortable underlining that, yes, in fact 20px of padding versus 2px of padding is a universe of difference. What To Do: Next time a detail is overlooked, use it as an opportunity to set a tone for why the team should get in the habit of paying closer attention. Log those moments as bugs and clarify in the ticket why details matter. The team will quickly get the message and start switching gears. 4. Opinions Differed No developer is quite like the other. Some have stronger opinions about design and different ideas on what the \"right\" approach is. At HubSpot we have team members who focus entirely on design engineering, for example, and these folks are understandably much more vocal about the user experience and look and feel of the product than, say, back end engineers. But at the end of the day, everyone involved in the process brings their opinions to the table; the problem arises when they aren't discussed, explored, and put out on the table. There's a good chance that the last person to touch a product before it ships will not see eye-to-eye with the original concept and that's when the outcome switches gears. What To Do: It's crucial to communicate who the owner is early and often. The rubber has to meet the road somewhere and ultimately there needs to be clear ownership over the user experience. Whoever owns these final decisions in your culture, be it designer, PM, or someone else (if it's not the designer though, then ... why? just, why?), that person needs to casually reinforce the ownership model. Saying things like \"there are clearly several approaches here and though it might not be perfect I'm going to decide that we do the following...\" makes it clear who's calling the shots. 5. Skills Were Missing Let's face it: every developer has a different skillset and not everyone is a master of CSS and HTML. Even those with fairly extensive knowledge of front-end technologies might need to stretch to implement a mockup to the pixel. One senior front-end tech lead on the HubSpot team once spent two hours implementing a gradient because a designer insisted it was important. It was a tricky implementation that was new to that developer even though he's senior in his experience and talents. In some cases, those two hours might not be as easy to find and can shift the outcome of your product. What To Do: Work with engineering leads to ensure that front-end engineers have the tools and workflow knowledge to implement designs accurately. Guarantee that skills like determining what color type is being used and measuring padding and margins in the mockup are common knowledge across your group. These five obstacles and solutions echo a common theme that will help keep your mockup and final outcome on the same page: tight alignment between product, design, and engineering is crucial. Collaboration across teams and talent is key to developing successful products so don't let miscommunication or other avoidable hurdles throw your team off track.", "date": "2015-02-03"},
{"website": "Hubspot", "title": "Evolution of a Web Developer: From PHP Newbie To Python Ninja", "author": ["Dharmesh Shah"], "link": "https://product.hubspot.com/blog/bid/85467/evolution-of-a-web-developer-from-php-newbie-to-python-ninja", "abstract": "Apologies for the title.  Here's what I wanted the title to be: Evolution of a Web Developer: From Newbie to Ninja Not-So-Newbie because I don't like using the term ninja (or rockstar or guru).  But, putting the striketrhough in an article title is ill-advised. Some of you may have come out of the womb hacking shell scripts to turn off that Internet-enabled baby video surveilliance monitor that your parents used to watch what you're doing on their iPad in the kitchen (visualize eTrade baby hacking away on a terminal app on his Android phone).  But, I suspect most of us started more modestly than that and moved up the learning curve (some faster than others).  The following is a somewhat fictional, somewhat true recollection. Favor request :  Please do not misguidedly think we have a bunch of newbies on the HubSpot dev team.  Quite the opposite.  Most of them did come out of the womb hacking shell scripts.  At the office, they speak some weird alien language that every now and then has words in it that make me suspect they're talking about software development.  But, a lot of the times, I think it's a diabolical plot to make me keep feeling like a rookie. In any case, on with the show.  Note that the time elapsed between steps varies dramatically.  I never had the talent for literal cadence (or whatever it is you call it when the time between things is consistent). Evolution of a Web Developer: From Newbie to Ninja Not-So-Newbie 1. I put the words print “Hello World” into a file called \"helloworld.php\" and I can make it show up in a browser.  Woo hoo! 2. Well, that was kind of lame. But, now I'm actually doing something dynamic and can include the current date and time. “Hello World on 2011-08-10 00:47:02.355000” 3. Learned how to pass parameters via the URL in the query string. It's kind of like the command-line argc, argv thing — but not. 4. Look ma, I can run database queries! 5. Using Javascript to actually run some code on the client-side. alert ('Hello World!”). 6. PHP is ugly.  Decide to use CodeIgniter to make it less so.  Considered Cake as well, but went with CodeIgniter mainly because I had friends that had used it.  Took me a couple of hours to get a handle on things. 7. Realized that my friends will forever make fun of me if I stay on PHP.  And, Ruby as a language feels a little strange.  Maybe it was designed for hipsters.  If I had a dog, it would bark at Ruby code. 8. Python and I experience a \"love at first sight\" moment (well, the love might have been unrequited at the time, but still).  The language is elegant and clean and all the things a language should be. 9. Went through all of “ Python The Hard Way ” just for fun. 10. The Django tutorial isn't too shabby. Only downside is that it made me want to just keep going with the polling app (I've always wanted to write my own polling software!)  I wonder how much influence development tutorials have on actual apps that get developed.  That could explain why there are so many custom blogging apps out there. 11. Writing CRUD queries from scratch is for the birds, learned about ORMs and database abstractions in Django. 12. Wait, what, Django's ORM doesn't support composite primary keys? That sucks! I'm just going to write my own database layer. 13. Reconsidering decision to write my own database layer. Maybe in the early days, it's OK to have auto-incrementing primary keys. I can always “fix it later”. 14. Discovered jQuery . Have no idea how humanity even existed before jQuery. 15. Used right-click, “Inspect Element” for the first time. FireBug forever changes my life. 16. Processing POST requests is almost as easy as GET requests. Only cooler and no length limitations. 17. Man, spammers suck. Need to go find a good CAPTCHA library. I think recaptcha is a pretty cool idea. 18. Heard that concatanating strings to form SQL queries is a bad idea. Looking up how to do bind parameters and escaping the strings.  I don't care which ORM you use, you're going to someday need to write direct SQL queries. 19. Session management makes stateless applications more statefully. 20. Database calls are slow. Memory access is fast. Memcached FTW! 21. AJAX makes web apps oh so much cooler. (Quietly blessing John Resig again for creating jQuery. Super happy that I didn't talk him out of his crazy idea when I met him years ago). 22. Considered using SQLAlchemy .  Seemed powerful, but all I really want is for Django's ORM to not suck, not do something completely different from the active record pattern. 23. Learned how to invoke other websites and applications from my own code.  This could get dangerously fun.  Or maybe, just dangerous. 24. Ah, the beautiful serendipitous wonderfulness that is Hacker News. Learned about the Python requests library . I will now judge all libraries based on this work of beauty. 25. Learned that everybody else's HTML sucks and is not XHTML compliant and won't parse worth a damn. 26. Learned that trying to process in-the-wild HTML with regex is close to pure sin. Figured out that Beautiful Soup is indeed, quite beautiful. (But not very soupy). 27. Wrote a note to self to learn how CSS is actually meant to be used. For the 5 th time. 28 Learn that my HTML sucks, is not XHTML compliant and won't parse woth a damn. 29. Spend half a day looking for libraries and frameworks that make CSS suck less. Decide none of them are “mainstream” enough yet. A little voice inside my head is telling me I'm missing out on something important. 30. Ooh. Came up with a clever way to use Javascript to insert dynamic hidden fields into my forms to stop the spammers without aggravating users with CAPTCHA. Later learn that this was not an original idea and had been done like, a million times before. 31. Read up on cookies. Then non-expiring cookies. Then cross-domain cookie issues. Then statistics on how many users turn off cookies in their browser. Then blog article about how Europe might make cookies illegal. Then just went and ate a chocolate chip cookie. Felt much better. 32. Learn there's actually a way to return things other than HTML from a web application. Not sure why I'd ever want to do that, but you never know. 33. Wait, wait, wait — you mean I can create a dynamic image from my code? <img> tags don't have to point to static JPG/PNG files on my web server? That's awesome!  I can build my own meme generator.  Woo hoo! 34. Wouldn't have believed it if I hadn't seen it myself, but SASS does make CSS syntacticaly awesome(er). 35. So, I have these objects in a simple two-level hierarchy.  And I have a relational database (MySQL) and Django has an Object Relational Mapper (ORM).  So, you'd think that the ORM helps you take the objects and map them to database tables in somewhat natural ways.  Au contraire mon frere! ({pardon my French).  It gets many of the basics wrong. 36. Consider doing A Very Bad Thing.  Simply taking data about my \"child\" objects and munging them into JSON and sticking them into a single database column  Avoids some of the issues with how Django handles things, but introduces other problems (like not being able to query on any of those object properties.  Plus, I have this feeling that a kitten is going to die somewhere if I do this. 37. Start reading up on MongoDB.  Seems simple enough.  Get it up and running in a few minutes.  Inserting and querying in a few more.  Now, I can have my objects stored as documents with the hierarchy loosely represented.  And, it's query-able.  I don't have anything against SQL (we go way back), but MongoDB feels like a more natural fit than trying to munge my simple objects into a relational database. 38. In my meanderings for ways to use MongoDB in cleaner, simpler ways, come across DictShield .  It's a wonderfully useful and simple library.  And @j2labs is a super-nice guy who gives near instantaneous support (including answering basic questions that have nothing to do with DictShield) 39. Learned the hard way that MongoDB 32-bit edition has a database size limit of 2GB .  Decided to stop being a cheapskate and spin up a 64-bit Amazon EC2 instance.  Besides, I'm not playing around any more.  The database is growing fast (it involves pulling down small parts of the interwebsociosphere. 40. Lamenting the fact that MongoDB doesn't have full text search (even MySQL had that).  Reading up on Elastic Search and just saw that Amazon now has some new hosted search service that looks pretty functional.  (Impressed how quickly those Amazon folks put new things out there – who knew that an online bookstore would rule the cloud computing world?) 41. Digging into the Python Natural Language Processing Toolkit .  Makes my head hurt.  Learning curve is a bit steep (or I'm a bit impatient).  All I need to do is some simple Bayesian classification.  (Famous last words).  Considered the new Google Prediction API, and though it has promise, is almost completely unusable for my simple use case (do some simple tweet classification). 42. Starting to read \" Natural Language Processing with Python \".  Don't grok all of it, but that's OK.  I can feel myself getting a wee bit smarter. Clearly, there's still a lot I have to learn – and I skipped a bunch of steps along the way.  So, where are you in the \"evolution\"?  Are you like at step #83 or something?  Any other major milestones you've hit along the way that you'd like to share?  I'll award the two funniest submissions a $50 Amazon gift certificate, so you can read whatever you need to read to get to the next step in your development. Please consider voting this up on my favorite news site if you enjoyed it.", "date": "2012-04-13"},
{"website": "Hubspot", "title": "1,000 releases in a month: working towards continuous deployment", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/64053/1-000-releases-in-a-month-working-towards-continuous-deployment", "abstract": "This is probably mostly of interest to HubSpotters themselves, but in April 2011, we hit a milestone: more than 1,000 releases of our software. We had 1,112 releases, to be precise, counting both our QA (or integration) environment and production.  That's 1,112 / 21 ~ 53 releases per working day of the month, on average. Obviously not every release is big nor does each one contain new functionality.  Many are bug fixes, small iterations on existing features, usability / UI improvements, and more.  And many of these just went to our QA environment, which customers don't see. But to do this many releases without impacting downtime (we were solidly at 99.99% uptime for the month, easily meeting our SLAs), feels good.  Having a \"kitchen sink\" team dedicated to deploy tools, scripts, monitoring, and the like, just makes everyone more productive and deploys safer. We're not at continuous deployment yet, but I hope to get there one day.", "date": "2011-05-13"},
{"website": "Hubspot", "title": "The Unix Toolbox: Awesome organized list of Unix commands by area of purpose", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/8966/the-unix-toolbox-awesome-organized-list-of-unix-commands-by-area-of-purpose", "abstract": "I often find myself looking for a Unix or Linux command in the shell, not quite sure which command I want, but knowing the rough area or purpose of what I'm trying to do.  For example, I know it has to do with listing or manipulating processes, or adjusting the way sudo works. I just stumbled upon a great list of Unix commands, the Unix Toolbox , which is organized  exactly for my scenario.  w00t! Bookmark it . Thanks for Francois Schiettecatte for the link.", "date": "2009-07-12"},
{"website": "Hubspot", "title": "STOP! Before You Add That Feature, Do You Know The Real Cost?", "author": ["Dharmesh Shah"], "link": "https://product.hubspot.com/blog/stop-before-you-add-that-feature-do-you-know-the-real-cost", "abstract": "You're excited! And, why wouldn't you be? This could be the one. This could be that feature that unlocks the holy grail of viral user acquisition. This could be the one that drives your cancellation rates down to microscopic levels. This could be the one that the tech press writes about. This could then cause random strangers to give you a small, congratulatory smile as they pass you on the street, acknowledging your brilliance. This could be that company-changing, life-changing feature. Or, it could not. There are many reasons you might consider adding a new feature to your product. Here are some of the most common ones: Reasons (and Rationalizations) To Add A New Feature 1) It Just Makes Sense. You're surprised that the product exists at all without this feature. You're not sure which idiot decided to leave it out of the MVP (oh, that might have been you). How could we have not had this from Day 1! It's obvious that our kind of product needs this feature. It's table-stakes. Lets add it immediately. 2) A big/important customer is asking for it. Based on how many customers you have, and how much this customer is paying you (or is promising to pay you), there's a strong push to just do it. You'll come up with many rationalizations: “Hey, if this customer wants it, likely others do too.” And, besides, it's not that hard. I think our dev team can crank it out in a weekend and we can still go out for drinks on Sunday night. And, we're supposed to be listening intently to customers, right? RIGHT? 3) A competitor just added it. So, your sales team starts banging on tables for the feature (or, you're the sales team). And, the feature is ludicrously trivial. They should be embarrassed for issuing a press release about it. And TechCrunch should be embarrassed for writing an article about it. Those dolts! So, you just go do it. Just so you can prove you can and how lame that competitor is for making a big deal out of it. 4) It will drive revenue! Your gut is telling you that more people will buy, more people will stay, or your existing customers will spend more money if you have this feature. There's a clear ROI path! We spend a weekend or two developing the feature, and if only [x] customers buy, we're golden. The feature practically pays for itself! Now, though I wrote all of those a bit tongue-in-cheek — the reality is that some of your reasons might be completely legitimate. Lets just pick the last one (we'll make more revenue), because it's the simplest to talk about. We're going to assume that your thesis is correct and that adding this feature adds more revenue. Let's stipulate that you are correct. The problem is being correct on the revenue side of the equation is not enough. What about the costs side of the equation? “Wait, wait,” you say “you silly nilly, this is the software business. Once we spend the money to build the feature, we're done. Software has high gross margins. This is MBA 101 stuff. Dharmesh, didn't you go to some high falutin' business school?” First off, nobody uses the phrase “silly nilly” anymore. Just sayin'. Oh and yes, I did go to a high falutin' business school (MIT Sloan) — don't hold that against me. There are some costs that you should consider as you add that new feature. Costs Of Adding That Awesome New Feature 1. Increase in setup time : It this new feature requires some configuration — or even some training to understand it, your costs go up. They go up because it takes longer to understand your product. They go up because your sales cycle might be impercetibly longer. They go up because customers have to spend more calories getting going (and trust me, eventually you pay the price for this). 2. Support costs : The feature might be a little complicated. Or, might not be as intuitive to your users as you think. Your support call-volume and e-mail volume go up. Last I checked, those things cost money. Real money. 3. Infrastructure costs : The feature is one of those that requires you to do a bunch of “pre-processing” to get the data ready for the user to consume (only a small fraction of whom will need it in any given time period). Example: A slow/expensive daily analytics report that you precompute/build from your Hadoop cluster so that users don't have to wait. Now, you have to consume resources to build this report for all customers (because you don't know which ones will login on any give day). This is just an example, but there are many different cases where features involve more data manipulation, indexing, retrieval of data from the web, etc. Side note on this kind of cost increase: You incur the cost for pretty much all of your customers, even though almost nobody uses it in the early days. Ideally, you should be looking for features where the costs to support it match the actual usage (i.e. you don't pay for non-usage). 4. Increased maintenance costs : As well as you might do to factor (and refactor) your code to ensure that features are decoupled from each other, so adding feeature [x] does not raise the complexity of feature [y], in practice, for any system of decent size, it's inevitable that you have some “leakage” in your abstractions. Some of these will be deliberate (you want to get code reuse, so you start interconnecting parts of the product together). Regardless, the fact is that every feature you add makes the overall system harder to maintain. Period. End of story. If you're really good, this cost might be nominal, but it's never zero. And, the most important, overlooked cost of all: 5. The Cost of Complexity : Startups are a constant battle against ever-increasing complexity. When you move to having multiple price options for your product, your complexity goes up. When you add an important feature/app, your complexity goes up. It's one more thing to track adoption of. It's one more thing you have to promote to your customers (so they know it's there). It's one more decision to make (should we include this feature in the free product, or use it to drive upgrades?). It's one more hungry mouth to feed when you're trying to allocate limited product/engineering resources. It's one more row in your pricing/feature matrix. Every one of those things cost money. They just may not show up on your P&L on day one. They're subtle and somewhat hidden, but they're very, very real. So, STOP! Before you just go add that feature because you know it's going to help you drive more adoption, revenue, etc. Spend a little bit of time thinking through what the actual costs for this feature will be over its lifetime. You don't have to analyze it to death, but it's deserving of some time spent that is proportional to how big the feature is. What do you think? Any other hidden costs that you've learned about in your experience building and delivering product? Would love to hear your thoughts in the comments.", "date": "2013-02-07"},
{"website": "Hubspot", "title": "Redesigning a Website to Attract Top Product Talent", "author": ["Hannah Fleishman (she/her)"], "link": "https://product.hubspot.com/blog/redesigning-a-website-to-attract-top-product-talent", "abstract": "A few months ago, we really started to think about how we can scale our product team long-term. Engineers, designers, and product managers are hard to hire, especially ones that will raise the average of an already world-class team. A big part of attracting that level of talent is being intentional about how we tell the story of product and engineering at HubSpot. Today, after redesigning our homepage and jobs pages , we launched a new and improved product.hubspot.com . Here’s how it happened and what the redesign is doing for our inbound recruiting framework. When Lesley , Margo , Chelsea , and I sat down for the first time to talk about the redesign, we quickly found glaring problems with our old site. The majority was hard-coded and difficult to navigate; it felt booby trapped for anyone that wasn’t a developer. Aside from being clunky, the old homepage failed to quickly answer one simple question: Who is the HubSpot product team? The subhead, “We build software to help businesses succeed”, suggested that we’re a product and engineering team, but it didn’t cover what HubSpot does or how our team is different from other development organizations. It didn’t make the case for why anyone should consider growing their career here. We relied on a video, front and center, to tell that story and answer visitors’ questions about what we do, how we work, and what our culture is like. Unfortunately, only 11.4% of visitors were actually clicking play, and even fewer were making it past the first 30 seconds (thank you, Wistia .) So, the homepage gave visitors the option to apply for a job or read our blog without any context on why they’d want to do either. It was a dead end. This brought us to the most important question of any homepage redesign: What did we want visitors to do when they got there? This problem, and the solutions we ultimately came up with for the homepage and jobs pages, was pivotal in pushing us to think deeper about inbound recruiting on the product team and how we could design a valuable experience for candidates and future candidates, and but also for visitors that will never become candidates. Balancing Recruiting and Inbound Marketing There’s a sweet spot where employment branding and the hiring process meet. They can happen independently but there’s a 1+1=3 effect when they talk to each other. That by-product is inbound recruiting. While the website hosts our jobs pages and is a recruiting tool, we don’t think of it purely as a careers site. It’s a platform for our product team to connect with the product world at large in a meaningful way. Visitors should learn something whether they want to work at HubSpot or are happy building products at a startup out in Colorado. We needed the homepage to reflect that mission, to balance candidate value with community value. There’s a synergy in solving for both. After dozens of mock ups, iterations, and HipChats, we built a solution. (Above: The old homepage on the left and the new one on the right. Below: Open source projects and blog posts featured on the new homepage.) The new homepage answers point blank “Who is the HubSpot product team?” and has a better user experience with featured content from our product blog and open source contributions . Both future candidates and visitors that will never enter our recruiting pipeline now have ways to engage on the site beyond submitting a resume. Getting that content front-and-center helps us create v alue for the product community and the candidate. There’s lots to iterate on, but ultimately, the old homepage pushed visitors away. The new homepage invites them to take a step further. And in some cases, that next step is going to be to learn more about our career opportunities. Featuring Job Listings that Solve for the Candidate A company’s jobs pages should reflect what it’s like to work there and make it easy to apply. In our case, that meant we didn’t just need to redesign our jobs page. We needed to rethink the entire flow and experience. The first step was finding other companies whose jobs pages we admire and dissecting them. What works? What doesn’t? What’s their tone? How do they highlight talent? How many steps do you have to take before you can submit an application? What should we try to emulate? One of the biggest discoveries, though, was what we didn’t want to emulate: a laundry list of open positions. On most sites, when you click ‘View All Jobs’, or a similar CTA, you’re presented with a scrolls-worth of specific titles like ‘Software Engineer- Design Tools’, ‘Software Engineer- Blog Tools’, ‘Software Engineer- Mobile’ etc. For those companies, this approach probably makes sense for how they hire and structure their teams. But it doesn’t really align with how we think about attracting and growing talent. A candidate’s potential is more important than how closely their resume mimics the work they’d be doing. We’d rather hire a less experienced engineer with an unrelenting passion to get better at their craft than a senior engineer who meets the minimum and doesn’t lose sleep over improving. For us, that cultural piece holds more weight than anything and we felt that specific job listings put more emphasis on the work than the talent, which could potentially alienate candidates. (We also heard feedback that this format can be stressful for job seekers; they aren’t sure which title is the best fit for them and are wary of submitting multiple applications.) So, we created one application (per location) for each division within the product organization: Software Engineer, Product Designer, UX Researcher, Product Manager, and Intern or Co-op. The job descriptions for each (specifically “We hire talented people at all seniority levels and work with them to shape their role”) are explicit about who should apply and how the generalized title actually solves for the candidate. Capturing What It’s Actually Like to Work Here Company culture is a competitive hiring advantage. Top talent wants to work for companies that share their values, have a strong mission, and are full of bright people they can learn from. The biggest problem with our old jobs page was that it didn’t reflect what any of that looks like at HubSpot. We needed our new jobs pages to capture what the HubSpot Culture Code (new hires often cite the deck as a big factor in deciding to join our team) does: that HubSpot has an unmatched environment for growing your career. Because culture is so paramount at HubSpot, we (and specifically our co-founder Dharmesh Shah who created the Culture Code) have done tons of thinking, both internally and externally, about it over the years. There are countless sound bites to describe our values, mission, and team. That’s why one of the hardest parts of redesigning the jobs pages was coming up with content. We didn’t want to leave anything out or miss an opportunity to share one more great thing about our culture and team. Distilling information was hard but ultimately we rallied around three key things that are central to how we build products: our mission of solving for the customer, our commitment to autonomy and speed, and our incredible team of makers. (Above: Old jobs page on the left and new jobs overview page on the right. Below: Engineering jobs page) We’ve found that the #1 thing that attracts amazing people is other amazing people. That’s why the new pages feature photos of employees, what a typical day looks like for them, quotes from them about the impact they’re making on customers, and blog posts they’ve published about their work. Now, candidates can actually picture themselves at HubSpot and get a real sense of our team’s personality, work ethic, and motivations. Looking Ahead at Scaling the Team and Site The site’s live and now it’s time to iterate. Like any product or project, there are tweaks, updates, and feedback we need to digest. And over time, as our team grows, our recruiting process is bound to change and require different solutions on the site. There could be an increased need for more specific title listings as our product offering expands. We will probably need a different solution for the ‘Apply’ CTAs if we start hiring for product in more offices globally beyond Cambridge and Dublin. We’re already rethinking the ‘Apply Now’ CTA on the jobs overview page to create a more intuitive path for visitors to choose which product vertical they fall under. From the very beginning, the goal of this redesign was to build a site that reflected who the HubSpot product team is and what it’s like to work here. The new site pages capture that with good design and people-centric content, but also because they are a constant work in progress just like our inbound recruiting playbook. Both the site and our approach to attracting top product talent will continue to evolve as we learn from what works, what doesn’t, and how we can make our team more valuable to our candidates and community.", "date": "2015-07-23"},
{"website": "Hubspot", "title": "Come Meet the Honorable Princess Becky @ HubSpot", "author": ["Karen Rubin"], "link": "https://product.hubspot.com/blog/bid/60313/come-meet-the-honorable-princess-becky-hubspot", "abstract": "Almost any thing can happen when you combine an unlimited beer fridge, desk chairs on wheels and cardboard tubes. However, even I was surprised by a late night duel which happened at our head quarters over the honorable Pricess Becky. Watch for yourself to find out how it ended.", "date": "2011-02-25"},
{"website": "Hubspot", "title": "8 Reasons to Co-op at HubSpot", "author": ["Allison, Molly, and Rose"], "link": "https://product.hubspot.com/blog/8-reasons-to-co-op-at-hubspot", "abstract": "1. Join an amazing team, build amazing things This one seems pretty obvious—HubSpot has an amazing product and co-ops have the good fortune to work on it. But a killer product does not always mean an incredible co-op experience. The incredible experience at HubSpot largely comes from the way we work together. A co-op at HubSpot joins a small team of 2-4 engineers and works closely with their Tech Lead to push code to production on their first day . Each group of engineers is paired with a Product Manager and a Designer to form a small, autonomous team that fully owns every stage of an app's lifecycle, from mockups to maintenence. A co-op becomes an integral part of a team by playing an an almost identical role to a fulltime developer. It might sound a bit intimidating a first, but luckily everyone has a team to support them! 2. Break stuff (and then fix it) If you're not breaking things, you're not moving fast enough. HubSpot engineers work in an environment that encourages building, testing, and shipping code many times per day. At that pace, everyone is bound to ship some bad code at one point or another. It's not the end of the world, and often it's one of the most valuable learning experiences a newbie developer can have. You simply don't know \"real world work experience\" (or real fear, for that matter) until you've had to quickly roll back a deploy or attend a critsit review meeting. Someone might even show up at your desk with a real life fubar . 3. Feel overwhelming pride for your work Building cool features is fun, but it's even better when you know that your work is helping someone else. Co-ops get to work on some amazing projects that have a huge impact on other people. Whether that work is building internal tools to make the lives of other HubSpot employees easier, or exciting new features that HubSpot users can enjoy, people notice your work. HubSpot even has an internal \"cheers\" system that allows people to congratulate and thank other employees for work they’ve done, so that no good work goes unnoticed. Be proud of your work—you deserve it! 4. Stand on the shoulders of giants The people that work here are smart. Need help with CoffeeScript? No problem—someone who works here literally wrote the book on CoffeeScript. Use Stack Overflow often? Cool—you might work day to day with someone whose reputation is in the top 0.04% of all time. You will run into mind-boggling challenges no matter where you work, but at HubSpot, there is a whole team of brilliant people who are willing, able, and excited to help out. We're nearing the completion of our co-ops at HubSpot, and we agree that we've learned way more from co-workers than from most (dare we say all?) of the classes we've taken at school. 5. Become a resource for your team HubSpot is a hiring machine, and within a six month stint, a co-op could end up as one of the most \"senior\" developers on their team. Like any other full-timer on a 3 or 4 person team, a co-op will probably end up knowing all there is to know about about parts of a service or app. How cool is it to know that people will start coming to you for questions? 6. Delight your users, change their lives If you’re too humble to admit your work is amazing, try sitting among thousands of people at HubSpot’s Inbound conference as they cheer when Brian and Dharmesh unveil a feature you developed. HubSpot's software really improves peoples' lives, and you get to be a part of that.  The changes you make reach users all around the world. Many of these people can’t keep their love for your work quiet, and will talk about that feature on social media. You can be sure that your work will be enjoyed by many. 7. Learn to really push yourself Co-ops have completed some pretty impressive projects at HubSpot, and it's paved the way for future co-ops to be trusted with some really cool work. There's tons of time to have fun with coworkers (and we really know how to have fun), but there is also a huge sense of responsibility that comes with our high-impact projects. Understanding the value of these projects pushes us to grow as developers and learn to work super hard. One of the co-ops this semester has a record-holding 79-day GitHub contributions streak, and he did it just for fun. While we are not expected to be that extreme (looking at you, Zach!) we certainly aren't an apathetic, bored, or disinterested bunch. 8. Be part of something special Co-ops at HubSpot get to participate in \"Intern Lunch & Learn\" events, where we gather and have lunch with different execs across the company. It's a cool opportunity to meet and chat with HubSpot leadership, and understand the story and trajectory of HubSpot from their perspectives. We've also got weekly Tech Talks, awesome dev events, board game nights, beach house weeks in the summer, ski chalet weeks in the winter, all the candy in the world, a nap room, etc etc etc. Basically, we've got great perks and great people to enjoy them with.", "date": "2015-01-06"},
{"website": "Hubspot", "title": "The Road to My First Product Analyst Position", "author": ["Erin Wilt (She/Her)"], "link": "https://product.hubspot.com/blog/the-road-to-my-first-product-analyst-position", "abstract": "I didn’t grow up knowing I wanted to be a product analyst . Honestly, the role probably didn’t even exist when I was a child. It wasn’t until about halfway through college that I even had an inkling that I wanted to work with data, after gaining minimal exposure to it in classes. I took an internship to learn basic SQL, popped it on my resume and was fortunate to have someone from HubSpot reach out over LinkedIn about an opportunity. Despite it being an entry level position , I remember feeling incredibly intimidated by the interview process. It was far more technical than anything I’d done before and the whole time I couldn’t help feeling like my knowledge was subpar. But I hadn’t come in totally unprepared, I had my experience in SQL and while I knew there were more advanced functions I’d never heard of before, let alone used, I was confident with my foundational knowledge that I could pick them up easily on the job. And what I lacked in technical skills I tried to make up for in interpreting results. None of the analysis I did in the take - home assessment was fancy or novel, but I did my best to explain why I looked at the data the way that I did, what it told me, and what I would recommend doing with that information. In the in-person interview I was asked how I would go about answering a particular question from a stakeholder. Again, I don’t think I gave an impressive answer, but afterwards I did ask the interviewer what she would do. While I may not have demonstrated that I had a ton of experience or knowledge in answering those kinds of questions I did demonstrate a desire to learn and a curiosity for what could be done with data. I think those were critical factors in convincing the company to take a chance on me. So what was it actually like? Just as in the interview process, I felt completely intimidated during my first few weeks of work. I’d sit in meetings and be amazed by the work others were doing. I asked a ton of questions. Many felt stupid, many I spent waaay too much time trying to figure out on my own before asking, but my teammates always answered them without the slightest bit of judgement — except maybe to wonder why I hadn’t asked sooner . As an associate I tried to soak up as much knowledge as possible. In the first two months I didn’t really perform any “big analyses.” Instead, I focused on learning the company, learning the team I worked with, and learning the data that we had. It seems like a common fear across all of the analysts I’ve spoken with during those early days of onboarding (not just entry - level) is that they’re not delivering results fast enough. But if I hadn’t built that foundational understanding first, any analysis I would’ve performed would’ve been crap. In fact , over the coming months , I would find what felt like gaping holes in my analyses. “Oh, I didn’t factor in that these were “test” accounts or that we have this special discount that totally skews the results.” So that’s not to say that my foundational understanding of the product area I worked with was perfect, but it did show me that the product understanding was just as, if not more important than, the technical aspects of the analysis. I was given an area to focus on, and I think that was the greatest gift I could’ve received during my early associate days (so if you’re not given one, create one yourself based on where you think there’s a need). I started to gain confidence as I understood that area more and more deeply. And because I “owned” that space, I was given the freedom to experiment and learn how to be an analyst. So I took a stab at an analysis for an initial question my team had identified. I remember reviewing it with my mentor and I think he looked at me like he never would’ve spent the time doing it that way . Looking back now that I’ve “graduated” from being an associate, I really wouldn’t either. But it was so helpful for me because it was a start. It was something to build on. And while no, it may not have been the most efficient way to tackle the problem, it did yield some insights that I was able to take back to my team. And from there the project gained momentum. I got questions from those insights which led me to new analyses with new insights that again led to new questions. And with each new insight (no matter how small) my stakeholders continued to build trust in me. I feel like you always see the advice of breaking your goals into small, discre te tasks — and to celebrate the completion of those little tasks. And it’s so true, especially with something you don’t have a lot of experience with. Set up those small wins, so that your job doesn’t feel so daunting, and so that you can tell you’re making progress. By the time I was four or five months in, I felt completely different about my role. I suddenly felt confident, and that even though I was still figuring things out, I truly had a unique value that I brought to the team. After all , I had been the one that spent the weeks digging into the data, so I really was the best person to talk to about my focus area, and I could give truly educated opinions there. It was funny because even in the short months that I had been in the role, I’d already look back on earlier work and think, “What was I doing?” It was okay, though — I’d grown beyond that. I had also realized by that point that the toughest parts of the job were actually figuring out what work would be most helpful for your stakeholders, and how to present that work in a meaningful and actionable way. And while I think that’s a really hard skill to master, the more you practice the easier it becomes. The one piece of advice I’d give to new analysts is to always be ready to try new things. If your whole analytics team is learning something new, be an early adopter of that skill/program. It’ll help you start feeling on the same “level” as your more experienced teammates and can even be an opportunity for you to teach them something new. And then you’re no longer just a sponge absorbing everyone else’s knowledge because you too can share your own. Takeaways Yes, you’ll likely feel intimidated, but that’s okay, everyone has to start somewhere. Build a strong foundational understanding into what you’ll be analyzing before you start trying to analyze it. Learn all that you can from your more experienced teammates, don’t be afraid to ask questions. Take on a project or problem, own it, and break it into small manageable tasks to build confidence and experience. Be open to trying new things (even if they seem beyond your skillset) as that’s how you’ll start to gain expertise — that’s what will help you go beyond just being an associate. Do you have your own goal to become a Product Analyst? Apply today to our Associate Analyst Rotational Program .", "date": "2020-10-15"},
{"website": "Hubspot", "title": "Riding the Synthesis Wave: How to Avoid Drowning in Your Qualitative Data", "author": ["Margot Lieblich (She/Her)"], "link": "https://product.hubspot.com/blog/synthesis-wave", "abstract": "In the field of User Experience (UX) Research, we apply a lot of rigor and methodology to designing and executing research projects, but often not as much on how to analyze our results. On paper, the “synthesis” phase can sound very simple. You just review your findings and come up with major takeaways to incorporate into your work. But in reality, this stage is very complex, arduous, and time consuming. And it’s far too easy to introduce our own biases. When we introduce our own assumptions and predictions to our research synthesis, we put the validity of our findings at risk. I think of research synthesis as a series of waves, with relatively predictable highs and lows. This helps me prepare for the natural low points in the process and to carve a path out to minimize error or bias. The synthesis wave is based on the startup lifecycle , a model developed by Paul Graham of Y Combinator that shows the natural highs and lows of working in a startup. The four stages in the synthesis wave are: Externalization. This is the tough but necessary phase of listening to session recordings and identifying key takeaways from each. At this stage, I know I’ll be tempted to let my mind wander, so I schedule breaks to keep my perspective fresh. Affinitizing. At this stage, my goal is to find super high level, early stage patterns. I often have to remind myself to slow down, and not jump to conclusions. Insight identification. This is one of the most critical points of the process, where I start to tease out more nuanced findings. I come up with as many different ways as possible to visualize and reorganize the data to see what deeper patterns emerge. Insight refinement. Finally, I bring a critical eye to my findings and put my potential insights to the test. At this point, I make sure I consider business impact as well as user impact and bring in quantitative data to assess which insights are most meaningful to our organization. It’s the third stage, insight identification, that’s most challenging for many UXers. So that’s the stage I’m going to explore in this post. It’s far too easy—and common—to speed things up at this stage and just go with the surface level patterns you’ve identified in the Affinitizing phase. But I’ve found that you can push those surface level findings into much deeper insights with just a few simple tricks. Imagine we’ve just finished a hypothetical research project where we observed and spoke with people who drink coffee. After we finished affinitizing our notes, we found the following high level themes surfaced throughout our research: Commuting with coffee My everyday routine Health concerns Loyalty Looking at these themes, it’s hard to know just what to do. This is where I’ve learned to spend a little more time and start to dig deep. One of the first things I do is come up with different spectrums that relate to my initial themes and common topics. Then, I map the different findings onto these spectrums. Since I take all of my notes on color-coded sticky notes during the Externalization phase, this makes my process very easy to visualize as I start identifying insights. Looking at our different themes and findings, we might come up with a few different spectrums for our coffee project. For example: Coffee as convenience ← → Coffee as indulgence Consistency ← → Variety Ritual ← → Routine Individual ← → Family Budget-focused ← → treat yourself! I’ll typically draw the spectrums on a whiteboard and start moving stickies to see where they fall onto the spectrum. Often in this type of research, I’ll have done research with a couple different segments or cohorts of people. It’s helpful to have the sticky notes color-coded by each segment, so that I can see holistic patterns when I look at multiple spectrums. But if I were only working with one group, I’d try to give each participant their own color sticky. Let’s imagine in our research project, we saw that the same people who fall on the “Consistency” side of the “Consistency ← → Variety” spectrum also fall on the “Budget-focused” side of the “Budget-focused ← → Treat yourself!” spectrum. By looking at those types of patterns, we can start to see patterns and identify new segments of people based on traits we might not have otherwise noticed. If you find these types of patterns emerging, you might find it natural to put together examples of proto-personas, where you flesh out the defining attributes across your different research samples. If you don’t find these types of patterns emerging, that is also okay. It might just be that you didn’t encounter different clusters of behaviors within your sample. Instead of trying to make connections where they don’t exist, take a break from the spectrums and think of another way to organize your data. In general, I’ll try to re-organize my data into two or three different ways for each project. Depending on your unique research project, different frameworks for visualizing your data can serve different purposes. Now let’s say we noticed the theme of “Loyalty” was particularly interesting, and had a lot of different angles and nuances to offer. Looking at our notes for just that one theme, we might find it helpful to organize the subfindings into a hierarchical diagram. Picturing Maslow’s hierarchy of needs , we can ask ourselves, what are the minimum requirements for someone to be loyal to a certain coffee shop or product? What attributes are secondary? What are their ideal “nice to haves” that come last? Or if our data was more scattered across multiple themes, we might come up with a framework to study the relationship between a couple themes. For example, we might try to put our findings from “Loyalty” and “Commuting with coffee” into a Venn diagram and see where they overlap. Throughout this process we’d keep an open mind, and come up with new frameworks that are suitable to our specific findings. The point is not to force your findings into a predefined framework, but rather to look at your findings and see what framework comes naturally. Depending on your research methods and focus areas, the way you visualize the data can be very different. Consider how other research examples might be suited to other frameworks. If during the research we followed people throughout their entire morning routine, you might see how those findings would fit nicely into a journey map. However, if our research consisted of people describing their favorite coffee shops, a journey map might not fit the data we collected. As you become more familiar with this practice, you’ll naturally gravitate toward certain frameworks. When you find yourself relying on the same tricks, I encourage you to challenge yourself to incorporate something new. By avoiding developing habits in this phase, you can reduce the influence of your own natural biases. Instead, push yourself to find another method to organize the data and see if that surfaces a different perspective or pattern. What happens when you feel stuck, and don’t immediately see a framework that suits your research? Consider setting up a mood board to capture inspiration from other places. I often look for inspiration from unique quantitative data visualizations , and browse the Google Slides “Diagrams” feature to look at different models. Or, you can do yourself one better and involve your whole team. Show your process to a coworker and see how they might reorganize the data in a different way. I’ve found that at this stage in synthesis, it’s helpful for me to do a “mini share-out” with my stakeholders. I’ll show them a very messy whiteboard with a few frameworks or categorized sticky notes, and have them ask questions and poke holes in my story. By bringing in these fresh perspectives, I can surface assumptions that I made without even realizing it. As with any new skill, the more often you incorporate these practices into your method, the more confident you will feel changing and adapting them to suit your own needs. By following these guidelines and building more meaningful synthesis time into your research efforts, you can reduce the influence of your own bias and ensure your results are truly impactful.", "date": "2020-03-24"},
{"website": "Hubspot", "title": "Understanding Thread Dumps", "author": ["Jacob Schlather (He/Him)"], "link": "https://product.hubspot.com/blog/understanding-thread-dumps", "abstract": "Your application slows down suddenly or maybe it just stops doing anything. What do you do? What can you do? Well, you can take a thread dump. In the JVM, all execution is performed via threads. The JVM executes commands on the host OS by running a JVM thread corresponding to a built-in thread of the OS. So whenever the JVM executes an instruction, it's always done via a thread. JVM threads have a stack of what method invocations have been called to reach the one they're currently executing. You typically see these printed as stack traces in exceptions, showing which line of code caused your exception to be thrown. But, a stack trace can be taken with jstack at any point during execution and will show you that thread's call stack. A thread dump is a list of all the threads in the JVM with a stack trace and some metadata for each. Anatomy of a Thread Dump Entry Let’s start with a very simple example. \"Keep-Alive-Timer\" #12 daemon prio=8 os_prio=0 tid=0x00007f89a4008d90 nid=0xabf9 waiting on condition [0x00007f85a319d000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at sun.net.www.http.KeepAliveCache.run(KeepAliveCache.java:172) at java.lang.Thread.run(Thread.java:748) The first thing to note is the thread name “Keep-Alive-Timer.”  This thread is created by the KeepAliveCache in order to keep http threads alive. The #12 refers to this being the 12th thread created by the JVM since it started.  After the thread number, the daemon keyword indicates that this is a daemon thread, which means that it won’t prevent the JVM from shutting down if it’s the last running thread. After that, there are several less important pieces of metadata about the thread, such as the priority, the os priority, the thread identifier, the native identifier, the state (this one is important) and its address in the JVM. Finally, we have the thread state. Java threads can be in seven states . The important states are Runnable: Means a thread is currently executing. Blocked: The thread is waiting for a lock to be released. This happens when entering a synchronized block, for instance. Waiting / Timed_waiting: The thread is waiting for something to happen. These are joins/gets on CompletableFutures, calling Thread.sleep, or Thread.park. Threads in a thread pool waiting for work will be in this state. Going back to our example we can see that it’s in a `TIMED_WAITING` state, so the thread is currently waiting. From the KeepAliveCache source code, we can deduce the thread is currently waiting before it keeps alive some more http connections. A Few More Examples \"NioHttpClient-Callback-670\" #68821 daemon prio=5 os_prio=0 tid=0x00007f15781d8170 nid=0x814d waiting on condition [0x00007f1594761000] java.lang.Thread.State: TIMED_WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for  <0x0000000083d10a78> (a java.util.concurrent.SynchronousQueue$TransferStack) at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215) at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460) at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362) at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Here is a thread “NioHttpClient-Callback-670” which, based on the name, is in the NioHttpClient-Callback pool. This thread’s state is `TIMED_WAITING`. Reading the stack trace, the thread is calling getTask() which means it’s polling a synchronous queue and waiting for an element from the queue. So, this thread is currently waiting for work from its Executor and is not executing any tasks. The majority of the threads in a thread dump are typically waiting for work from a threadpool and can usually be ignored (the signal to noise ratio in thread dumps is very low). \"update-pool-12\" #1157 daemon prio=5 os_prio=0 tid=0x00007f155800de00 nid=0x11484 waiting on condition [0x00007f133dc7e000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for  <0x0000000785af47a0> (a java.util.concurrent.CompletableFuture$Signaller) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.CompletableFuture$Signaller.block(CompletableFuture.java:1693) at java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3323) at java.util.concurrent.CompletableFuture.waitingGet(CompletableFuture.java:1729) at java.util.concurrent.CompletableFuture.join(CompletableFuture.java:1934) at com.hubspot.wal.WalWriter.writeToStore(WalWriter.java:79) at com.hubspot.wal.WalWriter.write(WalWriter.java:66) at com.hubspot.contacts.hbase.data.updaters.ContactUpdateWriter.publishWalMessage(ContactUpdateWriter.java:97) This thread (stack trace truncated) is taken from a HubSpot Kafka worker that updates contacts (CRM stuff). The thread name tells us it’s from the update pool. Currently the thread is in a waiting state. Reading backwards in the stack trace it has called `CompletableFuture#join()`, which will wait for the future to complete. Continuing down the stacktrace it's called `publishWalMessage`, which refers to a Kafka write ahead log (WAL), so this worker is currently waiting for a Kafka produce to its WAL to finish. Effectively Reading Thread Dumps Thread dumps are full of noise: threads that aren’t doing anything, hundreds of stack frames that aren’t meaningful and metadata that you’ll never need (I’m looking at you, native thread identifier). If you try to scroll through a thread dump looking for the information you need, you almost certainly won’t find it. But there are ways to read through them. When you’re looking through a thread dump, you’re typically interested in what your threads are doing. Instead of looking through the whole thread dump, you search for your package name. For instance in this stack trace: \"update-pool-12\" #1157 daemon prio=5 os_prio=0 tid=0x00007f155800de00 nid=0x11484 waiting on condition [0x00007f133dc7e000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for  <0x0000000785af47a0> (a java.util.concurrent.CompletableFuture$Signaller) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.CompletableFuture$Signaller.block(CompletableFuture.java:1693) at java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3323) at java.util.concurrent.CompletableFuture.waitingGet(CompletableFuture.java:1729) at java.util.concurrent.CompletableFuture.join(CompletableFuture.java:1934) at com.hubspot.wal.WalWriter.writeToStore(WalWriter.java:79) at com.hubspot.wal.WalWriter.write(WalWriter.java:66) at com.hubspot.contacts.hbase.data.updaters.ContactUpdateWriter.publishWalMessage(ContactUpdateWriter.java:97) We know it’s a Contacts service, so we search for the package of that service which is `com.hubspot.contacts`. This gets you to a stack trace you’re interested in and the part of the stack trace you care about. The first occurrence of your package name in the stack trace is the point in your code where the thread is currently executing. So you know where to look in your code to find context to what it's executing. It’s worth noting that sometimes in a thread dump, your package won’t be there, which means that none of your code is currently executing. This is frequently the case for low throughput web services and workers (for example, a web service doing < 10 req/s at 10ms mean latency means 90% or more of the time no thread is doing work). Taking a Thread Dump Thread dumps can be taken using the jstack utility. If you're running jstack it's important that you run it as the same user running the JVM you're taking a thread dump of, otherwise thread names won’t be populated. For example if you have a JVM running under user java-service with PID 435, you could take its thread dump via sudo su java-service jstack 435 Use Cases for Thread Dumps Slow downs in async workers and web services Thread dumps can be very handy for analyzing when a service slows down. An example is a web service that’s rejecting http requests because it’s http thread pool and queue are full. Then you can take a thread dump to see what all of the http threads are stuck doing. Go through around 10-15 stack traces and see if they’re all doing the same thing. Look for things like lots of threads making database queries, waiting to acquire database connections, waiting on or calling out to an http api, or stuck in some surprisingly expensive computation. If you can identify what’s slow then you can investigate that service/database/computation to see why it’s slow. Performance tuning via sampling Performance profiling with thread dumps can be done, but is not the most efficient way to profile. Flame graphs or a profiling tool like yourkit are better suited to the task, but thread dumps can be used if you don’t have either of those available. Take several thread dumps over the course of a minute when a service is at peak traffic. Then analyze where in the code each of the threads are currently working. This is very similar to looking at slow downs, except there’s going to be more noise and you’ll have to be more careful about drawing conclusions. If all of your threads are calling out to a datastore, it’s not necessarily because the datastore is slow, but maybe that they spend the majority of an http request talking to that datastore. You should go in with an expectation of the work you think your threads should be doing. Then verify that there aren't any areas where the threads are spending more time than you'd expect. A useful tactic when profiling/tuning async workers is to scale them down so they can’t keep up and then look at the performance characteristics. Finding deadlocks Looking for deadlocks is usually straightforward with a thread dump. Find a thread that should be doing work and then look at what it’s waiting for. If it’s on a lock, then you know the lock is the issue. So you need to find what’s holding the lock or why the lock was not properly released. Sometimes the thread holding the lock will be stuck and you can find that in the thread dump as well. If you can't, then you'll need to figure out how the lock got into this state. Taking a heap dump and analyzing the values of the classes that interact with the lock can be a good first step. If the thread is waiting on a future, then you need to find the thread executing the future and figure out why the future isn’t complete. In some cases the future will not correspond to a thread (such as async http) and it can be helpful to take a heap dump to examine the classes involved. Hunting down thread leaks For hunting down thread leaks, you can group threads together based on their thread names with a command like awk '{ print $1 }' threaddump.log | grep '\"' | sort | awk '{print substr($0,0,13)}' | uniq -c | sort -nr > sort-threadnames.log You can adjust the `13` characters as needed. If all of your thread pools have been properly named, it will be easy to find the culprit. If you find that you have thread-1 to thread-200, it’s going to take a little longer. By taking several thread dumps, you may be able to find one of these threads executing application code, which should point you to where it’s being defined. Otherwise you can take a heap dump and look for thread pools/executor services. When you find the one in question, look for incoming references to that thread pool and it should tell you what’s creating it. If the thread pool has been orphaned (non-empty thread pools are never garbage collected because they are always reachable from the threads inside the pool) then you will need to do an audit of all of your thread pools. Running the application locally with a breakpoint on thread pool constructors is also an option (though a very painful one). Another option for analyzing the thread dumps, rather than bash one liners, would be Spotify's thread dump analyzer , which will also group them together.", "date": "2019-09-05"},
{"website": "Hubspot", "title": "Building a Robust System Using the Circuit Breaker Pattern", "author": ["Andrew Herbst"], "link": "https://product.hubspot.com/blog/bid/64543/building-a-robust-system-using-the-circuit-breaker-pattern", "abstract": "HubSpot is a big system. We're composed of lots of databases, web servers, third party integrations and myriad other components. So when one of those subsystems goes down and the larger system isn't insulated against such failures adequately, it can be a headache. Let's consider a concrete example. Say you have a web server that populates data on a page from sharded databases, call them A and B. Half of your users are in A and the other half are in B. Let's also assume that we're being naive and have little or no caching of data—every hit to the page results in a database roundtrip. Database connections have timeouts of 60 seconds, which is to say that the web server will attempt to connect to the correct shard for 60 seconds before giving up and throwing an exception. All good? Now let's take one of your shards away, shard B. What happens? Shard A users will be happy—the server will grab a connection to the database, pull the data and be on it's way in short order. Shard B users will have a rougher go of it—the web server will try to connect to the database for 60 seconds before giving up and hopefully showing an error message saying their data is unavailable (or an ugly stack trace failing that). How will this situation scale? If you have enough shard B users trying to access the site at the same time, the web server will quickly run out of worker threads as it tries to connect to the unresponsive database; at that point you'll get browser timeouts or proxy errors for both A and B users since the entire web server is unable to serve requests. \"Do you really expect my load balancer to timeout with a proxy error when I can't connect to my database?\" \"No Mr. Bond, I expect you to die.\" In this case, Goldfinger is actually on to something. What we need is a way to detect the failure of this database (or really any subsystem) and avoid even the attempt to connect to it until the error condition has passed—we should just die. This is called a Circuit Breaker , and it's well described by Michael Nygard in Release It! . Here's how it works. Let's define three states: CLOSED Connections to the monitored subsystem are passed through as normal OPEN Connections to the monitored subsystem are intercepted and immediately fail; an error or exception is passed back to the calling client HALF_OPEN A limited number of connections to the monitored subsystem are allowed to pass through but further failures put us right back into OPEN (this is our retry mechanism) And, we have a state machine: Exceeded failure threshold on CLOSED ? Move to OPEN . Retry timeout passes? Move to HALF_OPEN . Connections succeed while in HALF_OPEN ? Move to CLOSED , otherwise move back to OPEN We recently implemented this here at HubSpot and we're seeing some nice early returns. Here's an example of how it works: public interface MonitoredResourceInterface { @CircuitBreakerExceptionBlocklist(blocklist={SQLException.class}) public void someMethodToMonitor() throws SQLException, BlahException; public void someMethodWeDontCareAbout(); } public void getCircuitBreakerMonitoredResource() { MontioredResourceInterface ds = getMonitoredResourceImplementation(); CircuitBreakerWrapper wrapper = CircuitBreakerWrapper.getInstance(); CircuitBreakerPolicy policy = getPolicyImplementation(); ds = wrapper.wrap(ds, policy); return ds; } There are two important keys here. One is the notion of an exception blocklist : that is, a list of exceptions that our circuit breaker will watch for and that will cause us to eventually trip when we reach a threshold determined by the passed in CircuitBreakerPolicy instance. In this example we know that we don't care about BlahExceptions—perhaps they happen all the time and we know they don't hurt overall system performance. But we do care about SQLExceptions: those can be caused by database connection problems and too many of those lead to serious issues. We want too many SQLExceptions to trip us to the OPEN state so our app can live to fight another day when our database is gone. The other key is our transparent wrapping of an object in a dynamic proxy that monitors thrown exceptions and intercepts failing methods when appropriate. We've used this approach for third-party service monitoring to great success at HubSpot, but that's another article. This basic pattern should be part of any software engineering toolkit. As your software grows in complexity and scale, it's critical to effectively insulate subsystems from each other so that one failing component doesn't bring down the whole system. The circuit breaker is one pattern that, when used judiciously, can increase overall system robustness and improve end user experience.", "date": "2011-05-25"},
{"website": "Hubspot", "title": "Anthony Roldan is a HubSpotter", "author": ["Elizabeth Dunn (She/Her)"], "link": "https://product.hubspot.com/blog/bid/86784/anthony-roldan-is-a-hubspotter", "abstract": "Name: Anthony Roldan Role: Developer at HubSpot Superpower: Never skipping a meal Anthony Roldan joins HubSpot as the first engineer on our new mobile team. Not surprisingly, he'll be spending most of his time building HubSpot mobile apps for iPhone, iPad, and Android. In fact each of these should be showing up in app stores sometime in the next few months, which is pretty rad. Anthony is originally from Lexington, MA and went to college at Olin College in Needham. He comes to us from San Francisco, where he built apps for Second Glass , a wine events startup that runs the very successful Wine Riot events in Boston and around the country. Follow Anthony on Twitter at @aroldan or check out his periodically updated food blog Justice Kitchen .", "date": "2012-05-17"},
{"website": "Hubspot", "title": "Lessons from Leaders on Cultivating Culture", "author": ["Ian Marlier"], "link": "https://product.hubspot.com/blog/notes-from-cultivatecon-2013", "abstract": "Not many people have the opportunity to listen to 8 successful technologists and businesspeople talk about their successes and failures, let alone having the chance to do so in one place at one time.  Below are some notes from CultivateCon 2013 , which offered exactly that.  Among our key takeaways: Culture is not a replacement for Product .  The best culture in the world can't make people buy a bad product.  Every speaker touched on this idea to some degree. Transparency is important. The best people, especially at a startup, are the ones who function best with context and full information. Bored people quit .  Almost everyone in a technical organization has a state change every 3 years or so.  If you're not giving people the opportunity to do that within your organization -- a new position, a new product, a new challenge -- you're risking having your best people walk away. Kittens .  You have to read the notes if you want to understand this one... Check out the full notes below! Culture is something that we feel strongly about here at HubSpot.  It's something that we spend a lot of time talking, thinking, and writing about, as well as living on a day-to-day basis, and so we're not unbiased observers.  Take a look at our Culture Code to get a sense of what our lens looks like. Culture Code: Creating A Lovable Company from HubSpot All-in-one Marketing Software With that background, the speakers: Tim O'Reilly Topic: \"How I Failed\" Largely similar to a recent blog post , but with a few additional personal anecdotes that highlighted his points. Failure #1: Not making sure that the team actually heard what I was saying. That is to say, you can tell people exactly what you want, but you need to take the time to make sure that the thing that they actually hear is the thing that you mean. Michael Lewis, talking about the fact that a lot of people went into finance because of Liar's Poker: \"you never know what book you've written until you know what book people have read.\" Have a mission.  Have a set of strategic priorities that further the mission.  Have a set of priorities that contribute to achieving those strategic priorities.  Have a set of activities that are aligned with those priorities. Failure #2: That's how it's done. Don't be locked in to the way that things have been done historically. We apply creative thinking (hopefully) to technology problems, do the same for business problems. - Failure #3: Lack of financial and operational discipline. This was probably our biggest failure . We missed so many opportunities because we didn't have the savvy to understand that we needed to be financially disciplined, we needed to be operationally smart. O'Reilly almost died as a company because they weren't smart about how they used their cash, they weren't smart about leveraging/negotiating with suppliers.  They looked around after the web bubble burst in 2000/2001 and realized that they had accumulated people who weren't actually doing anything valuable to the priorities->strategy->mission tree. Treat your financial team as a first-level group. Hold teams accountable for their numbers, make sure that the right team is being measured for any given number We used to do something silly, where the people putting on a conference weren't the ones who were responsible for the P&L -- that was someone else's problem.  But that meant that one team (the financial team) was being measured based on the success of another (the content team creating the program).  Make one team responsible for both, measure them based on their own success. Run lean, and when you pivot, reassess your staff It's easy to ignore the fact that some people are good at one thing and not at another, and that when you change what it is that you do you might have some people who aren't the right ones. People want Autonomy, Mastery, Purpose (from \"Drive\" by Daniel Pink).  Keeping someone around who's the wrong one for the job isn't good for you or for them. Failure #4: Don't tolerate mediocrity Sometimes, insisting on taking more time, or spending more money, is the right answer.  If your gut is telling you that something isn't good enough, then it's not good enough.  Go fix it. Failure #5: Hiring supplements, not complements Don't hire more of what you have.  An organization that is monotonically aligned with the person at the top, it's going to be inefficient in some ways, because it's going to be blind to some of what's happening. The person at the top of the tree probably shouldn't be the best at anything the business does O'Reilly had mediocre financial people for a long time, for example Failure #6: \"I'll Take Care Of That\" When people who work for us aren't strong enough, the instinct is to compensate. This is something that a lot of strong managers, particularly in technical fields, are prone to. If you do this, you're solving the wrong problem. Elaine Wherry Topic: \"Cracking Culture\" Clarity in communicating your mission, vision, and strategy is key. Artifacts of culture are not the same as culture.  Good job, you have a ping-pong table.  That does not mean that your company is place where people want to hang out and play ping-pong. A quote that really jumped out: \"Meebo is not a lifetime employer, but we want people to grow and become more employable as a result of their time here.\"  That's quite a statement, one that is hard to swallow at one level, but I think more accurately reflects the state of the employee/employer relationship than most.  The days of the flannel-suit IBM model are pretty much gone.  (This was also echoed, in its own way, by Rands in his talk at the end of the day.  His form of this sentiment is best paraphrased as \"people get bored in 3 years.  Bored people quit.\" \"Truth\" is vital, but it's not necessarily the same for everywhere. Culture is not a cult -- it's just a way of doing business.  Avoid being self-congratulatory.  (Yes, HubSpot sometimes gets self-congratulatory about our culture.  This was a valuable takeaway.  We need to be sure that we're constantly re-examining.) Kate Matsudaira Topic: \"What _DO_ you do all day?\" How do you measure performance? Hours worked?  Means nothing Lines of code?  Doesn't account for how difficult or meaningful that code is Bugs?  Tests?  Don't account for customer satisfaction Features?  Doesn't account for quality I've been thinking a lot about flat organizations.  An organization with no managers is an organization where everyone is a manager, because someone still needs to lead. Leadership is a decision, not a position . 3 types of informal power: Charisma: Charisma is a thing that you have or you don't.  It's not something that can be taught, really (though it is something that you can optimize) Expertise: Lots of people end up in a leadership role because they're simply the most knowledgable about something.  This, too, isn't really something that can be taught. Relationships Start from trust What is trust in the context of an organization? Don't expect things from others that you wouldn't ask of yourself Know your timing -- whether in the context of a day, or a deliverable Relationship Architecture Make two lists: The most important people on your team; and, the people on the team with whom you have the best relationships.  How much overlap is there? How can you strengthen those relationships? If the people on the second list aren't the same as the ones on the first, why not?  Why aren't you making a point to build relationships with the people who are leaders in their own right? Rebuild burned bridges.  Don't bypass a problem, address it. Don't deflect, especially in the context of conflict.  Sincerity in your responses to conflict will build other people's trust in you. Be present.  Stay focused. Ask questions, wait for answers. Focus on the long term.  Who are the people who you should have relationships with?  What can you do to develop those relationships, and to nurture them? Things won't always go well It's easy to forget how hard relationships are. Where does success come from?  From people.  Ideas are cool, things that are actually Patrick Collison Topic: \"Nothing to Hide: Living with complete email transparency\" Stripe has rethought everything from scratch, haven't adopted much.  This has ended up being a little inefficient.  For example, we initially thought that we didn't need an office, turned out we did.  Initially thought that everyone should get paid the same, that turns out to be silly. Rethinking everything from first principles can be exhausting and inefficient, but sometimes you stumble on something that works. I'm a big believer in ambient transparency.  The transparency that comes of having a small org in a small space, but that you lose as you grow. Initially, when the company was only a couple of people, just used a single shared email address.  As we hired new people, we added them as well (though gave them their own mailboxes) Set up outgoing mail server to automatically BCC everyone else in the company on outgoing email That doesn't scale forever, of course.  But, we felt that it was important that everything was internally public. We created mailing lists for every functional group (sys, ops, dev, investors, etc, etc), and BCC outgoing mail there. Created tooling for automated configuration of GMail filters to avoid overloading people Benefits Means that people are not surprised by things happening in the company.  Surprises are generally not good for morale Makes it easier to integrate new folks Less communication needs to happen, sometimes.  Less time spent talking to X or Y trying to find out the state of a project or something like that. Eases people's curiosity Helps in reducing politics. We have the goal of being a \"hive mind\", and we push our tools that way.  For example, we use Hack Pad -- a shared text editor that will even give you a feed of documents being used across the organization.  It's another version of the idea of overhearing a conversation in a 4 person office. Decide what properties you want in your communication.  Diff that against the way that you communicate now.  Solve for the diff. Some other lessons: You should in fact have an office Product Management may not be a useful function -- have engineers manage the product In hiring, self-discipline is maybe the most important thing Hiring someone who is capable of being very good at doing their thing well is undervalued.  If hiring engineers, code with them all the time, and see how well they do with that. Hack Trips -- changing scenery, taking some people who code to somewhere else can be a great way to help productivity.  (Stripe has done these to places like Rio and Hawaii, it's something that they brought over from Github.) Have a shipped@ email address, and every time something gets shipped, send an email that announces it.  Focus on quantifying the impact, not just celebrating the fact that a thing was done. When you fire someone, be very open about the reasons why, and be honest about them.  People will know if you are not telling the truth. Thank people when they raise a concern about the company. have lunch and dinner at the office.  Hire a chef.  (It makes financial sense around 20-25 people.) http://bit.do/cultivate Audience Question: Does transparency like this cause problems given that Stripe is handing financial data and PII? We keep user data and company data very separate.  User data is tightly controlled, and the expectations are very clear about it.  Company data is very open, though. Hiten Shah Topic: \"How to Create a Culture of Shipping Code Continuously\" Hiten has a reputation for dropping \"founder bombs.\" That is, he gets out of a conversation, meeting, or reading session, has some great ideas, and calls his team to share them. He had to learn to make sure the people hearing these ideas would take them with a grain of salt and not just as commandments. Teams should know what they're working on, and why. The \"why\" shouldn't be \"because my boss told me to\"; it should be something like \"to reduce churn\" or \"to affect these metrics.\" Closed door decisions lead to people doing things \"because my boss told me to\". Need to pass down understanding of the problem, the goal, and how the decision was made. Build products people want. -Paul Graham Shipping continuously is not enough. You have to ship the right things. Listen to the people building it. If they think it's crap, it's probably crap. What problems do your customers have, and how can you solve them? Focus your messaging around that rather than around your product. See Ian McAllister's post on \"working backwards\": http://www.quora.com/What-is-Amazons-approach-to-product-development-and-product-management/answer/Ian-McAllister Seek feedback from your team. Scott Chacon Topic: \"Leading by First Priciples\".  (Side note: Scott Chacon looks a lot like an old roommate of mine.  It's kind of distracting at first.) An anecdote.  100 years ago, a yarn factory had poor morale and low productivity.  An organizational psychologist suggested kittens -- have kittens running around playing with the yarn.  It worked, people were happier and productivity went up.  The most amazing part is that some factory owner said yes to this idea.  The morale: if someone suggested \"hey, let's try kittens\", would you say yes? First principles -- things that are more important than other things.  Disagreements should always come back to these.  Once you agree on principles, the rest follows from that. \"Three-year old prosecution\": 3-year olds just want to know why.  \"I think we should do this\".  Why?  \"Because doing X means Y, and Y is important.\"  Why?... This is also the 5-whys approach. What are the principles of your company?  Unlikely to be the same as Github's \"open source business\" model The office.  Why do we need an office?  The owners of the cafe where we're working are getting mad.  First Principles: Needed a place to work Needs to foster creative collaboration Needs to encourage serendipitous interactions Needs to allow for \"real business\" interactions Need a place to physically store and ship things The schedule.  Why do we need a schedule?  We don't -- with employees all over the world no one schedule is going to make sense for everyone.  First principles: People need to get their job done, and that's really it.  When they get their job done isn't particularly important. Meetings.  Why do we need to have meetings?  We don't -- for the same reasons as the schedule, meetings don't really work.  If you really need to have a meeting, it needs to be done in some form that is distributed and asynchronous.  First principles: Make it easy for people to get their job done. At a distributed company, you have to go out of your way to make sure that you are including the people who are remote in time or space. Management: Why do we need management?  We don't.  The overlap of \"management\" and \"problems that Github has\" is very small.  We have chosen to distribute these functions instead of hiring professionals for the moment (coordination, planning, strategy, etc).  Give people trust, that they will make intelligent decisions about where to spend their time.  First principles: Give trust. Don't solve for problems that you don't have. Don't cargo cult.  If you're going to do something, there had better be a reason that you are doing something.  Understand that reason. Patty McCord Topic: \"Leveraging Logic As a Leader\" Fundamentals: Company First.  You don't need a great culture if your product sucks or your idea sucks.  Culture enables success, but it does not cause success. Judgment trumps everything.  Fairness is important, consistency is not.  Use your judgment of what's fair, use your judgment of what's smart, use your judgment of what's right.  Don't worry about being consistent with all of the things that you've thought in the past. Just tell people the truth. What does a strong team look like? You can't really answer this without knowing what you're building.  What does that team need to do?  The answer to that determines who you actually need. If the people you have can't get the job done, tell them that.  It's not being mean, it's being honest. It gives people the chance to decide if they're motivated by the challenge of the work, it gives them the choice of deciding what they want their own career to look like. My least favorite type of person is the whiner.  \"Oh, Patty, things have changed, the culture is different and I don't know if management realizes it.\"  And I look at them and I say \"Yep, I'm management, and I'm very aware of it.\"  And they say \"Why?  Why does it need to be this way?\"  And I look back at them and I say \"Because we're successful .  And we want to be a big, successful corporation.  And that means that things need to be different than they were.\" Imagine a world with no Performance Improvement Plans. Just tell the truth! Imagine a world where interviewing is not a sin When you're talking to someone who isn't happy or isn't performing, suggest that they go interview Turns out the grass isn't always greener When they decide to stay, then you can ask what they offered.  That tells you what actual market comp is. Visualize success In 6 months, if you had the perfect team in place, what would be happening that isn't now? What would you measure? Metrics? Deadlines? Progress? What would it look like? What would people have to know to pull this off? So quotable! \"Someone was saying that they moved everyone's chairs in the office, and they all freaked out.  Classic geek!  So sometimes I would move their chairs just to fuck with them.\" \"I was jealous because everyone else at Netflix got to innovate, and I didn't.  So I decided I'd start.  And the way that I innovated was by just not doing shit.\" Michael Lopp (aka Rands in Repose) Topic: \"Why I Hate Meetings\" You are (at most) three years from building something new.  Look at resumes in tech.  Everyone has a state change every 3 years (or so often as to be effectively all the time). Bored people quit Get a report, every Monday -- everyone who is at 2 years.  What they're working on. Irrelevancy is just around the corner.  There is someone out there who is making everything that you do unimportant, or commodity.  It's going to happen, and it's good. I hate meetings. Why did meetings come into existence (a theory) Scaling communication At some point, we (as leaders) no longer know when things are going off the rails. A timeline: One person in a cafe has an idea and does some analysis and decides it makes sense, so he starts to work on it Hires someone else, describes the idea, they debate it and make it better and then go work on it.  And sometimes they disagree, and they talk about it, and then they come to an agreement. This defines a meeting Not just you Together working to solve a problem In a finite amount of time As needed But sometimes this is not what happens They hire a bunch more people, and they build the company, and it's up to 30 people.  Ideas are coming from every direction.  Decisions are collaborative and visible.  Execution is key, and there's no time to bicker.  Everyone knows everyone and does everything.  Error correction is rapid and organic.  Lost cost situation awareness.  The most random stuff becomes culture.  (This is amazing, and is also the establishment of \"the old guard\") The idea of a meeting is still pretty consistent. Now the company grows some more.  Now it's 300 people.  Ideas still show up but there's an overwhelming number.  Decisions are slower.  Execution is stove-piped.  (This is \"the new guard\", and they're pissed, because the old guard can flit around and just do things and it seems so damn painless.) Stories from the past become myth Situational awareness is expensive Communication requires overcoming friction Learning can no longer occur via osmosis Things go off the rails The old guard has no incentive to actually make things systematic, because they are the special few who can fix things by wandering the halls But someday something blows up (Palantir example: \"Steve\" quit -- the best engineer, the guy who does all the things.  And the old guard didn't know, because of a signal/noise ratio issue.) A meeting _can_ actually solve things, sometimes, and in this case it does Meetings go viral Perceived value of meetings go up It begins to be seen as the right way to solve things People who are really good at running a meeting are incentivized to continue having meetings Meetings turn into something else Random people who aren't contributing A lack of agenda That doesn't respect the attendee's time That goes on forever and ever and ever and ever How do we prevent meeting culture? Have more meetings!  Obviously. Actually, have a culture that values consistent, useful communication in all directions Preventative Maintenance Meetings 1-on-1's Every week No matter what 30 minutes (at least) Cheat sheet Performance review: \"You said you wanted to be able to do X, how's that going?\" A current disaster: \"Here's something blowing up in my world, how would you handle this?\" Staff meeting (1-to-many): At Apple, it's called \"E-Team\", and if you get invited your thing is fucked up.  The point: Qualitative information is important too. Every week (early) No matter what 30 minutes (at least) Cheat sheet The Dashboard: What is the health of the team?  What is the health of the business? Disasters: Things that are blowing up right now Special Guests: Someone else from around the company comes in to share the dashboard and disasters from their team. Tapestry Meeting (many-to-many) Occasional Possibly over poker Not only when things are on fire The point: To set up an environment where unexpected/serendipitous conversations happen All other meetings need an expiration date", "date": "2013-10-29"},
{"website": "Hubspot", "title": "It’s Payback Time: A Crash Course in Our Favorite SaaS Metric", "author": ["Christopher O'Donnell"], "link": "https://product.hubspot.com/blog/its-payback-time-a-crash-course-in-saas-metrics", "abstract": "It’s a good time to be a SaaS company. We have tons of information at our fingertips on the metrics software-as-a-service companies should be tracking, including benchmarks for those metrics. But this wasn’t always the case; I remember when \"Customer Acquisition Cost\" and \"Lifetime Value of a Customer\" were buzzwords. Now, we have more acronyms than we know what to do with and those two only scratch the surface on how your biz is doing. No offense, CAC and LTV, but we need to dig a little deeper. There’s one piece of the SaaS metrics puzzle we, HubSpot’s Sidekick team , rely on heavily and that’s gross margin-adjusted payback period. It might sound like total Greek at first, but payback period is a simple metric (it is, I promise) that helps businesses keep acquisition, retention, and conversion costs in check. When you spend money to acquire customers, you expect to make that money back ... one day. Payback period tells you how long it’ll take for that to happen and the \"gross margin-adjusted\" piece is a valuable filter for freemium products like Sidekick. (Payback) Time is Money Imagine you just bought a house and plan to rent it out. You paid a certain amount up front to purchase the property (let's assume you’re not taking out a mortgage) and will collect rent from your tenant every month. If it takes 100 years for you to break even, the property probably wasn’t a great investment. But, if it only takes two months, you'd be crazy not to make more of those investments, right? For SaaS companies, it's the same situation: we pay up front to acquire a user and if that user ends up becoming a paying customer, they’ll generate value back to the business over time. Knowing whether that’ll take 100 years or two months is crucial because subscription-based business is risky. You’re investing money that you might never see again; customers could churn before you break even and a good chunk of your users will never become paying customers. That’s why SaaS companies aim to get their money back quickly; a payback period of about 12 months is a good goal. That way, customers are paying for themselves and becoming profitable within a year. So, how do you figure out what your payback period is? Easy peasy. Divide CAC by your Monthly Recurring Revenue (MRR) per customer, (the amount customers pay for your product or service, like “rent” for a property owner.) If you don’t know what your CAC is, shame on you. There’s a good primer here for calculating it, but basically it’s just the sum of what you spend on sales and marketing in a given time period (e.g. advertising, commissions, salaries, overhead) divided by the number of customers you acquired in that same time frame. After that quick math, you’re left with the number of months it’ll take you to break even ... sort of. This is where payback period gets interesting. Money Costs Money Say you have to pay the electric bill out-of-pocket on the house you bought. Or, maybe you have to spend your own time maintaining the yard or dealing with the tenants. These are real costs that we call costs of goods sold (COGS) and they affect the margin of your property. Though you collect $Y/month on the property, you spend $Z of that to keep things running; you have to factor that into your equation for your payback period to be truly reflective of what your output is. This is where “gross margin-adjusted” comes in. Keeping a product up-and-running and on the cutting edge, especially as your customer base grows, is a big investment. In the SaaS world, our COGS aren’t electric bills or landlord to-dos, but hosting and customer support. So, while gross margin-adjusted payback period sounds scary, it’s really just how long it takes to break even given all the costs that go into acquiring customers (not just marketing and sales). Here's what it looks like in a spreadsheet: (fake data) You can see here that the gross margin is 68.8%, so to calculate our gross margin-adjusted payback period, we do the same equation as above only the MRR value should be multiplied by that percentage: 200/((240/12)*0.688) = 14.55 Not So Fast, Freemium For freemium businesses like Sidekick, factoring in gross margin is crucial for two reasons: we spend way less on \"traditional\" acquisition costs like sales and marketing, and most of users aren't generating any revenue. Naturally, those conditions are going to cause a kink in the payback period plan if we're only looking at CAC and MRR/customer. One approach we like for this scenario is to determine what the usage breakdown between free and paid users is and to split hosting, and any other COGS, between acquisition and expense. (fake data) In this table, you can see there are line items for hosting and support in two places: under Acquisition Costs and Acquisition Expense. The total cost of hosting, capital expenditure, and support are broken across the two categories according to the ratio of active usage in each of the \"Free\" (acquisition) and \"Paid\" buckets. In short, you get a nice adjustment to your numbers by accounting this way, but it’s really only fair if you’re truly running a freemium model where your user base isn’t valuable until you invest time and resources into getting them heavily engaged with your product. In an inside or field sales model the analog would be investing in marketing campaigns and sales touches - in freemium, on the other hand, those costs are replaced and your payback performance should take that into account. Putting Payback to Work Now that you’ve got your fancy new gross margin-adjusted payback period, how should you use it to drive your business and product strategy? The truthful answer is, well, it depends. Every company is different and will have their own approach to defining and using metrics like this. But, there is a simple takeaway here that can help align your sales, marketing, and engineering efforts: Use your payback time as a thermometer for your business to diagnose what’s working and what’s not. If your payback period is under 12 months, consider investing in and experimenting with new and/or increasingly aggressive acquisition approaches. On the other hand, if payback is getting away from you (18 months or more) you should consider choosing an internal metric that could be weighing you down and optimizing it aggressively. The candidates to hammer on here include: churn rate, acquisition costs, user or lead conversion rate, and your average sale price (ASP). When all the moving pieces are aligned and working, you’ll find your sweet spot. At the end of the day, you can become a landlord or an entrepreneur overnight but you won’t be very good at either unless you know your numbers. Hopefully, this was a helpful look at calculating payback period and why it’s so important for SaaS companies specifically. For more guidance on tracking SaaS metrics, check out this blog from David Skok and let me know in the comments what would be a helpful post to write next on this topic. Happy to do it (with the help of HubSpot’s finest, of course). How do you and your team determine whether your product and sales efforts are cohesively successful?", "date": "2015-05-07"},
{"website": "Hubspot", "title": "How to gain widespread adoption of your design system", "author": ["Julie Nergararian (She/Her)"], "link": "https://product.hubspot.com/blog/how-to-gain-widespread-adoption-of-your-design-system", "abstract": "Using documentation to cultivate co-ownership between design and development This post is the second in a series about HubSpot Canvas, our new Design Language. Read the first here . I came to HubSpot as a software engineering co-op just as a movement was growing. The design team had, over the previous months, created a gorgeous set of new typography, colors, and basic components that would become the cornerstone of a major redesign of our entire platform. But because there had previously been no single style guide — no single source of truth — that meant, in reality, that we needed to do a complete rewrite of our product’s front end. It meant that we’d need to disrupt the work of more than 40 teams and rebuild hundreds of pages with a completely new set of components in order to bring the redesign to life. I joined HubSpot’s front-end infrastructure team, the team responsible for crafting our internal build system and for supporting HubSpot’s developers in everything from testing to third-party dependencies. They were the natural choice to spearhead the redesign, so five developers, including myself, were dedicated to helping every team upgrade to our new design system, HubSpot Canvas. When I got my assignment, my first thought was: Best. Job. Ever. followed shortly by: Wow. This seems like a lot of work. And it has been a lot of work. But it would have been a lot more work if we hadn’t learned a key lesson along the way: Redesigns only work when co-owned by designers and developers. We cultivated this co-ownership, in large part, by building good tools and documentation. Our documentation acts as a source of truth for everyone on the team, and the tools that our designers and developers use mirror each other, giving everyone a shared language and making them partners in the stewardship of our design system. This is the story of how documentation not only helped us pull off a massive redesign, but grow better as a team. The Headwinds and the Tailwinds With any huge project, there are forces working in your favor (the tailwinds), and forces working against you (the headwinds). In our case, they were: The Tailwinds Our entire product was on a pretty similar tech stack. The JavaScript ecosystem can change in the blink of an eye, and I would never have expected a company of HubSpot’s size to be on the same stack. But a homegrown, developer-driven movement towards React and away from Backbone had been widely successful. This meant that teams could redesign their apps without moving to a new stack and that my team would be able to maintain consistency relatively easily. We already had the makings of a reusable component library and corresponding documentation tool. As teams started to move to React, one of our engineers had spun up a reusable React component library with easily maintained, coded examples that could be edited inline, which meant we didn’t have to start our documentation from scratch. The Headwinds Unlike our apps, our libraries don’t have a dedicated QA period. I had come from a financial software company, and I probably asked my tech lead where the QA engineers were 5 times in my first week before it really sunk in. Not only were we on the hook for doing our own quality assurance, but every change we made would be picked up by all future builds — and because our teams deploy more than a thousand times a day, this meant any changes to the components would go out to every app, immediately. We’d need a coordinated effort between the front-end infrastructure team and the product teams to ensure that every screen was ready when we launched, while also taking care not to unintentionally cause any bugs in the product. But as long as we moved quickly and kept it easy to revert any bad changes, we could minimize the damage. HubSpot Product is made up of small, autonomous teams. Teams at HubSpot have complete ownership over a piece of the product, with the freedom and power to research, iterate, and find solutions. We were worried that it would be tricky to implement a new design system aimed at eventual consistency with teams who had such a strong culture and history around autonomy. During the transition, they’d have to completely stop working on new features, and we’d also be developing the processes and standards that the whole team would need to adhere to going forward. There’s a delicate balance between supporting your coworkers with a system and taking away their creativity with it. But we were also confident that by removing low-level, repetitive problems from our coworkers’ plates, we could free them to channel that creative energy into solving bigger problems. Our worries were mostly unfounded. The teams, too, were ready for a system-wide redesign, because: No one had to change their stack or business logic. Inconsistency was dragging us down. Product managers saw it in user feedback. Designers saw it in the numerous shades of gray across our product. Developers saw it in way too many date picker libraries. A reliable, reusable component library built and maintained by another team sounded like a pretty sweet deal. Our new design system, HubSpot Canvas, looked good. Like, really good . From Project to Process When other companies do big redesigns, they’ll often unveil them with great fanfare, like pulling a sheet off a car — yesterday you had the old, and today you have the brand new. That wasn’t going to work for us. Our product and our product team were just too massive to do it all in one go. We decided instead to tackle parts of the product one by one, starting with those that had fewer users and moving progressively toward the core of the software. This process would be way less disruptive, and meant that we’d get to make improvements to the design system before it was widely adopted. We wanted to move fast, so we laid down some rules. We stressed that the first pass would only be a visual refresh — no new functionality. We wanted to repaint our house, not build an addition. If teams were adding new features while rebuilding their products, we’d drag out the timeline indefinitely. Using each design team’s initial work as a guide, we transformed a handful of existing components into a basic collection of responsive, accessible, browser-compatible React components. In order to get the work done quickly, we’d work inside teams’ apps and change over the components ourselves. But. It wasn’t quick. We only had five engineers on our team and were working in unfamiliar codebases, so work moved slowly. And worse, because we were implementing the design system, the app team didn’t get the chance to master the design language themselves, leaving them with an app full of pieces of code they knew and pieces that were totally foreign to them. We realized this redesign needed to transform from a hands-on project to a real process that teams could tackle on their own. So we started facilitating that process by providing support and by building out and maintaining the component library. We worked with the design team to have each product designer redesign their part of the product using a Sketch kit that contained all the elements of our design system. We then did a component review with each team as they started their redesign to look for potential new components, new variations, or new functionality for components that already existed. Then, my team created issues in GitHub so we could continue to collaborate across development and design as we built components, and so that each team could track the progress of the components they needed. We staggered each app’s timing so we could ensure that our team’s backlog didn’t slow down the progress of other teams’ redesigns. For a while, it was smooth sailing. As teams completed their redesigns, they went back to feature work, their apps full of shiny, new components. But sometimes, teams didn’t know how or when to use a component correctly, or whether a component’s behavior was intended or not. As they brought their questions to us, we were bombarded with queries and requests for clarification. We fell further and further behind as we tried to support the teams that were finished while also supporting teams in the midst of their own redesigns. The solution was pretty obvious, but it wouldn’t be easy. We needed better documentation. Creating a living style guide Good documentation is an easy sell. Every second spent writing a line of clear documentation saves you an incalculable amount of time in the future — time spent, for example, trying to remember that brilliant thing that was on your mind before you stopped to dig up a link to explain to your coworker, again, the difference between a tooltip and a popover. You should be spending that time on new problems, not problems that have already been discussed, solved, and settled. We knew we wanted our documentation to be: Easily discoverable. We didn’t want anyone to spend time creating a component or variation that already existed, or have to ask a gatekeeper where it lived. Relevant and helpful. It should be the definitive resource on design system, and everyone should be confident that they can find answers to their questions. Self-maintaining and automated so that nothing would become outdated. Planting the seed In order to get our documentation tool right, we decided to build it the same way we build products for our customers. We started by interviewing a variety of people the product team, both designers and developers, from those who had been at HubSpot for years to those who had just joined. We created a card sorting exercise where we printed out screenshots of existing components and asked HubSpotters to name the component, then sort the components categorically and name that category. Surprisingly, we discovered a big discrepancy between the language that developers and designers used to talk about our components. Developers would often refer to objects by their names in other front-end libraries and frameworks (like jQuery and Bootstrap ). Designers would usually refer to components by the names of their sister components in Google’s Material Design System . We found people using the same word for two very different components, or different names for the exact same component. Without fail, every designer or developer wanted fewer opportunities for design decisions to fall through the cracks between the intended user experience (the designer’s mockup) and the actual one (the developer’s implementation). And they knew ensuring that wasn’t the duty of design or development alone — it was everyone’s responsibility. Instead of building another component library focused solely on developers, we realized that we needed to build a resource that would become the hub for everyone on the team. That set of documentation and tools would forge shared ownership of the design system between designers and developers. We started by renaming a few components, adding tags to some components for easier discoverability when searching, and asking for suggested component names at the beginning of the component design process so that designers and developers could decide on the right name collectively. We also grouped families of components together based on their similarities — so now, for example, all components used for alerts and messaging can be found on the same page. In order to help designers seamlessly move between Sketch and the component documentation, we decided to mirror the navigation, structure, and terminology in the Sketch kit and UI Library, and developed a system for keeping updates to the Sketch kit and the UI Library in lockstep. Full bloom With the basics down, we then got to work making designers’ and developers’ day-to-day work much easier and more efficient by bringing the rest of the insights from our research to life. Developers mentioned often having trouble knowing which React component matched the one they saw in their designer’s mockup, so we added a layer of visual search, with real, automatically generated screenshots, to make it easier to find what they were looking for. They also needed a place where they could see all the options each component contained, and a place where they could find information about the component’s API, so we brought those front and center in the component description. Developers also needed a sandbox where they could quickly test components, so we improved the real-time editing experience for components in the library by including a React code editor with all of our components in scope (complete with syntax highlighting and Prettier capabilities). We also made it simple to move those examples into a distraction-free editor that also renders components instantly, so developers could use it as a space to build out the beginnings of a design or to test out a particular combination of components. Then, they could then easily share it with other HubSpotters, letting them quickly iterate, debug, and conveniently share ideas and proposed solutions. Designers needed a place to reference and share assets, so we created browsing pages for our colors, typography, illustrations, icons, and product copy guidelines, with a link to download the most up-to-date version of the Sketch kit. We also documented our full design process inside the UI Library to help new designers get up to speed. Neither designers nor developers were always sure which components would allow the user to complete a particular interaction pattern (like copying a URL, or progressing through a step-by-step flow), so we built pattern pages to explain which components and copy should be used in common user scenarios. We wanted to get more developers involved with the design language, so we shared guidelines for how they could create components, and started building on top of our basic components by combining them with our favorite open-source libraries. This provided the freedom to experiment with new tools from the OSS community, to add more functionality and productivity to our stack, and, frankly, to let all developers at HubSpot who wanted to create, create. Because we were aiming to make our components the visual foundation for all our front-end apps, that left a lot of room for (and need for) additional layers on top of them. These made the choice towards consistency trivial for our developers. To encourage people to interact with that documentation on a daily basis, we added buttons to propose a new component, suggest a change to an existing component, report a bug, or request an illustration, right from inside of the library. Those buttons pre-populate GitHub issues with the necessary labels and pertinent questions so that it gets queued up in our process. This gives new designers and developers a single point of reference for learning how to use the entire HubSpot Canvas ecosystem from their very first day. The Effect Now both our designers and developers share a source of truth for our design system and mutual understanding has increased. Greater trust in the documentation has shown stronger trust in the system as a whole. I was so proud to see this tweet by one of our front-end tech leads just a few weeks ago: We do a platform infrastructure survey for all our engineers twice a year, and since we started including questions about our UI Library, we’ve repeatedly gotten responses like this: 100,000/10 Oh god the frontend UI framework is gorgeous and light years ahead of any open source react ui framework Our work to make our documentation a thorough, living document will never be over, but feedback like this helps us know that we’re on the right track. See it for yourself Here’s a peek at how quickly you can start from a pre-made template, then build out a page using the sandbox editor in our UI Library. See how our developers can build the exact same mockup using the UI Library editor and our reusable React components. We’ve made a version of our HubSpot Canvas UI Library public. In it, you’ll find a subset of our components and styles, pulled straight from our production code. It’s a window into how we build our products here at HubSpot, and we’re sharing it because we’re proud of the time and effort we’ve put into creating our design system and optimizing it for developers and designers so that it stays evergreen. We invite you to take a look and share your thoughts — we can’t wait to hear them. Credits: Illustrations by Sue Yee", "date": "2018-02-05"},
{"website": "Hubspot", "title": "Defining the HubSpot Development Process", "author": ["Jeremy Crane"], "link": "https://product.hubspot.com/blog/defining-the-hubspot-development-process", "abstract": "One of the questions people ask about our product team is what software development process we use. Do you practice scrum? Are you an agile shop? Does HubSpot take a Kanban approach? Are you lean? (That last one feels a little personal, doesn’t it?) The answer is always: we don’t follow a process, we pretty much just solve for the customer. And every time, they roll their eyes. Our “no-process process” might not always be a crowd-pleaser, but it's really what works for our team. We’ve taken a ton of inspiration from people much smarter than we are to find an approach that sticks. Our biggest influence is Eric Reis’ Lean Startup model . Of course, we’re hardly a startup anymore. We found our core product market fit a long time ago; scale is the name of the game right now. So, we’re always iterating on our process and developing it as we go. The best way to describe what this process looks like today is through an analogy. In my younger, leaner days I did a fair amount of sailing; I loved being out on the water and racing with just the power of the wind. Looking back, I see some strong parallels between sailing and how we build products at HubSpot. The reality of sailing is that no matter how much you plan, measure, and study you can never truly know the conditions until you are actually on the water. The wind is different, the currents are different, and the waves are different than you had planned. Even your crew’s and your own physical and mental state is different than you had expected before stepping onto the boat. Water, wind and people are extraordinarily dynamic. But despite all of this, a good sailor can always get from point A to point B by using their instincts and instruments to find the right path. Every one of our small dev teams has a goal, their own point B. We spend a ton of time defining how we’ll know when we get there because these goals are a combination of a high level “what” and “when”. The what could be something as big as “build a CRM that a sales rep would love” or “make our blog editing experience more writer-friendly”. For timing, “by INBOUND” (our big annual conference) or “before July” are typical targets. As long as we all have a clear, shared definition of success, each team has the autonomy to figure out the best solution for reaching point B. Once we have a goal, the next step is to get out on the water. In our world, that means getting something in front of the customer as quickly as possible. Our instincts and instruments are qualitative and quantitative data from customers. Once we can get feedback on a product, app, or feature, we can learn and respond. Sometimes, that means we have to pivot and figure out a new route. Other times, there are no surprises and we can stay on course. That’s why we don’t believe in roadmaps and specs. They don’t allow teams to change direction based on the conditions on the water. Similarly, we don’t do sprints. Teams are hellbent on getting to a point of learning as quickly as possible so that they can come up with a plan. But you can’t put a timer on finding the right solution. A particular effort could take a couple months, others could be a couple hours. We don’t let artificial boxing of time define when we tack or change courses. This can make timelines and deadlines tricky. As I mentioned, we set very big, broad timelines for getting to point B and don’t define incremental deadlines for each team. It’s up to them to define milestones based on where they are. The beauty of this is that it helps teams get aggressive about not polishing the product endlessly. Done is better than perfect. Besides, there’s no such thing as perfect. This is especially true when it comes to development processes. This sailing approach is allowing us to scale and solve for the customer everyday, but that doesn’t mean it’s perfect for everyone. Companies have to find the process that floats their boat based on their goals, conditions, and team. For organizations that just want to get going and ship faster, agile may make a lot of sense. (My partner in crime over here at HubSpot, Christopher O’Donnell , had a pretty interesting tweet storm a few months back sharing his thoughts on agile processes. Maybe if we bug him enough he’ll write a proper post on the topic.) Our process works because it fits into our ecosystem of product development. Small teams, high levels of autonomy, engineering ownership, and a mission of solving for the customer are all key ingredients that make the sailing approach work. I guess “ship it” is a fairly appropriate mantra for us afterall.", "date": "2015-05-22"},
{"website": "Hubspot", "title": "Data Processing -- Be Afraid, Be Very Afraid", "author": ["Dan Milstein"], "link": "https://product.hubspot.com/blog/bid/6916/data-processing-be-afraid-be-very-afraid", "abstract": "So, here at HubSpot, and at my previous gig at Lookery , I've been writing a pile of Hadoop code to take log files, pull out key info, sum it up in various ways, and store the results. Overall, this has been a lot of fun, but I've developed a sort of healthy fear. Because of one thing: it's terrifyingly easy to make invisible mistakes. E.g. say you're counting up unique visitors from paid search ads on Google. You run it on a month of data. Your program churns along, and then spits out: 12335. And now we come to the problem: is 12335 the Right Answer? If you've been writing programs for more than about ten minutes, you've discovered that your code usually has errors. If you're writing something which generates a web page (possibly by talking to a db), you find those errors relatively quickly. Even, worst case, you release it with a bug, then some customer says \"Hey, when I click on thing X, it doesn't do what it should.\" This is Not That Bad. But with data processing, errors can linger for a while, and, worse yet, can easily infect all the numbers you're collecting. Invisibly making everything wrong. Then, later, your customer says \"Hey, why didn't these ads show up on my search marketing screen?\" And it's totally non-obvious at which stage of your multipart data pipeline things went awry. It's also not clear how to fix all the existing data you've already collected, which is now suspect. This is Very, Very Bad Indeed. Here's how I'm currently dealing with the Fear: Test-Driven Development is Your Friend Without tests, why on earth would you trust the 12335 above? Also, data-processing programs tend to be very simple to test, because they have defined inputs and outputs. You're going to be a whole heck of a lot happier if you start with with tests. Kill, Kill, Kill the Whole Pipeline This is a Toyota-inspired idea, and, again, differs from other kinds of coding. Basically, in any kind of error or unexpected situation, it's really good to just kill the whole pipeline immediately. This encourages the developers to immediately deal with issues, and work towards an entirely defect-free pipeline. The alternative makes it very easy for downstream data to become corrupted, again, in ways you can't easily remedy. Reentrancy Will Save Your A** Even with your careful testing, and your aggressive pipeline stopping, you're still going to get into situations where you need to drop partial data and re-run. If you can make sure that every step can be run multiple times without causing trouble, you're going to be so, so much happier. E.g. if you're writing to a directory in HDFS, blow the entire directory away and recreate the whole thing. If you're writing summary rows into the db, record enough info to be able to either rewrite entire rows or skip ones which have already been entered. That's my current set of takeaways -- anyone else have experiences on these fronts they'd like to talk about? === Update: the nice folks over at Hacker News point out that when I say \"reentrant,\" I really mean \"idempotent\".  They are, in fact, totally right.", "date": "2009-07-01"},
{"website": "Hubspot", "title": "Name Dropping: Tiana Veldwisch, Director of Carbon Product Management, Indigo", "author": ["Francesca McCaffrey (She/Her)"], "link": "https://product.hubspot.com/blog/name-dropping-tiana-veldwisch", "abstract": "Name Dropping is a Q&A series that aims to elevate the stories of women and nonbinary people leading in the tech space. The idea came from Angela DeFranco, a Director of Product at HubSpot, who said one way to be better allies is to name drop more women and nonbinary people in discussions of achievement, inspiration, and disruptors in tech, instead of referencing, time and again, the same set of (often male) leaders. This edition of Name Dropping features Tiana Veldwisch , Director of Carbon Product Management at Indigo . When did you realize you loved product management? I didn’t really know that product management was a thing until my role evolved into that sphere. As a student, though, I fell in love with stage management. I did a lot of theater in high school and college, and found that stage management was the right role for me out of all of the different pieces of theater that I tried: acting, costumes, props. Stage management was where my propensity for organizing and getting everything to happen efficiently and figuring out which steps needed to happen to get from point A to point B really shone through. I’ve since realized a lot of those same ingredients go into product management. It’s just that when I was graduating college in 2008, I didn’t know very many people going into this field. Certainly it’s more of a thing now. I joined a team at athenahealth at the time that was called Process Innovation. And we were essentially doing product management for some of the internal tools that our operations team was using. It just wasn’t called that until the org evolved over time. You have extensive experience working in the healthcare technology space, including your previous role as Senior Director of Product Management at PatientsLikeMe . What drew you to this field? I really just wanted to do work that helped people. I needed to make sure that the work that I was doing was with products, services, and solutions that really made a difference in people’s lives, whether it was a better patient experience or a better diagnostic tool. Mission-based work is really important to me. You’ve recently become Director of Carbon Product Management at Indigo, a sustainable agriculture company. What are some of the most exciting challenges your team is working to solve today? I think focus is always an important challenge of a Product team. There are always so many ideas and so many opportunities, but only so many resources to go around. I’m working with a product team that formed pretty recently, so I’m excited about helping them develop the tools and practices to do their best work and really collaborate well as a team and across the organization. You served on the Board of Trustees for Olin College , your alma mater. What would you say to other women thinking about applying to similar positions? Serving on a board, especially if it’s a board of a nonprofit or similar organization, is such a fantastic experience. And if you can get such an experience fairly early in your career, it can be super eye-opening. For me, it was a great way to make connections outside of the people whom I work with every day. The board at Olin is comprised of business executives and presidents or past presidents of colleges, all sorts of leaders from various walks of life, so different people than I tend to interact with, and who are, on the whole, further along in their careers than I am, so just learning from them about how they think about a problem, or where they see risks on the horizon that I may not even be thinking about was really interesting. It helped me with being comfortable with leadership and executives and learning how to interact with them and talk with them in an appropriate and respectful way. I think that translates to other places where I’m working with people who are more senior and more experienced than I am. So that was fantastic. They’re really great people, so they’ve been good connections to have generally for life advice and networking, too. It is a decent amount of work, though. So my advice would be to only take it on if you can devote the appropriate time to it. Especially for nonprofits, they’re really counting on their board members to be involved and active, so making sure you actually have the time to devote to it. I was on the board for four years, and I just ended my term back in October 2019, and for those four years it was a decent-sized extracurricular. When you think about the best product managers you’ve worked with, what characteristics did they embody? I think empathy is huge. You really need to be able to understand your users and feel what’s important to them. Not just what they’re trying to do, but where they are emotionally and what they’re thinking. What are they afraid of or excited about? That’s why curiosity is important, too. Wondering, why is it this way? Or what happens if we do this? How do other companies do things, even if they’re solving a totally different problem in a totally different industry? Willingness to look outside your walls and be curious and then being unafraid to ask questions is an important mix. Part of the product manager role is gathering inputs from a variety of sources and understanding all the different perspectives. The engineering side, the design side, and the business context. You need to be someone who’s not hesitant to ask questions and risk sounding silly. What is one quality that you think every leader should have in order to generate impact and lead effectively? Authenticity. Being real with people is so important, and that really garners people’s trust and makes people want to engage with you and go along on whatever journey you’re on. That’s something I try to embody as much as I can. I think people can see it when you’re not authentic. So you have to be real, especially when things are tough. Authenticity is less important when everything is rosy. When things aren’t rosy, authenticity becomes all the more critical. It’s also something that’s easier to convey in person, so leaders are facing this challenge now of how to convey your authentic self to your team and your peers while we’re only communicating remotely. Who’s one woman in technology you’d like to name drop and why? Brittney St. Germain . She’s been the VP of engineering at PatientsLikeMe for a little while — she just left. She’s a badass engineering leader and she can wrangle tough technology challenges but also tough people challenges. She’s super authentic, so you know that she’s being real. She doesn’t tip-toe around things, she’ll just tell you, this is the situation, and she’ll help you sort out what to do next. What’s one book you think every leader should read? Mindset by Carol Dweck is a really good one. And I think it’s a book not just helpful to workplace leaders but all leaders: coaches, scout leaders, parents. It’s a great framing of how, with some very simple language changes, you can either encourage people to really think about their growth, or to put themselves in a box. It really opened my eyes to how some of the words I thought were encouraging can actually be limiting, and how easily you can change certain phrases to help people to think in a growth-minded way. For example, Dweck talks about celebrating the effort that someone’s put into a project as opposed to celebrating one of their characteristics. Instead of saying “You’re so smart to have done that,” say “You put so much effort into that.” If you put more effort in next time, you can reach a higher level, but if you’re hearing “You’re so smart,” then you have a metric you need to live up to each time: either you’re smart or you’re not. You don’t want there to be so much risk associated with failing — you can praise effort given whether or not a person succeeds or fails in the end. What advice would you give your 22-year-old self? Give yourself permission to explore and be curious. I think too often at 22 we think, I need to get on this path and follow it. I have a destination in mind and I’m going to follow these steps until I get there . In hindsight, rarely is anyone’s path that linear. It’s a series of winding roads, bumps and pivots and changes of course. My advice would be to take a more adventurous and exploratory approach to early jobs and learn from everywhere. Know another woman whose name we should drop? Tweet us at @HubSpotDev with ideas. This article originally appeared on Medium .", "date": "2020-05-04"},
{"website": "Hubspot", "title": "jQuery Zoomer - Zoom up your iFrames", "author": ["Adam Schwartz"], "link": "https://product.hubspot.com/blog/bid/89755/jQuery-Zoomer-Zoom-up-your-iFrames", "abstract": "Zoomer is a jQuery plugin that scales an iFrame by some percentage. It is currently used to provide instantaneous, live-previews throughout HubSpot’s new email tools . Background When I started at HubSpot about a year ago, I was asked to design and build a Content Management System, or CMS. Whoa… I thought, in a Keanu-Reeves-in-The-Matrix sort of way. That’s a somewhat daunting task. Right away, we started building the page in which a user creates a piece of content, such as an email or blog post. After a bit of brainstorming and creating mockups, we decided on the layout pictured above. With this layout, we wanted to accomplish two goals: Make the editing/creation process smooth by providing a clear list of fields in a simple form, all on one page. Provide immediate feedback after any change the user makes by updating a preview that travels with the user as she scrolls down the page. The Problem In order to guarantee accuracy, and allow for keystroke-by-keystroke updating, we decided to use an iFrame. But, there wasn’t enough room on a page to display the form and a preview of another page. So, what if we could scale it down? The Solution First, it’s worth noting that scaling an iFrame isn’t trivial. Why not? you might ask. Well, if you want to scale an img by some percentage, all you have to do is set the width in css to that percentage. But if you set the width of a div , that won’t scale the text or images inside of it; instead only the width of the boundary will change. So we decided to use CSS transforms . CSS transforms allows elements styled with CSS to be transformed in two-dimensional or three-dimensional space. Unfortunately, IE 9 and less does not support CSS transforms. However, IE has two other ways of doing a similar thing using either zoom or DXImageTransform.Microsoft.Matrix : For Zoomer, we decided to use zoom as it suited our needs and is simpler to use. The core part of Zoomer uses these CSS properties to scale the iFrame. Unfortunately, simply applying these CSS properties to an iFrame wasn’t enough. Problems can arise if a user tries to click on an element inside the scaled frame; and very bizarre FOUC issues can occur while the iFrame is loading. So in addition to scaling, Zoomer handles these problems too, by shielding the iFrame with a transparent cover, and hiding the contents until the iFrame load event is called, and the scaling is complete. In addition, Zoomer provides methods for refreshing the iFrame or updating the src in such a way that no such FOUC occurs. I’m excited to announce that we’ve released Zoomer on GitHub under the MIT License. How to Use Grab the source. https://raw.github.com/HubSpot/jquery-zoomer/master/jquery.zoomer.js Put this one-liner in your jQuery onReady handler: Demo and Examples For a demo and full reference, check out the GitHub project page . Here is Zoomer being used in HubSpot’s template editor , and as a fun close, Zoomer being used to preview this very blog post (in our not-yet-released blog editor):", "date": "2012-08-23"},
{"website": "Hubspot", "title": "Customer-Driven Product Development: 6 Steps to Using Live Chat For User Testing", "author": ["Matt Bilotti"], "link": "https://product.hubspot.com/blog/customer-driven-product-development-using-live-chat", "abstract": "The use case for live chat on a website seems obvious at first glance. It’s a support tool that allows users to more quickly and painlessly get help from your team, rather than having to fill out a ticket or call. Here at the Signals team , however, we use live chat for one other very distinct use case: user testing. The beauty of live chat is that it creates an avenue for you to speak with users when they’re in the thick of their experience with your product. As I explained in my previous post, it helps you get to the real problem . In addition, you can actually use it for gathering both qualitative and quantitative -- if executed under the right circumstances. Why live chat for user testing? While it doesn’t replace the value of traditional user testing , using live chat for feedback is a quick way to accomplish a few things. You can: Get feedback on a wide or targeted range of the product Get engineers engaging with users and customers Keep the product team close to the end user Gather lots of data in a short period of time Unearth pain points or confusion Drive UX & UI product decisions with the user in mind Step 1 - Get the engineers accounts Everybody on the team should be involved. After all, it’s their product too and it’s important that everyone has an understanding of the ins and outs of explaining the product. Get all of your team members accounts on your live chat service (at Signals, we use olark ). Have them log in and leave it open in a new tab. Ask them to turn on desktop notifications or connect it with their chat client so it pings the corner of the desktop when a user messages the chat room. Step 2 - Pick a focus Choose which part of the product you’d like to focus on and open olark chats to display on all the pages relevant to that part of your web app. Making live chat available on all pages of your app can help you identify where the most pain is, where the most improvements can be made relative to the rest of the product, and allows for easier access to quantifiable data. If you want to get really targeted, create some javascript snippets that only display live chat for certain users and on certain pages. This could be greatly beneficial when you’re releasing a new feature, implementing a redesign, or just wondering how a certain page in your web app is perceived. Step 3 - Unleash the live chat Flip the switch and let the chats start pouring in. Make sure the olark settings are set so that one person, presumably the Product Manager or owner of user testing on the team, gets the all of the transcripts sent to one email account. This will allow you to make sure nothing falls through the cracks and get a feel for what types of things are coming in, overall. Step 4 - Hold about 200-250 chat conversations, then turn it off Now that you’ve collect a bunch of data points, you likely have enough to create a backlog for months. Unless you have the human resources to leave chat on, it’s best to turn off the beast and send people through your normal support flows until next time. Step 5 - Do some data entry Read all of the transcripts to get the true nugget of where the root of the problem is. Organize it in a spreadsheet. Break down the spreadsheet by section of the product, as seen in the screenshot below. Tally the frequency and take notes so that anybody on the team can reference the sheet and know what’s going on. Make sure the topics are short, concise, and to-the-point. We used conditional formatting so that any topic with a high frequency was colored, which helped us create a heat-map of the product. Step 6 - Prioritize and take action Outline the top few things; see what can be solved with a product change, what can be solved with a copy change, and what can be solved with a documentation change. Prioritize those changes and execute. The beauty of having the entire team on these live chats is that convincing anybody of anything is incredibly easy as you have the quantitative data to back it, quotes to serve as qualitative data, and they’ve all likely experienced each pain point themselves. Rinse, repeat When you conduct live chat through the lens of user testing, you can flip the switch anytime and gather data for your backlog that can span months of work. The goal should be to extract the highest-priority issues, act on those, ship fixes, and move on the next round of feature building and testing. Warning: Avoid creating negative experiences With live chat services, you're able to log in often to your web browser to start accepting chats. Once chats die out for a few minutes, it's often easy to forget you had it opened as you turn to do other work. This could spell bad news for customers if you have your chat client set up to automatically accept chats and don't reply promptly. If somebody sees a chat box, messages you, and doesn't get a response within about 10 seconds, you've immediately frustrated your user and given them good cause to feel neglected. Don't do that. -- Want to learn more about customer-driven product development? Follow my personal blog at http://bilotti.org", "date": "2014-05-16"},
{"website": "Hubspot", "title": "Impostor Syndrome: The One Challenge Developers Don't Talk About  ", "author": ["Matthew Clamp"], "link": "https://product.hubspot.com/blog/engineering-challenge-impostor-syndrome", "abstract": "Sometimes self-doubt can make you feel like a fake. You’re convinced you’re a fraud and that it’s just a matter of time until your co-workers find out you’re not as smart as they thought. Looking at your achievements doesn’t really help because you’re too busy internalizing your mistakes. If this sounds familiar, you might have something called impostor syndrome. You might also be an engineer. Software development is no stranger to impostor syndrome. Because tech stacks and languages are evolving constantly, it’s easy for developers to feel like we’re falling behind. Over winter break this past December, my aunt, before even saying hello, said, “Matthew, I read an interesting article about how everything you learned in college will be obsolete in two years.” Not exactly what you want to hear on vacation, but there's some truth to it. We’ve chosen a field that’s always changing and the pressure to keep up with tech, and our peers, manifests itself into this belief that we’re not good enough. Even though I’ve read a lot about this and why impostor syndrome is so common in developers, for awhile I thought I was one of the few who had ever actually felt this way. So I recently sent a survey to software developers (both at HubSpot and external) simply asking “Have you ever experienced impostor syndrome?” Here's what they said: That's an insane amount of yeses. Keep in mind the sample size wasn't huge, but still: 88% of developers said they’ve experienced impostor syndrome. Even developers with over 10 years of experience shared feedback that they worry about keeping up with technology, their co-workers, and the pace of development. For a 22-year-old developer with just 14 months of “real world” experience, this was (selfishly) good news. It meant I wasn’t alone; feeling like an impostor from time to time was actually “normal”. With Great Power Comes Great...Uneasiness For me, self-doubt didn’t really kick in until I had the opportunity to make mistakes. I worked closely with an engineer during my first internship at HubSpot who has over 3700 answers on StackOverflow and is frequently referred to as the resident Java guru. By my second day, I was given complete control over the project I would be working on. I was architect, implementer, and builder - I shipped my code as soon as it was ready. Today, these are the things that make our development process engaging and rewarding. But at first, that level of autonomy was scary. Having my code reviewed by one of the smartest people I’ve ever met was, too. I started to wonder if I had somehow fooled my tech lead into thinking I was smarter than I actually was. I waited for everyone to discover that I had gotten here by accident. But that didn’t happen. No one ever pulled me aside to say they were onto me because it was all in my head. Instead, I made a ton of mistakes, quickly learned from them, and slowly started to realize something that’s helped put me at ease over time. And that’s that being uncomfortable can be a good thing because when you’re complacent, you probably aren’t growing. Getting Comfortable with Being Uncomfortable I’ve interned with companies in the past where there was separation of state for the product. There were QA teams, there were architects, and there were two week iteration cycles. As an intern, I was constantly monitored and given mundane tasks that other engineers had passed on. I never really doubted myself as a developer because I never had to leave my comfort zone or collaborate with experienced engineers. The problem with that is that you have to be challenged if you’re ever going to get better at something. That’s as true of development as it is of tennis or playing the piano. Staying in your comfort zone won’t change the way you develop code. But challenging things, which for me were autonomy and smart people, will because you want to make sure your code is perfect before it’s in production. I now review my PRs four or five times before submitting them and pay closer attention to my code. That doesn’t mean I don’t still feel like an impostor from time to time; there will always be tons to learn and smarter people in the room. It’s just that I try to think of my internal doubts as growing pains. A Few Thoughts on Building Confidence Getting comfortable with discomfort has helped me deal with self-doubt. But on a day-to-day, that’s a lot easier said than done. So, here are concrete ways that have been key in building my confidence over time: Take Your Time: I think a lot of engineers, especially younger ones, feel this giant need to produce code and tangible advancements quickly. There’s so much emphasis on speed when you usually have much more time than you think you do. Take an extra hour or two to write more tests or review your code; it’ll save you time in the long run. Look, Then Ask: On my first day at HubSpot I got a bowl of cereal and milk, but couldn’t find a spoon. I sat and waited for someone else to grab a spoon just so I wouldn’t have to ask anyone where they were. I’ve realized since then that it’s ridiculous to be afraid of asking questions. Most people like explaining something that they know that you don’t. Just be sure to look before you ask because there’s probably some documentation or source code out there that can help, too. Give Yourself a Break: Development has a wide scope and you probably won’t master everything there is to learn. And that’s okay. In the survey, Josh Levinson, an engineer here at HubSpot said of some of our co-workers: “I might feel like an impostor when talking architecture with Hatchet, or code with Matt Ball, or math and analysis with Axe. But I’ve managed to internalize that just because I'm objectively below some people in one specific skill doesn't mean I’m not as skilled overall.” Instead of getting hung up on what you don’t know, try to relax and learn from the people around you. Look for Growth-Oriented Cultures: Impostor syndrome is, by definition, an internal thing. But managers and companies play an important role in how confident employees are in their work and skills. Take feedback, for example. I’m lucky to have managers today that don’t just say “You’re doing great,” but tell me what I’m doing well and how I can improve. There’s not as much room for second-guessing when you truly know how you’re doing. For less experienced employees like me, mentorship is key. Over the course of writing this post, HubSpot actually launched a new company-wide program for employees to get 1-on-1 guidance from leaders who aren’t their direct managers. If a company cares about helping employees grow, their culture will reflect that. When I first started writing this post, I felt (fittingly) nervous about putting myself out there. But then last week, during our annual INBOUND conference, our VP of Culture tweeted a quote from Seth Godin that resonated with me . During his talk he said: “The story you are telling yourself about your competence or incompetence, it’s all invented.” Instead of letting self-doubt craft elaborate stories in our heads, developers should remember that it’s okay to feel uncomfortable sometimes as long as it's not stopping us from taking on new challenges or eating a bowl of Cinnamon Toast Crunch.", "date": "2015-09-16"},
{"website": "Hubspot", "title": "Scaling People, Not Just Product: HubSpot’s Internal Conference Week", "author": ["Emily James (She/Her)"], "link": "https://product.hubspot.com/blog/epic-week", "abstract": "Over the past few months we’ve been planning our yearly internal conference, affectionately named EPIC Week (Engineering & Product Internal Conference Week). Each year, the team gathers together to run our own set of talks, programs and events that tie back to one goal: to learn from each other. It’s no secret that creating a world class company culture is incredibly important to HubSpot. But when you think of culture, you may not think of continuing education. Sure, we have ping pong tables and cold brew, but we also have an incredibly strong set of values that guide us, both as HubSpotters, and as folks on the Product & Engineering team . We believe that our best perk is our people. That said, we should aim to scale not just product, but also each other. We hire (and are always hiring) great people. It would be a disservice to the team for us not to capitalize on the immense knowledge and insights folks have and are constantly gaining regarding product, engineering and UX. We also believe in sharing openly and being transparent. We want to walk the walk and not just talk the talk when it comes to our core values . From that knowledge, and a desire to keep enriching our culture, EPIC week was born. What is EPIC Week? EPIC Week is our Engineering and Product Internal Conference that takes place over the course of four days each year. We’ve iterated a ton on the content and format over the years, but generally the bones of the week looks like this: 2-3 Keynote events Engineering talk series UX talk series Product talk series 2-3 miscellaneous programs This year we have 700+ attendees, and 60+ speakers and sessions running across our Cambridge and Dublin offices as well as remote. As HubSpot has grown we’ve been able to leverage Zoom for events like these and it’s made a huge difference for the remote experience. Everyone on the team, no matter where they live, is able to participate in EPIC week. What content is presented? There are multiple different talk tracks that we have running each day during the conference. We call this series the “Whiteboard Talk Festival” (yes, that is WTF for short). When EPIC Week first began many years ago, the WTF was only a small portion of the schedule. We’ve since expanded the WTF to cut across all 4 days and it’s the cornerstone event of the week. Here are our tracks and some examples of the talks in each: Engineering track Why You Don't Have GraphQL Yet Making Friends with Maven Charles Proxy: The Swiss Army Knife of Debugging App Network Traffic Product track Building and Executing a Vision Why Customer-Obsessed Teams Ship Better Products, Faster Product Rollouts, From A to Z UX track An Introduction to Screen Reader Audits Visualizing the Invisible Connections Within a HubSpot Experience Picking the Right Visualization for Your Data Non-tech track Fix Your Writing Meet Your (API) Customer | A Look into HubSpot's Developer Community Becoming a Better Engineer, Designer, or PM by Holding Opposing Ideas in Your Head Like I mentioned above, we have more than 60 talks in this series so this is just the tip of the iceberg but gives a great view of the types of content we aim to showcase during the week. How you could do this at your own company It’s likely not surprising to anyone who’s planned events, but EPIC week is a *ton* of work. We’ve iterated on this program for the past four years so luckily we have a lot of momentum around the event. Here are some tips if you want to get this started for your company or team: Get leaders bought in early. EPIC week is only possible because the Product & Engineering leadership team advocates for it. They encourage their team members to sign up to give talks and they support each other giving talks as well. Pick one goal for the week. One mistake we’ve made in years past is combining too many goals and then not achieving all of them. Or worse, having so many goals that you don’t achieve any of them. Our goal for EPIC week is to learn from each other. That means we aren’t planning social events during the week, or asking external speakers to come in. We’re able to target the content to that one goal. Seek out people who are passionate about continuing education and leverage their expertise to source and vet talks. If you’re planning a series like this, it’s likely you don’t know the ins and outs of each function. Planning and sourcing top quality content is not easy. Put team members from all different disciplines on the talk committee to help you ensure content quality is top notch. Hype it up! This is an awesome time for folks to stretch themselves through public speaking, or show off their domain expertise. If you have quality content, people will be really excited. So leverage that and have fun with it. This entire program wouldn’t be possible without the amazing people who work at HubSpot. If joining a company that takes learning within your role seriously is interesting to you, take a look at our openings. Maybe we’ll see you at next year’s EPIC week!", "date": "2019-11-19"},
{"website": "Hubspot", "title": "Git After It: Why GitHub Won When So Many Other Big Companies Failed", "author": ["Hannah Fleishman (she/her)"], "link": "https://product.hubspot.com/blog/git-after-it-why-github-won-when-so-many-other-big-companies-failed", "abstract": "Yesterday, Google announced they would officially be pulling the plug on open source project hosting service, Google Code. What launched ten years ago as an alternative to SourceForge never really grew up to be the social coding platform Google envisioned. In other words, it wasn’t GitHub. In their farewell blog post, Google wrote, “To meet developers where they are, we ourselves migrated nearly a thousand of our own open source projects from Google Code to GitHub .” This isn’t so much a failure for the tech giant as a win for the underdog. GitHub was a bootstrap startup about 7 years ago and now gets about 20 million visits a month making it one of the 100 most popular sites in the world. That’s hard to compete with. Even for Google. Google Code shutting down, suggesting repos move to GitHub. Amazing what a side project can become. http://t.co/9nYOA5SxCY — Tom Preston-Werner (@mojombo) March 12, 2015 By open sourcing HubSpot software and contributing projects , we’ve discovered bugs, learned new tricks, and helped developers build better apps. But beyond code, there are a few key ideas that got GitHub to where it is today that we can all learn from: (Sharing) Knowledge is Power The “democratization” age is real; hoarding ideas, information, or resources just doesn’t work anymore. GitHub was ahead of the curve by creating a free product that gave the developer community an outlet to innovate. They weren’t really concerned with who open sourced what or how it all tied back to their bottom line. What mattered was that developers were collaborating, making good products better, and learning from each other. Letting makers run with their ideas didn't put them at a disadvantage- it put GitHub at the core of the community. Making knowledge accessible is how you get to over 16.7 million code repositories. Culture and Product Should Hang Out Culture shouldn’t be separate from product development, it should be embedded in it. That continuity is a big part of what makes GitHub, GitHub. The reasons developers want to use GitHub, like the freedom to contribute to projects that look interesting to them and working with other developers from anywhere seamlessly, mirror the reasons someone would want to work there. GitHub has an ‘open allocation’ structure where employees get to choose what they work on instead of getting assigned projects and they’ve built a culture around communication and collaboration to scale that approach. It shows when a company's values, aspirations, and mission are reflected in their product. And just as much when they aren't. Drink Your Own Champagne It’s incredibly hard to get people using your product if they don’t trust you. Customers want companies to be an authority on what they’re marketing, selling, or building and easy indicator of that is whether or not they practice what they preach. Sure, GitHub hosts its own software on GitHub, but so do a ton of companies. The difference is, they’ve always gone a little further and created a dialogue around how they use GitHub, how they decide what should be public and what should be private, and why they’re after “open sourcing (almost) everything.” Whether its on their blog or one-off pieces of content about ' How GitHub Uses GitHub to Build GitHub ' (from former GitHubber Zach Holman), they try to be their best case study. Lastly, as we say goodbye to Google Code, be sure to migrate any projects over to GitHub. If you're not sure of the dates and timeline of the shutdown, just look it up. You'll always have Google.", "date": "2015-03-13"},
{"website": "Hubspot", "title": "What does a Product Manager do at HubSpot", "author": ["Jeremy Crane"], "link": "https://product.hubspot.com/blog/what-does-a-product-manager-do-at-hubspot", "abstract": "I recently published a post on our internal wiki describing the product management role at HubSpot. A good number of folks suggested that this would be great discussion for our external audiences as well, so here you go. What exactly does a HubSpot product manager do? This should be an easy enough question to answer, but in reality it's a bit more complex to describe than one might think. Part of the problem is that the product manager position is different in every company. There really is no one-size-fits-all way to go about the job, and that’s as it should be. Good product companies build engineering and product organizations that match their own unique cadence, customer needs, trajectory, market, and opportunity (among other things). And as your business grows and changes, so should your product team. We at HubSpot continue to evolve our product organization as circumstances change, but there are a few things that we hold fast to because we believe they set us up for success. A big part of that is the role played by the product manager. But in order to understand the product management role at HubSpot, it’s important to start by understanding the technical team structure as a whole. The Technical Team at the Center of the Universe In HubSpot engineering land, all things pivot around the idea of small autonomous teams. At the center of the team is the technical core, typically composed of a tech lead and two developers. The team is then rounded out by the addition of a UX Designer and a Product Manager. This team, as a group, owns their own designated product area. It’s important to note that the product manager is not the product owner. This is often the role of the product manager in other organizations, but we don’t believe that this is the best structure for our needs. The product manager co-owns that product area with his or her team. Product Managers at HubSpot are also not the day-to-day project managers of the technical teams. Tech leads are the project managers on the team. I’ll have more to say on that in a bit. What the product manager does own is what can be referred to as “the problem.” Every product team’s job is, essentially, to solve problems for their customers. Solving problems involves two key components: (1) Understanding the problem, and (2) creating the solution. At HubSpot the product manager owns the “problem” and the technical team owns the “solution.”  The “problem” is defined by whatever is likely to produce the greatest value to the customer and the business at large within the area of influence. The “problem” is both long-term and short-term in scope. It addresses the immediate challenges that the customer is experiencing, while still keeping an eye the longer-term vision of the product as a whole. It involves sifting through the myriad feature requests we receive from customers and identifying the often unnamed, as-yet unmet need that underlies those feature requests. It involves balancing the priorities between the things that are broken today with the things that need to be built tomorrow. This, my friends, is not an easy job. Truth be told, there are no easy jobs at HubSpot. If you have an easy job around here, my guess is that you aren’t doing it right. On the other side of the coin is the tech lead and team. Their role in defining the solution involves understanding the problem as deeply as they can. So the Product Manager serves as a resource for the technical lead and her team as they try to grapple with what the problem truly entails. The PM is a facilitator of the problem discovery process. Sometimes this is a simple matter of showing a developer the problem in the product. Sometimes it involves working with the resources at hand to engage directly with customers. After the tech lead and the team starts digging into the solution, the PM continues to serve as a resource. The PM is there to help the team determine the problem-solution fit. Have we solved the core use case? Is the solution the minimum viable product (if that’s the goal at the time)? Are we on track to add customer value? Improve EV? Is it ready to ship? These are the questions that the PM helps the tech lead and team assess as they work through their solutions. An integral part of the team puzzle is the UX designer. The UX designer owns the way in which the user experiences the solution. In many ways, the designer provides the bridge between the definition of the problem and the creation of the solution. He or she will work with the PM to understand the problem, then work with the rest of the team to find a design solution that fits the situation and the overall product. In the perfect world, the designer is just one step ahead of the tech team. To be clear here, product managers are not designers. Unlike PMs, who need to be comfortable being many steps ahead of the team, designers can’t get too far ahead of the team, or the solution they devise might become out of step with the problem itself. The HubSpot Product Manager Skillset So that takes care of what the PM does and doesn’t do within the framework of our team. But who are these PMs? What kind of person makes a successful PM? Again, this will vary from company to company. In some companies, being a PM requires extremely deep technical skill. Often this will be the case in an organization where the PM is driving the overall project management of the team. And in these scenarios, the technical team essentially reports to the PM. At HubSpot we leave that sort of management to the tech lead, and ask our product managers to focus on being champions of the customer instead. So what does it take to be a PM at HubSpot? Our most successful PMs are: Insight-driven and data-inspired Being able to make decisions quickly and effectively is paramount to PM success. Sure, it’s pretty dreamy when you have a pile of data staring you in the face with a blindingly obvious problem to solve. But most of the time that’s -- well -- just a dream. As a PM, you still need to be able to make decisions with the data you have -- or don’t have -- and still somehow establish a track record of making the right decision. Making snap decisions based on your gut can be dangerous, but sitting on indecision and letting your team get lost in a fog of obscurity is just as bad. You have to be the type of PM that understands the customer well enough to not get stuck on either end of the spectrum. Motivated by progress and guided by passion If you don’t love the product you’re working on, and don’t love making it better every day, then this simply isn’t the role for you. Your team needs to feel that passion emanating from you every day. Passion and energy are infectious. Able to see around corners Satisfying the current demands of your customers isn’t going to allow you to make the big leaps. The best PMs have a knack for being able to read the tea leaves and think about how to solve for or eliminate the customer challenges in ways that the customers themselves would never dream of. Multi-lingual I am horrible at learning languages. It’s just never clicked for me. Luckily, the type of multi-linguistics required of PMs has little to do with foreign languages. It’s about speaking the various languages of your business, customers, and team. The best PM must be equally comfortable speaking to customers, a sales rep, a support engineer, or a developer on their own team. No, you don’t have to be technical per se , but you do need to know enough about how the pieces fit together so that you can work with your technical team to find the best solutions you can. Always learning Product management, at its core, is an exercise in learning. You need to be constantly learning about what’s going well and what’s not within your realm of influence. Learning from customers, learning from developers, learning from competitors, learning from designers, learning from management... the list goes on and on. If you aren’t interested in operating outside of your comfort zone, you’re going to have a very bad time as a PM at HubSpot. Relentlessly focused on customer success We believe that the greatest enterprise value derives from our customers’ success. If you make your customer a hero, you win. Another way to think about this is that what you’re in the business of building isn’t a product, but a successful customer. Don’t think of the product as your baby. It’s really hard to give your baby a new face. And sometimes that’s exactly what you have to do in order to make your customer more successful. Get attached to your customers’ success rather than your piece of the product, and you’ll be on the right track. A product manager at HubSpot is a bit of a different animal than a product manager at another company, it’s true. But the PM role has evolved over time in tandem with the evolution of our team structure, and our understanding of how we can best serve our customers’ needs, into one that we believe works great for us.", "date": "2014-08-20"},
{"website": "Hubspot", "title": "Moving Faster with Packer to Build Images", "author": ["Tom McLaughlin"], "link": "https://product.hubspot.com/blog/packer-building-images", "abstract": "I used to hate building operating system images. It was an arduous process that took up too much of my time. I would put off building them as much as possible. Need a change? No, do you really need that change because I need to devote a few hours to this. Churning out a new image was a slow, error prone, and frustrating task and was a friction point at times between the our TechOps team and other teams. Now with the help of Packer they are an order of magnitude faster to create and much easier to reliably build. Below is how we got there. Building an OS image is easy, right? You just grab something from the AWS marketplace or if you want to get fancy maybe you create an image with a kickstart and use your own AMI.  That’s your golden image which you use for your instances.  Need to make updates?  Take the golden image, make your changes, and rebundle it.  Need to support different platforms?  Maybe you have VMware in your data center, you’re experimenting with cloud providers, and your developers want something they can use locally. You can get by building a VMware template, using a pre-built cloud image, and have a VirtualBox image that’s shared around. However we have our own set of requirements which made those processes unsuitable for us. They are: We retain end-to-end control of our golden image . We want full control of the image from its inception to deployment. Our image needs to be fully reproducible from scratch. If the golden image gets damaged in anyway we need to know how to reproduce exactly what we’ve been using. Images for all platforms must be as identical as possible. We want to ensure that an application's environment is predictable and does not vary by platform. Developers shouldn’t need to worry about what platform their application is deployed to. This is where Packer started to help us out. Packer is a tool for creating identical OS images using a single source template. Packer starts with builders that describes the process for building images. The builders section of the template can take a list of builder. An organization’s OS maintainer could for example list builders for VMware, AWS, and VirtualBox. Below is a template that specifies Virtualbox, VMware, and AWS builders. Each time Packer is run using this template it will produce three OS images. The next section of the template would be the provisioners . These are the scripts that would be run on each image after it was created during the builder phase. These can be anything from simple shell scripts to more complex configuration management like Puppet manifests or Chef recipes. If you’re familiar with RedHat kickstarts this would be like the scripts run in the kickstart %post section. Here you’re ensuring that all the images you’ve built go through the same set of configuration steps. In the example below we do familiar tasks such as cleaning NIC information and ensuring SSHD is locked down among other things. Finally there’s the post-processors section where after you’ve built and configured your images you put the final touches on them. One popular post-processors is the Vagrant post processors. This will take an image and package it into a suitable Vagrant .box file for distribution to your developers. Through plugins this section can be extended to perform actions like deploying an image to VMware vSphere or arching your images to AWS S3. Below our template is just creating a Vagrant box. Packer has made our process of making OS images far simpler than it used to be and it helps us to do so while maintaining the constraints we impose to make our environment more predictable. What was formerly a several hour process that required precise steps (not to mention repeated steps due to mistakes) is now handles by a few commands. We’ve even scripted Packer so that all our images can be generated with just a single command and no other developer intervention. This has freed us to experiment at a greater pace with new approaches to images and how we can make host deployments faster. No tool is perfect though. In another post I’ll write about how we scripted Packer to meet all of our needs. If you'd like to talk more about how we use Packer or other DevOps related tools, find me on Twitter at @tmclaughbos - I love this stuff.", "date": "2014-12-15"},
{"website": "Hubspot", "title": "Useful script for backing up MySQL on an Amazon EBS block", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/28112/useful-script-for-backing-up-mysql-on-an-amazon-ebs-block", "abstract": "At HubSpot, we use MySQL a lot (and more every day), and most of our MySQL servers live on Amazon's Elastic Cloud.  We use Amazon's Elastic Block Storage (EBS) storage service to store the database files and data. I wanted to point out a very useful set of scripts, from Eric Hammond and Assaf Arkin (my fellow Apache committer).  These scripts, one in Perl and one in Ruby, will take care of creating snapshots of MySQL EBS volumes for you, post the snapshots to Amazon S3 if you want, and discard old snapshots if you'd like. Eric's Creating Consistent EBS Snapshots with MySQL and XFS on EC2 , and Assaf's MySQL backups with EBS snapshots . I hope you find these as useful as we have.  Thanks, Assaf and Eric!", "date": "2009-10-17"},
{"website": "Hubspot", "title": "An Introduction to Big Data", "author": ["Christoph Koerner (He/Him)"], "link": "https://product.hubspot.com/blog/an-introduction-to-big-data", "abstract": "Big Data gained a lot of traction during the past ten years. You might have already heard about the MapReduce algorithm, seen the Apache Hadoop elephant or used a Hadoop Distributed File System (HDFS) yourself. If you’re looking to learn more about Big Data, you’ve come to the right place. This article is an introduction to a series of upcoming blog posts covering popular Big Data services used at HubSpot and across the industry, such as Yarn, Zookeeper , HBase, Kafka, Spark, and Presto, brought to you by the Email Analytics team at HubSpot. In this article, we’ll take a closer look at the foundations of Big Data and the use cases we have at HubSpot. We will cover the basic definition of Big Data, the secrets of scalability, and challenging analytics use-cases such as event processing and interactive analytics. Here at HubSpot, we use Big Data services to power many different parts of our product and to support data storage, processing, and analytics at scale. But what does this actually mean? What is Big Data? Before we jump into discussing the foundations for Big Data systems and Big Data Analytics, it might be useful to refresh the definition of Big Data. This will help you to identify when you are dealing with Big Data and choose the correct tools for your use case. While the term Big Data is often used as a synonym for large scale data storage and processing systems, its formal definition is very concise. Hence, before speaking about Big Data, it’s always handy to recall this definition, also called the 3Vs of Big Data: Data should be classified as Big Data if it is of high volume, high velocity, and/or high variety. Volume describes a large amount of data you want to store, process or analyze. In 2020, this amount could be anything from multiple GBs to TBs and PBs of data. Here is a good rule of thumb: If your data is growing by at least multiple GBs per day, you are dealing with Big Data. Velocity means a high data throughput to be stored, processed or analyzed; often a large number of records over a short period of time. In 2020, if you're processing thousands of records per second you might already be dealing with high velocity. Variety stands for the large amount of different data types and formats that can be stored, processed or analyzed. Different data types including binary, text, structured, unstructured, compressed, uncompressed, nested, flat, etc. should be processed and stored using the same system. However, data variety is often a consequence of Big Data rather than a requirement. A great example for variety is the highly scalable storage system HBase . It’s a distributed key-value datastore where both keys and values are simply byte arrays. The encoding is done in the application rather than the storage layer. Therefore it is often used to store images, audio, compressed data, json documents, or any type of encoded or raw data. At HubSpot, we store much of our application data encoded as Protocol Buffers in HBase. To recap, Big Data systems are systems to handle data of high volume, high velocity, and high variety; these systems are usually distributed systems that allow us to store and process data that requires high flexibility, high capacity and/or high throughput. Other definitions for Big Data vary slightly. You will find definitions with 4 or even more Vs, such as Veracity for example. Veracity refers to the trustworthiness of the data and hence describes how useful your data actually is. While these extended definitions are relevant aspects for Big Data, they don’t necessarily turn data into Big Data. Let’s take a look at how we can scale a system to handle Big Data! The secrets of horizontal scalability Big Data systems are distributed systems that allow for storing, processing and querying data of high volume, high velocity, and/or high variety. However, it’s a lot more intuitive to turn this statement around. In order to store, process, or query data of high volume, velocity, and variety, you need a distributed system. Let’s look at one example from the Email Analytics team at HubSpot. In order to perform analytics on email events data, we need a system that can handle the throughput of more than 30k messages per second (high velocity). The following figure shows a typical week of incoming event data to our analytics pipeline. Events in a Kafka topic Once the data is processed (cleaned, transformed, enriched, etc.) we need to persist the data for other consumers, such as customer-facing web services and internal applications. In total, we store 260TB of compressed event data (high volume) while supporting more than 30k writes and 100k read requests per second (high velocity). The following figure shows a snapshot of one of our event datastores. Events in an HBase table As you can see, both use cases require high scalability and high throughput. Ideally we would like to scale the system linearly — for example, doubling the amount of nodes to double the throughput or double the storage capacity. This is also called horizontal scaling as opposed to increasing CPU, memory, and disk size of individual machines (vertical scaling). Most Big Data systems and frameworks such as Hadoop Distributed File System and MapReduce have been built to allow for horizontal scaling for linear scalable data storage and processing. At HubSpot we extensively use Hadoop and Spark for data processing as well as Kafka for scalable message queuing and HBase for efficient data storage. In order to handle the increasing amount of data, write and read requests, we split all messages into multiple partitions using a partition key. The data is then distributed over multiple nodes as shown in the following figure. Partitioning allows for high write throughput In HubSpot, all data can be naturally partitioned by the HubSpot account id because the data will always be accessed by account. Within Email Analytics, most events can also be partitioned by email recipient or a Marketing Email campaign id. By partitioning the data we can distribute the write traffic across all nodes and hence achieve higher overall write throughput than on a single node system. Most Big Data systems handle partitioning out of the box as it is a requirement for horizontal scalability. Partitioning allows us to distribute data across multiple machines and hence allows for horizontal scalable systems. However, in order to increase availability and read throughput to multiple 100k per second we also need to use replication. By replicating partitions across machines we ensure that the same data is available on multiple machines. Hence, services can consume the data at the same time from different machines which allows us to scale read throughput. Replication allows for high read throughput Similar to partitioning, replication is a core technology of most Big Data systems and is often used to ensure availability and high read throughput. However, it’s worth mentioning that using partitioning and replication to improve throughput and fault tolerance comes at a high cost: namely, data consistency. This problem is better known as the CAP theorem, which limits consistency and availability of any distributed system. Analytical vs. transactional processing in Big Data Big Data systems are often used for data storage, querying, or data processing. These use cases can be categorized into two types depending on the write and read patterns: Online Transactional Processing (OLTP) and Online Analytical Processing (OLAP). OLTP-optimized query and storage systems such as HBase , Cassandra and Kafka are great for writing and reading individual records or small batches of records at a time. Stream processing systems such as Storm , Spark Streaming , Kafka Streams, or Flink that are used for per-record transformations and real-time (temporal) aggregations are also good examples for OLTP. In Email Analytics, we use OLTP systems for processing transactional events in our real-time data pipeline such as reading, writing, and updating the current state of an email send attempt. OLTP system optimized for reading/writing individual rows As OLTP systems are row-encoded, they are optimized for reading and writing individual rows. This is also what most relational databases do. OLAP systems such as PIG , Hive , Impala and Presto (when combined with Parquet , Arrow , ORC , etc.) on the other hand, are optimized for writing, reading and aggregating data from individual columns across many rows efficiently. They are often used for data warehousing, data analytics, and batch processing systems. In Email Analytics, we use OLAP systems for querying and aggregating event statistics such as the open rate of an email campaign for a specific group of contacts. OLAP system optimized for reading/aggregating individual columns In contrast to row-encoded OLTP datastores, OLAP systems use column-encoded file formats and hence are optimized for reads and aggregation of individual columns over a large amount of data. Many classical data warehousing systems such as Teradata or Oracle use this technology as well. It’s worth mentioning that some Big Data systems such as Druid cover both areas by providing high-throughput writes of individual records while enabling efficient OLAP-style queries through continuous file compaction. However, as implied in the CAP theorem, there is no silver bullet for Big Data and each system has its own tradeoffs. Let’s take a look at the most common analytics use case. What exactly is Big Data analytics ? Big Data systems are used to store, process, and query massive amounts of data, mostly batch and stream processing using OLTP or OLAP-based processing techniques. Let’s drill into the use case for analytics by looking at four different use cases of increasing difficulty in Big Data analytics: Historical Reporting Real-time Stream Analytics Real-time Interactive Analytics Behavioral Modeling and Forecasting The simplest and most common use case for Big Data analytics is processing of historical data, also known as reporting . In reporting we usually perform a relatively small number of long-running scheduled jobs that aggregate data stored in Big Data systems. A typical question to answer with reporting could be how many emails did HubSpot customers send in the past year using Starter, Professional, or Enterprise Marketing Hub tiers? In reporting, it is common to normalize your data into numerical transactional records⁠ — also called measures or facts⁠ — and dimensions containing aggregation keys (common examples are Star schema , Snowflake schema or Data Vault modeling ). While this helps to model historical data of well-defined schemas, it requires joining data at query time. In Big Data, complex joins involving network shuffles are the most expensive operations and hence reporting queries are typically slow. A query often takes longer than one minute to finish. The second most common use case in Big Data analytics is real-time event processing, often referred to as stream processing or stream analytics. In stream analytics, we extract and aggregate data over a short amount of time to compute real-time insights. A typical example of real-time stream analytics is Bot detection on email events . We do this by analyzing all email events such as sends, opens, and clicks of a recipient in a short time window (e.g. five minutes) and identifying abnormal behavior and anomalies. The third application in Big Data analytics is a combination of both previous methods, namely real-time interactive analytics. Interactive analytics is like reporting with real-time data ingestion and response times of less than one second. To achieve better query performance, data for interactive analytics is often denormalized . Good examples for interactive analytic use-cases are evaluating the number of recipients in a dynamic list ahead of sending an email campaign⁠ — including real-time properties such as recipient bounces , graymail suppression , and other dynamic properties. Another important application for Big Data analytics is behavioral modeling and forecasting. For this use case, we analyze the past to build a model that can predict the future. We often use heuristics, statistical methods (such as Linear Regression , Logistic Regression , etc.) as well as Machine Learning techniques (such as SVM , Gradient Boosted Trees , Deep Learning , etc.). A typical practical example is forecasting the amount of email campaigns for the next Black Friday weekend, classifying out-of-office replies or computing the best time for a recipient to receive an email. In Email Analytics at HubSpot, we are currently working on many of these use cases to help our customers send better emails and grow better. Summary To recap, we've seen that storing, processing and querying Big Data requires horizontally scalable distributed systems that let you process 100s of GBs of data and 10s of thousands of messages per second. We've talked about data volume and throughput, and how partitioning and replication allows for horizontal scalability. Depending on the use-case we choose OLTP and OLAP engines to answer some of the most complex customer questions at HubSpot. While we are working on the next article in this series — Introduction to Hadoop, from MapReduce to Spark — you can check out this video of Kafka Night at HubSpot about Confluent and HubSpot on Real-Time Data Processing . An earlier version of this post appeared on Christoph's blog .", "date": "2020-07-14"},
{"website": "Hubspot", "title": "Working on HubSpot's Content tools", "author": ["Samuel Siskind"], "link": "https://product.hubspot.com/blog/working-on-hubspots-content-tools", "abstract": "The Content team at HubSpot is always looking for engineers and designers who are passionate about changing the way marketers create and optimize their content.", "date": "2013-03-13"},
{"website": "Hubspot", "title": "We play dodgeball, eat falafel balls and drink highball cocktails", "author": ["Odette Santos"], "link": "https://product.hubspot.com/blog/product-team-playing-dodgeball", "abstract": "Last week the product team went out for a night of dodgeball, falafel and cocktails. Apply to join our team at http://dev.hubspot.com/jobs and join us for our next event!", "date": "2013-04-01"},
{"website": "Hubspot", "title": "Kafka Night: Confluent and HubSpot on Real-Time Data Processing (Video)", "author": ["Hannah Fleishman (she/her)"], "link": "https://product.hubspot.com/blog/kafka-night-confluent-and-hubspot-on-real-time-data-processing-video", "abstract": "Neha Narkhede is the co-founder and head of engineering at stream data platform company Confluent , and one of the original authors of Apache Kafka . Earlier this week, Neha joined us at HubSpot for Boston Kafka Night where she talked to us about Kafka's architecture, discussed how companies are leveraging it for advanced real-time data processing, and discovered Samza on the Rocks . Neha walked through the evolution of LinkedIn's data systems from an increasingly coupled architecture to separate systems linked with Kafka as a message bus. Similarly, Kafka is now an instrumental part of HubSpot's infrastructure. After Neha's presentation, two of our engineers, Ze'ev Klapow and Mike Axiak , spoke on how we've operationally integrated Kafka. Mike spoke about how HubSpot has dealt with availability and failover, and Ze'ev covered the consumer metrics we've developed to gauge our system's performance and health. Save the date: The Apache Kafka Summit is in San Francisco on April 26th, 2016.", "date": "2015-10-09"},
{"website": "Hubspot", "title": "Code Screen Problems Don't Have to be Unspeakably Terrible", "author": ["Anthony Roldan (He/Him)"], "link": "https://product.hubspot.com/blog/code-screen-problems-dont-have-to-be-unspeakably-horrible", "abstract": "Many software developers are familiar with a “ fizzbuzz ”-type problem in coding interviews. The idea is to ask a fairly trivial coding question of candidates to make sure they are competent coders. This can be done on-site, or in a phone interview format. Although well-intentioned, these kinds of questions are annoying and insulting for qualified candidates, can give false negatives as a result of trivial errors (especially if asked on a whiteboard) and are tedious for interviewers to ask. In recent years, many companies have forgone these dull onsite interviews in favor of automated code screening tools like CoderFights or HackerRank. These provide an online IDE in which candidates can solve programming questions in a browser. We used one of these for years - here’s the problem description we used: A palindrome is a word that reads the same backward as forward. For instance \"civic\" or \"deed\" are palindromes while \"toyota\" is not. Your task is to write a function that rearranges letters in a string to become a palindrome, or \"-1\" if it's not possible to rearrange to be a palindrome. For example: \"cecarar\" can be rearranged to obtain \"racecar\", which is a palindrome. \"aab\" can be rearranged to obtain \"aba\", which is a palindrome. Note that palindromes don't need to be real words from the dictionary. \"abc\" cannot be rearranged to become a palindrome. Therefore the correct output is the string \"-1\". You will receive an array of strings to rearrange. You should return an array of strings converted to palindromes, or \"-1\" if a palindrome cannot be made. That’s a reasonable technical problem to solve, but it has one very troublesome flaw: it looks absolutely nothing like the work we actually do day-to-day at HubSpot. We were finding that many candidates could pass a test like this which assesses basic coding competence but still were underwater when it came to the basics of building web apps. We’ve tried hard to make our interview process more closely match the environment of doing real work in other ways, like cutting any contrived whiteboard coding in favor of in-person coding questions exclusively on computers (ideally on the candidate’s actual laptop with their IDE and documentation of choice). So we wondered... could we do that for a pre-screen coding test too? What if we could create a test that could automate some of the assesment, but was in the realistic environment of writing code in your language of choice on your own machine rather than the rigid web-based IDE? Turns out, yes. Well, we think so at least. As of mid-last year, the coding project we use isn’t through a test provider, but instead an API and associated documentation. We email a start link to a candidate with a link to an overview page. Once they land on the page and click through to start, we provide the documentation on how to use a source API, and provide a spec for how to transform the data from that API and send it back to another API. We start a timer when they click start, and when they send in the right response (or run out of time), we send an automated email with a link to upload code. Here are the rules we provide: This gives us a “semi-automatic” assessment - we know if candidates are able to complete the problem in time, but lets us dive into the code as well. Best of all, it lets us give candidates a problem which looks a lot like a problem we actually deal with all the time: take data from some API, perform some processing, and send it to another API. It’s way more realistic, less anxiety inducing, and ultimately far more reflective of candidates’ ability to work at HubSpot than assessing identification of palindromes. We send out anonymous post-interview surveys to candidates after they interview, and here’s some real, uncensored feedback we’ve gotten: \"The written technical test was, by far, the best technical test I've ever done; it was clear, concise, challenging but also reassuring given you know that your solution works at the end.\" \"I really liked the challenge! I believe it really shows both the knowledge of data structures & algorithms, and web development skills of the candidate. While looking for a summer internship, I've completed a lot of challenges and code tests but this was by far the best.\" We’re happy to be part of the trend of moving software engineering interviews away from riddles and CS puzzles and more toward real, practical work. If that kind of a process sounds cool to you, we’d love to get to know you better and show you firsthand - we’re hiring software engineers to work on a bunch of problems that have nothing to do with finding palindromes.", "date": "2017-05-11"},
{"website": "Hubspot", "title": "Practical Advice for New Software Engineers", "author": ["Ernie Park"], "link": "https://product.hubspot.com/blog/practical-advice-for-new-software-engineers", "abstract": "A big part of writing great code is the series of “aha!” moments we have on the job that teach us to solve problems faster and more effectively. For engineers that are just starting out, getting a head start on those inflection points never hurts. So from one engineer to another, here are some learnings and hacks I’ve collected over the past few years on everything from the dangers of abstracting to why we should all be rubber duckies from time to time. Ask For Feedback Early Try to get feedback on code as soon as it makes sense. If you're working on a Pull Request flow like we do at HubSpot, make a trivial change just so you can open the PR and have a place to discuss design and code. It's faster and takes less energy to iterate on prototypes than a 'finished' product. Depending on how your team is structured, getting immediate feedback might not mean writing code at all. Mockups, whiteboard wireframes, and sketches are a lot cheaper to throw out than hundreds of lines of code. Be a Rubber Ducky, Find a Rubber Ducky Have you ever talked to someone about a problem and realized the solution as you were describing it? In these situations, the person you’re talking to is a real life rubber ducky . Thinking out loud gives you clarity around a problem so everyone on your team should be open to being a sounding board, including you. Having rubber duckies to lean on will help your team work through problems faster and move on to the next challenge. Get End-to-End First When working on a new problem or feature, it's easy to dive right into the nitty gritty details. Instead, I've found it’s better to get end-to-end as quickly as possible (or alternatively, to a \"Hello, world!\"). For example, say you need a user click on a web page to trigger a complicated calculation and then save some results to a server. It’s tempting to jump right into figuring out the meaty calculation. A better approach is to set up the event handler for the user action, mock the calculation with some fixed values, and then fire the API request to the server. That way, you can test the system end-to-end before working out every detail and there’s a feedback loop to help you iterate and code faster. The design might not be perfect at first but by seeing how the pieces fit together, you get a clearer picture of the full system you're trying to design. We take this concept even further with HubSpot's development process by pushing features to production before they're even finished so that we can test them internally. Our gating infrastructure makes this possible, but more on that another time. Step Away From the Keyboard Sometimes putting in debuggers, console.logging everywhere, and just bashing at the keyboard is a good way to test code. Other times, when you're having a tough time managing a complex design or problem, you need to stop looking at your screen. I’ve come up with solutions and have had some of my best insights in the bathroom. Silly, but true. My wife, who’s also a software engineer, does her best thinking when she’s falling asleep. (HubSpot actually has a nap room for that reason.) So get some rest, go for a walk, or read a book. Just find ways to think away from your computer. Automate To Get More Done It's not a secret that efficient developers automate many of their tedious processes. But there’s a common misconception about automation that it's only about saving time. While that’s one important benefit, automation gives you the chance to chase a train of uninterrupted thought and increases the likelihood that a task will actually get done. For example, say there was a long, complex SQL query you needed to run frequently to get some metrics. You’d be much less inclined to run the query if you had to type it every time. But if you saved the query on your clipboard using a program like Alfred , or somewhere else that’s easy to access, you’d probably run the query often instead of putting it off. Automation doesn’t just help us get tasks done faster, it helps us get them done when we otherwise might have avoided them altogether. You Can DRY Off Later It's tempting to write perfect code and figure out every abstraction when you're designing new code. But abstractions can be dangerous. They can slow you down on a new project, even when they seem obvious and easy to design. So rather than abstract right away I simply copy and paste large chunks of code while I’m prototyping. It helps me move quicker at the start of a new project and usually reveals better abstractions and concerns than I would have discovered on a piece of paper or whiteboard. The caveat though is that you actually have to clean up the code before it rots. Stay Active Coding doesn't burn too many calories so it's important to force yourself to stay active. Get a good stretch in a few times a day and walk around from time to time. We have a push-up club at HubSpot that does push-ups together before lunch three days a week. It helps to keep the blood flowing throughout the day. Sitting for long periods of time causes a lot of developers (myself included) back and shoulder pain. If you have this problem I strongly suggest trying a standing desk. We have motorized desks here that switch between standing and sitting height, and I bought a cheap standing desk on Craigslist for those work from home days. Anyone who works at a desk most of the day should prioritize staying active in one way or another. Read Ahead Reading documentation, technical articles, and code can be confusing and maddening. Before flailing your arms and scratching your head, read ahead and get more context. Programming concepts are difficult to express in a linear form but by jumping ahead you can get a better handle on what a previous sentence or code snippet is talking about. Take Meticulous Notes This tip might not jibe with the less organized devs out there. I take detailed notes in Evernote every day about what I worked on, the problems I encountered, and how I solved them. Setting aside time daily, or even weekly, to write a quick status update will help organize your thoughts so that you can revisit them in the future. These notes are invaluable when you're facing a problem you’ve solved before but can’t quite remember how. They also have the added benefit of making it easy to recall your accomplishments next time a performance review or 1-on-1 with your manager or comes around. Plan for Tomorrow, Today Finally, before going home for the day or when you get home at night, make a to-do list of everything you’ll try to accomplish the next day. That way, when you get to work in the morning, you’re focused and have a clear agenda to hit the ground running with. Personally, getting a good, productive start to the day often sets the right tone for the rest of the morning and afternoon. What lessons and hacks have helped you become a better engineer? Share your advice in the comments below or tweet us at @HubSpotDev .", "date": "2015-08-17"},
{"website": "Hubspot", "title": "Why We Made the HubSpot CRM Free", "author": ["Brad Coffey (He/Him)"], "link": "https://product.hubspot.com/blog/why-we-made-the-hubspot-crm-free", "abstract": "When we launched the HubSpot CRM at our INBOUND conference last year, one of the most buzzed-about aspects of the announcement was how much we planned to charge for it: nothing. As we celebrate the product coming out of beta and over 60,000 users on our sales products combined, I wanted to share why we made the CRM free and how we got this decision to work. When our product team started building the CRM, the truth is that we didn’t have a price tag in mind. We simply wanted to see if we could create something useful and meaningful for our customers. But as we explored the market, the need for a solution in this space kept presenting itself. From a culture perspective, giving the CRM away for free wasn’t a crazy idea. Our overarching mission is to solve for the customer and the entire inbound movement is rooted in the idea that the size of your brain matters more than the size of your wallet. We didn’t want a product that would only be valuable to our existing marketing customers or to companies with big budgets; we wanted one that would empower any business to grow. The simplest way to remove any barriers to smarter prospecting was to make the CRM free to everyone. Growing the number of visitors, leads, and customers is a goal shared by thousands of companies HubSpot reaches every day. But many of them don’t use the core, modern tools to engage with those prospects effectively. These companies are relying on email, spreadsheets and their memory to move their deals through the sales process. They simply don’t have a CRM -- and they should. We found that cost and complexity were the big inhibitors of adoption. Passing the Free Test Delivering on our promise of helping businesses grow sounded great, but we needed to know that this idea would work from both a cultural and business perspective. Could the CRM actually work as a free model? To figure this out, we tested the product against four criteria that I think are fundamental to any successful, free product: 1. There needs to be a ‘simple promise’ that’s widely applicable. For free products to work, the value proposition needs to be incredibly easy to understand. You shouldn’t need a sales person or expensive marketing campaign to articulate it; this is the simple promise you’re making to customers if they use your tool. This promise also needs to be widely useful. How’d we do? The CRM is a simple sales platform to help you grow your business. It’s a product that every company with a sales funnel needs. That's a simple promise for a mature, well-understood market. 2. The product must be easy to adopt. We built this initial product for people that aren't already using an existing CRM. To turn non-consumers into consumers, it had to be easy for them to sign up, get familiar with, and start using right off the bat. It had to have a great ‘single player mode’ so that one person could sign-up and start seeing value. If you have a free product that requires sign off from the CEO to use, it’s going to be impossible to get traction. How’d we do? This has been the most difficult test for us to pass. Most CRMs take months to setup. There’s an entire consulting industry built around helping companies build and optimize their CRM implementation. We need to radically avoid this standard, and we continue to make strides here in combination with our Sidekick product. 3. There must be a path to monetization. The allure of free products are seductive but rarely profitable. Free lowers the barrier to get started and is the path to massive, massive adoption. This can lower the cost of acquiring customers (CAC), but the economics need to work in creating and sustaining the lifetime total value (LTV) for those customers. Simply put: there needs to be a path to profitable monetization on a per unit basis. How’d we do? We have a unique opportunity to monetize the CRM effectively for two reasons. First, because we already have thousands of customers on our platform, we’ve solved many of the cost and scaling issues that would otherwise make delivering a free CRM cost prohibitive. Second, we already sell software. Our inbound marketing platform is an effective way to get more leads into your CRM, and works great with the CRM. It’s a great upgrade path for CRM users creating sustainable LTV. 4. There should be benefits to wide adoption. Free models can work as a step in the sales cycle, but typically aren’t as effective as free trials or other inside sales models. However, that changes when the value of adding more free users increases value for the rest of the user base. Said differently -- free makes sense when there’s a network effect. How’d we do? One opportunity we’re excited to explore is the benefit the free CRM user base will have on our integration partners . While adding more users to the CRM doesn’t have direct impact on other users, it creates more opportunities for us to attract meaningful partnerships that then create value for our users. It could become a virtuous loop, like we’ve seen with our marketing platform. It’s early but we’re excited about what the future can hold here. While our CRM passed the test, the opportunity for free wasn’t obvious; the answers above are not without holes. These concerns (and more) were brought up during the hardest part, arguably, of getting an unconventional idea off the ground: getting the rest of the organization on board. Taking Uninspired Compromises Off the Table At most big companies, this is when a lot of bold decisions get watered down. Getting everyone bought in on a big (and potentially risky) idea at a small startup means you have to get a handful of stakeholders, or less, on the same page. But as that startup grows to 100, 200, or even 800 people, the chance that every leader across the company will be in favor becomes less and less likely. In this environment, remarkable ideas turn into average solutions as you tweak and tweak them to satisfy every concern and objection. These are what we call uninspired compromises. When we proposed giving the CRM away for free, nearly every leader across the organization had a good reason for why it could be problematic for their department. Finance, sales, services, and beyond could make persuasive cases for charging for the product. So, we focused on articulating the vision, assigned an owner to the decision and opted to make an inspired decision. By applying those four free criteria to the business and tying the idea back to our overall mission of solving for the customer, we were able to take a remarkable bet and truly solve for our customers. We’re excited about the response from our early users and to see more and more businesses grow on HubSpot’s free CRM. Thank you to our customers, users, and community for helping us reach this milestone with our sales products!", "date": "2015-06-30"},
{"website": "Hubspot", "title": "Gatekeepers and Gardeners", "author": ["Jared Williams (He/Him)"], "link": "https://product.hubspot.com/blog/gatekeepers-and-gardeners", "abstract": "Balance is an integral part of every job. We have to balance our priorities at work and our lives outside of work. We need to balance the time we spend building with the time we spend maintaining. We need to balance the needs of our teams with the varied needs of the rest of the organization. And that’s just the start of it. Never does this become more apparent than for new tech leads - we see it all the time at HubSpot. When they step into the role, they usually find themselves with new (sometimes competing) priorities. I often hear that they're not sure if they're spending their time as well as they could. And when new tech leads lack balance, they might end up losing sight of what success for themselves and their teams should look like. When you're a tech lead, you have a diverse group of engineers, a product manager, a designer, a product expert, and user researchers you work in partnership with. And you have pull requests, JIRAs, alerts, migrations, and other teams begging for your attention. Oh, and you have an evolving, interconnected product mission that your team should be working towards. And through all this, you’re supposed to be helping your engineers grow…and you have this nagging feeling that you’re not getting your own work done, and maybe even that you’re no longer growing yourself. Whew. Somewhere along the path of leadership, new tech leads can become overwhelmed, exhausted, and burnt out. How does that happen? In many cases, it’s because new leaders end up focusing too much on trying to control their domain. They almost always do this with good intentions. But it’s easy to pick up responsibilities that we conflate with success in our roles that don’t lead to success at all. To manage, new leaders often adopt the role of a gatekeeper early on and have a hard time letting go. What is a gatekeeper? A gatekeeper controls the flow of information in an attempt to narrow focus and avoid surprises. I often hear new managers who adopt this role describe themselves as a “shit shield.” A gatekeeper might: review all of their team’s work to ensure quality and consistency handle all the task management, prioritization, and design so the team can focus on their day-to-day work have conversations on behalf of their team get in front of every decision to help ensure that their team doesn’t make mistakes take on the grungy work themselves so that their team can focus on more appealing work You might be a gatekeeper if: your team regularly waits for you to review their PRs your team waits to do the next thing assigned to them instead of taking initiative to find projects for themselves you hesitate to go on vacation because you’re concerned your team will struggle in your absence While gatekeeping can often be detrimental to a team, this leadership role is extremely helpful for new members of a team or for someone new to a skill. For those folks, too much information can be overwhelming, and it’s unlikely they’ll have the context necessary to handle all of their tasks independently. Helping them digest their projects and giving thoughtful review of their work benefits both that person and the team, because too much autonomy could result in them getting stuck, going down the wrong path, creating more work for the team, and probably feeling like an imposter . By reducing autonomy, they can focus on skill growth and be protected from mistakes and outside forces. But if you remain a gatekeeper as an individual contributor grows, they might end up underexposed. Their potential will likely be squandered. And you’ll become overwhelmed if you continue gatekeeping for your whole team as it expands. By not encouraging your team to grow, you’ll get stuck. So how do you fix it? Well, you need to become a gardener. What is a gardener? A gardener trusts, encourages autonomy, and exposes their team to higher level problems. Gardeners turn scaling and growth into a team sport. A gardener might: forego reviewing work, or let other members of the team take on the responsibility let the team handle their own task management, trusting they understand the needs of the customer, business, and team encourage members to build relationships on and off the team let the team experience failure, trusting in their accountability to fix their problems and learn from their mistakes have their team take on grungy work along with the \"fun\" work, because they understand the value of it When you’re a gardener, individual contributors are trusted to know when to ask for guidance, request feedback, and, for the most part, self-review and make their own decisions. In general, we should bias towards being gardeners as long as we’re not giving too much autonomy too soon or setting our team up for failure. Like with situational leadership , you need to match your style to the individual’s skills and experience. When to gatekeep and when to garden A good leader will understand the right time for gatekeeping and gardening, and determine the right approach for each member of the team based on their individual skills and areas for growth. When a new individual contributor joins the team, you should assume that they have high potential, but you shouldn’t assume much else. On their first day you’ll be a gatekeeper, and become more of a gardener as they grow and become more comfortable with their day-to-day responsibilities. You should guide this process with checks and balances. As they start to succeed in small, prescribed tasks, they can move on to slightly larger tasks that aren’t as well defined. If they struggle, use it as an opportunity to show them how to think through the problem or introduce them to resources that will help them work through it themselves. Exposing members of your team to your thought process or your understanding of the task will help them build a mental model that will help them with their future work. In doing this, you’ll chart a course towards autonomy without swinging too wildly in the either direction. By modeling successful practices, you’ll end up sharing the behaviors that you’ve nurtured to successfully grow in your own role. And as you transition from a gatekeeper to a gardener, you’ll allow them to follow a similar trajectory in their roles. Their growth will lead to increased autonomy, and their autonomy will free you to focus on the problems that are most important to you. In this, you’ll create a virtuous cycle of team growth. By becoming a gardener instead of just a gatekeeper, you solve for the team, solve for yourself, and help scale the organization as a whole. Gardening helps grow your organization’s future leaders. It opens you up to new opportunities as you create the potential to replace yourself in your role. It helps you accelerate the careers of everyone on your team by encouraging them to work on bigger, harder problems. And while there is some danger in encouraging new responsibilities at the wrong time - you should expect to find and learn from failures along the way - pushing yourself to become more of a gardener over time is crucial to avoiding burnout. If you’ve found yourself questioning how to find balance in your role as a new leader, look at your team and the responsibilities you’ve assumed and think deeply about areas where you’ve become a gatekeeper. In some cases, it’ll make sense to keep things as they are, but in others, start trying to understand what it will take to boost growth in those around you. Eventually, you’ll to get a point where you can start opening the gates. And good things will be waiting on the other side.", "date": "2017-10-12"},
{"website": "Hubspot", "title": "New Open Source Nagios Plugin For Checking JSON Web Services", "author": ["Stephen Huenneke"], "link": "https://product.hubspot.com/blog/bid/71188/new-open-source-nagios-plugin-for-checking-json-web-services", "abstract": "We're starting to release some of the Nagios plugins we've written or modified internally for wider use.  The first one is a handy tool for checking JSON web services response values via Python 2.4+ utilizing the simplejson module.  It's faily simple at the moment but expect threshold and timestamp matching to come in the next few weeks.  Follow the updates on our GitHub repository: https://github.com/HubSpot/HubSpot-Nagios-Plugins This plugin was a fork of work previously done by Peter Kropf , and is hosted at https://github.com/pkropf/Nagio-Plugins/tree/master/json The main use for this was to create useful status checks on our existing JSON API's (check out docs.hubapi.com for more info on those)  through the actual mechanisms they use to deliver normal responses.  Other Nagios plugins offer you the ability to check for strings or regular expressions, which does part of the job, but we wanted to make sure the status returned was properly serialized JSON and that it used the same code that serves data to non-monitoring requests.  Future improvements mean we can monitor error rates and timing information from the service directly and not have to add circuitous checks on logs or other items through slower aggregation techniques.  And of course, better monitioring means better information which leads to better quality software which ultimately leads us to happier customers!", "date": "2011-08-11"},
{"website": "Hubspot", "title": "5 Whiteboard Coding Tips for Interviews", "author": ["John Nagro"], "link": "https://product.hubspot.com/blog/5-whiteboard-coding-tips-for-interviews", "abstract": "Whiteboard coding is a standard part of technical interviews these days. Candidates focus on preparing for questions and forget to practice delivering their responses. Interviewers use whiteboard coding problems to evaluate how a quickly, clearly, and concisely candidates articulate their designs. Common factors in a unsatisfactory interview performance are writing messy code, running out of space, and forgetting essential parts of the question. Keeping a few common-sense simple tips in mind can help a candidate avoid these pitfalls during an interview. 1. Write down the question. Write down the problem in its entirety and read it aloud. Writing the problem on the board provides a reference which avoids confusion and wasted time. All too often candidates anchor onto one part of the problem and begin coding with an incomplete or incorrect understanding of the question. 2. Write down examples. After taking the time to understand and record the question, distill that understanding into some examples. Written examples are an easy way for candidates to verify their understanding of the question with the interviewer. Examples also allow candidates to explore interesting test cases quickly. Some interviewers expect a small test suite along with the answer but, written examples are often enough. Candidates should use these examples when they walk through their final answer. 3. Take time to write clearly. The candidate's ability to articulate their ideas clearly is necessary because, a large part of any interview is to judge how well the candidate communicates. Writing clearly not only allows the information to flow more freely but, allows the candidate to more quickly spot their own errors. Writing code by hand can be tricky even without doing it on a whiteboard. A candidate can improve their legibility by writing slowly. Legible writing also allows the candidate to write with smaller font, which saves valuable space. 4. Use double-spaced lines. Adding space to make small changes can save time and avoid messy code. Very few candidates write a perfect answer without making changes. Interview answers typically evolve with multiple passes over the same code. Even when candidates provide a complete solution, the interviewer will often further complicate the question or have the candidate optimize their answer. Candidates who use double-spacing in their answer can quickly add extra variables, branching statements, and other changes without needing to rewrite large portions of the code. 5. Use the space provided efficiently. Candidates should make efficient use of the board space by starting in the upper-left corner and working down and right. It is difficult to judge the amount of board space a long-hand answer to a coding questions will consume. Most interviewers will also evolve the complexity of the problem throughout an interview, which also changes the amount of code required for a complete answer. Candidates tend to start writing in the center of the whiteboard which is a waste of space and sometimes leads the candidate to awkwardly wrap code over to the left-hand side of the board. First impressions are often the most lasting -- and sometimes the only -- opportunity a candidate has to achieve a favorable review. Interviewing is a stressful and intense experience because candidates are so focused on giving their best performance. Candidates who remember these common-sense whiteboard coding tips will avoid confusion, make fewer mistakes, and save time, which they can use to focus on presenting their best work instead.", "date": "2013-08-19"},
{"website": "Hubspot", "title": "A Workshop on Designing Design", "author": ["Lesley Burr"], "link": "https://product.hubspot.com/blog/a-workshop-on-designing-design", "abstract": "What do you get when you mix a 484-piece classic Lego set, approximately 100 gallons of caffeine, 2000 stickers, sharpies galore, and enough Post-its to wallpaper an entire house? A HubSpot design workshop, of course. There’s nothing more inspiring than knowing that design can make a dent in the universe . Making an impact, though, requires taking a step back every now and then to recognize our challenges, identify where we need to improve, and find opportunities to become stronger designers. That's why, last month, our product design team assembled at Workbar in Cambridge for a 2-day workshop. Our goals were to critically examine the current state of product design at HubSpot, develop a new design mission, and come up with measurable ways to reach that vision. Getting A Lesson in Vulnerability Fresh out of INBOUND , Brene Brown’s keynote really resonated with us, especially when she said: “ Vulnerability is the birthplace of innovation, creativity and change.” If we were going to pick apart our current state of design and find areas of opportunity, we would have to be vulnerable and honest with each other, and with ourselves. That’s why we started the workshop with a series of group exercises. On the highest level, we shared baby photos with each other and laughed while trying to guess who each person was. On the deepest level, we shared our lives with each other, drawing maps of some of our happiest and most challenging moments. I realize how “kumbaya” this sounds (I swear we didn’t do trust falls), but these exercises really helped us break out of our shells, bond, and in the end, foster a culture of trust which is necessary when sharing our ideas and for giving and receiving critiques. It wasn’t until we were vulnerable together that we could talk critically and openly about our own product design process and its flaws. Analyzing Our Current State of Design At its core, development at HubSpot is rooted in autonomy. Each product designer works on and owns the overall user experience of a part of the product. We’re embedded on small, autonomous teams typically containing a product manager, tech lead, and a few engineers. Together, each team is responsible for the direction of their product. While autonomy can give us blue skies to innovate and the ability to ship quickly, it’s not without its challenges. Each designer’s process and how they work with their team is different. Couple that with having the responsibility to maintain older features while building new ones that push our product forward, and inconsistent experiences naturally occur. Sometimes to compensate for moving at such a rapid pace, one-off components would be created which over time served to slow everything down and make the product more disjointed. Just three examples of various iterations on modal window styles in our product over the years. Knowing this, we pinpointed over 36 tangible areas for improvement by the end of day one. They ranged from things as high-level as “lacking design principles,” to things as nitpicky as our “usage of colors” in the app. From that long list, we voted and pulled out five overarching areas to improve on that we would focus on first: We need defined UX methodologies to follow and to teach. We need a unified style guide and pattern library. We need design principles to guide our decision-making. We need to update our UI. We need to be less risk-averse. Crafting Alignment, One Post-it Note at a Time After analyzing our inconsistencies and variation across design processes and styles, we realized how big of a weakness it is that we don’t have a clearly defined set of design principles. The HubSpot Culture Code guides our company and how each of us approaches our work every day. As individuals, we’re already good at using that deck to inspire us to solve for the customer and work autonomously to make an impact. But as a design team, we are still missing a unified set of values and motivations. We set out to define both our team mission and our vision for what we hoped to become in the next year. As simple as it sounds to come up with two sentences, it was a rigorous process. We spent a few hours individually coming up with phrases that might work in our mission statement, sharing our ideas, grouping our ideas into overarching categories, and then reiterating. Rinse and repeat. We kept at it until we found ourselves converging on the same few phrases and words. Mission: Human Authentic We empower others Personal satisfaction through work satisfaction Helpful Vision: Infectious design culture Accessible design language Design methodology These are just a few of the values and aspirations we came up with, and we’re now using them as a blueprint for building a mission statement and vision that is actionable, concrete, and shareable. Work Hard, Play Hard A 2-day workshop in one room can be physically, mentally, and emotionally draining. We knew each other’s life stories, we ripped apart our design processes and exposed every issue and weakness, and we had taken the first steps towards building an improved team. But in true HubSpot fashion, we also made time to have fun, let loose, and get creative. We made flying frog figurines of Legos and covered a laptop in post-its of animal doodles. We practiced making the exact same funny faces. We refined our art of chill. We listened to fellow senior designer Jonathan Meharry’s hilarious accents and impressions , and to Of Monsters and Men at Boston Calling. Team building and brainstorming can sometimes seem trivial in a fast-paced development environment. We were worried at first that a 2-day workshop might slow us down. The reality is, taking time to recognize our weaknesses and areas of improvement is going to save us time, and more importantly, customer pain, in the long run. Getting out of our comfort zones and doing something completely different and reflective created a new, shared perspective on our approach to product design. We’re now in the thick of crystallizing our mission and vision, coming up with a game-plan for tackling the top areas of improvement, and creating effective methods for measuring our solutions. This workshop was only the beginning of the work we have ahead, so stay tuned for more updates as we build a smarter and more effective approach to product design.", "date": "2015-11-03"},
{"website": "Hubspot", "title": "How (And Why) We Launched The HubSpot AUX Rotational Program", "author": ["Quintin Marcus (He/Him)"], "link": "https://product.hubspot.com/blog/aux-rotational-program", "abstract": "At HubSpot, we know just how hard it can feel to break into UX. Many of us remember those days of scrolling through job postings not being sure how anyone ever got started when every posting said “3-5 years experience required.” We also know that even the most junior members at HubSpot can have an impact, and that everyone has potential. We’ve seen this realized in engineering co-ops who have built out heavy hitting features and gone on to become full-time hires. We’ve seen it with members of the support organization who became so much of an expert on customer needs that they transitioned into product management positions. That’s why we launched the Associate UX (AUX) Rotational program last year, with a cohort of four members with backgrounds in customer support, sales, and medical research. We wanted to build a path for folks to get started in UX as well, a path that would allow them to learn on the job and apply their skills even if they had never worked in a traditional UX job. We wanted to diversify our talent pool, and create an opportunity that is accessible to all. We looked for candidates who had the aptitude without the experience, prospects with the drive and motivation for UX who just needed help getting that first foot in the door. We looked outside the traditional UX bootcamps and programs, sharing this role at diversity and inclusion-focused events, during college campus visits, and looking internally for people within our Customer Success and Services organizations. We also wanted to give members of the team who were curious about management an opportunity to mentor and teach. We’re excited to share how it’s been going and how your company could start a similar program. How we built it We wanted to be really clear about the type of candidate we were looking for, in terms of skill attributes and growth potential. Since this was a new program and involved technical rotations, we were looking for candidates who had: Proven experience problem solving The ability to adapt to ambiguous situations Strong interpersonal skills A willingness to take and run with feedback Passion for understanding and delighting customers Demonstrated interest in UX To find folks with these skills, we partnered heavily with recruiting. We knew we’d have a lot of applicants, and with only four positions available and potentially hundreds of applicants, we needed a better way to trim this pool down. We also wanted to give candidates an opportunity to tell their story, without requiring them to do a “homework” assignment which we felt would put certain groups at a disadvantage. We landed on a three-question video essay (maximum five minutes long). In it, candidates explained why they wanted to break into UX and gave an example of a product or experience that was built with the customer in mind. This helped us determine whether candidates understood the concept of customer-centricity, without relying on specific academic programs or tools. It also allowed us to give more specific feedback to those candidates who didn’t make the cut. We wanted to level the playing field and help everyone grow—not just the candidates that we accepted. We knew once we had our cohort, we needed to figure out the best way to level them up. We wanted to have enough guardrails, support, and structure in place to facilitate a person’s growth without hampering their creativity. We mapped out a two year plan for each potential hire based on the changing functional rotations, business needs, and mentorship pairing. So, how’d it go? Well, we learned a lot and we’re still figuring things out as we go, but we’re so happy with the results. Here are the top three things we learned: The people you hire will surprise and delight you: When we launched, we expected to do most of the teaching. What was surprising was to see just how immediately each of our Associate UXers (or AUXers for short) could make an impact. Each one was able to meaningfully contribute to their teams in their first rotation—which was only six months long—even as they were learning the basics. We saw prototypes make it all the way to production, hands-on research conducted independently, full personas get vetted and built out, real tangible work that had value. I t was thrilling to see. Even though they lacked experience, their curiosity—paired with strong, stable mentorship—enabled them to hit the ground running. You’ll hear more of their stories in the coming weeks. Things change fast, so iterate often: HubSpot has a culture that encourages feedback and quick adaptation. Just because we set up the program in a certain way didn’t mean we had to leave it fixed in place. Our initial plan was to have each AUXer dedicated to either research or design, paired with a mentor from that specialty. Every six months for two years they’d swap disciplines, teams, and mentors. We checked in with the AUXers regularly, and found that there was some nervousness around this switch. Half had just found their footing in design, the other in research, and no one wanted to lose that knowledge by switching focus after six months. We also saw them moving faster than anticipated, making us realize that our initial plan of two years may be too long. What this led to was a rejiggering of our program. Instead of one mentor, we’d pair them with two: a mentor from research and a mentor from design. The two mentors work together to decide how to divvy up work, and make sure the AUXers were learning all aspects of the UX practice. We also shortened the program to three rotations (18 months), enabling us the ability to potentially hire faster in the future. The work doesn’t stop once you hire your cohort We had assigned mentors to each of the AUX hires, but a program of this scope needs a strong project manager to stay with the process and continue to iterate upon it. We didn’t have that at first, but it’s something we knew we wanted to add going in. So we did. While mentoring, I realized that I could lead the evolution of the program. I had already developed a curriculum with my mentee, so I shared it with all the AUXers in the next rotation. It eventually made sense for me to actually own the program as part of my full-time job. You’ll hear a little bit more about that in the coming weeks. Starting an entry-level program was a lot of work, but we found that the benefit far outweighs the cost of the work put in. If you’re a passionate UXer at a smaller company, or a UX leader at a big company who needs more talent, this type of program is a great thing to explore. We in the field have the power to create more accessible opportunities to those who may not have had access before. Even better, we can all benefit from creating that access. We piloted this program last year with a core concept, a loose framework to work within, and four excited AUXers ready to take on the world. A year later, we’ve seen the work they’ve produced, the bonds they’ve formed with their teams, and the initiatives they’ve impacted. We’re very excited to continue this program in 2020 and we hope it inspires others to create their own. This post was a collaboration between Quintin Marcus, Lauren McKenzie, and Ashley Hodder. We’ll be posting some additional articles about this program in the coming month, and the job listing to apply for the AUX rotational program will go live on March 30th, 2020.", "date": "2020-03-10"},
{"website": "Hubspot", "title": "log4j dynamic appender configuration", "author": ["Dan Abdinoor"], "link": "https://product.hubspot.com/blog/bid/6011/log4j-dynamic-appender-configuration", "abstract": "At HubSpot we use log4j with all of our Java projects. It's an excellent logging tool and for the most part makes life with logs much easier. Recently I wanted to convert a bunch of projects from just logging to file to send emails when errors were logged. Luckily log4j has an email appender (SMTPAppender) that does exactly this. You just set the threshold of event (Error in my case) and the buffer size for previous events. Say you want to get emailed the last 100 lines logged before an error, just set up an appender with a threshold of Error and a buffer size of 100, sounds easy. The interesting part (for me) was that I wanted to differentiate emails sent on my Production servers from my QA servers. Since I always deploy the exact same package to Production and QA I couldn't change the appender definition. The answer was to use dynamic appender configuration. Basically, any log4j configuration can read system-level variables. You can pull the hostname of the server, or even the IP address if you want, and use that value in the appender configuration. In my case I opted to use a system variable to specify the operating environment (Production or QA in my case). Here's an example of my appender configuration: <!-- Email Appender sends on ERROR level --> <appender name=\"email\" class=\"org.apache.log4j.net.SMTPAppender\"> <param name=\"subject\" value=\"[LOG] ${app.log.environment} PasswordReset\" /> <param name=\"to\" value=\"logging@server.com\" /> <param name=\"from\" value=\"noreply@server.com\" /> <param name=\"SMTPHost\" value=\"mail.server.com\" /> <param name=\"bufferSize\" value=\"512\" /> <param name=\"threshold\" value=\"ERROR\" /> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%d [%t] %-5p %c - %m%n\" /> </layout> </appender> If you are using Tomcat to run the Java application, set the system variable in the bin/catalina.sh file. Just add or update the JAVA_OPTS variable like this: JAVA_OPTS=\"-Dapp.log.environment=QA\" There turned out to be a couple of tricky bits before I was able to get this working. The first was that the use of system variables to dynamically configure Appenders doesn't appear anywhere in the log4j documentation. I managed to figure it out with excessive Googling and putting together pieces from all the sources. The second tricky part is that the Appender threshold doesn't really matter. In practice, the Email Appender will only fire off a message when an event of Error-level or higher (Fatal) is logged. For instance, you can not set an Email Appender to send messages on Info or Debug level events. Overall, log4j dynamic appender configuration is powerful and super useful, hopefully this post can help others avoid the trouble I had getting it set up. Note: This post is republished with permission from abdinoor.com.", "date": "2009-06-26"},
{"website": "Hubspot", "title": "Name Dropping: Maria Loughlin, VP Engineering at Toast", "author": ["Eric Richard (He/Him)"], "link": "https://product.hubspot.com/blog/name-dropping-maria-loughlin", "abstract": "Name Dropping is a Q&A series that aims to elevate the stories of women leading in the tech space. The idea came from Angela DeFranco, a Director of Product at HubSpot, who said one way to be better allies is to name drop more women in discussions of achievement, inspiration, and disruptors in tech, instead of referencing, time and again, the same set of (often male) leaders. This edition of Name Dropping features Maria Loughlin, VP Engineering at Toast, sharing her ideas and insights with Eric Richard, SVP Engineering at HubSpot. W hat was the first thing you built that made you realize you loved engineering? I’ve always loved puzzles. As a kid I assembled jig-saws, read puzzle books, and chose scrabble as my favorite board game. After high school I majored in Electrical Engineering because it involved physics and geometry, my favorite subjects. I’ll never forget my capstone project, designing a multilayer integrated circuit chip. I was hooked on a new genre of puzzles! What drives and motivates you as a leader? I have learned that people will forget what you said, people will forget what you did, but people will never forget how you made them feel — Maya Angelou As a technology leader I want to create software that matters. My team at Toast builds technology for the restaurant community, enabling our customers to succeed in a fast-changing digital world. That’s motivating! As a people leader I’m inspired by Maya Angelou. I want to be a positive force for the people around me, the type of leader who listens to others’ perspectives, appreciates their talents, and provides opportunities for them to reach their goals. It’s the combined opportunity — to have an impact on my colleagues while we do something important for our customers — that motivates me every day. What advice would you give your 22-year-old self? Stay open to the twists and turns of life. At 22 I had no idea I would marry an amazing colleague and share his journey as an immigrant to the United States and an entrepreneur in the dotCom boom. I didn’t know my career would immerse me in newspaper publishing, banking fraud, and restaurant operations. I would have been surprised to see I have a talent for motivating people, shaping culture, and managing organizational change. At various points I embraced unexpected opportunities and the resulting experiences have enriched my life. I would also advise my younger self to be open to personal growth. I had an “aha moment” when I read the book Growth Mindset. It shifted how I see my strengths, gaps, and potential. My inner voice now celebrates when I push outside my comfort zone and learn from feedback. It’s subtle, but thinking about failure differently frees me to take more risks. Toast is growing fast, so what advice do you have for other engineering leaders about scaling a hig h performing team? Growth is exciting and all-consuming. For myself, and others lucky enough to be in this position, my advice is to be thoughtful about maintaining balance. For your team, balance may mean investing in long-time employees while aggressively ramping new hires. For your products, it‘s about improving the experience of current customers while innovating for new markets, and paying attention to quality while rapidly delivering features. For yourself, it’s prioritizing family and healthy living, alongside work goals. On any day, week or month, things will go off-kilter; that’s normal. What’s important is that you recognize the shift and make adjustments to regain equilibrium. Balance provides the foundation for long-term growth and success. What’s been your favorite part of managing technical teams and the hardest part? In my favorite moments I’m brainstorming tough challenges with a diverse team. I love the energy in the room and the flow of crazy ideas. Somehow we always finish with a plan and a renewed energy to forge ahead. My hardest days are those where I run from one challenge to another, barely having time to think before the next commitment is due. I’m a high-energy person but on the busiest days the pace feels overwhelming and my introverted-self needs a break. That’s when I know it’s time to go home to my wonderful family and come back refreshed after a good night’s sleep. When you think about the best engineers you’ve ever worked with, what characteristics did they embody? Great engineers have a passion for their craft. They love technology, dig in to understand, and continuously learn new ways to deliver great solutions. Amazing engineers also share their expertise. They seek out collaboration opportunities: They encourage and mentor their peers. These engineers raise the performance of their entire team. Who is your mentor or someone you look up to? Through the years I’ve had many informal mentors, sometimes a manager or organizational leader, other times a friend or family member. After a difficult meeting, a mentor once explained the value of “the meeting before the meeting.” I still think of her when I navigate complex organizational agendas. Another mentor encouraged me not to avoid conflict (my default response) but rather to dig deeper, understand others’ motivations, and listen while defending my ideas. This kind of in-the-moment mentoring has broadened my perspective, helped me see blind spots, and raised my confidence. What are 2–3 core values of your engineering team? “Do right by the customer” We strive to make every Toast customer successful, because their success is our success. Empath y is our default. “Play and win as a team” We’re going to win by solving problems together and sharing lessons along the way. Toasters have each other’s backs always. “Make an impact” At Toast, we’re building something big and every individual “Toaster” has an impact. We love that we can make a difference to the company, to our customers, to an industry. What’s one interesting challenge your team is actively trying to solve today? This is a time of enormous change in the restaurant industry. Consumers eat more restaurant food than ever before, yet less food is eaten in restaurants. Driving this trend is our desire to eat restaurant food on our terms — at home or in our workplace, with the convenience of take-out, delivery, meal kits and other off-site options. This is the context in which Toast is innovating. We build technology that enables restaurants to offer convenience while maximizing their profit margins. Restaurants use Toast to plug into the third party ordering and delivery ecosystem. They connect with online diners via the web and mobile apps (without the million dollar IT budget required to go it alone). Toast’s technology frees them to stay focused on what they love — delivering great food and guest experiences. My team is building the technical foundation to enable this new world. We’re solving to optimize kitchen operations across ordering channels. We’re making sure there is a good response for diners, even when there are connectivity issues. We’re designing user interfaces that work for a single restaurant as well as multi-region restaurant chains. I’m a movie fanatic, so I have to ask, what’s your all time favorite movie? This one is easy! It’s “The Commitments”, a 90’s Irish comedy where a rock band comes together in inner-city Dublin. The characters are quirky, the scenes are gritty, and the sound track brings me back to my Irish roots. Whom should we interview next? Tweet us at @ HubSpotDev with ideas. This article was originally published on Medium .", "date": "2019-09-24"},
{"website": "Hubspot", "title": "Forget Multi-Tasking. It's Context-Switching That Matters.", "author": ["Saverio Morpurgo (He/Him)"], "link": "https://product.hubspot.com/blog/forget-multitasking-try-context-switching", "abstract": "Parallel task execution is a matter of perception. I often get asked how to do many things simultaneously, how to be in multiple conversations at once and (almost) never miss something. The first reply that pops into my mind to that question is: you can’t. You can't humanly do two tasks simultaneously. If you can, I envy you and I’d love to know your secret! What you're usually doing is actually switching between multiple tasks, and depending on how fast you can do that, you can give the illusion of parallel execution. Think of it this way. When you watch a juggler, you see them handle many objects at the same time. Are they really, though? Here's a fun video on how to learn to juggle three balls . If you look closely at the learning process and the movements, you might realize that a juggler’s hands are only ever taking care of one ball at a time. They just switch between them very fast! How do you know if you’re context switching properly? So, since we can't do multiple things simultaneously, we need to learn to switch from one task to another, quick enough to push forward more than one \"at the same\" time. As the example of the juggler shows, we can't start immediately with three (or more) objects. We start with one, and we skill-up over time with patience and exercise. The question is: while we learn, how do we know if we're doing it right? And what does \"doing it right” mean? It’s difficult to give a good description of  what \"good context switching\" looks like ⁠— the ideal flow might be different from person to person. Personally, I tend to approach it by identifying clues that something's not exactly right, indications that I'm struggling in doing my job. Let's take a typical one-week time frame to keep track of my work. I will ask myself: At the end of the week, do I get tired, drained? Have I done many things, but still have a feeling of underachievement? Do I lose track of conversations I'm having? Do people have to remind me to complete something or reply to a message? If you replied positively to one or more of these questions, it could be a sign that your workflow has space for improvement. Of course, not all of this might be related to context switching. Feelings of underachievement might be a sign of a lack of short term goals and good position fixing (literally: checking your position often enough to know if you're going in the right direction). I’ll talk more about position fixing later on in this post, and how, when done right, it’s the perfect complement to context switching. What can we do to build a healthy context switching process? When deciding when and how best to context switch, you need to weigh a number of factors: Do you have enough context to jump in on the new task? If not, how long would it take to gather that context? How quickly do you think you can help solve the unexpected problem in front of you (once you have the context)? Is this not only a high value task, but a high priority one? (They’re not always the same thing.) How many people are already working on it? Are you actually providing any additional value? How significant is the ripple effect of the (new) task? (Is this a small task that will have a big impact? Vice versa? Somewhere in between?) Reviewing these factors helps me apply a process of instant-prioritization , navigating through multiple problems and choosing which one to give attention to in a few minutes. Here are some key rules to follow as you practice context switching. Make use of instant-prioritization Let's take a typical example. You’re \"in the zone\" coding or thinking about a complex problem, and here it comes, the unexpected slack message, something's going on, you’ve been mentioned in a conversation, you’re being asked questions. The thread’s already several messages long, and you have to go back to the beginning and catch up while it’s all unfolding. That's when instant-prioritization can kick in. Go for context first: Read the first few messages only and try to get a hang of what’s going on. The moment you read it all and try to dive in, you're not instant-prioritizing ⁠— you're already working on it! If you couldn’t gather enough context from those first messages, ask a follow-up question of whomever started the thread ⁠— starting a private message with them instead of crowding the group message can be helpful. Ask them some clarifying questions to check whether you’re on the right course. Now that you have the context, you can understand if you can be helpful (or just a silent follower) and, if so, weigh how urgent it is and how much time it will require from you. When I find myself in situations like this, I often realize I'm not needed; maybe I've been mentioned just to be kept in the loop. Or perhaps I have some information I can add, and I'll give that single piece of information without trying to dive in. Sometimes, though, you need to get more involved. Think about whether you want to do it immediately, disrupting your line of thought, or if you can defer to later. That's the time to consider if, and how, the task is blocking someone else: will waiting mean they’ll have to stop what they’re doing (or have to context-switch themselves )? This brings us to the ripple effect. On one side of the spectrum, a conversation that requires me to reply with information quickly, unlocking an entire project for another team, feels like a good reason to stop what I'm doing and try to help. On the other side of the spectrum, what’s needed of me might be a time-consuming investigation into a very specific problem that isn’t blocking the whole team. There are many scenarios in the middle ⁠— there’s no catch-all playbook. You need to weigh all the factors at play, using your good judgment to make a conscious choice. Make a conscious choice when you switch context It's common to feel that you need to help everyone on every topic, anytime, and it's a good sign you care about collaborating with your team or your company to achieve a shared, bigger goal! But it’s not healthy for yourself, the team, and the company if your attention is spread so thin that you give wrong, or partial information because you didn't dedicate the right amount of time to someone. When you jump on something else, you should do it because you chose to be elsewhere; you decided to interrupt your current task, and you know the reason why you made that call. I love this sailing example: you're in the middle of the ocean, on a trip from Spain to the Canary Islands, and along the way you have a pleasant encounter with a sea turtle (on their way to their natal beach to lay eggs, or simply chilling). You want to see her a bit closer or a bit more (without disturbing her, mind!) so you might choose to change your route a little bit, or slow down. Then you realize the sea turtle is going on a completely different route: are you going to follow for a whole day? Probably not. After a few minutes, you'll set your sails back on course to your destination. You chose to do a \"small\" switch for a benefit but then reconsidered when it grew so big it would  disrupt your goals. What if, instead, you're sailing in a fleet. You receive a call for help from another boat and realize you're the only one near enough to give support and achieve something important for your team and whole fleet. You turn around and go to the aid of the other boat. You'll get to the Canary Islands later, most likely, but you know exactly why ⁠— you made a conscious, well-informed choice to do what was best for you and your team. Fun fact: The story about sailing to the Canary Islands is actually true. Here's some photo evidence. 😀 Remember that telling others that you can't do something is doing something I believe a piece of simple communication advice tends to be underestimated: telling someone \"I can't right now\" is an action in and of itself. If you’ve reviewed a situation and can't interrupt your work to jump on something else, it's ok and useful to express that. The person receiving that information can put it to good use, for instance, by looking for a temporary workaround or planning around it. Follow the way of the Jedi (seriously) \"Don't center on your anxieties, Obi-Wan. Keep your concentration here and now, where it belongs.\" Star Wars - Episode I  - The Phantom Menace As Jedi Master Qui-Gon Jinn used to say to Obi-Wan, stay in the moment, stay in the context, and focus your best on it. Have you ever tried to follow a conversation in a meeting thinking about how to solve a bug that's haunting you, and then had a question asked of you during the same meeting, which you had to ask to have repeated while you struggled to regain context? All good signs your concentration is not in the here and now! Remember that the bug will still be there after your meeting. What you're doing is vital because you chose to be there, so be there. Or question if you should be there at all. Hone your position fixing skills Position fixing is material for a whole other post, but it also plays a role in understanding when you're unconsciously switching too much for the wrong reasons. Here are some questions to use to check in with yourself: Did you establish goals at the start of your week? How often do you look at them? If you only calibrate at the end of the week, you'll realize too late if you shifted your focus from something important to something (maybe) important without a deliberate call. In other words, by Friday you might realize you followed that turtle for two days, and it was a fantastic experience, but you lost your entire fleet! Keep in mind that high priority/ high value tasks don't always have to be the first thing you take care of It might seem counterintuitive (I hear protesting already!) but let me share my rationale here. Priority, impact, and value can be affected by bias. We naturally tend to give more importance to our tasks if we don't exercise the muscle of looking at the bigger picture. Going back to the many factors you want to consider when performing instant-prioritization, your perceived impact is only one of them. One heavyweight factor: how much that task is a blocker for someone else, and what is their perceived impact? What is the shared impact? Unblocking someone else’s tasks with my action enables parallelization. If you have a small/ medium task that is unblocking someone else’s work, even if the short-term benefit for you is low, you're probably solving something that has an immense value for them. Find (and stretch) your limit over time This brings us back to  the juggler starting with one, then two, and only later with three objects: start with few tasks simultaneously. Look back, assess, increase, find your limit, and you’ll soon enough find your sweet spot. Then you’ll be able to identify when you’re really stretched and it’s time to get things off your table. The signs of good context switching Setting up the right flow is complex, and requires time, attention, and exercise. It's a muscle to train. If you’re willing to try one or more of these pieces of advice, you might feel like forcing yourself. Don’t try all of them at once. Incrementally identify the most impactful actions that work for you and your environment. After a while you should notice that you’re focused during the meeting, you easily prioritize your projects, and you find it easier (and faster) to decide on the spot if it’s important to dive into a conversation or not. More than anything, a great sign is when you start feeling like you did so many things at the end of the week, you can’t believe it, and your team will have achieved so much more around you. Interested in working with a team that's just as interested in how you work as what you're working on? Check out our open positions and apply .", "date": "2021-02-02"},
{"website": "Hubspot", "title": "Every Second Counts: 5 Tips to Make the Most Of Your Internship This Summer", "author": ["Chris Gullo"], "link": "https://product.hubspot.com/blog/every-second-counts-5-tips-to-make-the-most-of-your-internship-this-summer", "abstract": "You just checked your inbox and there was good news waiting: you got the internship at your top choice company. The first order of business is to celebrate. You beat out other candidates for the spot and all your hard work has paid off. So go ahead, brush your shoulders off a little. Once the excitement sinks in, it’s time to start thinking about how you’re going to get the most out of your summer in the ‘real world’. When I started my co-op with HubSpot's engineering team four months ago, I knew I wanted to sharpen my development skills but I quickly realized that this goal only scratched the surface. There’s way more to interning than stacking your resume with bullet points. You want to leave a company having gained new perspectives, experiences, and connections. The problem is, internships are temporary and guaranteed to fly by. Before you know it, next semester will be starting soon, and you don’t want to be wishing you had grabbed coffee with that Tech Lead or gone the extra mile on that one project. That’s why it’s important to be proactive. Your manager or mentor will be a huge help, but it’s up to you to get outside your comfort zone. I’m hoping some of the things I’ve learned along the way here at HubSpot will help you squeeze everything you can out of your internship. 1. Make Time for Extracurriculars at Work, Too There are so many ways to develop and learn during an internship beyond your day-to-day projects. A lot of companies host activities, workshops, or classes for employees to do something out of the ordinary from time to time. Just because you’re not a full-time employee (yet!) doesn’t mean you can’t take advantage of perks like this. HubSpot, for example, has weekly Tech Talks on everything from building Chrome Extensions to writing microcopy and a monthly Science Fair where Product Managers get to demo what their teams are working on. Anybody can go to hear what co-workers are up to and see how other parts of the product work. Stay up to date with what’s going on in your product or engineering organization and get it on your calendar. These are just a few examples, and the company you’re working for is bound to have similar opportunities so seek them out to fill your brain with anything and everything. 2. Don’t Leave Networking at School There’s a ton of emphasis at school on networking and how important it is for finding an internship or job. But that doesn’t mean you should take your foot off the gas on making new connections once you’re in the ‘real world’. When you settle in at your company, start meeting as many people as you can. Your co-workers are great resources for learning about various parts of the business, hearing different perspectives, and learning something completely new. The right conversations with the right people can sometimes teach you as much as a class or lecture. I think most engineers would agree that networking sounds pretty daunting. But I’ve realized it’s actually a lot less scary when you’re an intern because you already have something in common with the person you’re meeting: you work at the same company. Conversations don’t feel as forced as they might at networking events in school because you’re already on the same page with your co-workers. Ask your manager or mentor who you should get to know better, reach out to someone who’s leading a project you’re interested in, or grab lunch with someone from a different team each week. You might make valuable connections, and you’re guaranteed to soak up some new insight. 3. Make This Your Longest First Impression Instead of thinking of your internship on a 3 or 6-month timeline, approach it like a first impression. If you’re meeting your friends’ parents for the first time, you’re probably going to wear a nice outfit, be politer than usual, and generally be on your best behavior. Internships aren’t all that different, except making a good first impression with your company takes a lot more work than putting on a clean shirt. What can you do outside your area of responsibility to improve the way you or your team works? What challenges can you identify, and what solutions have you brainstormed? Is there a project outside of your day-to-day tasks that could use your skills? Your goal shouldn’t be to meet the minimum or check off all your boxes; it should be to go above and beyond. At HubSpot, the projects I work on are only a small percentage of the hundreds of applications we have in our GitHub environment . As an intern, you have the ability to navigate these other projects and contribute, whether they are related to your team’s work or not. Commenting and providing suggestions to other pull requests can go a long way, and you’ll undoubtedly learn a lot, too. Leaving that kind of impression will make a world of difference when your manager is considering making you a full-time offer or when they’re asking your co-workers for feedback on your performance. 4. Stop and Enjoy the View I think a lot of interns worry so much about being professional and nailing that first impression that they don’t let themselves enjoy the perks a company or team has to offer. Working hard is important, don’t get me wrong, but so is striking a balance. No one’s going to think you aren’t taking your internship seriously because you went to company trivia night, took advantage of the on-site cooking class last week, or joined the Panini Club (a HubSpot favorite). There’s a lot to soak up at work besides work, and internships are a great time to get your hands dirty with everything. And, that goes beyond the office. If you’re interning in a city that’s new to you, like Boston is for me, get out there and explore. I’m lucky to have a group of fellow interns and co-ops here that are always up to get some good eats, go to a concert, or check out the city with me. Most co-workers will be more than happy to show you their favorite spots, or at least point you in the right direction. Just don’t be afraid to ask. 5. Take Cultural Cues Culture fit is one of the most important factors in finding the right place to work. In fact, more and more people are starting to value culture over compensation . Some companies capture their culture through content like HubSpot's Culture Code or Netflix's culture deck , but it’s not always easy to gauge what a work environment is really like from the outside. That’s why internships are a great opportunity to size up what kind of culture aligns with your style, values, and work ethic. Having a better grasp on the type of workplace you thrive in will help a ton when you’re looking for your first real job out of school. A couple things to ask yourself throughout your internship are: How are teams organized? What values and missions are embodied? How do employees interact and collaborate with each other? Are policies and guidelines a match? Depending on the company, these answers will differ immensely so it’s important to give some thought to which aspects of the culture you like and which you don’t. That way, when you’re interviewing in the future, you can ask concrete questions about what to expect and find the most compatable company for you. Ultimately, internships are a fantastic opportunity to apply what you’ve learned, get exposed to new perspectives, and make valuable connections. But before you know it, you’ll be back at school so it’s important to make every day count and soak as much up as you can. Interested in an internship opportunity at HubSpot? Check us out!", "date": "2015-04-24"},
{"website": "Hubspot", "title": "Growing Your Design Career: 4 Highlights from Tuesdays by Design", "author": ["Hannah Fleishman (she/her)"], "link": "https://product.hubspot.com/blog/growing-your-design-career-4-highlights-from-tuesdays-by-design", "abstract": "When Sean Duhame was asked last night how the role of designer has changed, he explained that designers today have more responsibility than they did ten years ago. “The world now understands that design is the linchpin for success,” he said. Not surprisingly, designers are constantly pushing themselves to get better at their craft and sometimes, that means stepping away from the screen to learn from design leaders. Last night, designers from all different backgrounds came out to HubSpot HQ for our first-ever Tuesdays by Design meetup to hear from Sean, Tim Merrill (Senior UX Manager, Medullan ), Will Smith (Director of Product Design, InsightSquared ), and moderator Nelson Joyce (Product Entrepreneur, Leadin ) on how they can grow that newfound responsibility into a successful career in design. Thanks to their reflective, honest, and sometimes challenging responses, the panelists felt more like mentors for 45 minutes and gave the audience a ton of valuable ( and tweetable ) advice to absorb. Whether you’re thinking about getting started in product design or are managing a team of designers, these four discussion recaps from last night’s panel are helpful for anyone growing a career in the design world. On Getting a Formal Design Education Thanks to free resources like YouTube Photoshop tutorials and design blogs, there’s never been a better time to become a designer. “It’s easier than ever to take some initiative,\" Will said. This begs the question: do you have to go to school for design? Panelists agreed that a formal education is invaluable for understanding the fundamentals of design. “Layout, spacing, grid, typography, get that stuff down. That’s the basis of visual communication,” Tim shared. Aside from building that foundation, design classes give designers the opportunity to get used to feedback. Nelson added that giving the wrong answer in school used to be a bad thing but when designers get comfortable with critique, “you almost want to be wrong so you can learn from that mistake.” “Design school is really good for the critiques and softening up the ego a little bit.” - Will Smith Going to design school is important for learning the basics but Sean said he’s hired talented designers with zero training. Not everyone is going to start their careers with a four year degree in design and that’s why he’d “love to see more old school mentorship.” On Being a Good Person Whether you’re just starting your career or trying to take it to the next level, it’s crucial to know what employers are looking for in designers. Panelists shared what’s top of mind for them when talking to design candidates and their responses had nothing to do with your resume or portfolio. It’s about character. “Attitude first, aptitude second. If you’re humble, you tend to be a good listener and other things just follow.” - Sean Duhame Will wants to work with designers that have empathy, first and foremost. “You need to be able to think around the whole problem and think about the users,” he said. To know if someone is empathetic, he looks for designers that have “diverse experiences” and asks how they arrived at their decisions to gauge how they solve problems and think about the user. Another big theme was passion. “If you’re passionate about something, even if you don’t have the skills, you’re going to work hard to get better at it,\" Tim explained. He wrapped the question up by illustrating why designers should think about personal and professional development in tandem: “If I can tell that you’re someone I actually want to work with, that, being a good person, is going to mean more than anything.\" On What Designers Should Look for in a Company After discussing what our panelists screen for when hiring designers, we shifted gears to what designers should be picky about when looking at companies. And, all signs pointed to impact. You want to work at a company where you can shape the final product and where there’s support for a designer’s vision, Will said. Panelists agreed that you have to talk to the people actually doing the work to figure that out. The hiring manager or interviewer won’t always be the best indicator for how designers contribute on a day-to-day. Ask engineers about their relationship with their designers. Ask them what the CEO is like and if she dictates the product vision or collaborates with the product team. Their responses can tell you a lot about a company’s culture. “ I look for meaning at a company, a sense of purpose. I look for a place where the employees actually care about the stuff they’re doing.” - Tim Merrill Beyond having the ability to make an impact on a mission you care about, designers should think about matching their values up with those of the company. “If you’re a scrappy person, then find the place where you can do that kind of work. You really have to align what you want out of being a designer with the company’s philosophy,\" Sean said. On Working with Engineers When the floor opened up for questions from the audience, one of our product managers sparked a conversation on how designers can best collaborate with engineers. Panelists had a few different ideas to share like Will’s tip on using customer stories and personas to connect with engineers and illustrate the common ground between design and development. The best alignment though, according to Tim, happens when designers welcome engineers’ feedback. Instead of getting defensive and pushing back, get developers on board early by being open to their feedback and acting on it. “When you’re doing research and developers are part of that ideation process, they get a sense of ownership.”- Tim Merrill Sean said user flows are always a good way to bridge the gap between product design and engineering. Talking through the steps a user will have to take with your product and what could happen along can get a valuable dialogue started. “Engineers understand logic and that’s what flow is all about,” he added. Designers today do have more responsibility than they did a few years ago. And I think part of that responsibility is furthering the design community by adding value where you can. For seasoned designers like Tim, Will, Sean, and Nelson, that means helping other people navigate the waters and grow their own design careers. So, I'd like to give a big thank you to them for sharing their insights at Tuesdays by Design. Stay tuned for the next event; we hope this can continue to be a platform for designers to learn from one another and get inspired, off the grid.", "date": "2015-06-17"},
{"website": "Hubspot", "title": "Building More Humane Software With humanize.js", "author": ["Bryan Ash"], "link": "https://product.hubspot.com/blog/humanize-js-making-the-internet-more-humane", "abstract": "As front-end developers, we're always looking to make the software we create as friendly as possible for actual humans to use. We're frequently called on to transform all kinds of data — currencies, dates, times, arrays, and objects — into human-friendly versions for display. We'll often end up writing one-off functions for these small tasks. Which can be deceptively simple when you start out, so it doesn't feel like you're creating a maintenance burden for yourself, but in fact, you are. Sometimes we can get away with using built-in methods, like Date.parse() or some fancy type conversion. But, that often doesn't go far enough. Simple string concatentation just doesn't cut it. So here at HubSpot we improved on the best parts of current formatting libraries to create Humanize . This library has been helpful in creating a consistent, human voice throughout our applications. It has a simple API, and it's both performant and well tested. What Is It? Humanize is an \"object to string\" formatting library. Unlike other libraries that only let you format strings, Humanize helps you convert different types of data to human-readable text, like turning an array into a comma-separated list ( oxford comma optional). Examples: Humanize.dictionary({apples: 'red', banana: 'yellow'}) // 'apples are red, bananas are yellow' Humanize.oxford(items, 3) // \"apple, orange, banana, and 2 others\" Humanize.formatNumber(123456789, 2) // \"123,456,789.00\" Humanize.ordinal(22) // \"22nd\" Humanize.filesize(Math.pow(1000, 4)) // \"931.32 Gb\" Humanize.truncate('long text is good for you', 19) // \"long text is goo...\" Naturally, Humanize also includes optimized versions of basic string formatting methods ( truncate , pluralize , etc.), but there are (intentionally) no date formatting methods. For that, we highly recommend checking out moment.js . Humanize ( github ) is written in CoffeeScript (because we love CoffeeScript) and compiled using Grunt , complete with Jasmine specs. As always, send us a pull request if you have any ideas for improvement. Or if you're just a regular human (that is, not a developer), please leave a comment on this post and let us know other ways we can make our output more human. Image via masterdata.se This is part of a series of posts on a bunch of new open source software released by HubSpot developers.", "date": "2013-02-05"},
{"website": "Hubspot", "title": "The 5 Whys Of Feature Bloat", "author": ["Dharmesh Shah"], "link": "https://product.hubspot.com/blog/the-5-whys-of-feature-bloat", "abstract": "I t seems that just about everyone knows that a product that is a large heap of stinkin’ features is a Not Great Thing . There are hundreds of articles written on the topic of good product management and why it’s so important to fight the good fight against feature bloat. You probably have a great product team comprised of smart, well-intentioned people who care about the customer and are thoughtful about the classic trade-offs in product management. Perhaps you're on that team. So, why do so many products become feature bloated over time — and how do we go about reducing the likelihood that ours will fall into that trap? As a thought exercise, I thought I’d do a simple 5 Whys Analysis of Feature Bloat and see what road it would lead me down. 1. Why do we have feature bloat? Because we regularly add new features but rarely take features out. The net result, over time, is that products accrue more and more features. It’s just simple arithmetic. We add more than we subtract. 2. Why do we regularly add features but rarely take them out? Because adding features is easy. As product leaders, our job is to build great products and create many happy users. Improving the product with new features is a common way to do that. Most of us have a long list of ideas for improvement submitted by customers, prospective customers, our sales team, marketing team, customer team, founders, etc. Most of our time is spent figuring out which of these features to add based on potential impact and available resources — and then adding those features. As product leaders, we may get criticized every now and then for which ideas we picked, but not for picking some ideas. We’re expected to improve the product and add features our users are asking for. I don’t think I’ve ever seen a product team criticized for shipping too many new features. So, at a relatively regular rate, we keep adding features. But, more interesting is: Why do we rarely take features out? Because taking features out is exponentially harder than adding features in. 3. Why is taking a feature out so hard? Because it’s hard to justify taking a feature out. Usually, nobody is asking us to take things out. With ideas, there are some people pushing for those particular features. They’re advocating, they’re lobbying, they’re sending you cupcakes and cookies. But, I’ll bet you a dollar that nobody is sending you baked goods to entice you to prune a particular feature. Chances are, if you are fighting to kill a feature whose time has come, you are fighting that noble fight as a lone hero, and like many lone heros, you are unlikely to get fame, glory or cupcakes for your valiant effort. In fact, there’s a decent chance that you will be battling some folks inside the company (like your sales team) that don’t want you to remove things for fear of impact on likelihood of closing deals. 4. Why is it hard to justify taking a feature out? Because it’s hard to tell whether removing a feature is worth it. Some user(s) somewhere probably uses that feature. Some may even love that feature. Some may have bought the product because of that feature. Some may threaten to cancel if you don’t keep that feature. And that is why product management is so hard. You’re trying to balance different needs for different constituents across different time horizons . Some things make absolute sense in the long-term, but are hard to explain in the short-term. 5. Why is it hard to tell whether removing a feature is worth it? Because the payback for removing a feature happens over time but the pain from removing it happens right now . Also, it’s unlikely that the feature is bad. The idea underlying that feature was on the backlog for a while. It was chosen from a long list of other possible ideas. If a feature got added, it was added for a reason, and is doing some good for somebody, somewhere. In order to be implemented, ideas must survive the brutal battle for resources. Hundreds enter, few survive. And also… Because we think that the resources spent adding that feature are a sunk cost . And we learned somewhere along the way that sunk costs are sunk and we shouldn’t let them cloud our thinking. So, now that we have a theory of what’s going on, how do we address the issue? A few thoughts on this: As product leaders, we have a limited set of data that we work with. We do our best to pick the ideas with the greatest “ wow to work ratio ” (the most amount of customer impact and delight for the least amount of calories spent). We make our choices with the data we have and the resources we have at that time. But our choices are not always right — nor should they be expected to be. So, the first thing to do is accept that… We are all fallible and some of the features we add will turn out to be flops. And, since we can’t always know for sure a priori which features will be flops, how do we figure it out a posteriori ? (Don’t be impressed with my Latin — I had to look it up). Answer: Use the data! We live in an age where most of us have tons of data on what our users are actually doing with the products we build. We should instrument the features we add (particularly new ones) and analyze what the actual usage is. Let me give you an example. You know about Settings. We all know about Settings. A setting gets added to a product when a debate was had as to whether it should work this way or that way, then everybody got tired of arguing, and just made it a setting. Let the user decide. I’m going to resist going on a rant as to why most settings are uninspired compromises. But let’s say you add a new setting to your product that lets the user configure [x]. The setting will likely have a “default” and then some possible set of overrides for the default. Here’s the thing you should measure: On a cohort basis (after the setting is added), how many users ever change the setting from the default to something else? Let’s be generous and say it’s 10%. It’s not 10%, but let’s say that it is. Like I said, we’re being generous. That means for every one user that thought they needed to override that setting in the hopes of getting some value, we complicated life just a little for 9 other users. Not to mention all the people on your team that will have to document, support and troubleshoot that setting. In the long-term, was it worth it? Chances are, probably not. But, we leave it alone because we think “hey, sunk cost…we’re moving on with our lives…” But that’s a big, BIG fallacy. Most of the cost for a feature is not in the initial development but in the long-tail of time after it is launched. Here’s what I think you should do. Decide a “minimum bar of usage/value” that every feature must pass in order for it to remain a feature. If a new feature doesn’t hit that bar in some set period of time, prune it. Support those efforts to prune where pruning makes sense. Acknowledge that there will be some short-term pain, but that the long-term value is worth it. Create a culture that rewards the heroic efforts of those that fight as hard to take features out as they do to add features in. CELEBRATE THE SUCCESSES! Thanks to the HubSpot product team for a) being awesome b) helping make this article better.", "date": "2016-03-01"},
{"website": "Hubspot", "title": "One more developer job application tip: Check your spelling and grammar", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/23375/one-more-developer-job-application-tip-check-your-spelling-and-grammar", "abstract": "Related to Dan's post on developer interviews , I wanted to add another tip for developers applying to work at HubSpot (or anywhere else): carefully check the spelling and grammar on your resume, cover letter, and other application materials. Trivial, you say?  So I thought.  It seems like every career site, coach, and friend mentions this advice numerous times. But having reviewed every single engineering resume submitting to HubSpot within the past two years (almost), I'd say at least 75% of them contain some spelling or grammar mistakes. That's 75% bad, not 75% good ;) Some developers say that they're not hired for their writing skills.  I disagree.  Communication skills, including written communication, are important to everyone.  In our environment at HubSpot, we don't have long specifications or requirements documents.  We rely on a lot of ad-hoc communications, such as emails and comments in our issue tracking system. What's more important, though, is that in the context of a job application, this kind of mistake shows lack of care.  Lack of attention to detail.  Maybe you were rushed.  Maybe you copy / pasted the contents from elsewhere.  Maybe you did spell-check, but as we all know the Microsoft Word checker is not perfect, especially when it comes to grammar or places where multiple words can be used. Most of the time, we reject those careless applicants right off the bat.  It's a waste of everyone's time.  So please do yourself a favor, and carefully review your writing.  You may find this Guide to Grammar useful -- I know I do. What do you think?  Are we too harsh / strict on this topic?", "date": "2009-09-15"},
{"website": "Hubspot", "title": "Tech Talk at Night React Meetup (Video)", "author": ["Emily James (She/Her)"], "link": "https://product.hubspot.com/blog/tech-talk-at-night-react-meetup", "abstract": "On Wednesday, October 12th we hosted a React Meetup here at HubSpot. We had a wonderful time with over 150 attendees, 200 delicious Mexican tortas, and lots of great content. Ben Briggs started off the night discussing how we at HubSpot use Draft.js , Facebook’s new React framework for building rich text editors. He discussed the problems traditional rich text editors present and benefits of using a framework like Draft. Finally, he introduced tools we’ve built around Draft to make it easier to build plugins for features and to persist content to HTML . Lee Byron from Facebook followed up with a great talk on building apps with immutable architecture. He presented an alternative to the traditional MVC/REST pattern using React and immutable state. Lee also gave an introduction to GraphQL , what queries to a GraphQL API look like, and how it’s a natural fit in an immutable app architecture. In case you missed it and want to learn more, check out this video below.", "date": "2016-10-21"},
{"website": "Hubspot", "title": "Design Consistency and the Brilliance of Twitter Bootstrap", "author": ["Adrian Mott"], "link": "https://product.hubspot.com/blog/bid/83845/design-consistency-and-the-brilliance-of-twitter-bootstrap", "abstract": "Sometimes the database schemas and app development aren't the only challenging issues facing a product development organization -- consistency of the design of all apps within a product and platform can present a major hurdle. Design consistency is something that many companies making web applications today face head on and deal with in different ways.  It just isn't that easy to have many small development teams, each working on different apps, magically create apps that have the same look and feel for the user. More and more, especially with the recent popularity of Twitter Bootstrap in recent months, the rise of style guides has shaped the way companies are handling their design and development efforts. Part of the success of Twitter Bootstrap isn't just the ease if gives developers to pop it into a project and have the design taken care of (which is really nice), but it's the idea of unified style rules for an entire development organization. It just takes the guess work out of design consistency, and that idea alone is worth its weight in gold. Here at HubSpot, we have a great group of designers, who work with each product team to make sure that their apps look awesome.  You'll see some of their work in some upcoming releases of new core HubSpot apps. Much of the success that we're now seeing in the design of the products comes from the idea that Bootstrap imparted - create a unified style guide that all apps can use (we actually ported out style guide here from Bootstrap, but used Sass and Compass, as well as HTML and CSS). Laying the \"design foundation\" down and allowing for designers to spend more time on polish has really helped the team's productivity as well. It brings up another great thing that the Twitter team did with Bootstrap: they open sourced it.  Putting it up on GitHub (where it has become one of the most popular projects) and licensing it under the Apache License allows for free use by other developers, but also and immense amount of collaboration and added ideas and code back into the project - a fundamental benefit of all open source software. I thought this article on A List Apart is a really good account of how Twitter Bootstrap came to be and where it's going. I hope it's the start to seeing many more excellent style guides coming out in the near future.", "date": "2012-03-09"},
{"website": "Hubspot", "title": "Product Management in the Age of Hybrid Teams", "author": ["Eric Peters (He/Him)"], "link": "https://product.hubspot.com/blog/product-management-in-the-age-of-remote-product-teams", "abstract": "In January 2019, I joined a team that was based out of HubSpot’s Dublin office, while I was based in Cambridge, MA. Our frontend engineers, backend engineers, designer, UX researcher, and analyst were all sitting together and for the most part, had been working together for some time. It was an intimidating career move to join that team as a product manager. At the time, I would still go into the HubSpot HQ office in Cambridge every day. I spent most of my morning on Zoom with the team and then the afternoon writing, researching, or meeting with stakeholders who were in my timezone. It took some time to get used to working this way, and I’d be lying if I said it was a smooth adjustment. For the three years prior, I sat with HubSpot’s marketing acquisition team, who were all colocated. The truth is that Zoom calls weren’t the norm at the time ⁠— in-person design workshops, in-person team meetings, and in-person after work beers were. I thought building camaraderie and the team’s sense of purpose was primarily an in-person activity. Since then, and especially over the past year of COVID-enforced remote work, I’ve realized that working on a fully distributed team isn’t the asynchronous collab disaster I once thought it might be. In fact, the organizational design my team and I share now is actually a blessing in disguise. Our team learned to think of our operating system more intentionally, as well as how we should optimize our time together and apart in order to maximize our mental health and our impact (in that order). If you’re new to managing a distributed team, or your company, like HubSpot, is planning to remain a hybrid workforce even after the pandemic ends, this post is for you. So read on, and share with your team members: if a team is going to be successful, it’s because everyone involved is contributing to its adaptability. Optimize Your Operating System Remember back in March of 2020, when we all first went remote and our calendars lit up with more Zoom meetings than ever? It was a stressful time for everyone on the planet anyway, and the number of non-work-related Zoom meetings ⁠— the hangouts, the watercoolers, the trivia sessions ⁠— introduced us all to the concept of Zoom fatigue in a very real way. Suddenly we were logging off from a day of Zoom meetings, only to log back in to have Zoom drinks with our friends who were quarantined in other parts of the same city. I even hosted my sister’s baby shower over Zoom! It didn’t take long ⁠— somewhere in between buying stock in Zoom and ordering at-home exercise equipment ⁠— for me to realize that a rebalance of our operating system was in order. I surveyed the team to get everyone’s perspective on all of the recurring meetings we were having, how valuable they were to each team member, and whether or not they thought we should adjust them. I noticed that, for the most part, our team All-Hands meeting every two weeks could take the place of several other meetings as long as we planned it more intentionally. The last 30 minutes of the first all-hands meeting of each quarter could work as a quarterly team retro. It seems small, but save 30 minutes for eight people, four times per year, and those precious minutes add up. Also, those watercooler chats that are great for building camaraderie and zooming out from our day-to-day fit nicely at the start of a team meeting while attendees are all logging in. Make Your Calendar Work For You That mindset of intentionality led to me rethinking my own calendar, and leaning into something I’d only done haphazardly before the pandemic: time-blocking. If I have ten 30-minute meetings sporadically throughout the week, my productivity suffers due to the sheer amount of task switching between creative mode and collaborative mode I’ve induced on myself. As an introvert, collaboration mode isn’t my default setting, and turning it on doesn’t come easily for me ⁠— getting myself in and out of it takes time. If I consolidate meetings into a few long blocks per week, particularly similar ones like 1:1s with my core team, I'm a lot less susceptible to task- switching-induced brain drain. My Thursday mornings these days are like speed dating! (Well, not exactly, but you know what I mean…) Therein lies my tip for productive remote product management: biohacking my calendar. I know that my creative brain runs the smoothest in the morning, while my collaborative brain works better in the afternoon. (I’m writing this post at 7:30am, if you’re wondering.) Of course, my morning is also the only time I have to meet with my Dublin-based team, who are five hours ahead. My solution? When I have some control over scheduling, I group all of my meetings in the morning later in the week, prioritizing the ones that really do have to be in the morning because they’re with a Dublin-based teammate, and block off my creator time in the morning in the beginning of the week. Having a finite amount of time in which we meet and collaborate forces my teammates and I to use that shared time efficiently. And having hyper-productive ‘creator’ time built into my calendar allows me space to think deeply. Afternoons are left for stakeholder meetings, user interviews, or meetings with my colleagues around the US, and of course, anything I didn’t get done that morning. It’s not always perfect, but I’ve found that this strategy enables me to maximize my time as a remote product manager working with a team across multiple time zones. Lean Into Asynchronous Collaboration Individual meetings are one thing, but the team also needed to figure out how to have brainstorming sessions and workshops via Zoom. For the most part, these types of meetings  went smoothly with the help of digital whiteboard apps. We learned how to do this better over time and ultimately got to the point where we could do them asynchronously. Having the option of asynchronous collaboration let us look at each individual meeting and decide whether it truly required us all to be logged in to a Zoom at the same time, whether part of it could be done asynchronously (like preparation for a team retro), or whether all of it could be done asynchronously (like a content design workshop.) To be fair, there are some ground rules to making asynchronous workshops work. Your first one will likely be a mess, but that’s okay. Everyone has to participate with positive intent, fully aware that we’re trying something new that’s destined to get more efficient over time, and that the team is owed feedback on the experience so that we can do it better the next time. I’m lucky to be on a team where this was the default mode of operation. What it comes down to is an extra hour or so spent preparing the ‘whiteboard experience’ ahead of time, which then tends to save the 5-15 participants about 30 minutes later on. That’s a bet my team and I are willing to take, as long as we share the responsibility of setting it up. If you’re just getting started with asynchronous meetings, that setup time is key: prepare the board by giving your attendees written instruction, drawn out boxes to enter their opinions, and pre-made post-its next to their avatar to help them orient themselves. Even your basic synchronous digital whiteboard meetings are much more susceptible to distraction than in-person meetings, so write down the instructions on the digital whiteboard so whoever missed them in the beginning of the meeting can easily catch up and follow along. As for asynchronous meetings, logging in to a well-set up digital whiteboard feels like you’re about to go on a scavenger hunt and generally amps up the excitement and participation. I have our UX Content Designer Dayne Topkin to thank for running our first ever asynchronous design workshop, and this really was a turning point for our team and our operating system. I will try to convince Dayne to write up a post here on the HubSpot Product Blog with more specifics on how to do this, but to give you a idea, here is how the workshop starts at the top of the digital whiteboard: If you want to dig deeper into strategies for distributed work, here’s a post with tips for better asynchronous communication in general . Final Thoughts I think there are more positives to having a product team distributed across multiple time zones than negatives. Sure, it’s easy to look fondly on the old ways where we would all get a beer after work together, but then we wouldn’t even have some of the teammates we have now. When you take geography out of the equation, you can bring the best talent to the team, not just the best talent in your proximity. We’ve learned to optimize our schedule so that time spent together is spent more intentionally. New team members ramp up faster because the whole team knows the routine, and there’s predictability and camaraderie built in. Our meetings are more productive, and our operating system is more adaptable. As Iron Man once said: No amount of money ever bought a second of time. Working flexibly and asynchronously is the future of distributed product teams, and while it might be intimidating at first, it will make your team stronger and more productive in the long run, and it balances productivity and collaboration in a way that I never would have expected. Interested in working with a team that's just as invested in how you work as what you're working on? Check out our open positions and apply .", "date": "2021-05-05"},
{"website": "Hubspot", "title": "Training the Next Generation of UXers Through the AUX Rotational Program", "author": ["Quintin Marcus (He/Him)"], "link": "https://product.hubspot.com/blog/aux-rotational-program-2021", "abstract": "Interested in applying? Click here for more info. “I want to build a company my kids and grandkids can be proud of” is a quote we often repeat from our founders. In the product organization, we say “we build careers, not software,” because we believe that what we build is about the people, our users and customers, not about a list of capabilities. We think the same of our employees: they aren’t just cogs in a machine, but people whom we care deeply about, people whose careers we want to grow. As a UX organization, we want to take this even further. The Associate UX (AUX) Rotational Program aims to educate the next generation of UX professionals, by bringing on individuals who have all the potential but just need that first step. We want to make UX more accessible to those who have been unable to break into this industry. When I started out, I applied to hundreds of places and would rarely hear back. It’s an experience I still hear about when connecting with aspiring UXers. Entry-level UX roles are few and far between, with many job listings still requiring multiple years of experience. At HubSpot, we want to change that, and we hope that other companies will do the same. What is the AUX Rotational Program? The program currently consists of three six-month rotations. In each rotation, the associate UXer is embedded onto a product team as a full-time employee, no different than any other employee. They’re paired with two mentors, consisting of a product designer, content designer, or researcher. They gain exposure to different areas of the business, team dynamics, and networks, diversifying their UX development across design, research, and more. Learn Our associates’ first rotation focuses on learning. While embedded on their teams and working on real-life small scope projects, they also meet for a once a week class to learn some of the fundamentals of UX. These classes are run by various UXers in the organization and show how these fundamentals are applied at HubSpot. Grow As associates move on to the second rotation, the focus moves to growth. Associates will work with their mentors to take on more ownership, focusing on applying what they’ve learned, and exposing themselves to areas they may not have covered in the first rotation. They’ll also tackle more end-to-end projects, with a larger scope. Execute The final rotation is focused on the application and execution of what they’ve learned throughout the program. Their mentors will mostly be there to oversee and provide support, with the associates taking on full responsibility of initiatives and overseeing their project management and prioritization in coordination with their teams. Throughout the program, the associate will continuously get feedback and receive quarterly informal reviews with their mentors. After 18 months, provided the associate has maintained an excellent track record of performance and there are available roles, they will be promoted to a Product Designer, User Researcher, or Content Designer role. What we look for An interest in UX We want to see that an applicant has made a clear effort in their journey to becoming a UXer. We want to know how they’ve learned about UX, what makes them excited about it, and why they want to pursue this as a career. We also want to hear about what they’re doing to prepare for a UX role, and where they’re at in their learning journey. People-focus Our UXers are obsessed with our users. We talk to them all the time, and try our best to ensure we are always solving for the customer. We look for folks who have been able to apply this customer-centric mindset in their own roles, even if their user-base may look a little different. The best applicants will be solving for their own customer, even if it’s not a customer who is literally paying for a service or product. Perhaps it’s volunteers they are coordinating, or students they are solving for. No matter what form it takes, we look for folks with a high level of empathy and human interest. Communication, collaboration, coach-ability These skills underlie a lot of what we do as UXers, enabling us to be the most engaged and effective with our teams. We want our associates to become full team members, learning from their mentors and peers, as well as offering their own perspectives. As the associate progresses through the program, their communication and collaboration will be key in defining their work and sharing their insights with their teammates. This will ultimately lead to better experiences for our customers and more impactful work. As they are coached throughout the program, they’ll be expected to incorporate their learnings and feedback to continue to develop and deepen their understanding of their product areas. Adaptability and problem solving What we work on as UXers shifts with the priorities of the business, as well as with constraints that may pop up along the way. We may design what we think is the perfect user experience only to uncover a new piece of data that changes our direction. We’re looking for folks who are excited to unpack a new problem each day, and can adjust to meet the needs of the business and learn in doing so. FAQs What should I do to prepare? Most often I tell folks to really take a look at their resume and how they’ve positioned their past experiences. How are they designing themselves ? UX is everywhere, so I urge folks to consider how their previous experiences map to a UX skill set. For instance, someone working in customer support might reference the interactions they had with customers and their user focus, or a teacher might talk about how they measured success with their students. For more resume tips, check out this article from Loe Lee, a UX Manager at HubSpot, on Designing a User-Centered Cover Letter and Resume . I’d also recommend checking out our AUX Product Design Book List , which has resources folks from our team have thought were helpful for them in their UX journeys. What if I’ve never worked in (tech/product/UX)? That’s totally okay, and expected. Everyone has to start somewhere, and that is part of the mission of this program. We’re looking for potential, folks who can be coached and taught the technical skills of UX. How is HubSpot organized? Where does AUX fit in? UX is part of our broader product organization. In the product organization, we have several product groups, under which there are many small autonomous product teams. They vary in size, but each typically has a Product Manager (PM), a Product Designer (PD), and a Technical Lead (TL) who manages the dedicated software engineers who work on that team. The PM, PD, and TL will work together to determine what the team should work on. They’ll also work with our UX Researchers, Content Designers, and Analysts who tend to work across multiple product groups. Depending on your mentors, as an AUXer you’ll be a full fledged team member, sitting alongside the PD on a specific product, or alongside the UX Researcher or Content Designer at the group level. Do I need a portfolio? No, we won’t be looking at portfolios, though it’s a great exercise in crafting your own narrative, even if you’re just starting out. Is this program remote-friendly? This program is remote-friendly.  We are able to hire candidates based in the United States as well as in Ireland. When can I apply? The listings for this role ( in the U.S. and in Ireland ) are now live on our careers site, and will remain up until April 14, 2021 at 5pm EST/ 9pm GMT. What happens after I apply? The interview process is broken up into 5 progressive stages: Resume review Video exercise where you answer a few questions Recruiter phone screen Manager phone screen Video interview with the UX team", "date": "2021-04-02"},
{"website": "Hubspot", "title": "Why HubSpot began publicly answering its own interview questions", "author": ["Timothy Downs"], "link": "https://product.hubspot.com/blog/bid/64001/why-hubspot-began-publicly-answering-its-own-interview-questions", "abstract": "Most technical students are familiar with the concept of a test bank. For those who aren't, test banks are collections of old tests and homework. They can be passed down informally from older students to younger ones or they can be complex digitized systems spanning years worth of material. The basic idea is that if you have an idea of the format in which the professor will ask you to demonstrate the knowledge you've attained in class you'll be able to get a higher grade. When I was in school, all the professors knew our fraternity system maintained elaborate test banks called \"cribs\". They chose to handle it one of three ways: ignored it, acknowledged and fought against it or embraced it. Those who ignored it passed students that then flopped when asked about the material later. Those who fought against it spent untold amounts of time massaging their material to be crib proof. Their students often tried to absorb everything and often times weren't able to properly demonstrate their knowledge. The professors that embraced it focused on their old tests and changed minutia that required true knowledge of the concepts. They were open about the fact that they knew where you'd be looking for guidance and encouraged you to practice as much as possible. Their students were most often able to both accurately demonstrate knowledge of the material and the professors were able to quickly and easily identify those who didn't measure up. Interviewing is in many ways like a test. Glassdoor is a great website that has many useful features, including a test bank of sorts where candidates can share information about the questions they were asked during their interview. As Glassdoor grew in popularity and as HubSpot interviewed more and more people the inevitable happened, our tests made their way into the bank. We had a choice to make: What kind of testers where we going to be? Sticking our head in the sand and carrying forward, besides being very much against the very fiber of HubSpot, seemed like it would inevitably lead to some poor hires. Poor matches have the potential to hurt our business and they eat up a ton of time. We could work really hard, constantly monitor Glassdoor and spend a bunch of time coming up with new questions. The chances of us being able to generate radically new questions that tested for the knowledge and skills we most value at the same pace they leak out seems very unlikely and in the mean time, we may miss out on candidates that will have the potential to be great HubSpotters. Ruling out the first two options left us with one obvious choice. Moving forward we're going to embrace the transparency that Glassdoor provides. We've going to answer the questions as they come out. We want candidates to know exactly what we've done in the past to identify our current team. We hope that by doing research into what questions we've asked and why, they'll come prepared with their skill set best tuned for us and we'll be able to quickly and accurately identify the candidates that best fit our needs and capabilities.", "date": "2011-05-12"},
{"website": "Hubspot", "title": "Name Dropping: Amy Schultz, Senior Director of Product Recruiting, LinkedIn", "author": ["Francesca McCaffrey (She/Her)"], "link": "https://product.hubspot.com/blog/name-dropping-amy-schultz-senior-director-product-recruiting-linkedin", "abstract": "Name Dropping is a Q&A series that aims to elevate the stories of women and nonbinary people leading in the tech space. The idea came from Angela DeFranco, a VP of Product at HubSpot, who said one way to be better allies is to name drop more women and nonbinary people in discussions of achievement, inspiration, and disruptors in tech, instead of referencing, time and again, the same set of (often male) leaders. This edition of Name Dropping features Amy Schultz , Senior Director of Product Recruiting at LinkedIn . What are the top priorities your team is working on today? What challenges are you solving? Diversity, inclusion, and belonging (DI&B) is our number one talent priority at LinkedIn, and it certainly is for us too in Product Recruiting. It’s super important for us to recruit talent that reflects the diversity of our member population, as the people we hire are designing and building the products our customers and members use every day. Therefore, for our products to be inclusive for our over 660 million members, it’s vital that the talent we hire can reflect, represent, and have empathy for the experiences different groups have across the globe on our platform. While this can be seen as a ‘challenge’ to solve, it presents a huge opportunity to help LinkedIn realize its vision of creating economic opportunity for every member of the global workforce. Never before has the intersection of talent and business strategy been more integral to how companies respond to and rebound from COVID-19. What underpins the future of work is empathy and the experience we create for our members, customers, candidates, and employees. Can you talk to us about how remote work is changing your recruiting approach at LinkedIn, if at all? When LinkedIn moved to a work from home model globally, we made the move to a virtual interviewing and hiring process overnight! While we were already using video technology to conduct many of our interviews, we had to pivot fast, and to the credit of our recruiting teams and hiring managers, we were able to do so relatively seamlessly. Once that was done, we needed to think through ‘how do we create a world class candidate experience that’s 100% virtual’? We’ve replaced in-person office and campus tours with video tours and have partnered closely with our Learning and Development and IT teams to help ensure a positive onboarding experience. There were a few bumps at first, but it’s been amazing to see so many teams pull together quickly to come up with creative ways of making things work in a remote world. Given most tech companies in the Valley (and globally) will continue to allow employees to work from home for the medium and even long term, this creates such an amazing opportunity to rethink our hiring and talent strategy, which I believe could have a very positive impact on DI&B. I predict we will start to be more open to hiring talent where they are, rather than having them relocate to the Bay Area or another location. I’m excited about the convergence of workforce planning, DI&B, and real estate, and how together these groups can reimagine the workplace and workforce of the future, which I hope will be more inclusive and hyper-focused on employee experience. Let’s go back in time a bit: how did you first get into the tech recruiting field? I’ve been with LinkedIn for over five years now. Prior to that I was a recruiting leader in the pharmaceutical industry. I was living and working in Shanghai and one day received an InMail from LinkedIn. Fast forward to me moving to Singapore to join LinkedIn! I spent three years there leading recruiting teams in Australia, Southeast Asia, Japan, Hong Kong, and China and then two years ago I relocated to San Francisco to lead our Product Recruiting team. It’s been an incredible ride professionally and personally, and I’m immensely grateful for the opportunities. When you think about the best product recruiters you’ve ever worked with, what characteristics did they embody? Without a doubt, curiosity! Being curious about someone’s motivators and the products they’ve built is critical when interviewing candidates. They also need to stay curious about their own company’s product roadmap to help identify talent that could help design, build, and launch the products of the future. The other important characteristic is being insights-driven. We talk a lot about the importance of data-driven recruiting, but being able to take that one step forward is key. Data only becomes an insight when it comes with a recommendation, and the best recruiters I’ve worked with actively work on their confidence and communication skills to make those recommendations. Being able to tell a compelling story with data to a leader to help inform a decision or role pivot and also being able to tell a captivating company story to a candidate are recruiter life skills! When you’re recruiting for a product team, what makes a candidate stand out outside of a traditional resume/experience? We recently launched a new approach to hiring at LinkedIn designed to shine a light on candidates’ skills, not their resumes. We removed basic requirements for a particular role and added in an optional learning path and skills assessments to the hiring process to enable candidates to both learn and demonstrate that they have the skills to do the job at Linkedin, when they may not have ‘the traditional experience.’ Working in tech and at LinkedIn has highlighted to me that the network gap is real⁠ — meaning knowing people working at companies who can refer you or can facilitate introductions is a huge advantage and therefore an acute disadvantage for those who don’t have these connections. The other is the opportunity gap. By that I mean having the opportunity to interview for a role when you don’t meet the basic requirements based on previous experience or education, but you do have transferable skills and with access to learning or re-skilling, you could in fact do the job. At LinkedIn we are actively working on closing both these gaps. Learning agility, diversity of thought and background, and a unique perspective to add to a company’s culture are all areas that I look for outside of a traditional resume, because companies will not be able to evolve and become truly inclusive, diverse places to work if we continue to just focus on assessing the tried and true. What advice do you have for women and nonbinary people pursuing careers in tech? It might not seem from the outside that there are people who look like you working in tech, but there are! It’s also possible to not come from tech and have a great career working in the industry. I didn’t come from tech before joining LinkedIn! Creativity, problem solving, collaboration, design thinking, systems thinking, and grit are all needed skills and attributes for working in tech and they are transferable. The brilliant Carla Harris says that we should focus on the content of the job and the skills that we will learn, not the job title. So for women and nonbinary people pursuing careers in tech, I think it’s so important to look for managers who will invest in you and to surround yourself with people from whom you can learn and who will be advocates for you. We need people who will speak on our behalf when we aren't in the room, but we also have to use our own voice, too! It's important to speak up and be allies for one another. Who’s one woman or nonbinary person in tech you’d like to name drop and why? Renee Reid is a Senior UX Design Researcher at LinkedIn with such magnetic energy you can’t help but smile and be inspired in her presence. I always love our conversations. Renee is a leader in her field of Human-Centered User Experience Research, is a mentor to many, and if you get the opportunity to hear her speak on a panel or present at a conference, you are always enthralled. Renee is a huge advocate of and activist for representation change in the tech industry and is a legit force of nature whom I’m lucky to work with at LinkedIn! What advice would you have for your 22-year-old self? It's all not going to go to plan, but it is all going to be ok. Stop comparing yourself to others and basing your definition of success on relationship status or job title. Your time will come and while you might not have all the things you thought you wanted by the time you felt like you should have them, the adventure ahead is better than you ever imagined. Don't worry, what's for you will come your way. What’s been your favorite recipe or takeout place while quarantining? Like the rest of the world, it would seem, I have tried to perfect banana bread and decided adding chocolate chips is a must. I have also got my lasagna-making game down pat. Clearly diet hasn’t been a huge priority during quarantine! Know another woman whose name we should drop? Tweet us at @HubSpotDev with ideas. This article originally appeared on Medium .", "date": "2020-07-28"},
{"website": "Hubspot", "title": "The first ever Boston Hadoop User Group (BHUG) meetup", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/29688/the-first-ever-boston-hadoop-user-group-bhug-meetup", "abstract": "Last night HubSpot hosted the first-ever Boston Hadoop User Group (BHUG) meetup.  Organized by Dan Milstein and hosted at our office, the event had a good turnout and great talks. I think we had about 45 people RSVP on meetup.com , and about 40 showed, so that's pretty good.  There was a lot of decent socialization, pizza, and beer.  In fact, Dan kind of had to get people to shut up so we could have a talk or two ;) Ryan from ScanScout gave a fun talk about Apache Hive , which generated some discussion, and we also had a few quick \"lightning\" talks, although I couldn't stay around long enough to hear all of them.  I think overall the level of energy was fairly high, and there is a lot of evident interest in these topics. We've been getting positive feedback today and expressions of interest, so we'll definitely do another Hadoop meetup.  Whether we host it or someone else does, the group has promise, and you should join if you care about processing large amounts of data. Useful links: - Boston Hadoop User Group on Meetup.com - Hadoop itself (and Hive ) - Ryan's talk slides", "date": "2009-10-29"},
{"website": "Hubspot", "title": "Name Dropping: Michelle O’Keeffe, CEO of Engaging.io", "author": ["Francesca McCaffrey (She/Her)"], "link": "https://product.hubspot.com/blog/name-dropping-michelle-okeeffe-ceo-of-engaging.io", "abstract": "Name Dropping is a Q&A series that aims to elevate the stories of women and nonbinary people leading in the tech space. The idea came from Angela DeFranco, a VP of Product at HubSpot, who said one way to be better allies is to name drop more women and nonbinary people in discussions of achievement, inspiration, and disruptors in tech, instead of referencing, time and again, the same set of (often male) leaders. This edition of Name Dropping features Michelle O’Keeffe , CEO of Engaging.io , a HubSpot partner agency. You’re CEO of Engaging.io, a human-centered digital strategy, design, and development firm. What are the most exciting challenges you’re currently working on? Things are obviously changing pretty quickly at the moment, as they normally do in tech. With everything that happened this year, we’ve got to answer to the business. We’ve got an agency arm and we’ve got a product development arm. And we were always hoping to build more and more products, some of those associated with HubSpot. Some might be HubSpot plugins. But we build other things, as well. And I think what we ended up focusing on was solving the biggest pain points for our enterprise level clients and turning those into products. We’ve been able to launch two since the beginning of the pandemic, which has been really good. And it keeps our engineers happy, as well. They love building products, as opposed to running multiple agency projects at any one point in time. We’ve escalated this kind of work because of COVID, and because of that recurring revenue model that those products have, versus most of our agency work, which is all project based. It’s been really good. I’ve been really happy and proud about the progress we’ve made there. When you visit Engaging.io’s website, you list all the ways that you, as a company, are “engaging humans” ⁠ — through intuitive UX, through reporting and attribution, through beautiful websites, etc. What does true engagement mean to you? We’ve got four directors of engaging, and we’d all been off in corporate doing our own things before we came together about 10 years ago. Our approach with every client is very much, if this were my business, what would I do? We treat every client as if it were our business: these are the challenges, this is what they’re facing, this is what they’ve asked us to solve for. And given that approach, sometimes we reverse-engineer what they’ve asked us for or what the brief was for. But it means that we’re really open and honest. And, you know, most of the time, there is a reverse engineering of the brief as well, which was made at the beginning of the relationship. There might be uncomfortable conversations to a point, but our clients also give us this element of trust. I think that’s why we’re so successful. We try to instill the same thing in our staff. If you’re talking to a client about the brief, put yourself in their shoes. And imagine if this were my business, and this was my money and my revenue, what would I do? You also have to say no sometimes, though. If there’s not a good cultural fit between us and a client, we have to say sorry, we can’t help you. Especially right after we see the brief. They may want us to build something we know isn’t going to work. We’ll say look, this is what we would recommend doing. If they don’t want to hear it, we’re not going to build something that we know is going to fail. Not everybody’s used to that approach. But I think it’s the honest way of doing business. And certainly our staff like working on projects that work, and that achieve really good outcomes. And that’s self-perpetuating. We’re 100% referral, because we work that way. That’s the core of engaging: connecting as humans first. What are your business challenges second, and then how can we solve for those? How has solving for your customers changed, if at all, during the current pandemic? When everything first hit, nobody really knew what was going to happen, or how we would all be impacted. I think we definitely got off lightly and HubSpot was really helpful, as well. In that sense, it was kind of miraculous that HubSpot acted so quickly, and identified that one of the biggest pain points would be cash flow for organizations like ours. We’re still having the same amount of sales conversations, and we still have plenty of work to do. But clients that we had been working with, their businesses fell away overnight, and now they had to say to us, I know, you’ve done this work over the last three months, but we now have no money to pay you. So that was our biggest struggle. Now, we’re very, very comfortable with the conversation around payment plans for clients, because their businesses still need to be able to function. We’ve just had to be flexible there in order to help them. And I think, while MVPs in tech have always been an intelligent way to go, it’s much more part of the conversation now: “I just need to get to market with this as quickly as possible. I need to prove that it works.” And then you can build out and adopt an iterative approach later. What would you say is your greatest career achievement to date? I’ve done lots of things and been lots of different places. For a while, this was for big corporate companies. And I did some cool things there. I made it to the top of my career space. I was with an organization that paid more than anyone else, and things like that. From a career perspective, that was great, but at the same time, I was working 120 hours a week, and was not very healthy. This came as a surprise to me at the time, which it probably shouldn’t have. And I ended up just thinking, it’s great to have all this money and everything else with it, but I’ve got nobody to spend it with and nothing to spend it on. I don’t have a life. So I ended up quitting. That was one of the funniest conversations I’ve ever had. Because they asked, Where are you going? And I said, I’m not going anywhere. And they said, I know you’re going somewhere. And I said, I just don’t want to be here anymore. We went in circles for about 20 minutes. Fast forward to my career now, and my greatest career achievements aren’t on paper ⁠ — they’re about people. We, as directors, we’re all really clear that we wanted to create this environment within our company that acknowledged that work is secondary to real life. Of course, you spend a reasonable amount of time at work, but there’s no reason it can’t be an enjoyable place to be, and we can’t all be nice to each other. It’s like a little mini community. We’ve always had a great culture, but I think it was really demonstrated for me with COVID. At the beginning of the pandemic, we all said, Okay, everybody work from home. We’re lucky ⁠ — we’ve got all the tools and tech we need to keep things functioning without being in the office. But everyone was working 1,000% because nobody knew what was going to happen. They were working for each other, going the extra mile ⁠ — directors were working really hard to make sure employees were all still getting paid 100% of their salaries, because a lot of their partners had been laid off. In short, we knew that our people were working hard, even from home. I didn’t think about this too much until I spoke with some other agency owners and they said, I’m really worried, I hate the working from home thing, because I don’t think my people are working. And I thought, How does that happen? And I sat down and thought about it. I honestly think that would be my greatest achievement: building and fostering this team of people who work for each other and care about each other. Which is what happens with community, right? When you come together, you can do great things. And that’s just not something you can tell people to do or be. That’s something that we’ve built. People feel like they are part of the community, they care about each other. They go the extra mile for each other and the company succeeded because of it. What advice do you have for those with nontraditional backgrounds looking to break into the tech industry? In tech, I think it’s a more of a level playing field in the sense that if you build a good product, it doesn’t matter who you are, doesn’t matter what you look like (your end customers can’t see you). But in that context, there’s still the same sort of hierarchical games that you have to play if you want funding, and things like that. And I think I’ve always naturally called that poor behavior and naturally gravitated away from that behavior. If you’re getting into tech, there still needs to be this awareness and social responsibility. If you’ve got good ideas and good ability, I think that gets you in the door. But once you’re in the door, not everyone benefits the same. Nor is the place you’ve found yourself always a place you want to stay. I think it’s worth looking for those people and organizations that share your values, and gravitating toward and aligning with those people. While sometimes the money and the bright lights might be somewhere else, going that route instead can equate to selling your soul. Over the course of a career, you might find yourself asking, How did I get here? This doesn’t match with my value system. That’s why people have their midlife crises. It’s really worth finding your niche within tech. People who work in a way that is consistent with your values. We’re all human beings, and work is a part of our life. And if you don’t like your work, you don’t like what you’re doing, what you’re able to achieve, you won’t be happy in the rest of your life. There’s lots of opportunity out there, almost too much. New products are coming up all the time. You have to decide for yourself where success lies. I’ve worked in very male-dominated industries, even before I got into tech. I’ve seen some very poor behavior, but I always spoke up and did the right thing by myself. But what I came to realize over time is that not everyone is like that. And that I should be using my voice and my ability to actually help support people who for various reasons feel like they can’t speak up the way I have. And it’s not just being a female in male-dominated industry. In all of the different contexts that people face, we have a social responsibility to look after those who don’t have the same voice that we have. And it’s hard, and it can feel like it’s going to be career-limiting. But that’s never been the case for me. So if people feel like they have the platform to speak up, then I highly encourage it. What’s the most important lesson you’ve learned so far from your experience as a CEO? Apart from that daily feeling of having no clue what I’m doing? It’s that old adage, the more you know, the less you know. It definitely applies. Honestly, the biggest lesson has been to look after myself. You’ve got this idea that the buck stops with you, you’ve got to do everything to get there, push yourself to get there. But, COVID brought this lesson to me, because I was just getting exhausted and burned out. And you cannot be of any use to anyone if you’re burned out. They say to mothers, if the mother’s sick, then the kids don’t thrive. It’s the same thing. It’s a little bit counterintuitive, but I honestly think if you, as a leader, take time for yourself to make yourself healthier, then you’re going to have more to give to others, and you’re going to do a better job. I’ve not always been good at it in the past, but it’s so important. You have a background in teaching Qigong ⁠ — are there any skills from that experience that you use in your current position? For me, that’s the real stuff. That’s what gives meaning to my life, full stop. Everything kind of underpins that. One of the really good sayings in Qigong is “energy flows where attention goes.” Being mindful about what it is that you’re trying to achieve, and then directing your energies to that will give you success every time. It’s really easy to get distracted and have what they call ‘monkey mind’ and try to do too many things at once. But at the end of the day, if you set goals, just like an organization sets their business objectives for the year or the next three years, you can achieve them. It’s just as important for a person to set goals as an organization. Put them up somewhere where you can see them, where they are integrated in your daily life, and then they’re something that you think about and your energy goes toward them naturally. That’s been really good for me, that sort of single-minded focus. Filter out the noise and focus on one thing. I think our brains need meditation. It is so rejuvenating, for us to try to slow our brains down like that, especially with the sort of work that we do, and the amount of information that we absorb. I think it’s really nice to have those big ideas and those dreams. They’re the sort of things that make life exciting for me and give me motivation as an individual. There’s a little bit of mystery around that, as well. It’s great to make money, it’s great to build great things, but at the end of the day, life is always going to be way more important ⁠ — real life, beyond work. That was just a belief that we had when we started the agency, but after living that way, everyone has benefited from it. People love to work here, they stay here a long time, they contribute wherever they can, and I think they feel supported. This idea that the individual is everything just doesn’t work. It’s community. We’ve got this responsibility to look after each other no matter what you look like, or what you do for a living, or what you have or what you don’t have. None of that matters. I think you can have a business that makes money and still live that way. They’re not completely separate ideas. That was the philosophy that we had. There were a few moments early on, where I thought, Oh, this cannot work. But it does work. It does work. There are plenty of agencies that started at the same time that we did, and they don’t exist anymore. It’s because they didn’t treat their staff well. You need to put your profit into the business and hire more people. Make sure everybody is looked after. That works. Who’s one woman or nonbinary person you’d like to name drop, and why? Over my career, I have found that my female bosses were much more difficult for me than my male bosses, who were also challenging. But I’m 44. That was a while ago. And I’d like to think that things have changed a bit since then. We may have talked the talk then, but we didn’t actually walk it. That said, I don’t have the feeling that I’ve had women leaders in my personal life whom I aspired to. But I do know great women through my own company. We’ve got some great female engineers, who are really open about balancing their real lives and their kids and their work. And they’re just unashamed about it and unapologetic about it. And I really liked that because it normalizes what it means to have these other challenges in your non work life. And I think it’s little things that are brave. So there’s Neema Tiwari , who is a developer of ours. And she’s obviously working from home at the moment. Her family comes first. And she doesn’t skip a beat with work because she uses her flexibility however she needs it. Sometimes that might be doing something at two o’clock in the morning, although we try to try to make sure she doesn’t do that. But I really like that, just this absolute idea that this is who I am, this is what’s in my life. And I can still make this work. And I can still do phenomenal work. I think it’s really cool. I remember interviewing her. And it was actually the case for all of our women on the team. They were all very outspoken in the interviews about their abilities. I hadn’t heard women be that outspoken in interviews before ⁠ — you hear it a lot from men: Yeah, I can do that. Even if they’ve never even contemplated doing it before. And that was the thing that resonated with me. You are demonstrating to me what your value is. Let’s give this a go and see how far we can take it. I love that. That’s my favorite thing. Empowering each other. What advice would you give your 22-year-old self? So firstly, I would not have listened to it. I’m stubborn. Like I said before, I’ve learned well by making mistakes, but very rarely by following advice. I would say, don’t work in corporate. Find something you love. And do that. Regardless of whether you think it’s going to make money or not. At the end of the day, you find a way to support your lifestyle by doing something that you love, and there are so many ways now that we can do that, that maybe I wasn’t aware of back then. I thought, you finish school, you go to university. But I struggled at university. I did a Bachelor of Arts and thought, why am I here? There was no motivation. I finished, which I think was my greatest achievement ⁠ — actually completing my degree. But then I thought, I need to get a job. That’s what you did. I didn’t have a lot of advice around me. So I was just a bit of a leaf in the wind and ended up finding my own way. So that would be the biggest thing ⁠ — find what you love and do it, regardless of what you think is right or wrong about it. If you do that, it’s got to be an interesting journey. Know another woman or nonbinary person whose name we should drop? Tweet us at @HubSpotDev with ideas. This post originally appeared on Medium . Interested in working with people who care about thoughtful leadership? Check out our open positions and apply .", "date": "2020-12-22"},
{"website": "Hubspot", "title": "Unlimited Vacation: HubSpot Product and Engineering Edition ", "author": ["Hannah Fleishman (she/her)"], "link": "https://product.hubspot.com/blog/unlimited-vacation-product-team", "abstract": "In the early days of HubSpot, a developer had worked nights and weekends to get a critical project to the finish line. Shortly after, he asked CEO Brian Halligan (who ran the product organization at the time) to sign off on his requested vacation days. It hit Brian how backward it was that this employee had the autonomy to drive a serious company-wide initiative but needed permission to take time off. Today, employees are evaluated on their results, not the number of days they're in the office, thanks to a \"policy\" called unlimited vacation. One thing unlimited vacation has revealed over the years is that our product and engineering team is full of jet-setters. When they aren't building best in show software, our developers, designers, and product leaders can be found in every corner of the globe (really, look ) making them some of HubSpot's best travel guides. F rom Iceland to India, these recent trips share a glimpse (and snapshots) of where unlimited vacation has taken our tech team over the past year. Japan: Meghan Nelson, Software Engineer \"My boyfriend, a mutual friend and I spent a week in Tokyo, three days in Osaka, two days in Toba, a day in Kyoto, then back to Tokyo. We (purposefully) went during cherry blossom season. There's a Japanese tradition called 'hanami' during this season which is essentially picnicking/partying underneath the cherry blossom trees. We set out in Osaka to do our own hanami at Osaka castle. I was expecting it to be just a couple of people, some blankets and that's it - but no, hanami is serious business. The whole place was packed and people came very prepared. It was similar to how people gather around the Charles River in Boston on the 4th of July with their own tarps and sit there all day for the fireworks. It was just a really nice, relaxing experiencing sitting under the cherry blossoms, by the castle and the water, surrounded by all these people having a good time.\" Cape \"Code\": Francisco Dias, Design Engineer \"This summer was the second year HubSpot's rented a beach house on Cape Cod for our product team. We call it Cape Code. Over the course of a week, about 70 of us went up (either for the day or to stay overnight) and played frisbee in the ocean, had a campfire until 4:00AM, cooked an entire lamb, played every board game we could find, set up a fish taco bar, and way more. Co-workers who like to entertain (and there are lots of them) jumped to cook, make s’mores, mix cocktails, or set up bocce for everyone. Cape Code was great because I got to go with friends who truly enjoy creating great experiences for everyone else; we all brought something to the table that made it an unforgettable week. Having a beautiful house on the beach didn’t hurt either.\" India: Rachel Decker, UX Researcher \"For the month of February I traveled to India on a tour with travel blogger Wandering Earl . I had been following his blog for a few months when he sent an email about upcoming tours he was running (email marketing works #inbound.) India was the first on the list and somewhere I never thought about going alone, so I decided to check it out. It was incredibly affordable for a 3-week trip and I knew I would meet a bunch of amazing people, so I pulled the trigger and reserved a spot. It was an incredible experience where I met 10 hilarious and really cool fellow travelers and saw things I will never forget. The best thing was getting to know everyone and knowing I now have friends I can visit all over the world. The weirdest thing was seeing a cow on a train platform at 2 am. It had to go down stairs to get there.\" Thailand: Lincoln Bryant, Software Engineer \"I recently visited Thailand and marked the #1 spot off my vacation wish list. I didn't bring a laptop or have cell service and my tech lead and product manager were great in planning around the trip (we really are 'teams' at HubSpot.) This gave me the luxury to be truly immersed in the scenery and culture, ranging from the capital metropolis of 10 million people to uninhabited islands in the Adaman Sea in the south. We found ourselves visiting during Song Kran (Thai New Year) which is an interesting mixture of Buddhist ceremonies and squirt-gun fights in the streets. Food is integral to culture, with bustling night markets offering familiar staples like green curry and pad thai, and also surprises like edible insects and exotic live seafood. One of the best parts of the trip, though, was visiting an elephant sanctuary where tourists can interact with wildlife and endangered Asian elephants.\" Iceland: Talia Swartz, Software Engineer \"This past winter I went to Iceland with a group of 12 other HubSpotters on an amazing whirlwind 3-day trip. We saw incredible natural landmarks, swam in hot springs, and even got to go caving in a lava tube. It was really like no other place I've ever visited, sometimes it almost felt like another planet! My favorite part was probably getting to see the Northern Lights, which was something I never thought I'd get to do.\" ( Editor’s note: The Iceland crew (and fellow wanderlust-ridden HubSpotters) is currently planning a 10-day trip to Asia in their ‘Vacation Club’ HipChat room.) Maldives: Ian Marlier, Director of Reliability \"I share a common trait with many other engineers: I find it incredibly hard to actually put my work down.  It's not that I don't like travel, or vacation, it's just that even when I'm traveling or on vacation I feel the need to stay in the loop. To break myself of the habit, my girlfriend and I decided to visit Maldives, an island nation in the Indian Ocean known for it's snorkeling and diving, brilliantly white beaches, excellent seafood -- and terrible Internet connections. We swam in an infinity pool, got massages, read on the beach, sailed in the lagoon, and pretended that the world didn't really exist.  As amazing a place to work as HubSpot is, there's a lot to be said for having the ability to truly disconnect from work, and to let your mind focus on other things.\" Read more about unlimited vacation in HubSpot's Culture Code .", "date": "2015-07-30"},
{"website": "Hubspot", "title": "My Father’s Accident Brought Accessibility Into Focus", "author": ["Bryan Hoy (He/Him)"], "link": "https://product.hubspot.com/blog/my-fathers-accident-brought-accessibility-into-focus", "abstract": "Have you ever gotten the call? You know, the call that heralds a seismic shift in the life of someone you love, or even yourself. Last year, I received the call from my panicked mother, and she told me that my father had gotten into a serious bicycle accident, and because of the severe spinal cord injury (SCI) he sustained, had lost the use of his arms and his legs. My father had become quadriplegic. I immediately booked a flight back to my childhood home in Calgary, Canada and spent the following weeks with my father in the intensive care unit, reading up on SCIs, helping my mom around the house, trying to take over the day-to-day financial affairs of the family and finding accessible tech solutions for my father (did you know you can control your iPad with only your eyes?). I was a complete mess, and definitely not my best self. I wrote a couple short emails to my manager and team leads and they were all incredibly supportive. “Take all the time you need,” was their collective answer. And I felt as though they truly meant it. Walking along the Great Wall with my father in 2015. Dad’s recovery was going well, and after several weeks of being away, I felt comfortable coming back to work. To be honest, having a little bit of routine back in my life was nice, and coming into the office was a welcome distraction. I was once again inundated with support, and had to convince everyone that I was back at work not because I felt like I needed to show face, or prove my commitment to the company, but because I felt comfortable with my father’s recovery. Because of HubSpot’s commitment to remote work , even in a pre-COVID world, flexible work arrangements were available to me so I could spend time with my father. I also had the HubSpot Employee Assistance Program at my fingertips, which offers a multitude of services including counseling. Lessons learned the hard way As I returned to work, I had a whole new lens on the issue of accessibility in technology. Here are a couple of the lessons I took away from the experience. You might not see the accessibility gap until you’re tripping over it Accessibility is one of those things that is invisible, until all of a sudden it isn’t. Human nature is often to ignore the things that aren’t directly relevant to you. I hope that through my father’s story, we can all become better at spotting accessibility-related issues and bring them to the attention of our companies and communities. The social model of disability defines ‘ disability ’ as a mismatched interaction between a person’s abilities and their environment, and around 70% of disabilities are not visible at the surface. It could be very difficult for my dad to find a job now and to use many tech products. My father is an ideal job candidate: he’s incredibly smart, received his bachelor’s degree in engineering as well as a master’s degree in business, and founded several small businesses. I fear, however, that many employers would look at him and their first impression would be based on his disability, not his accomplishments. Furthermore, I’ve realized that he would have trouble using most devices and apps. Strides are being made, though⁠: this video from Apple about Voice Control for Mac and iOS is a great example. Treating people like people engenders loyalty At the time of my father’s accident, I had been working at HubSpot for a mere four weeks. Company leadership treated me with respect and empathy during a very difficult period, making me feel very grateful that I had chosen to work here. HubSpot’s Culture Code states “Life is short. Always be kind and compassionate,” and we can all embody that spirit no matter our role — whether it’s welcoming a new parent back from parental leave with more empathy, or creating space for someone who is dealing with a family emergency. I also learned that everyone has the ability to improve accessibility in your company or your product, no matter your title or role, and that even if you yourself do not have a disability, there are key steps you can take to ally yourself with people with disabilities. So, what can you do to help? Spot accessibility gaps Observe and bring attention to accessibility gaps in the world before something happens to someone in your life. As Microsoft’s Christi Olson said in her INBOUND19 talk , “think about accessibility by design, not as an afterthought.” Think about accessibility gaps in your physical workspace as well as in your product and listen empathetically for concerns raised by your customers, partners, and prospects. Get involved! Get involved in accessibility initiatives. At HubSpot, our Accessibility Task Force aims to make our product more inclusive and accessible to everyone. I’ve joined the group, and my new personal mission is to help people like my father get the most from our platform. Regardless of which company you work for, Microsoft’s Inclusive Design , WebAIM and the Web Accessibility Initiative resources are world-class for recognizing accessibility gaps and designing with accessibility in mind. Recruit a diverse team Actively recruit and hire people who live with temporary or permanent disabilities. Not only is this the right thing to do, but research shows that diverse teams outperform homogeneous ones . If someone you know is looking to join a company that embodies these values, HubSpot is hiring . Final thoughts Full accessibility should be what all of us in the tech industry are striving for. Even if you’re not there yet, now is the time to start. As a leader in your company, think about how you can start implementing these changes throughout your team, your workspace, and your product. As an individual contributor, be diligent about spotting gaps and bring them to the attention of your team, and think about starting an employee resource group dedicated to accessibility issues. You can make a difference⁠ — no matter how small it may seem on the surface, it has the power to change someone’s life. Someone like my father.", "date": "2020-07-29"},
{"website": "Hubspot", "title": "Why do we have an img element in HTML? Because shipping code wins.", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/29987/why-do-we-have-an-img-element-in-html-because-shipping-code-wins", "abstract": "My colleague Steve L pointed out this great blog post , documenting the history of the img tag in HTML.  It's written like an investigative journal account, not a boring technical manual, although the technical details are all there. Mark Pilgrim is the author.  Thanks, Mark.  I've just subscribed to your blog ;) It boils down to shipping code.  Get it out the door. Release early and often .  Remember that facts exist outside the building, while opinions live inside .  That's why you want actual feedback from actual customers, not would-be / theoretical folks. Your baby is ugly , but it will get prettier over time if you do this.", "date": "2009-11-03"},
{"website": "Hubspot", "title": "Celebrating 2015, a Blockbuster Year for People and Products", "author": ["Hannah Fleishman (she/her)"], "link": "https://product.hubspot.com/blog/product-engineering-2015-review", "abstract": "It isn’t hard for product people at HubSpot to agree on what the most important milestone of 2015 was. We spent months anticipating it, hours preparing for it, and days reflecting on the highs and the lows after it was over. That’s right, Star Wars: The Force Awakens was a defining highlight. But like many engineers, designers, and product leaders around the world, our development team has a lot to celebrate from the past year beyond the destruction of a third, even larger Death Star. For starters, we welcomed a ton of new HubSpotters (read: Jedis) to the team. There are now over 170 people building, designing, and managing our software between Cambridge, MA and Dublin, Ireland. That's 69 newbies. New talent means new teams and new products. We introduced huge improvements and additions to our software (some were even introduced at the INBOUND conference in front of 15,000+ attendees) like the Ads Add-on , the Reporting Add-on , HubSpot Connect , and brand new content editors . While many of our dev teams were working on our marketing platform and growing our sales products, one team was working on a brand new tool to bring inbound to everyone: Leadin (which can best be described by Kevin's tweet here ). Of course, 2015 wasn't all software all the time. We rented a summer house in Cape Cod, spent four days in Texas at the Grace Hopper Celebration of Women in Computing , worked from a cottage in Ireland for a week, successfully consumed several 35 ft. italian subs, trolled each other (lovingly) on Slack, had a dance party with our customers, got to meet and learn from the creator of Kafka , mingled with over 500 attendees at Tech Talk at Night events, wore some very ugly sweaters at the December Science Fair, and got front row seats to a surprise kung-fu dance performance at our annual INBOUND Product Party . To recap, here's a snapshot of some of our other favorite highlights, milestones, and moments from 2015: All in all, it was a banner year for people, technology, and J.J Abrams . Thank you to our customers and the entire HubSpot team for making 2015 awesome. To see what else HubSpot was up to in 2015, visit hubspot.com/move to see highlights from across the company.", "date": "2016-02-12"},
{"website": "Hubspot", "title": "5 great QA blogs", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/7776/5-great-qa-blogs", "abstract": "Kashif Ali posted a good comment on our blog post from last week, \" What makes a good QA engineer / tester? \"  In his comment, he linked to four more good blogs on the subject. The Google Testing Blog is decent.  It has multiple authors, as with most Google blogs.  The posts are not very frequency: once every week or two is typical.  But then they tend to be longer, more essay-like.  Personally, I prefer multiple shorter posts, but that's just me. Jonathan Kohl writes Collaborative Software Testing , which I really like.  It focuses on the toughest issues around testing, which are teamwork and process.  Most testing blogs focus on technical tools and tips.  Those are fine, but I usually don't find those to be the hard parts.  The posts are still long and essay-style, but I enjoy them a lot. James Bach writes The Consulting Software Tester .  He is an experienced, known software development \"guru.\"  He blends short quips with longer essays, which is nice, and he also quotes / links to more external resources than the other blogs.  Personally, I find a really good insight, a gem, about once every five posts on this blog.  It's worth reading for those alone. The last blog on this list is The Thinking Tester, by Shrini Kulkarni.  James Bach, for one, is a fan.  I only recently stumbled upon this blog, so I don't know it well yet.  But it seems like the author has mostly moved from longer blog posts to Twitter.  He's @shrinik there, for the curious. All of these, along with my original favorite, Abakas , make for valuable reading.  Even as an agile, light-QA guy, I really enjoy them. Do you have other favorite blogs in this area?  Or online QA resources in general?", "date": "2009-07-07"},
{"website": "Hubspot", "title": "Inheriting Code: Why You Should Keep Code Teardowns to Yourself", "author": ["Whitney Sorenson (He/Him)"], "link": "https://product.hubspot.com/blog/inheriting-code", "abstract": "We all dream of a perfect, unencumbered world, working with a pristine code base or starting a project from scratch. In reality, I’ve started enough projects to know that I can build myself into a corner just as well as anyone else can, and that things always get messy unless you spend an incredible amount of time refactoring. I’d like to offer some advice about taking over someone else's code based on my experience: Keep your code teardowns to yourself. I learned this the hard way. There was once some outrageously wrong code in one of HubSpot ’s tools pummeling our services, and I jokingly started a witch hunt to figure out who had done it. It got to the point where people would ask me every morning “Did you find out who did it yet?” After a few days of digging I started to get a sinking feeling: I actually may have been the offender. Once I confirmed my own involvement I tried to just let it slide (“Uh, we’re still talking about this?”), but sensing my deflection, the team’s questions only increased in fervor. I eventually fessed up and felt like a total idiot, both for the mistake and for making a big deal out of it. One thing that has felt almost universal to me as I’ve passed projects on to new owners, or picked up where some other team left off, is that the initial reactions are almost always too harsh. It’s very easy to be a critic, especially of someone else’s code (or even your own). Maybe we think of it as a rite of passage when we talk shit about a code base, but it can alienate the former team and is only a useful mindset if it pushes you to worthwhile action. It can also be poisonous for your team members and shift their perspectives to pessimism. Overall we should assume best intent and try to look at things optimistically. Finding a problem or bug in someone’s system shouldn’t be met with “Wow, how could we let this happen :sadpanda:?“, it should be “Wow, I’m glad I was able to spot and fix that issue.” There are two possibilities to consider next time you take over someone else’s code: The code has legitimate structural issues, logic errors, and bugs (and you should just fix them), or you’re suffering from some sort of Dunning-Kruger effect where you don’t know enough to be accurately critical. It’s overwhelmingly likely that the team or person who wrote the code did so in a different context than the one you’re in today. They probably saw less of the problem than you do now: You may have the advantage of looking at a working or complete system with the full set of requirements fleshed out. It’s also likely they had a different set of constraints. Maybe they were operating with a smaller team, different requirements altogether, or were rushing to market. Sometimes at HubSpot we ship something and intend to iterate on it, but admittedly never get around to it. In other words, they may have been intentionally optimizing for speed over quality at the time. On the other hand, spotting issues and leveraging your new perspective can be helpful if it results in valuable improvements. I think it’s important that we don’t lose sight of leaving things in a better state than when we found them. You may even find that digging in and attempting to fix or improve code leads you down a path of understanding why things are the way they are in the first place. Personally, I’ve started large refactoring efforts a few times only to have it fall apart last minute because I’d missed some critical constraint. You’ll likely be spending a good part of your career working with code that someone else originally wrote. You might as well accept that it won’t always make immediate sense or look great. To that end, two critical skills are learning to become comfortable making changes when you don’t understand the whole codebase, and knowing what changes would be valuable. Don’t be intimidated by a code base that you’re unfamiliar with — my recommendation is to dig in, focus on how you can test or verify what you’re doing, and start making small changes. It always feels daunting at first, but seeing the system behave differently in even the most minor way after a change you made can be invigorating. I’ll leave you with two action items that I try to remember when inheriting code: Don’t complain about someone else’s code. You probably don’t have all the context. Leave things better than you found them. Embrace strange code and spend time where it is most valuable — digging in and making changes that help your customers or users — not WTFing.", "date": "2017-04-24"},
{"website": "Hubspot", "title": "HubSpot's Approach to Front-End Development at Scale", "author": ["Timothy Finley"], "link": "https://product.hubspot.com/blog/frontend-development-at-scale-1", "abstract": "Over the years, our engineering teams at HubSpot have run into issues with deploying, updating, and sharing front-end assets (e.g. Javascript, CSS, images, etc). Sure, web development has come a long way, and the latest browsers, libraries, and tools enable us to build incredibly rich and complex applications. But in many ways, webapp development is still quite young. In particular, the tooling needed to help larger-scale development teams share front-end code and inter-operate across applications is pretty much non-existent. It is true that we’re making progress, such as vastly improved code collaboration via Github pull requests. And the impressive surge of front-end package managers like Yeoman / Bower , npm, Jam , and Volo . These kinds of tools are great and are quickly becoming indispensable. But unfortunately, as they are right now, they still have a long way to go before they can solve some of the issues that larger-scale development teams run into, including: Having consistent styles and reusing Javascript components across several applications (without resorting to copy & paste!) Accidentally breaking other applications when updating shared CSS and Javascript Dealing with the subtle annoyances of higher-level front-end languages like Coffeescript and SASS (e.g. having to check in compiled output, keep everyone on the same version, run 3 different watchers, etc) Getting everyone to consistently use best performance practices So we did what any self-respecting team that discovers a new problem does, we built our own solution. So what is it? So what exactly are we talking about? It's a long story, but here's a sneak peek: A dependency management system for Javascript and CSS that allows our developers to share code and still move lightning-fast (with far less worry about breaking other people's applications) A local server and package manager that installs and updates dependencies for you, plus lots of other conveniences (like auto compiling SASS and coffeescript so you don't need to run any watchers) Build tools that automatically \"link\" your project's code to specific dependencies and optimize everything (concatenate, minify, and far-futures caching headers) A server-side runtime that allows those front-end dependencies to be updated on-the-fly without any re-deploying (plus easy debugging) But before we get to all the details, it is worthwhile to explain why this matters. And fair warning, this will take a little while, so we've broken it up into parts: The what's and how's of front-end dependency management. The goals and core concepts for Asset Bender.  (TL;DRers and know-it-alls, you can wait for part 2 or see the code on github ) More details about Asset Bender's internals. The path forward. Scale you say? In the beginning, most front-end development teams have one source code repository. Life is good in those days. You don't have any complicated setup scripts, dependencies are just copied right into the repository, and there is only one set of code that needs to run in production. But those days can't last forever. As your application and development team (hopefully) grows, you'll eventually hit a point where one source repository doesn't make sense anymore. Maybe it is just for logistical reasons or maybe it is because there are too many coders stepping on each others toes (everyone loves merge conflicts!), but it eventually will happen. I realize that there are lots of small companies that will never outgrow a single codebase and will never have have to worry about this. That's awesome, live it up! But for those of us that have to work with other people... Everything looks good to me When you get to the point of needing two or more front-end codebases, you'll quickly end up having dependencies between them. For example, the second project might share some base styles (CSS) with the first project. Or maybe the second project uses some jQuery plugins that are defined in the first. So what happens when those shared bits of code are updated? Do your developers realize that when they adjust the base styles in the first project, they might be breaking things in the other project? Everything might look fine when they are testing locally, but who knows what havoc it might wreck on other applications when it hits production? Copy and paste to the rescue! You might be thinking of some ways to get around this. Why not just make a copy of the styles for each project? But all that does is just trade one problem for another. Now any updates and bug fixes that happen in one place need to be replicated. Come on, we know that's not going to happen, developers are lazy! :) Another approach might be to refactor out all the shared pieces into another project. This does help organize things, and might help your developers realize that they need to be more careful when committing to the shared project, but it doesn't actually solve the core problem . You'll still only have a single instance of the shared assets in production. And deploying any breaking changes will require immediate updates to both dependent projects. In other words, all projects still need to move in lockstep and update as a unit (despite our initial desire to keep them separate!). The real solution isn't copying or organization. It is versioning . Instead of forcing both projects A and B to update at the same time to keep up with changes to shared project C, let project B rely on version 1 of project C while project A updates to version 2 of project C. Since we're keeping multiple copies of project C around, A and B can stick with the old version of C and wait to be updated as needed. The buzzword for this is dependency management . Has this been solved before? Yes and no. Yes, there are lots of mature dependency management solutions out there (Maven, Pip, NPM, etc). But all are primarily built to deal with the issues that arise when running code on desktops and servers. They simply weren't built to deal with browsers that are interpreting code and resolving dependencies at runtime. Even though the core concepts are the same, dependency management of front-end assets is quite different. The web is simply a whole different ballgame: Performance on the web is a big deal. And to do that well, you need to limit the size (and number) of your front-end assets, share code whenever possible, and aggressively use HTTP caching. However, you probably couldn’t care less about the size of the code that is running on your servers. On the web, dependencies (aka the Javascript, CSS, and images your page links to) are resolved at runtime, independently by each and every visitor that hits your page. But server-side dependencies are only resolved once when the project was built and/or deployed. Front-end webapp code tends to move faster than its desktop/server counterparts. There’s no need to package up and ship executables around, so it is easy (and preferred) to incrementally change content, styles, or code as necessary. Unlike server-side code, CSS (and HTML if you exclude server-side template languages) is static. And it is delivered to the client verbatim, unlike server-side code that can respond dynamically (different logic, fetching data from databases/APIs etc) BONUS: Sharing CSS is immensely different than sharing code. Unlike \"real\" code, CSS does not have specific API boundaries. Instead it has an amorphous set of styles ( Flying spaghetti monster anyone?) that a web page may or may not intersect with. And because of this, subtle changes to your HTML structure and/or CSS can easily break things. In other words, CSS dependencies are far more fragile and difficult to predict than server-side (and Javascript) dependencies. So yeah. Even though dependency management is an established and understood practice, something new and different is needed to deal with the constraints that come with the web. Read on to part 2 to start learning about Asset Bender—HubSpot’s tool that deals with these issues, and makes our front-end developers’ lives so much easier.", "date": "2013-03-19"},
{"website": "Hubspot", "title": "Pixels Matter", "author": ["Adam Schwartz"], "link": "https://product.hubspot.com/blog/pixels-matter", "abstract": "Last Wednesday I gave a Tech Talk, Pixels Matter, to the Dev team. It explores the importance of pixel-perfect user interfaces, provides helpful tips to train your eye to identify problem pixels within a design, and even contains a small workshop which teaches you how to fix a few common problems with CSS. View the slides (Works best in Google Chrome) View the code on GitHub", "date": "2013-03-25"},
{"website": "Hubspot", "title": "Rands in Repose on performance reviews", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/25162/rands-in-repose-on-performance-reviews", "abstract": "Since we've been talking about finding a job, I thought it might be interesting to balance it out with something that (often) happens once you have a job for a little while: a performance review. Rands in Repose , one of my favorite blogs, just had an excellent post on this topic: No Surprises . There are a whole lot of good and useful nuggets in the above blog post.  It's worth reading the whole thing.  But here's one that stood out at me, because the HubSpot engineering team is so full of stars that this is actually a real possibility: See, your boss has you and a bunch of other yous who are all allegedly kicking ass, and all of that ass kickery is tricky to monitor, especially over an entire year. It gets even worse when one of your team members is not kicking ass. Legitimately or not, that's actually where a lot of your boss' attention is going. You read that right: someone else's failure is distracting from your phenomenal year. One way we try to mitigate this is that I meet with every member of the engineering team once a month to talk about this review sort of stuff.  It eliminates surprises, for the most part.  And it lets me take notes during the year about how things are going.  But most importantly, it shortens the feedback cycle. We do the formal written evaluation thing once a year.  But I think once a year is far too infrequent to get or give feedback.  Once a month may be overkill for some people, but it usually feels pretty good / right.  At least to me.  Maybe it's a personal preference? In many cases, there are few (if any) substantial updates from month to month.  So it's a quick cup of coffee, or lunch, and we have plenty of time to chat about other issues, including non-work stuff. Anyways, I'll stop rambling. Rands in Respose writes better, and if you care about this blog, you will most likely want to subscribe to that one.", "date": "2009-09-22"},
{"website": "Hubspot", "title": "Fix the Problem, Not the Symptoms", "author": ["Tim Hennekey (He/Him)"], "link": "https://product.hubspot.com/blog/fix-problem-not-symptoms", "abstract": "Here’s something I think everyone can relate to: you fix a problem, only to discover later on that it’s still happening. Why is that? Sometimes we’re in a rush, or are a little careless. I believe it’s often because we did not understand the problem well enough to actually address it. By being a little more deliberate we can avoid this, and reliably fix problems once and for all. And it’s not a particularly technical skill. We need to start by asking “why” more, and looking for the answers to understand the problem well enough to confidently solve it. The case of the OutOfMemoryErrors At HubSpot one of the things I’m responsible for is a web crawler. This system has had a multitude of issues but one class of them, OutOfMemoryErrors, have been perennial. At times it seemed there was another every other week. They no longer plague me, and I attribute that to continually questioning why the error was occurring and searching for the answers before fixing it. An example from earlier this year started like most others: with a heap dump. Why did it fill the heap? Turns out while parsing the HTML a base 64 encoded PNG was taking up a considerable amount of memory. Why did it have an image at all? The service is supposed to collect only the HTML. The code had set a flag to not download images for the headless browser client so that naturally made me question: Why then did the image appear in the heap? Looking further into the client I could see that the flag was being passed down, but I was able to repeatedly capture images with that client, with the flag set. So why were the images present? A quick search revealed that the name of that flag was wrong. I was able to submit a pull request to the client, with screenshot evidence of an example webpage before and after my change to demonstrate that it was in fact not properly omitting images before. Had I just added more memory to the service, this issue would have been buried for longer. It would have consumed more resources, which cost us. Other users of the headless browser client would be inadvertently downloading images as well. Best of all, I don’t get OutOfMemoryErrors any longer. A habit of asking “why” At each step of the way I was able to find some concrete evidence that led me to the next step. Often the code itself is not enough to correctly discover an issue so these artifacts are incredibly important. Things like heap dumps, thread dumps, and log files can give us a picture of the system as it runs. They also typically have timestamps included so it is possible to collate the evidence to construct a more complete picture of what happened. By cultivating a habit of asking “why” and searching for evidence, we can solve problems rather than treating symptoms. I say “habit” because it’s a practice that we add to our work rather than a specific skill. You may find that it takes a while to become successful at it, but like many things, the more repetition, the easier it will become, until you find it’s happening automatically for you.", "date": "2020-01-29"},
{"website": "Hubspot", "title": "HubSpot Customer Spotlight: Su Sanni, President, Technology Solutions, Allegiance Fundraising Group", "author": ["Francesca McCaffrey (She/Her)"], "link": "https://product.hubspot.com/blog/hubspot-customer-spotlight-su-sanni-president-allegiance-fundraising-group", "abstract": "Some of the best perspectives on HubSpot's product come from those who use it every day. In this interview series, we profile HubSpot partners, providers, and customers, and ask their thoughts on what our product team should keep in mind while solving for them, and where the future of the industry lies. In this installment, we chat with Su Sanni , president of technology solutions at Allegiance Fundraising Group and founder of mobile transit company Dollaride . How did you first come to work with HubSpot's products? My introduction to HubSpot's products was through WeDidIt, my first tech startup, which was acquired by Allegiance Fundraising. I believe the 500 Startups accelerator program introduced us to HubSpot and we took advantage of the discount pricing provided to early-stage companies. That was back in 2014, and I've been a customer ever since. What's the best piece of wisdom you've gained so far from being a founder? Always try to hire and work with people who are better/smarter/more talented/experienced than you are. Working with great cofounders and teammates will make your job much easier, and you'll always be inspired to step up your game. On LinkedIn, you've listed yourself as a \"Social Entrepreneur.\" What does that title mean to you? I describe myself as a social entrepreneur because I tend to gravitate toward businesses that address social problems. I'm most interested in working on solutions that positively impact people's lives, so I often find myself engaged and most passionate about solving problems that can affect millions or billons of people. Can you tell readers a bit about the mission behind Dollaride and what they can do to get involved? Dollaride's mission is to make public transportation accessible to everyone, everywhere. 4.5 million people live in transit deserts across the country. So we're focused on first creating more transit equity for those folks, who live in 52 of America's most transit-starved cities. We've found a unique way to do this by leveraging the shadow network of commercial dollar van or jitney drivers that operate in each city. To get involved, send us a message through our website at http://dollaride.com or find us on Twitter (@dollaride) . In your opinion, what's the most important thing for HubSpot's product team to keep in mind when solving for customers today? The most important thing to keep in mind is that marketers and salespeople often have too many tasks to do in not enough time. The more time HubSpot can save a customer through product features and services, the more valuable and integral HubSpot will be in the customer's daily workflow. What's the biggest challenge your team (either one!) is facing right now? Updating our business model(s) to be more resilient given the impacts of the pandemic on the economy and our marketplace. What's one small thing that makes a difference when it comes to choosing what kind of marketing software you use? Integrations into other products that we use. What about one big thing? Price. What do you want to see more B2B software companies focusing on in 2021? Growing the digital economy by bringing more cash-only businesses online and creating more digital offerings/solutions. Want more profiles of tech industry leaders? Check out our Name Dropping series . Interested in working with a product team that solves for marketers, salespeople, and developers alike? Check out our open positions and apply .", "date": "2021-03-04"},
{"website": "Hubspot", "title": "Just open-sourced: Send Jenkins (Hudson) stats to Graphite", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/81142/just-open-sourced-send-jenkins-hudson-stats-to-graphite", "abstract": "At HubSpot we use Graphite for most of our operational graphing needs, tracking such things as server uptime, response times, response codes (errors, etc.), cache layer capacity and hit rates, and more. We also use Jenkins (formerly Hudson) for continuous integration, since we like to deploy very often.  Jenkins, like all systems, can have capacity bottlenecks where there are no build executors available to run a build.  This results in delays that frustrate developers and slow us down. But how often does it happen?  When should we add Jenkins nodes to our cluster? One of our developers, Jeremy Katz , has recently written a script to track just this using the Jenkins API , and push the results to Graphite for easy viewing and analysis.  He went a step further, open-sourcing his script under the Apache License. Read more information, and enjoy the script, on Jeremy's blog .", "date": "2012-01-13"},
{"website": "Hubspot", "title": "5 Takes on Frequently Asked Product Questions", "author": ["Magdalena Georgieva (She/Her)"], "link": "https://product.hubspot.com/blog/5-takes-on-frequently-asked-product-questions", "abstract": "There is a set of product questions we often discuss internally and with folks outside of HubSpot. A couple of weeks ago, we hosted a panel for Northeastern's Women in CIS to discuss some of the most frequent questions as seen through the lens of different people on the engineering team – from designers and product managers to software developers and tech leads. Below are some of the highlights, but feel free to check out the video for more detail . 1. On the operations of small product teams A small team has complete ownership of the thing they are building. It gives you a lot of control over how you want to building something, test it – you are responsible for it. It gives you a lot of ownership and pride over what you are building. I like that approach better rather than a team broken up by role. - Laura Martinez, Tech Lead 2. On the day-to-day job of a tech lead The management role is not a top-down leadership role, it’s more of the servant leader role, a mentoring role. My role as a tech lead is to help my team be successful. So I work very closely with my PM to flush out ideas and talk about priorities at the high level, but the responsibility for building and executing is really on the individual team members and I am just there to help guide them and give them the resources they need. We have regular 1:1 meetings, so it’s a lot about communication, feedback, and mentoring. - Laura Martinez, Tech Lead The whole idea of servant leadership is that you have to help other people perform and grow. It’s not about you telling other people what to do. I have three constituents – upper management, a team, and the individuals. So I spend a lot of time talking to them, understanding what their needs are, what their priorities are. - Sharon Chang, Director of Engineering 3. On including design early in the development cycle The Product Manager usually does the heavy work with finding the problem, and goes to the tech lead and designer to discuss the problem, how feasible it is, can we actually solve it, what are some ways to solve this... So we mock it up, we do user testing, we see if it’s a valuable option. Usually we pull in other engineers just to get more ideas out there because everyone has a part in this defined solution. - Amy Guan, Designer 4. On being successful as a newbie engineer Two things: a really awesome onboarding process and the relationship between you and the tech lead. That person is incredibly helpful and important to get you started, get you acclimated with the code, and help you understand more about the product. Also, being able to ask question is really important. My strategy at HubSpot if I don’t know something has always been, spend a reasonable amount of time trying to figure it out and if I know of someone who is able to unblock me pretty easily, then go down that road. - Rose DeMaio, Software Engineering Co-op 5. On the most challenging thing as a product manager Conflicting points of view don’t help me make a decision. When somebody from one part of the business is saying, “Who would ever want that?” and another person in the business is saying, “This is absolutely amazing! Keep building more things like this.” They are diametrically opposed. When I first started I took everything really personally. And then you learn that it is not about you and it is actually a really good lesson to learn when you are trying to guide the vision. But now my most frustrating thing is when my decision is being made harder by directly opposing feelings. - Angela DeFranco, Product Manager What are your thoughts on these questions?", "date": "2014-12-12"},
{"website": "Hubspot", "title": "How we gave SSL to all our customers in 5 days, for free", "author": ["Eric Richard (He/Him)"], "link": "https://product.hubspot.com/blog/how-we-gave-ssl-to-all-our-customers-in-5-days-for-free", "abstract": "I regularly talk about the HubSpot Product Team's culture – both internally and externally – and I always start my discussions on our culture with the following idea: We believe that if you give a team a compelling mission, the autonomy to attack the mission the way they see fit, and the support to accomplish this, magic happens. This is, in essence, my management philosophy. The bulk of what we do on the leadership team here involves setting up situations where that magic can happen. It’s hard work. There’s a lot that can go wrong. But every so often, all of the right ingredients come together and magic really does happen. And being able to witness this and see a team operating at a totally different level is, well, magical. Recently, I got to watch one of these magical moments. An Impossible Task Google has long made it clear that they give preference to sites that are SSL-activated. For example, a while ago they changed their ranking algorithm to give an extra boost to secure sites. And furthermore, we started to hear some rumblings that they’d be raising the bar yet again inside of Chrome by warning users who are filling out forms on sites that aren't SSL-activated that their data might not be secure. There are a few reasons why these changes are a Very Big Deal to HubSpot and our customers: Google is still king when it comes to our customers’ sites getting found on the internet. Therefore, any way we can help them rise to the top of the search rankings is at the top of our priority list. A fundamental part of HubSpot's Inbound Methodology involves using forms to capture information about leads who want to engage with you. We host over 70,000 customer domains on our platform. For every one of those sites, it's incumbent on us to provide the best experience for our customers and for their customers. With this in mind, we’ve been tirelessly working to make it easier and easier for our customers to get SSL when they host their content on our platform. For a long time, this was done manually, and only when customers requested it. Then, we spent a huge amount of time automating as much of this process as we could. And while this automation was great, the process to turn on SSL on your domain was still rather cumbersome and slow. Our long term goal was to provide SSL to everyone, automatically, for free. But we just didn't have the systems in place to make that happen yet. Then, in September, we learned from our contacts at Google that Chrome 62 – the release that would start flagging forms on non-SSL pages with scary warnings – would be going live by the end of October. Which means that in October, any of our customers whose sites weren’t SSL-activated would have that scary warning on their site. Image source: Google Security Blog Crap! Our support team was concerned that once this release hit, customers would rush to turn on SSL for their sites. We knew that our current SSL setup process was pretty glitchy, and it would likely cause a flood of calls to support. It wasn’t out of the question that 10,000 calls could hit our support team (and while they’re amazing, even they have limits on what they can do), and we were trying to figure out how we'd deal with that kind of load. It wasn’t too long before we got some even worse news. The Chrome release wasn't going to drop at the end of October. It was going to drop in mid-October. So the team that builds our CMS got together. And they asked themselves, \"What if there's another option? What if we could automatically provision SSL for 100% of our customers? And what if we could do this BEFORE the Chrome release goes live?\" Those were some pretty big what-ifs. It was an insanely audacious plan. It would require tons of work across a bunch of different teams. But that's exactly what they set out to do. And over the course of a five day period, they did it. They provisioned SSL for nearly 47,000 domains that didn't have it before. To put this in context with a very Boston reference, in the previous years that we'd been working on this, we'd provisioned 12,000 domains with SSL. That's fewer than the number of seats in TD Garden. Then, over the period of five days, we turned on SSL for more sites than there are seats in Fenway Park. And today, we have more domains on SSL than there are seats in Gillette Stadium. Go Pats! And they got all of this done before the Chrome 62 changes went into effect, which means that all of our customers who host content on our CMS don't have to worry about that scary warning. And we did it automatically, without those customers having to take any action. And we did it for free, because it was the right thing to do. Was there a secret to the team pulling off this amazing feat of engineering? Hardly - they just had all the right ingredients in place. The team had a compelling mission. They had the autonomy to attack the mission the way they saw fit. For instance, they had the freedom to deploy new technologies, including new APIs we hadn't had access to before and AWS Lambda - these were the key to being able to make this change so quickly. And they had massive support. Teams from around HubSpot rallied around our product teams to make the process as seamless as possible. Folks from our infrastructure team helped with configuring DNS and networking. Our product marketing department did an amazing job educating customers on what SSL is and how the upcoming change would affect them. Our pricing and packaging team moved mountains to make this feature free to our users, knowing that it was the best way to protect them given the impending Chrome release.  And our support team encouraged the team to move quickly and take risks, even though they knew it might cause some extra support load, because they knew that the payoff was worth it. This is a classic example of our philosophy in action. When mission, autonomy, and support combine, the result won’t just be remarkable. It will be magical.", "date": "2017-11-16"},
{"website": "Hubspot", "title": "Paul Schwarz is a HubSpotter", "author": ["Elizabeth Dunn (She/Her)"], "link": "https://product.hubspot.com/blog/bid/86878/paul-schwarz-is-a-hubspotter", "abstract": "Name: Paul Schwarz Role: Tech Lead at HubSpot Superpower: Used to work at NASA Paul Schwarz is a Tech Lead at HubSpot, heading up the new Integrations team. He spends most of his time fine-tuning the synchronization of our customers' HubSpot data with Salesforce, keeping things nice and stable and awesome. Paul grew up in Houston, where his first job was as an embedded software engineer at NASA.  After a brief stint in San Antonio, he headed on up to Boston. Prior to joining us here at HubSpot just across the river in Cambridge, he spent some time scaling out warehouse operations at online home furnishing retailer Wayfair. These days, Paul spends most of his off-hours just enjoying living in Boston, and likes to to check out new restaurants and the occasional indie rock show whenever he gets the chance.", "date": "2012-05-18"},
{"website": "Hubspot", "title": "Purple Teaming with the Threat Hunters", "author": ["Alyssa Robinson (She/Her)"], "link": "https://product.hubspot.com/blog/purple-teaming-security", "abstract": "For many SaaS companies, responsibility for an application’s security is shifting to the application teams themselves, and HubSpot is no exception. HubSpot has always engaged with penetration testers from external security firms — in addition to security researchers via our bug bounty program — and will continue to do so. These external engagements do provide real value in terms of independent testing and verification, but there are advantages to Engineering taking direct responsibility for a portion of security testing as well. With external testers, HubSpot engineers have to spend time providing the right context, setting up access, and helping to troubleshoot through the engagement. With thousands of deploys daily, we need the freedom and flexibility to tackle high value changes without a ton of overhead. To help meet this goal, HubSpot has a new Infrastructure Security team in town: the Threat Hunters. With a mix of internal and external hires, the members of the Threat Hunters team bring a wealth of security experience. The mission of our team is to systematically reduce HubSpot’s attack surface and continue to improve the maturity of HubSpot’s product security. This means working with the development teams across HubSpot to make the product as secure as possible for our customers. One way we’re doing this is through an idea called “micro purple teaming.” Why Purple? The idea behind purple teaming is to create a feedback loop between red teamers — ethical ‘hackers’ who emulate an adversary and simulate attacks in an environment — and blue teamers, the defenders who continuously assess the security in an environment and attempt to mitigate and prevent attacks. Micro purple teaming is the HubSpot version of purple teaming, where folks from the Threat Hunters team work with the owners of various features and applications within product to attack our product and then provide ideas for mitigations and security improvement before an attack comes from a real threat actor. Process The Threat Hunters team starts the process by meeting with a development team to understand more about their system and tackle the logistics of the testing. When will the features be ready? Are they gated or available to everyone? Should this be tested in QA or Production? We learn about how the features are meant to be used and the potential areas that could be abused. The development team has time to share their fears and the areas they’re unsure about. A testing time is put on the calendar. In the week leading up to the planned test, the Threat Hunters take time to review the codebase, noting high risk areas and preparing the tools we’ll need for testing. Having this plan ready allows for maximum results during a relatively short testing window. During testing, the team keeps detailed notes on the process, so that found vulnerabilities can be re-created by other team members and re-tested after fixes. While we are on the lookout for areas that can be exploited, we’re also keeping “blue team” defensive tactics in mind. Did any exceptions or alerts warn the team that an exploit could be happening? Could the activities of an attacker be accurately re-created from a service’s logs? Once the test is concluded, team members review the findings and write up a detailed report with information on areas of concern. Once the report is shared with the development team, HubSpot’s Mainsail process is used to track the items. Reports are available for all HubSpot engineers to review and learn from. Value to HubSpot While external penetration testers can offer only generic advice for possible fixes, an in-house purple team knows exactly which tools are available in HubSpot’s environment to address a vulnerability. It can offer pointers to strategies other internal teams have used in similar situations. When the same vulnerability appears multiple times, the team can create new training videos, deliver a presentation to the team during HubSpot’s weekly “Tech Talks,” or develop tools that can detect the issue sooner in the development process. Using tools such as Portswigger’s Burp Suite for manipulating input, in addition to code review and homegrown scripts, the Threat Hunters have helped multiple teams with security improvements before new features made it to production. In some cases, these were minor improvements: better error messages that avoid leaked information, or improved auditing that could help investigators during a security incident. Other discoveries, however, revealed flaws in business logic or situations where a backend service put too much trust in the inputs it received. These could have seriously weakened security protections were they not caught early. By working as an extension of the development teams, HubSpot’s purple team can develop a trusted relationship with them. Dev teams know there is a resource for asking questions, or offloading nagging security worries that they aren’t sure about. An internal team also understands the internal pressures and processes that might lead to a particular bug. Identifying these culture- or environment-related issues can lead to security improvements for every team. If solving problems like these and creating better application security solutions interests you, check out our open Senior Software Engineer position .", "date": "2020-03-16"},
{"website": "Hubspot", "title": "How do we handle billing for third-party apps in our Marketplace?", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/83323/how-do-we-handle-billing-for-third-party-apps-in-our-marketplace", "abstract": "One of the major items on the roadmap for us this year is making it simple and easy for our customers to purchase applications in our App Marketplace , and for those app developers to easily specify their app price as well as collect payment. We've begun working on this recently, starting with an internally-built application ( Webinars ), so that we can work on collecting money, but we don't yet need to worry about paying out 3rd party developers.  This went reasonably well, and customers have been purchasing the application in production since January. The next step is figuring out revenue sharing, accounting, user experience, and the back-end implementation for 3rd party billing.  We've been researching how other marketplaces do it, e.g. Apple's App Store, Google's Android Market, Salesforce.com's AppExchange, eLance, and more.  They are all over the place with various approaches. What do you think? If you are a developer reading this blog, have you ever charged for an app in someone else's marketplace?  If so, what was your experience?  What did you like?  What did you dislike?  Did they have revenue sharing?  If so, what proportion did you get to keep, and was this reasonable? If you are a customer (or prospective customer) who has bought an app in someone's marketplace, what did you like (and dislike) about your experience? We are trying to make this simple and easy for both app developers and customers.  We'd love your ideas, thoughts, comments, and suggestions, including what to avoid or NOT do.", "date": "2012-02-28"},
{"website": "Hubspot", "title": "Flatten the Web With This Bookmarklet", "author": ["Adam Schwartz"], "link": "https://product.hubspot.com/blog/flatten-the-web-with-this-bookmarklet", "abstract": "In some ways, a flat UI represents less information than one with depth.  The ultimate extension of this is this quick bookmarklet which can make many websites \"flat\" just by adding a bit of CSS (skip down for the source): Drag This To Your Bookmarks Bar Some Examples GitHub Twitter The bookmarklet works in part by removing background images. Websites need to define a good background color behind their images, if they don't, you might see some unexpected things: Pandora Source Follow @adamfschwartz on Twitter", "date": "2013-11-07"},
{"website": "Hubspot", "title": "Speeding up Deep Clustering with Concrete GMVAEs", "author": ["Mark Collier"], "link": "https://product.hubspot.com/blog/speeding-up-deep-clustering", "abstract": "The AI team at HubSpot recently published a new paper which we presented at the DeCoDeML workshop at the European Conference on Machine Learning 2019. In this blog post we provide some details on the paper and how it is useful for marketing, sales, and customer service organizations in particular. Our paper makes it practical to apply deep learning tools to a common marketing problem: clustering of datasets. As part of market and customer research, we often wish to discover groups (or clusters) of customers in our data. If we can put our customers into different groups, then we can do more targeted outreach or content creation, build products/features for specific group’s needs, or generally just understand our customers better. Given that we often have very large, complex datasets about our customers, automating the discovery of clusters is ideal. This is where machine learning comes in. There are many machine learning techniques we can apply to our data that will produce clusters. For example, k-means clustering and the Gaussian Mixture Model ( GMM ) are popular clustering algorithms. These models work well on some datasets, but don’t take advantage of recent developments in deep learning. It turns out that other researchers have developed deep neural network techniques that perform clustering. One such method is the Gaussian Mixture VAE ( GMVAE ). The GMVAE takes inspiration from GMMs in introducing a discrete random variable into the latent space of a Variational Autoencoder ( VAE ). VAE is a popular unsupervised learning algorithm. Clustering our dataset with off-the-shelf GMVAEs shows positive results. The problem with GMVAEs is that their training time computational complexity is linear in the number of clusters used. This means that if, for example, we expect our data to break down naturally into 200 groups, the time it takes to train the GMVAE will be approximately 100 times more than a dataset with 2 clusters. Thus when we apply GMVAEs to large, complex datasets with many natural clusters, the training can just take too long. In our paper, we propose a solution to this problem by introducing a continuous approximation to the discrete latent variable in the GMVAE. This continuous approximation means the Monte-Carlo estimate of the GMVAE loss function has a complexity constant in the number of clusters. Experimentally, we find that this reduction in computational complexity corresponds to a remarkable decrease in training time under a realistic training setting. For example on CIFAR-100 (an image dataset) where we use 20 clusters, training time drops from 47 hours to less than 6 hours. Remarkably, we find that our approximation does not reduce the quality of the learned solution! For the rest of this post, we will provide some of the more technical details of our method. GMVAE As with a VAE, for a GMVAE we imagine a process under which our data x was generated. Unlike a VAE, though, the generative process for a GMVAE involves a discrete variable y (think cluster ID). We imagine that each data point we see is the result of first randomly picking which cluster y the data point belongs to. Then we randomly choose some attributes z of the data point within the cluster. Finally, given these attributes, we produce the data point. For example, consider a dataset of images of handwritten digits from 0-9. Under our generative process, we imagine that the images we see are the result of first thinking about which digit to draw, e.g. a number 2, then choosing what type of 2 to draw, e.g. a slanty one with a loop at the bottom, and then actually writing the number 2 on paper. This generative process can be described probabilistically: where y is described by a categorical distribution, z by a normal one, and x is Bernoulli distributed. Here each step in the process is parameterized by a (potentially deep) neural network. Having defined our generative process, we need a way to train our neural networks. Ideally we would like to maximize the probability of our observed data, i.e. make the data we see as likely as possible. However, computing log p( x ) (the logarithm of the probability of our data) is intractable. We instead settle for maximizing the Evidence Lower Bound (ELBO), an unbiased estimate of a lower bound on log p( x ): However, note that this estimate involves summing over all possible settings of the cluster id random variable y . This summation causes the training time complexity to be linear in the number of clusters used, which is the problem with GMVAEs that we seek to solve in our paper. But why is this summation necessary? We note that in equation 6 we are approximating the expectation in equation 5. In making the approximation, we have sampled z ~ q( z | x , y ). This gets rid of a high dimensional integral over z . The reason why we can’t do the same for y and sample y ~ q( y | x ), is because y is discrete, so we cannot make the sampling procedure for y differentiable, which in the continuous z case can be done by the reparameterization trick . To train our neural networks we need differentiability. Concrete GMVAE Fortunately for us, there exists a continuous probability distribution designed specifically to approximate discrete random variables such as y . The Concrete distribution has the property that in the limit of zero temperature (a hyperparameter used to control the randomness of the sampling process) it becomes exactly discrete, but for non-zero, low temperatures is approximately discrete. We can apply the reparameterization trick to a Concrete distribution. This means we can sample from a Concrete distribution and differentiate through the sampling procedure. In our paper, during training, we simply replace the discrete y with its Concrete approximation. As we can now sample y ~ q( y | x ) and still get gradients for the parameters governing q( y | x ), our unbiased estimate of the loss function becomes: Notice how the loss now does not depend on the number of clusters. In practice, we find that using this estimate drives the Kullback–Leibler (KL) divergence between q( y | x ) and p( y ) to zero, causing the system to not do any clustering at all. This can be easily fixed by encouraging the system to use y by annealing the penalty on KL(q( y | x ) || p( y )) from zero to one during training via a weight w t : We test our Concrete GMVAE by comparing both training time and the quality of the learned solution on two image datasets; MNIST and CIFAR-100. We demonstrate that this theoretical reduction in training time complexity, is, in fact, borne out, when using a realistic training setup (i.e. one that includes early stopping, etc). The theory's predicted reduction in training time complexity from linear to constant scaling in the number of clusters (K) is observed.  Despite significant speedup in training time, our introduction of a continuous relaxation of the latent variable y in a GMVAE has had no significant negative impact on test set log-likelihood. Thus where previously long training times made it practically impossible to apply deep learning powered GMVAEs to unsupervised clustering problems, our Concrete GMVAE makes it possible.. We hope that the Concrete GMVAE will prove useful for marketing, sales, and customer service professionals, as well as other users of clustering algorithms. and We also hope that our research will demonstrate the power of using continuous approximations to reduce the computational complexity of existing methods which sum over discrete random variables.", "date": "2019-10-17"},
{"website": "Hubspot", "title": "The Moment I Realized Leadership Isn’t About Me", "author": ["Lauren McKenzie (She/Her)"], "link": "https://product.hubspot.com/blog/the-moment-i-realized-leadership-isnt-about-me", "abstract": "Effective leadership. Every leader wants it. Every company tries to hire and train for it. According to research, 83% of organizations say that it’s important to develop leaders at all levels , but only 5% of companies have fully implemented leadership development at every level. When I first started at HubSpot I told everyone my brain felt like it was on fire (in a good way). This is because HubSpot is a great place to learn, not only in your day-to-day work, but also in HubSpot-provided programming. There’s a library of self-paced courses in our Learn@HubSpot online platform, manager ThinkSpaces, an annual mini-MBA Fellows program, and much more. One part of HubSpot’s investment in employees at the Director level and above is The Leadership Consortium (TLC). Led by Harvard University’s Frances Frei and Anne Morriss , the virtual experience mimics a Harvard Business School classroom and is a unique opportunity to learn, grow, and develop leadership intuition, decision making, and pattern recognition. With case-based classes and individual coaching, sessions take place over the course of four months, and you’re placed into “learning teams” with leaders from other top companies like CapitalG, Google, Lyft, IBM, Cloudflare, and UiPath. Going through the program, what surprised me wasn’t that I learned something new about my leadership style, it was what I learned about it that has been the most transformative for my career. From Me to We Frances Frei started off the program by instilling in us that \"leadership is about empowering other people as a result of your presence, and making sure that impact continues in your absence.\" This may sound like just another variant on the definition of leadership, but it was that second part “making sure that impact continues in your absence” that made me pause. Why did this line shake me up so much? Simply put, it made me realize leadership isn’t about me . Now, I would say that I’m not new to this idea as I’m all about servant leadership and the multiplier effect . I also don’t believe leaders need to be the most charismatic, loudest or smartest person in the room (or Zoom!) But still, at the core, my presence has always been very much tied to the way I lead. Working with my coach to review my 360 feedback, and deeply reflecting on what was/is holding me back, I realized that what was holding back being able to scale my leadership was in fact, me. In order to grow myself, I needed to put mechanisms in place that would help make my team succeed and grow. These are the three core areas I’m focused on to achieve that. Overcommunicating My Strategies, Decisions, and Practices Upon realizing that leadership is about what my team does when I’m not present, I realized that I need to over communicate my process, even when it’s not always clear myself. For example, as a leader, we’re taught to know how to navigate through challenges and lead the team by having all the answers. But, some of the best leaders I know admit that they don’t have all the answers, and admit to failures. By spending the time communicating to my team about how I'm thinking through certain decisions, it opens the door for transparency, and shared learning. And, it's a major component to operating at scale. One example of this is when I realized it would help if I could visualize how I thought about when we needed to do research. Working in tech we have a tendency to move fast and ship the MVP (minimal viable product). Leading a team of User Experience designers and researchers is tough in this environment as we often want to make sure we have the best possible product before we release it. I created a simple decision tree which showed the way I think about it. It asks a few basic questions: Can we answer our research questions with product usage data? Has another team (within or outside of HubSpot) answered this question before? How risky is it to launch without answering this question? This was a simple rubric I went through in my head, but sharing it allowed a whole product team to move faster. Creating a Team Operating System I’ve always been wary of team operating systems because at best it sounded like more process than was necessary, and at worst it sounded like micromanagement. Now I look at it as something that just helps everyone understand expectations so they can focus on the real work — creating value for our customers. Your team’s operating system should refer to the way you work, behave and make decisions. As we build ours, we’re challenging the way we’ve done things in the past, and asking ourselves if we can improve the ways in which we work to be more productive, inclusive, and consistent. For example, what meetings do we have and what’s expected at each one? There are times we meet as a team just to connect, versus ones where we focus on how we’re improving the lives of our customers. Both are important, but being clear about which is which helps us set the agenda and know how to contribute. Embracing Tough Love Finally, I am embracing this idea of tough love that Frances Frei and Anne Morriss talked about in class and in their book, Unleashed . The idea that empathy, empowerment, and belief in people is not enough. You need to be able to hold the bar high and challenge them as well. Not raising the bar is taking the easy way out and, again making it about yourself over them. Challenging your team, giving them something clear to reach for is a gift, and shows love. It’s tough love. I’m committing to this by creating clearer and more specific goals for my team (specific goals are helpful and clarifying, not limiting and micromanaging), holding my colleagues and peers accountable for actions as well, and leaning into positive feedback as a way to keep standards high in a way that not only feels authentic to me, but is proven to be more effective . A little over a year ago I remember sitting in a room with my manager and other leaders. I actually said the words “my leadership style doesn’t scale.” It was a sad and limiting phrase for me, my team, and my company. I’ve come to realize that it was my own leadership philosophy that was holding me back. When previously asked about my philosophy, I always said it’s about: people over process, candor over etiquette, and learning over perfection. While this may be helpful to share with coworkers, managers, potential employees, it’s insight into how I like to work, not how I lead others . 71% of companies do not feel their leaders are able to lead their organization into the future . But I think if we shift our mindset to recognize that the most effective form of leadership is others-centered, not self-centered, we’ll be better equipped to impact both people and profit. This post originally appeared on Medium .", "date": "2020-07-09"},
{"website": "Hubspot", "title": "What do UX Writers do at HubSpot?", "author": ["Lynsey Vallandingham (She/Her)"], "link": "https://product.hubspot.com/blog/what-do-ux-writers-do-at-hubspot", "abstract": "User Experience (UX) teams have existed at software companies for a long time. But as the field of UX continues to grow and develop, more specialized roles, like UX writers, have been steadily growing and developing in importance, too, taking their place alongside more established roles like UX (product) designers and UX researchers. UX writers (also sometimes known as content strategists) are the folks responsible for crafting the words you see on the screen in the software you use. It’s a job that seems simple in concept, but, like the job of most UX professionals, is filled with complexity. Think of your favorite app or piece of software. Now imagine it without words. It’s meaningless, right? How would you know which button to press, or which field to fill out? UX writers make sure that context is clear and straightforward, and good UX writers can help infuse products with the small details that delight users and keep them coming back. Broadly speaking, the ultimate goal of a UX writer at HubSpot is to create the content that makes our users successful when using our marketing, sales, and customer service software. But to many outside of our team, the day-to-day life of a UX writer can be a bit of a mystery. Our work isn’t done in a silo – we don’t just sit alone at our desks turning out magic words. Instead, our work requires a substantial amount of partnership and collaboration. So, here’s what it’s really like to be a UX writer at HubSpot. Where we fit in At HubSpot, UX writers work closely with product designers to provide the best possible user experience. We create a holistic experience with words and design, and we think about words and content as part of the design from the beginning. Our job is to help teams choose the right words that will be understood by the most people. We get many different types of copy requests every day. Sometimes we work with designers on long-term projects like the launch of an entirely new product, where every word and illustration need to be created from scratch. And sometimes, it’s as small as an existing sentence that just needs some sprucing up. We also work closely with product managers (PMs) and software engineers, who contact us for requests both small and large. And we’ll work with them wherever they work. So if a product manager or software engineer wants to mention their UX writer in GitHub (where all of our actual code lives), we’ll leave copy suggestions there. If a designer is working on an early design in Invision (a design and prototyping tool), we’ll leave our thoughts and recommendations there. We’re also present in many early-stage whiteboarding and ideation sessions, where we’re co-creating a new feature or flow from the ground up. It’s a best practice here at HubSpot to involve a UX writer as early in the design process as possible, as equal collaborators with the designers, PMs and engineers. In order to foster those relationships, our writing team tries to make sure all our product team members feel welcome to reach out to us, no matter how big or small the request is. We’re here for it all. The writing process We sweat the small stuff There’s no word too big or small to necessitate a request, and requests come from all sources: Slack, GitHub, a shared Paper doc with the product teams, hallway run-ins — you name it. Requests can cover anything, from a current label in the product, to a simple checkbox that seems to be confusing our users. When we're asked to help on a redesign of an existing feature, the best way to collaborate with the designer is to drop our comments and recommendations right into their Invision screens. We do our best to handle each individual request in a timely manner and are careful to keep track of all copy requests, whether they’re open, in progress, or live. … and the big stuff The launch of a new feature usually involves a lot of conversations and copy iterations. For example, we’ve recently been working on a new product that includes a multi-step creation flow unfamiliar to our current users. After user tests on the early designs showed some confusion, the writer, designer and product manager got together to understand the pain points. The writer could then go through the Invision mock-up and pinpoint where copy changes could be made, and where the the current design was in conflict with effective copy. From there, this sparked multiple conversations and large, impactful design changes that cleared up where users were getting confused. Copy helped clear the path toward a more concise design and, in turn, a better user experience. We name things, too Naming a new product or renaming an old feature is… well, it’s hard. Naming is about setting expectations and resonating quickly – the user should understand immediately what the product is and what value they’ll get from it. We also need to be sure that a name doesn’t already exist somewhere else in the product, because that will only add confusion. We also want to make doubly sure that other companies don’t have similar names. We don’t want a name to evoke another company or service where expectations about that name might already exist. So we created a process for figuring out how to make naming a little easier. First, we developed a sheet of questions to help us describe what we’re naming, why, and if there are any background issues or context. Next comes the serious brainstorming to generate a list of suggestions. We then work with our UX researchers to find the best name through user testing before bringing it to our localization team to figure out how well it’ll translate across the globe. And, of course, we work with the new feature’s product team to see what they’ve been calling it and how they see that feature growing or changing down the road. Longevity is important in a good name – we need to come up with a name that works now, but also a name that will work for the product as it evolves. There are a lot of pieces to this puzzle, but this process adds clarity and accountability. How is UX writing different at HubSpot? What makes us “HubSpotty” HubSpot’s known for its unique culture code . Similarly, we strive to make product copy that’s uniquely “HubSpotty.” HubSpot employees are humble, transparent, and empathetic , and our company’s culture code has a strong and direct influence on the voice and tone of the UX content throughout the HubSpot ecosystem. The UX design team at HubSpot recently launched our new design language, HubSpot Canvas, into the world, which includes HubSpot’s voice and tone guidelines. In a nutshell, we aim to be friendly but professional. We know there are times to be fun and even a little surprising, but mostly we just need to be simple, direct, and get right to the point. Solid foundation of trust For a long time, HubSpot had just one UX writer. What was once a team of one is now a team of three UX writers and one illustrator. The original UX writer at HubSpot, Beth Dunn , worked hard to build a strong brand and demonstrate the value that thoughtful and consistent content brings to a product team. That built-up trust has made everyone’s job so much easier, and gave us the opportunity to show how much value UX writers can add to the design process. Designers, product managers, software engineers, and UX writers all have a clear sense of how writers contribute to the larger goals we all share. Collaborators, not an agency Because we’ve worked so hard to develop relationships with designers and others in the company, we’re not just seen as service providers, but as collaborators throughout the life of a project. We get to be involved early in the design process because the words we use, even in early designs, can directly influence what a product becomes. Just as design shouldn’t come last as a sort of “make this look good” final step, UX writing can’t come last as a “make this sound good” step, either. We also lean on our fellow UX writers for help with the real meaty content. We have regular meetings and a private Slack channel to review our current work and help each other get over any hurdles. What does a good UX Writer look like? Strong writing skills When we recruit, we look for people with a strong understanding of correct grammar and good language structure. It’s worth noting, as a personal anecdote, that I started in the role with no UX writing experience, just general writing experience. I have a creative writing background from school, and was a technical writer at HubSpot before I applied for this role. My biggest challenge in becoming a UX writer was adapting to a new audience but my solid writing foundation made learning the more specialized skills of UX writing much easier. Relationship-building The UX writers at HubSpot work closely with product managers, product designers, software engineers, localization experts, researchers, and many others. Being able to adapt to the needs of our peers has been critical. We look to insert ourselves into current workflows instead of creating new ones and forcing them on colleagues. We want to make sure product managers know we’re looking out for their product and solving for speed, and that designers feel they have a partner in their design process. We have regular meetings with each product team and their associated researchers, writers, designers, and product managers, so we can all do our best to help and support each other as our products grow and change. Alignment is key. Organization We use Trello to manage our daily work. This has been a lifesaver in terms of keeping track of open requests. Establishing a reputation as someone who is highly organized can also help build a strong foundation of trust with other teams. It’s important that we maintain a quick turnaround time and that no requests for content design fall through the cracks. The UX writing team relies heavily on process to help manage daily work and maintain high functioning relationships with everyone we support. Prioritization Sometimes we have multiple requests sitting in our queue, big and small. Understanding the urgency of one request over the other allows us to prioritize our workflow and ensure that we’re handling the right request at the right time. Being able to work on a few small requests along with a larger project is a constant juggling act, but it’s something that’s been essential to my success in the role so far. Advocate for the user As UX writers, it’s important to feel confident that we understand and empathize with the mindset of the user. We don’t just write copy to fill the available space — we want to write copy that matches the user’s feelings and thoughts in that moment. Designers, product managers, researchers, and our personal experience can all help inform this user-centered approach. A UX writer is also likely to have a strong desire to be a part of the larger content conversation in the field of user experience, and to promote what good writing can add to the real value of a product and the bottom line of your whole business. UX writers are more than just wordsmiths. We’re relationship-builders, information architects, linguistic resources, content designers, user empaths and advocates, and a whole lot more. It’s a pretty exciting role and we’re looking forward to seeing where it takes our content team next.", "date": "2018-04-10"},
{"website": "Hubspot", "title": "Video: Keeping busy during the winter", "author": ["Samuel Siskind"], "link": "https://product.hubspot.com/blog/keeping-busy-during-the-winter", "abstract": "The HubSpot product team has been hard at work on new features, and we thought you might like to see how we roll.", "date": "2013-01-30"},
{"website": "Hubspot", "title": "HubSpot’s Engineering Values", "author": ["Whitney Sorenson (He/Him)"], "link": "https://product.hubspot.com/blog/hubspots-engineering-values", "abstract": "As our team has grown, we’ve reached a point where institutional knowledge just doesn’t get transmitted as easily as it used to. For much of this institutional knowledge — like why half our infrastructure team recently Photoshopped lasers onto their eyes in their Slack pictures — it’s not a big deal if not everyone's in on the joke. But when it comes to our team’s values — the very principles that shape how we work, and why — well, we want everyone to be on the inside. At our engineering leadership offsite last month, we realized that as we scale, we need to share our engineering values — our most important institutional knowledge of all — more plainly, more publicly, and more often. While much of our value system gets transmitted by osmosis during everyday interactions between people and teams, we recognized that it was time for more explicit reinforcement and articulation. If we aren’t deliberate about exposing new hires to these principles early and consistently, as time goes on, we risk eventually diluting (and possibly losing) these important and hard-won values altogether — values that have shaped the team and the company that we are today. As Dharmesh, our co-founder and CTO, says in our Culture Code : “Many companies start out being exceptional. As they grow, there’s a dark, powerful force that pulls them towards the average. If we regress to the mean, we fail. It’s that simple.” As we started to craft our principles, we looked at the writing that Netflix and Amazon — companies we admire — have done about their engineering and leadership culture. Our own guardrails were: We want these values to be opinionated (and maybe even controversial). We think HubSpot is a special place that does things differently from many other companies. Instead of coming up with middle-of-the-road values that most people would agree with, we wanted these values to represent what makes our engineering culture unique and powerful. While they might be interesting or inspiring to other companies, they won’t necessarily be applicable to every business. These values should be a useful heuristic for decision-making in how we design our systems and how we allocate our time and effort. We have another set of values, called HEART, which Dharmesh talks about in our Culture Code . While our engineering values are close cousins of these company-wide values, HEART describes who we are, while these values are more focused on how we work. These values aren’t set in stone. Like all of our work here at HubSpot, we’re likely to iterate on them over time. Below is the list we came up with, roughly ranked in order of importance: Customers Come First Complacency Equals Failure Think Like an Owner Move Quickly & Iterate Small Teams Win Keep It Simple Embrace Organizational Change Scale Each Other So let's dig in: Customers Come First Everything we do should bring value to our customers. We’ll only stay in business if we continue to provide value to and maintain trust with our users. Customers don’t care about our teams, organization, processes, or promises. They care about what they’re seeing, using, and feeling in the tools every day. Complacency Equals Failure We know that software companies can go from apparent stability to ruins in a surprisingly short period of time. The market moves quickly and customers have options. We don’t take our successes for granted and recognize that we must continue to deliver value to customers and grow better as an organization in order to survive. Think Like an Owner We are all granted tremendous autonomy to make decisions, but we all, in turn, have a responsibility to be critical, flexible, curious, driven, and accountable. We have a responsibility to run towards fires instead of away from them. We also keep the long-term interests of HubSpot and our customers at the top of our minds, without letting short-term or team-specific goals get in the way. We don’t believe in “not my job” when it comes to building great products. Move Quickly & Iterate Software in general, and SaaS software in particular, is temporary by nature. Our work, while informed by data, research, and the business, is only ever just a best guess of what customers want — and their needs evolve over time. But luckily, software (unlike most other types of engineering) is gloriously malleable, and we therefore favor rapid iteration, experimentation, and improvement over attempted perfection. We want to strike the balance between planning and doing, because we acknowledge that code that never ships has no value. As inspiration, we look to the many imperfect but useful architectures and libraries which have provided the building blocks that our product and much of the software industry are built on. We’ll never get everything right on the first pass, but we’ll learn from our experiences and grow better over time. Small Teams Win We believe that a small team empowered to make decisions and relentlessly drive towards their goals will deliver results and insights much more quickly than a larger group. A small team is more likely to engender stronger psychological safety and avoid groupthink. Lastly, small teams have limited resources, forcing them to prioritize and focus on only the most important problems. This leads to less feature bloat and obsessing about technical details that don’t add customer value. Keep It Simple We favor simple solutions to problems over complex ones. We acknowledge that we can’t build a perfect system that will solve every problem, predict every edge case, or prevent every possible failure. Our systems will fail occasionally, and when they fail, they should do so in obvious ways. We apply this principle to all aspects of our work. From a system design perspective, we prefer microservices to monoliths and simple, straightforward objects to larger building blocks. From a product design perspective, we prioritize ease-of-use for the majority of users, even if it sometimes comes at the expense of the most advanced use cases. And from an organizational design perspective, we have a relatively flat organizational structure, stay flexible in how we plan and manage, and avoid elaborate processes . Embrace Organizational Change We embrace change in our product and organization. At times, we even push for it. We grow through change: by changing roles, pivoting teams to meet new customer demands, and recognizing that part of our job is to enact changes to make HubSpot better, even if it extends beyond the formal bounds of our roles. Scale Each Other We intend to continue growing rapidly and recognize that having the best people to deliver value to our customers is the biggest bottleneck on growth. We acknowledge that interviewing, coaching, and growing the next generation of leaders are some of our highest-leverage activities. We’re always thinking about how to replace ourselves, and as a result, we don’t insulate others from risk, information, business constraints, or making and learning from mistakes. The values listed above aren’t common knowledge — they represent the years of hard-won wisdom as we’ve built a lot of product, worked with some very smart people, and encountered many successes and failures along the way. We’ve avoided mediocrity and built the business that we have today by working according to these principles. As such, we’re working to make sure these values are deeply embedded in everything we do — because this institutional knowledge can’t be lost.", "date": "2018-07-23"},
{"website": "Hubspot", "title": "Thoughts on Returning to Java", "author": ["Dan Milstein"], "link": "https://product.hubspot.com/blog/bid/5395/thoughts-on-returning-to-java", "abstract": "Early in my coding career, I did a lot of work in Java, but for the last few years, I've mostly worked in Python. Since joining HubSpot a few months back, I've been gradually getting back in to the Java world. Here's some quick takes on rejoining the Java borg. Pros These crazy IDE things are really quite good. When I last was coding the Java, I was still using your basic text editor to do everything. And hence I was constantly bitching about the endless repetition. As I was leaving Java, there were these rumors about Eclipse and IntelliJ and all that, but I was on my way out, and am slow to adopt the new tech, so I had never tried them. Well, here is a shocking newsflash: the rumor I had heard from Everyone I Ever Asked is true--modern IDE's are very helpful if you're coding Java. Don't get me wrong, Emacs is still wired into my brain. As Paul Sutherland, a recent HubSpot hire, twittered recently: thank god for 33 year old software. Exactly. But for Java, I join the ranks of the sane and will use Eclipse. The new enums are delightful. Just nailed it. Very happy to see that. Generics are also very nice. I had been following their development in GJ and pizza, and am delighted to see them in the lang itself Cons I remain profoundly suspicious of the \"make everything available via getFoo/setFoo\" idiom. Once you've got all your properties available via get/set, it seems much to me like you have the worst of both worlds -- all the concise elegance of Java, with all of the type safety of python. Because everything is still resolved at runtime, but you have to say what you mean, like, eighteen times. I may still come around, but for now, I look askance, I say. Life without hash/dict literals is going to make me sad.  My Favorite Python Idiom is to turn a complex chunk of logic into a small piece of code which walks over a static data structure.  With no hash literals, no tuples,  and only homgenous lists, it's a lot harder to employ that idiom. Alright, I think I'll leave it at that for now.  Anyone else have back-to-Java stories to share?", "date": "2009-06-23"},
{"website": "Hubspot", "title": "Attribution Reporting: Delivering the Core, Not Just Building More", "author": ["Dave Chen (He/Him)"], "link": "https://product.hubspot.com/blog/attribution-reporting", "abstract": "If you’re a marketer, you want to show how you’ve helped move the needle for your business. You want to know what’s working, not just what’s happening, and that you’re spending money in the right places and on the right things. You want to see the impact of all your marketing activities, and in terms anyone in the business can understand: Revenue. Attribution reporting is a massively complex problem space. Most marketers make do by exporting data from many different systems, throwing them into a spreadsheet, and trying to make connections between cause and effect. My team at HubSpot built a new reporting tool recently that lets you measure exactly how much money your marketing drives for your business. No exporting data, no complicated setup. Just clear attribution reporting, which means you know which marketing efforts are delivering the most value for you. Making attribution reporting this easy for marketers was an incredibly difficult project to tackle. Maybe your team is working on something hairy and complicated, too. Here’s what we learned about clarifying our goals, sharing our vision, learning as a unit, and looking past the technology to deliver real value, fast. Clarify your goals Discovery work doesn’t always result in a clear product direction. The more research we did, the deeper we went into a spiral of possibilities. It wasn’t long before we were inundated by all the different use cases we could potentially solve for. We tried to catalog every single different use case, but the variations were endless. Every user, it seemed, had a slightly different question they were trying to answer. How are my campaigns bringing in revenue? What about my channels, are they bringing in revenue too? Which types of content are offering the most bang for the buck? From a single piece of content, to campaigns, and then up to channels, our users wanted to see how it all delivered revenue. Most people called that kind of solution “multi-touch attribution.” But most people were also sort of unclear about how it might work. The reality is that most marketers can’t spend their time studying attribution models. What they want is a tool that does that modeling for them, and to know they can rely on the accuracy of what they see. They want the data that will help them make good decisions. They want to know they’re making decisions they can feel confident about. Tons of articles online talk about attribution models and how you might measure your marketing with them. But not one of them addresses the realities of sales and marketing misalignments, data fragmentation, and undefined business processes. If we had just focused on building a tool that offered a wide variety of attribution models to users, we would have missed out on solving the core user need. It doesn’t have to be complicated to find out how marketing is driving real business results. It’s not about offering and explaining a vast array of mathematical models, it’s about helping our users make good, data-driven decisions. Share your vision That became our vision: To help marketers make good, data-driven decisions. But we knew we wouldn’t be able to do it alone. You can’t deliver an experience that spans across products without the support of the different teams that build them. A clear vision and strategy helps define and shape the mental model of your people across the organization. Showing others how you see the problem and how you’ll wrangle it from a design lens helps you all go beyond the interface and focus instead on what the interface is trying to achieve. To make it easier for everyone to visualize, we developed a simple framework that broke down the system into three parts: Connect, Credit, and Measure. We knew marketers wanted to track their buyer’s journey from beginning to end. And for the most meaningful touchpoints, marketers want to clearly show which content buyers interacted with and how much credit is deserved for closing the deal in the end. Our framework of Connect-Credit-Measure helped us understand and explain how all these things worked together as parts of a unified whole. Learn as a unit Designing data products comes with its own unique set of challenges. One significant hurdle is using fake data in your prototypes and mockups. In a word: Don’t. Getting the data right is just as important as the interface. Testing prototypes with fake data and content is like taste testing a new flavor of soda by just licking the can. Building prototypes with real data meant letting go of the usual ways of operating. We found that we had to learn to work more closely together, and to get creative about how we understood our various roles. To get the data right early on, it meant we started by building an excel spreadsheet with realistic data with no front end at all. Now design shifted to be more focused on learning how people could use their data, rather than rushing to make the right interface. And our engineers used that context to get a working prototype up and running, without feeling like design held the keys to all the answers. As a designer used to pulling together mockups first, that felt unusual. But it turned out to be far more powerful when design relinquished the role of needing to be right, in favor of being productively wrong as soon as possible. The product vision and design strategy set the foundation, and everyone on the team felt empowered to start delivering value however they could. We pictured the team tied together with a giant elastic band. No one was waiting on anyone else, so everyone was moving in the same direction together. And when one person makes progress, it pulls the whole team along. We made sure to get the entire team on feedback calls with customers. Just like how a basketball team reviews game footage together, you need your engineering team listening in on calls, asking questions, and debriefing afterward. Our backend and frontend engineers were in every call seeing how customers interacted with our prototypes. It made a tremendous difference in our progress. Everyone on the team benefits from seeing how the customer thinks about and experiences the core problem. We moved faster, found what didn’t work earlier, and stayed better aligned when we stayed focused on learning as a unit. Look past the tech The tools we build should help people feel more capable in achieving their goals. Tools should exist to make the tool-user awesome, not to glorify the tool (or worse, the tool-builder). Technology is only a means to an end. The most critical part of our strategy was to not focus directly on building a set of attribution models. We saw many products in this space were too technology-centric, leaving users with the burden of having to interpret the output. The experience we aimed to create was one where users’ questions were in the forefront, not the models. Where users felt they could literally see the questions that the tool could answer for them. The core of our intention was centered on the user first, and the technology was deployed in service of their needs. If we were building a tool for full-time data scientists, we might have built something else. But it wouldn’t have solved for everyday marketers. It would instead have focused on the fancy models — the tech — as the means to that end. I think Dyson vacuum cleaners involve a lot of cool technology with hundreds of unique patents. But they didn’t create amazing technology as an end in itself — they created it so that my job of cleaning floors becomes incredibly easy to accomplish without my needing to achieve any new technical skills. It’s not about the tech, it’s about what you can do with it. It’s about delivering the core, not just delivering more. Easy and powerful is the future In every product shipped, there are a few critical things that end up making the most impact with customers. It’s easy to get bogged down in all the possible things we might build. It’s easy to come up with all the “more” we can add. But staying focused on the core user needs will keep us from straying into building something that misses the mark. We couldn’t have found this core if we hadn’t focused on clarifying our goals, sharing our vision, learning as a unit, and looking beyond the technology. Last month, HubSpot unveiled our new revenue attribution reporting. We’re pretty proud of what we delivered. We’re helping marketers demonstrate the real business impact of the work that they do. It’s easy to use, and powerful, too. And that helps businesses everywhere grow better. This article originally appeared on Medium .", "date": "2020-04-22"},
{"website": "Hubspot", "title": "Infrastructure as Code: Getting the best of both worlds with AWS and Google Cloud Platform", "author": ["Kerry Munz (She/Her)"], "link": "https://product.hubspot.com/blog/infrastructure-as-code-getting-the-best-of-both-worlds-with-aws-and-google-cloud-platform", "abstract": "HubSpot has been an Amazon Web Services (or AWS) customer for ten years now. Our footprint includes almost 2,500 EC2 instances, many petabytes of data on EBS and S3, and over a petabyte of web traffic flowing through over a hundred different ELBs each month. AWS’s offerings have been a huge driver of our growth because it has allowed us to easily scale up or down our infrastructure as our needs have changed. Furthermore, running our infrastructure in the cloud allows our engineers to focus on building HubSpot instead of building a data center. However, the cloud provider landscape has changed dramatically since 2008; where there was once just Amazon are now a handful of choices, so when we started planning the international expansion of our computing footprint, we decided we should check out our options. HubSpot’s engineering team have always been great admirers of Google. We use a lot of their open source libraries -- Guice, Guava, GRPC, and Protobuf, to name a few -- and had been curious about Google Compute Engine ever since we caught wind of it at Google I/O back in 2012. In 2017 we started adopting Kubernetes , Google’s open-source platform for managing containerized workloads, for our data infrastructure. Our first big project has been migrating all 400+ of our MySQL databases from standalone instances into Kubernetes with the help of the Vitess project. All signs pointed to Google Cloud Platform as an option worth exploring. Google’s networking offering was the first thing that impressed us. We liked that Google's Global AnyCast network terminates traffic at the nearest Google point of presence to the client, and routes the traffic over Google's fast internal network rather than the public internet. We also liked that they allowed for a flat IP space between regions before Amazon did (Amazon released inter-region VPC peering in November 2017). Support for multi-path routing, tag-based routes and firewall rules, as well as fast cross-zone networking within a region only sweetened the deal. There were also a number of compelling hosted services we could take advantage of if we decided to use Google Cloud. HBase sits at the heart of HubSpot’s data platform — it handles 530+ terabytes of data per day, and up to 80 million requests per second. But we’ve always admired Google’s BigTable , which is Google's NoSQL big data service. It powers many core Google services, including Search, Analytics, Maps, and Gmail, and we were excited about being able to explore leveraging that power in the HubSpot stack. But talk is cheap. Launching an entirely new computing environment on a cloud provider we have no experience with is no easy task. We weren’t ready to take that leap without knowing if it would be an improvement for our customers. But the only way we could truly measure the impact would be to have Google Cloud Platform serve production traffic. So, we settled on a multi-provider approach: we’d keep our pre-existing infrastructure on AWS and use Google Cloud for our new international expansion. Because we treat our infrastructure as code, we were well equipped to take the chance, especially if it could drive improvements in reliability and customer experience. Infrastructure as code Many companies treat their infrastructure as a bespoke process. You need a cluster? File a ticket and someone will set it up for you eventually. You need to launch a new microservice? You’ll need the expertise of a release engineering team (or more often, some lady named Jane who can cobble a script together for you). You need a high-throughput, reliable queuing system? Good luck. You may have to figure out what technology to use and how to set it up yourself. There’s an infrastructure concept called pets and cattle . Pets are things you treat with care; they’re the most critical parts of your infrastructure. They’re the hosts that must never go down. You can usually tell something is a pet because it has a very specific name. Cattle are the opposite -- they’re the things you don’t care about. The pieces of infrastructure that can fail and it won’t matter because you’ve got five more of them, or some automated way to fix it. At HubSpot, we strive to treat all our infrastructure like cattle through automation. The less important any one piece is and the more automation you have in place, the less energy and focus it takes to operate. We use a number of open-source tools to help accomplish this, including Mesos and Kubernetes for running applications, and Puppet for ensure that all of our instances are configured the same way. We’ve also built some of our own tools to help manage our infrastructure more effectively. Rainmaker is a web app that we started building in 2012 that provides a simple wrapper around the AWS console, as well as implements features like access control and auditing that haven’t existed in AWS forever. We also abstract many AWS-specific concepts in Rainmaker to reduce cognitive load on our engineers. Exposing just the information and actions that HubSpot engineers need in order to do their jobs helps things get done faster and with fewer mistakes. Integrating Google Cloud Platform into Rainmaker turned out to be pretty easy. Being able to leverage most of our pre-existing code and automation allowed us to get a proof-of-concept working in record time. Google Cloud Platform in 30 days We put Google Cloud Platform though a variety of tests to assess its performance and reliability to help us make our decision. We needed to make sure that Google could run any workload or datastore we were currently running in AWS, and that communication between AWS and Google was fast and reliable enough for our services spread between the providers to function smoothly. But the first step was to set up HubSpot’s Google Cloud environment in the first place. This meant creating machine images to match our EC2 AMIs, getting Rainmaker to properly provision Google instances, and setting up a VPN between AWS and Google. With all this in place, we were able to spin up instances that were identical to each other in either provider, and have them communicate with each other with no issues. With all the basic plumbing in place, it was time to deploy some actual applications. The first step was setting up Singularity , our open-source Mesos scheduler. This included a Mesos cluster, a ZooKeeper cluster, and a MySQL database (for storing “cold” data to minimize load on ZooKeeper). Then we updated Orion, our deployment orchestration tool, to be aware of this new Singularity cluster as a location engineers could deploy to. The last step was provisioning Google Cloud Load Balancers and wiring them up to our NGINX load balancers running in the new Singularity cluster so that the outside world could access our services. We decided to test our collection services, because we collect a lot of customer data through forms on websites, and track thousands of individual customer metrics through our analytics pipeline. We were hoping that running our EU customers’ data through Google Cloud in Frankfurt would be a bit faster than it had been using AWS. So we set some tests using a handful of dummy accounts from Stockholm, Berlin, and even Australia, and the results were, to put it lightly, stunning. It wasn’t a little bit faster. It was a full 5 times faster. We were excited, because that would be a Very Big Win for our customers. But before we moved full steam ahead with Google Cloud for our international infrastructure, there were a few things we needed to figure out. We were concerned about the Live Migrations Google uses for rolling out updates and moving workloads away from bad hardware. They seemed magical; exciting but also scary. These migrations can occur at any time on any host, and for write-heavy workloads like HBase, live migrating seamlessly from one VM to another while handling millions of requests per second seemed impossible to pull off. We did not want our customers to experience any lag or delay while updating contact information or tweaking their campaigns. Replicating that firehose of data across the globe in real-time would be like trying to change the tires on a bus while it’s moving at 1,000 mph. We’d had years to learn all the ways that things can break in AWS, and had built up a ton of tooling to handle these cases. We put in robust notifications for when servers go down, and built automation to replace servers that are failing so that we’d have no latency due to maintenance or server issues. In order to verify that response times remained consistent during those migrations, we replayed 7 hours of production traffic while working with Google's engineering team to force live migrations. As it turns out, we had no reason to worry — we saw no impact to our response times whatsoever. That was the sign we needed to start moving forward with Google Cloud Platform. We took what we’d learned from our testing and set up official QA and Production environments in Google Cloud Platform and a higher-throughput VPN between Amazon and Google. We then provisioned all our core pieces of platform infrastructure including LDAP slaves, DNS servers, and a Vault cluster. We deployed everything we needed, and spent the next couple of weeks chasing down loose ends and making sure we were ready to rumble. Our platform team did all of this heavy lifting in about 30 days. Now, any HubSpot engineer can decide that they want to run their service in Frankfurt on Google Cloud Platform by a one-line change in a configuration file, and boom, it’s there. If you’re using a cloud service provider, or are thinking about using one, we encourage you to put some thought about how your team interacts with your underlying infrastructure. Creating tooling that abstracts away the implementation details of your infrastructure will make it easier to expand and to take advantage of all the awesome, up-and-coming technology in the fast-growing world of cloud infrastructure. We’ve heard that companies can take up to two years to migrate from an on-premise solution to the cloud because they’re so tied into their existing infrastructure. But by creating a layer of abstraction between the infrastructure your services, by treating your infrastructure less like pets and more like cattle, and by using technologies like Mesos and Kubernetes, you give yourself the optionality to move fast and try new things. We’re happy to announce that we’re partnering with Google on our international cloud infrastructure. We’re excited to see how investing in Google Cloud Platform can help grow our company and our platform and we're even more excited to see where it takes us in 2028.", "date": "2018-02-22"},
{"website": "Hubspot", "title": "Building a Great Product Starts with Building a Great Culture ⁠— and the Best UX Leaders Know It", "author": ["Libby Maurer (She/Her)"], "link": "https://product.hubspot.com/blog/how-ux-builds-a-great-product-culture-at-hubspot", "abstract": "When I greet HubSpot’s new hire classes each month, I tell them we’re known for having big, ambitious goals in service of our customers. Then I talk about how we as leaders help our teams succeed. It’s one of the things that drew me to HubSpot three years ago – the promise of working on a team with really ambitious goals to solve for our customers and employees in remarkable ways. As a product team, we build products that help our customers grow their businesses and build their careers. And as a company, we build a culture that supports people as individuals with wonderfully diverse backgrounds so they can do their best work. We believe building a remarkable culture fuels our ability to deliver the most value to customers, and I loved the way HubSpot saw these two goals as inextricably connected. Create a product that helps a global community of users grow better, and create a culture that helps a global workforce of humans grow better, too. Leaders at HubSpot play an important role here because it’s our job to weave them together – especially in challenging, unpredictable, uncharted circumstances much like this year has been. It’s the most interesting UX challenge I’ve faced in my career, living in the intersection between customers and our people in every moment. And these twin challenges still get me fired up to get to work every day. We build a remarkable product... The way we develop products at HubSpot is unique, and marked by how much we value and invest in the work of small teams that include engineers, PMs, and UXers. These teams are highly autonomous and empowered to solve big, thorny problems in transformative ways. As a UX team whose members are embedded on these small teams, our job is to help our users get the most out of the powerful HubSpot product by keeping it easy to use. While a lot of business software is known for sub-par usability that costs valuable time to set up, HubSpot aims to make our product easy for anyone, in order to accelerate customers’ time-to-value. Our team takes this challenge seriously and our leaders play a key role in helping teams strategize how to achieve it. Here’s an example of how this challenge takes shape. We’re expanding on our vision of delivering a world-class platform experience by building new products for people in highly technical roles: developers, operations professionals, and data analysts. It’s a wide-open space that carries deep, far-ranging, even philosophical UX implications about how to best serve these users and extend the HubSpot platform in a usable, scalable, and ethical way. HubSpot is powerful, and becoming more so every day. How can we also make it remarkably simple, equitable, human, and inclusive? Solving for equity and inclusion is where our cultural values drive our work as UX leaders. We see it, celebrate it, and invest it in our product work, and in the culture we’re building at HubSpot, too. ...and a remarkable culture Each HubSpotter is also deeply engaged in the work of building a culture we all can be proud of. For a HubSpot UX leader, this carries its own set of unique opportunities that sets us up to deliver better results for our customers. This year we’ve stepped out and said the future of work is hybrid, and we’ve updated our approach to everything from hiring, to collaboration, to recognition and rewards, so each employee can choose how and where they’ll do their best work. UX team members can choose to be fully remote, fully in-office, or somewhere in between. Distributed teamwork isn’t a new thing at HubSpot, but we’re still learning and adapting as we lean into the change, and we’re looking for leaders who will help us grow better at evolving how we collaborate, communicate, and celebrate with our team members in a fully hybrid workplace. And we’re all responsible for creating an inclusive workplace culture, too. We want HubSpot to be a company where everyone can do their best work and be fully seen as the humans they are. That’s why we’re standing up for anti-racism at HubSpot , committing to confronting systemic racism , and reaffirming our commitment to build a more diverse workforce . I’m proud to say our senior UX leaders are running projects to remove bias from our recruiting practices, learning more from and listening to Black-owned businesses, and facilitating conversations with our team about race. The leaders on the UX team are deeply engaged in this work, lending their voices and passions to the employee resource groups, book clubs, mentoring programs, and internal trainings, while also working to establish more inclusive design practices, and cultivating the next generation of UX talent with our associate UX program . As we deepen our learnings, we are mindful that creating a diverse and inclusive culture is right for our team, and taking care of our team means we’ll have a better shot taking care of our customers. The road goes on... We’re only scratching the surface of how the UX team can advance the cause of building a better product and culture at HubSpot. We care deeply about helping our customers, colleagues, and communities grow better — as much as we care about learning and growing into better humans ourselves. As the best UX leaders know so well, the toughest and most rewarding UX problems are really about finding more ways to be more fully human and helpful to each other, whether it’s by building great software, creating a great company culture, or reaching for a brighter future for all humans. It’s what keeps me coming back and loving my work at HubSpot, every day. If that sounds like the kind of work that would energize you, too, we’d love to talk to you. We're currently looking for a Director of UX (based in Cambridge, MA or Remote), as well as several other UX roles. Interested in working with a team who cares just as much about the culture we build as the product we build? Check out our open positions and apply .", "date": "2020-10-12"},
{"website": "Hubspot", "title": "3 Developer Interview Tips", "author": ["Dan Abdinoor"], "link": "https://product.hubspot.com/blog/bid/19209/3-developer-interview-tips", "abstract": "At HubSpot, I do a lot of interviewing for the Dev Team. For more than two years now, I've been talking to candidates that ranged from very disappointing to utterly amazing (of course we've since hired the amazing folks). After interviewing in the neighborhood of one hundred developers I've come up with a bunch of interviewing guidelines, here are my three most valuable tips: 1. Never take basic skills for granted. When interviewing someone with loads of experience I tend to want to skip the basics. More than once this has bitten me when I figured out the candidate has poor logic, design or coding skills. Never assume that experience means skill. Hopefully the candidate will breeze right through your easy questions, if they don't: Fail fast. 2. Ask for the outcome. All candidates should be willing tell you about projects they either spearheaded or contributed to significantly, but not all will be eager to share the outcome. I always ask for the outcome of important projects and what measure they used for success. Great developers either succeeded in a measurable way or failed while learning very important lessons (that they should be able to explain). 3. Have a red flag policy. Ideally, you'll ask a candidate about many different areas of development and be impressed with all of their answers. However, sometimes you'll get good answers in two areas and a complete bomb in the third. I consider the bomb to be a red flag, and seriously reconsider the other areas that didn't seem to be a problem. If your interview questions are chosen to test separate core areas, a single red flag should be enough to disqualify the candidate. What are your developer interviewing tips?", "date": "2009-08-28"},
{"website": "Hubspot", "title": "Why We Overhauled the Most-Used Screen in Our Product", "author": ["Ben Keller"], "link": "https://product.hubspot.com/blog/overhauling-the-index-page", "abstract": "Contacts, Companies, Deals, and Tickets are the backbone of HubSpot. They hold all the context our customers need to create great customer experiences. With that in mind, it's no surprise that the index pages for each object are the most used pages in all of HubSpot. More than 96% of all users who enter the product on a given day touch one of these index pages. That's over seven million actions every day. On a recent call, one CEO called the Contacts index page \"the heartbeat of our organization.\" After a service outage last year, we took a long hard look at the performance and usability of the index pages. What we found surprised us: while our customers frequent these pages, they don't love the experience. It turns out there's a lot of friction in finding the pages and navigating through their most important features. With that in mind, we've spent the last few months redesigning the index pages from the ground up. TL;DR: that 96% is about to get a whole lot happier. So, what were the main reasons we felt a redesign was necessary? Usability: Early in 2019, members from HubSpot’s UX team conducted a study to see how “usable” our product was in the Sales and Services Hubs. In other words, how well did users discover and grasp the tools and features presented to them? During the studies, the CRM Index Pages did not perform well. Certain prominent features were not getting noticed or used by a large portion of our users. These features include filtering, saving a view, sorting, and adding columns. Additionally, features that commonly get used together were far apart on the screen (i.e. search and filtering). Another look: After last year's service outage, we dug into all past JIRAs that were closed as \"Works As Designed.\" The thought was that if a JIRA had to be created to surface something that works as designed, it probably has user experience flaws. This focus on past \"Works As Designed\" JIRAs surfaced clear issues with the index page experience. Missed Opportunity: Data shows that users who save a view and revisit it have a 16% higher retention rate by week 12. Yet the discovery of saved views is poor (5% of new users in their first month interact with it) and the retention rate of the tool itself shows that it is not easy to use. The Research & Design Process: To start tackling this enormous project, we mapped out every interaction flow on the pages, and identified problem areas in the design and architecture. We then combined these findings with the themes from past JIRAs and Usability Baseline Studies. Our team at work Once we developed the themes, we dove headfirst into different research methods: Questions & assumptions mapping Problem audit/analysis Usage data analysis User research with both new and power users Competitive analysis Concept testing with internal sales reps and managers Concept testing with both new and power users Iterative internal stakeholder feedback sessions Interactive prototype testing with both new users and power users Coded software usability testing After several months of deep research with all types of users, we felt confident that we had a firm grasp of the many shortcomings of the current index page design. The four most prominent were: 1) The information architecture of these pages was a problem Adding a filter to segmenting the data in our CRM is an \"aha\" moment for our users — it enables marketers to identify new leads in the database, helps sales reps decide which leads to prioritize, and shows support reps their most pressing tickets. But we've made it far too hard to get to that \"aha\" moment. The CRM has been adding features consistently for years, and the current design has not been updated in the past several years to keep up with the pace of that change. The result: the page lacks visual flow, and the controls on the screen are often far from the actual objects they manipulate. 2) The layout didn't promote a sense of “my workspace” There are very few places in the product that are truly unique to each individual user. The Contacts, Companies, Deals, and Tickets index pages are completely owned by each user. The saved views they Favorite, the columns present in the table, their default view—these things are all unique to the individual user and saved to their user settings. Because of this, users can customize their index pages to match their process and maximize their output. This is a missed opportunity: ownership and personalization lead to more in-depth and consistent interaction. 3) Index pages looked like spreadsheets, but they were missing a lot of the same \"industry-standard\" functionality our users learn through Excel and Sheets. Most of our users don't get to choose to use HubSpot—leadership in their organization makes that decision. With that in mind, the quickest way for our users to appreciate HubSpot is to become familiar with our tools. When users see an index page, they see a spreadsheet. Yet our current design does not take advantage of our users’ familiarity with Excel and Sheets by incorporating spreadsheet UI patterns like tabs. I mentioned earlier that 96% of daily users interact with the index pages, but only 15% end up saving a view. Lack of familiarity is a big reason why. 4) The board and table layouts didn't match our users' goals. Today, the surrounding layout of the board and table view are exactly the same. Favorite views, saved view library, filters—all look the same and located in the same spot. While this promotes consistency, through usage analytics we discovered that our user actions and workflow was different between the two experiences. In the table layout, users want a familiar, holistic window into all their deals, no matter the status. On the board layout, on the other hand, they want to see what's in flight, highlighting stage and motion. The new design of each layout needs to reflect our users' goals. After spending months defining the problem, talking to customers, trying out crazy ideas, and going through multiple rounds of usability testing and iterations, we've landed on a brand new design for the index pages that we’re excited to start getting in the hands of our users. The New Design The table layout: The new table layout aims to highlight prominent features to enhance discoverability and ease-of-use. Additionally, we incorporated common patterns found in popular software to promote familiarity. The three main highlights of the new design are: Tabs . With tabs, users can more easily revisit saved views on a regular basis. Saved views encompass criteria, sorting preferences, and a specific set of data table columns. The tab design is a common industry pattern, and a \"+\" icon encourages new users to incorporate their use in a daily routine. The screen will now feel more unique and personalized to the individual user as they leverage their tabs. Quick filters. Our users love the “most used properties” option in filters, picking these options 71% of the time they add a filter. In the Sales Usability Baseline study, it was discovered that many users never noticed that filtering was an option on this screen. By incorporating quick filters into the design, we make the process of quickly organizing their dataset an absolute breeze. This pattern was one of the most well received by our users during concept testing. Easier access to column editing. Editing columns has been buried beneath the \"Actions\" dropdown for as long as this page has been in existence. It has massive discoverability issues. Surfacing this important function to the main screen will encourage all types of users to make the data table their own. The board layout: The board layout has a different design than the table layout, because our users have a different goal. On the board layout, pipelines are the most important data axis (in addition to saved views). With that in mind, the new screen puts both pipeline and saved view toggles front and center. In the board layout, we also pulled out the “Sort” and “Edit Stages” features out from behind the “Actions” dropdown. These features have significant usage among a small pool of our users, and we'd like more users to discover them moving forward. Conclusion If you haven’t already, all users have the ability to opt into this new experience. Give it a try and let us know what you think. And if you like digging into complex user problems, using data to make decisions, or want to build product for thousands of businesses around the world, we're hiring an experienced Product Manager for our CRM .", "date": "2020-04-14"},
{"website": "Hubspot", "title": "Name Dropping: Nancy Wang, Head of Product and Engineering, AWS Backup (Amazon Web Services)", "author": ["Francesca McCaffrey (She/Her)"], "link": "https://product.hubspot.com/blog/name-dropping-nancy-wang", "abstract": "Name Dropping is a Q&A series that aims to elevate the stories of women leading in the tech space. The idea came from Angela DeFranco, a Director of Product at HubSpot, who said one way to be better allies is to name drop more women in discussions of achievement, inspiration, and disruptors in tech, instead of referencing, time and again, the same set of (often male) leaders. This edition of Name Dropping features Nancy Wang , Head of Product and Engineering, AWS Backup ( Amazon Web Services ). When did you realize you loved product management? I was designing and creating products before I was even in an official product management role. For example, my first “product” role was out of undergrad, for the US Government’s Department of Health and Human Services (HHS). They asked me to build HealthData.gov , which opens access to the thousands of datasets owned by HHS divisions the CDC, FDA, and NIH. Throughout the process of designing this website and data repository, I fell in love with delighting the customers who, in this case, were large research hospitals and academics — who had never had access to this much healthcare data at their fingertips. Since then, I’ve found my interactions with customers (whether people or enterprises) to be the most fulfilling part of being a PM. And it’s what drives me to go deeper into whichever industry I serve, whether networking ( Google ), data protection ( Rubrik ), or cloud storage infrastructure ( AWS ). You’re head of Product and Engineering at Amazon Web Services. How do you balance data protection and new functionality when it comes to the data services you build for your customers? Always focus on the customer. While it might seem cool to explore technically interesting challenges, it's a no-go if it's not what the customer wants. As I help lead the vision of next-gen cloud data protection, I also try to predict where the market moves. Successful PMs, I’ve found, are right a lot when it comes to predicting how customer preferences or requirements will change. As a result, they anticipate change when developing roadmaps. You’re Founder and CEO of the organization Advancing Women in Product. Tell us about AWIP’s mission and what inspired you to create it. Advancing Women in Product (AWIP), was founded to bridge the gap that I and others saw in tech leadership. There are many great initiatives to bridge the entry-level pipeline gap like Girls in Tech or Girls Who Code . Those organizations encourage young girls and college students to pursue careers in STEM. However, I believe we should do more to promote diversity in rising leadership levels, such as early directors and vice presidents. The dearth of women and other diverse people in these positions results in very few qualified candidates with such backgrounds ready for promotion to the C-suite. At Google, while my female colleagues and I had many supportive male managers, we also sought more women leaders and role models. So what started out as a living room gathering in my San Francisco apartment grew into an international NGO with over 15,000 members and six international chapters (San Francisco, Seattle, Boston, New York City, Paris, and Chennai). We provide skills-based training and executive mentorship via our Ambassador program, made up of product and engineering leaders in each technology vertical. You believe what you see. And since even male-dominated C-suites and boards of directors complain that there are too few diverse candidates for the highest levels of technical leadership — CTOs, CPO, COOs, and CEOs — organizations like AWIP provide skills and mentorship for women to succeed. In addition to your leadership roles, you’re a freelance technology writer for Forbes, focusing on women in leadership and women of color in tech. What are some of the most interesting stories or trends you’ve covered? I’m fortunate to share my perspective on women in leadership and women of color in technology via Forbes . One of my favorite pieces is AWIP’s coverage of the 2019 Obama Foundation Summit .The Obamas discussed education equality and career success among social-economic groups and women. Their increased attention toward these topics shed a light on the importance of mentorship in someone’s career. One of my most popular pieces was the one contrasting mentorship with sponsorship , an increasingly important distinction for companies who want to change the status quo by pairing protégés with sponsors to accelerate the career growth of underrepresented groups. I’d love to follow up with another article on the evolution of these programs along with data on how the type and involvement of sponsors influenced the protégés’ career achievement. Who do you think has helped you become a great leader, either as an inspiration or a mentor? A pivotal sponsor in my life is Tatyana Mamut , who helped me obtain my current role with AWS. Like me, she immigrated to the United States. She has been a product executive at many top companies, including IDEO, Salesforce, Amazon Web Services, and, most recently, Nextdoor. She’s always unabashedly herself, and it’s that energy and drive that I aspire to every day. A recent sponsor is Wayne Duso , a Vice President at Amazon Web Services. Like me, Wayne grew up disadvantaged and dedicated himself to academic excellence. Through tireless effort, he became one of the most senior leaders at AWS. Moreover, he is authentic enough to care and give back to organizations that aim to foster more diversity and inclusion like AWIP. What is one quality that you think every leader should have to generate impact and lead effectively? Leadership is a combination of many different things: empathy, work ethic, and vision. If I had to rank these, empathy would be top of the list. The ability to connect with everyone on their team (regardless of race, seniority, or gender) enables leaders to make decisions that, while not universally popular, take into consideration how others may feel. This leads to long-term cohesion and trust, and top-performing teams. When you think about the best product managers you’ve ever worked with, what characteristics did they embody? Passion for delighting the customer. As long as this is their north star, other exemplary qualities like work ethic and ability to dive deep will follow. What’s your greatest career achievement to date? My greatest career achievements are impacting and influencing other people’s careers. In that sense, building and boot-strapping AWIP and watching it grow into an international organization is one of my proudest achievements. What book do you think every product leader should read and why? Inspired by Marty Cagan . It walks leaders through a framework on how to think about staffing and lead a product organization in the best way. Others examples in this book guided me as I built my product (and engineering) organization. Who’s one woman in technology you’d like to name drop and why? Praveena Vajja , VP of Product at Oracle and AWIP’s SF Chapter Lead. Not only is her career journey super inspirational (she rose through the ranks at Oracle from a software engineer to a Vice President of Product), but she also finds the time to lead one of our biggest chapter teams along with family commitments. I’m constantly in awe of her dedication to the AWIP mission. What’s your go-to song to get yourself pumped up before a big presentation or event? A classic! Pat Benatar’s “Hit Me With Your Best Shot.” Know another woman whose name we should drop? Tweet us at @HubSpotDev with ideas. This article originally appeared on Medium .", "date": "2020-04-02"},
{"website": "Hubspot", "title": "Our first Android app: HubSpot Leads", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/60253/our-first-android-app-hubspot-leads", "abstract": "Yesterday we released the first early version of our first Android built-in application, HubSpot Leads .  You can download it directly from the Android marketplace . The application lets you see your leads from your Android phone wherever you might be.  You no longer have to be in front of your computer or in the office.  It has some lead intelligence, such as how the lead found you, some analytics about the lead, and the ability to call or email each lead instanteously right there. This application is free, it's beta (i.e. immature, might break in various ways), and it's unsupported.  There's a feedback form you can fill out , and we look at the feedback and try to address it, but it's not the normal HubSpot support.  It's not an official part of our product. The application was written by one of our developers, Owen Raccuglia , mostly on his spare time, using the new HubSpot Leads API .  Like other applications using this API, you need to be a HubSpot Medium or Large customer (not Small, at this time...) to use it. Nonetheless, we think it's pretty exciting.  We'll do a post on lessons learned from Android development in the future, since we're already working on another, separate app, to exercise our new blog API. If you're a HubSpot customer with an Android device, please try out the app and let us know what you think . If you have other thoughts on mobile offerings from HubSpot, we'd also love to hear those.  What would you like to see?", "date": "2011-02-24"},
{"website": "Hubspot", "title": "Culture Hack: Cheers for Peers ", "author": ["Mike Champion (He/Him)"], "link": "https://product.hubspot.com/blog/culture-hack-cheers-for-peers", "abstract": "We all know employee recognition is important in keeping people happy. But getting promoted, winning an award, or having a great performance review only happens so often. That could be why peer-to-peer recognition is 35% more likely to have a positive impact on financial results than manager-only feedback. Good things happen when we feel valued by our teammates. So, a few months ago, we tried an experiment to keep peer-to-peer recognition top of mind. We use TinyPulse to gauge employee engagement and get feedback from the team, and it offers a feature to send “Cheers” to teammates when they’ve gone above and beyond. When you send someone a Cheers, they get an email notification and a thank you note about what they did that was so awesome. We thought it’d be fun to take that peer-to-peer praise beyond the inbox and share it with the whole Product Team by displaying the ‘thank yous’ on TV monitors around our office. What Cheers look like on the big screen So, I built a small Node app to hit their API for the most recent Cheers which are then shown on our monitors for 5 minutes every hour (unless our alerting is red!) Everyone loves getting a virtual high-five from a peer and it turns out, having some casual, public recognition makes it a little more special. I’ve gotten positive reactions from the team and can see the benefits in a few different ways: Cheers Are Contagious: Some unscientific calculations indicate that the number of Cheers sent has increased by 30% since we started displaying them. At our Awards Banquet in February, we even gave out ‘The Giver (of TinyPulse Cheers) Award’ to our PM, Maggie , for sending so many. We’re All in the Loop: We work in small, autonomous teams and sharing Cheers with everyone is another way to stay tight-knit as an organization. The ‘thank yous’ let us know what’s going well on other teams and what their dynamics. Small things like inside jokes and tone can tell you a lot about a team and make it a little easier to connected. Culture’s at the Core: Building amazing products is first and foremost about creating a great workplace. When candidates get a tour of our dev space and see employees thanking one another up on the screen, they get a better sense of our culture. We want to work with people that are humble and effective (this slide from HubSpot’s Culture Code captures that spirit well) and the Cheers have been a great way to display those values. Spotted: a Cheers around the office One thing we like to say is that when it comes to employee engagement, peers matter more than beers ( Tweet This ). Surface-level perks like ping pong tables and free food are great, but at the end of the day, it comes down to the people you work with. Encouraging employees to recognize each other's hard work and talent, even with something quick and easy, like a Cheers, can make a big difference in their day-to-day. Just like our software, we are continually iterating on our culture to improve it. So, I’d love to hear about the culture hacks you’ve tried and what works at your company.", "date": "2015-04-13"},
{"website": "Hubspot", "title": "Building a Platform Internal Teams Love to Use", "author": ["Chelsea Bathurst (She/Her)"], "link": "https://product.hubspot.com/blog/how-we-designed-a-reporting-platform", "abstract": "I work on the reporting team at HubSpot, and have for some years. And things have definitely evolved on the product during that time. New team members have come and gone, new organizational developments and projects have kept us on our toes. But the biggest and most powerful change has been our transformation into a true platform team that creates things that can effectively scale all over the product. It wasn’t always this way. In the olde n days of HubSpot, for instance, if the email team wanted a chart, the email team sent one of their engineers deep into what we’d come to think of the High Charts W asteland , where they would wander among earlier examples of similar reporting and charting, and eventually just commence to build a new thing themselves . In the High Charts W asteland, any one can build any chart to any specification, with no concern for consistency across chart styles and options. If the social team wanted a bar chart, the social team sent one of their engineers deep into the High Charts W asteland, and that engineer returned with a new beautiful bar chart that served their purposes and needs . If another team wanted a bar chart, their engineer went on a similar journey and returned with another beautiful, but slightly (sometimes very) different chart indeed . This was all fairly suboptimal, as the kids like to say. Each engineer w as using different data, and their designers were using different types of information architecture and labelling, resulting in wildly different chart styles and formats. U sers w e re often confused by the many slightly different bar charts they encountered , and the 30 slightly different meanings of words like “views” or “visits” that accompanied them. But the thing is, HubSpot runs on and prizes deeply our value of having small autonomous teams, which allows each of us to move quickly to solve for the customer with minimal dependencies. So we rely less on opinionated rules and systems than other, less autonomous teams, and more on guiding principles and good judgement to shape what we do. It became clear to us that we needed to find a middle ground by offering our teams a true reporting platform. Autonomy is great, but duplicating efforts and providing an inconsistent user experience is not. We knew it wouldn’t erode anyone’s autonomy if we offered a platform of consistent charting components, and a framework to approach using data in the product , then let each team solve for their customers in their own way . So that’s what we set out to do. Still, a sking a group of people to change the way they do something is hard. People have habits and workflows baked into their existing process. People don’t know or understand your proposed improvements at first. People don’t know what they’ll get out of it or how it will benefit their customers. People fear it will slow their team down or create needless bureaucracy. So how do you convince people to change their process? Prove that it works Prove that it’s better Make it ridiculously easy Prove that it works What happens when you make something that slows people down, or worse, doesn’t work as promised? They lose trust. They will never try to use your solution again. Your coworkers are the customers of your process proposal. If you don’t show people that your recommend ed change in process will make their day easier, and their work faster, they won’t invest in you or your efforts. Chart consistency We provided a selection of standard charts and a guide for how to think about them. As a reporting team leader, I made myself available to guide and provide feedback if the new self-service system was too daunting for designers or product manager s to navigate . Our engineering team built us a sandbox so engineers c o uld build their own reports. Experience consistency One problem we faced was an inconsistent depth of reporting across different parts of the product . Users w ould sometimes see a simple dashboard with one date filter, while other times they ’d be able to look at their data through many lenses and explore it in depth . We took the time to identify the two approaches and prescribe their best use in the product. We defined the first type as a dashboard and the second as an explorative chart. Dashboards are for “ best of ” type s of data presentation , usually with some default start state to make it easy to use . Some filtering is possible, but for the most part, they should be understandable at a glance so you can move on with your day. Explorative tools help you understand the full scope of your world. You don’t even need to know exactly what your question is before you dive in . You can wander around in your data and poke at the edges. You can drill down, go deep, then pull back out again for the overall view . Prove that it’s better We had plenty of customer feedback that told us we had a problem that needed to be solved. Customers wanted more consistency between reports across the product, and they wanted more power to find the data they wanted to see over time. It’s not an unreasonable request, and it was one we knew we needed to fulfill. So our teams would be motivated to make the change if they could see that it would solve this customer pain. We did even better than that. We made it clear that using our new reporting platform wouldn’t just make users’ lives less painful, it would give them more joy. First, by using the reporting platform, customers would see much more consistent numbers across different tools . This would improve trust in the data we gave them wherever they were in the product. So if they checked page performance in one place, and then found that data again somewhere else , the numbers matched up . This sounds like a simple proposition, but anyone who has worked with a large product group consisting of many small, autonomous teams knows it’s easier said than done. Well, the reporting platform made it nearly as easy to say as to do. Another benefit was that using the platform gave our user more freedom to customize the tool to their own unique needs. Tapping into a product-wide reporting platform meant that customers could add any chart to their dashboard no matter w hich tool it came from . Again, it seems like a simple thing, but it was only going to be possible on a fully supported, cross-team reporting platform. Make it ridiculously easy T his was another obvious area of improvement we could offer our teams. The old process of sending an engineer into the High Charts Wasteland was an incredible waste of time and often led to confusion and frustration on individual teams. Offering a platform that promised grab-and-go service of just the reporting your team needed, in a way that would be consistent and clear right out of the box, was a very easy sell to our internal teams. We offered a lot of help and support to the teams that wanted to migrate to the new reporting platform, and made sure they knew they didn’t have to do it alone. Our Tech Lead Zoe Sobin was instrumental in making this switch as painless as possible. While migrations are never easy, ours was once again supported by the motivation that the old way wasn’t exactly pain-free, either. Together, we helped every team move their reports to the new platform in less time and with fewer problems than anyone expected. Communication is also key in any change management process. We created and circulated a helpful diagram to explain the process and system so that everyone knew what the point of it all was. We took every opportunity available to roadshow this diagram internally, talk about it, explain it, answer questions, and calm fears, until we’d built up demand for migration to the reporting platform and built a huge backlog of trust that it would go according to plan. The reporting platform is now three years old and still going strong. The framework supports our commitment to small autonomous teams that can move fast and solve for their customer needs , and it’s giving our customers more of the consistency, freedom, and flexibility they want from their reports . We will, of course, keep working to improve and add to the ways in which our reporting platform can help support great work on our teams and great user outcomes. And we’re happy to report that the High Charts Wasteland is no longer a place anyone — HubSpot team member or customer — needs to go anymore.", "date": "2019-11-14"},
{"website": "Hubspot", "title": "Wooster Scripting for Fun & Profit", "author": ["Thomas Petr"], "link": "https://product.hubspot.com/blog/bid/84948/wooster-scripting-for-fun-profit", "abstract": "One of my favorite things about working at HubSpot is everyone's great sense of humor. The developer chatroom chronicles most of our zany antics, and it's facilitated by our very own robotic butler, Wooster Bot (named after Bertie Wooster , and based off of GitHub's Hubot ). These bros want a chat bot... Wooster is pretty smart; we've taught him how to evaulate mathematical expressions, translate text between languages, kick off new builds, generate a whole slew of different meme photos, and even tell us what today's specials are at the deli across the street . Any employee can add more functionality to Wooster by writing a node.js script. What else can we do with Wooster? #JFDI David Cancel , our fearless leader Chief Product Officer, is known for his poignant, humorous, and often quotable hashtags: .@ antrod lots of books and events cause a new sucker is born every day. #FAKERZ — David Cancel (@dcancel) April 9, 2012 Boston Startupers beware. #GeekswithGuns is back. #actlikeyouknow — David Cancel (@dcancel) April 5, 2012 The @ HubSpot sales team is making it rain like a Lil Wayne video today! #majorleagues — David Cancel (@dcancel) March 30, 2012 So we figured, let's harness this corpus for some laughs. A man's gotta have a code. We can implement this easily in CoffeeScript : Our final implementation makes use of Redis as a backing store to minimize how often we hit the Twitter API, but this was left out to improve clarity. Hello World After deploying to our new Wooster script, we're in serendipitous hashtag heaven!", "date": "2012-04-17"},
{"website": "Hubspot", "title": "Why do all deployment systems suck?", "author": ["Jeremy Katz"], "link": "https://product.hubspot.com/blog/bid/27307/why-do-all-deployment-systems-suck", "abstract": "At HubSpot , we have a pretty wide array of different things being used for the webapps running behind the scenes. This isn't surprising. There'a also some home-grown scripts (in python, as that's the scripting language of choice... something I'm not complaining about) to take care of deploying the various webapps. It works, but I really want to get it doing a bit more so that it's more useful and also get the different scripts doing a bit more sharing of code so that we can improve one place and get the benefits for everything. Given that this seemed like a pretty typical problem, I figured I'd take a look and see what open source projects exist out there to see if any of them were suitable or could be at least close to a good fit for what we need and want. Unfortunately, I was kind of disappointed... Capistrano seems to be the big player in this arena. It was originally written for Rails and still very very strongly shows that heritage. This isn't necessarily bad, but it makes it a lot harder to get to work if you're not doing something that's rails-like. There are some people who have gotten some things working with Java app deployments for tomcat, but they all feel a bit hacky. The other downside for me/us is that Capistrano is very much Ruby-based, both in how its own deployment language looks as well as some of the \"how it depends on things working\" aspects. Also, the fact that it's written in Ruby and thus a little bit more difficult for us to hack on if/when we run into problems is a point against. So it's probably a non-starter for now, or at least a pretty difficult sell Fabric is written in python and seems to be following in the footsteps of Capistrano. Right now, it's far far simpler. This is in some ways good but some of the pieces that we'd want (eg, scm integration) aren't there and so I'd have to write them. And I'm not sure if the Fabric devs are really interested in expanding in that way; haven't sent email yet, but planning to tomorrow to feel it out. Config Management + Binary deployment is the approach taken in Fedora Infrastructure for app deployment and it seems to be working pretty well there. It might be something to get to eventually, but that's going to be a longer term thing and I'm not actually convinced that it's really the best approach. For Fedora it grew out of only a couple of things which could be considered \"webapps\" and a lot of system config that has turned much later into more webapps. It also pre-supposes a bit more homogenous of an environment than we use at HubSpot from the work I did there Func is something that a few people have been working on that I keep wanting to find a use for but it seems a little less well suited to doing a lot of java app building/deployment given that it's more https/xml-rpc based than shell based. Roll your own is what we're doing now and what it seems like is pretty common. I don't necessarily like this, but it's certainly the path of least resistance So, what am I missing? Is there some great tool out there that I haven't come found that you're using for Java (and more) webapp deployments? Bonus points if its python-based and pretty extensible.", "date": "2009-10-07"},
{"website": "Hubspot", "title": "Doing More with Less Using Bayesian Active Learning", "author": ["Mukul Surajiwale (He/Him)"], "link": "https://product.hubspot.com/blog/bayesian-active-learning", "abstract": "In order to reduce our data labeling needs, the AI Product Group at HubSpot is implementing an Active Learning based approach to choose samples from an unlabeled dataset that provide the most value. More specifically, since the majority of our models are based on deep neural networks, we incorporated recent advances in Bayesian deep learning regarding extracting reliable uncertainty estimates from neural networks into our Active Learning framework. Some Context The majority of the machine learning models we build at HubSpot fall under the category of supervised learning, and getting ground truth labels is not always easy. In the context of a model being used within our product, we can either have the data hand-labeled by humans or collect the labels via a feedback mechanism within the product. The latter requires some foresight and isn't always possible. For example, consider the use case where a model is used to detect suspicious email lists and prevent users from sending emails to addresses found on said lists. In order to collect ground truth labels via a feedback mechanism we would need to ignore the model’s suggestion and send emails to the suspicious email addresses to determine if they result in bounced emails. OK, so let's just have our data hand labeled by human experts. There are a plethora of companies that offer data labeling services. We can have our pick, upload our data, sit back, and watch the labels come in, right? While we can do this, it can quickly get expensive. Additionally, when dealing with a lot of unlabeled data, the question arises of how to choose which samples to get labeled. Consider a vehicle detection task of training a model to determine if an image contains a motorcyclist, cyclist, or neither. We might have hundreds of millions of unlabeled images. Most images will be nearly identical in their scenario in the sense that it will be fairly easy to tell if they contain motorcyclists, cyclists, or neither. However, there will be a long tail distribution of non-trivial corner-cases. For example, an image might contain a person riding an electric scooter from one of the popular scooter riding services. Is this person considered a cyclist, motorcyclist, or neither? Generally speaking, a machine learning model will be able to learn the patterns found in the common scenario relatively quickly and will eventually face the law of diminishing returns. So how do we choose which samples to label? Here are some options. Label all of them → This can get very expensive. You’ll have many redundant samples. Label a randomly sampled subset →  You’ll still have many redundant samples. Be smart about how we select which samples to get labeled and choose them in such a way that gets us the most for our spend. We are going to go with option three, as it’s where the concept of Active Learning comes into play. Active Learning What if our model could tell us which samples to label? This is precisely what the method of Active Learning is used to do. Using Active Learning, the model is able to proactively select a subset of samples to be labeled next from a pool of unlabeled samples. By doing so, the model can potentially achieve better performance with fewer labeled samples. The Active Learning Cycle consists of four major steps. We need to start somewhere, so we select a small sample from our unlabeled pool data and get it labeled. Train a model on the labeled training dataset. Use the trained model to select samples from the unlabeled data pool. Send the selected samples to be labeled by human experts. Add the labeled samples to the training dataset and repeat the steps. By following the Active Learning Cycle, the model is able to incrementally build up a training dataset that allows it achieve better performance on an out-of-sample test dataset. More importantly, it does so with fewer training samples when compared to a model that just randomly selects a subset of samples to be labeled. Picking Samples to Label Let’s talk more about step two. Once we have a trained model, we need to use it to somehow select which samples from our unlabeled pool dataset to get labeled. Consider again the vehicle detection task and imagine for a moment that you are the model and you need to pick which samples to get labeled. Logically, you wouldn’t pick samples that you are absolutely sure about. Rather, you would pick samples that look like they might contain a bicyclist or a motorcyclist, but you are uncertain about your judgment. The interesting bit is figuring out exactly how to measure uncertainty. Measuring Uncertainty One simple way to measure uncertainty is to just look at the output of the model. In our multiclass vehicle detection problem the output of the model is the result of a softmax function applied to the outputs of the last layer of the neural network. The resulting vector contains three probabilities, one for each class, that sum up to one. Using this output, we could use a couple of popular selection methods such as Least Confidence Selection, Margin Sample, or Entropy Sampling. However, we need to step back and ask ourselves: is using the softmax output actually a good measure of uncertainty? The simple answer is no. Just because the model performs well for the prediction task, it does not mean that the estimated probabilities from the softmax function are well-calibrated. A one-third split across the three classes in our vehicle detection task could be derived from a very sharp distribution around those values, or from a uniform distribution across the 0 - 1 interval. The former indicates a confident model and the latter an unconfident one. Even with a high softmax output probability the model can be uncertain about its prediction. OK, so we can’t rely on the softmax output of the model as a good estimate of uncertainty. No worries, as there is a particular type of model that, in principle, knows what it doesn’t know. Gaussian Processes In a machine learning problem where the input and output are denoted by x and y respectively, the goal is to learn a function g( x ) = y' that best approximates the target function f(x) = y. In order to do so, the learning algorithm seeks to optimize a cost function that measures the difference between the model’s predictions y'and the ground truth labels y. A Gaussian Process model uses a non-parametric approach that finds a distribution over all possible functions approximating the target function f(x) that are consistent with the observed data. The charts above show the decision boundaries of a Gaussian Process versus a Network model. If we use the predictions from the model as a measure of uncertainty, then the decision boundaries can be interpreted as an uncertainty heatmap. Notice how the Gaussian Process model is less certain about its predictions on data points that are farther away from the training data points. So that’s it right? Let’s just use a Gaussian Process model. Problem solved. Unfortunately, it's not that easy. Gaussian Processes models are non-parametric, which causes them to require the entire training dataset each time to make a prediction. Furthermore, they lose efficiency in high dimensional spaces where the input to the model consists of many features. As a result, using a Gaussian Process model is too computationally exhaustive and not well supported for a production setting. So we can’t directly use a Gaussian Process model. What if there was a way to approximate one? Bayesian Deep Learning In their paper Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning , Garin et al. show that a “multilayer perceptron with arbitrary depth and non-linearities and with dropout applied after every weight layer is mathematically equivalent to an approximation to the deep Gaussian process”. Let’s break that down starting with the concept of dropout. When training neural networks, it is common practice to use different regularization techniques to reduce overfitting, which occurs when the model learns to simply memorize the training data. As a result, its performance on training data is significantly better than the performance on test data. Dropout is one such regularization technique used to reduce overfitting in neural networks. It works by randomly turning off some of the nodes in the network during each training iteration. Source : Srivastava, Hinton, Krizhevsky, Sutskever and Salakhutdinov (2014) Typically dropout is applied only during training. During inference time, the dropout is not applied. Therefore, the predictions from the model for a particular input are deterministic and can be thought of as the average of an ensemble of neural networks. If you leave dropout on during inference time and pass the same input through the network, the output will be non-deterministic. Garin et al. showed that dropout in neural networks is identical to variational inference in Gaussian Processes. Therefore, if we leave dropout on during inference time, its predictions can be interpreted as samples from an approximate posterior distribution over the parameters of the neural network. What makes this especially cool is that by performing several stochastic forward passes through the network for a particular input we can obtain good uncertainty estimates! This method of dropout is called Monte Carlo dropout. Here is an example. Let’s go back to our vehicle detection model. Imagine that we pass as input to the model an image containing a person riding an electric scooter. Is it considered a motorcyclist, cyclist, or neither? If we just look at just a single prediction from the model with dropout turned off, we might find the model to predict with high probability the image to contain a motorcycle. If instead we use the Monte Carlo (MC) dropout technique to get 100 different predictions from the model, we might discover that the shape of the underlying probability distribution over the parameters of the network is close to uniform. As a result, if we were to take the argmax of each of the 100 sample predictions, we might find that 40% of the time the model thinks it’s a motorcycle, 30% of the time it’s a bicycle, and the remaining 30% it’s neither. Clearly the model isn’t confident about its predictions. Monte Carlo dropout is a very clever trick. At HubSpot, we also use it to build adaptive tests powered by deep contextual multi-armed bandits . Connection to Active Learning Recall that for Active Learning we want the model to be able to choose which samples to get labeled. One way to do so is by having the model choose samples from the unlabeled pool dataset it is most uncertain about. Using Monte Carlo dropout we can make multiple predictions for each unlabeled sample and use them to extract uncertainty estimates. For regression problems we can choose samples with high predictive variance to be labeled by a human expert. For classification problems there are a couple of different acquisition functions we can use. For example, we can choose samples that have the highest entropy or samples where the model is uncertain on average, but makes different predictions for the same input with high certainty. So what kind of samples might a model pick? We trained a model on the popular MNIST image recognition task, which consists of images of handwritten digits. The three images above are samples from the test set the model chooses to get labeled. As we can see, even for a human, it’s not obvious what the above images represent. Thus, the model would greatly benefit from having them labeled and used as training data. If you are curious, you can read more about Bayesian Active Learning in the paper Deep Bayesian Active Learning with Image Data , by Garin et al. Putting It All Together Labeled data is increasingly hard to come by and getting samples labeled by human experts can quickly become expensive. Furthermore, a model will learn more effectively by learning from a variety of samples and not just the easy ones. Using Active Learning, a model can proactively select a subset of samples to be labeled next from a pool of unlabeled samples. By doing so, the model can potentially achieve better performance with fewer labeled samples. In order to select which samples to get labeled, the model must be able to tell which samples it is uncertain about when making a prediction. Simply relying on the output of the softmax function does not provide a reliable estimate of uncertainty. In order to obtain reliable uncertainty estimates in neural networks, we can use Monte Carlo dropout. By using the output of Monte Carlo dropout in conjunction with acquisition functions, we can allow the model to select samples to get labeled which it will benefit from the most. By iteratively repeating the Active Learning process we can obtain the optimal training dataset for the model. Below is a plot showing the Active Learning method discussed in action for one of our models related to search result relevance. The plot shows that using the methods discussed the model is able to obtain a higher average precision when compared to randomly selecting samples to get labeled. Thus, we are able to get the most impact by achieving higher performance with fewer labeled samples!", "date": "2020-10-06"},
{"website": "Hubspot", "title": "Tactics to Safely Rewrite a Major API", "author": ["Jared Stehler"], "link": "https://product.hubspot.com/blog/tactics-to-safely-rewrite-a-major-api", "abstract": "Here at HubSpot, we ship new code quite often . Development at such a rapid pace only works if you can ensure as little disruption as possible (if any) for your customers by using strategic patterns and techniques. We have a system in place that allows us to toggle features on a per-customer basis and we recently applied it to successfully rewriting an existing, high-trafficked API. We implemented this with our own homegrown gating system , and our nginx loadbalancing tier, but the general pattern could be applied to other architectures, too. Here’s a rundown of how we did this and the steps you can take to address issues with a new system before they impact your overall customer base. Step 1: Create internal proxy in nginx Load Balancer The first thing we want to do is allow the load balancer to transparently proxy a request to the existing API on a conditional basis, as determined by our new application (in this case, our condition is the evaluation of a feature gate). Nginx has built-in support for internal proxying, via a feature known as X-Accel (or x-sendfile) .  If during the processing of a reverse-proxied request, nginx receives a special response header from the upstream server, \" X-Accel-Redirect \", with a URI, nginx will internally proxy the request to the named location and return the response straight out to the originating client. Here's our internal proxy setup: The critical bit here is that this looks for an additional response header from the upstream server, X-Downstream-Url , and uses that value as an internal proxy source. By setting this into a variable, it forces nginx to resolve the host via DNS, which is absolutely necessary in an EC2-like environment where your hosts can get reassigned IP's on a whim, especially if you use ELB's. Note: the downstream url must be an absolute URL, complete with scheme (http://) or else it won't work, since we're using an external DNS resolver. Step 2: Check gate early in request filter in new API Next, we need to create a request filter in our new API service which can evaulate our condition (gate check) and trigger the redirect to the existing API if necessary. Since we are a dropwizard shop , naturally our filter is a ContainerRequestFilter: Step 3: Reroute all existing API traffic to new API load balancer This is the potentially risky step as we're actually affecting all existing traffic, even though our gate will be initially set up to not allow any traffic past our new filter. Once the traffic has been rerouted, however, we are free to ungate and/or re-gate customers whenever we need to! Step 4: Validate, Verify, Vanquish (the old API) Our final step is to validate that the new API functions correctly. We've created a number of specialized tools for comparing responses side-by-side, automated smoke tests and regression tests, and tools for visual diff checking, which would make for a good follow-up post. Stay tuned! As you can see, using an internal proxy at the load balancer can be a powerful technique for rolling out new code in a controlled fashion. An added benefit is that you aren't tying up your new API application server with the I/O of proxying requests to the existing API during the rollout period.", "date": "2015-03-12"},
{"website": "Hubspot", "title": "This time we didn't even try to fly an RC plane", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/63780/this-time-we-didn-t-even-try-to-fly-an-rc-plane", "abstract": "The HubSpot engineering team has an annual \"Cinco de Mayo\" party.  It's a fun tradition, accompanied by Mexican food and much drinking, hosted by our beloved CIO Jim O'Neill . Devoted groupies, if we have any (which I doubt), will remember the videos from our last Cinco de Mayo party.  A couple of them are below.  In short, we failed miserably at flying an RC plane, despite assorted approaches and attempts. This time, we gave up the RC plane a priori.  We're good at eating and drinking, so we'll stick to that.  We did add new \"HubSpot Dev Awards\" with prizes for \"Most Reverted Code\" and \"Most Likely To Do Body Shots,\" among others. As you can see, the team has grown quite a bit.  Last time we used just a couple of cars to get to Jim's house, whereas this time a party bus was completely filled up. By the way, we're still hiring developers.  If you want to join, please apply .  If you have a developer friend, you can refer them , and get $10,000 if we hire them.", "date": "2011-05-09"},
{"website": "Hubspot", "title": "Maybe IDs Should Be Object-Oriented Too", "author": ["Edmund Jorgensen"], "link": "https://product.hubspot.com/blog/bid/51697/maybe-ids-should-be-object-oriented-too", "abstract": "What's wrong with this picture? class PageStoreDB { Page getPage(int pageId) throws PageNotFound, IOException {//... boolean deletePage(int pageId) throws IOException {//... boolean pageExists(int pageId) throws IOException {//... //etc... } There might well be more than I can see, even in this simple snippet, but I can see at least two problems--one pretty obvious and one maybe not so obvious.  Obvious (assuming we're in Java): PageStoreDB should be an interface, to make it easier to mock for tests, swap out implementations, etc.  Less obvious: I don't think pageId should be an int. Almost everyone makes it an int, of course.  I've done it plenty of times myself, because it's natural--usually you're using an id to read from a database, and the id in the database is typically an int.  As programmers we also tend to think of ints as \"primitive\"--about as simple as you can get.  I'd like to suggest that this isn't so.  What if our snippet looked like this? class PageID { PageID invertSign(PageID id) {//... PageID add(PageID id) {//... PageID subtract(PageID id) {//... PageID multiply(PageID id) {//... PageID divide(PageID id) {//... PageID leftShift(PageID id) {//... PageID arithmeticRightShift(PageID id) {//... PageID logicalRightShift(PageID id) {//... PageID greaterThan(PageID id) {//... PageID lessThan(PageID id) {//... PageID equalTo(PageID id) {//... PageID notEqualTo(PageID id) {//... PageID lessThanOrEqualTo(PageID id) {//... //...and much, much more... } class PageStoreDB { Page getPage(PageID pageId) throws PageNotFound, IOException {//... boolean deletePage(PageID pageId) throws IOException {//... boolean pageExists(PageID pageId) throws IOException {//... //etc... } You'd probably think the programmer who created this was borderline insane.  About the only methods in PageID that you'll actually use are equalTo and notEqualTo.  The rest are not just superfluous, they're distracting and potentially dangerous.  Do you really want to be able to logically right shift an identifier by accident?  But this is exactly the interface you're getting when you use an int for an identifier.  What you're really looking for in an identifier from the client side is something more like this: abstract class PageID { abstract boolean equals(Object o); } The rest of the implementation details, mapping this object representation to the id field in the database, are exactly that--implementation details--and should be handled in implementing classes in the PageStoreDB's purview. So, you say, is that it?  I have to write at least two classes to handle the simple identification of a Page, a job I could do with no work using an int, and all I get in return is that I can't accidentally right shift my id?  I still think you could argue that was enough to justify the work, but I think we actually get more. Let's say we're using ints for our ids and, somewhere down the road, we have to start merging pages in the page store--that is, we want to essentially forward one id to another id.  With the int approach, we have some problems.  Just testing id1 == id2 doesn't really work any more.  You have to start writing methods like PageStoreDB.idForwardsTo, and remembering to call them when you want to compare ids.  If we're using the class as an id, however, it's pretty easy to handle.  We have each object keep a list of forwards, and consult these in the equals method.  This lets us maintain a nice invariant of our system--that all ids that identify the same page test as equal to each other--without altering client code, because we encapsulated early on. We get a similar benefit if we stop identifying pages with ints in the database, perhaps because generating them in sequential fashion is causing a bottleneck, and start using uuids instead.  Very little code needs to be changed, and all of it is in the provider class, where it belongs, instead of in the client code. There are a host more benefits as well: logging, checking for goodness, control over creation.  If and as these become needed, they can all be done in one place. I'm coming to believe that the basic principle here applies pretty widely: namely, that you shouldn't use \"primitive\" types to represent just about anything in your system.  Use a URL class or an AnchorText class instead of a raw string, for instance, or an enum with custom methods for a set of bit fields.  It doesn't take much extra work once you get into the habit, and the aggregate work you save yourself down the road is usually more than worth it.", "date": "2010-09-16"},
{"website": "Hubspot", "title": "Starting Summer In Style", "author": ["Odette Santos"], "link": "https://product.hubspot.com/blog/jerry-remys-rooftop", "abstract": "Last thursday, HubSpot's Product team gathered at Jerry Remy’s Rooftop Patio near Fenway Park to celebrate the beginning of summer and welcome our Summer co-ops and new hires to HubSpot. This was the first of many Product team events for this summer and we will update the blog with highlights. Check out some footage of the party after the break.", "date": "2013-06-26"},
{"website": "Hubspot", "title": "By the people, for the people: Keeping your design system evergreen", "author": ["Lara Tacito (She/Her)"], "link": "https://product.hubspot.com/blog/by-the-people-for-the-people-keeping-your-design-system-evergreen", "abstract": "This post is the third in a series about HubSpot Canvas , our new Design Language. Read the first here and the second here . Every January, millions of people decide that this is the year their lives will be different. You’ll read more books. You’ll put more money into savings. You’ll eat fewer Cool Ranch Doritos and pints of Ben & Jerry’s. And you will gym. Every. Day. But more often than not, as soon as February rolls around, there’s a stack of unread books on your nightstand. Your savings is routinely going to fund your Taco Tuesday habit. And there’s a fine layer of Dorito dust covering your couch. Why? Because good intentions aren’t enough. Unless you make a lifestyle change, even the best-intentioned resolution just won’t stick. The same is true with design systems. When you redesign your product, the systems that caused your product’s style guide to stagnate (or led to your team creating 6 different primary buttons ) is probably still around. And without a true lifestyle change, you’re likely to end up right where you started. That’s why the most important part of your new design system isn’t your beautiful new color palette , or even the tools you put in place to make using your design system effortless — it’s the way your team interacts with the system on an ongoing basis. We didn’t want our new design system, HubSpot Canvas, to follow in the footsteps of our old style guide, which ended up stale and ignored. We wanted it to be a growing, changing, living thing. We needed a lifestyle change. And we were only going to get there by overhauling our design process. By the people - your system should be owned by all Process sometimes gets a bad reputation. And it’s true — process for the sake of process can be inefficient at best and frustrating at worst. But the right process removes friction. It speeds up decision-making, makes roles and responsibilities crystal clear, and gets everyone on the same page. In figuring out how to govern HubSpot Canvas, our design language, we wanted to create a process that achieves all these things. We knew that if our new process was going to succeed, it would need to be lightweight and co-owned by the people who were using it every day. There’s no question that building and maintaining a design system can be a full-time job. But we’ve found that spreading that job across a rotating group of designers works best. It stands to reason that the designers who work on our product every day, who understand our users, and who are trained in how to prioritize work and iterate on solutions make for the best shepherds of this process. Every 6 months, a group of four designers rotate in and assume specific roles and responsibilities on the Canvas team. The benefits are twofold — not only will they directly improve the system while they’re on the team, but they’ll have a deep understanding of how to contribute to it after their rotation is over. Our goal is to have every product designer at HubSpot eventually do a tour of duty on the Canvas team. The designers who work on our design language do so in addition to their “day jobs.” We’ve found this works well, because now that all the major pieces of Canvas have been created, the task of maintaining the design language is much less demanding. Still, the designers on this team must: Champion the HubSpot Canvas design language Be well versed in the existing documentation and decisions to date so they can easily answer questions and identify inconsistencies Continue identifying ways to improve the process and documentation Update the Sketch UI Kit weekly and send out an email detailing the updates to designers and front-end developers Triage incoming issues and facilitate discussion and decisions in our weekly review meetings Proactively reach out to designers across the team to help document use cases, variants, and patterns Work with our Frontend-as-a-Service team to answer questions and help ensure components are correctly changed or built. How a bill becomes a law Keeping a design system evergreen requires close collaboration between designers and developers. So in order to facilitate effective collaboration, we decided to build our process where the conversations and decisions about our design system were already happening — in Github. This makes Github our single source of truth for Canvas. So… If an engineer needs to know whether a component has been approved by the design team? It’s in Github. If a designer needs to know whether a component has been built yet? It’s in Github. If the team needs to debate whether a component should exist at all? You guessed it — we do that in Github. Step 1: We need a new component, or an edit to an existing component. From our UI Library , anyone can submit a Github issue to the team for review. These issues are how a designer gets the ball rolling with the Canvas team. We ask for a number of details in the initial Github issue. We’ve learned over time (and communicated broadly) that things move more smoothly when the submitter has considered the details and use cases for a component thoroughly. This isn’t the place for general ideas or future improvements (those conversations often happen over Slack or offline between designers) — it’s for a component that’s ready to be reviewed and built. It then gets added to our queue: Step 2: The issues get triaged by the Canvas team. This process has evolved over time, but our goal has remained the same. In order to make sure that nothing slips through the cracks, we realized that each issue needs someone responsible for shepherding it through this process. Instead of devising a sophisticated model for how to divide or evenly distribute the work, we ended up with a simple volunteer triage system each week. We settled on this for a couple of reasons. First, some people just have more interest or expertise in certain topics. And second, workloads outside of this team fluctuate — sometimes certain people on the team are busy and sometimes they aren’t. This way, the team can react to work in an elastic way, trusting each other to pick up the slack. It’s not perfect; sometimes we need to reassign issues or make small changes. But it fits our general style of working at HubSpot, and it hasn’t failed us yet. Step 3: The issues go through review. At a high level, the review process mirrors our overall design process (but at a smaller scale): Understand the problem Determine who is affected by the issue Chat and collaborate with teams who are affected Craft, modify, and hone the component design Review with the Canvas team We aim for this process to take a week, but some issues take minutes and some can take weeks depending on the scope of the component and its dependencies. Step 4+: It depends. There are a couple of scenarios that can come out of the component review: Design 👍 for components with wide use. It makes the most sense for our Frontend-as-a-Service team to build and implement these components, since they’ll be used across the product. Design 👍 for components with more narrow use. Often, if it’s a single team that needs a component most, they’ll build it in a reusable way, then add it to our UI Library. Design 👍 for components that don’t need to be reusable. Sometimes, components are so narrow in scope that there’s no reason another team would need to use it. In this case, the component is reviewed to ensure that it fits with the rest of the system, and then the team will build it into their app. If it needs to become a reusable component at some point in the future, teams can then add it to the UI Library. If these issues result in something needing to be changed or added in our Sketch UI Kit, it receives a special tag with the name of the upcoming release. This makes it easier for the designers who curate the UI Kit to see everything that needs to be addressed. There are also a few reasons why the team might reject a component request: Design 👎 for components that we deem unnecessary. The team will always include a thoughtful reason for why a component shouldn’t become a standard or why it doesn’t fit our guidelines. If applicable, other solutions or considerations are offered. Design 👎 for components that need more information. Sometimes, designers need to go back to the drawing board to figure out additional details before a component is ready for prime time. For the people - your system should help you We wanted Canvas to be so easy to use that our designers would never dream of using anything else. So, for example, instead of using just numbers to label our UI Kit versions, we started naming each version alphabetically after famous rappers. Not only did we get fun facts and great playlists, but it also made remembering and talking about the different versions a lot easier (unsurprisingly, Jam Master Jay and Kris Kross is a lot easier to remember than v1, v22, or v100). Once we made it through the alphabet, we started working our way through As Seen on TV products. We care a lot about continuously evaluating and improving our process to make life easier for everyone on the design team. Some examples of the challenges we’ve solved over time are: Visibility into what’s changing. In the early days, designers on the team had trouble knowing what was changing unless they were on the Canvas team. So we started sending out email every time we release a new Sketch UI Kit. These emails help us clearly and consistently update the team on what’s new and different in each version, and provides an easy place for designers to download the new Kit. Each UI Kit also includes a changelog on the first page of the Sketch file. Matching code in the UI Library to design assets in the Sketch UI Kit. In the beginning, we had a bare-bones Sketch kit cataloging the different components we might need and a front-end component library for developers to reference and use, but they didn’t always match up. This divide led to mismatched language between designers and developers. So in order to cultivate co-ownership between designers and developers, we undertook a big project to match the navigation and naming conventions in our UI Library and our Sketch UI Kit. Thinking beyond traditional components. Illustrations , page layouts , empty states , error states — you name it. If reusing an object creates leverage, it’s worth making it into a component or an add-on. Our Frontend-as-a-Service team has also made it extremely easy for engineers on product teams to submit components or add-ons to the system themselves. We’ve also started documenting UX patterns (not just “which component should I use?” but “how should I use it?”). But we certainly haven’t fixed everything. Some challenges we’re still trying to solve and have been iterating on include: Effectively assigning and displaying priority. When we started moving our process into Github, we provided tags that let users choose the priority of their request on a scale from P1 to P3 (a P1 meant “we need this done yesterday” and a P3 meant “we’ll get to this someday”). But because our team moves so fast, almost everything ended up being a P1. But we also can’t do everything — we need to balance the priorities of 40+ teams, and we’ve had some issues slip through the cracks. We’re rethinking how we prioritize issues today so we can both solve for the team that builds our components and for the teams who are waiting on them. Not having a dedicated design resource. While we’d like for all designers on the team to do a rotation, their main responsibilities still lie with their product teams. This means we need to be scrappy and resourceful when it comes to getting the work done in a timely manner. We may consider supplementing the rotational team with designer who’s focused on the system full-time in the future. In our system we trust We have a golden rule here at HubSpot as part of our Culture Code: U se good judgement . It stems from a culture of trust and accountability to others. We built our principles, guidelines, and processes on a bedrock of trust to ensure that our design system lasts, because a system only works if people trust it. We created that trust by making it easy to understand how decisions are made and how to contribute if someone wants to help or disagrees with a decision. We gather feedback periodically and make plans to address improvements. We find ways for people who care about it or use it a lot to get involved. And we document as much as we can about why decisions were made so that anyone can see and refer back to them. At the end of the day, making the maintenance of our design language a breeze wasn’t just good for our designers and developers — it was good for our users. Redesigning our product with Canvas was a big change, but our goal was to build a system and process so strong that we’d never need to redesign our product again. With the foundation we’ve created with this entire system we have the capability to make smaller changes across our product over time. New primary color? Done. Rounded corners not cool anymore? Gone. Users have trouble figuring out how to proceed in a wizard flow? We’ll research and fix it without a whole UI audit across the app. By creating a strong design system and a strong process to support it, we can support a thoughtful process of product evolution — without the burden of wholesale revolution. It’s a system that works.", "date": "2018-05-24"},
{"website": "Hubspot", "title": "Bulletproof Demos", "author": ["Zack Bloom"], "link": "https://product.hubspot.com/blog/bulletproof-demos", "abstract": "We all like to build software which is reliable, but every once in a while it seems like a good idea to demo something still in its unreliable infancy. Google Chrome has a little known feature which can help. Record modes let you record every request Chrome makes. Playback mode serves requests out of that recorded cache just as if they were being loaded on the spot. It doesn't record where you click or what you open, just every request as it moves over the wire. These instructions are tuned for OS X, but can be adapted to any operating system. 1. Start by closing Chrome (after copying down these instructions!) 2. Open a Terminal (Cmd+Space then type \"Terminal\") 3. Type open -a \"Google Chrome\" --args --record-mode and hit enter. 4. Run through your demo, and close Chrome, returning to the terminal. 5. Type open -a \"Google Chrome\" --args --playback-mode and hit enter. 6. Everything will be served out of the recorded cache, even if your servers have exploded, a bug has been deployed, or the conference wifi has dropped out. Thanks to commenter Michael Kenniston we have these commands for Ubuntu (and most other Linux): google-chrome --record-mode google-chrome --playback-mode As with the OS X instructions, remember to close Chrome before beginning and between steps. Commenter Kristian J. has provided these instructions for Windows: Press Win+R to open the run dialog, enter chrome --record-mode for record mode and chrome --playback-mode for playback.", "date": "2013-03-14"},
{"website": "Hubspot", "title": "Four Things I Wish I Knew When I Became a Tech Lead", "author": ["Emil Sit"], "link": "https://product.hubspot.com/blog/four-things-i-wish-i-knew-when-i-became-a-tech-lead", "abstract": "Years ago, a mentor of mine talked to me about the distinction between leadership (coping with change) and management (coping with complexity). A tech lead does a little bit of both: we have to come up with the vision for growing the technical systems that solve problems for our customers and shepherd the solution from concept to production. While all that’s going on, we need to guide, manage, and support the people on our team so that they can always be growing. For first-time TLs, this can be an intimidatingly wide spectrum of responsibility. I know it was for me. Now, as a senior TL, I have found some modicum of success at HubSpot. There was no rulebook or guide that helped me master this role overnight. But a lot of mistakes and ‘ah-ha!’ moments helped me realize a lot of things I wish I had known when my title changed to tech lead for the first time. Here are four that I think are key in getting started as a leader. You Can’t Learn Everything on the Job Unfortunately, just like how an education only prepares you in the most basic ways for being an effective individual contributor, being an effective individual contributor only gives you a fraction of the skills you need to be an effective leader. That’s why I think it’s important to be proactive about learning as much as you can about leading a team before, during, and after you become a TL. I was lucky enough when I started my career to have a manager who hooked me up with someone outside of our company who helped me navigate my career path. He shared tons of insight with me on what’s expected of a TL, recognizing the different strengths of people on your team, and balancing people and product demands simultaneously. Whether they’re your manager or someone with a similar career trajectory at another company, finding a mentor is a serious asset in becoming a leader. But you have to be intentional about it; no one’s going to knock on your door begging you to let them mentor you. Be on the lookout for events where maybe you can make a good connection or communities where leaders can connect . Depending on the company, you might not have to go too far to find ways to cultivate your leadership style. One of the most exciting things I learned after joining HubSpot was that there’s an internal team here that provides explicit training for managers. They run a 12-course program on everything from running effective 1:1s, to providing coaching, to discussing career goals. These classes have been invaluable as a manager and full of practical insights that I’m still trying to master. Luckily, if these types of programs aren’t available at the office, organizations like Intelligent.ly (in Boston) host leadership workshops and management trainings, too. There are a handful of books I've gleaned leadership insight from over the years, too. In his book, Turn This Ship Around , former submarine captain L. David Marquet frames the success of a leader as creating more leaders instead of followers: if you are a good leader, when you leave your organization, it continues to function well. In order to do that, you have to establish technical competence in all the members of your team and provide them with the organizational clarity to know what to do. This has been really helpful for me to navigate our culture of small autonomous teams . On a more personal note, I recently read The Heart and the Fist by Eric Greitens, which captures the importance of resilience and willpower when facing challenging situations, something every TL does frequently. There are a million resources out there that have the potential to change your thinking and prepare you just a little bit more for running a team. But you have to be proactive about seeking them out and making learning part of the job. Leadership Style Should Reflect the Team, Not the Leader When I first became a leader at a previous company, I knew what I didn’t like. I had been on teams that were “agile” because “agile” (aka scrum) was the thing to do. We had standups where people who had just been working together would stand up and say what it was that they were just working on. We had standups where people who didn’t work on any of the same things (but were on the same “team”) gave cursory summaries of work they were doing for people who didn’t have any context. I went to retrospectives where no one wanted to say anything. I dreamed of being part of a self-organizing agile team, the kind you hear about in scrummaster training but are never part of, where individuals pick up the work necessary and make it happen amongst themselves. I wanted meetings that were interactive and inclusive. So, I just tried running my team and meetings that way. Parts of my strategy worked out okay. For example, having people write ideas on sticky notes during a quiet brainstorming period at the start of the meeting instead of calling them out in-person (a trick I stole from Dave Gray’s Gamestorming book) helped some of the quieter people on my team engage during planning and retrospective meetings instead of being overpowered by a few forceful personalities. It may feel strange to do the first time, but a few women on my team told me it made a big difference for them. Others parts fell flat. My team wasn’t ready to be self-organizing because they never had had to be that autonomous before. We failed to deliver projects on time. Tasks didn’t get done; it was like watching a volleyball hit the ground because no one called it. Instead of leading and managing, I let the team run itself sideways. Don’t assume that what’s right for you will be right for your team. I’ve realized that when you match your leadership style with what the individual (and team) is ready for, you feel more confident in their output and they feel more comfortable doing it. Once you’ve established a rhythm, you can work on growing their skills and giving them more independence. (Over)communication is Key I was having dinner once with our CEO, Brian Halligan, when he asked every HubSpotter at the table what we would do if we were CEO. I said I would make scaling communication and transparency a priority. I had been at companies before where the core values and mission were diluted by the time they trickled down from management to individual contributors. Every quarter, the CEO or the VP of our business unit would hammer home the vision. But there were so many layers of middle management and so much PowerPoint markitecture that it was hard to link our day-to-day individual contributions to the bigger picture. When companies grow, especially when they grow quickly, it gets harder to be proactive and intentional about every moving piece. But good internal communication should never get lost in the shuffle. Upper management has to be thoughtful about keeping an entire company in tune with how they’re driving the business, and as a TL, you have to be fixed on doing the same for your team. My team here is hungry to know how they can contribute, find something to own, and make an impact. I just need to make sure I’m guiding that energy and skill in the right direction for the business. Sometimes, I realize haven’t communicated the context of a project or technical decision as well as I could have. But when I do distill the bigger picture in a way that’s actionable and personalized to our team, their world becomes clearer, their ability to work independently improves, and they can tie their efforts to our larger mission. It’s also important to communicate beyond your team to help the larger organization understand what you’re up to. Especially when things aren’t going well, I’ve found it very helpful to document everything in a shared document (we use Google Docs), that has the most up-to-date information. This allows the team to collaborate and contribute to solving the problem, but also becomes a resource to bring other parties (e.g., legal, operations, other development teams) up to speed quickly, without requiring that people read through hours of chat logs or email threads. You’ll know when you fall short on communication. You can see it in the direction your team took a project and their confusion when they need to rethink their solution. You will hear hard questions coming down from your management. That’s why it’s best to over communicate. Lean On People Smarter Than You The TL is almost always the final arbiter of technical decisions regarding the product in our organization. We love giving people responsibility and we can afford to do that because we make sure they have all the tools and knowledge they need to make the right decision. As a TL, I have multiple “spotters” who watch out for me and help me get back on track if things go off the rails. My first spotter is my manager, who holds a regular 1:1 with me. My manager has proposed alternatives that I had forgotten to consider, and also pointed out times when I wasn’t providing enough leadership and my team was getting lost. We also use 15five as a tool to encourage everyone to reflect on their week; my 15five reports give my manager a different view of what’s going and allow him to ask questions and make suggestions. Having a more experienced and detached eye that can look at the situation and provide feedback has been invaluable. As a SaaS company, we also need our operational systems to be highly reliable. Our Director of Reliability functions as a spotter by helping TLs manage operational crises, conduct post mortems successfully, and implement remediations. For me, working with our reliability team has taught me how to think about the severity of issues and apply best practices from the rest of HubSpot to our Sidekick organization. TLs are also are given explicit opportunities to learn from one another. In addition to the daily work that span teams (giving implicit opportunities to learn from peers), we have a weekly rotating TL lunch program. This gives us a platform to share problems and solutions with minds we might not get to work with everyday. Beyond tapping into other TLs, we have another program that gives us the opportunity to lean on our senior executives from time to time (sometimes over dinner, drinks, or bowling.) I've realized there's nothing wrong with asking for help or looking outside yourself for guidance. In fact, it's the only way to grow into an effective TL. Becoming a great TL is a long-term investment. I’m still running into new problems and hard conversations all the time. That’s why the last thing I wish I had known a few years ago is that TLs, especially those just starting out, need to get comfortable with being uncomfortable. Being proactive about reaching out to mentors and learning as much as I could early on was in my control, but I learned just as much, if not more, from the things that weren’t. Instead of letting a mistake throw everything off course, it’s important to look at it as one more lesson that’ll make leadership come more naturally down the line.", "date": "2015-06-05"},
{"website": "Hubspot", "title": "Eric Ries Lean Startup talk at MIT -- videos!", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/32028/eric-ries-lean-startup-talk-at-mit-videos", "abstract": "Last month a bunch of us HubSpotters went next door to MIT to listen to Eric Ries talk about his Lean Startup framework.  The talk was organized by Tom Summitt of Genotrope , another local startup like HubSpot -- thanks, Tom! For those of you not familiar with Eric Ries, please stop reading this blog.  Go read his blog, Startup Lessons Learned , instead.  Really.  I'm not joking.  You'll do yourself a favor, and be happy for it. Eric helped found IMVU and some other companies, has a bunch of operating experience, and also serves as an advisor to some startups.  He is a gifted writer, and as I found out, a gifted speaker as well. He has so much valuable stuff to say about startups, growing companies, improving the product, running experiments, and using validated learning about customers to move forward.  It's impossible to summarize.  In fact, I think he's writing a book to collect the thoughts from his blog. In case you thought I was joking, I really mean it: go read his blog . With Eric's permission, we video-taped his talk at MIT.  The resolution is not great, since we were a bit far away with the camera.  I apologize about that.  Nonetheless, we hope you enjoy. Thanks to @KarenRubin and @Abdinoor for taping the talk, and to @DanMil for organizing the whole thing.  And of course, thanks to @EricRies for sharing his thoughts, experiences, and approach with all of us. First half: Second half:", "date": "2009-12-08"},
{"website": "Hubspot", "title": "The Future of Marketing is in Your Hands (HubSpot App Marketplace - Part 6)", "author": ["Adrian Mott"], "link": "https://product.hubspot.com/blog/bid/78391/the-future-of-marketing-is-in-your-hands-hubspot-app-marketplace-part-6", "abstract": "My first few months on the HubSpot development team has been an great experience, not only from a learning perspective, but also from seeing first hand and participating in the future of marketing. Even if you believe that traditional marketing still works and you or your company practice traditional marketing techniques, there's no denying the effectiveness of inbound marketing - and it's only going to get more popular and prevalent over time as the web and web apps continue to gain in popularity and business effectiveness. Creating marketing web applications that let marketers more easily do inbound marketing is what we've aimed to do here at HubSpot, with pretty good success so far. Now, as we open up our doors and create an open platform on which to build apps, the future of marketing lays in the hands of you all - the developers. We're certainly going to be as accommodating as possible: the public HubSpot marketplace will be launched soon, soon to follow there will be billing incorporated into the marketplace, making it easier for people to make real money through marketing apps. We'll continue to release more APIs to supplement those that already exist, look for announcements around a Keywords API and Prospects API coming soon. We'll also be working hard to lower the barrier of entry to the HubSpot Platform for HubSpot customers by changing our authentication model over the coming months. Going big is something that we like to talk about here at HubSpot, and part of that mantra is being as open and accommodating to developers outside of the company. We're believers in the bazaar mentality , especially as it has to do with platform ecosystem and development. Not only do we want the development community to help us change the face of marketing forever, we need it. Only together can we change an industry for the better moving forward and get out of the old marketing practices that we're now blocking out. A good analogy that I use is that inbound marketing is \"opt-in\", which enables a world of reliably and efficiently finding what you're looking for. Old marketing techniques are more like \"opt-out\" except the problem is that opting out usually doesn't work... If you're reading this and I have you wanting to explore the platform and potential ideas for apps, head on over to our developer documentation , which also includes the App Marketplace docs that will give you the lowdown on creating a HubSpot app. If you're wondering about ideas for inbound marketing apps, check out some of the apps that exist already , then head over to our ideas site, where HubSpot users throw new app ideas the community's way all the time. As usual, we want fedback on how we're doing so far. If you're and app developer and think we could improve on something, please DO NOT hesitate to let us know. We'll do our best to be totally transparent and work to improve things over time. If you have a suggestion, jead over to our Discussion Group and drop us a note.", "date": "2011-11-11"},
{"website": "Hubspot", "title": "Keeping Flux Flexible with general-store", "author": ["Colby Rabideau"], "link": "https://product.hubspot.com/blog/keeping-flux-flexible-with-general-store", "abstract": "Last fall at HubSpot, we started to experiment with React and Flux as the foundation for the future of our web products. Having experienced the challenges that accompany large Backbone applications, we’re confident that React’s declarative, composable components and the Flux uni-directional data model will alleviate some of the growing pains we’ve run into with Backbone. Over the last few months, there’s been a lot of buzz about Flux . Flux is mostly an architectural concept, but there are quite a few frameworks out there (e.g. Fluxxor , Delorean , Tuxedo , the list goes on...) which implement the concepts. We evaluated a few of them but for one reason or another were unable to find a good fit. In our case, flexibility is of the utmost importance. HubSpot’s marketing and sales products are made up of over 50 separate Backbone \"micro\" applications (alongside hundreds of microservices ). Consequently, a rewrite of our entire codebase is out of the question. Instead, we'll migrate our apps incrementally, with a hybrid phase when data is shared between Backbone and Flux. Since React is data agnostic, it’s possible (maybe even easy) to incrementally build React subtrees within an existing application. We need that same agility from Flux. We need to build stores based on Backbone Models shared with legacy sections of the UI now, and remove the models in favor of vanilla JS objects (or possibly immutable data structures ) later. Introducing the general-store general-store aims to provide all the features of a Flux store without prescribing the implementation of that store's data or mutations. Briefly, a store: contains any arbitrary value exposes that value via a get method responds to specific events from the dispatcher notifies subscribers when its value changes That's it. All other features, like Immutability, data fetching, undo, etc. are implementation details. We use a builder pattern to define stores and encapsulate a store’s data within a function closure. function defineUserStore() {\n  var users = [];\n  return GeneralStore.define()\n    .defineGet(function() {\n      return users;\n    })\n    .defineResponseTo('ADD_USER', function(user) {\n      users.push(user);\n    })\n    .register(dispatcherInstance);\n}\n\nvar UserStore = defineUserStore();\nUserStore.addOnChange(function() {\n  console.log('users changed:', UserStore.get());\n}); general-store also ships with a sweet mixin for declaratively expressing a React component’s store dependencies. var UserListComponent = React.createClass({\n  mixins: [\n    GeneralStore.StoreDependencyMixin({\n      users: UserStore\n    })\n  ],\n  render: function() {\n    return (\n      <ul>\n        {this.state.users.map(user => <li>{user.name}</li>)}\n      </ul>\n    );\n  }\n}); Learn more To learn more about general-store and the React mixin visit HubSpot/general-store on Github. Install general-store with npm (npm install general-store) or bower (bower install general-store). Or download the source from Github .", "date": "2015-02-25"},
{"website": "Hubspot", "title": "Coding With Inclusivity", "author": ["Zoe Sobin (She/Her)"], "link": "https://product.hubspot.com/blog/coding-with-inclusivity", "abstract": "My name is Zoe Sobin. I’ve worked at HubSpot for over six years now. First as an intern, then a full time engineer, then a tech lead and now an engineering lead. I’m also a woman in tech! And as a woman in tech, there have been many times throughout my career where interactions and experiences I’ve had made me feel like I don’t belong. Through my own personal experiences and spending time mentoring and talking to newcomers in the industry and at HubSpot, I’ve developed some opinions on changes we can make to help software engineering become a more inclusive environment. I cannot speak for everyone, especially for people who identify as BIPOC or are members of marginalized groups, but I want to use my limited experiences and my position of power as a growing leader to try to shine a light on areas where we as engineers can go about our jobs in a way that fosters an environment where everyone feels like they belong. Why does coding with inclusivity matter? We’ve learned from countless studies that diverse teams outperform homogeneous teams. We’ve also learned that psychological safety is the most important factor in defining a high-performing team. The tricky part of this is that creating psychological safety for a diverse group of people requires much more thought than it does for a team where everyone shares the same skin color, gender, and background. You may have had really wonderful experiences at your job where although you felt challenged, you felt comfortable stretching yourself and taking risks. You found people like you or people who went out of their way to make you feel comfortable and at ease.  Not everyone has that experience. As we hire more people who add value to our teams, in addition to, and often because of, a diversity of thought and experience, we need to spend more time and energy on ensuring that they have the inclusive environment and support that they need to truly flourish. So what is HubSpot doing about it? In addition to creating content that highlights a diverse array of voices and backgrounds, and running programs and ERGs to support growth and psychological safety for all of our HubSpotters, we have a number of manager-specific measures in place. To start: Anti-racism trainings Psychological safety trainings Role requirements that include fostering an inclusive team + commitments to DI&B More! This kind of operationalized accountability is TABLE STAKES and its importance is not to be undermined. I can’t stress enough how critical these measures are. But accountability doesn’t end with managers . A true sense of inclusion and belonging also comes from the people you work and interact with throughout every day. When I was a brand new software engineer and my confidence in myself was the lowest, the most impactful thing was finding the right people to support me. The people who would go out of their way to make me feel comfortable and like a valued member of the team. As I got PR reviews, sat in team meetings, ate at the lunch table, they were the ones who helped me feel like I truly belonged. So with that in mind, I want to call out a few ways that you all can strive to be that person for the people on your teams. 1. Fully internalize that there are no dumb questions * We want people to feel safe asking questions anywhere to anyone at HubSpot. While I could say this with a wink and whisper “well, don’t openly judge bad questions,” what really needs to happen is that you actually need to believe deep down inside of yourself that there are no dumb questions. You need to have empathy for where a person is in their career and truly believe that they are on a journey to becoming a strong, autonomous engineer. Only then will you actually go about your work in a way that doesn’t send the wrong message. Here are some ways you can make sure that you’re sending the right one: When you are about to respond to a question that you think should have been obvious, SLOW DOWN. Be thoughtful and empathetic. If you are feeling heavily burdened by answering too many slack questions or reviewing too many PRs, don’t put that on the person asking the question by answering in a way that is sloppy/curt/harsh. Ask for help. Ask your own questions in public channels to set an example that even if you’re experienced and comfortable you still need help. Be careful about accidentally sending hostile signals, like piling a ton of upvotes on a correct answer in Slack. A few will send the message without also signaling “isn’t it obvious.” * Although there are no dumb questions, it’s important to call out that asking really good questions is an incredibly important skill to develop as an engineer and is really helpful for the people trying to answer your questions. There are great resources out there, from straightforward tips on how to improve your question-asking skills to more specific takes, like the 15-minute rule . Never heard of it? It’s worth a read. 2. Look at PR reviews as a chance to build people up, not knock them down Before you light up a PR with 1000 comments, take a step back. Without an empathetic approach, that can quickly make someone feel really demoralized and demotivated. The most important question to ask yourself ⁠— do you have enough trust built with this person to deliver effective feedback in this way?  Here are some more PR review tips: Sometimes a better approach is to summarize the feedback and remove yourself from the literal code. This is a great strategy for teaching a lesson rather than correcting a mistake. Tone can easily be lost over asynchronous messages. Don’t be afraid to chat through your feedback in person or over Zoom. Knowledge-share if you see gaps ⁠—  I like to joke that at a fast growing company like HubSpot, we are just as much in the business of growing engineers as we are writing code. Avoid projecting your opinion as fact. This can be really stifling or demoralizing, especially when someone is new and they might not have enough context to know what is fact vs opinion. When you find yourself coming in strong with an opinion, make sure to look for the gray area and highlight that. Instead of saying “X is the right way to do this”, try “Here are some other things you should consider with your approach” or if you are really getting into minutiae about things that are super subjective, consider if it’s even worth bringing up. Vocalize positive feedback!! I can’t stress this enough!!! 3. Avoid ‘assume best intent’ Candidly, I think that this saying can be helpful in the context of actual work. Such as when you’re reviewing a PR that is all over the place and you start to think ‘Did this person even try?!’ You should always assume that the writer is trying their best and approach their work product accordingly, with patience and empathy. When you get into the realm of interpersonal exchanges or emotional impacts, though, it gets a lot messier. Why? Instructing people to assume best intent minimizes their feelings and devalues their perceptions and reactions. This is especially harmful for people in marginalized groups. Where I see this come up a lot is the matter of tone. Tone is hard to convey through text, it really is. That isn’t an excuse, though. What that means is that you need to work that much harder to make sure your words land how you intend them to. When someone provides you with feedback either for yourself or someone else and you find yourself leaning toward saying ‘assume best intent’, remember that intention matters less than how it made them feel. Own that impact and work to make adjustments. I am a privileged white woman so take this with a grain of salt, but here’s a personal anecdote to try to highlight this more clearly. When I first started working professionally, nothing made me feel worse than getting my PRs blown up with tons of really curt comments. When I brought it up, I was encouraged to assume best intent in those people ⁠— that they were just trying to help. I’m absolutely certain that there were no bad intentions, but I walked away feeling like it didn’t matter how it was making me feel, and I needed to get over it and make it work. My feelings and the impact of the unwanted behaviors weren’t centered in that conversation ⁠— the intent of the other people and justifying their behaviors were. What did that teach me about the next issue that might arise? Don’t forget ⁠— society primes us to assume best intent from those in power. 4. Extend your comfort to the people around you If you are feeling socially and professionally secure, you should feel an obligation to make people feel welcomed to your team. Be intentional about it. Schedule 1:1s, hangouts, etc. If you are starting a project with someone you’ve never worked with, go out of your way to set up a Zoom introduction. These small gestures can create a world of difference. All this holds even more true when someone is new. The first two months or so are what will tell them whether they made the right choice in trusting us as teammates and whether this is the place to grow their career.  Here are some other ways to extend your comfort to those around you: Be vulnerable about your own feelings and experiences in order to create space for others to be, as well. Share your stories and struggles and make space for others to do so, too. Be free and liberated with your questions and your curiosity. Take your questions back to basics and ask them in public channels. In essence, do whatever the opposite of “flexing” is. :) Use your position of comfort and power to hold others accountable to coding with inclusivity, too. This means providing real-time feedback to those you work with. Make sure to use the well-documented SBI model for providing feedback. These are just a few thoughts on how to go about your job as a software engineer in a more inclusive way. It’s by no means a complete list. The challenging thing about this stuff is that there is no one right answer and there are no shortcuts. We’re never done building an inclusive workplace and we are all responsible for doing so in every interaction we have. Every single person at your company plays a part in helping it become a place where anyone can grow and flourish. Want to work with a team that prioritizes inclusivity? Check out our open positions and apply .", "date": "2020-12-09"},
{"website": "Hubspot", "title": "jinjava - a jinja for your java", "author": ["Jared Stehler"], "link": "https://product.hubspot.com/blog/jinjava-a-jinja-for-your-java", "abstract": "TL;DR: H ubSpot is open-sourcing its fast, Jinja-compatible templating language runtime for Java. HubSpot's Content Optimization System (COS) was originally developed in python, and the templating engine chosen to power it was Jinja . Jinja provides a robust and powerful foundation in which to craft page templates, in a syntax derived from django templates. While python was a fine choice at the start, and allowed us to rapidly iterate on the COS, we started to run into growing pains and scalability issues with python and django. Over the past year, we've been reimplementing parts of the system in Java. While there are a multitude of mature and widely used Java templating engines out there, we realized rather quickly that it wouldn't be feasible to try and migrate our existing customers' templates to a different language; we've historically allowed our customers to use all of the language constructs, filters, tags, etc. In searching for an off-the-shelf java implementation, the closest we found was an old implementation of django templating, jangod . This proved to be a good start to get the ball rolling with the COS renderer port, but there were many gaps which needed to be filled in order to bring us up to where we needed to be. After the first 100 commits or so, we ended up forking the project and pushing it to where we needed it to be, and Jinjava was born! A Client-focused Templating Library Perhaps differently than other templating libraries for Java, Jinjava sports an API which reflects our application's use of customer-created free form templates. This means that when you render a template, you can get as a result a listing of any errors encountered during the render complete with template line numbers. Jinjava jinjava = new Jinjava(); RenderResult result = jinjava.renderForResult(template, context); for(TemplateError error : result.getErrors()) { renderError(error.getSeverity(), error.getMessage(), error.getLineNumber()); } Extensibility There are four extension points in Jinjava where you can add custom functionality: Tags Tags are a standard construct in any templating language; in Jinjava they have a declaration syntax which is similar to mustache: {% timestamp %} {% if my_var > 0 %} ... {% endif %} Adding new tags is a simple process; extend from com.hubspot.jinjava.lib.tag.Tag , and register the tag with the Jinjava instance before you render anything with it. Tags can have inner content, and have the ability to modify the template context during execution, doing things like setting / updating variables, etc. public class TimestampTag implements Tag { @Override public String getName() { return \"timestamp\"; } @Override public String getEndTagName() { return null; } @Override public String interpret(TagNode tagNode, JinjavaInterpreter interpreter) { return new String(System.currentTimeMillis()); } } register the tag with the global context, so it'll be available in all render operations on that jinjava instance: Jinjava jinjava = new Jinjava(); jinjava.getGlobalContext().registerTag(new TimestampTag()); Filters Filters are functions which can be used in expressions, invoked via a \"pipe\" operator syntax signifying their purpose of translating/transforming a prior value: {{ my_val | uppercase | split(',') }} You register filters in the same way as tags above. A filter's signature includes the \"affected\" object, as well as a parsed list of any arguments passed in: public class ConcatFilter implements Filter { @Override public String getName() { return \"concat\"; } @Override public Object filter(Object var, JinjavaInterpreter interpreter, String... args) { String addend = args[0]; return var.toString() + addend; } } Expression Tests An expression test is a special type of function invoked via the 'is' operator: public class IsEvenExpTest implements ExpTest { @Override public String getName() { return \"even\"; } @Override public boolean evaluate(Object var, JinjavaInterpreter interpreter, Object... args) { if(var == null || !Number.class.isAssignableFrom(var.getClass())) { return false; } return ((Number) var).intValue() % 2 == 0; } } Functions As you might expect, you can define raw functions which can be used in expressions. In their simplest form, Jinjava functions are public static java functions which you register with an instance of ELFunctionDefinition: register(new ELFunctionDefinition(\"fn\", \"list\", Lists.class, \"newArrayList\", Object[].class)); which can then be used in a template expression: {% set mylist = fn:list() %} Additionally, we created a special proxy wrapper class so that we could define template functions which have access to Guice-injected instances like DAO's and API services: InjectedContextFunctionProxy . You can use the static function defineProxy(..) on this class to wrap an object instance with a static invocation wrapper, so it can be invoked in a template without a target object. Performance & Benchmarks We did set up some performance benchmarks, to relatively compare ourselves to similar libraries on other platforms. Generally speaking, the overhead of the rendering engine is such that the likeliest bottleneck you're apt to have will come from custom tags which do time-intensive things like pull data from remote service APIs and such. With that said, here are our very unscientific results, with benchmarks from each compared engine ported to Jinjava (run on MacBook Pro 2.6 Ghz, OSX Yosemite 10.10.1): Jinjava vs. Liquid Liquid (@e2f8b28) on Ruby ( 2.0.0p481) Jinjava parse 21.814 runs/s 1383.319 runs/s parseAndRender 14.840 runs/s 627.996 runs/s Jinjava vs. Jinja2 Jinja2 (@85820fc) on Python (2.7.6) Jinjava RealWorldish Benchmark 1387.3108 runs/s 1643.407 runs/s Conclusion Jinjava has served us well so far, easing our transition from python to java. I think it can hold its own against similar rendering engines out there. It powers the HubSpot COS, what can it do for you? References Jinjava Project Page HubL Developer Docs jinja reference Liquid template engine by Shopify Django template engine Mustache JS templates", "date": "2014-12-18"},
{"website": "Hubspot", "title": "Engineering Success: How Five Companies Onboard New Developers", "author": ["Hannah Fleishman (she/her)"], "link": "https://product.hubspot.com/blog/engineering-success-how-five-companies-onboard-new-developers", "abstract": "Companies invest a lot of calories into recruiting and hiring engineers . We obsess over helpful prep information, interview questions, and timely follow-up emails. Creating a great experience shouldn’t stop once someone's accepted an offer, though. The time right before a new hire starts and their first few weeks are just as important, if not more, in shaping how engaged and happy they’re going to be on your team. The challenge is there’s no one-size-fits-all approach to onboarding engineers . Managers and team leads have to identify what a new hire needs to be successful based on the team culture, dev process, and that individual’s learning style. Not surprisingly, getting someone up to speed is hard and making sure they’re engaged and comfortable while doing it is even harder. We wanted our tech leads to have the chance to learn how other organizations are tackling these challenges, so we hosted Tech Talk at Night: Tech Lead Edition last week where engineering leaders shared their best onboarding practices. Robby Grossman (Director of Engineering at Wistia ), Arian Radmand (Co-Founder and Director of Engineering at CoachUp ), Robert Lacy (Principal Software Engineer at Demandware ), Bryan Healey (Software Development Manager at Amazon ), and our VP of Engineering Eric Richard talked about how they get new hires started, and some of the “aha!” moments they’ve had over the years. Check out the recording and key ideas below. 27:54 Starting Before You Start A theme that was shared across the panel was doing as much as you can for a new hire before they actually start. Those few weeks, and in some cases months, between accepting an offer and getting to the office shouldn’t feel like a prolonged awkward silence for you or them. The key is giving them context without making them feel overwhelmed. Wistia has new hires sign an NDA before they start so they can get familiar with their tools and technology as soon as possible, and Demandware runs compliance onboarding training before employees’ actual start date. Robert added that having their laptop ready to go before they even walk in the door goes a long way in making their first day go smoothly. We’ve sent interns and co-ops newsletter-type emails that highlight team announcements, fun activities, or big projects we’ve shipped since they accepted their offer, and we’re thinking of more ways to keep that dialogue open. Whichever way they work with developers before they start, all our panelists agreed that getting a new developer up to speed technically and culturally early helps ease day one jitters and gets them contributing to the code base faster. Mentoring Can Be a Group Effort Giving new hires advice, guidance, and feedback is a big job whether you’re running a big team or managing two developers. At Amazon, a huge company that Bryan described as a “humongous collection of a million startups”, once engineering orientation is over (where all new hires learn standards and best coding practices together), individual teams and team leads are responsible for mentoring the people on their team. For smaller organizations, like CoachUp and Wistia, it’s helpful for newbies to go outside their direct team for guidance. Robby said that every new hire has a buddy when they first start who they can go to with work questions, cultural questions, general office questions etc. That person isn’t usually their manager, but a peer who can help them get unstuck. At CoachUp, developers are encouraged to “code with everyone to get to know everyone”. Different organizations and TLs have different ways of setting the tone for the player/coach model, but making mentorship easily accessible and readily available is critical across the board. Giving Feedback Early and Often New hires are going to make mistakes because, well, they’re humans. But when you’re new to an organization and trying to find your footing, missing the mark on a project or task is going to feel like a much bigger deal than it would a year down the line. Everyone agreed that creating an environment where failure isn’t a taboo is critical for those first few weeks. Robert says he likes to “make mistakes in front of people so they know it’s not a big deal.” That way, when they mess up, they don’t need to feel uncomfortable or intimidated to ask for help. Robby made a great point about how important it is to give new hires negative feedback. Managers tend to want to give encouragement and hold off on constructive criticism to build up someone’s confidence early on, but TLs should be giving them \"direct feedback, good and bad\" as soon as they can. If you wait, “it’s more biting because they know they’ve been doing it wrong for a few weeks or months.” Setting Up for Success Mistakes are inevitable, and being new to an organization is always going to be tough in some ways. But TLs can make a huge difference in someone’s success by thinking through every detail early on and making sure they have the right goals and tasks; Bryan described the best project for new developers as deliverable, and “real world, but contained. It has to be something they know is going to actually be used.” Creating those opportunities for new hires to have an impact from day one, making mentorship readily available, and providing them with context before they get their hands dirty can all make onboarding a little bit easier on you and your team. What are some of your best strategies for onboarding new hires?", "date": "2015-12-17"},
{"website": "Hubspot", "title": "Why Culture is a Competitive (Product) Advantage", "author": ["John Nagro"], "link": "https://product.hubspot.com/blog/why-culture-is-a-competitive-product-advantage", "abstract": "Earlier this week, our co-founder and CTO Dharmesh Shah gave a talk at our company meeting about culture as a competitive advantage. He said every small interaction that happens at a company adds up to its unique culture, making it impossible to replicate; every decision, laugh, beer, handshake, everything. It’s easy to see the tie between those details and the parts of a business that deal with people, like recruiting. But when it comes to building software, the competitive advantage of culture isn’t so clear. Two years ago to the day, Dharmesh published the Culture Code , a 135-slide deck on HubSpot’s values, mission, motivations, and flaws. Because I like you, I’m not going to dive into every single slide (I’ll save that for the 5 or 10 year anniversary but check out the full deck below). But I do want to talk about a few key parts of our culture that have shaped the way we develop, manage, and ship products. Autonomy Doesn’t Work Without a Compass “We believe in autonomy, not autocracy.” This part of the deck is especially true for our product team. We’re broken up into about 30 small teams so every tech lead, engineer, PM, and designer has ownership over part of the product. We trust everyone on the team to work with our customers, figure out the problem, and come up with a plan to tackle it. As managers, we’re not here to tell them how to approach development, we’re here to squash any friction that stands between them and shipping a solution. But, autonomy only works when there’s a shared definition of success. Our company-wide goal is to solve for the customer, or SFTC as we like to say. The customer is so deeply ingrained in our culture that every decision, big or small, is easily made by asking “does this make our customers’ lives better?” If the answer is no, we don’t do it. Everyone’s on the same page in that regard so it’s pretty easy to let makers be their own bosses. We built a new CRM from scratch last year and our Engineering VP only checked in with the team twice- once when they got started and once when they were done. It’d be really hard to do that without a strong, well-communicated mission (and incredibly smart people with lots of espresso at their disposal). You Can’t Build Amazing Things Without Breaking Something First One of our engineers used to work at a social media giant in the Valley and because they could only deploy once a week at their size, he said breaking something was pretty stressful. We’re lucky that we’re at this growth stage and have an environment where making a mistake isn’t that big of a deal. The Culture Code says we’d “rather be failing frequently than never trying new things.” And it’s true; shit happens. A lot. Our dev team deploys about 300 times a day and we’d be lying if we said we never shipped some bad code. Things break, we fix them, and we move on. I accidentally deleted half of our customers on my second day at HubSpot; at first, I wanted to hide under my desk for the next few months but the team made it easy for me to bounce back quickly and learn from that mistake. Because it’s okay for things to go wrong, we’re more inclined to take risks if we think it’ll take a part of our product from good to great. Dharmesh says, “we don’t penalize the many for the mistakes of the few.” I think having that in our back pockets has made us better at building software in the long run. Your Product Will Only Get Better If Your People Do Lots of companies obsesses over hiring great product people but then completely change their tone as soon as they get them through the door. There’s this idea that getting top talent to join your team is the end goal, when really it should be getting them to stay. We like people that are curious and have found that if they’re not continuously learning, they’re not happy. That’s why one of my favorite parts of the deck says, “we invest in individual mastery.” We try to make sure there are constant opportunities for our team to collaborate and do something they’ve never done before. There are weekly Tech Talks (like this one on React from Gus Vargas), presentations from interesting people like Zach Holman (formerly) of GitHub and Jonathan Klein at Etsy, and on a day-to-day, we’re always here to mentor each other; ask any person on our team if they've had the pleasure of getting a few pointers on their pull requests from Matt Ball and you'll hear a resounding yes. This funny thing happens when the people building your product are growing: your product does, too. Everybody wants to hire people that are really smart, but you also want to hire people that have the capacity to get better at their craft so there’s constant improvement happening. In the past 6 months, we’ve launched an entirely new CRM, reached 300,000 monthly active users with Sidekick , and improved our reliability scores across the board. We also had the highest eNPS ( employee net promoter score ) in the history of HubSpot during that same time frame. I don’t think that’s a coincidence and I hope we can keep finding creative ways to feed our team’s curiosity. There’s a natural separation at companies between the ‘hard stuff’, like engineering software, and the ‘soft stuff’, like aspirations and vision. But the intersection of that venn diagram is where great products are built. We do our best to keep that shared ground top of mind and are always learning from what’s working and what’s not. How does culture influence what you ship?", "date": "2015-03-20"},
{"website": "Hubspot", "title": "Warp Speed with GitHub Enterprise", "author": ["Mike Champion (He/Him)"], "link": "https://product.hubspot.com/blog/bid/88470/warp-speed-with-github-enterprise", "abstract": "We've recently switched to using GitHub Enterprise for our product development here at HubSpot, and I wanted to share some lessons learned from how we've made the transition. So why the move? Previously we'd been using a mix of tools: svn & git for source control, ViewVC for repo browsing, Confluence for shared documentation and Review Board for code reviews, JIRA for bugs. We have a lot of GitHub fans at HubSpot and frankly it is a better and more enjoyable tool set in one place. (And we here at HubSpot certainly appreciate an all-in-one solution since that is what we build for our customers.) It has let us simplify our development process and better collaborate among our developers, designers and product managers. Since the switch there has been a lot of appreciation for the speed of git, pull requests & commit comments for code reviews, the wiki for easy documentation, great code/changeset browsing. There are definitely less expensive options but none stacked up to what GitHub offers. We care deeply about developer happiness and productivity, and this is great advance for both. The Migration - Make It So GitHub Enterprise (GH:E) is nearly identical to the public GitHub, but self-hosted as a virtual appliance and with support for LDAP. GitHub has pushed out new versions of GH:E reguarly so it doesn't usually lag by much. The releases are distributed as an OVA format image which we've installed in VMWare. Ours is running on a Dual-Quad Core AMD Opteron box with 16GB of RAM and 5 HDDs in a RAID5 configuration. We had this server handy so YMMV when sizing a machine. The virtual appliance has been stable and has not required much day-to-day administering after initial configuration. View of a product family & who has contributed In preparing for our migration the Etsy dev blog post, Moving from SVN to Git in 1,000 easy steps , was very useful. We took a different tack in that we didn't have a single flag day for the move, but instead phased it in over time. The HubSpot architecture is such that there are many independent apps, so it was possible to do in batches. Each team owned moving their apps and ensuring developers were comfortable using git. The biggest decision for us was around what git workflow to use since there are many different ways to use git. We use something similar to what Zach Holman describes in his talk on How GitHub uses GitHub . Our Voyage So Far In the few months we've been using GH:E it has been a great experience. A few highlights from our time using it: The biggest surprise benefit is that it has made it much easier for the non-developer members of the product team to contribute. Our UX team is using it to share and collaborate on mocks, our product people can change copy through the web UI, and it is easier for everyone to see what changes are happening across the group. The GitHub tagline of \"social coding\" is very apt. GitHub allows pull requests work from branch to branch and doesn't require forking. I think a lot of people have missed this capability. Despite the most recent debate we use both feature gates and feature branches as needed. Both can be used to help keep the number of unmerged commits small, and managing how new features are introduced. Following a suggestion by Etsy's John Goulah (who was generous enough to chat with us before we made the switch), we have put all our team members in one \"organization.\" Managing groups on a smaller scale can be a pain as teams change over time. hub is a handy wrapper for git and works with GH:E. Simplifies some common git flows, and hides some of the git command line noise. Pull request between branches Of course there are always improvements we'd love to see in GH:E. Here are a few: The code search is okay, but could be improved to allow search over the history of source control and more deeply understand languages. It would be especially handy when trying to track down code in earlier revisions. The \"news feed\" is great when you want to see what is happening across the team. Having even more controls about what projects I see updates for, inclusion of wiki updates, etc. would make it an even better heads-up display of what's going on. The Issues functionality is a fine light-weight tracking tool but hasn't won large adoption among our teams. We primarily use JIRA for bugs, particuarly because of integrations with customer support process, and Trello for product backlog feature development. Overall the switch to GitHub has been a big win for simplifying our tools and staying focused on shipping software faster.", "date": "2012-07-10"},
{"website": "Hubspot", "title": "How Grading User Flows Helped Us Launch a Delightful CMS", "author": ["Jonathan Meharry (He/Him)"], "link": "https://product.hubspot.com/blog/user-flows-product-launch", "abstract": "In April of 2020, we launched HubSpot’s CMS Hub . As the UX leader responsible for CMS Hub, I had to answer a simple question: Was it ready to launch? There are lots of ways to answer that question. Are the features built? Are the Services and Sales departments fully trained on the product? Is the marketing campaign ready to go? A task force of more than 20 people across all departments at HubSpot collaborated to answer this question from all of these angles and more. But even if the answer was “yes” across all of HubSpot, it still didn’t tell us if the product experience itself was good enough to launch. The features were built, but were they easy to use? Was the product delightful? Our strength as a product organization is based on the ability of small, autonomous teams to quickly ship features. We crank out products: we launch, learn, and iterate. It’s rewarding to us and our customers, but requires more discipline and rigor to evaluate the full experience that spans across teams. It’s a conscious tradeoff we’ve made, which means we have to work harder to answer cross-team questions about quality. With this in mind, I worked closely with our lead researcher to come up with a plan to ensure product readiness in the three months we had before launch. The challenge In the fall of 2019 I shared a user experience vision for CMS Hub with our product group. This visualization shows the high-level parts of the journey and how multiple personas overlap along the way. It also illustrates how 14 product teams layer across this journey and just how interdependent they are in creating a seamless, delightful experience for customers. It’s also obvious looking at this that no single team could say if CMS Hub was ready for launch or not. The solution We had a few months to go before launch, so we needed something we could deploy quickly. It needed to add value to teams through actionable user feedback, while also giving an ongoing snapshot of readiness to product leadership. To address both of these needs, we came up with the idea of grading user flows. The research team would record videos of customers going through the user flows every two weeks and assign a letter grade based on a roll-up of four usability metrics: task success, number of errors, ease of use, and satisfaction. The letter grade would make it easy to report on status to leadership and see movement over time. Multiple usability metrics would give us the inputs we needed to give the team actionable feedback they could use to make targeted changes to the product. My hypothesis was that we’d see some lower grades, some average ones, and that hopefully as teams iterated on the feedback, we’d see real usability improvements in the areas that needed it the most. I had no idea if a grading rubric would work, but figured it was worth a shot. The process Choose flows to grade The first step was deciding which user flows we needed to grade. This was easy because we already had a list of prioritized pre-launch initiatives as a group. It was just a matter of mapping to those. The flows in order of priority were: Building, Editing, and Designing a CMS Website Page In-App Marketer Onboarding Web Developer Onboarding The first flow (Building, Editing, and Designing a CMS Website Page), was designed to capture the main features we were introducing to solve the crux of marketer and developer pain with the CMS. The second flow (In-App Marketer Onboarding), was meant to capture the experience of a net new customer signing up for a CMS trial and kicking the tires on a new website. This flow represents the beginning of onboarding for a new customer, a critical piece of the puzzle that we hadn’t included in our previous iteration of the CMS. As it stood, a customer would be unceremoniously dropped into the Marketplace (where you can purchase website templates) after signing up for a trial with no indication of what to do or where to go next. Not good. The third flow (Web Developer onboarding), was important to get right because a foundational part of the CMS Hub strategy was attracting and growing a vibrant developer community that could build websites that marketers were empowered to easily manage. We needed a process for CMS developer onboarding in place for our launch. Define tasks within the flows With the flows defined, I asked the designers and PMs to define the actual tasks that would make up each user flow. There were two reasons for this: The teams being graded deserved a say in the metrics used to arrive at those grades The team members working directly on the product knew best which collection of tasks would most accurately capture the essence of what we were trying to measure Each flow had 3–5 tasks from start to finish. For example, there were five tasks that made up the first flow: Edit a rich text module Adjust the layout of modules Edit the design of a section Edit the content of a global module Edit the styles of an existing website theme Watch, measure, improve, repeat We recorded videos of customers going through each task. They were encouraged to talk out loud so we could hear their thought process as they went. This was an example of basic unmoderated usability testing. After completing each task, they gave a rating on how easy the task was and how satisfied they were with the experience on a five-point Likert scale , with the option to comment further. Researchers made a judgment call for each user on whether they completed the flow successfully, completed it with some difficulty, or failed to complete it. They also watched for errors, like a user clicking on a module when they were supposed to be finding drag and drop handles instead. After task success, number of errors, and the self-reported measures were captured for each flow, we put out a report. Teams then took the feedback and translated it into GitHub issues that could be worked into the product for the next round of grading. Setting targets This was the first time we had measured user flows like this. So we didn’t have a baseline to know what was a good or bad grade, and how changes to the product would impact the grades. Before we could set target grades we wanted to aim for, we needed a couple of rounds of results to see how the grading mechanism was working. We didn’t want it to be too easy to get positive results. We also didn’t want it to be too difficult to improve grades. While there were only two groups of users, this gave us enough confidence to know that the grading mechanism was reflecting reality enough to make it a useful tool. At that point, we felt comfortable setting targets for which grades we wanted to aim for by launch. Without targets, we’d be making improvements but wouldn’t know what we were defining as “ready.” I set targets by socializing with teams and then sending out a memo to the group. One main reason grading flows was effective was that as group leads, we tied these usability targets to official milestones on our roadmap. In addition to the outputs being actually helpful to teams, tying usability measures to a group milestone was another key lever. I set the target for the first flow as a B+ with a stretch target of A- and the target for both the onboarding flows as a B- with a stretch target of a B. Across the board, ease of use and satisfaction scores needed to be 3.5 or higher. Any user errors subtracted from the score and brought the letter grade down. Anything less than a 2 for success rate meant there was some difficulty in completing the task, also bringing down the letter grade. We aspirationally set the bar high, stating that in addition to the letter grade hitting a certain target, we wanted to see a perfect average score on a success rate of a 2, with no difficulty from users in completing any tasks in the flow. Our rationale was that this would prevent flows being too heavily weighted on users giving positive self-reported ratings. The outcome After five rounds of grading, we hit most of our targets and made significant usability improvements across the board. In-app Marketer Onboarding ended with a D+ but the key task in the flow that needed to be great for launch landed at a B which was on target. More on that below. The biggest gains were early on The most notable jump on the first flow was on Task 4 (Edit the content of a global module from a CMS website page), going from a D to a B. The design changes that caused this big improvement were planned on the team roadmap, but engineers jumped on it to prioritize between rounds of grading. The Web Developer onboarding flow made a big leap early on from a C- to a B+ and stayed steady through the remaining rounds of grading. A big insight was just how much small changes to developer documentation can make a huge difference. For developers, documentation is a product. It’s what they rely on to get set up and understand how the system works. So in addition to improving that onboarding experience, grading this flow also placed the importance of documentation in the spotlight. We missed some of our targets We were shy by one letter grade on Task 2 (Adjust the layout of modules on a CMS website page) of the first flow. This task was aimed at the drag and drop usability for websites. We made steady progress in usability improvement through round five, but I knew this would be the hardest one to move. We saw some issues with drag and drop discoverability that the research team recommended we dig into further with different research methods. The In-app Marketer Onboarding flow stands out as the lowest grade with a D+. That doesn’t look good. But if you look closely at the grades for each task, it tells a different story. The most critical task for launch was Task 1 (Create and publish a website after signing up for a CMS trial page). We ended with a B on that flow, which hit our stretch target for onboarding. Instead of getting dropped into the Marketplace with no direction, you can now sign up for a trial, pick a beautiful website theme, and start editing a page in a few quick steps. The grades that really brought the overall flow grade down were Tasks 2 and 3, which were aimed at the Blog and got a D- and F respectively. Yes, it’s possible to get an F with this rubric. While Blog wasn’t our priority for launch, the team responsible for onboarding included them to get a baseline, since we knew these tasks were stumbling blocks, and are part of overall CMS onboarding long term. While these grades are low, this is a great example of using usability measurement as a source of leverage. The team knew flow grading had great visibility, so they used it to move forward the conversation on how we would fix these parts of the experience. Teams worked together to fix the low hanging fruit we could before launch, while also clarifying what structural issues we’d need to address post-launch. Flow grading for Blog came up in several conversations in the product group as we talked about who would own Blog after launch and how we’d tackle the overall user experience. What we learned About setting targets Making a perfect average task success score of 2 an added requirement in addition to hitting certain letter grades was too rigid. By that standard, we only hit a couple of our targets. But what we saw is that all but one user could pass without difficulty, and because one user had some difficulty, the task wouldn’t get a perfect average of 2. This was the first time users encountered these tasks, so no difficulty at all in completion from any user was unrealistic. In the end, we decided we were ok without a perfect task success average, as long as the letter grades were where they needed to be. In order to get a letter grade in the target range, the success score still had to be high and errors had to be low, with qualitative measures in the 4 to 5 range. That kept the bar high with users feeling good about the experience. About handling missed targets When I set target grades to hit, I wanted to make sure we defined what would happen if we didn’t hit our targets. Otherwise, I worried that the grading wouldn’t have any “teeth” and successive efforts wouldn’t mean as much. We agreed as a group that if any flows or tasks didn’t hit our targets, we’d keep grading them until they did. What we found is that in both cases of missed targets, we had learned everything we could from the flow grading method, and would need different research methods to dig into both drag and drop discoverability and the UX of Blog. Of course, the grades and targets are only a means to an end. And as I covered earlier, we were happy with the actual usability improvements, and launch readiness was still the outcome we achieved. About the process Judging task success and task errors is subjective. It takes carefully watching the video recording of the user to see if they completed the tasks without difficulty, and to decide if the user is straying too far from the intended action of a task. Sometimes there’s not always a clear cut call on an error in the user flow. But it’s important to surface these with teams, and better to grade harder in most cases to keep the bar high. Because this method is unmoderated, we had to change the wording of task instructions a few times to avoid user errors that looked like they were being caused by unclear instructions. When grading on a 2-week schedule, having a pool of customers to recruit from is important as are incentives to get users to participate. The first couple of rounds were delayed due to not all users completing the flows on time. It took a few rounds to get in a rhythm. It took a full day to analyze videos to capture task completion and errors. It’s time-intensive, but somewhat offset since tasks are unmoderated. Final thoughts There will always be more to do to improve usability. The main limit of this approach is that like all usability testing, it’s not a realistic scenario. The users that went through these linear flows weren’t actually under pressure to launch a new website that would generate more leads for their growing business. That said, this was a successful strategy for us and one example of how to tackle the hard problem of improving usability across the user journey. Most importantly, we launched a much more polished product than we would have without this approach. We were ready for launch. This article original appeared on Medium . Interested in UX positions at HubSpot? Visit our HubSpot Product Careers site.", "date": "2020-05-11"},
{"website": "Hubspot", "title": "A Night to Remember: Recapping the 2014 Product Awards", "author": ["Hannah Fleishman (she/her)"], "link": "https://product.hubspot.com/blog/a-night-to-remember-recapping-the-2014-product-awards", "abstract": "Last week, we celebrated an incredible year with our very first Product Awards Banquet. Boston’s record-breaking snowfall delayed the Awards not one, not two, but three times, but luckily, it only made us that more excited to cheers to the great year we had after having some time to reflect on our milestones and big wins from 2014. Our VP of Engineering, Eric Richard, kicked off the night, decked out in his finest ballroom attire, recapping how monumental 2014 was for our people and for our product. We welcomed over 45 new people to the Product team, were lucky to have 25+ stand out co-ops and interns, and celebrated a ton of promotions and new roles. Thanks to that team, we were able to build a new CRM and empower our 13,500+ customers to do even more business; in 2014, customers sent over 3 billion emails and created 486,000+ blog posts with HubSpot. Our team, customers, and product saw a ton of growth this past year. Now, here’s a glimpse into the night’s most memorable, and unexpected, moments: Toasts on toasts on toasts We all learned one important thing about our team at the Banquet: we love giving toasts. After Eric’s reflections on 2014, the floor opened up for anyone to grab the mic and raise their glass. It didn’t take long for a line to form around the room as people waited for their turn (in some cases, more than once). Some speeches were serious, others were on the lighter side (our espresso machine got a pretty heartfelt shout-out), but all in all, the toasts captured our tight-knit culture and spirit of the evening. One of our Tech Leads even went home with an award for the best toast of the night- congrats, Mike! Why say it when you can sing it? Most people tend to think engineers and designers are on the quieter side. Eric turned that assumption on its head when he wrapped up his talk with a surprise musical number. He sang his own original lyrics about how \"you just have to ship\", followed by a little tap dance action. Don’t worry, we captured it on camera! And the Richard goes to... The Richards were the main (and arguably, funniest) attraction of the evening. The awards celebrated 24 folks from across the Product team; a few of our favorite Richards were: The Github Streaker Award: Zach Friss (Co-op from RIT) contributed on Github for a record-breaking 79 days in a row. The Giver (of TinyPulse Cheers) Award: Maggie Georgieva (Product Manager) gave the most virtual high-fives to her co-workers in 2014. The Social Butterfly Award: Pat Dignan (Software Engineer) sent the most HipChats per day of anyone on the team. The Hero Award: Jen Huang (Software Engineer) responded to the most after hours PagerDuty alerts. The standing ovation Saving best for last, there was one more toast to make as the evening came to a close. Building a great culture doesn’t happen all on its own; you have to hire the right people and keep them engaged day in and day out, and there’s one person who goes above and beyond to make that happen. Whether she’s ordering soup for everyone on a chilly day, organizing a scavenger hunt for 100+ people, or single-handedly making sure the Banquet was a success, Becky Garber always has team happiness top of mind. And, it shows: the whole room jumped to their feet clapping to say thank you right after a toasting to Becky. It was a night to remember and we’re excited for all that’s in store for the Product team in 2015. Thank you to everyone who made it a great ride!", "date": "2015-02-24"},
{"website": "Hubspot", "title": "Name Dropping: Kathleen Mitford, Chief Strategy Officer and EVP at PTC", "author": ["Francesca McCaffrey (She/Her)"], "link": "https://product.hubspot.com/blog/name-dropping-kathleen-mitford-chief-strategy-officer-evp-ptc", "abstract": "Name Dropping is a Q&A series that aims to elevate the stories of women and nonbinary people leading in the tech space. The idea came from Angela DeFranco, a VP of Product at HubSpot, who said one way to be better allies is to name drop more women and nonbinary people in discussions of achievement, inspiration, and disruptors in tech, instead of referencing, time and again, the same set of (often male) leaders. This edition of Name Dropping features Kathleen Mitford , Chief Strategy Officer and EVP at PTC . You’re currently Chief Strategy Officer and EVP at PTC. How have you had to pivot in your role due to the uncertainty of COVID-19? For most of us, this year looks very different than we thought it would, both professionally and personally. The biggest pivot for me and my team has been switching our priorities to focus on understanding the impact of COVID-19 on our customers and our long-term strategy. In the beginning we switched to “solving” mode — how can we make sure our customers are as productive as possible during this pandemic. This meant understanding their challenges and barriers with remote work and lack of travel. Many of our products at PTC enable remote collaboration and we ended up offering these free of charge for an extended time period. It also meant pivoting how we engage with customers to figure out the best way to replicate in-person events and sales meetings virtually. In addition to the short-term changes, we also re-examined long-term strategy to see if it still made sense, given that COVID-19 has changed the way we work and interact with each other. An area we were watching and investing in is SaaS. While SaaS is mainstream in CRM and ERP, the engineering world hasn’t fully caught up yet. We had been investing in SaaS products organically and through acquisition but decided to accelerate the SaaS versions of all our product lines. We didn’t change our strategy, but accelerated it by a number of years. I believe strategy is not something you define once a year but something that is constantly evolving based on what is happening in the market and with your customers. The current situation makes it more important than ever to constantly look at your strategic choices and see if they still make sense. What are some of the most exciting challenges you’re working on right now at PTC? PTC is an innovative company, with a running joke that PTC stands for “Prepare to Change.” Over our 30+ year history we have evolved from CAD (Computer Aided Design) to PLM (Product Lifecyle Management) to IoT (Internet of Things) to AR (Augmented Reality) to SaaS. We are in the process of re-factoring all our product lines to be true multi-tenant SaaS. SaaS companies operate very differently from on-premises companies and it requires us to change not only our products, but also our processes, our systems, and how we deliver value to our customer base. It is super exciting to be working on this strategic evolution. Over the course of your career, what have you learned about what makes an exceptional product leader? Exceptional product leaders have a deep understanding of the customer and the customer’s needs. This leader can recognize how a customer’s business is evolving and how technology needs to advance to support them. Early in my product management career I learned that talking to customers about new features or new modules doesn’t always end well because the customer can’t relate it to what they are doing today. When I pivoted from talking about technology to talking about the customer’s business problems, the conversation changed. The customer could clearly articulate how their business was changing. An exceptional product leader can translate business needs to technology evolution and have the technology ready before the customer needs it. What’s your greatest career achievement to date? I am incredibly proud to be part of the team that transformed PTC from a leader in CAD and PLM to also a leader in IoT and AR. The transformation was important for our portfolio, but it was also a multi-year effort to transform our business model (from perpetual to subscription), our go-to-market strategy (higher focus on partners and marketing), and our culture (cool, high- tech company). Who’s one woman or nonbinary person in technology you’d like to name drop and why? I’d like to name drop Catherine Kniker , PTC’s DVP of Corporate Development. She is incredibly talented and has held almost every role in tech, including engineering, sales, marketing, partnerships, acquisitions, etc. But what I really value about Catherine is she is truly an inspiring leader, always putting employees and their needs first. What advice would you give to your 22-year-old self? Advocate for yourself, find a trusted mentor, have confidence in your abilities. What’s one prediction you have about the future of work? Not much of a surprise, but I believe the work from home environment will become a more permanent option for most tech companies. I think meeting technologies like Teams and Zoom are going to evolve so meetings can feel more personal. Have you been taking comfort from any simple pleasures during quarantine? I begin most days with a workout, running every other day and doing a workout video the next. I’ve moved my workout mat and weights from my basement gym to my patio outside and it has been wonderful. My house overlooks a cliff so all I see is trees, clouds, and the birds flying above me. It feels like being on vacation at a nice spa resort. Know another woman or nonbinary person whose name we should drop? Tweet us at @HubSpotDev with ideas. This article originally appeared on Medium .", "date": "2020-09-10"},
{"website": "Hubspot", "title": "Hadoop World impressions", "author": ["Steve Laniel"], "link": "https://product.hubspot.com/blog/bid/27054/hadoop-world-impressions", "abstract": "I know that Dan has already written up his impressions of the conference and, being Dan's words, I'm sure theyr'e incisive and witty. Still, I'm not going to read what he wrote before I write what I write. The quantity of talks at Hadoop World, and their intellectual content, was frankly staggering. By 4pm my brain was completely full, and I had a frenetic kind of energy that I normally associate with caffeine toxicity. It was an exhilirating conference. The big boys at the conference were Yahoo! and Facebook, with relatively little involvement from Amazon. Yahoo! shoves a ridiculous quantity of data into Hadoop; I believe the number they threw out was 4 terabytes a day. Indeed, the words \"terabyte\" and \"petabyte\" were thrown around so casually that when someone -- the HadoopDB team, I believe, which is an academic group at Yale -- mentioned mere gigabytes, it hardly registered. Most of the talks dealt with abstractions above Hadoop; of these, the most prominent -- I believe everyone mentioned them at one time or another -- were Hive and Pig. Both are SQLish languages that optimize their queries into map and reduce jobs. eBay had its own variant on this, whose name I didn't write down; it was a special language meant to speed experiments on their recommendation engine. Someone loses an auction for, say, a 1998 Volkswagen; what's the best thing to suggest that they buy instead? They conduct thousands of these experiments per day, and they need a language to efficiently encode consumer-behavior patterns. Hadoop appears in the backend, but eBay and most of the other speakers quickly leave it behind. It's a testament to the technology's maturity that it has become something like electrical wiring: largely unnoticed, and there to serve the real action a couple layers up. For my money, the coolest use of Hadoop was Jake Hofman's analysis of the social graph . He notes that 30 or 40 years ago, one could do detailed analysis of very small (10-odd-node) networks , that today we can do high-level analysis of massive networks, and that the ideal would be that kind of intimate network knowledge at massive scale. To that end, he's developing a library to handle the sort of operators one wants to think about in any network: average number of in-links and out-links, the number of connected components in the network (e.g., are there really \"six degrees of separation\" between any two nodes on the graph?), some measure of \"pagerank\" for each node in the graph, etc., etc. Thinking at a productively high level about this stuff wasn't possible until we had the computation resources to walk massive graphs; walking the graph is something that can be done very efficiently in MapReduce/Hadoop. (Indeed, it seems to me that the \"social graph\" as such has been all talk and little delivery. Those of us who don't work within Facebook or Google don't have access to the full graph; at most, we have access to the few hundred or thousand nodes immediately around us. Hofman suggested in his talk that Twitter's APIs are opening up the graph in a really useful way. This is exciting to me. Maybe we can finally start reasoning about the graph as a whole.) I could go on about each of the other talks, but I won't; in the next few days, I'll try to compile all the Hadoop World slides for this blog's readers. Suffice it to say that the range of uses for Hadoop is fairly jaw-dropping, and the amount of architectural work being done behind the scenes by Yahoo et al. is humbling. The great power of computer science is that it allows us to express previously inaccessible concepts using powerful abstractions, while tremendous work goes on behind the scenes that we never even need to think about. Alfred North Whitehead put it best in his Introduction to Mathematics : It is a profoundly erroneous truism, repeated by all copy-books and by eminent people when they are making speeches, that we should cultivate the habit of thinking of what we are doing. The precise opposite is the case. Civilisation advances by extending the number of operations we can perform without thinking about them. Hadoop is one important step in this evolution: a tool for making formerly daunting work possible.", "date": "2009-10-03"},
{"website": "Hubspot", "title": "How to Set the Analytical Foundations for the Future of Your App", "author": ["Magdalena Georgieva (She/Her)"], "link": "https://product.hubspot.com/blog/how-to-set-the-analytical-foundations-for-the-future-of-your-app", "abstract": "Do you know if people are using your product the way they say they do? Especially at scale, customer interviews and usability tests aren't enough to answer this question. You need to see what happens in reality, which should be well reflected in your usage numbers. Whether you are building a tool from scratch or have been focused on a mature product, you should have the analytical foundations to uncover problems through data. Plan for the future by anticipating the questions that will keep you up at night when usage decreases, customers churn, or NPS is low. We talked to our own growth & analytics manager, Daniel Wolchonok , and asked him to for some tips on digging deeper to the root cause of user behavior. 1. Are your usage tracking events instrumented properly? Ensure that your team is tracking the important stuff. This step is easy if you are starting a product from scratch because you will need to track most things. If you have been working on an existing product, make a list of the actions that should be tracked, check if they are, and ensure their names are consistent and discoverable. Tracking key components correctly will help you build the foundations of the AARRR framework (acquisition, activation, retention, referral, revenue). No matter how you are keeping track of events, an audit of what you currently have and what you wish you had is a good idea. Consider grouping specific events into classes - for example, a \"view\" class can reflect landing on various pages and a \"usage\" class can include creation, deletion, copying, and other actions. Here is an example of how you can structure that audit: Tools like Mixpanel and Amplitude can help you identify the best way to fire an event, pass it over, and access your data on an ongoing basis. Regardless of the tool you decide to use, ensure it's easy to see your data and ask questions of it. A few years ago, all of HubSpot's usage tracking was done by making SQL queries, and it took our product managers much longer than necessary to answer simple questions and uncover insights. The more difficult accessing data is, the less you will do it. In addition to the actual usage events, think of what data you will need in order to segment stuff in the future. Nothing is more frustrating than to forget these attributes, see a problem, and not be able to dig into which users have the issue. The channel from which a user came from (social, paid, referral, search engine, etc.), what type of product they signed up for, and if they are a trial user are all examples of attributes you might be interested. Here at HubSpot, we often look at trial users separately from paying customers or we segment users based on whether they are engaging with our sales products or marketing products. Inevitably, the data looks different when you can break down your install base effectively. 2. How many people use your product weekly? Not all user actions are created equal, so you need to identify which ones actually mean usage (and not just clicks or views that don’t bring value to users but are necessary to get to the value). For example, leaving a comment on a blog post is a meaningful usage event, but collapsing the comment - not so much. Once you have identified these meaningful usage events, track the number of users who perform them on a weekly basis. Monitor your Weekly Active Users (WAUs) to see if this number is growing or decreasing and at what rate. Having such a graph will help you see changes that have happened and give you ideas about how you can affect change in the future. (When running this report, make sure you exclude any internal users.) Here is an example of what the line chart may look like: Even better, you can export this data and monitor the rate of growth of your WAUs and focus on that number. In the example below we see that there was a drastic increase in users into the 18th of July week (104%), but then we stayed flat for about week. You can use these changes in the WAU growth rate to confirm that something like a product marketing push or releasing a product to new users was as successful as you thought it should have been. This data shows the general usage volume of your app, but it's a pretty generic number. As Jonathan Hsu, the Head of Data Science at Social Capital explains , such number needs to be further broken down into brand new users, retained users from previous weeks, and resurrected users. For example, if we were to take the chart above, 804 people used the tool in the week of August 8th and 878 used it the week after. So there was a 9.2% growth there, but we can’t be sure what the attrition rate was. Maybe only half of the 804 users came back the following week and we got half as many brand new users. This would be a bad drop-off rate and indicate that the tools aren't truly valuable on the long run. That’s when you need to look at a retention report and what different levels of growth mean . 3. How many people are coming back to your app? Even if you have a good handle on your WAU growth, you need to know if the same people are getting value from your product or if they actually churn pretty quickly. When do they drop off? Is it a natural drop-off as a result of people who decide the product isn't for them or go out of business, or can you improve the usability of your app to make the experience delightful in the long run? A retention chart shows you different cohorts of users and how many of them come back to perform a specific action (or just use the product) again and again. In order to build a retention report, you need to have some event that represents a cohort. Otherwise, it’s hard to truly have actionable cohort data that you can track over time. Signup isn’t a great identifier for a cohort since many of your signed-up users won’t activate. Prioritize putting in an activation event so you can do retention off of it. Here is an example of what a retention report may look like: There are three directional ways to read the chart. You can read it horizontally and you will see that ten groups of users started using a tool in 10 consecutive weeks. Of the first group, the one with 97 users in its cohort, 47% of users returned to use the product again the following week. In the third week, 41% of them, and so on. So looking at it horizontally, you recognize the opportunity to grow the number as much as possible or at least keep it flat. Another way to look at the chart is vertically . That will show you trends of how you’re doing at a point in the lifecycle of a cohort. Even if you increase the number of users in the cohort, like the chart is showing for the following weeks, the retention in the second week should keep growing. If you changed your onboarding, you'd expect increased retention in the first week(s) as people understand your product more. A third way to read the graph is diagonally . This way you’ll notice things that are points in time - holidays, maybe a campaign to win users back, an email blast, etc. In this specific case, we are going to focus reading the chart horizontally because that drop-off over time is worrisome. In week eight, only about 20% of the users who started using the tool stuck around, so we need to understand why the drop-off is occurring and what can reinforce the long-term value. Of course, we if grow the numbers from week one to week two we will also see a huge spike in usage throughout the user's journey with this tool, but if eventually the long-term value is missing, they will abandon the ship. 4. What are your most and least popular events? You should know what folks are doing the most in your app and what they are doing least. Not all events are created equal, so it may be absolutely fine that one event is triggered by 100 users and another by 1000. Understanding common and uncommon events can help inform product decisions in the future such as designing a great onboarding experience. Often times, you may be surprised to find a specific event getting more traction than you thought it would or the reverse. You can visualize this in different ways, but I use a line chart over time like this: The surprising bit about this specific graph is how popular the action of searching in a list is. Surprises like this reveal opportunities: given that searching is more popular than anticipated, would it maybe make sense to invest in making it easier? 5. Do you have funnel reports for common user flows? By now you probably have some solid expectations of how users interact with your app. For example, we knew that our users often need to search for specific contacts in a list in order to double check their logic, troubleshoot, and narrow down criteria. Knowing from the graph above how popular that action was, we assumed we'll see the same trend on our main page of all contacts where we offered an advanced search option. Yet we found that wasn't actually what was happening. We already had a hunch around the difficulty to search on that particular page, but were able to validate that hypothesis by looking at a funnel of events. The example below shows that less than 1% of the users who landed on our contact page were performing an advanced search. Our guess here was that users would derive value from this action but it wasn't easily discoverable due to the way we presented it in the interface. That was also the sentiment a lot of internal folks expressed and was reflected in support cases. So we dug into a redesign to tackle this problem as well as a few others and ended up with this version of the page: After the redesign, search was exposed a lot more, resulting in over 10% of users performing a search on the same page. This is a very tangible way in which funnels can help you see whether usage data confirms your expectations and what users are saying, or contradicts them. Another way that you can double-check if the usage data matches your expectations is by seeing what activities your most engaged users are performing. Our advice here is to create a trend report of weekly events, break them down by user, and sort by whom performed the most events. Once you find these users you can also use this group for user testing or customer interviews to identify an \"Aha! moment\" and design around achieving that sooner. We cover this approach in a lot of detail in this post . Start with these five components to build the analytical foundation for the future of your app. They will support you in making a lot of decisions and staying on the path of increased usage and success. Let us know how it goes and what you find.", "date": "2016-09-27"},
{"website": "Hubspot", "title": "Charting a Steady Course: A Framework for Building a Secure, Reliable, Consumer-Grade Product", "author": ["Marcy Kenney (She/Her)"], "link": "https://product.hubspot.com/blog/mainsail-framework", "abstract": "Infrastructure upgrades, improving user flows, a backlog of support issues, bugs, security work, improving latency, refactoring old code, building new features. If you’ve ever worked on a Product team, I’m sure you’re very familiar with this list. And I’m sure you’ve asked yourself, “How do I prioritize all of these things I care deeply about?” At HubSpot, we face the same problem. We are made up of over 140 small, autonomous product teams comprised of engineers, product managers, designers, researchers, and more. These teams are constantly asking themselves, their managers, and leadership how they’re supposed to decide which item on a very long list is most important to tackle first. And when there's always a desire to release new features, how do you justify spending weeks on your support backlog? The good news is that we, as humans, are no strangers to complex prioritization. We make value decisions about how to prioritize some actions over others every day, often unconsciously. We don’t look for healthier foods if we’re still struggling to find shelter, for example. Just as we can relatively easily see where we stand along a spectrum of wants and needs, so too can we identify at what level our product needs our attention. Enter: the Mainsail (We love nautical references here at HubSpot. This is only one of many.) If you’ve studied basic psychology the graphic above should look familiar to you. Based on Maslow’s Hierarchy of Needs , we’ve created Mainsail to help everyone in Product, Engineering and UX understand and prioritize all of our customers’ needs while maintaining the autonomy that makes up the DNA of our Product and Engineering organization. The seven levels of the Mainsail are split into two sections: Guardrails and Goals. The Guardrails are each tied to a metric (or metrics) with an explicit SLA (service-level agreement) that Product teams can track to assess their health: Security, Privacy and Compliance: Security tickets (e.g. security, compliance and privacy-related tasks that address major risks to our customers) Infrastructure: Infrastructure tickets (e.g. issues related to critical infrastructure upgrades or migrations) Reliability: Support tickets, incident follow ups, service availability SLAs (e.g. failure rate) Performance: Service latency SLAs (e.g. response time, or time until successful page load) Usability: UX tickets (e.g. usability/interface issue data from all data sources, including but not limited to: customer research, NPS, support tickets, the Ideas Forum, etc. categorized by severity (how bad is it?) and reach (how many people does it impact?)) The Goals levels on the Mainsail typically relate to new features, though sometimes new features can be the solution to a Guardrail level. The metrics for Goals vary by team, though we are working on standardizing these over the next year as well. Some examples of Goals metrics include: Value: Signups, activation, usage data Growth: Signup and retention data The idea is to move “up” the mainsail, starting with Security, by getting each level healthy before focusing on the next level up. Your Guardrails must be healthy before working on Goals (or you at least need to have a very good plan for how you’ll achieve your Guardrail SLAs while also working on Goals). For example, say you’re a product team working on a new feature that adds functionality to a report with the goal of having it in beta by next quarter. This work likely falls into the Value level. If a high-risk security issue comes up, the team can use the Mainsail to prioritize the work in the Security level over the new functionality they have planned. Sometimes this looks like pausing work on the new functionality completely, and sometimes it looks like taking one engineer off of the feature work and dedicating their time to fixing the Security issue. Another great example comes from migrating or deprecating internal infrastructure. It’s hard to complete major, cross-organization migrations when you’re working with 140 autonomous teams. Oftentime the team that owns common infrastructure might not feel they have the influence to have their work adopted by all teams, resulting in long periods of time where they could have to support multiple solutions or potentially forgoing a migration entirely. That could either mean increased complexity and support burden, or complacency with what exists today. The Mainsail helps in both of these cases by giving teams a mechanism to prioritize the most critical infrastructure work across all teams. We track our Mainsail data in a single dashboard that is accessible to the entire organization, but beyond this guidance, we leave it up to each team to decide how to tackle these items and trust that they know what’s best for their customers. Implementing the Mainsail has been possible at HubSpot solely due to our culture and values . Like any change, it hasn’t been easy. Having a clear, simple process that was created (and improved upon) by listening to feedback from our teams was key, as was always keeping the customer at the forefront of every discussion. At the end of the day, Mainsail has given our teams a shared language for how to prioritize the multitude of inputs and requests on their plates while maintaining autonomy. It’s our mission to help millions of organizations grow better, and we believe that giving them secure, reliable, performant and usable software will help do just that.", "date": "2019-12-18"},
{"website": "Hubspot", "title": "Name Dropping: Taylor Poindexter, Senior Software Engineer, tech co.", "author": ["Francesca McCaffrey (She/Her)"], "link": "https://product.hubspot.com/blog/name-dropping-taylor-poindexter", "abstract": "Name Dropping is a Q&A series that aims to elevate the stories of women and nonbinary people leading in the tech space. The idea came from Angela DeFranco, a VP of Product at HubSpot, who said one way to be better allies is to name drop more women and nonbinary people in discussions of achievement, inspiration, and disruptors in tech, instead of referencing, time and again, the same set of (often male) leaders. This edition of Name Dropping features Taylor Poindexter , Senior Software Engineer at tech co. and Co-Founder of Black Code Collective . When did you realize you loved engineering? The crazy thing is that I didn’t fully fall in love with engineering until the last couple of years. During my second year of college, a family friend suggested that I take my first computer science class, and while I was originally reluctant, I gave in and agreed to take it. For the first time in my life, I struggled academically because it was so hard for me to change my way of thinking to fit how programming works. That first class kicked my butt, but I was intrigued and energized to conquer programming. Post-college, I struggled to gain confidence in the field and questioned if I should change fields altogether. But eventually I joined an amazing team, and it became clear that I wanted to continue to be an engineer. My team is composed of smart, yet kind, engineers who have helped me gain confidence in the skills I already had, as well as pick up new skills along the way. Over the past few years this confidence has fueled a new level of curiosity in engineering and has made me love the field more than I ever have. You’re a senior software engineer at tech co., a platform that strives to increase civic engagement through technology. What are some of the most exciting or challenging projects you’re working on right now? Working to fix democracy is a lofty goal (I know, shocker! Haha), but I’ve been enjoying thinking of ways we can make a more participatory democracy a reality and create a platform that users find intuitive and useful. I’m currently tech lead on a project that helps our users analyze their data sets and garner meaningful insights. It’s been exciting to learn about what data points are most useful to our clients, and brainstorm effective and efficient ways to complete this project. tech co. recognizes how blah the name is, but the name is merely a placeholder because we’re in “stealth mode.” While we’re in stealth mode we’re building the foundation of the platform that will be our future company. When the time is right, we’ll come out of stealth mode and reveal our full brand identity. You co-founded Black Code Collective in 2016. Can you tell readers about the organization, and any ways they could get involved or support the initiative? Myself and my co-founders started Black Code Collective after we became frustrated with being the only or one of only a few Black engineers at our jobs. The mission of BCC is to provide a safe space where Black engineers can collaborate on tech projects, grow their network, and feel at home. Being “the only” at your job can be incredibly isolating. Having a community of people who experience life in ways similar to you can be a way for you to recharge. If folks are interested in learning more, I’d suggest they check out https://blackcodecollective.com/ . There they can find ways to join our Slack, donate, become a sponsor, or read our recently published Black Tech Workers’ Manifesto . What advice do you have for women and nonbinary people pursuing STEM car eers? Strive to only work in places where you have psychological safety, and don’t let other folks in the industry chip away at your confidence. I struggled to gain traction in the beginning of my career, and now I realize the reason for that was a lack of confidence. STEM is a male-dominated industry (though this is shifting for the better), and folks won’t always treat you with respect if you don’t fit the mold of what they think an engineer should look like. But that’s their problem, not yours. Don’t let them make you doubt yourself. Never work at a place where you don’t have psychological safety ⁠— it will only stunt your growth. And remember that everyone was a beginner at some point in time. What book do you think every engineer should read and why? The Pragmatic Programmer . It’s a very popular book, and for good reason. It will change the way you attack problems and make you a more efficient programmer overall. What is one quality that you think every leader should have in order to generate impact, and lead effectively? Selflessness. A lot of people think that leadership is about doling out tasks, and while delegation is important, it’s only one piece of it. In my experience, leaders who are selfless are the most effective. They realize that the work/mission is bigger than themselves, and focus on empowering and uplifting their team instead of serving as an overlord in control of their worker bees. Who’s one woman or nonbinary person in technology you’d like to name drop and why? Please forgive me, I couldn’t pick just one. The first woman I’d like to name drop is Georgette Kiser . She started off as a Software Engineer, and until recently, she was the CIO of the global investment firm The Carlyle Group, helping to advise them on technical strategies. The second is LaBrina Loving . She’s a Senior Cloud Architect for Microsoft, and she works with Microsoft’s partners to help them figure out how to migrate and build solutions on the cloud. What’s your go-to song to get yourself pumped up before a big presentation or event? It very much depends on my mood, but it’s usually between Travis Scott’s “Highest in the Room” and Kings of Leon’s “Sex on Fire” (yes, I acknowledge this is a weird title for a pump up song lol, but how could you not get pumped listening to those guitar riffs?!) Know another woman whose name we should drop? Tweet us at @HubSpotDev with ideas. This article originally appeared on Medium .", "date": "2020-07-02"},
{"website": "Hubspot", "title": "Why I’m Excited To Join HubSpot", "author": ["Eric Richard (He/Him)"], "link": "https://product.hubspot.com/blog/why-im-excited-to-join-hubspot", "abstract": "Over my last 20 years in the Boston high-tech industry, what has kept me excited and gets me out of bed in the morning is the opportunity to join, lead, and transform high-performing teams. I’ve played a wide variety of roles ranging from founder to CTO to Chief Architect to VP of Engineering at some really amazing companies including NetGenesis, SPSS, Idiom, and most recently, Compete, and each of them has come with some incredible rewards and learning experiences. For the next step in my career, I wanted a role that would challenge me to leverage all of those insights (and bruises) to contribute to a once in a generation company. For this reason, I’m ecstatic to announce that I’m joining HubSpot as a VP of Engineering, and I couldn’t be more excited for my next chapter. But enough about me, let me tell you why I’m excited to be part of the HubSpot team: 1) Their unabashed, aggressive plans for world domination: Back in the late 90’s, I had the opportunity to work with companies like Netscape.  When you walked into their offices, you could sense electricity in the air. They were growing at a frenetic pace and opportunities for greatness abounded. Their biggest challenges had to do with how to manage through this growth and stay on target.  Walking into HubSpot you get the same feel. Their ambition is inspiring and they have no interest in hitting modest goals -- they are shooting for the moon. They are one of those companies that comes along in a blue moon where you say, “They are really special and I want to be a part of that.” 2) Their remarkable culture and team : I have long been a fan of the Silicon Valley books talking about amazing companies doing amazing things on the West Coast. Development teams who are performing high wire acts, innovating and pushing the edge of technology. About companies like Zappos who build their company with culture front and center. It is great to see a Boston-based company blazing these same paths. A development team who has taken continuous deployment and agile development to their extremes. A company who has literally written The Culture Book. 3) The transformative nature of their product: HubSpot is out to change the world -- both for marketers and for consumers. Moving from the adversarial relationship with marketers trying to figure out how to get their message in front of consumers who aren’t interested to a world in which marketers succeed by creating content that consumers want. Being a part of building a platform that empowers businesses to grow by earning the attention of their prospects and leads versus renting it is compelling to me. The HubSpot team helps companies create marketing people love, but they’ve also developed an integrated platform that is legitimately easy to use without sacrificing power. 4) Global growth: One of my favorite times in any company’s growing process is moving from being a U.S.-centric company to being a truly global company. The issues that a company has to tackle to become global are challenging, and exciting, and HubSpot is already heading down this path.  HubSpot has 10,000 customers worldwide, and that number continues to grow each day. The company not only has talented engineers in Boston, but in Dublin as well. Creating a development organization and a platform that scale to the needs of a global customer base is imperative to HubSpot’s success, and it’s something I’m excited to contribute to and be a part of. If you’re looking for me over the next several months, you’ll likely find me at 25 First Street getting to know our team and rolling my sleeves up to get to work. I know the sweat equity, time, and energy it will take to achieve the lofty goals our team has set for the months and years ahead, and I’m excited to get started. If you’re interested in joining our team too for the reasons above (or any of your own), we’re hiring .", "date": "2013-12-13"},
{"website": "Hubspot", "title": "Customer-Driven Product Development: How Signals Handles Customer Support", "author": ["Matt Bilotti"], "link": "https://product.hubspot.com/blog/customer-driven-product-development-part-1-how-signals-handles-customer-support", "abstract": "As the Signals team works toward an increasingly tighter product-market fit, we've taken a somewhat different approach when it comes to support. Operating at a low .01 tickets per user, we’ve used customer-driven product development in the early stages of Signals. While the fundamentals of this approach aren't radically new, it does speak to how you can create a beautiful product experience, faster, by keeping your entire team plugged in with your customers. On the Signals team, Uservoice is our current support platform of choice. It serves the purpose of three key features of customer-driven product development. Uservoice allows us to: Triage tickets easily tickets through custom rules and assignment properties Host all of our help documents in an accessible format Host a feedback forum to allow for more direct and freeform user feedback How Signals Handles Support Everyone answers tickets - Every single engineer on the team is set up with a Uservoice account. Depending on which part of the product each engineer owns, they have specific categories of tickets that are automatically assigned to them. This keeps every engineer deeply connected to the customers that are the heaviest users of their piece of the product. Screensharing is caring - If a ticket is filled where we can’t quickly figure out what the issue is, we ask the customer for 10-15 minutes of their time in order to look at their screen to either: A) Collect all of the technical information necessary to debug or B) Solve what’s wrong with the customer’s computer. Write a help document for anything we hear more than a few times - Large-scale support teams with help lines are a thing of the past for touchless-sale tech products. In order to scale our support processes, we need to provide our users with the tools they need to solve their own problems. Diligently maintain the knowledge base / help article database - While we’re constantly shipping code, we still need to make sure that we're shipping just as much content on the support side. This means keeping on top of images, videos, and the language we use in our help articles. The clearer our help articles are, the fewer support tickets we’ll receive. File Github tickets immediately - While we don't necessarily need to address them right away in the roadmap, we still need to keep track of all of the bugs in our backlog and link them to the direct ticket that the user submitted. We use a Github label “Product Quality - High Priority” for any bug or issue that is affecting more than a few percentage points of our userbase. Incentives Make It Easy Engineers tend to enjoy shipping code more than they do answering support tickets, so adding in a layer of incentives is vital to this process. And here's where another great feature of Uservoice comes in: The leaderboard, where team members are awarded points for answering tickets in a timely manner and with thoughtful responses. This has created a bit of an internal competition within the engineering team, as team members are constantly dropping the leaderboard in our shared HipChat room to show off their position on the leaderboard. This leaderboard has even motivated some team members to drop what they’re doing, go into Uservoice, and get back to a user as quickly as they can. Hey, whatever works. If you’re not on Uservoice, you might want to find a way to generate this competitive spirit by pulling stats on who is answering the most tickets and at what speed and share it with the team. How to Get Started Choose a team member who will \"own\" the higher-level processes around customer support. Ideally this would be somebody in a Product Management role, or even a C-level or founder if your team is still small. Have them spin up a Uservoice account and get a few team members signed up. The idea here is to begin funneling all user feedback and support into one repository and get your engineers at least one step closer to the user.", "date": "2014-04-01"},
{"website": "Hubspot", "title": "Sunshine is the Best Disinfectant, or Why it is Important to Have a Burrito of Tears", "author": ["Dan Abdinoor"], "link": "https://product.hubspot.com/blog/bid/75629/sunshine-is-the-best-disinfectant-or-why-it-is-important-to-have-a-burrito-of-tears", "abstract": "October marks the 40th month that we have been practicing Scrum at HubSpot. Obviously we have learned a lot of lessons over that time. But one of the best things we have learned is how to do the basic things right. One example is the sprint retrospective meeting which at first was an awkward, confrontational, waste of time. Here is the definition of the retrospective from Scrum Alliance : The sprint retrospective meeting is held at the end of every sprint after the sprint review meeting. The team and ScrumMaster meet to discuss what went well and what to improve in the next sprint. The product owner does not attend this meeting. The sprint retrospective should be time-boxed to three hours. That description is nearly useless. And a time-box of three hours? Who has three hours for these meetings? But sure enough, sprint after sprint, we found ourselves in a room asking everyone to reflect on the past sprint. It was an awkward meeting filled with questions like \"How did you feel about the stories?\" and \"Why were your tasks not estimated accurately?\" One team at HubSpot started to call this meeting the \"Burrito of Tears\" because it was not fun, and because they held it during lunch at the nearby Boca Grande . Eventually the purpose of this meeting became clear: to shine some sunlight on the past sprint. We needed to get together and be totally open and honest. So we started to discuss why some things did not meet our expecations. Did we get slammed by bugs? Did we screw up in our initial tasking and miss an important part of the solution? What could we change so that we do not have this problem again? The sprint retrospective can feel like a 5 Whys . When we identify something that is not perfect we dig down until we find a systematic issue. Usually it is something in the way that we practice Scrum, and we change it. Over time we got our practice finely tuned. There are still surprises but we learn from them. The retrospective also helps us to identify the things that went well so we can try to repeat them in future sprints. Some positive things we have discovered: We were able to get more done by dividing into teams building/consuming an API. We had better testing by identifying the use cases upfront. We like having our standup right before lunchtime so we do not have to break our concentration twice. Finding the things that went well is just as important to having succesful future sprints as preventing the things that did not go well. Not to mention, morale gets a nice boost when you end the retrospective discussing what went well for the team. The retrospective is about the process more than the people. It does not have to be a confrontational blame-throwing meeting. It can be both enlightening and productive. And it does not take anywhere near three hours! Have you found helpful ways to make Scrum work better for your team?", "date": "2011-10-07"},
{"website": "Hubspot", "title": "What We've Learned About Interviewing Engineers", "author": ["Zack Bloom"], "link": "https://product.hubspot.com/blog/interview-loop", "abstract": "At HubSpot, we have grown from one to 75 developers in a few short years. This is what we've learned. Why Interview There is no one brilliant solution to the interviewing problem. Deciding if someone should spend 40+ hours a week with you for the next several years is a very hard question to answer based on a couple hours of contact. The one tried-and-true method we have is the interview. Interviewing is based more on tradition and \"doing what the guy who interviewed you did,\" than hard science. With rare exception, it's impossible to tell if you are hiring the best candidates, or missing some of the best. Each company has their own formula, and even the worst systems (looking at you 90s era Microsoft) are allowed to persist for decades. There is no one brilliant solution to the interviewing problem. Evaluating the developers you have hired is an unsolved problem, much less trying to evaluate everyone you don't hire. It's best to avoid the \"clever\" solutions and stick with a simple formula. The Interview Loop An interview is an opportunity for the candidate to expose to you their abilities. You only have an hour, the amount of information gained per minute is worth trying to optimize. Try keeping this model in your head during the interview: Think \"What more do I need to know to make a decision?\" Ask a question Listen to the answer Repeat until you have no big unknowns about their ability or fit An interview is an opportunity for the candidate to expose to you their abilities. You have to get off of topics quickly when you have hit their limit, to give them a chance to demonstrate all of the skills they do have. Your Purpose One of the more terrifying moments of a young developer's career is the day they are conducting their first interview, and their mind blanks looking for a question to ask. Nothing makes a company look like more of a joke than an interviewer failing at their own interview. Let's start by defining our purpose: Decide if the candidate should work at your company. Make the candidate want to work at your company. You should try to make every question and statement work to accomplish one of those goals. Deciding Before the Interview The test saves us a week of developer time for each candidate we end up hiring. Each stage of the interview process costs proportionally more in developer time. Most interview processes follow a funnel, where each step winnows out as many candidates for as little investment of time and money as is possible. So lets create a semi-realistic example of a hiring funnel: Review Resume / Web Presence - 100% of applicants - 15 minutes Phone Screen - 50% of applicants - 1 hour In Person Interviews - 10% of applicants - 6 hours Offer - 2.5% of applicants Acceptance - 1% of applicants With these ratios about 135 developer hours, three weeks of full time work, goes into finding a single employee. At HubSpot we have started to use a programming test web app which asks candidates to spend a few hours solving problems and writing code. The test saves us a week of developer time (using the figurative example above) for each candidate we end up hiring. Anything you can do to make the early steps filter out more unsuitable candidates will help your efficiency. Getting candidates to write code in your phone screen (particularly with a tool that lets you execute it live like CoderPad ) is going to help filter out those people who won't pass an in person interview. If the candidate is not actively looking for a new job, you may have to play it slow. Ask them to dinner, to come in just to chat, or meet up with them at an event. Parts of an Interview The basic components of an interview: Small talk to make the candidate comfortable Technical questions where they write code Behavioral questions where they talk about past projects Answer any questions and sell the job Small Talk Not every technical candidate is going to be Stephen Fry. An interview is uncomfortable. How the candidate feels in the interview though will determine what they think about your organization. They aren't going to want to work with people who made them feel nervous and uncomfortable. Keep it personal, and talk about what you do specifically, rather than talking in the abstract. To make it not feel like an inquisition, to share as much about yourself as you ask about them. Don't read the conversation like a script, talk like you would over beers, leaving room for the candidate to enter the conversation as you go. Frankly, not every technical candidate is going to be Stephen Fry. Some people, even more so technical people, are naturally awkward around people they don't know well. If they aren't comfortable answering questions in the abstract (\"what do you like to do for fun\"), ask concrete questions (\"have you ever been sailing\"). The more factual the question, the easier it is to answer for someone who is nervous. Of course, if you truly can't have a conversation with the canidate, he or she may not be a great culture fit for your organization. Sample Script Intro \"Hi, my name is Zack Bloom, I'm the frontend tech lead on the contacts team. Contacts is one of the six major \"apps\" that form HubSpot. Do you know much about HubSpot?\" What We Do \"HubSpot is like Google Apps for marketing and sales. Each developer has ownership over some parts of the product or infrastructure. For example, I'm responsible for the frontend of the contacts database and all the tools people use to find and understand the contacts they're marketing and selling to. It, like most of our apps, is built in CoffeeScript as Backbone app serving data from the Java APIs that our backend developers build.\" Small Talk Prompts \"I tried Kite Surfing for the first time this weekend, it was really cool. Have you ever tried any sports on the water?\" \"I'm really into Starcraft 2 right now, are you playing any video games right now?\" \"Is this your first time in Boston? I remember when I first moved I couldn't navigate two blocks without getting lost. Have you gotten lost yet?\" Technical Questions The purpose of the interview is to get an accurate opinion of the candidate at whatever skill level they have, not demonstrate your superiority. Virtually any technical interview should include some amount of code writing. You can't become good at calculus unless you know algebra front to back, similarly, we expect that if you can't answer basic questions very quickly, you are very likely not a stellar programmer. This is not a perfect test, some organizations have had a lot of success with take-home projects or using short-term contract work to evaluate candidates before making a final decision. Our attitude is that we are hiring engineers who will be solving problems, not scientists who will be theorizing about them, so we avoid overly theoretical or 'word puzzle' type questions. The goal should always be to evaluate the candidate on topics which are as close to what will be required of them as is possible. Your feedback during the questions is important as well. If the candidate sees you shaking your head, getting exasperated or getting up and writing a different solution on the board yourself, they are going to be discouraged at best, hate you at worst. The purpose of the interview is to get an accurate opinion of the candidate at whatever skill level they have, not demonstrate your superiority. If you feel like your time was wasted, that's something to take up with the person who did the phone screen or reviewed the resume, not with the candidate who's just trying to do his or her best. Question Examples Knowledge Based A developer is not proficient unless they have grasped some basic concepts in his or her language of choice. The difficulty of these questions is set based on how strong the candidate claims to be, but every candidate with some amount of experience should be very skilled in at least one language. \"Do you know what the GIL is in Python? In what way does it limit what Python can do?\" \"Can you explain how scoping works in JavaScript? How does this work?\" \"What's the difference between a div and a span?\" Coding These questions are essentially to winnow out canidates who can't write code. They also provide great launching points to enter into more in depth discussions. Here's an example of how that might go (in an abbreviated way): \"How would you find the first duplicate string in a list\" \"I'll sort it, and then scan through.\" \"Great, what would the efficiency of that be?\" \"Hmmm... O(n log n) for the sort + O(n) for the scan\" \"Can you do it faster?\" \"I could keep track of all the strings I'd seen, maybe using a hashtable?\" \"Great, can you write that up in whatever language you're comfortable with?\" Writes the code, with some back and forth to fix issues \"What's the efficiency of that?\" \"O(n), but it really depends the hash function and what happens with collisions\" \"What if you had 100 TB of data and a hundred servers?\" A great candidate might start talking about Bloom filters, what map/reduce steps might work, or what the minimum amount of data you would need to send over the wire might be. Experience Questions You can't trust a resume. People become great engineers by engineering lots of things. These questions center around real or hypothetical \"big projects\" in the candidates past or invented by the interviewer. They help us to confirm what real experience the candidate has (you can't trust a resume), and allow the candidate to demonstrate how they approach problems. \"Do you know what reddit is? How would you go about building it? How would you support merging a bunch of subreddits together to form a user's homepage? How would pagination work?\" \"How would you build YouTube? How would the video be ingested? What are the biggest scaling issues? Would you treat videos that get millions of views differently than ones which only get a few?\" \"Looking at your resume, I see you built a missile defense system to protect us from alien invasion. What parts were you responsible for? How did the system work? So aliens are real?\" Selling The six hours the candidate spends with the interviewers is likely the only real contact they will ever have with the company before making a decision. It doesn't matter if your interviewing process is perfect, if no one accepts your offers. In too many companies the interviewers are seen as just evaluators, with no responsibility to educate the candidate about the company. The six hours the candidate spends with the interviewers is likely the only real contact they will ever have with the company before making a decision. Many engineers see selling as a duplicitous process dominated by men with bad mustaches and worse morals. But, assuming that your company is actually a place worth working at, selling is just education. It's teaching the candidate about what it's like to work with you, how it's better than their other options and why they should take the job. If you can't make a convincing argument to that effect, you shouldn't be interviewing (and you might want to look into getting a different job yourself). Selling Guidelines Be somebody someone would want to work with Educate the candidate on why working at your company is better than working elsewhere Being Nice If someone had told you that you were an idiot back then, do you think you would be working with them today? When you are doing an interview, you are the companies representative. If they hate you, they will hate the company. You don't necessarily represent all of the company, so it's alright to tune your energy level and behavior to match that of the candidate within reason, but the most important thing is to be honest. It's not worth lying. The one thing worse than not hiring a candidate is having to fire someone, or having them quit. They will cost you more on the way out than they did coming in. That being said, it is your place to paint the best, but accurate, picture of your company that you can. Be excited about the vision of both the organization and the dev team, and try to get the candidate excited about that vision. Share the great things you've done, and plan to do. If you haven't done much yet, talk about what great things you want to do, or would do if you had the resources. It should go without saying, but treat the candidate with respect. Be punctual and respectful. Don't check your email during the interview. You may do a dozen interviews a week, but for them it represents a pivotal moment in their life. Remember when you were interviewing for your first job; how nervous you were. Give positive, but truthful, feedback, even if they aren't stellar yet. An example might be: \"I really appreciate how focused you were during the interview.I know how motivated you are, and we all have been at your experience level at one point, but we just don't have the mentorship resources right now to take you on right now.Keep working on projects and developing your skills, and we'd love to talk to you again in six months.\" We were all at the point in our career when we thought global variables were a fine idea and the hardest problem we would ever have is implementing quick sort. If someone had told you that you were an idiot back then, do you think you would be working with them today? Sometimes you can take a candidate with less experience, it they're smart enough and you have the resources to work with them, sometimes you can't, but either way, be honest so they can move on to the next phase of their career. Closing You need to listen before you can talk. Selling comes down to convincing them that the job you're offering is better than other jobs they may have on the table. The variables you can play with are the enjoyment and challenge of the work, the quality of the coworkers, the prestige of the company and the salary/benefits. The points you choose to extenuate depend on the audience and what they tell you. If they tell you they use subversion, talk about how you use git. If they don't get much freedom in their job, talk about how much autonomy your position offers. You need to listen before you can talk. Before you can convince them of anything though, they need to trust you. They need to believe that what you're telling them is the truth. The best way to do this is to actually have a genuine relationship with the person. If you are active in the community and put in the effort to maintain connections with fellow devs you meet, you will have a network which allows you to potentially hire them, and other people they may know. If you don't have the luxury of a long term relationship, build a rapport as quickly as you can, speak plainly and don't sell too hard, just talk about the company as you would with a friend. RFC Please share your interviewing tips in the comments below, on Hacker News, or tweet us @HubSpotDev . You should follow us as well.", "date": "2013-09-04"},
{"website": "Hubspot", "title": "A Product Designer's Playbook for Working with Engineers", "author": ["Gabriela Lanza"], "link": "https://product.hubspot.com/blog/a-product-designers-playbook-for-working-with-engineers", "abstract": "I’m a product designer. I spend my days working with a handful of product managers, a troop of engineers, a pack of other designers, and occasionally a few other types of people (like user researchers and product experts.) One of the most crucial things I’ve had to get the hang of over the past (almost) year at HubSpot is how to communicate with all of these different people. As designers, communication is sort of our thing--at its core, design itself is communication . The interfaces, systems, and interactions we create tell our users what they’re seeing, what they can do with that information, and why it matters to them. But sometimes, this knack for communicating doesn’t carry over to our day-to-day interactions, making it harder to collaborate with our teams and deliver good design. One of the most critical (and sometimes the most challenging) types of communication in this realm is between designers and engineers. When it works, it’s like magic. But when there’s a disconnect, it takes longer to ship products and those products usually aren’t as good as they could have been. I was an engineer at HubSpot before becoming a designer, so I have the advantage of understanding both workflows when trying to find the best ways for design and development to collaborate. Define the Design Vision Offline Right now, I work with about 10 front-end engineers and while the bulk of our communication happens in GitHub , the first step of any new project usually happens offline. Syncing up with developers face-to-face early on makes it easier to get everyone on the same page and bought in on the design direction. I’ll first sit down with the tech lead for the products I’m working on to talk through the problem that needs solving and any constraints (technical, time, etc.) we have. This initial conversation gives me the context I need to start working on a solution. Once the design is ready, it’s time to sit down with the engineer that’s going to bring it to life. I’ll walk her through the decisions and if necessary, explain what should happen in certain edge cases and the interactions between states (these things can be hard to convey in a static mockup.) One thing I’ve learned to over-communicate in these meetings is how final the designs are. Being explicit about whether I’m still toying with a solution or if it’s ready to go can save the team a lot of headaches down the line. No engineer wants to think her work is done only to find out that the designs have changed and she’ll have to go back and redo part of it. And the corollary is true: no designer wants to see a final product that's changed drastically from her designs. Of course, sometimes the design does need to change. Maybe user or beta testing shows that our users are having trouble with a feature and we need to smooth some of the rough edges. Or maybe the technical framework we use won’t let us make the right custom UI element and we have to find a different element that works. These things are going to happen so it’s important that designers can admit when their vision is wrong, and be willing to change it. That’s another reason good communication is important; iterating is so much more productive when teams can work together to pivot. Stay On Top of the Process in GitHub Once we’ve gone over the design together, the engineers go off and work their magic. (Of course, I’m always available for quick clarifications or to answer any questions they have along the way.) When the work is in a good place, engineers will usually submit something called a pull request in GitHub. These pull requests let engineers review each others’ code before it’s shipped, but they also give me a chance to give things a once-over before our users see them. I set aside time in my day to respond to these threads and give feedback, so that things can keep moving and design doesn’t become a road block. Getting into GitHub means I can make provide feedback on any changes while they’re still top of mind for the engineers on my team, instead of after the code has been pushed to production. It also gives me control over the design process from start to finish. By reviewing every change, our users won’t see anything that doesn’t have my stamp of approval. In fact, I encourage my engineers to copy me on every UI change that goes out, no matter how small it is. This helps me keep on top of the state of the UI so that these small changes don’t start to pile up. I also heavily use GitHub’s issues feature. When I see something I didn’t expect in the UI, I’ll create an issue on Github, describe what’s not quite right, and provide screenshots of what it should look like. I’ll then assign the issue to the tech lead to either fix or assign to someone on our team to fix. I’ve found that this works much better than creating a card in Trello or messaging them on HipChat. Embedding myself into my engineers’ process on GitHub means my design feedback stays top of mind without disrupting their workflow. Own the Final Product Jonathan Meharry (a fellow product designer here at HubSpot) once said something that really struck a chord with me. He said we don't want to make products that just match our users’ expectations for how an enterprise app should look and feel. We want to make ones that can compete with intuitive consumer products they use every day, like Google, Twitter, and Facebook. Good communication is important to me because, at the end of the day, I can't reach that design standard unless I'm on the same page as my engineers. As Julie Zhuo, the director of product design at Facebook bluntly put it , “Own the product that goes out to users, not the mock on your computer.” I’m the person who ultimately owns the user interface and user experience of the products that I work on, products that our customers use every day to do their jobs. So while there are many reasons why a finished product might not look like my mock up, it’s my responsibility to spot those potholes, get into my engineers' workflows to avoid them, and ultimately, deliver good design.", "date": "2015-07-15"},
{"website": "Hubspot", "title": "List of startup-oriented events, meetups, and people in Boston", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/27175/list-of-startup-oriented-events-meetups-and-people-in-boston", "abstract": "A lot of people always ask us how we found out about HubSpot when it was a tiny, unknown startup.  We're still fairly small and that well-known, but this question keeps rising in frequency. Many of us found HubSpot through friends or through professional networking.  There are HubSpotters at many Boston-area startup-oriented events. Don Dodge compiled an excellent list of these events.  Check it out on his blog at http://dondodge.typepad.com/the_next_big_thing/2009/10/boston-startup-events-resources-people-you-need-to-know.html . Don is too humble to mention himself as a nice guy and a great connector.  If you see him, say hi ;)  He will always be happy to listen and possibly help you out. The other person I'd mention as a connector in this list is our co-founder, Dharmesh Shah .  He, too, is too humble to mention himself in any kind of list like this, so we have to do it for him. If you're looking to find a hot startup in Boston, join one, form one, or just network with other entrepreneurs, this is a great way.  Maybe the best way. Are there any events you like that are missing from this list?  The only one that came to my mind was the occasional co-working sessions and parties at BetaHouse .", "date": "2009-10-05"},
{"website": "Hubspot", "title": "Announcing Mixen", "author": ["Zack Bloom"], "link": "https://product.hubspot.com/blog/announcing-mixen", "abstract": "Mixen is a library that has, over the last few months, changed how we write CoffeeScript at HubSpot. Mixen allows you to mix classes together, even if they all implement the same method, to build a new class that has just the components you need.  It's made our code more testable, more maintainable, and it has made it much easier to develop new bits and pieces which might not be ready for universal consumption. At HubSpot we have a Mixin for Backbone.Model to use our API interface library.  If we mix it into a model, it knows how to talk to our APIs: class ContactModel extends Mixen(APIBinding, Backbone.Model) urlRoot: 'contacts/v1/contact' It's just like if you had made APIBinding extend Backbone.Model, but you define the relationship when you use them, not when you define them.  If we want the model to be cached, we can add the cachingMixin: Mixen(Cache, APIBinding, Backbone.Model) Both mixins can have a sync method without either being clobbered. It doesn't just call each copy of the sync method, it uses the super concept built into CoffeeScript (but works with JavaScript too).  This means you can have a mixin which will stop the sync: Mixen(Validate, Cache, APIBinding, Backbone.Model) That's it! No BaseModel full of a bunch of junk no one uses, use what you need, and each mixin is just a class.  Read our documentation for more, and send any useful Mixins you make our way!", "date": "2013-08-29"},
{"website": "Hubspot", "title": "AWIT Panel Video: Diverse Teams Win", "author": ["HubSpot Product Team"], "link": "https://product.hubspot.com/blog/video-diverse-teams-win", "abstract": "As your business seeks to reach a diverse audience and grow a broad customer base, you've probably heard that having diversity within your product teams is important. Why is that the case? How are product leaders building diverse teams in real life? What outcomes are they seeing? These questions and more are addressed in the following video, hosted by HubSpot for the 2020 Advancing Women in Tech Summit. Panelists include: Darling Jimenez, Leading Results (A HubSpot Solutions Partner) Jaya Kandaswamy, Capital One Loe Lee, HubSpot Maia Singletary, G2 The panel is moderated by former HubSpot Director of Product Design Lauren McKenzie. Interested in learning more about opportunities at HubSpot? Visit our product careers page to find out more .", "date": "2021-02-09"},
{"website": "Hubspot", "title": "How do designers fit into Scrum and the Agile development process?", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/12003/how-do-designers-fit-into-scrum-and-the-agile-development-process", "abstract": "Last month we hired a new user experience designer .  We're pyshced to have him on board, and he's already contributing tons of useful stuff in various areas: usability testing, visual design, user interviews, mockups, wireframes, and more. We use the Scrum framework for agile product development, as I've mentioned in the past.  It's a great framework that I love and that has yielded tremendous results for us. I'm curious how people combine designers, with their typical wish to have specs and user requirements known up front, so they can do mockups and such, with the small user stories that evolve throughout the sprint.  Often there is not as much time for user experience design or mockups. How do you handle this? I've been doing some reading on the topic.  So far I've found a couple of good resources on the topic. Twelve emerging best practices for adding UX work to Agile development is a fantastic article, over on AgileProductDesign.com.  Another good one is Agile Designer / Developer collaboration with Scrum , by Allen Manning. Do you knowany other good resources?  Have you run into trouble incorporating more design and user experience work into your agile process?", "date": "2009-07-27"},
{"website": "Hubspot", "title": "Java library versioning for code access", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/6007/java-library-versioning-for-code-access", "abstract": "Most code libraries have versions. Versioning is one of those generally Good Things. Yesterday @danmil and I were looking to see what specific Hadoop version was installed on a node in our EC2 cluster. While Java has several mechanisms to specify library versions in a declarative way, especially when packaging a JAR or using a system like Maven, it doesn't seem like there's a standard for querying said version in code. Hadoop has a command-line option to print out the version of the library.  There is a custom little Hadoop class, VersionInfo , with an annotation that specifies the version. This is not bad.  It's useful, and it works.  Except yesterday, it said the version was unknown ;) We eventually figured it out, we think, but the episode was interesting. Is there some standard way to find the version of a Java library you're using, at runtime, from code?  Maybe something JMX -related?  If not, what's the best system you've seen? Do other languages do better in this area?  What does Python or PHP do?  C#? I'm not talking about a way for a sys admin to click around or view file versions.  It's a way for one piece of code (maybe in the same JVM, in the Java case, but not necesssarily). http://dev.hubspot.com/bid/6007/Java-library-versioning-for-code-access", "date": "2009-06-26"},
{"website": "Hubspot", "title": "Planning a tech meetup? Here are some helpful tips", "author": ["Cian Mac Mahon (He/Him)"], "link": "https://product.hubspot.com/blog/helpful-tips-for-running-a-tech-meetup", "abstract": "ReactJS Dublin is a quarterly meetup that I, along with a few other dedicated HubSpotters, run. We’ve been running it for almost two years - since November of 2015. In that time it’s grown from roughly 30 attendees sitting in a rented hotel room to 150 React enthusiasts at our most recent meetup, which booked out in fewer than nine hours. We have over 1,200 ‘Reactors’ at the time of writing and we’ve hosted twenty talks. You could say that it’s going pretty well. Like any event of this size, we on the organisation team often find ourselves stressing out about the small details. Why hasn’t a speaker sent us her files yet? How do we handle people who turn up the day of without registering? And most important: Do we have enough pizza to go around? Over the last 6 gatherings, we’ve learned quite a lot about running a regular tech meetup, and we’ve developed some best practices for how to run our events as smoothly as possible. Roles on the ReactJS Dublin Committee While the ReactJS Dublin Team might seem a like small and steadfast group to the attendees of the event, in reality it’s quite large and constantly in flux. One month before an event, the three other core team members and I meet and dish out jobs and responsibilities amongst ourselves and whoever happens to be volunteering. The jobs include: Speaker Wrangler Speaker Wrangling is, without a doubt, the most stressful part of organising a meetup. A good Speaker Wrangler is able to track down a series of interesting speakers, get their commitment to speak on a certain date, and offer any coaching and advice needed in the run-up to the event. And a great Speaker Wrangler will do all of that without making the speakers feel, well, wrangled. On the night of the event, the Speaker Wrangler might need to chase down a speaker who hasn’t arrived on time, make sure that everybody’s laptop works with the our tech setup, and be the general point of contact for anybody who is speaking or is interested in speaking in the future. I have speaker-wrangled for two of our six meetups, and I’m still dealing with the night terrors. Facilities DRI Because ReactJS Dublin is sponsored by HubSpot, we’re pretty lucky to be able to use our office’s event space. We’ve got a great Facilities and IT team who make the job of the Facilities DRI relatively easy - but it isn’t without stress. We need to make sure that we have the event space booked as early as possible, and we like to follow up and confirm that we have the space at least once in the run-up to the meetup. Along with booking the location, the Facilities DRI is generally in charge of working with IT to get the event filmed. We've had almost every hiccup you could imagine with video recording and audio capture, but have settled on the surprisingly simple and reliable solution of just putting the presenter laptop on a video conference with the event space camera and recording it. That way, we get to record both the screens in the room and the presenter, ready to be posted on our YouTube channel . Perfect! The third job of the Facilities DRI is to organise food and drink for the event. Generally this means giving the heads up to either our favourite local pizza place ( Base Pizza , if you’re wondering) or our in-house caterers, as well as giving our facilities team a ballpark number of attendees so that they know how full they should stock the fridge. If we’re going to be serving alcohol, we also make sure to have a full selection of fizzies and water. Host The role of host seems, on it’s surface, to be the easiest. You just speak for ten minutes at the start, three minutes in the middle and two minutes at the end. Surely that’s simple. Not so. The host is the face of the meetup, so they tend to take any jobs which are public-facing. This includes creating the event on Meetup.com , following up with attendees to share the video of the event, and building the feedback survey we send to attendees. There are other responsibilities, of course. You need to be actually able to speak in front of large groups of people, for a start! The host will also often help out with speaker wrangling once the speakers are on-location, trying to help the speakers get comfortable if they’re nervous. One quick tip that I’ve learned in my 4 bouts of hosting - unless your speaker has a name like ‘John Doe’, confirm how their name should be pronounced. This will save you some embarrassment. Miscellaneous This is the Hufflepuff of meetup role categories , taking all the jobs that don’t fit elsewhere. This might include: Swag (we have some amazing vinyl ReactJS stickers, and HubSpot sometimes provides other swag too) Meeting attendees at reception Sushing HubSpotters who’ve discovered leftover pizza in the kitchen but don’t realise there’s an external event occurring Figuring out what music to play during the networking portion session of the event Photography The core committee will meet the week before the event and the day before the event to ensure that everything is going smoothly. We also have an open invitation to any speakers to meet with one or all of us to workshop their talk, something that both we and the speakers find very valuable. Diversity Diversity of our speakers and our attendees is something super close to my heart - the meetup is meant to be a forum for the sharing of opinions, and without a wide variety of experiences we’ll just end up a whole load of sameness. I’ve heard from attendees that we’re doing pretty OK in terms of speaker diversity. We’ve had a variety of nationalities, although our speaker list is predominantly male with only four out of twenty talks to date given by women. We've been trying to improve this by chatting one-on-one with potential speakers during the networking sections of the evening and asking past speakers if they can recommend any future speakers (diverse or otherwise) to try to broaden our pool, but speaker diversity is an area we need to continue to push on in the future. Diversity of attendees isn’t where it should be, and it’s also something we need to get better at. I’d be surprised if more than 10% of our attendees are female. We’ve gotten feedback that our meetup is very open and welcoming, but reaching a more diverse group of attendees is something we’re actively working on improving. Feedback At HubSpot we’re pretty data-driven, and this has had a hugely positive effect on ReactJS Dublin. After each meetup we send out a request for feedback. We ask attendees to rate, on a scale of 0-10, how likely they are to recommend ReactJS Dublin to a friend or colleague. This uses the industry-standard Net Promoter Score format, where respondents who answer from 0 - 6 are considered ‘detractors’, those who answer 7 or 8 are ‘passive’ and those who answer 9 or 10 are promoters. Detractors We found that in most cases, detractors didn’t tell us why they were detractors. In addition, detractors tended to rate us 0, rather than any of the other numbers - interesting, but without further data we can’t really say much. Promotors Attendees consistently mentioned the quality of speakers, friendliness of HubSpotters and the organisation. Past comments have included: the selection of topics was great! The best meetup yet, a huge improvement on the past ones. Great job! The HubSpot team were really welcoming, please keep it up - it can be daunting to arrive in someone else's office for the first time, surrounded by strangers (/ future friends :D) - everyone was welcoming and showed us where the drinks were, introduced themselves, etc.! Overall a great meetup. Organisation level keeps improving too, keep it up and thanks. In addition to the traditional NPS questions, we also follow up with some freeform questions where we gather information about what attendees thought went well and what didn’t, as well as what they thought of the topics discussed. The aim is to get as many respondents into the promoter section as possible by addressing the concerns brought up by those in the detractor and passive groupings. Focusing on these is one of the big reasons we’ve been able to create an event that’s been well-attended and well-liked. I'm often asked why we choose to spend so much time planning and running ReactJS Dublin, and why HubSpot is so willing to dedicate the resources to sponsoring and hosting the event. When we started the event, React was blowing up online, but there wasn't much of a community around it in Dublin. Everybody wanted to know more, but there were no opportunities to gather, discuss, and learn. And over the course of the last year and a half we've learned a lot - about patterns, libraries, best practices, and other frameworks. Being a part of the community and facilitating that learning is well worth the investment to us. A less obvious reason to host is the employment brand recognition you get from inviting attendees to your office, letting them meet your team, and building an association between your company and new, interesting technology. In fact, we regularly hear during interviews that candidates became interested in working at HubSpot after attending ReactJS Dublin. We hope this template helps you plan your own successful meetup - the thriving meetup community is one of the great things about working in tech. And if you’ve attended a particularly good meetup in the past (and can pinpoint what made it so good) let us know in the comments - we’d love to shamelessly copy it.", "date": "2017-10-06"},
{"website": "Hubspot", "title": "Name Dropping: Maria Pereda, Director of Product Design at Clio", "author": ["Francesca McCaffrey (She/Her)"], "link": "https://product.hubspot.com/blog/name-dropping-maria-pereda-director-product-design-clio", "abstract": "Name Dropping is a Q&A series that aims to elevate the stories of women and nonbinary people leading in the tech space. The idea came from Angela DeFranco, a VP of Product at HubSpot, who said one way to be better allies is to name drop more women and nonbinary people in discussions of achievement, inspiration, and disruptors in tech, instead of referencing, time and again, the same set of (often male) leaders. This edition of Name Dropping features Maria Pereda , Director of Product Design at Clio . You’re currently Director of Product Design at Clio. What’s one of the most interesting design challenges your team is working to solve right now? We’re in an incredibly interesting problem space. How do we help small legal practices function better so they actually have time to focus on helping their clients rather than trying to deal with the difficulties of running a business? One core mission of Clio is to increase access to justice and make it more equitable to everyone, not only by making it more affordable, but by making it more accessible to folks who today would not even know where to start. While this is challenging, it is an exciting problem space, and a great motivator for everyone who works at Clio. How have our current circumstances affected how you and your team work together? How do you anticipate it changing how you work in the long term? Our company recently moved to a distributed model, and we’re all trying to adjust to what it means to collaborate more intentionally and effectively in a way that doesn’t involve just turning around from your desk or a passing conversation while you’re making coffee. We’re trying to figure out new ways where collaboration feels like a value add and not some forced meeting on the calendar. This spans how designers collaborate with one another, how triads make decisions and work together, and how teams and leaders build cohesion and alignment. How do you stay close to customer and user feedback? Clio is in the legal space, and while we’ve gotten to know our customers fairly well, we are well aware that we need to keep our user at the center, from problem definition to finding the right solution, in order to ensure we continue to provide a solution that solves the right problem. It’s not one of those things that we can just guess at. We have a user research team and we work closely with them at all stages of the product lifecycle to access the right type of customers. In addition to that, we have several mechanisms to get feedback from our customers inside the app and through our user support and customer success teams, and the design team has full access to those. We are empowered to reach out to customers directly when needed to get insights directly from them. You’ve worked across several different fields, from banking to learning management systems to tech ⁠ — what are some of the lessons you’ve learned from cultivating this wide range of experience? My lesson number one is that there’s always something to be learned, and no matter how many years of experience you have, be humble. You can learn valuable lessons from your team, your peers, and your new industry. The second one is that nobody has it figured out. No matter how big or small the company is, some problems are universal. Friction between design and PM and design and engineering is always there, issues with collaboration span many industries, and human behavior is predictably irrational in any industry and setting you can think of. What is one quality that you think every leader should have in order to generate impact, and lead effectively? Self awareness. Developing it enables you to understand your superpowers and blind spots as a leader and to know which modes and styles of leadership come naturally to you and which ones you need practice to become better at. Self-awareness is also a prerequisite for leading with integrity, practicing what you preach as a leader, and being true to yourself, qualities that are often missing in today’s organizations and society. You’ve been a mentor at Side by Side Co. , a design industry nonprofit providing women, agender, and non-binary designers and technologists with goal-oriented mentorship and support. What advice would you have for anyone who’d like to get involved in mentorship? Have clear goals and ensure both you and the mentee stick to them. Mentorship does not have to be a huge time commitment, but without a clear goal and some desired outcomes, it can become a waste of time for both of you. What’s your greatest career achievement to date? In most of my roles, I have been the only woman in the room. Not only that, but also the only person with a Hispanic name and an accent. In a few companies and roles, I was the first woman on the leadership team. I had to work very hard to earn the respect of my peers, colleagues, and leaders, and to prove that I belonged. I’d like to think that, in my own way, I have blazed a trail for others who look or sound like me to come into those rooms, sit at those tables, and feel like they belong a bit more than I did. Who’s one woman or nonbinary person in technology you’d like to name drop and why? Daniela Jorge , Chief Design Officer at Paypal. As an immigrant myself, I find Daniela an endless source of inspiration, generous with her time and knowledge, always willing to share the inside track to help others succeed. What’s your favorite thing you’ve eaten in the past year? It could be something you cooked, it could be takeout from a favorite restaurant that just opened back up ⁠ — anything. In the middle of the first wave of the pandemic I had to rush to the hospital. My appendix had burst. I had emergency surgery and didn’t eat for an entire week. For some reason, when I got back home, the only thing I wanted to eat was shrimp Pad Thai from a restaurant in Toronto called Pai . And for the rest of the confinement I have been ordering it at least once a week. Sometimes twice. My husband thinks I have an obsession. Know another woman or nonbinary person whose name we should drop? Tweet us at @HubSpotDev with ideas. This post originally appeared on Medium . Interested in working with people who care about thoughtful leadership? Check out our open positions and apply .", "date": "2021-01-29"},
{"website": "Hubspot", "title": "Laura Martinez is a HubSpotter", "author": ["Elizabeth Dunn (She/Her)"], "link": "https://product.hubspot.com/blog/bid/86929/laura-martinez-is-a-hubspotter", "abstract": "Name: Laura Martinez Role: Tech Lead at HubSpot Superpower: Exploiting Amazon Prime Laura Martinez is on the HubSpot COS team, where she's building out the suite of content management and optimization products (email, landing pages, blog, etc.). She's pumped about the shnazzy new email product we just launched at HubSpot, although she claims that she can take no credit for that. Up next on her to-do list is a new integrated landing page and blogging tool. \"All of our stuff is Python/Django,\" Laura says. \"And you'd be amazed how much code can be shared between such seemingly different products -- these folks take meta to a whole new level.\" Before coming to HubSpot, Laura managed the web dev team at Compete, where she was the longest tenured employee at nearly 11 years (making her essentially the Patrick Fitzsimmons of Compete). Before Compete she attended school at MIT, where she studied CS (Course 6). Laura grew up in Miami, Florida, and spends most of her free time with her husband and their 15-month-old daughter. Every once in a while, when the kid is napping, she'll squeeze in a jog or a Bikram yoga class.", "date": "2012-05-21"},
{"website": "Hubspot", "title": "Name Dropping: Liz Borowsky, SVP Platform Engineering at Akamai", "author": ["HubSpot Product Team"], "link": "https://product.hubspot.com/blog/name-dropping-liz-borowsky", "abstract": "Name Dropping is a Q&A series that aims to elevate the stories of women leading in the tech space. The idea came from Angela DeFranco, a Director of Product at HubSpot, who said one way to be better allies is to name drop more women in discussions of achievement, inspiration, and disruptors in tech, instead of referencing, time and again, the same set of (often male) leaders. This edition of Name Dropping features Liz Borowsky , SVP Platform Engineering at Akamai , sharing her ideas and insights with Eric Richard, SVP Engineering at HubSpot. What’s the first thing you ever built that made you realize you loved computer science? I got into computer science through the back door, in a way. As an undergrad I was a math major, and frankly, I had no interest in computer science at all. My high school calculus teacher said that I should try computer science. I wasn’t sure, but then computer science was required for my math major in college. As it turned out, it was really fun, and it was really easy compared to math. I really liked building things. I enjoy an elegant proof as much as the next girl, but being able to build something that was interactive, that was very tactile, was so much fun. But even then, I loved graph theory, and networks, and algorithms, so I sort of made this slippery slide from theory into systems. I did CS theory for grad school, and slowly became more and more practical, and here I am. Before coming to Akamai, you worked as an Assistant Professor of Computer Science at Boston College. What are some skills from academia that have come in handy in your current role? There are two things. One is that I can talk in front of a crowd without any worry. When you lecture two or three times a week for large groups of students at a moment’s notice, stage fright just disappears. The other thing is, I’m really good at explaining things to people in the way that their mind works as opposed to the way my mind works. I think of it as translation. Meetings run better when I’m in them because I can hear what this person is saying or asking, and translate it into how that person is thinking about it. And that’s what makes our systems run smoothly — communication, and making sure that we’re all on the same page and not just talking past each other. When you teach, you have to do that. Not everybody comes to a discipline with the same kind of mindset. Some students like lectures, some have to work through the problem, some have to build something. Thinking intentionally about the ways people process information makes me better at collaborative work, which in turn makes me a better manager. Akamai’s made news lately for enhancing its cloud security portfolio and network protections overall. What other interesting challenges are your team trying to solve today? We do a lot with security. The security landscape on the internet is always escalating as we all do more and more online. The other big challenge we have, and have always had, is scale. We run a good chunk of the internet’s traffic, and those traffic needs are ever increasing. For example, think about how much video you watch over the internet instead of through your cable provider on TV. The bandwidth demands of streaming video, gaming, and augmented reality stresses internet infrastructure in ways it was never designed for. Making the whole internet work at the scale and quality that end users demand, and with the security level that people assume they’re getting, is a huge challenge. I’ve been at Akamai for 13 years now, and I have a very low boredom threshold, and I’ve never been bored here. The internet’s always changing. Even when you solve one problem, there’s a whole new set of challenges popping up. Who do you think has helped you become a great leader, either as an inspiration or a mentor? I don’t have that many mentors. There are people I look up to, professors who were great. Leonard Kleinrock, one of my professors in grad school, was one of the founders of the internet. He’s fantastic. But there haven’t been many women to look up to and follow. That said, I’ve been fortunate to work for many men who value work life balance and encourage that for all of us. In academics it was harder, because most of the rest of the department was men, many of whom had stay at home wives. I had my two children when I was a professor and balancing babies and research and classes was hard, even with a very flexible schedule. That said, I have a great group of friends and peers, both men and women, and we mentor each other. We get together, they vent, I vent, we keep each other sane. We give each other advice, we hold each other accountable. It’s sort of like making your own family, and we forge our paths together. What is one quality that you think every leader should have in order to generate impact, and lead effectively? I’m all about authenticity. I think this is especially important for women — you need to just be yourself. There was a long period of women trying to be like the guys. And that doesn’t really work, because if you’re aggressive like a guy, people don’t take it as well from a woman. How can you be strong and kind and still be yourself? Maybe you are aggressive. Just own that. If you’re not, that doesn’t mean you don’t know your stuff any less, or are able to make decisions and lead any less, it just means you have your own style. Instead of thinking so hard about what you have to be in order to reach a certain level, if you’re just true to yourself and it’s the right fit, then you’ll be ok. That’s my best advice. Just be who you are, and have a little more confidence. It took me a long time to realize that if I don’t understand something, it’s not necessarily me. Maybe it’s not being explained well. Be comfortable with that. You don’t need to know everything all the time. Be ok with asking questions. Eventually you get to a point as a leader that you can’t know everything, because it’s just too much. Might as well get used to that early. Who’s one woman in technology you’d like to name drop and why? I have two. One is Bobbie Carlton , whom I just met at a MassTLC training. She runs Innovation Women , which is a website and organization that gets women on panels. You can register and list your expertise, and she’ll match you up with speaking gigs. She does a lot of work on “end the manel,” which I think is just awesome. Like Name Dropping, it’s a way of getting people out there and getting more exposure. Number two is Sarah Downey who works with Rev Boston . They’re an organization that’s been trying to get more women into venture capital. She’s great as well. When you think about the best engineers you’ve ever worked with, what characteristics did they embody? Passion and curiosity. It’s inherent in engineering. Engineers like to solve problems. We’re driven by problems. If you have a problem, we say, let me tinker with it, let me fix it. From a leadership perspective, of course, it can be a little interesting. Sometimes you have to remind engineers, some of the things we do are actually good and people are happy with them and we need to appreciate that. Sometimes engineers can get too tied up in, “Oh, but there’s this little problem here, how can we fix that?” But the will to make things better and that curiosity about how things work and how to optimize them, it’s just great. As far as passion goes, I’ve seen avid discussions about all kinds of things between my engineers — for example, how many bits you have in what kind of data structures and the merits of one over another. I just love hearing that kind of passion about any part of the system. What’s your greatest career achievement to date? The thing I’m most proud of is that I helped IPV6 happen on the internet at large. An IP address is essentially the address of a machine on the internet. In IPV4, that address is 32 bits long. When the internet started, everyone thought this was fine, because they didn’t foresee the advent of personal computing or smart phones, let alone the internet of things, with every person in the world having several devices that all need IP addresses. So in IPV4, the world was running out of IP addresses. IPV6 is a standard that was developed a long time ago, with 128 bit IP addresses. This extra length meant it would last us much longer than IPV4, but implementation was a challenge. The problem was there was zero rollout plan. IPV6 was not compatible with IPV4 and we had this real chicken and egg problem where the network carriers didn’t want to IPV6 their networks if the content wasn’t going to be available on IPV6 and the devices weren’t available on IPV6. And the content and the devices didn’t want to do it if the carriers weren’t going to do it. And Akamai, as an internet middleman, was one of the key pieces of enabling this. If we could enable our services to be IPV6 compatible, we could enable our customers, the content providers, to be IPV6 enabled in one fell swoop. The team that I was leading at the time was the first team to build that technology and led Akamai through IPV6’ing our platform. We participated in IPV6 launch day, and got a lot of our customers on board. It was a lot of work, but it was really fun. The other fun thing was that it gave us a chance to go into all of our components and do open heart surgery and restructure everything. The engineers were able to go in and retire a lot of technical debt and renew the code base. They were so happy. To be the girl behind the scenes who helped to make IPV6 happen, that was probably one of the coolest things I’ve done. What advice would you give your 22 year-old self? Essentially, fake it ’til you make it. Give it a try. What’s the worst thing that happens? You fail? Then you learn from failure. Case in point, I was around 22, maybe a little older, and my thesis advisor in graduate school asked me if I wanted to work on the “hot topics” in the field, which other researchers would be working on as well, and there would be a lot of pressure. These were big name people whose textbooks I’d read. And here I am, 22. Or, I could work off on my own and it wouldn’t be as much pressure, but I also wouldn’t get as much of my advisor’s time, and it wouldn’t be as important work. Meanwhile, I’m one of the only women in my program in grad school, and I thought, what would my guy friends do? They’d all think “Sure, I can solve the hot problems, why shouldn’t I be able to do this?” And here I was, so intimidated and thinking how can I possibly do this? So, I decided “I’m just going to pretend I’m a guy for a while and that I have the ego to assume I can do these things”. As it turns out, I did tackle those hot topics in my thesis. I have prizes now because of the work we did solving those problems. So, don’t take yourself out of the running. Give it a try. You find out it’s not for you? So what? Move on and do something else. But it’s way better to have tried and failed than to not have tried at all. Be courageous and fake it when you have to. I’m a big movie fan, so I have to know: all time favorite movie? This is a tough one, because it depends on my mood. But I always like a heist movie. Maybe it’s because of the systems, and the people, and the teamwork, which I really like. And then they always manage to do the heist, so it all comes together. I like The Italian Job best — the remake with the Mini Cooper chase scene. That’s my favorite. Know another woman whose name we should drop? Tweet us at @HubSpotDev with ideas. This article was originally published on Medium .", "date": "2019-12-19"},
{"website": "Hubspot", "title": "Enjoy the newly open-sourced oneforty Twitter app data", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/80950/enjoy-the-newly-open-sourced-oneforty-twitter-app-data", "abstract": "Earlier today, we open-sourced all of the social media & Twitter app data collected and curated by oneforty , the great local startup HubSpot acquired a few months ago.  This means the data is fully available for the public to use and enjoy. In addition to the data itself, there is technical documentation as to its format, tools to import it into other systems, and human-friendly instructions for working with this data in Microsoft Excel. Get it on GitHub: https://github.com/HubSpot/oneforty-data (http://bit.ly/onefortydata) Like most software companies these days, HubSpot relies on a variety of open-source tools, and we generally try to continue any patches or fixes back to the open-source projects we use.  We also have a number of engineers working here who are committers or contributors to a variety of projects. Today we took the next step, by open-sourcing the data itself, which was one of the main and most valuable oneforty artefacts.  The data is licensed under the Creative Commons License , and you are free to use it in numerous ways.  We just ask for a small attribution, please. It looks like at least one company, SocDir ( @socdir on Twitter), is planning to use this data in interesting ways. If you are curious about Twitter applications, watch SocDir and/or have fun working with this data yourself.  We're not sure yet how much time we'll spend maintaining it ourselves, but patches ( GitHub pull requests ) will likely be very welcome.", "date": "2012-01-09"},
{"website": "Hubspot", "title": "Onboarding Engineers: How to Tackle the First 30 Days", "author": ["Jeff Dwyer"], "link": "https://product.hubspot.com/blog/onboarding-engineers-how-to-tackle-the-first-30-days", "abstract": "When you’re a tech lead, the most important work you do is helping other engineers grow and setting them up for success. That means making sure they have the tools, guardrails, and confidence they need to have an impact from day one. But, that’s easier said than done. Pretty much every engineer I’ve worked with has a different learning style, and every engineering manager I know has a different leadership style. There isn’t really a one-size-fits-all method to onboarding but I think we all agree that the first 30 days are critical for every new hire. TLs at HubSpot are very hands-on with new hires and, personally, I think that’s better than sending them to a week long “boot-camp”. I’d say we do a pretty good job at onboarding engineers, but we’re working on how we share best practices and standardize a little bit of the process where it makes sense. So I shared these thoughts internally about a few onboarding pieces and how I’ve approached the first few weeks with a new hire, and hopefully they can be helpful to external engineering managers, too. Task Selection The number one, most important, super-critical thing you can do is to think hard about task selection. That means putting together a detailed list of tasks for your new hire and thinking hard about what skills they'll need to approach each one. I forced myself to write a plan for each new hire . I keep it in a Google Doc to strikethrough each task as they’re completed. Tips on Task Selection: 1. Have small wins every week so they get comfortable owning tasks and projects. Save some bigger, tastier morsels until they start to ramp up. That way, the impact they’re having on customers will be that much more rewarding. 2. Avoid company-specific things to start. The ideal first task is a medium sized method, with a unit test that needs a behavior change. I typically don’t dive into HubSpot stuff until they’re ready. 3. Start the task yourself first. If you find you need to tweak Mothra, PR another project, read source for another project, opengrok something, then this is not a good first task for someone new. 4. Think hard about how long you expect these tasks to take. Split them up by week so you can see how they're progressing relative to your expectations. (Factor in time for them to get their workstation setup.) 5. Develop weekly themes (and don't forget to tell your new hire what the themes are). I'd skip JIRA / Sentry / Monitoring to start. They're great things to do as a week 3-6 \"theme\". 6. Work towards a moderate sized feature in week 4 that is challenging but has clear bounds. Ideally, this will be their first major work on whatever section of the code base you’ve decided to give them ownership of. When you’re writing your plan, think of it as \"telling a story\" to your new hire. \"First we're going to learn A. Then we'll learn B. Then we'll see how A+B can work together.\" \"The reason we are doing A is because ...\"  “Don’t worry about anything ops related, we’ll be doing that in a few weeks”. Giving people a timeline can make the ramp up period much less stressful because they don't feel like they're expected to do everything at once. Coding Mentor Pairing new hires up with a coding mentor isn't something we do all the time, but I think it can be really useful for certain people. Ideally, a mentor will be a more junior coder who is looking to expand their scope, or is just a few steps ahead of your new hire on the learning curve. (Save a super-coder for a few in depth code reviews.) This person should be on the front-line for questions before they need to ask in Slack, ping their their coding style/formatting helper, or check your resources reference. This is particularly beneficial if you’re a backend tech lead trying to onboard a frontender or a frontender with a new backender. Wait, but why not do this yourself? There are a few reasons. First, it will introduce them to other people in the organization and since tech leads are more likely to get waylaid by interruptions, it should provide them with a more reliably available resource. Secondly and I think more importantly, this makes your role more like a coach than a teacher. It orients you toward guiding their approach to learning rather than being their oracle. Pull Requests Pull requests are the lingua franca of engineering culture at HubSpot, but there are a number of pitfalls to be avoid. 1. Consider what PR behavior you \"model\". If all a new hire sees is you aligning code and and fixing style conventions, then that's what they'll fixate on. If you’ve paired them with a coding mentor as suggested above, then their mentor should be in charge of style conventions. 2. Be careful not to do too much QA. Fixing subtle bugs in a new hire's PRs can lead to a dynamic where they code and you're in charge of QA. Rather, push back on PRs to make sure that they have a plan about how to deploy it safely, and how they'll verify it's working in production. You don’t want your “lgtm” to mean “I put my personal seal of approval on this code and confirm that it works as expected in production”. 3. Agree upon a system sketch before they start coding. PRs are an unfortunate and expensive place to redo the architecture of a solution. It’s very discouraging to code, put up a PR, and then hear they’ve re-invented the wheel because \"ServiceXYZ\" already did that. If that's happening to your new hire, you're not giving them what they need to succeed. Work through each task with your new hire in detail before they start coding to limit wasted work. I have had great luck working with Sketch to bat some complicated proposals back-and-forth; here's an example of a final Sketch my team and I came up before starting a fairly complex project: 4. Focus on naming and clarity of code. PRs should be easy to review because the variables, methods, and code organization are clear. Optimize and nitpick until PRs are easy to read because the intent and effects of the code are so very clear. 5. Avoid massive PRs, but always keep your primary branch deployable. That’s easier said than done though. How can we reconcile a deployable primary branch with an avoidance of long-lived branches? Feature flags are our primary weapon here. Help your new hire figure out a strategy to get all of their code into production, but hidden behind a flag. Better yet, break that PR down into a few logical chunks that can be independently verified to work and even then put them behind a feature flag so you can deploy safely even if they don’t work. Pair Programming Wouldn't it be neat if there were a way to convey all of your wisdom without having to spend nights and weekends working? Do you feel like you don't have time to make a detailed plan for onboarding and coaching your new hire? Why not try pairing? In just a few hours a week you can successfully onboard your new hire by just sitting down next to them and working with them for an hour all for the low low price of free. All kidding aside, pairing (two people coding on the same problem, be it small or large) is a great way to onboard your new hire. IntelliJ tips and tricks? Check. Working on how to break down a problem? Check. Super fast ability to give feedback on coding style? Check. Efficiently teaching them what tools and services are available? Check. So, what are you waiting for? Call now to start pair programming today.", "date": "2015-12-03"},
{"website": "Hubspot", "title": "Application Warmup URLs", "author": ["Dan Abdinoor"], "link": "https://product.hubspot.com/blog/bid/75626/application-warmup-urls", "abstract": "The HubSpot Dev Team is constantly coming up with really small, but really helpful patterns for building web applications. One of the most flexible and powerful items has been the application warmup URL. The story of the warmup URL goes back a few years to when we were starting to build out a deploy system for our code. We decided to run most applications on two or more identical EC2 instances and put a load balancer in front of them. It was easy to take a server off the load balancer and deploy new code. But when you shifted traffic back to that server, the first request was slow. Because the applications get requests at all times of day the first request was often a customer and the slowness was a bad user experience. We investigated the slow requests and found that the intial lag was from the database connection pool setup. Once the connections were made and the pool set up, subsequent requests were performant. No amount of lazy-loading or multi-threading would be able to shorten this necessary step. We quickly came up with the idea of a warmup URL with an action to execute a database query. The warmup URL is called from the deploy script, and the response is checked for a \"success string\". The success string tells us that the connection pool and query have completed and that the server is ready to start handling real requests. During a deploy we only return traffic to the server after the warmup URL is successful. If we get an error response, or no response, we stop the deploy and alert the developer. Additionally, the warmup URLs have been useful for external monitoring. Once the app is up and running there is almost no overhead in hitting the warmup URL. Pointing Nagios or Pingdom at it allows us to have a constant health check on the application. Do you have any simple or quick patterns that make your web applications awesome?", "date": "2011-09-30"},
{"website": "Hubspot", "title": "Post-Mortems at HubSpot: What I Learned From 250 Whys", "author": ["Dan Milstein"], "link": "https://product.hubspot.com/blog/bid/64771/post-mortems-at-hubspot-what-i-learned-from-250-whys", "abstract": "At HubSpot, for the past two years, we've modeled our post-mortems on Eric Ries's 5 Whys .  When we started, I served as the facilitator for basically all of them -- over time, we've added other folks into that role. It's been a deeply interesting learning experience. I've learned about how HubSpot's systems work, why they sometimes break, and what we can do to make them more resilient.  Beyond that, I've learned a lot about complex systems and failure in general.  Which, in case you're wondering, is a fascinating topic.  I highly, highly recommend Richard Cook's essay \"How Complex Systems Fail\" in O'Reilly's Web Operations .  Or Atul Gawande's Complications and Better .  Or basically anything John Allspaw writes. If you'd like to build resilient systems, here's some of what I've learned from the fifty-plus 5 Whys I've been a part of. (And by \"systems,\" I mean systems of people + machines, and by \" resilient ,\" I mean I'm stealing from Allspaw.) Let's Plan for a Future Where We're All As Stupid as We Are Today This is a somewhat specific detail, but it comes up a lot, so I wanted to pull it out.  If you run a bunch of 5 Whys, you'll find that a lot of times, the developer who made the first-order mistake (forgot to copy configs from QA to Prod, or deployed two apps out of order, or whatever), will say \"Look, this was totally my fault, I screwed up, that's the whole story.  I'll be more careful next time.\" The very short summary of which is: We're going to fix this problem by being less stupid in the future. Which, well, you can guess how that's going to turn out. I now start all the 5 Whys by saying \"We're trying to prepare for a future where we're all just as stupid as we are today.\"  (Actually, my more nuanced view is that we're all really smart on occasion, and really stupid on occasion, to varying degrees, but none of us is never stupid). Or, I sometimes say: \"Someone made a mistake, but we all somehow built a system that turned that mistake into a disaster.  This is an opportunity to improve that system.\" Less Root Cause, More Broadest Fix One lesson from the study of complex systems is that there is almost never a single root cause.  Really bad failures only happen because several things conspire.  A developer made a mistake, and our automated testing was weak, so we didn't catch it before it went live... but the pain was magnified because our monitoring was weak, so we didn't notice until it had done significant damage to a large number of customers. In practical terms, just about every 5 Whys has a branch point, where there are two roads you could go down (testing vs. monitoring is a classic one at HubSpot). When I lead them, I say something like \"We're not really looking for 'root causes' so much as identifying the areas where an improvement would prevent the broadest classes of problems going ahead.\" I find that perspective useful -- instead of people debating \"Which of these two causes is the real one?\" you're asking them \"If we made A slightly better or B slightly better, which would prevent the broadest class of future problems?\"  I've had better luck with that conversation. Oh, and speaking of testing vs. monitoring... Err on the Side of MTTR, Not MTBF Asking \"What would prevent the broadest class of future problems?\" has led us pretty steadily towards improving Mean-Time-To-Repair, and focusing a lot less on Mean-Time-Between-Failures. Incidentally, this is also more John Allspaw.  Last winter, Jeremy Katz went around the office grabbing everyone by the lapels and forcing them to read this blog post: MTTR is more important than MTBF (for most types of F) If you can swiftly identify failing pieces of your system, and swiftly recover from those failures, you're in good shape for a wide variety of different failure types (I can think of specific 5 Whys triggered by all of the below): Bugs in code Mismatches between QA and Prod configs Out-of-control thread pools eating all of memory DNS problems Network partitions Spontaneous machine/instance failures Full data center outages We host a lot of stuff at EC2, and had an all-things-considered pretty good day during the Amazonpocalypse -- see more below. If you're reading this, and thinking, well, duh , I'll just say: the idea of preventing failures is very, very seductive to people.  In fact, it may be very seductive to the people who sign your paycheck.  Because, come on, what's the alternative -- accepting failure?  Why would we do that?  Don't we care about the customer? Consider the 5 Whys as a way to build up evidence that recovering from failures is a much better economic bet than trying to prevent them. Never Let \"Slow Down\" Be The Answer In addition to forbidding a future in which we're less stupid, it's also useful to try to take \"slow down\" off the table at the outset.  In fact, I like to sometimes think of 5 Whys as \"How can we address this problem so we can go even faster than we currently do, while causing less pain to customers?\" That's not strictly a part of 5 Whys, but people tend to underestimate the economic costs of slowing down, so it's good to make sure that you don't retrospective your way into waterfall.  HubSpot has a pretty deep cultural commitment to velocity, but even so, I've found it useful to say this out loud on occasion. If you want to learn more about the hidden costs of slowing down, give Donald Reinertsen's Principles of Product Development Flow a careful read.  It's a deep, insightful analysis of all sorts of marvelous product development geekery: the cost of queues, the power of small batches, techniques for decentralized control, etc, etc.  Really just amazingly good. Our Biggest Win: The Product Quality Crisis In the fall of last year, after a particularly nasty spate of customer-facing bugs, Brian Halligan (our CEO) said \"Folks, what the hell is going on, we've got to stop inflicting so much pain on our customers.\"  And he sent a bunch of us off to come up with ideas for improvements. This was, in my estimation, where our history of 5 Whys really paid off.  Because, if you ask a bunch of people \"What should we do so we stop having so many bugs in production?\" most of them will come up with some variation on \"Slow down and add more human review.\" It just feels intuitively right to a lot people -- surely we're having bugs because our developers, who are speed cowboys, are being careless, so we should slow them down and double-check their work, right? Yoav Shapira, Jeremy Katz, and I took a careful look back over the 5 Whys we'd run, and the message was clear: It was our systems that were unreliable, not our developers.  We needed to improve our monitoring, we needed to make our deploys more deterministic, we needed to match configs from dev to QA to Production.  We were able to stand up in front of leadership and say \"If we'd released less often, and had someone QA every release... we'd still have had 80-90% of our worst problems hit us.\" Not long after this, Jeremy (one of our strongest developers) was asked to set up a new team to focus on Tools & Infrastructure for the developers.  That's a serious investment on the part of our leadership. I'm not sure they would have made it without such a clear vision of where we'd been getting tripped up. Hard Choices are Still Very Hard Overall, we've been very happy with the wins we've gotten from our post-mortems.  I recommend 5 Whys highly.  But they don't magically make your problems go away.  For example, I've sat in on, or led, probably a half-dozen different 5 Whys, where we ended up with a root problem involving this one specific, painfully unreliable, legacy system. So you ask: Why can't you incrementally improve that system? We have.  Somewhat.  However, not only is the system legacy and not seeing almost any active development, but it runs on an OS that we've deprecated for new server-side code.  Almost all the improvements (even modest, incremental ones) would require expertise we don't really have on our team.  Do we hire that expertise?  Train someone up in it?  Hope that our ongoing, gradual rewrites will get enough critical code off that system + OS eventually?  Buckle down and just port everything off that OS in one (incredibly expensive) fell swoop? We haven't found a great answer. And so we keep on having occasional, sometimes pretty nasty, issues, where we're facing that system again. I think the lesson here is: No post-mortem process will excuse you from making hard economic choices.  It helps you frame them well, but -- not infrequently -- you're still facing a difficult tradeoff. Where We Are Today The Amazonpocalypse was, for us, as for many startups, an intense test of our systems' resilience.  How'd we do? Overall, pretty well. Customers saw little downtime -- pieces of our app were unavailable at various times, but the overall system was up and running with pretty much no interruption. We got a bit lucky, but we've definitely built, between our code and our people, a pretty resilient system. The 5 Whys discipline helped give us: - Solid, high-quality monitoring We found out about the issues at 4 am, and had people failing over key databases to slaves within an hour or two. Two years ago, our monitors failed mysteriously pretty much every night, and everyone had learned to ignore them.  Many post-mortems had pushed us to clean those up and make sure someone was listening when they went off. - Clear team ownership over systems We've embraced the DevOps model, and it served us incredibly well.  The developers who own and live with our key systems were able to put them into a degraded, but functioning state, and then work to restore full functionality.  Clear ownership has been another post-mortem theme. - Fast, reliable deploys Over the day, people pushed out new code to dozens of servers -- putting in place messaging for customers, switching off non-critical functionality, pointing at new database masters as they came up.  Our deploy process has been subject to a long series of 5 Whys-driven improvements--to the point that we all depend on it unreservedly in the midst of a nasty crisis. We've got a lot of work to do, but I think we all came out of that day pretty proud of where we are. Some Practical Tips for the Moderator The follow-up Eric Ries post on how to conduct a 5 Whys , is very good.  In the spirit of that post, I've included some additional notes on how we run ours: Start by framing the \"Bad Thing\" in terms of customer/economic pain People will say \"We pushed a bug for the leads app,\" and I try turn that into \"From such-and-such time, to such-and-such a time, customers were unable to view the public leads details screen. There were N reports of customer complaints from support (or we've looked into the logs, and Y customers were impacted).\" It really helps to understand just how Bad the Bad Thing was (so you can decide how much effort you're going to spend on corrective actions). Write it all out on a whiteboard as you go My opinion: your job as facilitator is not to identify the causes/fixes, it's to build consensus in the room about what those causes/fixes are.  Your expertise is valuable in pushing the room to think about different ideas, or to help identify something that they're all circling around, but you should be asking, often \"Why was the system set up that way?\" or \"If we fixed this, would the problem been prevented?\"  They own the answers.  Write it all out, see if people agree.  If no one's offering any ideas, write something down to spark conversation.  But make sure you're listening more than you are doing your own analysis. Don't be afraid to call on people Often, there's a developer or support person sitting in a corner, not saying much.  It's really good for the facilitator to draw them in, e.g. \"Does that sound right to you?\" or \"Was there anything else going on while you were trying to fix this?\"  Definitely do that if you sense that anyone is uncomfortable with the path you're going down.  If half the room is nodding, but one person is looking uncertain, you want to find out why. Try really, really hard to have everyone in the same physical room Because of the importance of reading people's emotions, as above, I personally hate having people call in via conference call for 5 Whys analysis.  We do it on occasion, but I fight it pretty hard.  Skype has been marginally better, but it still ain't great.  I like to have no more than about eight people, max, in the room.  It's hard to have a really good conversation with more. Want to work with us to make our system world-class?  If so, we want you, frankly, more badly than we should likely admit.", "date": "2011-06-01"},
{"website": "Hubspot", "title": "Why we treat interns like full members of the team", "author": ["Eric Richard (He/Him)"], "link": "https://product.hubspot.com/blog/why-we-treat-interns-like-full-members-of-the-team", "abstract": "There are some companies that have special co-op and internship projects that are separate from their normal stream of product development. Often, the work of co-ops and interns never sees the light of day, or at least not while they're at the company. We fundamentally do not believe in this approach. We believe that the best way to learn is by doing, and therefore, the best way to learn how to be a software engineer is to do what a software engineer does. A few of our recent interns pulling their weight at our summer product party. Because of this philosophy, we look at interns largely the same way we look at any other full time software engineers. We put interns on the same types of projects as other full time engineers. We expect them to develop the same sorts of features and ship into production, just like other full time engineers. They ship production code within their first few days of being here. During their internship, they develop real features that are delivered to real customers and are often even demoed in front of the entire company at our monthly Science Fair. Those on external tools often get to sit in on calls where they can watch customers using our software and see their struggles and successes, then make those tools better. For many co-ops and interns, this is a combination of exciting and daunting. On one hand, their connection to creating value is palpable: the code they create powers the real features that real customers use. On the other hand, the learning curve can be steep. We often expect interns to come up to speed quickly on technologies they've never used before, like React, Java, Kafka, and others. We don't give them micro-sized tasks and tell them how to solve every problem. Instead, we ask them to think through challenging problems and come up with their own solutions to them. Of course, there is a safety net for our interns. We don't throw them in the deep end and expect them to swim all by themselves. Each intern has a tech lead, a product manager, a product designer, a handful of other engineers on the team, and in some cases a separate mentor all there to help them learn, grow, and succeed. And yes, the idea of shipping real code to real customers can be scary. I'm sure most interns at some point wonder to themselves, \"What happens if I screw up and cause a bug or a, even worse, take down part of the product?\" While it's an intern's job to diligently learn and try to write high quality code, ultimately, it is their tech lead's responsibility, not their own, to ensure that the code that goes into production is good. It's the tech lead and team's responsibility to do code reviews and make sure that things go fine. We don't want put the weight of all of our customers on our interns' shoulders. We don't want our interns to be afraid of failure. We want to give them the opportunity and the tools to stretch themselves to do things they've never done before knowing that they have a support network around them to help. And to be completely transparent, this approach isn't for everyone. There are some people who want way more hand holding and guidance than we give here. They want to be assigned tasks and told what to do. We've also had a few interns who have come in, started doing the job of a software engineer, and then realized that it's just not the right path for them. And that's okay. It isn't in anyone's interests to make them do a job they just don't want to do, so in that instance, we try to find the solution that works for everyone. We feel that helping those individuals figure out what they do and don't want to do with their lives is a success in and of itself. Our interns are here for two big reasons. First and foremost, they're here to learn how to be better software engineers and how to work in a professional setting. And through that, they'll accomplish their second goal - to ship code and delight customers. Goal #1: Learning by doing For every co-op and intern, the primary, overarching goal is to learn. To learn new technologies. New skills. How to think about complex problems. How to translate customer features into code. How to write high quality, readable, maintainable, scalable, reliable code. How to diagnose and solve problems. How businesses operate. What it's like to work in a company setting and how it differs from school. Whether all of these things are what they love doing. At school, a lot of a student's learning is done through reading or lectures. At HubSpot, the vast majority of their learning is accomplished by doing.  They get their hands dirty and work on real problems and writing real code. Some people join HubSpot already having experience with the technologies they'll be using here. For those folks, the goal should be how to master those technologies and become better, more proficient engineers. Other people join HubSpot without experience in the specific stack we use here. That's okay. We don't expect people to be experts on day one. In this case, the primary goal is to gain proficiency in those technologies and be able to apply them to their role. If, at the end of their co-op or internship here, they feel like they've improved their skills as an engineer, become proficient at new technologies, and gained a better understanding of what it is like to be a full time software engineer - that's the mark of a successful internship. With this in mind, we want our interns' daily goal to be quest for knowledge through their own self-motivation and practice. What can I learn today? How do I take advantage of all of these resources around me to become a better engineer? Those are the questions we hope interns ask themselves during their time here. Goal #2: Shipping good software that helps customers There are few things as gratifying as being able to say, \"I built that!\"  Ultimately, as makers, that's why we do what we do, right?  We love to build stuff. With that in mind, the second most important goal for interns at HubSpot is building real software that is used by real customers. At the end of a co-op or internship, it's incredibly rewarding for interns to be able to point to the things they accomplished. This also helps them whenever they go for their next co-op, internship, or full time job. Being able to show the real software that they built and shipped into production is a great addition to their resume, and the lessons that they learn about what it's like to build software for real people is invaluable experience for whatever comes after their internship here. Ancillary Goal: Making friends and having a good time Let's face it - we spend more time at work and with our coworkers than almost any other single place. So, making sure that our employees are happy coming into work each day is important, and this also includes interns. As part of this, we try to make sure that their time at HubSpot is engaging and productive. We sponsor events to help co-ops and interns make friends and have fun at, and away, from work. But, overall this is an ancillary goal - not a primary goal. As our COO JD Sherman wrote on our internal wiki: Is our goal to make HubSpot a fun place to work?  Nope - although in my career I’ve never had more fun, and I've never laughed so much or worked with people I loved nearly as much. Are we trying to make HubSpot an easy place to work? Nope. HubSpot isn’t an easy place to work, and it never will be, because we’re trying to accomplish so much. Folks who are on board with that mission tend to love it. The reason that we invest in culture - and the reason we think it’s our secret weapon - is because we want to make HubSpot a place where people can do their best work! Our focus is on creating an environment where interns can do their best work and hopefully have some fun along the way. What about getting a job? None of goals above is “get a job at HubSpot”, although an internship is somewhat of a test run of what it’s like to work as a software engineer at HubSpot. HubSpot's co-op and internship program is a huge driver of our growth as a team. There's a huge number of people who succeeded here as interns and now succeed here as full-time employees. In fact, many of our current leaders on the team started out as interns. But landing a full-time job shouldn't be the be-all, end-all for an intern or co-op. If an intern excels at learning and shipping and enjoys doing it, that conversation will likely arise - but even if it doesn’t, that's totally okay. It doesn’t mean the internship wasn't worthwhile. We have had plenty of co-ops and interns who did a great job and turned our offers down, but that didn't make us think that their time here was any less valuable. Similarly, we've had co-ops who did a good job and learned and grew as software engineers who we didn't extend offers to, and hopefully they felt like they they had a successful co-op despite the lack of an offer. The key here is that both the co-op/intern and HubSpot should be focused first and foremost on the two most important goals of the internship and letting the rest happen naturally. Neither side should get so obsessed about the offer that we lose sight of those goals. We truly can’t imagine our team without the dozens of interns that join us every year. When we treat them like real employees, with real projects, real goals, and real responsibility, it lets us focus on what's important - building software that helps our customers grow their businesses. If you're a current student and this sounds like the internship for you, learn more about the internship and co-op opportunities we have available. We'd love to hear from you.", "date": "2017-08-22"},
{"website": "Hubspot", "title": "Git by a Bus", "author": ["Edmund Jorgensen"], "link": "https://product.hubspot.com/blog/bid/57694/git-by-a-bus", "abstract": "Developers are always being told to document and collaborate on their code in case they are \"hit by a bus.\"  Usually \"hit by a bus\" is code for \"go to another company,\" but the point is the same: if you are a developer with unique knowledge of code, that knowledge is at risk if you depart either your job or this life. I got interested in the problem of identifying and quantifying that risk, and Git by a Bus is the result.  It analyzes the history of your git repository (there is also experimental svn support), estimates unique knowledge per file per developer or group of developers, and then writes an html summary of unique, at-risk, and orphaned knowledge for each project and file in your repository. If you're interested in trying it out or hacking on the code, HubSpot has let me open the source, which is available on github here .  Read on for more details on how it works. I experimented with a few different models for unique knowledge as I was writing the script, but the one I settled on is pretty simple and has the virtue of allowing you to estimate risk with the joint probabilities of more than one developer being hit by a bus. In the final model, the \"knowledge\" contained in a file at any point in time is represented as the number of lines in the file plus an adjusted \"churn\" value.  \"Churn\" is the number of lines that are estimated to be changed rather than added in a revision, and we multiply by a constant (by default 0.1) to translate that churn into a knowledge value.  In other words, we estimate that for every line added to the file, one knowledge point is added, for every line removed, one knowledge point is removed, and for every ten lines changed, one knowledge point is added. Using this model, Git by a Bus marches chronologically through the log of each file in your repository, applying the following algorithm for each revision: If the revision resulted in a net gain of lines, assign that net gain as unique knowledge to the author of the revision (we'll call him A). If the revision resulted in a net loss of lines, find the percentage of the total knowledge represented by those lines and destroy that percent of unique knowledge held by each dev or group of devs. For the \"churn\" of the revision, as defined above, multiply it by the churn knowledge constant (0.1 by default) and assign that as new unique knowledge to A. For the \"churn\" of the revision, as defined above, multiply it by 1 - the churn knowledge constant.  That gives us an estimate of knowledge that used to be unique to other developers or groups of developers, but which A now shares.  Find the percentage of the total knowledge of the file represented by this newly shared knowledge, and then for each dev or group of devs that does not include A, remove that percentage of their unique knowledge and assign it to a group including the original dev or group of devs as well as A. At the end of this process, we have basically built up a venn diagram of how all the knowledge in the file is distributed.  For example, if three devs A, B, and C had participated in a file's history, the output of our algorithm would show how much knowledge each dev held uniquely, how much A and B held jointly, or A and C, or B and C, and how much estimated knowledge was shared between all three. Now, using supplied input files that tell us which devs have already departed, and the estimated risk of each remaining dev getting hit by a bus in some time frame, we can calculate: \"Orphaned\" knowledge--that is, knowledge that was estimated to be held uniquely by a dev or groups of devs who are all departed. The expected unique knowledge that each file / project stands to lose in that time frame, calculated by multiplying the unique knowledge of each dev or group of devs by the joint probability that all dev or devs in that group will be hit by a bus.  The algorithm assumes that the probability any two devs will both be hit by a bus is independent, so it doesn't take into account devs who bike into work together, are conjoined twins, or enter into bizarre death-by-bus pacts.", "date": "2011-01-05"},
{"website": "Hubspot", "title": "What makes a good tester / QA engineer?", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/6912/what-makes-a-good-tester-qa-engineer", "abstract": "There are a ton of development blogs out there.  We all read many of them. But a good QA (Quality Assurance, aka Quality Engineering, Quality Control, or just testing) blog is hard to find.  Do you know of any, by the way? My current favorite QA blog is called Abakas , and it's written by Catherine Powell .  Her recent post, on what makes a good tester , is a fine example of why I like the blog. She takes on tough issues, handles them well, writes clearly, and has a very realistic outlook.  She's not a dogmatic, process czar type of QA person.  We don't have anyone like that at HubSpot, thankfully. To summarize Catherine's points, a good QA engineer must be: - Curious - Detail-sifting - Able to translate - Have good memory - Logical Read more on Abakas .", "date": "2009-07-01"},
{"website": "Hubspot", "title": "The HubSpot App Marketplace (Part 3): Successful Companies Built on HubSpot", "author": ["Adrian Mott"], "link": "https://product.hubspot.com/blog/bid/74153/the-hubspot-app-marketplace-part-3-successful-companies-built-on-hubspot", "abstract": "When I started working on the Platform Team here at HubSpot, one of the big goals that I wanted to see us hit was to have a real company be built and achieve success (by their standards) by building apps and services on the HubSpot Platform.  Today, we can say with confidence that we've reached that goal with a few different companies, but two that i'll highlight here are LyntonWeb and Zery's (Interact Media). Founded by Daniel Lynton in Houston, TX back in 1999, LyntonWeb has recently seen a slew of growth in revenue and employees after beginning to develop apps on the HubSpot Platform.  They have focused primarily on the integration side of the HubSpot app development world, providing CRM and E-commerce integrations to HubSpot customers and offering a ton of value.  Lynton's apps have done so well here that it's become standard practice for the sales and consulting teams to make sure new customers have the integration apps they'll need. The growth of the company in the past couple years has been impressive to watch, as we can see by the graph below which measures head count of the company: Looking at the integration apps that the LyntonWeb team has engineered is also interesting, as we see a diverse set of apps that they work with and provide apps and services around: Zery's started as a a blogging service in the HubSpot Services Marketplace, but really found lots of success from building a canvas app in the HubSpot App Marketplace.  The premise of the Zery's app is to provide on demand content marketing (literally blog posts and other marketing content) for very reasonable prices.  Thus far the results have been great for the app and the reception awesome from HubSpot customers.  Here are some stats that represent this success: 55% growth rate in revenue from the HubSpot canvas app. Only 10 days development time on their app to adapt it to the HubSpot App Marketplace. 750+ total app installations to date. Zery's is one of our fastest growing and most successful apps to date. Having successful companies growing and profiting from building on our Platform is one of the ultimate marks of success for any software platform. We plan on continuing to work to empower more success and growth for companies building on HubSpot.  If you'd like to learn more about building apps on the HubSpot, please comment on this post or post to the HubSpot API Discussion Google Group.", "date": "2011-09-13"},
{"website": "Hubspot", "title": "How We Onboard External Engineering Leaders by Having Them Be Software Engineers", "author": ["Eric Richard (He/Him)"], "link": "https://product.hubspot.com/blog/onboarding-external-engineering-leaders", "abstract": "I regularly get asked what my biggest challenges are or what keeps me up at night. For me, it’s making sure we attract and retain the right engineering leadership (who believe in our shared philosophy ) so that they can support our rapidly growing team. When you are growing as quickly as we are, it is extremely important that you have leaders in place who can sustain the culture of excellence as we scale. A bad leader has a very high blast radius. One of the solutions here is internal promotions. And we certainly lean in here, looking to cultivate our next generation of leaders and giving up and comers larger and larger opportunities to have an impact. But, it’s also important that we bring in leaders from the outside in order to foster a culture that brings in differences of opinion, background, and experience. So, how do we set them up for success and help them assimilate without putting undue pressure on them to succeed on day one? A few years ago, on one of our annual West Coast field trips, we asked several executives whether they hired external engineering leaders and, if so, how they onboarded them. They told us that they do hire external leaders… but… they do not put them in role on day one. Instead, they give them an extended period of time to get to know the organization, the culture, and the tech stack. While this makes sense initially, what’s the real ‘why’ behind it? Say Kim comes in from another tech company and she immediately starts to manage and lead a team. Most likely, her leadership skills, and the software the team builds, will be in the style of her old company, not in HubSpot fashion. And not through any fault of her own, but because she was thrown into her role and not given the time and space to learn how we operate, how we build, and how we lead teams to success. Over time, you have enough Kims joining the leadership team building the way they know how to build, and HubSpot’s culture, core values, and foundation becomes misaligned and cracked. In addition, this doesn’t really set Kim up for success.  She’s not being given any opportunity to adjust her style and, therefore, its creating a really high barrier for her to get the trust and alignment with her teams. So to avoid this potential pothole, every external engineering leader who joins the team goes through what we call an “Embedding Process” for the first several months at HubSpot. They are onboarded and treated just like any other engineer who joins the team taking the same training and going through the same onboarding project. Then, leaders start with a single “deep embed” where they focus on one single team for two to three months. This is a deep immersion where they are really learning the tech stack, the culture, the domain, etc. Then, they start to move toward more of a rotational model where they might spend one month or even just a few weeks moving from team to team learning the domain of that team. We’ve even started to do some rotations to other teams (ones they won’t be managing) if there are tight relationships between those teams. For us, a successful embed looks like this: The leader has built credibility amongst the team by getting their hands dirty, working side by side with the team, and solving real world problems They have a deep understanding of our development philosophy by living it first-hand They build empathy and intuition for all members of the team they will ultimately lead They understand the customer needs and product roadmap by working directly on projects engineers face on a daily basis If there are key teams outside their group that they will be working with regularly, they have also developed a similar empathy with those teams to build trust. They learn how our tech stack truly works (by the way, this is intentionally last here as people often think this is #1) To date, we’ve had a small but mighty group of leaders go through this process, and we’ve certainly learned a lot along the way. Here are a few lessons we’ve learned: Set the right expectations early: One of the biggest misconceptions people have is that we expect them to be a great engineer during this process. In fact, the expectation is that they will be roughly at the level of a new experienced software engineer, but not the “best” engineer on the team. This means that it’s really important to set expectations for the leader up front, but also for the teams they will be managing. Actively discourage imposter syndrome: Leaders often feel a combination of nirvana (“you are actually going to pay me to learn for 6 months?”) and apprehension (“am I going to be judged for my software programming skills?”). There are periods of elation and periods of tremendous imposter syndrome, but as long as the expectations are set and we’re clear on what we consider success, the doubts should fade. Trust the process: One of the biggest questions we wrestled with was the timeframe we had leaders embed for. Initially we started with three months. But over time and several iterations, we landed at five to six months, because we found that, given more time, the process was more successful. It’s hard to have hired someone who has a lot of experience at managing tough situations and then we tell them and all of their future peers that they won’t be doing that role for 6 months, but we need to believe in the process and the outcome. Lean into the power of saying no: One of the things we learned early on is that there are a myriad of pressures that are pulling the individual out of their embed. Their future leadership peers want to pick their brains and ask questions. They have years of experience solving difficult problems and, when they see them, they want to jump at them. In order to resist the temptation, you have to set expectations across the organization, but also give the new leader the power to say no. Re-entry is critical: We’ve learned to make the transition into the leadership role post-embed much more of a focal point. The last month, the embeds shadow more leadership meetings, so that they listen and learn and understand context to help them be successful in their own role. As people rise up through leadership, some strive to stay technical, stay close to the code and make a contribution. And one of the hardest things is to balance that passion that initially landed you a career in CS with the role of being a leader. Add on transitioning to a new company and having to learn a new tech stack without the time or space to do it, it becomes an impossible balancing act. Engineering leaders at HubSpot do both jobs: they are technical leaders and they are people leaders. This is thanks in part to this embed process. So if the idea of spending six months close to the team, doing something a bit scary, but embracing that as a growth opportunity sounds exciting, we want to hear from you.", "date": "2019-09-17"},
{"website": "Hubspot", "title": "HubSpot Partner Spotlight: Miles Ukaoma, Head of Growth Driven Design, Lean Labs", "author": ["Francesca McCaffrey (She/Her)"], "link": "https://product.hubspot.com/blog/hubspot-partner-spotlight-miles-ukaoma-head-of-growth-driven-design-lean-labs", "abstract": "Some of the best perspectives on HubSpot's product come from those who use it every day. In this interview series, we profile HubSpot partners, providers, and customers, and ask their thoughts on what our product team should keep in mind while solving for them, and where the future of the industry lies. In this installment, we chat with Miles Ukaoma, VP of Sprocket Rocket and Head of Growth Driven Design at HubSpot partner agency Lean Labs . How did you first come to work with HubSpot's products? In 2015 we made the transition from WordPress to HubSpot. The captivating promise of HubSpot was that it would serve as a one-stop-shop for all our marketing efforts. I believe many of us in the digital marketing space have created or encountered \"The digital marketing Frankenstein.\" If by some chance you are the exception — picture a marketing tech stack made up of various third-party plugins and applications that organizations cobble together to create solutions for their challenges. HubSpot released us from having to coordinate dozens of tools in our tech stack. After 5+ years in the HubSpot ecosystem, we've been able to streamline our processes with a single record of truth, allowing the entire organization to provide the best possible experience for the brands we have the opportunity to partner with. What does true growth mean to you? Growth means developing the skill set and abilities to accomplish a goal or realize what we desire through dedication and hard work. We don't work with companies who are just trying to make a buck. We work with brands that offer products and services that solve their customers' problems. These are brands that deserve to win, and by helping them grow, they can have a greater impact and deliver results to more people. It isn't easy to grow or optimize what can't be measured, so my approach is a data-oriented one. At Lean Labs, we view ourselves as a growth team that helps deserving brands outsell and outgrow the competition. I believe it's important to note that every organization starts in different places and with varying end goals in mind. Therefore, how we define success needs to be flexible for each brand. That's why we set a quarterly north star metric for each organization. A critical aspect of the north star is that it should be a leading indicator of future success. What's your favorite feature within the HubSpot product? I love all of the A/B and multivariate testing features available right out the box with HubSpot. As a data-driven growth team, we rely on the ability to A.B.C. (always be challenging) our assumptions, beliefs, and the status quo via split test. The ease at which we can set up, monitor, and validate each test makes HubSpot a no-brainer for any brand looking to implement growth-driven design. In addition to being a marketing pro, you're also an Olympian. What's the most important lesson you've taken from that experience into your current career? In a former life, I was a professional track and field athlete sponsored by Adidas. I competed in the 2016 Rio Olympics and earned the O.L.Y. (Olympian) title as a result. For me, athletics served as a practical teacher of Kaizen, or \"change for the better.\" In the running events that I competed in, milliseconds determined the difference between victory and defeat. I learned that minor things make the most significant differences. However, if you focus on the wrong items, your efforts and results will flounder. Do the right thing and do the thing right. The ability to focus on the small details that separate success from failure while parsing the signal from the noise was my most important lesson. Some spectators may view athletic feats and accomplishments as effortless or the result of genetic chance. But for the initiated, we understand that luck is where preparation meets opportunity. In your opinion, what's the most important thing for HubSpot's product team to keep in mind when solving for customers today? It's more important than ever for teams to have everything they need to make marketing decisions on one platform. The more tools you use, the greater the chance that something slips through the cracks. HubSpot should ask, \"How can I help my customers have all the tools they need without having to incorporate other platforms or tools?\" In addition, HubSpot has always been laser-focused on their purpose and whom they serve. This customer-centric view of the market is, without question, one reason HubSpot has done so well. As the product team aims to add new features and tools to the platform, using that customer-centric lens to clarify the purpose of new solutions and precisely whom it benefits will be the most important things to keep in mind. What's one small thing that makes a difference when it comes to choosing what kind of marketing software you use? When picking new Martech, I often ask myself two questions. 1. Does this integrate easily into my existing stack, and 2. Are the added benefits worth the additional friction needed to complete a given task? If the answer is no to either, I tend to look for alternatives to solving my challenge. What about one big thing? Not having to switch platforms every time the organization grows. Having all the content, contacts, analytics, and pre-customer touchpoints in one place is quite a force multiplier as the company grows and scales. Ideas are cheap. Execution is everything. Therefore, I seek out marketing software that allows my team to be more efficient and execute at a higher level. What's one prediction you have about the future of marketing and demand generation? As buyer intent data becomes easier to collect, I believe personalized customer-centric marketing will come to the forefront. At its core, the purpose of marketing is to change beliefs with the intent of a sale. The ability to provide the right message at the right time is paramount to the effectiveness of all our marketing efforts. Our websites can provide us with all kinds of buyer intent data, which can better align with each visitor's goals, pain points, and jobs to be done. As a result, each touchpoint will output more personalized marketing aimed at helpful ways to move prospects through the buyer journey. What do you want to see more B2B software companies focusing on this year? I think many organizations will be asking themselves how they can cut software rather than add new ones. As a practitioner, I feel that integrating one solution with another makes a world of difference in the tools I choose to keep in my software stack. Want more profiles of tech industry leaders? Check out our Name Dropping series . Interested in working with a product team that solves for marketers, salespeople, and developers alike? Check out our open positions and apply .", "date": "2021-03-26"},
{"website": "Hubspot", "title": "BostInnovation Feature on \"The Tech Behind HubSpot\"", "author": ["Edmund Jorgensen"], "link": "https://product.hubspot.com/blog/bid/64598/bostinnovation-feature-on-the-tech-behind-hubspot", "abstract": "We in the HubSpot R+D were excited to see Kevin McCarthy's great BostInnovation article on The Tech Behind HubSpot . Among other matters, he talks about our our technology stack, our 1000+ deploys last month, and--my personal favorite--the blinking red light in the dev area when continuous integration is failing. Check it out!", "date": "2011-05-26"},
{"website": "Hubspot", "title": "How Messing Around With the Facebook and Flickr APIs Got Me an iPod and a Job", "author": ["Nick Pettazzoni"], "link": "https://product.hubspot.com/blog/bid/61419/how-messing-around-with-the-facebook-and-flickr-apis-got-me-an-ipod-and-a-job", "abstract": "\"Mom, I accidentally a job.\" I was excited, and articles of speech were only slowing me down. \"HubSpot. They me a job.\" Who needed verbs anymore? I got a job at HubSpot. Sure it was only an internship with me still being in school and all, but still. How did I find myself in this awesome position, you ask? Well it's simple. I made a web app. I got an email from a CS academic adviser explaining that The HubSpot Web App Challenge was now open to all CS majors. The challenge was a simple idea: have a user connect to their Facebook account, and use their profile information to show them some pictures on Flickr that are somehow relevant. At first I thought it was pretty straightforward. Grab a bunch of interests from their info (movies, music, activities, etc.), and then search for pictures of those items on Flickr. Then I thought about what’s in my info: Tay Zonday, Internets, Ben Folds, and “samy is my hero.” I realized that I don’t really want to see pictures of any of that, and tried thinking of something a little more clever, resulting in a headache and no new ideas. So I did what anyone does when they’re trying to get something done; I went on Facebook. But the headache was making all those annoying words all over my news feed really hard to handle. If only it could be displayed to me as a series of pictures instead. The two real challenges that came up in making TL;DR were finding which phrases in each post to try mapping into an image, and dealing with the Facebook API. I only had a limited time to get this thing working and then look halfway decent, so I wasn’t going to be recreating Watson to pick out important phrases. I just needed something that looked sort of intelligent about it most of the time. Almost right away I found that using each individual word was pretty much useless, both in terms of latency and quality of results. After a lot of trial and error, I eventually settled with splitting posts on any punctuation or instance of a word from a defined set, like “the” or “and” using a regexp. It isn’t the best way to get very accurate chunks of meaning, but then again Flickr’s tags generally give you nothing related to what you searched for anyway. The whole thing quickly turned from making a legitimate tool to “hey this could be pretty funny” when I saw it take “happy birthday pope” and replace it with a picture of a small child dressed as the Pope standing alone in a hallway looking sad. After getting over the frustration of Facebook’s Graph API not handling the offset and limit parameters as promised (or sometimes just not at all) and creating a function to manually pull the “Next Page” URL out of the API call data, I finally had a working app. The two real challenges that came up in making TL;DR were finding which phrases in each post to try mapping into an image, and dealing with the Facebook API. I only had a limited time to get this thing working and then look halfway decent, so I wasn’t going to be recreating Watson to pick out important phrases. I just needed something that looked sort of intelligent about it most of the time. Almost right away I found that using each individual word was pretty much useless, both in terms of latency and quality of results. After a lot of trial and error, I eventually settled with splitting posts on any punctuation or instance of a word from a defined set, like “the” or “and” using a regexp. It isn’t the best way to get very accurate chunks of meaning, but then again Flickr’s tags generally give you nothing related to what you searched for anyway. The whole thing quickly turned from making a legitimate tool to “hey this could be pretty funny” when I saw it take “happy birthday pope” and replace it with a picture of a small child dressed as the Pope standing alone in a hallway looking sad. After getting over the frustration of Facebook’s Graph API not handling the offset and limit parameters as promised (or sometimes just not at all) and creating a function to manually pull the “Next Page” URL out of the API call data, I finally had a working app. I submitted it to the competition, showed it to some of my friends, and went to sleep, thinking it was going to be another toy I made that sits forever in my projects folder with no one to love it. Imagine my surprise when I got an email from Mr. Tim Downs himself congratulating me on my second place win and asking when I could come in to pick up my prize: a new iPod touch. I left HubSpot the next Friday with a new iPod, a pile of swag, and an invitation to send in my resume, and a few days after that I had an internship offer in my inbox. It’s a fantastic opportunity that I never would have had if I hadn’t entered a competition that I never thought I could win. Sure, I didn’t actually win, but I think overall I did. So my advice to all the developers out there looking for an opportunity, as a semi-contest-winner, just try to do it anyway, whether you think you have a shot in hell or not. Your high school guidance counselor may have beaten the idea to death, but it doesn’t make it any less true: You never know what’ll happen unless you try. I thought I might get a few hits to my site an d something to add to my portfolio, but instead I ended up with a new iPod and a job.", "date": "2011-03-23"},
{"website": "Hubspot", "title": "Good Brainstorms Drive Outcomes, Not Outputs", "author": ["Chris Miller (He/Him)"], "link": "https://product.hubspot.com/blog/effective-brainstorming-tips", "abstract": "Brainstorms are fun and essential for almost every product team. They can get everyone in the team involved, they help fill out your backlog, they’re the things that get creative-minded folks out of bed in the morning. But there are many ways teams can let brainstorming sessions get in the way of progress. Brainstorms can be noisy, and without active facilitation, they’re not always inclusive to all members of the team. They can be emotional (people tend to love their own ideas) and without the right structure, they can quickly tailspin into being counterproductive. Everyone has experienced at least one brainstorm where the team struggled to decide on the next steps and then defaulted to a vote, nervously hoping that a 51% majority would reveal the right thing for the team to build. But by far, the most dangerous form of brainstorming is when teams rush to brainstorm the wrong thing and jump into solutions before they fully understand the problem. Skipping the problem to think of solutions usually means the team is focused on outputs, rather than outcomes. What you build and ship is an output, but the only thing your customer needs and cares about are outcomes . The first step in delivering outcomes is understanding what problem stands in the way. At HubSpot, the Growth Team’s responsibility is to convert someone who signs up for our free tools into a delighted customer by helping them unlock the value of the HubSpot platform, no matter what their software budget is. Rather than diving right into a discussion about all of the things we could possibly build to achieve this (aka outputs) we shelve blue-sky ideation in favor of focusing exclusively on understanding what problems exist in the user experience today. Why? Simple: getting clarity and alignment on the problem yields higher quality solutions. If someone told you they were injured and needed help, it would be difficult for you to know whether they needed crutches or a bandage unless you had more information about what the issue was. It’s the difference between “ready, aim, shoot!” and “ready, shoot! Did we miss? Shoot again!” Here are some key themes for guiding a conversation around problems, specifically the friction standing in between your users and the desired end state. I present to you the three D’s: Discoverability Desire Doability Discoverability Can your users find the action they need to take to be successful with your product? This is a great first question in the problem discovery process, yet simple adjustments to interface design are something teams may overlook in favor of chasing complex solutions. Jason Fried has a great framework for understanding discoverability hierarchy called The Obvious, the Easy, and the Possible . Oftentimes, the problem your product has is that there’s an important task or action that should be easy or even obvious for your customer to locate, but for some reason, they struggle to do so. Prioritize understanding if this is a pothole for your customers before moving on to other hypotheses. Validate what your users are struggling to locate, architect solutions from there, and if they work, you’ll have confirmation that you’re on the right path. Some helpful tips and launch points: Make sure that you have instrumented all page and button views in your analytics tool of choice and then study this data first. If the vast majority of users don’t see the button or the page the button is on, you could have a discoverability problem. Check your pages on multiple devices and browsers. If the content is below the fold, then it’s possible people aren’t seeing it. Institute a quarterly cadence of usability benchmarking to help identify areas where users are struggling. Task-based usability is key to answering your discoverability-related hypotheses, and the same goes for desire and doability, as you’ll see below. Desirability So let’s assume the action your users need to take in order to be successful with your product is easy, maybe even obvious, to locate, yet they still don’t take the action. Well, the truth is that the people who use your product can read between the lines. When we put that big button in our navigation bar, users are well aware that it’s because we, the product team , want them to take that action. Perhaps the reason that no one is clicking it is that they, the users, don’t want to. If you’re wondering why no one is clicking on your big button, your users may lack desire. Spending time with your team brainstorming hypotheses about why users don’t want to do the thing you’re asking them to do is time well spent. So much of growth work is manufacturing motivation. Come up with some ideas about why users don’t want to do the thing, talk to them to validate whether you’re on the right track, and then figure out ways to fix it. Some tips to try Don’t look past the words. Content testing is important and getting your meaning and message right can often help manufacture desire from your users. Check your funnels. If people are seeing it and not clicking, don’t spend weeks testing button colors. In your usability sessions, find out why users don’t want to click, in their own words. Maybe they aren’t ready yet? Maybe they don’t care about it at all? Maybe they’re not the person with the permission to do the action and they need their boss’s approval? Whatever it is, go talk to people and find out. Doability Ok, so you’ve made the button obvious, you’ve confirmed users are clicking it, but they’re not finishing the flow. Maybe the action is just too damn hard to complete. Understanding your product’s usability issues and addressing them is critical to growth ⁠— your team should care about this as much as they think about shipping new features. Just think: if your highest-intent users and customers are struggling to do basic things in your product, how much money are you leaving on the table? Take the time to understand which flows are causing your users pain. Some best practices In your usability sessions, observe people trying to complete the task in your product, unmoderated. Even if you’re 1000% sure your product is easy as pie and flawlessly amazing, humor those around you by putting it to the test in a usability session. The results can be unsurprising at best and downright mortifying at worst when you see people struggling to complete a task. But that’s how you make your product better. Embrace the cringe. Cut out the cruft. Eliminate features or steps that are unnecessary or force users to provide data you don’t do anything with. While it may seem small, adopting this method has helped our team significantly. Focusing on problems first has helped us be more efficient with our meetings and more effective in our execution . And most importantly, it’s helped us become an outcome-driven team rather than an output-driven one.", "date": "2020-05-13"},
{"website": "Hubspot", "title": "Book Corner: Hadoop, The Definitive Guide", "author": ["Dan Milstein"], "link": "https://product.hubspot.com/blog/bid/12078/book-corner-hadoop-the-definitive-guide", "abstract": "Just finished working my way through O'Reilly's new Hadoop offering , written by Cloudera's Tom White.  Overall, I recommend it very, very highly.  He does an incredibly effective job of moving back and forth from specific, detailed advice (e.g. per-node memory allocation recommendations), to high-level descriptions of how MapReduce works and how to write applications which make use of it. This is the sort of book that, at their best, O'Reilly does better than just about anyone else: full, rich info about a key piece of emerging technology.", "date": "2009-07-27"},
{"website": "Hubspot", "title": "Monitoring Driven DevOps", "author": ["Jeremy Katz"], "link": "https://product.hubspot.com/blog/bid/65871/monitoring-driven-devops", "abstract": "Last week, I attended the Velocity Conference on web performance and operations out in California. The conference itself was really good; a ton of good talks on topics like post-mortems, building systems for failure, failures that people have hit, how to successfully embrace developer ownership of product operations. Basically a lot of the things that we embrace and encounter every day at HubSpot. On Tuesday night, there was a set of Ignite talks. If you've never been to an Ignite talk, the idea is that you have 5 minutes to give a talk. Pressure, right? Well, to make it more fun, you also have 20 slides and they auto-advance every 15 seconds. Okay, lots of pressure. And somehow I talked myself into submitting a proposal which was accepted so I then had to write a talk. Just Too Late View more presentations from katzj . As with many of the Velocity talks, mine was a story. About six months ago, I shifted to running a team that is responsible for automating, standardizing and improving the infrastructure that powers HubSpot. Part of this has involved a bit of a mindshare shift from that of just being a developer to caring a bit more about the operations side of things. In doing so, I've noticed some differences that have made me feel a bit more like the work I'm doing is reactive and just a little bit too late. Part of this is because the goal of operations work is that nothing goes wrong... this means that you build something and nothing happens! So you don't get to some of the preventative work you'd like. But then, inevitably, the bad thing occurs. And then you do some sort of post-mortem. One of the things we've been finding in a lot of ours is that we could have found the problem faster instead of having our customers report the problem. So a lot of our corrective actions end up being things which would allow us to do so: alerts in our monitoring system, automated testing and similar things to find out sooner. From here, I talked a bit about how we fared with the Amazon EBS problems a couple of months ago. Overall, we fared pretty well. But there were some areas where we had problems. One of these was that we had a database which was not being backed up according to our standards. We were lucky and it wasn't a lasting problem. But as part of the post-mortem, I went ahead and backed up the server. I then put a monitor in place to ensure the server was backed up. And then I generalized it out so that it applied to all of our servers. And this is when we discovered that there were a few other servers on the brink of disaster. So then I backed them up. Coincidentally, my team was working on the automated build process for our database servers of the future, so we went ahead and built it into that process so that servers would get it automatically in the future. But I had a little bit of an inspiration here. As a developer, I would do test driven development; I'd write a unit test and then get my code to work to make the test pass. As an infrastructure developer, I was doing monitor driven infrastructure development; I wrote a monitor and then made the infrastructure match that state. Pretty powerful; I could do it with our old stuff or with new things we were building. And adding a monitor to start with is cheap; from there you can make easier value judgements on what the cost is of not making preventative improvements. You do have to be careful that your monitors aren't noisy in the process, but it's working. I finally don't feel like I'm always behind and getting to things just too late. Instead, I'm getting to things before they explode which in the end means a more stable system, happier developers, and happier customers using our product.", "date": "2011-06-27"},
{"website": "Hubspot", "title": "Modern Java at HubSpot", "author": ["Whitney Sorenson (He/Him)"], "link": "https://product.hubspot.com/blog/modern-java-at-hubspot", "abstract": "HubSpot’s core technology stack has been through a lot of change and iteration. What started as a simple content system based off a C# framework has evolved into a broad application platform. Today, our tech stack is made up of hundreds of services and dozens of full-fledged products. We’ve experimented with a lot of languages and frameworks along the way: We’ve built services in Go, Scala, node.js, and Ruby, and launched major product initiatives in Python and Java. Looking ahead, we need a tech stack that will help us scale. We need to be able to rapidly build services and test out new products and features, quickly onboard new engineers, and allow easy collaboration across teams. That’s why Java has become our language of choice at HubSpot. Java has come a long way; it used to slow development down with clunky frameworks, endless XML, and over-engineered libraries. But it’s evolved into a modern platform that we think is perfect for building fast, reliable services and web apps. Here’s a look at why we’ve adopted Java and some of the key benefits that I think make it right for us. What We Like About Java: The Fundamentals I’ll get into what we like about building Java for the web, but first, here’s a snapshot of some of its core language features and fundamentals we’re leveraging: The Java Virtual Machine (JVM) is robust and outperforms many dynamic languages so we don’t have to rewrite sections of code in other languages to be performant. Java has powerful library support for managing threads, collections, and network connections. That means we aren't limited when adding additional code and libraries to extend and run inside our services. We can add threads that help us monitor and debug systems. And when we want to communicate over new protocols or talk to new services, we can easily add support via a rich networking stack. Modern Java IDEs have powerful and simple debugging capabilities, auto code-completion and refactoring, trivial introspection of core and third party libraries, and code generation. A rich IDE that allows developers to quickly understand code and to use new libraries without context switching into browsers is magical. Java does its own garbage collection. We like the fact that Java is high-level enough to perform some of the mundane and less critical tasks for us. Java is widely used. Many engineers are familiar with its syntax and libraries, and there’s a big community providing high-quality open-source frameworks. Java Continues to Evolve for the Web On top of its fundamentals, tooling, and community, Java has continued to evolve over time. We’ve seen lots of valuable changes in official releases and from the ever-growing (and often open-source) Java community. Some of these updates have drastically improved the way we write Java: Java 8 introduced a slew of new features, like lambdas, making the language more functional than ever. We like Java but we also like light-weight and expressive code, something Java has never been known for. As Java has changed over time, it has removed unnecessary verbosity without compromising core language features. Modern Java frameworks make it easy to build simple REST and JSON-based services rapidly, while open-source libraries like Guava, Guice, Hystrix, and DropWizard have made programming in Java more friendly and powerful. Companies like Google, Netflix, Facebook, Twitter, and HubSpot have made strategic investments in Java and have open sourced much of their foundational work. Building a web stack on Java is natural and lets you stand on the shoulder of giants. High-quality open-source distributed systems that power much of the internet are written in Java. These include Elastic Search, HBase, Hadoop, Cassandra, ZooKeeper, and OpenTSDB. How We’re Using Java at HubSpot Over time, we’ve built an ecosystem around Java that’s become a competitive advantage for our engineers, and many of Java’s advantages are amplified by our scale as an organization. We don’t serve templated HTML out of Java services. Instead, we produce JSON that is consumed by other Java services, internal and external clients over HTTP, and our JavaScript web applications. JavaScript is our dynamic language of choice and powers much of our front-end web stack. Many of the distributed data-stores we use at HubSpot are written in Java and get top-level client support as a result. It also means: Our engineers are able to quickly and easily grok the library code for these systems, providing patches and deeper insight into operational issues. We are able to extend these systems, by providing our own extensions of the built-in clients. For example, we were able to easily fork and build the HBase client code to add support for Hystrix, an open-source library which improves fault tolerance of distributed system clients. Because we are able to leverage a single JVM for both our application stack and systems, we can share a lot of our tooling and operational knowledge: analyzing stack traces, thread dumps, and heap dumps from these services is already part of our core operational competency. We take advantage of annotations, static compilation and types to write self-documenting code so that: Engineers don’t need to find or read out-dated documentation, because the code is readable and more importantly - navigable - in the IDE. We can refactor critical code paths without using find/replace and regex. This makes it easier to keep code named appropriately. Engineers can create and ship new services with very little code and configuration. It’s easy to provide common frameworks and abstractions in Java - the building blocks our engineers, and especially new hires, take advantage of - to build reliable and modern systems. We have clean, modern libraries for tasks like making HTTP calls, delivering distributed configuration to services, and performing authentication and authorization in services. All of these libraries expose simple APIs that can be understood through the IDE, often without reading documentation, examples, or drilling into multiple abstraction layers. Since we don’t have to deal with the overhead of a polyglot environment, we only need to provide a single set of high-quality components, which we have an incentive to continue to invest in and improve. And as our team and application evolves, our common Java platform allows us to maintain development speed even as engineers move between systems and teams. By building microservices in Java and combining great libraries with sophisticated open-source distributed systems, we’re able to scale our organization and our product. We’ve been able to avoid the old pitfalls of the language by using modern Java and pushing HTML and templates into the client, keeping our backend code nimble. Even engineers who were initially skeptical about a Java-only environment have come around. When we recently surveyed the team about our infrastructure, one said that they “really enjoyed writing code in Java” for the first time thanks to our libraries. Another said they “came in pretty skeptical of Java” but have been “converted by the maturity and niceness of the tooling in place.” Ultimately, we’re faster and better as an organization because of Java, and it’s integral to a tech stack that our engineers love building on.", "date": "2016-01-20"},
{"website": "Hubspot", "title": "The Metric Watched by Top Startup Growth Teams", "author": ["Dan Wolchonok"], "link": "https://product.hubspot.com/blog/the-metric-watched-by-top-startup-growth-teams", "abstract": "It is easier to create technology products today than it has been in the past (and is only getting easier.) With more entrepreneurs building new products, the competition for people’s attention is accelerating. I used to think that building a great product would result in press and demand for your project; but I now know that is naive. Even if you build a wonderful product, it doesn’t mean that people will flock to use it. You need to be maniacal about understanding how many people are using your features, and improving your metrics over time. Dave McClure’s pirate metrics are an invaluable model for analyzing SasS metrics, but little has been written about them. Each of the metrics are not all immediately valuable and actionable as you first start building a product, but one of the ones I think that is valuable (and critical to start measuring) from the very beginning is an activation event. What is an activation event? I like the KissMetrics definition of activation : Activation is: The first point where you deliver the value that you promised. Activation Examples Some examples of activation (I don’t know if these are their real activation events): Dropbox: Your first file is backed up from your computer into the cloud Facebook: You connect with 7 friends within your first 10 days Stack Overflow: Your question is answered Instacart: When your groceries are delivered for the first time Instagram: Someone likes one of your photos Key Elements of An Activation Event There are key elements of an activation event that make it so valuable: It happens once.  Once someone has activated, they cannot activate again. This defines cohorts (daily, weekly, monthly) analyzed over time. It represents real value for users. It’s shouldn’t be a “bullshit metric” . It gives you a sense of how efficient your acquisition funnel is / how well you do at getting people to see value in your product. This is the activation rate. Not everyone who signs up for your service is going to be able to use it/get value from it. Over time, you should be optimizing for the percentage of people who can use your product, and then how many of these people come back and use your product in the long term. I have been using MixPanel to do this in my time on the Sidekick team , but any good analytics tool will be able to give you this type of insight. Measuring impact based on activation Some of the things that we track based off our activation rate: What is our overall activation rate? What is our overall activation rate by channel?For example: Paid Acquisition (platform, campaign, audiences), Content Marketing, Social Channels, SEO, Virality What is the time it takes someone to activate? Can we decrease this time? What is our retention of activated users over time?If a user doesn’t activate, I highly doubt they’ll keep using your product over time. By focusing on cohorts of activated users, you can optimize towards a ceiling that reflects an attainable goal How does our activation rate improve over time? When to start tracking activation When you’re first building your product, you should be speaking with all of the people that are using it. Once you get past those first 100 users, it’s hard to speak with everyone. That’s when having an activation event will give you an indication of whether people saw value in your app, and whether they’re likely to want to continue using your product. Even in your earliest days, it’s important to have an idea of what you expect people to do in your app and how many of them accomplish that task. Since it is a percentage, it is valuable when you’re the size of Facebook or for your first 1,000 users. As you grow, you will learn more about your users, your business, and how to optimize for success and activation over time.", "date": "2015-07-06"},
{"website": "Hubspot", "title": "How We Built Our Stack For Shipping at Scale", "author": ["Mike Champion (He/Him)"], "link": "https://product.hubspot.com/blog/how-we-built-our-stack-for-shipping-at-scale", "abstract": "We've designed our team structure, development processes, and technical architecture to promote strong team ownership and iteration velocity. HubSpot makes a growth stack platform (marketing, CRM, and customer success software) trusted by more than 64,000 customers to power their businesses. They rely on our SaaS platform to host their website, blog, landing pages and forms, collect web analytics, manage their contacts, store prospecting data, deliver marketing emails, and more. The capability is relatively broa d -- each functional area has many companies that focus on just one vertical -- and is growing as we continue to introduce new products. Our stack is not only a function of building B2B SaaS offerings, the company's stage and size, but also the cultural values that we want reflected in our products and organization . Small, autonomous teams are the core Each team is typically comprised of a tech lead (TL) and two developers working with a product manager and designer. The teams are kept small to eliminate scale challenges and communication overhead (e.g. very few meetings). It also allows the tech lead to be deeply technical and product-focused as well as spend time coaching the two developers they work alongside. (There is a small number of people who support the TLs by focusing on organizational issues and structure.) This unit owns a functional part of the product (ex. \"Social Media\") and is chartered to make meaningful progress for its customers . (Around this team are others that provide services for user testing, data management, reliability monitoring, etc. to allow them to focus on solving customer's problems.) We have a frontend team and a backend team for any given area. This structure is informed by many feedback loops: usability testing, direct customer interactions, usage tracking, customer support and other stakeholders. The team decides what ideas to build, how best to implement them and own their ongoing operation. If something is broken they own fixing it -- there is no QA team to off-load responsibility to. If the user flow is confusing then they own iterating on it. When customers are excited about what they have shipped they get the kudos. The overall result has been to allow for rapid progress and harness developer passion for improving customer's experience. Often as teams grow individual contributors are forced into people/project management - this structure allows for technical mentoring while minimizing the number of full-time people managers. The primary challenge in this model is driving design and technical consistency. Conway's Law poses an obstacle that requires teams to communicate effectively to avoid silos and diverging. There is a strong set of peer communities (ex. PMs, Java back-end developers) across product teams that work to be on the same page. Initiatives that are cross-cutting are sometimes harder and often lead to scenarios of \"eventual consistency\" where teams evolve toward a similar goal over time. Microservices The HubSpot products are comprised from 1200+ different web services, and dozens of static front-end apps. Together these microservices form the products our customers buy. Most web services are written in Java using the Dropwizard framework, and the front-end largely uses Backbone and React in CoffeeScript. A single team will likely own several se rvices. The exact scope of a service ranges but having more than ~5 actively contributing developers can lead to coordination overhead. Services communicate through RESTful JSON APIs or leveraging a messaging system like Apache Kafka. This architecture aligns well with having clear ownership and quick iterations. There are over 9,000 separately deployable units, that can be scaled independently. Each family of services is owned by a team so the appropriate people are notified of service problem. It has facilitated scaling the organization as there is a pattern for forming new teams and spinning up new services. There is additional complexity to understanding how a distributed architecture is performing and managing configuration complexity (ex. services using different versions of a shared library). For smaller teams this trade-off from a monolithic app (ex. Rails) may not be advantageous until a tipping point in the amount of code or number of developers. Approaching continuous delivery The goal of shipping frequently is first and foremost to increase our rate of learning . It allows for getting rapid feedback from users, data points on the correctness and scalability of the code, and deliver value to customers. To allow small teams to focus on improving the product we've developed many internal tools that make shipping code simple and provide a safety net. Any commit to our hundreds of GitHub repos will trigger a build in Blazar, our open source build system that utilizes standard buildpacks for different frameworks (ex. Java Dropwizard, static apps, etc). Assuming all tests pass with a few clicks a web-based deployer puts that build on the relevant hosts. Initial deploys of a build are put on a shared QA environment which aims to mirror the production environment as much as possible (except in scale). Only those builds deployed to QA are eligible to be deployed to production. The goal is for a \"Heroku-like\" experience where developers have zero friction to pushing small changes frequently, and shielded from needing to know the exact steps being performed. Deploys Core to the goal of small, safe deploys is feature flags (or gates). As a feature develops over time it can be safely merged into primary behind a flag in stages. This separates deploying code from releasing the feature. The primary advantage is that the developer controls who sees the new functionality, while ensuring that it is technically sound in production. The typical order might progress from just the developer, to her team, to customers to a beta group, and then all customers. Depending on the scope of the feature that may happen within hours or weeks. At any time the feature can be hidden again without another deploy. No longer should developers have to wait weeks to merge branches, or pray when they deploy a large set of changes to all customers (especially on a Friday at 5pm). The downside is some additional code complexity -- effectively extra \"if\" statements -- and a clean-up task after a feature is fully released. It is a simple concept that has been around for years but still appears to be in less use than it deserves. The only way to feel comfortable deploying frequently is to have insight into state of the running service. In addition to off-the-shelf tools like exception tracking and tracing tools we've invested in ensuring every service has built-in health checks with reasonable defaults. An internal project, dubbed \"Rodan\", instruments services to collect standard metrics (ex. requests/sec, server errors) as well as developer-defined ones. Each service is part of a family that has configurable alerts and PagerDuty integration to let teams set appropriate thresholds. It has struck a useful balance by having developers own their alerting rules, while avoiding swamping inboxes with email alerts. Having a distributed architecture means that recording application metrics are often the best way to see what's truly happening. Our applications capture a lot of runtime metrics (via Dropwizard Metrics , the JVM, etc). To visualize and alert on those metrics HubSpot uses SignalFX. Each type of deployable has a set of standard metrics, as well as developers can create application specific metrics. We use additional tooling to analyze application traces. Mesos, singularity and beyond HubSpot has long been a heavy user of Amazon EC2 for server hosting. More recently we've taken advantage of Apache Mesos and we use Kubernetes to manage our large EC2 clusters. In conjunction, they have driven significantly higher density per server to reduce cost. Previously most services provisioned instances in isolation because coordination was too complicated. Even more importantly than cost changes has been the ability to insulate developers from details about any particular instance. Now the platform can handle problems like instance failures or availability-zone issues that previously required developer intervention. Mesos has been adopted by companies like OpenTable and Groupon but has required significant investment to see the benefits of this new platform. As we invest in our stack we look to solve challenges programatically with small developer teams, rather than larger numbers of people in specialized operations roles. This stack has evolved considerably over time as HubSpot has grown, and we expect that to continue. In particular as we look to scale our existing products, and build completely new products there will be a series of significant challenges to solve. Hopefully the principles behind how we choose to build software will lead us as we tackle them. Note: this post originally appeared on StackDive , covering the technology behind Boston startups.", "date": "2015-03-17"},
{"website": "Hubspot", "title": "The Programmer's Dvorak keyboard layout", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/6190/the-programmer-s-dvorak-keyboard-layout", "abstract": "Does anyone use the Programmer's Dvorak keyboard layout ? The other day we interviewed a developer candidate who uses this layout, with some of his own modifications.  We have another guy who works at HubSpot who is trying to learn this layout, and yet another guy, not a developer, who uses the \"normal\" Dvorak layout . I put \"normal\" in quotes because it seems highly unusual.  I hadn't heard of anyone even trying to use this layout on a daily basis in several years.  Is that common?  Do you have a lot of people in your organization who use this layout? If you do use the Dvorak, or Programmer's Dvorak, keyboard layout, what would you say your productivity increase is?  Have you measured it in some typing or other tests ? I wonder if it's mostly about the cool factor, about being different.  That has value, for sure.  It generates fun debates and discussions.  It makes for easy opportunities to play a joke on someone.  But is the productivity improvement there? Technorati, here's your claim code: ruftqj38ng", "date": "2009-06-27"},
{"website": "Hubspot", "title": "Video: Latest Developments: Dispatches From the HubSpot Product Team", "author": ["HubSpot Product Team"], "link": "https://product.hubspot.com/blog/event-latest-developments-dispatches-from-the-hubspot-product-team", "abstract": "Every week at HubSpot, we put on an internal event called Tech Talk, where our engineers share all the latest about what they’ve been up to and their peers get a firsthand look at the future of the HubSpot product. Now, you can go behind the scenes, too. In this video, you’ll learn about the latest HubSpot product updates in FinTech, Security, and Data Infra , and how we built them, straight from the engineers themselves. Get the inside scoop on our engineering principles, our latest projects, and what's coming next. Talks: \"Unique database auto-increments across data-centers\": The journey to creating a performant and reliable external auto-increment system for cross data-center MySQL installations Olga Shestopalova, Senior Software Engineer on the Data Infra SQL team \"Protecting your customer data at scale\": The key pieces to protecting your customers' data at scale, and how to use them properly Jakub Derda, Tech Lead of InfraSec Privacy and Compliance teams “Demystifying the magic of Google Guice”: How Google Guice handles dependency injections and what its annotations are really doing Caroline Hsu, Software Engineer on the FinTech Buying Intelligence team", "date": "2021-04-07"},
{"website": "Hubspot", "title": "A Human Approach to Product Content", "author": ["Elizabeth Dunn (She/Her)"], "link": "https://product.hubspot.com/blog/a-human-approach-to-product-content", "abstract": "At HubSpot, we’re working to build a more diverse and inclusive place to work. We want to make sure that HubSpot is the kind of place where everyone can do their best work. We also want to make sure that our software — which thousands of companies use in their own workplaces — fosters an inclusive environment for our customers, too. Our customers themselves are very diverse, and it’s important that the HubSpot software reflect and support that diversity, too. Small business owners from all over the world use HubSpot. So it’s on us to infuse our product with a spirit of diversity and inclusion, and the content in our product plays a big role in that. This post explores some the ways we’ve approached creating a more inclusive experience with product content design. It’s always a work in progress, and we’d love to hear from other teams who are working on this sort of thing, too. If anything here strikes you as insufficient, incomplete, missing, or off base, please let us know. That’s how diversity and inclusion works best, after all. First Principles We’ve got a set of unifying design principles at HubSpot that guide our work on the User Experience team. They were originally formulated as part of the Canvas design system project, and they’re worth a read . One of the first principles we identified is that our designs must be human . At first glance, this might seem too vague a directive to be helpful at all. As we all know, lots of design guidelines fall into this trap — just offer some aspirational hand-waving, stick it in a frame on the wall in your office, and then go on with your day. But this one, I think, is actually practical and specific, when you dig into what it really means. What does it mean to create language and imagery in the HubSpot product that’s human? That fosters joy? That resonates across cultures? First, it’s usually helpful to think about what it is not . Content that isn’t human would be jargon-y, robotic, tone-deaf, and abrasive (among other things). So we don’t want to do that. But that’s assumed. That’s just table stakes. Don’t be a jerk is a reasonable place to start when creating UI content, but it doesn’t exactly go far enough. We could start by looking more closely at the “global” part of what it means to be human. How can we create product content that will appeal and offer value to as many members of the human family who might be using our product as we possibly can? There are lots of ways, but they all boil down to variations on one basic theme: Try not to present the privileged, tech-savvy, wealthy, without disabilities, white, cisgendered, anglo-centric male experience as “standard” and everything else as “other” or “diverse.” Seek ways to place the “other” in the center of things instead. We recognize that to be human means a lot of different things. And we put that principle into practice in all sorts of ways. Clear and Simple According to another one of our design principles, our work must be clear . HubSpot Product Designers take great pains to make sure our UI is straightforward and easy to use, and our UX writers make sure that the language we use in the product is clear, simple, and as nontechnical as possible. Not only does this create a more helpful experience for new users and those of a less technical bent, but simple, plain language also has been shown to increase comprehension, usability, and satisfaction even in those who are highly technical and adept. From an accessibility point of view, users who rely on screen readers to use HubSpot are far better served when the UI content they hear is short, simple, and free of unhelpful (to the sight-impaired) visual cues. Plain language is important from a usability point of view, but it’s also important for inclusion: think about all the people who are non-native English speakers, using our English UI, and those who are non-native French, Spanish, German, Japanese, and Portuguese speakers using those interfaces, too. We live in a world of continual migration and mass movement, a world of first-gens using our kind of technology for the first time, a world of all kinds of people trying to use our software in difficult situations that complex language would only exacerbate. Even native English speakers benefit from plain language — a very sizable chunk of the population has basic or below basic English proficiency, and many of these hail from less privileged socioeconomic backgrounds. Because we’re serious about diversity and inclusion in the product, we try to make using the product easy for them, too. And remember, this is not about dumbing interface content down: Writing in plain language is good for all users. Nobody ever complained that an interface was too easy to read. It’s important to keep in mind that product content is much less about words than it is about the meaning we’re trying to convey . We have content components in the UI library that are constructed and ready to use for simple, repeatable patterns of content, such as form field prompts. But when the value that a user will gain by using a feature is complex or difficult to convey, that’s when our teams call on the UX Content Design Team for help. Working alongside a UX writer can supercharge our users’ comprehension, adoption, satisfaction, and usage. UX writers do this by applying the rules of the HubSpot style guide . They know all the idioms to strip out (and which ones to use), the plain language equivalent of jargon, the more straightforward turn of phrase — all elements of how to convey meaning in an inclusive way that a non-writer might struggle for hours to come up with. Does that mean you need to strip your product content of any personality at all? I hope not. Fun, idiomatic expression has always been a hallmark of HubSpot’s product content. People have always loved our quirky sense of play. So do we propose to create product content that’s completely free of idiomatic expression and our trademark sense of whimsy and fun, and give up that essential “HubSpottiness” we’re so beloved for? No, we do not. Within the bounds of writing clear, comprehensible content, there’s always scope for including whimsy and fun, when the situation warrants it. Whether or not it translates into other languages — or should — is another question, and it’s one we rely on our localization team to help us address. Global First We try not to put any content in the product that can’t be easily translated or localized. That includes any icon that relies too much on text (or an abbreviation) to convey meaning, or any illustration that features text. Icons and illustrations that rely on text to convey meaning would either have to be reproduced and translated into the five different languages we currently support, or we’d have to shrug and just say those users will have to adjust. Which is the opposite of inclusive, really. So we try to avoid it. We also avoid using video or static images that rely on screenshots to convey meaning. Whenever we rely on screenshots or screencasts, that imagery or video needs to be reproduced in five different languages before it will work. That’s fairly expensive and time-consuming, so we try to find alternatives if we can. It’s not always possible or even preferable to avoid it — after all, sometimes a screenshot or video screencast is exactly what a user wants and needs, and in fact some markets prefer video — but it needs to be planned for, and the costs and timeline of a global-first production fully accepted and understood. Just shrugging and accepting the idea that a non-English-speaking user is going to have to use a translated UI with an untranslated video stuck in the middle of it — a video that we put in there precisely because we believe the user needs to watch it to really get value or proceed — just isn’t good hygiene. It’s deeply non-inclusive, as a matter of fact. We also avoid using metaphors (visual and written) that are specific to just one culture or class. So for instance, we avoid using phrases like “knock it out of the park” or “hit a home run,” even though these phrases are pretty common in North America, because they’re just not going to resonate in all places outside of the US. Not because people will be offended by a reference to baseball, but because they won’t be as familiar, so the meaning won’t be as clear. All of our product content is translated by a top-notch team of localization specialists, and those specialists are empowered not simply to translate content, but to adapt (or “transcreate”) content so that the voice, tone, word choice, metaphor, and so on is appropriate for their market, country, or region, and delivers what the typical business user expects and wants to see there. This focus on adaptation or transcreation comes in especially handy when cultural norms differ across locations. HubSpot’s source language (English, North American) is, on a formal-to-informal scale of 1-10, usually about a 7.5. We’re pretty informal, but not wildly so, as a rule. And that informality expresses something important to us as a company, about how friendly and approachable and human we are. But the same level of informality in, say, Germany, would not come across as friendly and approachable; it would come across, I’m told, as immature or juvenile. Almost clownish. Obviously, that’s not the brand voice we want to convey, so our German localization specialists have established their own point on the scale — say it’s a 5 or a 4 — so that they can achieve a level of informality that gets across the same intended meaning that our significantly more informal voice gets across in the US. When our teams work with UX Content Designers, their content will, by nature, be more global-friendly and easier to localize, and this benefit multiplies for every language we choose to support. When content is consistent and clear, we pay less to adapt it, and we take less time to bring that content to other languages. Inclusive UX Content habits can help a company save significant time and money over time. Inclusive of all When you use HubSpot, you’ll encounter a number of illustrations — they exist to represent concepts, direct your attention, or even just add a bit of fun. We pay particular consideration to how we portray humans in illustration. Sue Yee , our product illustrator, tries to ensure that the people we represent in illustrations are diverse in appearance, and that these different types of people are represented doing many different things (for instance, a person of color doing the talking while others listen, a woman in a wheelchair at an executive desk, etc.). These decisions are often subtle, but they’re massively important in fostering a sense of inclusion in our global, diverse user base. We also have specific guidance in our product voice & tone guidelines about how to use language that’s truly inclusive. We encourage the use of \"they/their\" as a singular, non-gendered pronoun. We discuss how to avoid using humor that deprecates others or is at the expense of any class/type of person, how to avoid using metaphors and idioms that exclude or assume a certain class, culture, ability, age, other privileged status, etc. Any technology is going to reflect the life experience — and the implicit bias toward that life experience — of the people who build it. So we have to watch out for language and imagery that assumes or privileges the life experience of a tech worker in Boston or Dublin (where our product teams are mostly located). Everything from our tone of voice (we as HubSpotters are fairly informal in writing, as a rule, while our global user base frequently skews much more formal) to our cultural references (you’d be surprised how often our language is influenced by memes) to our idiomatic expressions (oddly enough, “Heads up” is not a universally supported way of saying “This is important”). We’re continually auditing and cleaning up our product source content (recent work included an effort to edit any error messages that started with “Uh oh!” and “Whoops,” both of which can come across as infantilizing or at least condescending, for example), and there’s always more work to be done. We are, after all, a pretty small team, and our product is large. So we’re always looking for ways we can automate and scale the effort to make our product content inclusive and world-class. Automated Editing We recently built an automated editor bot, known as Bethbot, which relies on some fairly comprehensive rulesets to flag non-inclusive language and suggest alternatives (as well as about a dozen other rulesets). Sexist, racist, and otherwise insensitive language can be hard to recognize and fix in your own writing (this goes for professional writers and editors, too), so it’s incredibly useful to have an automated bot to watch out for these things for us. Any HubSpotter can access Bethbot in our internal Slack workspace, as an internal web app, or — our favorite — a handy Chrome extension. Product teams can also opt in to enabling the bot in their Github repo as a final failsafe check. We’ll never be done working to create more inclusive content across our whole product. Our team is still learning how to design content for those who use screen readers, especially when it comes to illustration and video scripts. We’re actively trying to learn more (and apply what we learn) about ways content can do a better job of serving those with different abilities of all types. While we strive to create content that serves our whole user base, we’d love to get better at finding out just who those people are. It’s a bit of a moving target, thanks to our rapid global growth. So we’re always seeking out and learning about new audiences and cultures and segments that we need to solve for. If you have any ideas about how to write more inclusive content or thoughts about creating content that’s more accessible and clear, please let us know in the comments.", "date": "2018-11-02"},
{"website": "Hubspot", "title": "\"The Age of the Platform\" book", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/79696/the-age-of-the-platform-book", "abstract": "I recently (as in yesterday) learned that HubSpot is mentioned and discussed in a new book by  Phil Simon, \" The Age of the Platform .\" The book explains and elaborates on many of the principles we often cover here, on this blog, like how open platforms that empower 3rd parties to innovate offer far larger long-term benefits to customers. There are simply so many smart people out there in our flat world that if you're not empowering them to build stuff, you are missing out on huge potential wins.  With standards for APIs, high-speed networks, and other technology infrastructure pieces becoming available to more of the world, the talent pool is bigger than it's ever been. The book talks about how different companies, like Google, Apple, Twitter, and Facebook, take advantage of the above to improve their products, delight their customers, and grow their businesses. It's a good read, recommended even without the HubSpot part, which is short. By the way, as long as I'm issuing out recommendations, I also want to give a shout-out to Sam Ramji's excellent presentation on Slideshare: \" Amundsen's Dogs, Information Halos, and APIs. \"  Very worth clicking through, although it's a bit long. Amundsen's Dogs, Information Halos, and APIs", "date": "2011-12-09"},
{"website": "Hubspot", "title": "Mobile Rewrote the Rulebook for Software. B2B Is Still Catching Up.", "author": ["Martin McKenna (He/ Him)"], "link": "https://product.hubspot.com/blog/mobile-rewrote-the-rulebook-for-software.-b2b-is-still-catching-up", "abstract": "Fourteen years ago, Steve Jobs stood onstage and introduced the iPhone. It wasn’t the first smartphone, but it was the start of the smartphone era. And now 14 years later, we can clearly see some of the effects of this announcement on the ways that we think about and use computers and software. These changes are clearest when we look at consumer behavior. We’re all consumers in our day-to-day lives as well as being knowledge workers or professionals, and consumer behavior often offers a preview of trends that will be important for business or professional software, too. So let’s look at what’s happened since the introduction of the iPhone. Global access to devices First of all, the most important point is that smartphones brought access to computing to almost everyone in the entire world. Smartphone shipments have dwarfed PC shipments by about a factor of 10 to 1 for the last couple of years. Today, there are about 5.5 billion adults in the world and about 4 billion of us have an active smartphone. A new kind of computer interaction Along with bringing access to computing to everyone in the world, smartphones also ushered in a completely new experience of interacting with computers. Smartphones might seem limited by their small screens and low power compared to PCs. But in fact, smartphone hardware is much richer and more diverse than PC hardware. Smartphones have multi-touch displays, accelerometers, GPS, gyroscopes, compasses, microphones, front and rear cameras, mobile data connections, and even RADAR and LiDAR. And it wasn’t just the hardware that was different from PC hardware. The experience of discovering, trying, and using software was completely different, too. First of all, mobile apps are sandboxed, which means you can try a fun new app with confidence that it won’t brick your device or steal all your data, thanks to the much stricter security regimes for software on smartphones compared to PCs. Secondly, the App Store and the Google Play store made it simple to discover and install new software. You can learn how to download an app once and it works the same for all other apps ⁠ — you don’t have to mess around with installer files and .exes and so on. Finally, both Apple and Google handled payment processing on behalf of developers. While you might have trusted one or two recognizable software companies in the past with your payment information, today you can confidently pay an almost infinite array of independent software developers. The most important internet device So ⁠ — mobile brought access to computing to the whole world, and a new experience of interacting with computing that was richer, more fun, and safer to try and buy. And consequently, smartphones have become consumers' absolutely most important internet devices. Ofcom, the British telecommunications regulator, has been consistently surveying consumers' attitudes to the devices they use to go online over the last decade. From this research,  we know that 81% of consumers’ time spent online is spent on a mobile device and 60% of consumers consider their phone their most important internet device ⁠ — that’s doubled in the last six years . In fact, according to another Ofcom report, only half of us go online with a computer at all these days, and that’s down from 81% in 2014. Changing users’ expectations of how software works We can conclusively say that mobile has completely rewritten expectations of how software works. And it’s far from the first time that this has happened. We’ve seen this before ⁠— except that time, in the business software space. Twenty years ago, a plucky startup sought to position themselves against the incumbent in the CRM industry: Siebel. To use Siebel CRM, just like all software at the time, you had to first install and manage your own on-premises servers and then install the software on them ⁠— before you’d even thought about your users actually using it. Everyone understood that that was simply how software worked at the time. The startup was Salesforce, and you didn’t need a server to run it. You didn’t even need to install it ⁠— you just started using it. Salesforce actually hired actors to stage a fake “protest” outside Siebel’s developer conference holding up signs and shouting “No software!” to point out this difference. Twenty years later, we can easily say that Salesforce was right. Their cloud-based approach has been unequivocally adopted by the industry and now it feels just as inevitable and as unchangeable as on-premise servers felt to Siebel then. So, if Salesforce could completely re-write expectations of business software 20 years ago, and mobile could completely re-write expectations of consumer computing 14 years ago, could mobile do the same to business computing today? I think most businesses are underestimating the impact of this shift, and there are three misconceptions that endure. 1. There’s no money in mobile If you think about our smartphones as casual distractions from our day-to-day, it makes some intuitive sense that there isn’t any actual money to be made from business software on smartphones. And indeed, this is the conclusion that you’ll find in some analyst reports, like one from Deloitte which attempted to quantify “direct” revenue from B2B apps on mobile . They pegged that figure at about $2bn/year, which might sound like a lot. But for context, HubSpot alone is $1bn/year annually recurring revenue. That figure is dwarfed even by consumer spending on mobile, which is around $100bn/year (most of it on casual games). And that in turn is dwarfed by enterprise software spending, which is almost $500bn/year. But this kind of analysis has a fatal flaw. It tries to quantify direct mobile business software revenue. Consumer mobile revenue flows through touchless purchases in the app stores. No one is buying multi-year software licenses through these payment mechanisms, so these analyses can’t capture this value at all. So where is this value? The answer lies in customer satisfaction. When business software takes advantage of all the possibilities of mobile hardware and software and hits the mark on our new, heightened expectations for mobile ease of use, users are delighted. We can see this in our own first-party HubSpot data; HubSpot web users who also use mobile consistently have much higher NPS than those who don’t. Even in March 2019, when HubSpot suffered a weekend-long outage, the NPS of mobile-using HubSpot users was meaningfully higher than those who didn't. Other fields have wrestled with this before; for example, in customer support, it’s well accepted that investment in better trained, better paid support reps with more time to deal with customer issues pays off in terms of customer satisfaction, loyalty, and in turn, lifetime value and churn, and so on. So in order to justify and size investment into mobile app development teams, we have to do the same. 2. Mobile is for “on the go” The idea that mobile apps are for “on the go” use cases dominates marketing of mobile apps, especially in business apps, but in apps for consumers, too. I’ve always felt that this has minimized the benefits of mobile apps. This year, we got to see the effects of a once-in-a-lifetime event where the whole world was stuck at home ⁠ — not on the go at all. And it turns out that downloads of mobile apps spiked immediately following lockdowns around the world. In uncertain times, we naturally turned to our most important internet devices for escapism and connection to friends and family. The same was true for the HubSpot mobile app , too. There’s one feature of the app which is predicated on actual face-to-face meetings, and that’s our business card scanner. And indeed, usage of this feature did drop off a cliff in March this year. But the fascinating thing that this data revealed is that usage of the app’s other features actually stayed mostly in line with our web usage. So our mobile app wasn’t only for “on the go” moments at all ⁠ — the app lets you be productive anytime, not just anywhere. 3. Mobile is a nice-to-have complement to a web app Our customers are quickly realizing the benefits of work apps on their phones. Salesforce’s annual survey of 3000 sales leaders reveal that mobile sales apps for employees ⁠ — exactly what we’re building on the HubSpot mobile team ⁠— are number three on the list of top sales technologies that have been more important since 2019. Usage of mobile sales apps grew 60% from 2016-2018 , faster than any other sales technology that is tracked in this annual survey (including technologies like artificial intelligence, which have a lot of marketing hype behind them). And sales reps with access to mobile sales capabilities, including crucially editing customer, account, and opportunity information, are twice as likely to be “high performers” than those who don’t. This is just qualitative data, but in fact HubSpot’s own first party quantitative data backs up these attitudes. HubSpot sales reps who use the HubSpot mobile app actually achieve more overperformance relative to their quotas the more they use the mobile app. So, to summarize, mobile brought computing to the whole world, and with it a completely new set of expectations of how software works, just as Salesforce did 20 years ago when they pitched cloud apps as a better alternative to on-premises servers. With universal access and a richer, safer, and more fun experience of computing, smartphones unequivocally became our most important internet devices. But outside of the giants of our industry, B2B software has been too slow to recognize this shift, in part by failing to correctly quantify the value in mobile. If B2B doesn’t change, they’ll start to lose to mobile-first challengers. Interested in working with a team that's just as interested in how you work as what you're working on? Check out our open positions and apply .", "date": "2021-03-11"},
{"website": "Hubspot", "title": "Failure Testing Made Easy", "author": ["Eric Abbott"], "link": "https://product.hubspot.com/blog/failure-testing-made-easy", "abstract": "An interesting task I undertook recently was hardening our memcached infrastructure. We're an SOA shop with hundreds of deployables, most of which will interact in some way with our memcached clusters. I thought I'd take the opportunity to break down the testing process into a basic tutorial that could be repurposed for other external resources. Goals Present an adverse condition testing methodology against a simple external resource Familiarize readers with common failure conditions in distributed systems Familiarize readers with common failure testing tools and their uses Provide insight into spymemcached configuration options Failure Scenarios Due to memcached's simple functionality and consistent performance, we are able to categorize failures into three categories as seen from the client drivers. Network traffic is slow. Memcached responds correctly but slowly. This could potentially happen if the memcached host NIC or cpu gets accidentally saturated. Network traffic is dropped. Kind of like a black hole, tcp packets are sent by the client but no response is returned, (rejection is a response). This includes the case where the memcached host is ok (connections can be made), memcached accepts traffic, but memcached never responds to commands. Network traffic is rejected. Perhaps the Host or the memcached process is not running. We are successful when the following are true for each of the above three conditions. The specified connect and read timeouts are obeyed. The client eventually (developer specified) notices that a memcached server is down and marks it as such. For the duration of a server being marked as down, requests are failed immediately. There are no thread leaks. Memory use does not grown unbounded. The failure of one memcached server does not affect service to other memcached servers. The application starts and initializes without error. Tools The real challenge with failure testing distributed resources is visibility, how can we get a clear view into what is actually happening. Picking the appropriate toolset ahead of time will ensure the job is done properly, picking the wrong tools will simply drag out the process until the proper tools are utilized or the testing is incomplete. With tcpflow we can monitor packets going over the wire. With it we can watch in real time the (absense of) memcached traffic. With jconsole we can watch the jvm for thread usage, memory growth and kick off GC. With jmap we can count object instances should jconsole indicate memory issues. With iptables we can simulate failed resources. With a test application, watch and curl we can simulate steady traffic, say perhaps 1 request per memcached server per second. Be able to tail the output/access logs to watch for exceptions and the status of each request. The test appliction will also need custom endpoints that only contain simple get or set calls. The following chalkboard sketch lays out the relationships between the various tools and components. Setting up the test environment The testing environment for this blog was an internal example dropwizard application run locally on a laptop connecting to four memcached servers residing in AWS. Tcpflow and iptables will work fine in AWS and jconsole/jmap will function just fine on the laptop. The application server output all logs to stdout. To maintain a constant flow of traffic to all four memcached servers we used the ConnectionObserver in spymemcached to execute a stats call to each memcached server each second. This allowed us to easily monitor what communication channels were functional via tcpflow. As necessary we also used watch with curl to simulate steady traffic to a specific test endpoint. executor.scheduleAtFixedRate(new MemcachedKeepAliveRunnable(), 1000, 1000, TimeUnit.MILLISECONDS); private class MemcachedKeepAliveRunnable implements Runnable { public void run() { memcachedClient.getStats(); } } A custom endpoint was added to the app server to get and set a value in memcached. The value that is get/set each time helps us choose which memcached server to manipulate. We run tcpflow locally and use curl to hit the custom endpoint. Whichever memcached server is the target for the get/set operation becomes our guinea pig. With a simple networking setup, finding the memcached server that serves traffic for the testing key is as simple as running tcpflow on the local server that the app server is running on. For other scenarios such as a mac laptop going over a vpn to the memcached servers, tcpflow will need to be run on each memcached server. Each captured packet/flow is identified by the source_ip.port-dest_id.port, on both sides of the connection. Ie the source-dest prefix will look the same on both the client and remote servers. $ tcpflow -cv -i eth0 port 11211 | grep testing_key tcpflow[2806]: tcpflow version 0.21 by Jeremy Elson <jelson@circlemud.org> tcpflow[2806]: looking for handler for datalink type 1 for interface eth0 tcpflow[2806]: found max FDs to be 16 using OPEN_MAX tcpflow[2806]: listening on eth0 010.010.010.001.15422-192.168.001.200.11211: set testing_key 0 300 13 010.010.010.001.15422-192.168.001.200.11211: get testing_key 192.168.001.200.11211-010.010.010.001.15422: VALUE testing_key 0 13 In this example the tcp packets for setting and getting the keys originated from 10.10.10.1 and were received on 192.168.1.200. The value being returned from the get operation was sent from server 192.168.1.200 and received on server 10.10.10.1. Whichever side of the connection is using port 11211 is the memcached server. We've now identified our guinea pig memcached server. To test timeouts we need to simulate the memcached server taking a long time to respond. Never responding is a subset of \"long time to respond\", so to test we'll drop all packets via iptables. From the perspective of the memcached client drivers, we are going to allow packets to be passed to the local host's networking stack, but we'll drop them either on the local host or the remote host. Similar to the tcpflow tool, we can pick either side of the network connection to manipulate. # Drop packets on the memcached server iptables -A INPUT -p tcp --dport 11211 -d 192.168.1.200 -j DROP # Drop packets on the client server iptables -A OUTPUT -p tcp --dport 11211 -d 192.168.1.200 -j DROP # To flush all iptables rules iptables -F Lets verify iptables is indeed interrupting traffic. With the constant stream of stats pings every one second ongoing, run the iptables command and start dropping packets. The flow of responses to the stats calls on the guinea pig server should have stopped while traffic to the other memcached servers continues uninterrupted. Be aware that there may already be rules in place, and running the specified command will add the rule to the end of the chain where it would probably be ineffective. If thats the case you'll need to flush the rules and/or add yours in the appropriate location for the duration of the testing. Test 1 - sync get timeout For the first test we'll verify the configured 1s timeout works as designed. Fire up the application server Verify healthy traffic flow across all memcached servers with tcpflow Drop packets to guinea pig memcached server with iptables Within a few seconds hit the custom syncGet endpoint with curl Watch application log output for timeout error and timing Turn on packet flow with iptables again Running the specified steps results in spymemcached exceptions like the following. ! net.spy.memcached.OperationTimeoutException: Timeout waiting for value ! at net.spy.memcached.MemcachedClient.get(MemcachedClient.java:1185) ~[ExampleDropWizardService-2.0-SNAPSHOT.jar:na] ! at net.spy.memcached.MemcachedClient.get(MemcachedClient.java:1200) ~[ExampleDropWizardService-2.0-SNAPSHOT.jar:na] ! at com.hubspot.dropwizard.example.resources.AwesomeResource.get(AwesomeResource.java:50) ~[ExampleDropWizardService-2.0-SNAPSHOT.jar:na] ... Caused by: ! net.spy.memcached.internal.CheckedOperationTimeoutException: Timed out waiting for operation - failing node: guineapig.memcached.net/192.168.1.200:11211 ! at net.spy.memcached.internal.OperationFuture.get(OperationFuture.java:73) ~[ExampleDropWizardService-2.0-SNAPSHOT.jar:na] ! at net.spy.memcached.internal.GetFuture.get(GetFuture.java:38) ~[ExampleDropWizardService-2.0-SNAPSHOT.jar:na] ! at net.spy.memcached.MemcachedClient.get(MemcachedClient.java:1178) ~[ExampleDropWizardService-2.0-SNAPSHOT.jar:na] !... 59 common frames omitted The length of time until timeout isn't specified in the stack trace, it was collected explicitly in our code to determine the configured 1s timeout was being honored. long time = System.currentTimeMillis(); try { memcachedClientIF.get(\"testing_key\"); } catch (Exception e) { } System.out.println(\"Memcached.get time: \"+ (System.currentTimeMillis() - time) +\"ms\"); Test 2 - Application Initialization Will the application server start up correctly if a memcached server is unavailable? There are a couple different ways we could envision this test failing. If the memcached drivers threw exceptions while being initialized due to lack of connectivity that could break the app server. In addition, an exception could be thrown while pre-initializing values from memcached. This second case is application logic dependent and thus will need to be verified on each application stack (ouch). Reject(/Drop) packets to the guinea pig memcached server with iptables Start up the application server Verify in the application logs the application server did not fail anything important Run a few sample requests with curl to verify the application server accepts requests and properly handles them Turn on packet flow to the guinea pig memcached server with iptables again Hit the custom endpoints with curl to verify the downed memcached server is brought back into the pool. Re-including a downed server may take some time, we'll test for those timings later This test should be repeated for each memcached server verifying there isn't a single key used during startup that isn't handled properly on failure. Repeating the test by dropping packets instead of rejecting them reveals interesting behavior. Again recall that our application constantly pings all memcached servers for stats every second as visible heartbeat for us to monitor. When packets are rejected by the memcached server, the drivers immediately ascertain the memcached server is unavailable and change the internal state accordingly. However if the packets are dropped instead, there is a 60s+ period until the remote memcached server is considererd down and a reconnection is queued. Another interesting result appeared as we constantly hit the custom endpoint after starting the application server with packets being dropped. Before the remote memcached was marked as down, each custom endpoint call timed out at 1s as expected. However, after being marked down each hit to the custom endpoint also timed out after 1s instead of failing fast. Let's test this functionality a little more rigorously as our next test. Test 3 - Fast Fail Do requests to a downed memcached server fail fast? In particular we are concerned with cases when memcached is a black hole, we don't want 1s timeouts for all calls for the 20min it takes to replace a memcached server. For example, here's a heatmap of a service showing a large portion of requests taking slightly over 1s for a 10min+ period. The period corrosponds with a single memcached server rebooting. Start the application server Verify traffic flows to all memcached servers with tcpflow Start dropping packets to the guinea pig memcached server with iptables Hit custom endpoint and monitor timeout time via app logs Watch application log output to see when remote memcached server is marked down After memcached server is marked down, hit custom endpoint with curl Verify custom endpoint calls fail fast via app logs Failure. The memcached.get() calls all timeout instead of failing fast. Digging through the spymemcached docs and code it appears the failure mode we have set is FailureMode.Retry which will force a retry even when a memcached server is down . Let's change Retry to Cancel and test again. On Step 6 this second time around with FailureMode.Cancel, the custom endpoint stops timing out and fails fast after the memcached server has been marked down. Test 4 - Thread leaks Now we'll test if there is a thread leak during longer outages. Spymemcached client drivers keep one open connection to each remote memcached server. Requests are sent individually over the wire and are grouped/optimized if possible. Therefore under the hood all requests are inherently asynchronous and spymemcached spins up and handles its own threads as it sees fit. To test for thread leaks we'll need to keep constant traffic, then sever a connection to a remote memcached server, then reconnect, then sever for several iterations. After that we can leave a connection severed for awhile. To monitor thread usage during the test we'll use jconsole. Start up the application server with jconsole params present -Dcom.sun.management.jmxremote=true Start jconsole jconsole <pid> Turn on constant traffic (background stats calls plus manually hitting endpoints with curl ) Start dropping packets to the guinea pig memcached server with iptables Wait for the connection to be marked as down, and for several reconnect failures in the app logs Turn on packet flow to the guinea pig memcached server with iptables again Watch the app logs for the connection to be live and healthy again Repeat steps 4-7 several more times Start dropping packets to the guinea pig memcached server with iptables Leave it run for 10-20min Examine the thread counts in jconsole for the duration of the test The testing we did for this step is probably a bit outside the bounds of what would normally happen. It's not very likely a memcached server would disappear/appear many times, though those actions are the most likely to be the cause of a leak of some kind. One of the more likely scenarios we'll see in the wild is a memcached server being unavailable for 15-30min as a replacement is being spun up. Our testing showed no thread leaks, the thread count stayed constant throughout the testing. Test 5 - Memory Leaks Testing for memory leaks will follow the same testing routine as the testing for thread leaks with the additional help from jmap. Spoiler alert, there is a memory leak, and it was confirmed via jmap. Jmap can provide us with counts of objects inside the jvm. Excecuting the jmap command multiple times sequentially shows us which objects continue to collect. There are lots of objects, we can use an educated guess (and some hindsight) to just look for objects with memcache in their package structure. There's a pretty long tail for classes with only one instance, no point in examining those when looking for object leaks (grep -v). jmap -histo <pid> | grep -E 'Latch|memcache' | grep -v \"   1   \" Start up the application server with jconsole params present -Dcom.sun.management.jmxremote=true Start jconsole jconsole <pid> Turn on constant traffic (background stats calls plus manually hitting endpoints with curl ) Start dropping packets to the guinea pig memcached server with iptables Wait for the connection to be marked as down, and for several reconnect failures in the app logs Run jvm garbage collection (GC) with jconsole Watch the number of objects with jmap -histo Turn on packet flow to the guinea pig memcached server with iptables again Watch the app logs for the connection to be live and healthy again Run GC from jconsole Watch the number of objects with jmap -histo Repeat steps 4-11 several more times Start dropping packets to the guinea pig memcached server with iptables Leave it run for 10-20min Run GC from jconsole Watch the number of objects with jmap -histo The two signs of a memory leak will be the overall heap size in jconsole and the comparison of objects between jmap calls. To be most accurate, both of those should only be measured right after jvm garbage collection. Repeated iterations of a remote memcached server being down did not result in an overall trend indicative of a memory leak. A remote memcached server being down for a long period of time however does appear to have a memory leak as shown in the following char. Starting a bit before 2:20 until around 3:14 we see an upward trend of memory usage. The drops in memory usage came the next GC after re-enabling the packet flow to the remote memcached server. The cycle is repeated a second time as the packet flow is disrupted around 3:15 until 3:31. During the testing we were able to track objects being collected with jmap. Here are some sample objects collected while the remote memcached server was unavailable. jmap was run right after GC was triggered to ensure the most accurate results. num     #instances         #bytes  class name ---------------------------------------------- 53:           512          36864  net.spy.memcached.protocol.ascii.StatsOperationImpl 82:           445          14240  java.util.concurrent.CountDownLatch$Sync 91:           512          12288  net.spy.memcached.MemcachedClient$11$1 97:           440          10560  net.spy.memcached.MemcachedClient$11 125:           445           7120  java.util.concurrent.CountDownLatch Now here's the same set of objects a couple minutes later, again run directly after GC was triggered. num     #instances         #bytes  class name ---------------------------------------------- 36:          1256          90432  net.spy.memcached.protocol.ascii.StatsOperationImpl 78:          1256          30144  net.spy.memcached.MemcachedClient$11$1 91:           736          23552  java.util.concurrent.CountDownLatch$Sync 104:           731          17544  net.spy.memcached.MemcachedClient$11 132:           736          11776  java.util.concurrent.CountDownLatch The jconsole graph shows a leak and the jmap data narrows it down to specific spymemcached objects. Not coincidentally the solution to this problem is the same for fail fast, changing FailureMode.Retry to FailureMode.Cancel. Test 6 - Marking server as down We've already confirmed that servers are eventually marked as down and after that requests will fail fast. Next we need to determine what that threshold is and if possible how to lengthen or shorten that time. One would expect this value to be configurable, so we'll start guessing at configuration fields and tune them up and down to see which has an effect. Start up the application server Verify traffic flows with tcpflow Stop packet flow to the guinea pig server with iptables Measure the time it takes until the server is marked as down as noted in the app logs Repeat a few times to gauge the baseline time until a server is marked down Pick a field to modify (starting with TimeoutExceptionThreshold) Set the value very low as compared to baseline Run steps 1-4 a few times and compare against the baseline time If different than the baseline time, set a high value and repeat Repeat with different possible fields After fiddling with a few params and reading through lots of code we were unable to find any lever that would shorten/lengthen the amount of time it takes the spymemcached drivers to notice the remote memcached server has disappeared inside our test environment. If you've got some understanding or insight into the spymemcached drivers and how servers get marked down please let us know in the comments! Conclusion Hopefully you'll agree with me that failure testing is easy once you get a feel for the proper tools. Iptables does an excellent job of quickly and easily simulating a memcached outage while tcpflow allows explicit verification of what is and what is not going over the wire. For us the change from FailureMode.Retry to FailureMode.Cancel will help limit the disruption a failed memcached server can cause by allowing fail fast behavior. For next steps we'll be trying these tests out in our qa and production environments, getting us closer to being best buds with Chaos Monkey.", "date": "2014-05-13"},
{"website": "Hubspot", "title": "Bruce Schneier and xkcd walk into a bar...", "author": ["Dan Milstein"], "link": "https://product.hubspot.com/blog/bid/25397/bruce-schneier-and-xkcd-walk-into-a-bar", "abstract": "A somewhat astonishingly good explanation of AES via stick figures (yep, stick figures): http://www.moserware.com/2009/09/stick-figure-guide-to-advanced.html Very funny, and surprisingly good pedagogy.  I'm pretty much a math obsessive, and I now feel like I understand the 'byte xors == polynomial field arithmetic' better than I ever have before. (the release form in the middle is maybe the best thing ever -- it's rare to see a good math joke, and I can't tell you the last time I saw a good math/interpretive dance joke.  And thus, I celebrate it).", "date": "2009-09-24"},
{"website": "Hubspot", "title": "The Inbound Way To Get Hired", "author": ["Anand Rajaram"], "link": "https://product.hubspot.com/blog/bid/85974/the-inbound-way-to-get-hired", "abstract": "Getting hired at a great company is just like trying to acquire great customers -- if you use the classic inbound techniques of (1) creating great content and (2) nurturing your best relationships, you're bound to go far . I applied these principles when I was in the process of getting hired at HubSpot, and they served me very well. While these strategies might not work for everyone, I think they're pretty broadly applicable in the tech field, where personal networks are so vital, and where what you produce is essentially your best possible calling card. So, how did you end up at HubSpot? I have been at HubSpot for a little over two months. I consider myself fortunate to be a part of something really big, and when I am not drinking from the firehose, getting $hit done or talking to wooster bot , I have been thinking about how I got here, and wanted to share what I have learned. It all began when I sent an email to someone I knew (who didn't work at HubSpot) when I was looking for introductions (to people who didn't work at HubSpot), and I ended up getting hired for a position (that didn't actually exist at HubSpot). Wait, what? Nurture Relationships & Create Great Content I met HubSpot Chief Product Officer David Cancel at the Xconomy Cloud3 event when he was still with Performable, and developed a real respect for him, primarily based on his emphasis on listening to the customer and building products in an iterative, incremental manner. After this first meeting, we saw each other again at a number of events related to Lean Startups and Lifecycle Marketing. At the same time, we friended and followed each other on Twitter and LinkedIn. Twitter We kept in touch with each other over Twitter about topics like measuring product value and data-driven startups. Here's an example of what those conversations looked like: @ dcancel \"Ghettopreneurs like mAARRRketing\" #aarrr #datadrivenstartup #tshirtideas — Anand Rajaram (@anandrajaram) October 19, 2010 @ anandrajaram @ Evanish I wish that was my quote - I start every presentation with the Demings quote. — David Cancel (@dcancel) August 26, 2011 Incidentally, when I eventually did get a written offer from HubSpot, it was over a Twitter DM . Blogging As a member of various teams that worked on Lifecycle Marketing, I learned important lessons about how to acquire leads, convert them into customers, and retain them over time. I summarized these lessons and posted them as a whitepaper on the Performable blog. Performable, you remember, was founded by David Cancel and was later acquired by HubSpot. I posted another, similar blog post at the KissMetrics Blog on how to increase conversion . Creating this content helped me establish some more credibility for my own blog on startups and product management , and also helped me to forge some more valuable professional relationships. In a lot of ways, content creation goes right hand in hand with relationship-building. Quora I'm also active on Quora, and try to regularly answer questions that are within my realm of expertise. My answer for What are the best interview questions for Product Managers is the top-voted answer in that thread, and I was able to weave this -- both my answer and its popularity -- into my various interviews at HubSpot. The key lesson here is to contribute your knowledge and expertise to the wider world over time, so that you increase the chances of serendipitous discussion. If you code for a living, be sure to call out our your github link and brag about your StackOverflow reputation in your resume. You do use GitHub and StackOverflow, right? Sure you do. Know Your Audience Once I knew I was gunning for a job at HubSpot, I started researching the heck out of the company -- just like you would research your ideal customer as a marketer. The HubSpot culture is summed up by their acronym MATCHES , which you can learn more about via that link. I also checked them out on glassdoor.com, primarily to ask a few relevant questions and raise some concerns to see what kind of a response I got. I got a good sense for HubSpot's culture from MATCHES , and even mocked up a \"MATCHES Grader\" in the spirit of the other HubSpot grader products . The idea is of this app is that you would simply provide your LinkedIn profile and the tool would grade you and decide how much you matched the MATCHES of HubSpot's culture. As an aside, I was also working on a timeline-enabled version of my resume for Facebook, and a 140-character cover letter for Twitter. I am kind of glad I never had to use those. Sweat The Details • I obsessed over my resume font. After playing with a bunch of canned templates in Pages and MS Word, I decided on Book Antiqua, which is a popular font on book reader apps. This makes the resume much more readable. • I included links in my resume, and was careful to make them trackable links by using a good URL shortener. • I ordered special Moo Cards that used my Facebook timeline to use as my business cards. • I sent a thank-you note to everyone that I met with, being sure to reference an interesting point from our discussion. Get It Done The parallels between acquiring customers and getting hired in a great position seem blindingly obvious. Nurture relationships and create great content while also leveraging social media and tailoring the message to your audience. There is something to this whole Inbound-y thing, that makes it work is several contexts. And I am so glad I am living it. Anand Rajaram is a Product Manager at HubSpot, where he leads the company's mobile initiatives and gets away with claiming Angry Birds and Facebook as \"work.\" He blogs at startupproductmanager.com and would love to continue this conversation with you on Twitter at @anandrajaram . Image by Fracking", "date": "2012-04-25"},
{"website": "Hubspot", "title": "The Fault in Our JARs: Why We Stopped Building Fat JARs", "author": ["Jonathan Haber (He/Him)"], "link": "https://product.hubspot.com/blog/the-fault-in-our-jars-why-we-stopped-building-fat-jars", "abstract": "HubSpot’s backend services are almost all written in Java . We have over 1,000 microservices constantly being built and deployed. When it comes time to deploy and run one of our Java applications, its dependencies must be present on the classpath for it to work. Previously, we handled this by using the maven-shade-plugin to build a fat JAR. This takes the application and all of its dependencies and bundles them into one massive JAR. This JAR is immutable and has no external dependencies, which makes it easy to deploy and run. For years this is how we packaged all of our Java applications and it worked pretty well, but it had some serious drawbacks. Fat JAR Woes The first issue we hit is that JARs are not meant to be aggregated like this. There can be files with the same path present in multiple JARs and by default the shade plugin includes the first file in the fat JAR and discards the rest. This caused some really frustrating bugs until we figured out what was going on (for example, Jersey uses META-INF/services files to autodiscover providers and this was causing some providers to not get registered). Luckily, the shade plugin supports resource transformers that allow you to define a merge strategy when it encounters duplicate files so we were able to work around this issue. However, it’s still an extra \"gotcha\" that all of our developers need to be conscious of. The other, bigger issue we ran into is that this process is slow and inefficient. Using one of our applications as an example, it contains 70 class files totalling 210KB when packaged as a JAR. But after running the shade plugin to bundle its dependencies, we end up with a fat JAR containing 101,481 files and weighing in at 158MB. Combining 100,000 tiny files into a single archive is slow. Uploading this JAR to S3 at the end of the build is slow. Downloading this JAR at deploy time is slow (and can saturate the network cards on our application servers if we have a lot of concurrent deploys). With over 100 engineers constantly committing, we usually do 1,000-2,000 builds per day. With each of these builds uploading a fat JAR, we were generating 50-100GB of build artifacts per day . And the most painful part is how much duplication there is between each of these artifacts. Our applications have a lot of overlap in terms of 3rd party libraries, for example they all use Guice, Jackson, Guava, Logback, etc. Imagine how many copies of these libraries we have sitting in S3! Finding a Better Way Eventually we decided we had to find a better way to do this. One of the alternatives is to use the maven-dependency-plugin to copy all of the application’s dependencies into the build directory. Then when we tar up the build folder and upload it to S3 it will include all of the dependencies, so we still have the immutable builds that we want. This saves us the time of running the shade plugin and the complexity that it adds. However, it doesn’t reduce the size of the build artifacts so it still takes a while to upload the tarball at the end of the build, which also means we’re still wasting a huge amount of space storing these build artifacts, and then it still takes a long time to download these artifacts on deploy. Introducing SlimFast Using the example application from before, what if we just uploaded the 210KB JAR? Imagine how much faster the build would be (turns out it’s up to 60% faster). Imagine how much space we would save in S3 (over 99%). Imagine how much time and I/O we would save on deploys. In order to do this, we wrote our own Maven plugin called SlimFast . It binds to the deploy phase by default and uploads all of the application’s dependencies to S3 individually. On paper this actually makes the build slower, but the trick is that it only needs to do this if the dependency doesn’t already exist in S3. And since our applications’ dependencies don’t change very often, this step is usually a no-op. The plugin generates a JSON file with information about all of the dependency artifacts in S3 so that we can download them later. At deploy time, we download all of the application’s dependencies, but we cache these artifacts on each of our application servers so this step is usually a no-op as well. The net result is that at build time we just upload the application's thin JAR which is only a few hundred kilobytes. At deploy time we only need to download this same thin JAR which takes a fraction of a second. The Results After rolling this out, we went from producing 50-100GB of build artifacts per day to less than 1GB. In addition, not running the shade plugin and not uploading fat JARs to S3 had huge benefits in terms of build speed. Here's a graph showing build times before and after the change for some of our projects: We've been running this setup in production for over 4 months and it's been working great. Check out the SlimFast readme for more detailed information on how to get it set up and let us know how it works for you!", "date": "2016-06-16"},
{"website": "Hubspot", "title": "5 Tips for Getting Your First Technical Internship", "author": ["Mike Champion (He/Him)"], "link": "https://product.hubspot.com/blog/5-tips-technical-internship", "abstract": "For college students everywhere, it’s getting to be that time of the year again. You probably have your eye on an internship with a fast-growing company where you can get your hands dirty, own real problems, and move the needle on a product that actually interests you. The only thing standing in your way is a tiny little detail called competition. From my time screening and interviewing intern and co-op candidates for HubSpot’s Product Team, I’ve realized that not all tech applicants present their talents equally. Some applicants stand out more than others and it isn’t because they’re “better” designers or engineers. It’s because they demonstrate passion, culture fit, and potential to grow; things you can’t always get across on your resume. With all the competition out there it’s more important than ever to go that extra mile and demonstrate why you are the perfect fit, on and off paper. After thinking about the candidates that have stood out to me, I thought these tips from their playbooks might be helpful as you navigate your search: 1. Think Outside the Resume Today, the first thing a recruiter or hiring manager will do when considering you for an internship is a quick Google search. That’s why it’s important to develop an online presence instead of relying purely on your resume. Take LinkedIn, for example. You probably have a profile but are you using it to tell your story? LinkedIn is a great vehicle to describe past projects and share work you’re proud of. Along those lines, being active on sites like GitHub and Dribbble is a huge plus because it shows us that you truly have passion in what you’re doing beyond the classroom. Not to mention, they showcase your talents in a way that a piece of paper can’t. Resumes are important, but let’s face it, they’re old-school so I recommend putting some time into increasing your visibility on these platforms. 2. Don't Be Afraid to Try New Things (or Talk About Them) Growth stage companies want to see that you are hungry to learn new things. Sharing the computer science classes you’ve taken is helpful but it doesn’t show me that you’re curious or eager to roll up your sleeves. That’s why you should have at least one project in mind that you’re comfortable and excited to talk. It can be a side project you started with your friend something you worked on in class; what matters is that you set out to solve a problem, shipped a living breathing thing, and were engaged throughout the process. Candidates that share things like, “I started exploring iOS apps and I’d love to do more mobile development” or “I tried building a front end application because I already have a lot of experience with websites” are usually the ones that stand out. Find stories to tell and experiences to share that demonstrate that you want to grow. Often times, that’s more important to us than what you already know. 3. Do Your Homework To be remarkable, take the time to do some research on the company you’re applying to and their product. It proves you’re serious about joining the team. Luckily, Google makes this pretty easy. Start by taking ten minutes to check out a company’s website, blog, or latest headlines. Dive a little deeper by familiarizing yourself with their work: if you can, try a free trial of their software, use their freemium tools, or check out their open source contributions . Bonus points if you use one of their libraries or tools in a project. Later on, come up with a few thoughtful questions to ask before heading into an interview or recruiting event. A good rule of thumb is to think of a few things you’d like to know about the company or team that you couldn’t find online. Getting familiar with the ins-and-outs of the company speaks volumes about your commitment to working on their product. 4. Be a Team Player We like to work in small teams at HubSpot so that everyone has ownership over part of the product. It’s one reason we’ve been able to scale our speed and deploy up to 300 times a day. Our Product organization is broken up into teams of about 3 or 4 with one tech lead, developer, and engineer (typically). Not surprisingly, how candidates approach teamwork is more important to us than how quickly they can write code. Before your next interview, keep in mind that there are subtle ways to tell whether or not someone is going to be a team player. For example, if you light up when you’re talking about a group project or use “we” more than “I”, you’re probably a better culture fit than candidates that don’t show much interest in collaborating. It’s tempting to only talk about how great you are in an interview, but keep in mind that most product organizations are fueled by teamwork. 5. Don’t Underestimate Passion When he was a kid, professional hockey player Sidney Crosby practiced his shot in the basement every night. His net was set up right next to the dryer so everytime he missed, the puck would hit the dryer and leave a dent. Top tech talent and Crosby have one thing in common: they’re passionate. We want to work with people who are committed to projects and stay up late thinking about how they can get better. What are your hobbies? What keeps you up at night? We get excited when candidates tell us they're on a soccer team or take guitar lessons because there’s a good chance they’ll carry that drive over into their projects. During your interview, on your website, or at a networking event, tell companies what you’re passionate about. Show them that you can make a dent. Hopefully these tips come in handy as you start applying for internships and reaching out to product organizations. Have more questions about getting a technical internship? Let us know in the comments.", "date": "2015-02-09"},
{"website": "Hubspot", "title": "How to remotely test prototypes of mobile apps", "author": ["Molly Wolfberg"], "link": "https://product.hubspot.com/blog/how-to-remotely-test-prototypes-of-mobile-apps", "abstract": "The HubSpot usability team loves to get feedback on apps we’re developing to make our customer's marketing lives easier. But testing in the mobile environment presents a unique set of challenges. We recently devised a system that allows us to get much more insight from our testing sprints with real mobile users, using real apps in their natural environment -- in situ -- and discovered a whole new set of questions we were able to ask as a result. The Mobile Marketer Unless you’ve been living under a rock (or using a Blackberry), you’ve noticed the massive strides that social media and mobile marketing have made over the past year. And the HubSpot iPhone application has been keeping pace. With over 17,000 downloads to date, it’s clear that HubSpot customers are a mobile set. It makes sense that they’d start looking for us to develop more in the way of a social mobile app. After all, social is by its very nature a mobile game and HubSpot customers want to be able to see if social activity is or is not driving their success. So we here on the HubSpot usability team decided to look at how HubSpot customers are using social to help us decide exactly how to pursue developing the mobile social media publishing tool. The Problems with Most Prototyping Tools In the past, we used mobile prototypes on desktop computers for mobile testing. We’ve found that this strategy gives us a fairly decent understanding of how our customers use our mobile app. But even though mobile prototyping tools are relatively sophisticated, they were not entirely realistic. When you test with a mobile prototype, you compromise on a lot of important aspects of the user experience. Prototypes can't: Be tapped, swiped or zoomed, because there’s no finger interaction at all Scroll, which means you can’t see more than a screen’s worth of content Explore the whole in-phone context of the app, such as where the app lives, and how the user accesses it Recreate usage on a physical handheld device Be installed from the Apple App Store In addition, we wanted the least intrusive way to actually see how people were using these prototypes, and doing in-person testing simply would not scale. Trick 1: The Remote Hack Our mobile product manager Anand Rajaram discovered the first hack from the folks at Mailchimp , who shared a method to use the camera on your laptop or iPad to record what was happening on your iPhone. This simple hack allows you to see someone's phone from nearly the same perspective as they themselves see, and mimics real use amazingly well. (see picture) This solved part one of our dilemma, and would allow us to test with anybody who used the HubSpot mobile app no matter where they were. Trick 2: Use Proto.io The next step was figuring out how to test with a mobile app that didn’t exist yet. Clickable mockups are reasonably useful for desktop testing, but presented an obstacle in the mobile world. After trying out several different options, Anand decided to use an interactive mobile prototype through the tool Proto.io because it did the best job of mimicking a fully functional mobile app that can be downloaded and used on a testing subject’s own phone. It made it easy for Anand and the designers to create and customize prototypes for the varying devices and screen sizes of the testers, which made the testing experience the most realistic. Unexpected Insights Once we had a system in place that would allow us to test mobile users using prototypes with some degree of accuracy and authenticity, we were off and running. Aside from the more general usability insights we gained from these in situ sessions, we also discovered that testing the users on actual phones made a huge difference in the scope of what we were able to discover during testing. We documented findings that would never have arisen in a less realistic testing environment. For instance, we learned: What other apps people use: Seeing what other apps HubSpot users have on their home screens helped us understand what marketers are doing on a day-to-day basis on their phones, what other apps they’re trying and using, and what they like and don’t like about them. How people organize their apps: We got to see how our users group the HubSpot app with their other apps, whether in folders or just on separate screens. The folder names and the app with which they grouped us with were especially insightful. How people navigate between apps: Looking at how HubSpot users interact with their phones (such as using status bar to scroll to top, if they use the multi-tasking bar and so on), how they switch between apps with bookmarklets, copying and pasting etc. gave us a look into their basic actions with their phones. The Future of Remote Social and Mobile Testing Even though we've learned a lot about mobile testing so far, we plan to keep on refining our remote testing techniques. The role of the mobile marketer keeps changing every day, so our usability testing needs to keep changing with it. We’ll continue to conduct research on social media and mobile marketing, but more importantly, we’ll keep learning how to test for the best possible insights no matter what we’re testing for. In situ mobile testing is only the beginning. The HubSpot usability team has developed a process in which we do one-day testing sprints. We conduct testing in a fast-paced development environment, working to improve the usability and interfaces of the software. For us, it’s just not realistic to ask our customers into the office to test with us for an hour, due to location, time, and energy constraints. You can learn more about the testing sprint process here.", "date": "2013-04-02"},
{"website": "Hubspot", "title": "HubSpot Partner Spotlight: Resa Gooding, HubSpot Certified Trainer & Demand Generation Strategist, Cacao Media", "author": ["Francesca McCaffrey (She/Her)"], "link": "https://product.hubspot.com/blog/hubspot-partner-spotlight-resa-gooding-cacao-media", "abstract": "Some of the best perspectives on HubSpot's product come from those who use it every day. In this new interview series, we profile HubSpot partners and customers, and ask their thoughts on what our product team should keep in mind while solving for them, and where the future of the industry lies. In this installment, we chat with Resa Gooding , HubSpot Certified Trainer and Demand Generation Strategist at Cacao Media. You're a HubSpot certified trainer and demand generation strategist at HubSpot partner agency Cacao Media, based in Tel Aviv and Nairobi. How did you first come to work with HubSpot's products? I moved to Israel in 2007 from the Caribbean: Trinidad and Tobago to be exact. Because I did not speak Hebrew, the most logical job to pursue was in marketing, as most Israeli companies were seeking native English speakers for marketing and sales positions within their companies. While working for an advertising company as an account manager, I was exploring ways to reach more clients. I began doing some research about online marketing and came across HubSpot's blog and resources. Upon discovering HubSpot Academy, I spent a lot of time completing the certificates and placing them on my LinkedIn profile. Suddenly companies began reaching out to me asking if I could come in to help them set up their HubSpot accounts and, as they say, the rest was history. What's the most exciting challenge you're solving with your team right now? The most exciting challenge our team is solving right now is building templates that allow our clients to execute tasks such as lead scoring and reporting more easily. These two concepts require accessing certain logic that isn't always obvious. We are exploring different ways to make this really simple in the form of templates, or actionable guide books that will clearly explain the logic behind these two highly demanded requests. In your opinion, what's the most important thing for HubSpot's product team to keep in mind when solving for customers today? I'd like to say KISS (Keep It Stupid Simple). In my encounter with marketers and sales teams, many are still hesitant to adopt new platforms, especially one that runs their entire company's system. They are afraid to make mistakes so they prefer not to touch anything. Therefore, the easier things appear, the more encouraged they will be to try the system out. Thus far, HubSpot's product team has done an incredible job in the user experience of the platform but I do advise they keep the changes of the interface at a minimum, or at least longer timelines in between changes, so that users can get accustomed to where various functions sit and build the necessary confidence needed to master the platform. What's your favorite feature within the HubSpot product? Hmmmmmm... that's a hard question. I'd have to split my answer into two. The feature I enjoy most is Workflows because it makes the maintenance of the platform very easy. There is always something to update on contacts, or deals, or companies, and I couldn't imagine what it would be like if I had to do this manually. But the feature that gives the most value, especially after this year of COVID-19 where businesses needed to find more creative ways to reach their audience, is the Ads tool . I love seeing the look on my customers' faces when they see how many rich insights they can get out of the Ads tool in just a few clicks. Most marketing teams do not understand how to read ad reports in Google Data Studio or Facebook or LinkedIn Ads, so having all the data aggregated in one platform, as well as the ability to see the immediate ROI of their media spend, is a huge win. What's one prediction you have about the future of marketing and demand generation? This year, 2020, has definitely been the \"Year of Reveal.\" I say this because it exposed all the gaps in every area of our society, personal lives, and businesses. For the first time ever, it felt as if everyone was brought down to ground zero. We were all given a level playing field and with it the opportunity to reinvent ourselves in ways we never thought of. The last two decades felt like the ultimate race of technological advancements. We've grown leaps and bounds during this time, but there were many businesses and individuals who tried to steer far from this curve. For various reasons, many did not wish to tackle the adoption of technology to their businesses and this year revealed that without taking this step, your businesses have a slim chance of surviving and no one is exempt. Just take a look at the recent developments with Amazon Pharmacy shaking up an industry that felt they were 'too big to fail.' In one swoop because of technology, Amazon is able to slash prices and improve convenience for shoppers in a way that the pharmaceutical industry was ignoring for far too long. These are the trends I believe will continue in the near future. Businesses that have enjoyed any level of safety or comfort until now can no longer be complacent. We all must figure out how to stay agile and relevant to our consumers. The flywheel is now in full effect. Want more profiles of tech industry leaders? Check out our Name Dropping series .", "date": "2020-12-18"},
{"website": "Hubspot", "title": "O'Reilly's Beautiful X Series", "author": ["Dan Milstein"], "link": "https://product.hubspot.com/blog/bid/24069/o-reilly-s-beautiful-x-series", "abstract": "These last few weeks, I've had the pleasant luck to be staying with a friend who used to work at O'Reilly, and thus, has a house littered with pretty much every book they've ever published.  I've taken the time to catch up on some of their ever-growing \"Beautiful <Some Face of Software Development X>\" series. A few notes: Beautiful Code (which was first in the series), I can recommend fairly highly. I very much enjoy careful walk-throughs of complex code, and there's plenty of that.  A bit all over the map, but interesting insights into a bunch of different problem domains.  Oh, and, Brian Cantrill's detailed story of debugging priority inheritance in Solaris is worth the price of admission alone.  Memo to self: leave the locking code to people writing operating systems.  'cause, wow, that's some tricky stuff. (shared nothing is your friend, shared nothing is your friend...) Beautiful Data -- this one I've had a pretty binary experience of.  Some essays I could barely get through (surprisingly, Jeff Hammerbacher's piece about the data team at Facebook didn't do much for me), but several were just brilliant -- Peter Norvig's exploration of what you can do with the Google Web Trillion Word Corpus took the top of my head off (the part where he turns it into a tool for breaking ciphers, and then breaks a series of real-world examples, was absolutely gorgeous).  Similarly excited by the Surfacing the Deep Web (again, from some Google folks).  Those two essays got me really motivated to look for ways to use simple analyses + big data sets to do interesting things. Beautiful Architecture -- haven't found much that grabbed me in this yet, though I did enjoy Michael Nygard's piece very much (mostly because I'll read just about anything by him). Okay, and now it's time to get back to work (a house full of O'Reilly books can be pretty distracting...)", "date": "2009-09-17"},
{"website": "Hubspot", "title": "Writing A Google Chrome Extension", "author": ["Mohamed Faramawi"], "link": "https://product.hubspot.com/blog/bid/33406/Writing-A-Google-Chrome-Extension", "abstract": "When Google released its Chrome web browser , a lot of people (including me) loved it, but were missing Firefox like extensions, But these days are over now and Google's browser supports extensions. So I decided to write a simple extension to see if the delay for extensions public release was for a good reason.  Extensions have been present in Chrome for a while, but only in the Beta or Developer versions. I wrote a simple extension that generates a short URL for any web page you are viewing at any tab using HubSpot's own URL shortener service, Hub.tm , you can install it on your browser by going to https://chrome.google.com/extensions/detail/jhbjofkkhbgdgpbfkppblkpgkbefafkg It took less than an hour to write the extension, a really short time.   The developer guide is very clear, and the framework is built nicely. The framework is all JavaScript- and JSON-based, which makes things easy.  You are using JavaScript to do all your logic, and using JSON for configuration and message passing between your extension code blocks. I loved how JSON is used as a configuration format, as we already do at HubSpot in some places.  In my opinion, the JSON configuration format is more readable than XML, assuming you are carefully naming keys in your JSON. Other things I liked about the Chrome extension framework: Extension files are  as any web application: images, .css files, .html files, .js files.  Even the configuration file is .json , so there is no funky or new files formats. Permission logic, and how can you control which URLs your extension can work on, which JavaScript code to be loaded and when. Built-in JSON serializer. Attaching to browser specific event (like tab opened, closed , extension icon clicked..). Isolated world scripts execution environment,  which means your extension JavaScript code will never conflict with any code included in any page viewed in the browser.  This is also good for security. How its easy to include external JavsScript , CSS libraries with your ext code.  I use jQuery in my extension, and it's trivial. You can make cross-domain AJAX calls , thanks to HTML5 support in the browser). The HTML5 local storage . Nonetheless, it's not all trivial.  I also have a couple of tips on speeding up your extension development learning curve: If your extension works for any URL, you are doing a \"Browser\" action. If your extension works for specific URLs, or pages that must have some sort of pattern (e.g page that have an RSS feed) , you are doing a \"Page\" action. If you want to show some output to the user , use a \"Browser\" action \"Popup\" which is a  box that can contain inside it an HTML page (any HTML you want, including CSS, JavaScript, etc.) If you want to organize your JavaScript code, you will be using \"Content Scripts\", but remember they have limits.  Most notably, they can't do any AJAX requests, but they can access DOM of viewed pages. If you want to have long-running tasks, or save state information, use the \"Background\" page.  This page is always on and always running , even if the user did not interact with your extension. If you ever wanted to check how an extension was built, you will find all the files of that extension on your disk inside the Chrome folder ;) Overall, when you are writing an extension you will feel like you are writing a simple static web application (bunch of CSS , bunch of HTML, bunch of JS code , images..etc) , and everything you will be doing is something you know you have done hundred times before (e.g manipulating the DOM of a page). That's it.  Happy Chrome Extension-ing ;)", "date": "2010-01-12"},
{"website": "Hubspot", "title": "Open Sourcing the HubSpot Facewall", "author": ["Adam Schwartz"], "link": "https://product.hubspot.com/blog/open-sourcing-the-hubspot-facewall", "abstract": "In 2011, HubSpot had fewer than 200 employees. By 2013, the number had more than doubled. We wanted to maintain our small-company feel and startup culture, but it was becoming increasingly difficult to learn the names of all of our awesome new coworkers. We already had a process where new HubSpotters would make paper print outs with their names, photos, and bios - and put them on a physical wall. But over time this wasn't scalable, so we decided to make a digital version we call the Facewall. The Facewall is a display in our lobby that rotates through the names and faces of different HubSpotters so you can learn peoples' names as you walk by. There is also an online version which lets you search for the people you work with. There's even a Facewall Game which rewards you for learning the names of your coworkers. It has worked so well for us that we decided to open-source the Facewall so that other organizations could join in the fun. So go checkout the Facewall !", "date": "2013-06-04"},
{"website": "Hubspot", "title": "Content Testing Your Way to Happier Users", "author": ["Catherine Groux (She/Her)"], "link": "https://product.hubspot.com/blog/solving-user-problems-through-content-testing", "abstract": "As one of the newest and least-understood UX disciplines, content design is sometimes considered an afterthought, a luxury. The commonly held assumption is that nobody actually reads any of the words on the screen, so why bother? This assumption isn’t necessarily entirely false. In fact, Nielsen Norman Group estimates that people probably read only 20-28% of the words on any given webpage. At HubSpot, we actually translate this finding into a rallying cry for why content matters so much. If people are only reading 20% of the words, it's all the more important we use the right ones. We have such a limited number of words in which we can get the meaning and message right. So as content designers at HubSpot, we’re constantly reviewing qualitative and quantitative data for any indications that our content is not meeting our users’ real needs. Once we identify a potential problem area, we'll write new content that we think would better serve our users, then test it to see how it performs. Along the way, we’ve learned that even a few words can have a huge impact on user behavior. Here are three instances where two sentences (or fewer) have made a big difference in the HubSpot user experience. More feature usage with an improved text link HubSpot users can create Facebook, Instagram, LinkedIn, and Google ads right from their HubSpot account. They can see how well their ads are performing on their HubSpot ads dashboard. This dashboard features a table that shows a handful of metrics customers tend to want to see most, and there’s a small “Edit columns” text link that lets users customize the metrics this table shows as their needs and preferences change. The problem was that even though this ability to edit the ads dashboard has existed for a long time, some users didn't see it, and they were understandably unhappy that (as they thought), the ability to customize their experience was missing. We also saw that sheer engagement with the “Edit columns” link was pretty low. This led us to believe that the copy in the text link simply wasn’t clear. To better emphasize what our text link actually lets customers do, we decided to try changing “Edit columns” to “Add metrics.” After two weeks, the results were in. By changing “Edit columns” to “Add metrics,”  engagement with this link increased by 41%. Now we’re finding that our customers have a much better understanding of how they can edit their dashboard table. More people are using the customization feature, and more users are happier with the tool, because they're using it to its actual potential. So that's a win in our book. Align with customer goals with updated CTAs When people go to the HubSpot pricing page, they'll see a row of “Talk to Sales” call-to-action buttons (CTAs) for the products they can only purchase by speaking to a salesperson first. Not every product requires speaking to a salesperson, but some do. While there’s nothing wrong with this straightforward CTA, we noticed in user testing that the language was rubbing some people the wrong way. After all, \"talking to sales\" is rarely a user's ultimate goal. What they really want to do is learn more, get more information about the product, weigh their options, do the research they need to do before they can decide. They don't want to \"talk to sales\" as much as they want to build their own expertise. To better convey this idea that users will get truly useful, helpful information from our salespeople and not a high-pressure sales pitch, we decided to test changing “Talk to Sales” to “Talk to an expert.” After a few weeks of testing, the data on whether users were more likely to click “Talk to an expert” or “Talk to Sales” never hit statistical significance. In other words, the results of our test were inconclusive. However, we know that the impacts of copy changes can sometimes extend beyond the first click, so we wanted to look further down the funnel to see if there was any other sort of impact. For this particular test, that meant not only looking at how many people clicked the CTA, but also how many of those people actually went on to book a meeting with our salespeople. In doing so, we found that users who clicked “Talk to an expert” were 22.15% more likely to actually book a meeting with our sales team than users who clicked “Talk to Sales.” In this case, by changing the copy, we didn't change the number of people who clicked the CTA. But just as talking to sales isn't the real user goal most of the time, clicking a button isn't our own goal, either. But by making this small change, we encouraged higher-intent users to pursue a conversation with sales, which gave more meetings to our sales team — all from changing two words. Reducing users’ anxiety with helper copy When new customers sign up for HubSpot, we ask them to provide their website URL. The problem was that 21% of people who started our signup process gave up when we asked for this information. Our hypothesis, based on what we saw and heard in user testing, was that people had a lot of anxiety around providing their website URL. Specifically, some people thought our sales team would contact other employees at their company to try to sway them to use HubSpot. We, of course, would never use our customers’ data to do such a thing. We ask for their URL truly so we can give them a more customized experience once they're logged into the product. That's it. To put people's minds more at ease, we decided to clarify this through helper copy. Right below the field where we ask users to enter their URL, we added one simple line of copy saying, “This is between us. We won’t reach out to anyone else in your company.” This test ran for two weeks. When we checked the data, we saw that signup completion increased by 1.6%. While that number may seem small, it means we’re bringing in a significantly higher number of new signups to HubSpot every week thanks to two powerful sentences. These three tests were conducted on different types of copy on different areas of our site, but they had a lot in common. In each test, qualitative or quantitative data showed us that our copy was causing a customer problem. We were able to quickly iterate on that copy to make it more customer-focused. This, in turn, gave us happier customers and a better product experience. Content matters, and whether it’s one word or one paragraph, you should never underestimate the impact it’s having on your customers.", "date": "2019-11-13"},
{"website": "Hubspot", "title": "Meet the Movers and Makers: Adam Darowski, Senior Design Engineer ", "author": ["Hannah Fleishman (she/her)"], "link": "https://product.hubspot.com/blog/meet-the-movers-and-makers-adam-darowski-senior-design-engineer", "abstract": "Name: Adam Darowski Role: Senior design engineer (product designer on the social media team) What song is stuck in your head these days? Music is a big deal to me and it constantly fuels my work. The best album I’ve heard so far in 2015 comes from a new band from Ipswich, UK called War Waves. I recommend the track “Trophy Life” . How do you like your coffee? Hand me the cone of shame because I’m a tea drinker. Nothing fancy—black tea, no cream or sugar, steeped until the cup is empty. Rinse and repeat all the live long day. What’s one thing most people don’t know about you? Hm, how about a couple things? First, I recently started recording music after taking a decade off. Second, I created an alternate baseball Hall of Fame populated by a mathematical formula (because I’m a baseball history and stat nerd.) Now, down to business. How did you become a designer at HubSpot? I actually joined HubSpot in December of 2013 in a somewhat experimental role. I tend to bridge the gap between design and development and I was brought in to do just that for the social media team. At HubSpot, professional growth is taken very seriously. I’ve taken turns expanding on both sides of my skill set—getting deeper into the implementation side of things and then getting more involved in product design. I’ve enjoyed both, but been more comfortable expanding on the product design side. Fast forward to today and I’m the product designer for social and for a new product we’re working on (and planning to announce at INBOUND .) What’s one important thing you’ve learned from your fellow designers here? Chase Oliver, the original product designer on social, showed me that good product design goes way beyond the screens and interface elements you’re building. You have to think deeply about the user—like, what their job is and what percentage of their day is spent doing the job your app helps them do. For me, this was a bit of a wake-up call. Social was all I worked on, so it was naturally a big deal to me. But our customers were often one-person marketing teams and only had about twenty minutes to dedicate to social each day. Social media was overwhelming to them and they didn’t know how to be effective in such a short amount of time. Through copious amounts of user research , we identified what our customers needed to do in social to be successful. We focused our efforts on improving those tasks and workflows. We called it the Social Media Daily Checklist . But the nice thing about HubSpot is there are a ton of bright people everywhere. One of my strongest held design principles came from Jeff Dwyer, a backend developer I worked with on social (and had previously worked with—he was the one who brought me to HubSpot.) When building our Social Media Reports, he was insistent on never showing numbers without providing context that explains what the numbers mean. There are many ways to show this context, such as how well the user is doing compared to their previous performance or the performance of other customers like them. Our social reporting ended up not only showing statistics, but telling a story. What was your proudest moment at HubSpot so far? I think the proudest moments have been product launches. I touched upon the social reporting launch above and wrote about it in detail previously on this blog. The Inbox launch was also a big deal for me. We took a bit of a design gamble there, spending a large amount of effort on a feature users weren’t really explicitly asking for. But once they started using it, it was obvious to them that it was the feature that tied the whole social product together. What’s your favorite part of the Culture Code and why? Slide 51 references how HubSpot offers “the autonomy to be awesome.” This is what brought me into HubSpot. I’m a huge fan of shipping. Designing and building is fun, but it is most fun when it is an interactive experience with your customers. HubSpot gives me the freedom—every day—to have ideas, try things, and see how they work. It’s okay if something isn’t perfect the first time. The goal is to learn from that and make it awesome by the time it is released to all users. But a part of the Culture Code that hits particularly close to home for me begins on slide 11. The deck talks about how “people have dramatically changed how they live and work.” It then shows the workplace evolving from “Office” to “Wherever” and the hours going from “9-5” to “Whenever.” This is a big deal for me because I live in the mountains of New Hampshire, over 70 miles from the office. I commute in two days per week and work from home the rest of the time. My tech lead works from Alabama (and comes to visit us once per month). If we were required to be in the office every day, neither of us would be working at HubSpot. HubSpot’s flexibility on the workplace opens us up to a much wider pool of candidates. That said, I’ll be looking to hire a front-end developer for my team sometime within the next few months. I don’t have to consider only candidates who live in the Cambridge area or are willing to relocate close-by. Because our team is already remote, I can look for a kickass candidate anywhere. If you think that’s you, I’d love to talk to you! I’m adarowski@hubspot.com . That's all from our mover and maker this week, but you can follow Adam here . Stay tuned for our next profile and check out Síle Brehony's in case you missed it!", "date": "2015-06-12"},
{"website": "Hubspot", "title": "Name Dropping: Meena Vembusubramanian, Senior Product Manager, Amazon Web Services", "author": ["Francesca McCaffrey (She/Her)"], "link": "https://product.hubspot.com/blog/name-dropping-meena-vembusubramanian", "abstract": "Name Dropping is a Q&A series that aims to elevate the stories of women and nonbinary people leading in the tech space. The idea came from Angela DeFranco, a Director of Product at HubSpot, who said one way to be better allies is to name drop more women and nonbinary people in discussions of achievement, inspiration, and disruptors in tech, instead of referencing, time and again, the same set of (often male) leaders. This edition of Name Dropping features Meena Vembusubramanian , Senior Product Manager at Amazon Web Services . You’re currently a Senior Product Manager at Amazon Web Services (AWS). What’s one particularly exciting challenge you’re working on right now? At AWS, I work on developer- and IT professional-facing products that our customers use to build the applications and tools you and I are familiar with. I really enjoy working closely with builders, and getting to see how different trends in the industry are shaping how products are built ⁠ —  whether it’s a personal finance app you use at home, or a ride sharing app you use on the go, or something entirely B2B, like software that powers hospitals. If you think about the cloud adoption journey ten/fifteen years ago, we were at a point where everyone owned and operated infrastructure within their own premises. As cloud technologies evolved, we saw a lot of movement into the cloud. Today, that landscape has evolved to enable adoption that wasn’t possible before, but also to make some of this migration a bit tricker. Developments in technology and scale have enabled large or latency-sensitive applications to securely move into the cloud in a way that wasn’t readily possible before, and the trickiness comes in the form of new legal requirements around localization and handling of consumer data. With all of these changes, now we’re seeing some novel and hybrid approaches to architecture where builders are being thoughtful about where resources live, rather than adopting defaults. This general space and seeing how the customers in different industries are thinking about evolving their own architectures and products is super exciting for me. I love getting to see this evolution across multiple different industry contexts. Who do you think has helped you become a great leader, either as an inspiration or a mentor? For me, it’s a combination of people in my personal and professional life. One formative experience that will always be dear to me is my time at Olin College. Olin is very unique, particularly as an engineering institution, in that the student body is largely gender-balanced. Getting to learn with and from an awesome set of female classmates, continuing to stay in touch with them and seeing their careers progress in different directions, has been really motivating and inspiring for me. Particularly when I’m dealing with challenges, or decisions ⁠ —  if I’m unsure on whether I should go for that next promotion or next job, for example ⁠ —  seeing people I relate to navigating similar decisions successfully, or learning from those situations and sharing their wisdom, has proved salient to me in both my career and my life. Workwise, I’ve been lucky to cross paths with a number of inspiring female colleagues and mentors in a few different organizations, be it at my previous job at Veo Robotics or currently on my team at AWS. The other person I’ll add to the list is my sister, who is my ultimate source of Real Talk: she’s my harshest critic, but also strongest supporter. I’m very grateful to have her as a sounding board, no matter the topic. What advice do you have for other product managers when it comes to scaling high-performing teams? Table stakes for successful product management is understanding your customers and having real clarity on what problem you’re solving for them. Being genuinely interested in and passionate about the space you’re working in really helps with both of those. Beyond that, one thing I’ve come to realize in the past few years is how important it is to thoughtfully set up the people and process aspects of a team to be able to deliver on a product vision. Getting questions like “how do we make decisions?” and “what data do we look at?” right in the beginning is critical to being able to scale yourself to be more effective and to help the team be more effective once you are making more decisions and higher impact decisions. Unless you have that alignment up front, you’ll walk into every single meeting without a compass, and find yourself having to set the stage all over again. This makes it very difficult to work through all those pieces to make decisions or drive execution. This is not something I appreciated quite as much earlier in my career, but I have since gained a lot of appreciation for how challenging this can be, especially when you’re trying to do it from scratch at a start-up. How do you stay connected to user and customer feedback? I love taking every chance I get to talk to customers! I also make sure I spend time talking to people who are working with customers: sales, team solutions, architecture teams, etc. And it’s important to hang out on the internet where your customers hang out ⁠ —  where are your customers looking to get information? Find insight on what’s difficult to use about your product in commonly asked questions on Stack Overflow , for example, or through industry news outlets. Then, the important part is bringing that into how your team makes decisions and prioritizes things. If you’re considering a launch or a feature change, you need to get into the habit of asking “How will customers react to this? How is this going to affect customers?” rather than just “If we make this change, how does it affect our development roadmap?” And then, so you’re not just over-indexing on a small sample size of use cases, reference these questions back to one or two marquee customer use cases in your mind. You were a mentor for Girls Who Code . What would you say to women pursuing STEM careers? Mentoring for Girls Who Code was such a fun experience. It was incredible to get to work with one student over a semester and see her confidence and her comfort in her skill set go way up over the course of the twelve weeks, and to see all the questions she would ask. In terms of advice, I would say that early on your career, you should focus on improving your technical skills and building out a broad toolkit. The cost of not taking those risks gets higher and higher the longer you wait. Even ten years into your career, it’s a little bit harder to completely switch tracks. The skills you need to make that jump are at a very different bar at five or ten years in, than if you’re trying to do that one year, two years into your career. The other challenge I’ve been working on is that sometimes when I’m working on a team, and I see people having a hard time with a particular area, I feel a need to help. Women especially, I think, are sometimes more inclined to give in to this impulse. So one thing I’m trying to do is to separate this category of things that I don’t necessarily own but feel the need to help with from the ones that I actually own and I’m responsible for delivering and getting across the finish line, to make sure I split my time accordingly. At the end of the day, you need to balance your time and energy. When you’re in this reactive mode, trying to troubleshoot or unravel a situation you don’t own, it’s hard to still have the energy and focus to execute on a problem that you do own and are responsible for the delivery of. What’s your greatest career achievement to date? In a nutshell, it’s being able to say I was part of launching products, taking them from zero to one in a couple of different contexts. One product that comes to mind is one we’ve worked on at AWS, where we launched an event-driven compute product, Lambda@Edge . I got another chance to launch a product again at Veo, really from ground up as part of a small team. Who’s one woman in technology you’d like to name drop and why? I’m going to name drop Molly McCarthy , who is the head of sales and business development at Veo Robotics. She has this incredible way of parsing and processing complex data to narrow it down to the pieces that really matter to the customer, or are actually imminent decision points. She is just awesome to watch in action and work with! I also really appreciated the chance to see up close a model of how a high-achiever maintains balance: She has a rich personal life, but balances this with a discipline and focus on her career. Both she and her partner have challenging jobs, and seeing an example of a couple who’s very real about getting it to work, but also very real about the sacrifices that you sometimes need to make, was inspiring. Favorite show you’re currently streaming? We’ve been watching a lot of Man Like Mobeen , which is on Netflix right now. It’s a very, very funny but also very real take on being brown in the West. It really gets to the point on race and class, but it’s also some of the funniest writing I’ve seen in awhile, and it’s from a different voice and perspective than you see a lot of shows typically come up from. Guz Khan, who’s the director, as well as a writer on the show, is hilarious. Know another woman whose name we should drop? Tweet us at @HubSpotDev with ideas. This article originally appeared on Medium .", "date": "2020-06-10"},
{"website": "Hubspot", "title": "MySQL and Unicode: Three Gotchas", "author": ["Owen Raccuglia"], "link": "https://product.hubspot.com/blog/bid/7049/mysql-and-unicode-three-gotchas", "abstract": "Unicode support in MySQL is a pain — I lost a few hours to it today, and it won't be the last time. So here are the three MySQL unicode gotchas that took over my day. They're all based on this simple table: CREATE TABLE utfail8 (\n    str VARCHAR(250) KEY ); Gotcha number 1: In the latin1 character set, 'café' = 'cafe'. If you have a primary key or other unique constraint on your data, you can't insert both, and any SELECT queries for 'café' return the same results as queries for 'cafe': mysql> insert into utfail8 VALUES ('cafe'); Query OK, 1 row affected (0.00 sec) mysql> insert into utfail8 VALUES ('café'); ERROR 1062 (23000): Duplicate entry 'café' for key 1 At a glance, this violates one of my fundamental rules for \"equals:\" when I say WHERE str = 'café', you do not return 'cafe': those strings are different. The MySQL folks are quick to point out that it's not a bug . As someone who just wasted hours on variations of the feature, I think that's about as convincing as this proof that 1 = 2 . I wish it had just thrown an error (or warning), like if I had tried to insert a 200 character string into a VARCHAR(100). It'd be a cool feature if it weren't so easy to forget about. Anyway, the fix is nice and easy: just ALTER TABLE utfail8 MODIFY str VARCHAR(250) CHARACTER SET utf8 . Most of the time, this is enough. Gotcha number 2: Your column has the right character set, but you still can't INSERT 'café' ! This is about when you start losing hair; utf8 knows the difference between 'é' and 'e', right? So what's going on? If you're unlucky (like me), you'll start to question utf8, read up on collations, and waste time trying a few of them out. It turns out that, while SELECT's still not broken, your IDE might be. I ditched Toad and went back to basics, when the same queries that failed on my machine worked fine on @danmil 's plain mysql prompt. Gotcha number 3: It's time to push to QA; I run the ALTER TABLE to set the character set to unicode, and I run the python script I was fixing in the first place... and it fails, even after you \"fixed everything.\" So, I open a mysql shell on the server, and try the test script out, but it fails, too: mysql> select * from utfail8;\n+------+\n| str  |\n+------+\n| cafe |\n+------+\n1 row in set (0.00 sec)\n\nmysql> insert into utfail8 VALUES ('café');\nERROR 1062 (23000): Duplicate entry 'cafÃ©' for key 1 The ugly end of that error should catch your eye: it's completely mangled the unicode. Try running SHOW variables to see what's up. Here's what my client said: mysql> SHOW variables LIKE '%character_set%';\n+--------------------------+----------------------------+\n| Variable_name            | Value                      |\n+--------------------------+----------------------------+\n| character_set_client     | latin1                     |  <--- Hint: This is the problem\n| character_set_connection | latin1                     |\n| character_set_database   | latin1                     |\n| character_set_filesystem | binary                     |\n| character_set_results    | latin1                     |\n| character_set_server     | latin1                     |\n| character_set_system     | utf8                       |\n| character_sets_dir       | /usr/share/mysql/charsets/ |\n+--------------------------+----------------------------+\n8 rows in set (0.00 sec) Yep: it doesn't take an IDE to screw up your input. Anything — a mysql prompt, Toad, a database connection object in your python script — can mangle unicode like there's no tomorrow, with the right (wrong) settings. This was the hardest of the three to track down... and of course, like any hair-tearing bug worth its salt, it only showed up on QA or production. The good news is, it's easy to fix, too: just run SET character_set_client = utf8. To fix the Python script, I just ran that query right after opening a connection. How much hair have you lost to unicode lately? Know of any more nasty mysql character set \"gotchas?\"", "date": "2009-07-02"},
{"website": "Hubspot", "title": "Making DRY Go Beyond the Codebase", "author": ["Adrian Mott"], "link": "https://product.hubspot.com/blog/bid/84653/making-dry-go-beyond-the-codebase", "abstract": "DRY is a lesson that most developers learn early on -- the common idiom \" Don't Repeat Yourself ,\" standing for a best practice of not reusing the same code more than once.  It's a principle of object oriented programming, but one that's powerful enough to go way beyond codebases - it's a major principle of scalability in general. Take your everyday routine for instance, if you're like me, you probably deal with a varying number of questions throughout your typical day.  Working on the Platform team here, my questions typically come from outside developers who are wondering about developing apps, and our APIs.  What I eventually came to realize is that many of the questions are similar in nature, sometimes identical even, and answering these same questions over and over simply wasn't a scalable way to do my job. Enter documentation - which many of us simply scoff at and undervalue in importance.  No one likes to write documentation, but what may folks don't realize is that documentation creates a more scalable and efficient way to run any development team, business group or company in general. Try this: the next time you get a question that you've heard and answered before, write down the answer in a doc, website, wiki or somewhere public where the information can be consumed without your involvement. (aside: the wiki here at HubSpot has grown immensely overtime, and though it can sometimes be difficult to navigate, it still proves immensely effective after all these years - when the company was younger though, it was awesome for situations like this, and I recommend it for any startup). What you should find as time passes and you continue to note these answers is that you've created an awesome FAQ for your job which will be really helpful for many people around you to see what you do and what sort of value you add.  Even better though, this FAQ has added scale to your job because you've automated and manual question answering that used to take up chunks of your day - questions can be answered more efficiently by directing the askers to this FAQ. This practice is an example of how to take an excellent development practice and apply it to other parts of any business.", "date": "2012-03-30"},
{"website": "Hubspot", "title": "I’m a Former HubSpot Engineering Co-op. Here’s Why I Chose to Work Here Full Time.", "author": ["Jonah Min (He/Him)"], "link": "https://product.hubspot.com/blog/from-intern-to-full-time-at-hubspot", "abstract": "“Wow, that sounds like real work.” I remember driving through Vancouver on vacation with my family when I heard this from my dad. He had just asked me about my co-op at HubSpot and what I was working on, and after describing what my current project was he expressed surprise that they were giving me what he considered “real work.” It turns out that at his company, interns are given small side projects with little to no risk of breaking things. That difference in responsibility is what sets the co-op program at HubSpot apart from the other opportunities I looked at. I had heard so much about how HubSpot treats their co-ops like full-time employees, how they were even given the same interview as full-timers. I wanted to experience that for myself. And boy did they really have you hit the ground running. I started by working on smaller issues, of course, but they quickly have you work on bigger and bigger projects, and before I knew it, an email was being sent out to notify customers about a significant change that I had made and deployed myself. All of this, within the first month of my co-op. Soon after that I was working on larger projects, working closely with other teams, and even having other people ask me for help (which at the time was crazy to me.) At no point during that process did it ever feel like I was given a small side project, or that I was “just the intern.” I really felt like the work I was doing meant something to someone, and that the work I was doing was “real.” It was amazing. In just two or three months I already felt like I was growing as a developer more than I had during three years of college. You’re encouraged to ask for help What contributes to that growth are the people I work with. Coming from my last co-op, I was used to getting sparse feedback from the senior developers and feeling almost forgotten as I sat around for what felt like ages to get a little bit of help or feedback. At HubSpot, people are willing to drop what they’re working on to help you out, and it never felt like people were frustrated that they were being distracted from their work. I know it’s cliché for employees to say that their favorite thing about the company is the people, but I truly believe that the people are what make working at HubSpot amazing. Without them I wouldn’t have enjoyed my co-op nearly as much as I did, and I will never forget the memories I made with the other 35+ co-ops that started with me. My story isn't the only one. Hear from more engineering co-ops on why they've decided to return to HubSpot. Around three months into my co-op, I sat down in a conference room with my tech lead Talia for our weekly 1on1s, when Anthony, the director of engineering for our product group, also stepped into the room. Initially I freaked out a little bit, thinking I was in trouble. As I was imagining how I’d explain to my parents that I got fired from my internship, Talia and Anthony both smiled and extended me a full-time offer for after I graduated college. I couldn’t believe it. People often tell you to “play hard to get” and to negotiate when you receive an offer but because of the experiences I had during my co-op, I accepted on the spot. I knew HubSpot was the place for me. After I completed my co-op in August of 2018, I did some part time work in my last semester of college and started full time after I graduated in May of 2019. The weirdest part about transitioning from co-op/part-timer to full-time, was that there was no transition. Being treated like a full timer during my co-op meant I was already prepared to work full-time. I’d say the biggest difference was in the size of the projects I was able to take on. A co-op or intern has an inherent deadline which is when their co-op/internship ends, but when you work full time you’re able to take more interesting projects that take a little longer to complete. It’s a little scarier, but a welcome challenge. Your team understands (and helps you fight) imposter syndrome That doesn’t mean I didn’t run into any hardships. The biggest challenge I faced wasn’t even related to what I was working on: it was imposter syndrome. While I was a co-op, even with the responsibility of a full-timer, I knew that my managers would understand if I messed up. I was new, after all. When I started full time, because I didn’t feel like a new employee anymore (even though I technically was), I started to push unrealistic expectations on myself. I needed to finish larger projects quicker, to write code that would never break, and to know the ins and outs of every project. This quickly took its toll on me. I started to feel myself spiral into a pit of negativity. If something broke or took me longer than I expected it to, I started to worry that I didn’t deserve to work at HubSpot, and that it was only a matter of time before I was fired. Eventually I realized that the reason for my imposter syndrome was that I was trying to tackle every problem on my own. I thought being full time meant doing everything on my own, but really, it’s knowing when you should reach out and collaborate with others. Sometimes there are problems that you just can’t get over alone, and so I turned to my coworkers for guidance. I reached out to my manager, my engineering lead, other senior developers, and asked them for advice on how they deal with things like imposter syndrome and how I could grow as a developer. I got a wide variety of answers, but there was always one common thread in each of their responses. No matter how much experience they have, or what their title is at the company, they all felt a little bit of imposter syndrome. No one is perfect, and everyone makes mistakes. Instead of letting that burden consume you, just continue to try your best, make mistakes, and learn from those mistakes. Working here is more than just a job I used to believe that finding a job after college was just a means to an end.  I thought that it didn’t matter which company I worked for as long as they paid me enough to fund my hobbies and interests outside of work. Working at HubSpot made me realize how important the right work culture and environment are for your work performance and your mental health. I’m surrounded by coworkers who aren’t trying to bring me down and instead want to support me and work together to achieve something greater. I’ve grown so much as a developer and as a person over the past few years at HubSpot, and I owe it all to the support I get from my coworkers, and the great work culture I’m a part of. If all of this sounds good to you, check out our open positions and come grow with us.", "date": "2020-08-26"},
{"website": "Hubspot", "title": "Dreaming in codes", "author": ["Stephen Huenneke"], "link": "https://product.hubspot.com/blog/bid/36853/dreaming-in-codes", "abstract": "Lots of folks have work dreams, in fact around the office we like to share our more bizarre dreams with one another to determine who is most likely going insane each sprint.  I figured I'd share some of my most recent and most interesting dreams here! Dream 1: So there I am in the office with our CIO and another developer trying to solve some rather nasty bugs in our application that handles the creation of new user accounts and spinning up their HubSpot portal.  We keep discussing the issue of scalability and how it's just not going to be able to handle the throughput for the rate our business is growing.  As we're discussing this, someone keeps going behind a nearby desktop computer and removing plates full of pizza crusts.  Finally I stop the conversation: Me: \"Why are they removing all of those pizza crusts from that machine?\" CIO: \"That's the sign up application's box, it runs on pizza, didn't you know?\" Other dev: \"Yeah, that's the scalability issue, it eats pizzas too fast for us to clean out the old crusts.  No one can be here all the time to get the plates out before it starts to get clogged.\" [Eddie, another developer and a very good friend of mine, walks by eating a plate of the app's pizza crusts and waves at me.] Me: \"Maybe we can get Eddie to eat the crusts faster?\" Other dev: \"I don't know...I think that would buy us some time, but probably won't scale forever.\" Me: \"So..why exactly does it eat pizza?\" [Silence] CIO: \"Not sure, but it needs pizza, and we don't have time to fix that part right now...\" Dream 2: I'm dreaming in RRDTool logs.  I'm not kidding, I'm completely stuck in code, I can't figure out what I'm doing wrong, but I can't get our data to record properly.  It just won't work.  For the life of me, I know the configuration is completely correct. Finally I force my dream to stop reading RRDTool config info and instead look at my cron scripts, which were setup wrong.  The data is better.  My sanity is questionable as I wake up wondering why the RRDTool suddenly makes noises similar to my alarm clock... Dream 3: [This requires a little context, my particular scrum team is currently embroiled in a complete rewrite of one of our C# apps in Java] I'm at my dojo (not that I have a dojo I go to in real life), and I'm training with a group of other people to fight our foe.  Our swords must swing fast and precisely or else we will be overtaken immediately.  Our swords are katanas and of the highest quality, for they are Java(TM) swords.  They can strike exactly as we wish them to, but without training, it is useless and clumsy. We practice over and over, until the time is at hand.  Our final test, is to face the wielder of the double edged sword known only as C#.  He is swift, brutally strong and very determined to never lose a battle.  I am forced to do battle in the dojo itself, then in the outdoors, then in the land of cron scripts (oddly enough, this land is not the same as the one in the previous dream), and finally we in some room which looks rather similar to my web browser.  Just as I am about to strike a winning blow against the foe, I am awakened by the sound of bells ringing and ringing again...I have not defeated C#, I have only postponed the final duel until we meet again! Dream 4: [Note: HubSpot uses the Hibernate ORM for a lot of our Java web apps] I can't make the phone stop ringing.  It's the hibernate configuration calling, but I don't want to answer the call.  It keeps ringing.  I change all the variables.  No matter how many times I set the hibernate.call_stephen_while_sleeping variable to false, it keeps ringing.  I don't even know where the setting could be getting overridden!  Finally I start looking at garbled source code and realize it's a dream.  Then I realize that the sound of the phone is real.  Then I realize it's not Hibernate calling at all, it's my brother, a U.S. Marine in Afghanistan, calling me at 2am on a satellite phone!  He's just calling to say hi, no messages from Hibernate *phew*. Anyone else have some awesome dreams like this?", "date": "2010-03-17"},
{"website": "Hubspot", "title": "Making Hundreds of Apps Fast and Reliable", "author": ["Zachary Friss (He/Him)"], "link": "https://product.hubspot.com/blog/making-hundreds-of-apps-fast", "abstract": "2019 was a big year for the HubSpot Product team: we committed ourselves to providing our customers with a faster, more reliable experience across our entire product. The mission had a catchy name, 'Make HubSpot Fast', and had steadfast support from both Engineering and Product leadership. While HubSpot apps have had internal availability and latency Service Level Objectives (SLOs) for years, the percentage of apps meeting those SLOs had begun to decline over time. Teams cared about performance, but there was no framework in place for them to prioritize meeting these SLOs over their other customer-focused work, particularly new feature development. To deliver HubSpot customers a faster, more reliable experience, we created the Frontend Performance and Monitoring team , responsible for providing relevant guidance and tooling for teams to Make HubSpot Fast. How HubSpot works HubSpot Product & Engineering has structured itself around a set of core values , like \"Think Like an Owner\" and \"Small Teams Win.\" These values translate into our small, autonomous team structure, and our microservice architecture. We have 150+ different teams that own thousands of individually deployable backend and 400+ frontend applications that make up HubSpot's product offering and internal tooling. Most of our teams are entirely composed of engineers who work on either the backend or frontend, allowing them to be fully focused on that part of the stack. These teams build Single Page Applications in React, using a shared library of components from the HubSpot Canvas Design System . These applications are then built by our homegrown frontend build tooling. Even though we have hundreds of packages, our teams are using the same stack and foundation, which allows the Frontend Platform group to provide regular updates, upgrades, and guidance for everyone. How we track SLOs Tracking the performance of Single Page Apps can be difficult, as they are rendered client side and usually depend on async data. Since they're not simple static pages, we can't rely on more traditional timing data such as onload or DOMContentLoaded . Without a metric that we could use directly off the shelf we set out to track the data ourselves. We came up with the idea of a “Time to All Success” metric that would measure how long it took for the page to render successfully. We initially tracked our Time to All Success by having teams specify CSS selectors that should appear on the page when it rendered correctly and CSS selectors that would show up if there was an error. The library would then poll the page for these CSS selectors and once all the success selectors showed up on a page, it would consider the page fully loaded. In the case of an error selector showing up, the page was instantly marked as a failure. We also had a timeout of 60 seconds, and if nothing showed up in that time we also considered that page to be a failure. While this solution served us pretty well for years, it wasn't built for our React stack and had some major pitfalls as a result. First, it was easy for a code refactor to unintentionally remove the CSS selectors used for tracking, causing pages to start failing. Second, it was easy to accidentally “cheat” these checks by having checks defined deep within code splits that may have failed to load. To address these drawbacks we set out to build a new solution. For our new system we set out to build something that would hopefully fix some of the issues we saw devs hitting while also still reporting the same metric data we had before. Our second iteration starts with a static configuration file; this file includes a list of all the routes in an app, and which primary components (or \"NavMarkers\") are expected to show up for a given route. With this static configuration, we will know all of the routes in an app at and after build time. Then, developers can render simple React components, \"NavMarker,\" with specific names in their code. These NavMarker components can be static analyzed and are a little more obvious when they get removed due to a refactoring than the previous version’s CSS selectors. Another added benefit of having this static configuration allowed us to build out app health checks that automatically load all of the routes in an app to ensure they are loading properly—something we couldn’t do with the dynamic nature of the previous solution. Turning data into SLOs The timing data collected by these tools are then sent off to New Relic, a monitoring and metrics platform, and within New Relic we track Availability and Latency scores for all of our apps. For Availability we look at the number of page loads that happened over the time period and then calculate the score with `Successful / (Successful + Failures).` Teams need to have a score of >= .99 to pass. For Latency we use the Apdex score for each app. The Apdex is calculated by grouping users’ experiences into three categories based on a threshold, “T.” In our case “T” means the ideal time it takes for the app to load. Historically, we used a T value of three seconds. With that in mind, we divide all users into these three buckets based on the “Time to All Success” metric data we collected earlier: Satisfied (Page load <= 3 (T)), Tolerating (3 > Page load <= 12 (T * 4)) Frustrated (Page Load > 12 (T * 4)). Then we calculate (Satisfied + .5 Tolerating users) / (Satisfied + Tolerating + Frustrated) which needs to be >= .9 to be considered passing. SLO Tweaks How fast is fast? Given that many of our teams weren't meeting the Latency SLO with a T value of three seconds, we did the logical thing: we made it even harder for them , lowering the threshold further to be a T value of two seconds. While we could have stuck with three second threshold and had plenty of work to do we knew we could do better, and we wanted everyone to hold our product to a higher standard. This drop from three to two seconds also changes the buckets of tolerating and frustrated users. The buckets now look like this: Satisfied (Page load <= 2), Tolerating (2 > Page load <= 8) Frustrated (Page Load > 8). And yes, changing that T value from three seconds to two seconds was a bit arbitrary. In the end, it was a gut feeling about where we wanted our user experience to be and what we thought was possible given our infrastructure and our stack. This change wasn't met with much pushback from teams, as many were already missing the SLO anyway. But of course, there was some healthy skepticism concerning if the two-second bar was even reachable. Not all page loads are equal We also tweaked which page loads were counted in both the Availability and Latency SLOs page load numbers. When looking at the distribution of page load times, the vast majority of the upper 90th percentiles were pages that weren't always \"visible.\" By visible, we mean focused in the foreground of the browser. To track this, we listened to the “visibilitychange” event , and if the visibility state of the page ever changed from “visible” to “hidden,” we ignored the timing data from that page load. Doing so made sure that all page load data was equivalent and we weren’t trying to fight against browsers that deoptimized background tabs and page loads. Proactive monitoring and automation With our new SLO definitions in place, we set out to give our teams a better view of their app’s performance in a repeatable synthetic environment. The goal was for teams to be able to iterate on their app's performance and see improvements when we reduced the variables of which computer or network was being used, or what async data was being loaded. To do this, we built an integration with a 3rd party vendor, SpeedCurve . SpeedCurve provides insights into page load performance via automated WebPageTest runs. With this integration, every pull request that is opened for a project is automatically tested by SpeedCurve. This is powered by our “Branch Previews,” where each build of every application is immediately available to use as if it had been deployed to QA. After each pull request is opened, inside SpeedCurve we can compare against the currently deployed version of the app and look at metrics such as our “Time to All Success” that we calculated earlier, and the size of assets (HTML, JavaScript, CSS, images) while loading the page. Alongside the SpeedCurve tests we also calculate the sizes of all assets in each project and compare them against the primary branch. This way we can see the net change in asset sizes across branches and also track when new assets were made or lost due to code changes. This serves as a sanity check for when a new dependency or feature is added and it increases the size of the bundles in the app. Infrastructure improvements With the help of the other Frontend Platform teams, the Frontend Performance and Monitoring team shifted focus to providing some more infrastructure-level improvements to help teams pass their SLOs. We started experimenting in a few different directions: we upgraded Babel, created some tooling and guidance for code splitting, set a deadline to upgrade to React 16, and made a new bundle that we call “hubspot-dlb”. Babel upgrade One of our first experiments was upgrading Babel from v6 to v7. Babel converts code written in ECMAScript 2015+ (ES6) back to the more supported ES5 version for cross browser compatibility. Once we were on v7 we also worked to externalize the Babel runtime. Externalizing the Babel-runtime allowed us to reference only one copy of all of the Babel runtime helpers instead of the code being added to every JavaScript module in our builds. This change accounted for savings of around 5-20% in bundled JavaScript code depending on the size of the modules. Which amounts to hundreds of kilobytes of JavaScript that no longer needed to be parsed at runtime. This was something we could turn on for all teams without any code changes on their side. Code Splitting Code splitting was also something we quickly worked on to provide some more guidance and tooling around. First, the Frontend Platform teams worked closely with the UX team to provide some user experience guidelines for how loading states should work, taking into account perceived performance. The result event went so far as providing a few different loading components based on different scenarios and how they should show up on the page. We looked at this problem from a UX perspective instead of just a pure performance one because a page that jumps around as it loads in or shows multiple loading spinners is a poor experience even if it’s “fast” according to the metrics. We built a “UILoadable” component that enforces this well-defined experience for when to show a loading indicator and ensuring there is a failure state if there was a failure for any reason. React 16 Upgrade As we have hundreds of apps at HubSpot, not all of them get the level of attention that they may need to stay up to date, which leads to a bit of a dependency version lag. This also means that our core dependencies, like the components in the HubSpot Canvas Design System, need to work with the multiple versions of React. Because these older apps were holding us back, we set a deadline for all apps to migrate to React 16 by December 1st, 2019. While it took a lot of work, we were able to eventually get all apps on React 16 a month before the deadline. With all apps on the latest version of React 16, we unlocked some core upgrades for our design system such as hooks and Suspense while also upgrading other outside dependencies such as styled-components and react-router to build even better user experiences. Dynamically Linked Bundles With a core stack that is shared among all of the apps, we set out to extract the same core of our apps to a single bundle, called the hubspot-dlb, that we could share across all of our apps and increase the cache hit rate for. The hubspot-dlb or Dynamically Linked Bundle is a concept that we built that is similar to the Dynamic Linked Libraries (DLLs) in webpack and Microsoft Windows. We found that when users loaded a cached version of our apps, they would load over a second faster than cold caches, which is enough of a speedup to get more page loads into the satisfied group. This speedup was seen even if just the hubspot-dlb bundle was cached and the app code wasn’t. To start, we included react, react-dom, redux, styled-components and ImmutableJS. These libraries are large, rarely change, and are core to all apps built at HubSpot, making them great candidates for a meaningful and long-lasting bundle. Where we are now With these changes and the big push to Make HubSpot Fast in 2019, HubSpot Product & Engineering has made great progress. We started 2019 with 11% of teams failing to meet the availability SLO (>= .99) and ended 2019 with 5% of teams not meeting SLO. On the latency side we started 2019 with only 9% of teams meeting the SLO of >= .9 which we were able to increase to 45% to start 2020. We're proud of these improvements, but we still have work to do to get to 100% for our customers.", "date": "2020-03-09"},
{"website": "Hubspot", "title": "HubSpot Partner & Provider Spotlight: Desiree Whitehead, Founder, Howl Marketing", "author": ["Francesca McCaffrey (She/Her)"], "link": "https://product.hubspot.com/blog/hubspot-partner-spotlight-desiree-whitehead-founder-howl-marketing", "abstract": "Some of the best perspectives on HubSpot's product come from those who use it every day. In this new interview series, we profile HubSpot partners, providers, and customers, and ask their thoughts on what our product team should keep in mind while solving for them, and where the future of the industry lies. In this installment, we chat with Desiree Whitehead , founder of digital growth agency Howl Marketing and growth strategist at marketing agency Square 2 . How did you first come to work with HubSpot's products? I was first introduced to HubSpot as a customer while working for the largest drone distributor in North America, who started implementing the platform. After the rigorous five-day training with HubSpot customer training specialist Emily Morgan in Boston, I found myself enthralled with the capabilities and immediately went to work implementing HubSpot Enterprise for my company. Now as a HubSpot solutions provider , I have a new appreciation for this sophisticated all-in-one platform. It’s one thing to be a marketing agency and another to be a growth strategist helping on a ground-level. Having had the opportunity to experience the ins and outs of HubSpot from both perspectives provides me a deeper understanding. I don’t believe my clients would be where they are today without my introduction to HubSpot two and a half years ago. How did you get into marketing? What do you love about it? Is it okay to say “I was born this way!”? It’s hard to pinpoint exactly when it all clicked because I’ve always had a love for business, people and processes. I believe I found my happy place at a nonprofit Jewish organization in Plantation, Florida over 15 years ago. It was there that I realized my passion was rooted in highlighting the importance of finding a story in every single thing you do and having the ability to tell that story in a clear and concise way. What do I love about marketing? It would be easier to say that I’m absolutely obsessed with being a marketer and I’m proud of it! I’ve found that I’m really good at stepping back, analyzing an entire business model at a macro level, and applying strategy on a micro level. After perfecting my craft, I’ve discovered that diving into graphic design is where my creative side gets to shine and my love for people is where customer journeys live. I am marketing, marketing is me. What's the most important lesson you've learned so far as a founder? You could ask me this every single day and I would have a different answer. Every lesson I've learned along the way was important: patience, adaptability to different situations, and diversity. Being true to who you are, however, is the most important thing I’ve come to discover. Along my journey to becoming who I am today, I’ve knocked on every door and pushed every boundary, within reason, that stood in the way of my success. I’ve achieved my Bachelor’s degree, turned around and earned my Master’s degree, and to this day continue to take certification courses. Knowledge is power. My parents always remind me “You know who you are, we know who you are, now go out there and show the world who you are.” That in itself embodies the most important lesson I’ve learned⁠ — if I would have allowed outside influences to shape who I am, I wouldn’t be who I am. In your opinion, what's the most important thing for HubSpot's product team to keep in mind when solving for customers today? It is so very important for the product team to continue to grow, push limits, and continue to ask for feedback from those of us who are in the weeds of this platform every single day. Having the opportunity to be selected as a member of the HubSpot Customer Advisory Board recently, I’ve found that these are the areas where listening to feedback is already proactively taking place within HubSpot. The fact that the co-founders are so involved in the feedback cycle of the platform speaks volumes to their dedication to continued growth. The most important thing would be for HubSpot to continue doing what they do: grow better . What's one small thing that makes a difference when it comes to choosing what kind of marketing software you use? It’s not about the big, flashy name; my focus is to do good marketing and in order to do that, I’d like to provide the best all-in-one solution to my clients. The one small (but mighty) thing that makes HubSpot different is the FRIENDLY customer service. Your level of customer service, arsenal of resources, and friendly smiling faces I can tell are on the other side of the phone are truly unmatched. What about one big thing? Diversity. You may ask yourself why or how does diversity play a part in choosing marketing software or any consumer product, for that matter. The answer is simple. If I, the consumer, cannot see myself when I browse your website, in images of the founders, executives, account reps or content writers, then I don’t see myself in whom I’d be working with. So what would encourage me to utilize your platform? Talking through the benefits of the platform, sure, that definitely helps in making a decision, but the key is diversification. It’s evident that HubSpot is doing a wonderful job in taking leaps and bounds toward a greater tomorrow through the forums and meet-ups of Black at Inbound and I'm excited to see what the future holds. What's one prediction you have about the future of marketing and demand generation? This is something that digital marketers and growth strategists have been discussing for some time: marketing and demand generation go hand-in-hand. The marketing industry has gone digital and so many people have recently become more aware and willing to take note; whether it’s attributed to COVID or other areas, over the last decade the market has shifted and ways of getting your product in front of consumers have altered dramatically. The future of marketing and demand generation will remain digital. So find a platform that grows and evolves with you! What do you want to see more B2B software companies focusing on in 2021? In 2021 I’d like to focus on diversity, inclusion, and being the best version of yourself; this will be beneficial to us all. Want more profiles of tech industry leaders? Check out our Name Dropping series . Interested in working with a product team that solves for both marketers and developers? Check out our open positions and apply .", "date": "2021-01-26"},
{"website": "Hubspot", "title": "Ten Minutes to Help Secure Your Online Accounts", "author": ["Ryan DiPetta (He/Him)"], "link": "https://product.hubspot.com/blog/ten-minutes-to-help-secure-your-online-accounts", "abstract": "Look, I get it. Security for platforms where you store your data can be intimidating. And scary. And sometimes, it seems like you’re never going to know where to start. It can be tempting to avoid the whole mess, not to bother at all, and to go on with your life. After all, what’s the worst that could happen? Or, maybe you’re coming at it from the opposite perspective: no matter what you do to try and secure your accounts, you’ll never be as good as the hackers are, so why bother? No matter where you’re coming from, I have bad news and good news. To return to my earlier question, what’s the worst that can happen? Pretty bad . But what can you do to avert it? (Yes, even in the face of all of those talented hackers out there.) Actually, a lot. That’s the good news. And that’s why I want to encourage you to take just a few minutes today, maybe while you drink your morning coffee, to do security. Not to read think-pieces about it, or get lectured by some stranger on the internet. Just to cut to the chase and do it. It’s that easy. Note: In the following tips I use your HubSpot account as an example, but you can apply this advice to most, if not all, other important internet accounts, and should definitely consider doing so. Step One: Keep Yourself Safe Just like they say on airplanes, you have to put on your own oxygen mask before you can help anybody else. The easiest thing you can do today is secure your own user account, and luckily for you, that’s also one of the quickest and most effective steps you can take. Two-Factor Authentication (2FA) If you haven’t already, take a minute ( maybe two, max) to set up 2FA for your HubSpot user account . Make sure to save a copy of your backup codes and set up a secondary method to make sure that you won’t need help getting back into your account if you lose track of your phone. Given the choice, an authenticator app like Google Authenticator is a more secure option than text messages, but any 2FA is better than none! Use whatever works best for you. 2FA is the absolute best thing you can do today to make sure that your online accounts stay safe: it’s 99% effective against the most common types of attacks . And, it’s an option all over the internet, not just on HubSpot. Once you set it up for your HubSpot account, consider checking for the option on other sites you use, like your bank website, or email account. You should set up 2FA for your HubSpot account even if you regularly sign in with Google or single sign-on. That way, even if someone gets their hands on your HubSpot password, you can keep this simple extra layer of security there to protect it. Total time: Two minutes. Password Management Next, take a dive into the exciting world of password management. Are you still using the same password for HubSpot that you use for the Yahoo account you made to play fantasy football in high school? Is that password “ Password123! ”? Do you know how many other people have used Password123! before? Bad news, friend. Take it from the folks over at HaveIBeenPwned.com : It’s probably time for a change. Sharing passwords (or password variations) between multiple websites exponentially increases the amount of damage that password getting out into the world can do, especially since you likely already share usernames and email addresses between those sites, too. Using a password manager takes all the difficult work out of choosing a different password for every site you use by automatically generating passwords that are difficult to guess, and means you don’t have to remember each of those different passwords every time you want to log in. The best part? Most web browsers now include a built-in password manager, so you don’t even have to do the hard work of comparison shopping for one (though you can , don’t let me tell you how to live your life). Safari , Chrome , and Firefox now have various password management solutions included natively. If you want to do that comparison shopping after all, you can also consider third-party password managers and storage solutions, such as 1Password or LastPass . Start using a password manager and change your passwords as you use your accounts. Focus on the most valuable accounts first, like your personal banking, credit card, PayPal, email, and any systems where you might store personal information about your customers or contacts (like HubSpot). Password managers can also store notes or other pieces of information you want saved, meaning you can use them to store important things like your two-factor authentication recovery codes, security question answers, or other info you want to keep safe. Total time: Two minutes to set one up in your browser. Maybe ten to shop around. Sign Up for HaveIBeenPwned Email Alerts That lovely screenshot I included in the previous section? It’s from an indispensable site for the modern internet: HaveIBeenPwned . In less than a minute, you can enter your email address and sign up for email alerts if that address shows up in a data breach. If you get an alert like this, don’t panic! Simply change your passwords and set up 2FA on any sites where you may have used those credentials. Total time: One minute. Maybe. If you round up. Step Two: Keep Everyone Else Safe Are you in charge of access policies for some of your team’s accounts? Good news: most providers have some features that can help you both ensure that your users are keeping their accounts secure, and monitor for out-of-the-ordinary access or activity. You can do each of these things in the blink of an eye, and your account will be infinitely safer than it was before. Let’s start with an old friend from a few paragraphs ago: Requiring 2FA This one is even easier than setting up 2FA for yourself . Let’s use your HubSpot account as an example. Using this feature, you can enforce that everyone who logs into your account with their HubSpot credentials has to use 2FA. You’re the boss, so you just have to flip a toggle. That’s it. Enforcing 2FA protects every user on your account quickly, and many providers offer this as an easy option, or even enforce it automatically. I don’t even want to give this one an estimated time, but it’ll mess with the whole format of this article if I don’t, so: Total time: Ten seconds. Really. Familiarize Yourself with Account History Logs This one is more of an ongoing activity, but it’s important to stay informed about what’s happening in your account. As is the case with many platforms, all HubSpot accounts have access to Log In History and Security Activity reports. These reports allow you to see when your users have been logging in, as well as where and how they’re doing so, and keep track of what notable actions they may have taken while logged in. You should familiarize yourself with these logs, and consider regularly reviewing them for unauthorized activity. Total time: Five minutes. Bonus Round: The Wide World of Single Sign-on (SSO) HubSpot Enterprise customers can integrate their accounts with SSO providers , like Microsoft Azure AD, OneLogin, Google, or Okta, via SAML. This allows you to force your HubSpot users to authenticate with your SSO provider in order to log into your HubSpot account. Via the SSO provider, you can then enforce all sorts of security or access policies which your users will interact with as normal when they log into HubSpot. Total time: Getting an SSO provider and access policies set up will probably take longer than a cup of coffee. If you’ve already got one, integrating them with your service provider can usually be done in as little as five or ten minutes. Step Three: Know You’re on the Right Track Seriously, that’s it. Ten minutes, maybe twenty if you really need to find the perfect password manager, and you’re infinitely safer than before. These steps cover some of the most important things you can do as a user in any platform, not just HubSpot, today. That’s how easy security can be, and how quickly you can do it. It can seem overwhelming, but you don’t have to be a certified security expert to keep yourself safe. Some simple steps, a few monitoring tools, and you can become your office’s resident account security advocate. Maybe you’ll even score some more free coffee for your trouble. Want to work for a place that treats growth opportunities and inclusivity just as seriously as we treat security? Check out our open positions and apply .", "date": "2021-04-27"},
{"website": "Hubspot", "title": "Don't Make Me Think: A/B Testing at HubSpot", "author": ["Timothy Downs"], "link": "https://product.hubspot.com/blog/bid/62606/don-t-make-me-think-a-b-testing-at-hubspot", "abstract": "I really don't like doing a ton of choosing. I don't know a ton of developers that do. I think it's because when you choose you expose yourself to the risk of being wrong. I don't think I know any developers that like being wrong. A few weeks ago, I was going to have to make a choice. We weren't sure if we wanted to implement our new social media interactions with links on the right column or buttons at the top of app. Both are good options, so we should set up an A/B test, right? We'll get some data and we'll have an answer. Product owners and other MBA types absolutely love this kind of stuff. They can make a graph and put it on a power point. I like it because I don't have to choose, I know which choice works. The world is warm and fuzzy. Except... There's always an \"except\"; except at HubSpot our A/B testing wasn't very effective or glamourous. Generally, tests were implemented with modular arithmetic based on an arbitrary parameter like an ID and when we really took a hard look at the results, we realized that grabbing a number from a hat would have produced roughly the same results. That was until one of our resident smart people, Dan Milstein ( @danmil ), stepped up and created an awesome testing solution. Now, implementing a test is as simple as adding one line to your code. Dan's solution is able to insure a very close even distribution of the availible options, is extremely fast and allows you to set up reporting. Nirvana reached. After about 5 weeks our testing showed that the results were very close but the buttons won out. Preliminary poking with some of our heavier users has shown that they prefer the buttons. A very big win without any fretting or unnecessary meetings. Isn't working at HubSpot great? Yes, we're hiring .", "date": "2011-04-19"},
{"website": "Hubspot", "title": "Software Internationalization 101: How to Go Global Without Slowing Down", "author": ["Robert Bauch"], "link": "https://product.hubspot.com/blog/software-internationalization-101-how-to-go-global-without-slowing-down", "abstract": "Going global is a big vision for companies and it's just as big an undertaking for their development teams . Since we started internationalizing HubSpot’s marketing software over a year ago, we’ve realized there’s way more to it than translating “color” to “colour”. To create a truly global product from the ground up, organizations have to make a commitment to solving for customers worldwide. When we started our internationalization (i18n) and localization (l10n) efforts, our goal was to make our application feel just as natural for users in Munich or Tokyo as it does for our US-based customers. That meant we couldn’t put it off (we already had customers in 70+ countries at the time) or outsource a solution. (This might’ve worked in the short-term, but it wouldn’t get us thinking habitually global. And, we wouldn’t have had ownership over our source code; not very HubSpotty.) So, we went all in. But there was a catch, a cultural caveat. Our dev team is fueled by flexibility, speed, and complete autonomy. We didn’t want i18n to disrupt that rhythm so we needed to find a way to upgrade the engine while driving the car. It didn’t take too long to realize that this would be a herculean task. i18n usually entails large spreadsheets, product freezes, a lot of back-and-forth between developers and linguists (both of them often speaking different languages, literally and figuratively) and some mundane code writing. This traditional workflow wasn’t going to fly. We had to get creative, early and often, to avoid slowing down development. A year later, we’re still on the road to product i18n. We’ve started to see real results, international customers interfacing with our software in beta, and some key learnings that helped us get here. I wanted to share these findings because I think they can help expand what i18n means to SaaS development teams and ultimately, get more of a dialogue started on the role company culture plays in i18n. Get a Head Start on i18n If you’re an early-stage, fast-paced SaaS startup, going global is probably the last thing you’re thinking about, at least from a product standpoint. There are a million and one things to do so you’re usually focused on building for today or tomorrow, not ten years down the line. HubSpot was no different and we built some technical debt early on that we had to dig our way out of when we started i18n. Luckily, we started thinking about l10n before the business side of HubSpot really needed it so we were able to head off a lot of pressure from outside the product team. More importantly, getting a head start gave us ample opportunity to find the best plan of attack without implementing a breakneck timeline on the team. At the onset of the i18n project our development team was in the process of migrating away from our Python-heavy (Django) stack, built around server-side rendering, and moving onto a static, JavaScript stack. So we chose to marry up the i18n efforts with the stack migration and not pursue internationalizing the legacy code. Basically, we figured while the code was on the surgery table, we’d include the i18n work as well.  This allowed us to incorporate the i18n infrastructure in a very fluid and organic way.  The stack migration was a colossal task, but also incorporating an i18n-friendly infrastructure into the process was pretty remarkable and saved us a lot of energy in the long run. We managed to have a bare bones platform in place within about 4 months and have since incorporated roughly 90% of the app to the new tech stack , internationalizing as we go without ever bogging the team down with an additional rewrite effort. Getting a product to market and iterating is the foundation of development teams like ours. Having a head start on the business meant we could thoughtfully start implementing i18n, without disrupting that pace. There are many factors that go into determining the best time to start thinking about taking your product global, but being proactive will help avoid a mad rush when the continued growth of your company is on the line. Consider Your Dev Culture Before Incorporating Global Cultures Every development team is different. The i18n process that works for one team might not work for another because we all bring unique challenges and workflows to the table. That’s why having a solid understanding of how your team operates is crucial in shaping the optimal path forward. At a lot of companies, i18n can hold everything else up. Human translation takes longer (days to weeks) to process and instead of shipping updates in the interim, developers have to hold off until the translations are ready. It turns into a waiting game. When we were considering traditional i18n/l10n workflows, it quickly became clear that these constraints wouldn’t jibe with our team culturally. Our product organization is built on the premise that we ship quickly ( around 300+ times a day ) without much process or planning getting in the way. The goal is to get something in front of the customer as soon as possible so we can gather and implement their feedback just as quickly. Implementing a top-down approach to i18n would have been detrimental to. We specifically chose not to go down that path, forcing us to think differently. We’ve tried to build automation into a lot of tasks (like sending English strings files to our translation management system (TMS) and building in notifications for completed translations and pull requests) that would otherwise slow our developers down. The most important aspect of i18n for us has been coupling our required tech debt-relief activities and i18n into already planned development projects and then automating as much of the l10n process as possible. These decisions have helped us integrate i18n into our development culture without making it burdensome or attaching a negative stigma to the process. Build l10n Into Your Process, Not the Other Way Around You can probably tell by now that we put some serious time and effort into creating an environment that maximizes our developers’ strengths and lets us iteratively improve our product. So, the last thing we wanted was to hold our team hostage to a translation workflow. We work hard to instill a global mentality within the development team so that we’re always building with international customers in mind. But, we don’t want our developers to have to slow down to manage translations for their projects either. To tackle this, we built an internal service to manage the translation workflow and the connection points between our code repos and our translation management system. The typical workflow looks something like: A developer makes changes to their app that requires an addition/amendment to English copy in the app. (They do this by interacting directly with a “strings” file that houses all the English copy for their project.) They commit their changes to GitHub. The automated service, that we affectionately call Babel, is constantly “listening” for any changes to the English source files. Once the developer commits the change, Babel notices and triggers the translation workflow. Babel is tied to our TMS via a public API connection that allows us to automate the process of shipping the “strings” files and authorizing them for translation. Within a few minutes, Babel is notified that machine translation for the added/amended “strings” is complete. It then pulls them from the TMS and assigns them a pull request in the GitHub project they originated from. The developer that made the change is notified that translated files are ready to be incorporated into their branch. They can then merge them at their leisure. As the human translations are completed (usually 2-10 hours later), pull requests are created by Babel and the developer can merge those into the project, too. Waiting on human translations has traditionally been the long pole in the tent of deploying a localized product. So to counter that delay, we purposefully decided that after an app has been through initial translation we are comfortable with surfacing machine translated strings (for small bits of changed copy) while human translations are in progress. This has allowed our developers to focus on shipping code and not on copy translation. Traditionally, once a new feature is sent to be translated, developers don't deploy changes until days or weeks later once human translation is complete. At HubSpot, Babel lets us ship constantly with machine translations until final human translations are complete. We’re working toward making this step invisible to developers. In the future, they shouldn’t even have to check or merge any translation-related PRs; it will just happen behind the scenes. But for now, by coupling various forms of translation with an automated service, we have cut down a process that can take days to a few minutes. Which leads me to the final thought… Look for Translation Management Services (TMS) Built By Developers, For Developers This point is highly tied to making i18n/l10n work for your team. Unfortunately, in the world of TMS, the software development community is second-tier. The bulk of translation work that is managed by TMS platforms is in the realm of digital documents, forms, books, marketing content, etc., not software product strings. This has led to developers being pigeonholed into using translation workflows that aren’t tailored to their goals, making the process disjointed and tedious. Luckily for us SaaS companies, there are TMS platforms out there, like Smartling (what we use) that are becoming quite involved in the day-to-day lives of fast-moving development teams. Better yet, they’re starting to solve for our use cases. One indicator of a good, development-minded TMS is that they have a mature, well-documented API offering for developers to leverage. We’ve noticed that TMS platforms that make developers lives easier happen to have really sophisticated development teams themselves. Go figure. When I was approached with the prospect of leading the charge on i18n, I didn’t really know what I was getting into. But there were two things I knew for sure. The first was that HubSpot was going global no matter what; we were already expanding rapidly and constantly bringing on new customers in new countries. There wasn’t a question of whether or not we would internationalize our marketing software, it was just a question of how. The second thing was that i18n couldn’t leave us with culture debt. We’ve built a strong development culture that makes building products here challenging, autonomous, and fast. Our process couldn’t disrupt that. Now that we’re deep into i18n, I feel confident saying it hasn’t. The four lessons above haven’t just helped us fix the engine while driving, but replace it with a new, upgraded engine. We’re still learning a lot everyday about how to make this easier for our developers and our customers. Our culture of transparency and constant iteration makes it seamless for everyone to give us feedback and for us to put the feedback into motion. That holds true both internally and externally, so if you have any questions about i18n, want to talk shop, or share your i18n experiences, leave a comment below. We’d love to take the discussion global, too.", "date": "2015-05-18"},
{"website": "Hubspot", "title": "The Self-Referential, Executable svn Commit Message", "author": ["Dan Milstein"], "link": "https://product.hubspot.com/blog/bid/49333/the-self-referential-executable-svn-commit-message", "abstract": "A month or so back, the HubSpot svn repo began to approach commit number 50,000.  And, amid the idle banter about how best to celebrate the event, my friend and scrum team-mate Owen J Raccuglia, aka OJRac , aka Juice, quietly went and coded up a deviously clever hack, which, a brief bout of svn commit sniping later, became our commit 50K. Let's take a look (actual svn server name changed to protect the innocent): $ svn log -r 50000 https://svn.someserver.com/svn\n------------------------------------------------------------------------\nr50000 | oraccuglia | 2010-07-14 00:10:41 -0400 (Wed, 14 Jul 2010) | 6 lines\n\n#/bin/bash\n    svn export https://svn.someserver.com/svn/50k -r 50000\n\n    gcc -xc 50k\n    ./a.out | diff 50k -\n    ./a.out | python -\n------------------------------------------------------------------------ So, what happens if, say, you were to run that commit message as a shell script?  Let's see: $ svn log --incremental -r 50000 https://svn.someserver.com/svn | tail -n +4 | /bin/bash\nA    50k\nExport complete.\n#/bin/bash\nsvn export https://svn.someserver.com/svn/50k -r 50000\n\ngcc -xc 50k\n./a.out | diff 50k -\n./a.out | python - Okay, so, modulo a bit of output noise (which is a slight, irremediable flaw in the hack -- the svn export line should have had a -q -- but we can't change that message now, is part of the overall delight). But anyways, except for that, running the commit message... produces the commit message. But how does it do so? Let's unpack it. $ svn export https://svn.someserver.com/svn/50k -r 50000 That's checking out a file named 50k, which, if we look at the source, is: #include/*\nm='''#/bin/bash\nsvn export https://svn.someserver.com/svn/50k -r 50000\n\ngcc -xc 50k\n./a.out | diff 50k -\n./a.out | python -\n'''\ns='''*/\nmain(){char*_;/*'''\ndef printf(*a):print m\n#*/\n_=\"#include/*%cm='''#/bin/bash%csvn export https://svn.someserver.com/svn/50k -r 50000%c%cgcc -xc 50k%c./a.out | diff 50k -%c./a.out | python -%c'''%cs='''*/%cmain(){char*_;/*'''%cdef printf(*a):print m%c#*/%c_=%c%s%c;printf(_,10,10,10,10,10,10,10,10,10,10,10,10,34,_,34,10,10,10,10);%c#/*%cs='''*/%c}//'''%c\";printf(_,10,10,10,10,10,10,10,10,10,10,10,10,34,_,34,10,10,10,10);\n#/*\ns='''*/\n}//''' Okay, um, it looks like a C program, but also, if you squint, like a python program.  Alright, what does our friend the commit message do with this code? $ gcc -xc 50k It's compiling it as a C program, and, naturally, placing the resulting executable in good old a.out.  Then, gratuitously, just to show off, the commit message does: $ ./a.out | diff 50k - Meaning, it runs a.out, and compares the results with the original source code used to create it.  And... they're identical.  So, in the middle of this process, there's a C quine . Next up, the commit message runs that same program as a python script: $ ./a.out | python - (Of course, this step could have been \"python 50k\" , but that would take the fun out of the C-quine nature of the code). And, when run as a python program, it produces: #/bin/bash\nsvn export https://svn.someserver.com/svn/50k -r 50000\n\ngcc -xc 50k\n./a.out | diff 50k -\n./a.out | python - ... the orginal text of the commit message.  So, the file 50k is valid code in two languages, in one of which it's a quine, in the other it produces the original commit message. Overall, I see the commit message as a three language-long quine loop, depending on some external state in the svn tree (but that state is pretty long-term reliable).  In fact, when I consider it that way, it feels a bit like the genotype -> phenotype loop of self-reference and self-reproduction (which often depends on external state in the real world). All in all, it delights me no end. Anyone have any other tales of svn commit message hackery to share? Owen and I have been kicking around some steganography-inspired ideas for hiding code in the low bits of an image, or in diffs of specific commits, but, for now, those will just have to wait for commit number 60,000.", "date": "2010-08-09"},
{"website": "Hubspot", "title": "Meet the Movers and Makers: Síle Brehony, Product Manager", "author": ["Hannah Fleishman (she/her)"], "link": "https://product.hubspot.com/blog/meet-the-movers-and-makers-sile-brehony", "abstract": "Our mover and maker this week comes to us live from Dublin, Ireland. Síle is a PM on HubSpot's email team working closely with our customers, designers, and engineers to make emailing more intuitive. Here's a snapshot of how she became a PM, her first day at DubSpot, and the song we should all be listening to right now. Name: Síle Brehony Role: Product Manager What song is stuck in your head these days? Gooey by Glass Animals . Saw them recently - amazing! It’s also a great song for concentrating - gets me in the zone :) How do you like your coffee? Cappuccino or flat white (so milky). I’m anti sugar in coffee and constantly forget that a lot of places in the States add it by default - bad times :/ What made you want to become a product manager? It wasn’t something I sought out necessarily - it kind of happened organically. My background was initially in graphic & web design (not to mention interactive art installations - but that’s another story ...). So clean, intuitive, user centric UI design was always something that was very important to me. From there I moved into e-Commerce business analysis, which broadened my understanding of the importance of UX in business. Product Management came calling a few years later and I’ve loved working as a PM ever since. There’s nothing better than seeing an idea develop from early concept stages right through to fully delivered software that customers love. What was your first day at HubSpot like? Exciting. Strange. Surreal. All of the above. I was the first PM based in our Dublin office so it was both exciting and challenging trying to figure out my place within the team, but that’s what HubSpot is all about. Every team has ownership of the product, no one tells you what to do (there’s no rule book) - people are trusted to step up and figure out what needs to be done. There was also a LOT of food going around. Granted not on the first day - but certainly in the first few weeks I consumed my own body weight in Haribo sweets and chocolate - welcome to CHubSpot :) What's been your proudest moment at HubSpot so far? Shipping our first feature release for the new email performance screens and knowing we’d heard what customers truly wanted. Feedback from customers was really positive so for my team, it was validation that our process during research and design worked. You’re never fully done when it comes to improving features, but knowing we’re tapped into the pulse of our customer network is a big win. What’s one thing that you think is unique to building products at HubSpot? I love how user-driven product development is here. We constantly speak to customers and listen to their feedback. Ultimately, if the product isn’t working for them, then it’s not a success - simple as that! But strangely, this is something other tech companies often overlook. At HubSpot we wireframe and test out designs with customers before they even get to development, so users are massively involved in the process. We also have a fantastic group of customers that beta test new features during development, which helps us re-evaluate and refine the product as we go. HubSpot customers for President! Working in product development, I’ve worked with lots of talented people over the years, but in HubSpot the level of talent is consistently high. Being surrounded by the smartest people in tech is amazing - it pushes you to be the best and deliver the best products you can. What's your favorite part of the Culture Code and why? Humble. Effective. Adaptive. It still amazes me that even though I work with some of the smartest minds in tech - people stay humble. They’re  grounded and constantly striving to learn - there’s no room for ego’s or complacency here. I LOVE the GSD (Get Shit Done) attitude in HubSpot. I’ve worked in companies with super lengthy dev & QA cycles - so by the time a product gets delivered to market, it’s already out of date or no longer relevant. I call this paralysis by analysis :( It’s no good for the people building the software, who get project fatigue, are bored and lose interest. And it’s definitely no good for customers using your software. That's all from our mover and maker this week, but you can follow Síle here . Stay tuned for our next profile and check out Jen Huang's in case you missed it!", "date": "2015-05-26"},
{"website": "Hubspot", "title": "Name Dropping: Kelsey Steinbeck, Director of Software Engineering at Indigo", "author": ["Francesca McCaffrey (She/Her)"], "link": "https://product.hubspot.com/blog/name-dropping-kelsey-steinbeck", "abstract": "Name Dropping is a Q&A series that aims to elevate the stories of women leading in the tech space. The idea came from Angela DeFranco, a Director of Product at HubSpot, who said one way to be better allies is to name drop more women in discussions of achievement, inspiration, and disruptors in tech, instead of referencing, time and again, the same set of (often male) leaders. This edition of Name Dropping features Kelsey Steinbeck , Director of Software Engineering at Indigo . What’s the first thing you ever built that made you realize you loved engineering? The first thing I ever built that really put me on the engineering track was a CI/CD pipeline. It’s something that sounds so basic but really introduced me to engineering and the value of automation. A simple automated deployment pattern changed the entire paradigm of a team who was used to an all hands-on deck painful deployment event. I realized automation had so much power and I wanted to bring these practices to teams and really help define processes that add high value to engineering. Who do you think has helped you become a great leader, either as an inspiration or a mentor? This is a challenging question. I think the industry in general struggles in this area. What has helped me become a good leader has been taking the characteristics from many leaders in this space (some of whom I've met, some not) whom I felt really failed at being a leader, and doing the opposite of them. It's hard to know how to be a great leader, but it's easy when you know how not to be. The few leaders who have been inspiring have always been people-focused first. What I know is that a company is nothing without their employees. Leaders are nothing without people to lead. Therefore, my focus is on the people of my team and organization. You inspire people, they will build the world. You’re currently the Director of Software Engineering at Indigo. What are some of the most exciting challenges your team is working on right now? I lead the DevOps team at Indigo and the technologies and processes in this space are quickly evolving and really changing what DevOps means. DevOps is really at the center and heart of engineering. Doing DevOps the “correct” way becomes the challenge. This statement is highly subjective, but let me explain. Building bridges, being peacekeepers and not gatekeepers, having empathy toward our developer counterparts, and having the mindset to alleviate pain is the challenge. It happened organically, but our team has become the common space for teams to communicate with each other. Some of the hardest parts about engineering aren’t the technical problems, they’re the soft skills around that delivery and execution. Indigo’s mission is “harnessing nature to help farmers sustainably feed the planet.” How do you as a leader stay close to that mission? Indigo’s mission is what inspires people to come to work every day. Being able to do what you love (Engineering) while working for a company that wants to make a positive impact on the world is really the dream for a lot of engineers. Because the company has an inspiring mission, it really pushes you as a leader to be your best. I know by being my best self, that will rub off on those around me. I feel like my job is to keep that same inspiring morale across my team and department day to day. The mission got people in the door but it’s our job as leaders to provide a similar experience in our daily interactions. What is one quality that you think every leader should have in order to generate impact, and lead effectively? Empathy. Without being able to understand how people feel you won’t be able to really inspire, coach, or mentor them. You have to understand how people feel, what they want in their careers and out of life, and what drives them. You have to build relationships with people beyond a surface level. And empathy is the building block to do that. Who’s one woman in technology you’d like to name drop and why? Kathryn Glowinski . She is the lead engineer on our marketplace platform team. It’s always impressive to me when I see female tech leaders emerge. We are in an industry that has a shortage of senior engineers in general, let alone ones who are women. And Kathryn is one of those amazing engineers who has stuck with it and prospered and is helping define a path for the future of women in technology. When you think about the best engineers you’ve ever worked with, what characteristics did they embody? Engineers are some of the coolest people I have ever met. Their uniqueness and experiences make them great engineers. Magicians, board game enthusiasts, hustlers, yogi’s, gardeners, triathletes, carpenters, musicians, etc. It’s really this diverse blending of personal experiences with the one common characteristic of problem solving. Every great engineer is a learner by nature and is constantly evolving their skills.The best engineers adapt, re-learn, stay curious, and have passions outside of technology. What advice would you give your 22-year-old self? Coming out of school and going into a profession mostly dominated by men was an intimidating experience. I assumed that everyone knew so much more than I did and had their lives in order. Through my experience over the last decade, I’ve come to realize that not all individuals are confident in their role and in their workplace. What’s more, through conversations and getting to know people on a deeper level, I’ve also learned that general unhappiness outside of work plays a large part in how these individuals do their job. So as long as you feel your best you will far exceed those around you in every aspect of your life. You’re a certified yoga instructor. Is there anything you’ve learned from yoga that you apply to your day job? Yoga has been one of the best investments I have ever made for myself that will have lifelong returns. I would say the self-care practices I learned through yoga are really what I apply to my job and try to inspire those around me to do. Self-care sounds simple but is really hard for a lot of people. How you feel on the inside matters. Period. People really need to pay attention to this if they want a healthy, productive life. A large amount of people suffer from depression, anxiety, and stress. Practicing regular self-care allows me to circumvent some of these mental stressors and it’s my mission to bring those practices to those around me. If you want your team to perform at their best, they have to feel their best. I actually believe this is what distinguishes a good team from a great team. Know another woman whose name we should drop? Tweet us at @HubSpotDev with ideas. This article originally appeared on Medium .", "date": "2020-02-25"},
{"website": "Hubspot", "title": "Welcome to the HubSpot dev blog!", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/5783/welcome-to-the-hubspot-dev-blog", "abstract": "This blog is a place for HubSpot developers to riff about any technical topics of interest.  You might find tech product reviews, coding tips, productivity tips, gotchas, complaints, and anything else a HubSpot developer writes about. This is not a blog about HubSpot nor about our awesome internet marketing products .  There are plenty of channels for that.  In fact, most HubSpot customer would probably find this blog boring at best. We'd love to hear your feedback on any posts: comment here, follow us on Twitter , let us know what you think.", "date": "2009-06-25"},
{"website": "Hubspot", "title": "Crushing Code...and Expectations of Women in Tech", "author": ["Hannah Fleishman (she/her)"], "link": "https://product.hubspot.com/blog/crushing-code-and-expectations-of-women-in-tech", "abstract": "\"There is a profound joy in surprising those who underestimated you.\" Our co-founder tweeted that last week and like any Justin Bieber song, it's been stuck in my head ever since. I couldn't figure out why it struck such a chord at first. Then it hit me: Surprising people who underestimate me is my favorite thing about being a woman in tech. I'm not the only one, either. Talking with women at HubSpot (like Jen, Anum, and Danielle above), it's become clear that while being underestimated is a downside to working in a male-dominated field, we're motivated to work harder and better because of that profound joy. The look on people's faces when you tell them you're on an engineering team or say something they only expected to hear from a hoodie-clad brogrammer is annoying at first (it's 2016, people). But there's something rewarding about challenging the status quo by being great at what you do. Defying expectations isn't the only thing we have to celebrate. There are a lot of perks and gratifying nuances to being a woman in the product world. So in the spirit of International Women’s Day , the ladies on our team shared their favorite things about being a developer, designer, or product leader. Disclaimer: We used this as an opportunity to celebrate the big, small, and silly benefits that come along with being a woman in tech. Emphasis on the silly. The Best Part About Being a Woman in Tech is... \"Finding strong women role models and realizing you're becoming one yourself\" Tweet Me \"Celebrating every new woman who joins the team\" Tweet Me \"Having a fresh manicure and staring at it while you code is one of the best feelings in the world\" Tweet Me \"Having cider in the HubSpot beer garden <3\" Tweet Me \"Being part of the generation that will (hopefully, finally) crush the gender disparity in tech\" Tweet Me \"Strange sense of power when your boot heels are just RINGING out over rows and rows of sneakered dude desks\" Tweet Me \"No one asks to borrow my concealer\" Tweet Me \"Crushing stereotypes with every badass commit\" Tweet Me \"Bathrooms are always clean and we have them to ourselves\" Tweet Me \"Bringing in different humor that doesn't occur to guys\" Tweet Me \"Looking fashionable is easy\" Tweet Me \"Understanding our target persona, who is a woman\" Tweet Me \"I have the best looking desk in the office\" Tweet Me \"You and your female coworkers are ride or die together #SISTERHOOD\" Tweet Me Hopefully some of these made you laugh, and hopefully some made you think. Women pursuing careers in product development don't always have it easy. But fortune favors the bold, and the product leaders with the best looking desks in the office today are paving the way for women in STEM tomorrow. International Women's Day is a great reminder that we should be celebrating the amazing, bold women we work with. And not just today, but every day. What do you love about being a woman in tech? Tell us in the comments or tweet at us .", "date": "2016-03-08"},
{"website": "Hubspot", "title": "Some principles we design by here at HubSpot", "author": ["Josh Porter"], "link": "https://product.hubspot.com/blog/bid/86646/some-principles-we-design-by-here-at-hubspot", "abstract": "In our interface design work here at HubSpot we talk a lot about the unwritten rules that we design by. They come up in design reviews, in hallway conversations, and in heated chat rooms. I'm sure we have many dozen of both spoken and unspoken rules overall. Some of these rules are hard-and-fast ones like \"One primary action per screen,\" which means that we try for each screen to have a single primary purpose that customers use it for. Others are less formal sayings like \"Great design is invisible,\" by which we mean that if your design is working it's not necessarily apparent to the people using it. Here is the full list: Principles of User Interface Design I'm sure I could have written twenty more design principles, but these seemed like the big ones. They implicitly guide a lot of our design efforts here at HubSpot, from designing dashboards to setup flows to list pages. (although each designer has their own principles as well). Most importantly, these principles help guide us back to simplicity when we've over-complexified a screen. So let us know you think...would these principles help you when you're in the midst of design?", "date": "2012-05-11"},
{"website": "Hubspot", "title": "Styling console.log", "author": ["Zack Bloom"], "link": "https://product.hubspot.com/blog/styling-consolelog", "abstract": "Console.log is one of the simplest, and most powerful, tools frontend developers have.  Turns out, it's not quite as simple as we thought.  Console messages can be formatted using CSS.  You could, for example, make your error messages larger: You could give your log messages a pleasant shadow: The styles don't have to apply to the whole message: Each %c resets the styles: Add some formailty to your messages: Text is boring, use images: Include charts in your console logging: Even better, anything you can draw on a canvas, you can draw in the console .", "date": "2013-04-02"},
{"website": "Hubspot", "title": "Name Dropping: Fidelma Russo, CTO & EVP, Iron Mountain", "author": ["Francesca McCaffrey (She/Her)"], "link": "https://product.hubspot.com/blog/name-dropping-fidelma-russo", "abstract": "Name Dropping is a Q&A series that aims to elevate the stories of women leading in the tech space. The idea came from Angela DeFranco, a Director of Product at HubSpot, who said one way to be better allies is to name drop more women in discussions of achievement, inspiration, and disruptors in tech, instead of referencing, time and again, the same set of (often male) leaders. This edition of Name Dropping features Fidelma Russo, CTO & EVP at Iron Mountain . What’s the first thing you built that made you realize you love engineering? I’m an “accidental’ engineer and went into the field because I loved math and science and didn’t know what a different career option would be. I love taking complex problems and designing solutions to them and being part of a great team. It is just a fantastic feeling.The first thing I built that gave me that feeling was a network interface chip. I worked on a team based in Galway, Ireland. We worked nights and weekends on this project because we were driven by the excitement of creating something. That is when I realized that I actually loved what I do even if I didn’t really know what engineering was when I started in college. What’s your best advice for your 22 year-old self? Be brave and adventurous. Take opportunities that stretch you and put you outside your comfort zone. Ask questions so you are always learning. Have fun. What book do you think every product leader should read and why? Only the Paranoid Survive by Andy Grove, who led Intel through many technology transitions and threats. What is one quality that you think every leader should have in order to generate impact and lead effectively? Integrity. The best teams have a high degree of trust and need to have integrity at the core. Iron Mountain was recently named a Google Cloud Technology Partner of the Year for its work in AI and Machine Learning. Can you tell me about the most exciting projects you’re working on in that space? At the end of 2017, three people from Iron Mountain and three people from Google got together in a conference room and, with country music playing in the background, we dreamed about a potential solution for Iron Mountain records management customers to manage and classify their data, govern their data, and turn it into information using analytics. Some of our customers who store physical records with us are digitizing these records for access and they wanted a way to shine a light on their “dark data,” or data that has been collected, but has not yet been analyzed. In fact, it was a meeting with a customer that started the first “what if we could “ conversation. Customers wanted an easy to use platform that allowed them to manage their physical and digital records in one place across the lifecycle from creation to destruction. Iron Mountain Insight is the content services platform that we built to solve this customer problem. We worked in close collaboration with the machine learning engineers at Google to develop models for this platform and this work contributed heavily to Google’s announcement of a set of ML that is known as Document Understanding AI (DUAI). Our work continues and our content services platform is the first cloud-native, machine learning-based SaaS platform that manages both physical and digital data. Who’s one woman in technology you’d like to name drop and why? Gail Deegan , who was on the board of EMC, was a strong supporter of women at EMC and actively championed diversity initiatives at the company. She is now working pro bono on another initiative, called The Last Mile, to increase the percentage of women on corporate boards. How do you stay connected to user and customer feedback? I use a variety of mechanisms. I love visiting customers to understand what problems they are trying to solve and to solicit feedback on how we are doing as a company. I attend our customer advisory board meeting. I attend industry events with our users or target users and listen to what they have to say. We also measure customer sentiment via NPS (Net Promoter Score) and that also factors into staying connected with how our customers feel about the products, services and experiences we deliver. What characteristics do you think the best engineers and product people have? Curiosity, impatience, sense of adventure, courage to try new things and being great listeners. These are the characteristics that I believe differentiate the best engineers and product people from the rest. What’s your greatest career achievement to date? I can’t really point to one thing but I would say that it has varied through different phases in my career. Early on in my career I just cared about pure technology and had the opportunity to work on very technically challenging programs. At some point I got my sense of achievement from combining business and technology and now what gives me the most satisfaction is building strong teams to deliver significant business results. You want to take your team out to celebrate a big accomplishment — which restaurant, anywhere in the world, would you pick? I would take the team to the Old Head of Kinsale golf course and have dinner overlooking the course. I grew up near there and used to play there as a kid, so I have fond memories of it. Plus, I’m an avid golfer and have never had the opportunity to play there. Know another woman whose name we should drop? Tweet us at @HubSpotDev with ideas. This article was originally published on Medium .", "date": "2019-11-12"},
{"website": "Hubspot", "title": "Technical Debt, Technical Interest, and Technical Vigorish", "author": ["Edmund Jorgensen"], "link": "https://product.hubspot.com/blog/bid/54399/technical-debt-technical-interest-and-technical-vigorish", "abstract": "When was the last time you heard the term \"technical debt?\"  If you're a developer, it was probably pretty recently.  Now when was the last time you heard the term \"technical interest?\"  I bet it has been significantly longer.  Ward Cunningham, who coined the term \"technical debt,\" was definitely thinking about the interest angle: \"Every minute spent on not-quite-right code,\" he wrote, \"counts as interest on that debt.\"  But I think a lot of developers and shops today aren't thinking about technical interest as a consequence of technical debt.  They treat technical debt as a casual interest-free loan from friends or family--a \"debt\" that may never even come due.  I think this attitude towards technical debt is a mistake.  I think that we not only pay interest on our technical debt--we often pay vigorish. \"Vigorish\" is the unreasonably high and often compound interest that a loan shark charges.  It goes up at the shark's whim and is often so high that realistically the debt cannot be repaid.  How does vigorish apply to code?  Let's say you write a \"quick hack\" to do X.  The effort to fix that hack at some point represents your technical debt.  Now an experienced developer spends an hour tracking down a bug attributable to bad assumptions around your hack--that's some of your technical interest.  Now a new developer in your shop needs to do X as well and finds your hack in the code.  From that moment on, until the new developer is corrected, he will replicate your hack every time he needs to do X.  He thinks your hack is the \"right way\" to do X, or at least an acceptable one.  Future developers will then have even more examples of your \"quick hack\" to find and copy themselves, further spreading the influence of your \"quick hack\" in potentially exponential fashion.  And that's technical vigorish. Recently I've been trying to adjust my approach to technical debt in order to avoid technical interest in general and technical vigorish in particular.  Here are some of the better practices I've been attempting: Treat technical debt as debt .  Have a very good sense of how much there is in a given project, and a timeline for paying it back, just as if I were managing a \"financial debt.\"  This works pretty well in scrum, by the way. When I do have to incur technical debt, try to isolate it.  Prefer debt in implementations to debt in APIs / interfaces, which, being more public, tend to generate more interest and vigorish. Comment conspicuously on patterns that should not be emulated, ideally explaining the \"right way\" and why I didn't do it. Keep technical debt out of key infrastructure and processes that I depend on day to day.  By some trick of developer psychology it seems we're most tolerant of technical debt in the tools and processes we use all the time--like building and deploying--even though these generate lots of interest and vigorish very quickly. Submit code for peer review.  This practice has made possibly the biggest impact for me.  I work with sharp folks, and they sometimes see ways to do something that are both better and cheaper than anything I've come up with.  Review also helps catch fossilized bad habits, somewhat offsetting technical vigorish.  Finally, the shame of bringing bad code to the attention of folks I respect often inspires me to bite the bullet and pay down my code's technical debt before I even commit it in the first place.", "date": "2010-11-03"},
{"website": "Hubspot", "title": "Sprint Review Is Group Therapy For Development Teams", "author": ["Karen Rubin"], "link": "https://product.hubspot.com/blog/bid/14880/sprint-review-is-group-therapy-for-development-teams", "abstract": "We finished Sprint 13 at HubSpot last week. In some ways it was a rough sprint and as the Product Owner of the Red Sox team I had been feeling pretty stressed out about it. We hit one major bug that derailed us for a few days, and for some reason I couldn't identify we had a hard time hitting our stride after that. I agree with Yoav's last post in that one of my favorite things about Scrum is the end of sprint review. Each team has the opportunity to sit together and talk about the good and bad things that happened during the sprint. During my first sprint review, as everyone was discussing their feelings, something that doesn't happen all that often in business, I realized that sprint review is a little bit like group therapy. Each sprint review starts off a little awkward as someone has to start talking. When they do though, I find that everything they say resonates with me. As I headed into our team review this sprint, I wasn't sure why we hadn't been able to hit our stride, or why the major bug had derailed us. After talking about it with the team we had a couple of solid takeaways to help us prevent similar things from happening in the future. Sprint Review gives us the opportunity to sit down regularly for the specific purpose of talking about how things went. As a result, things never seem to get too far out of control. Had we just kept plugging away with our work and not had our sprint review, I think it would be harder for us to work out the kinks. By talking it out, we were able to come up with solutions to help us get our stride back so we can head into Sprint 14 feeling great. Reading what I have written, this seems so obvious, but I have never been a part of these kind of conversations outside of Scrum. I think this approach would work and be very beneficial for all types of team because it helps to identify kinks before they fester and become full blow wounds. Have you ever tried regular group therapy with your team?", "date": "2009-08-10"},
{"website": "Hubspot", "title": "The HubSpot engineering quarterly desk shuffle, May 2011 edition", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/63509/the-hubspot-engineering-quarterly-desk-shuffle-may-2011-edition", "abstract": "Every three months the HubSpot engineering and marketing teams, which sit mixed together in our office, do a random desk shuffle. We started this when the company was young and much smaller, but we have kept it as a tradition that is both fun and serves some useful purposes. For one, you get to sit next to new random people every three months, so you get to know them.  That helps everyone feel more at home, whether you've been at HubSpot for a week or a year or more. Another nice benefit is that everyone has to clean out their desks and related junk every three months.  It's amazing how much cruft accumulates over time without people realizing it.  We always toss out a lot of trash, and sometimes find some goods for charity as well. Finally, we allow trading of desks, so the seat you draw from the hat is not your final assignment.  People trade for quiet, to sit next to others, to sit AWAY from others, and for assorted other reasons.  It's always entertaining and informative. As the video below shows, sometimes it's a little chaotic, too.", "date": "2011-05-03"},
{"website": "Hubspot", "title": "Need for Speed: Accelerating Maven Snapshots", "author": ["Jonathan Haber (He/Him)"], "link": "https://product.hubspot.com/blog/speeding-up-maven-snapshots", "abstract": "At HubSpot, all of our backend code is written in Java and built with Maven. This code is spread over ~3,500 Maven modules, with lots of dependencies between them. We use snapshots for all of our internal dependencies, and we almost never do releases or version bumps. We pair this with a snapshot update policy of always , so that every build picks up the latest version of every library. W e like that it forces people to be conscious of backwards-compatibility, avoids version conflicts when using internal libraries, and gets us closer to the monorepo mindset while still being able to use mostly off-the-shelf tooling. Houston, we have a problem There are some performance drawbacks to this approach. Because of the update policy of always , each build needs to check whether there's a new version of every snapshot. To do this, Maven needs to fetch the snapshot metadata and its checksum from the remote repository (Nexus, in our case) so that it can compare to the cached data in the local repository. This requires at least two round-trips to Nexus for each snapshot dependency. If an app has hundreds of snapshot dependencies, this latency starts to add up. And for our Dublin engineers, where each of these round-trips is transatlantic, the latency is downright unusable. We were able to partially mitigate this issue by writing a local proxy that would cache responses for snapshot metadata and return the cached data if a snapshot hadn't changed. Each developer ran this proxy locally and configured Maven to use it instead of hitting Nexus directly. This sort of worked. But it was never perfect, because the cache invalidation wasn’t as reliable as we liked and our HTTP proxy just wasn’t very good. And even with the local proxy, snapshot resolution still added a few seconds of overhead compared to running the build in offline mode. But it was better than nothing, so local development relied on the proxy and our CI environment relied on low latency to the remote repository (which meant running all of our builds in the same region as our Nexus server). This was the state of things for a while, until we hit another performance issue. As the engineering team grew, the volume of builds grew with it. In less than 18 months we went from 1,000-2,000 builds per day to over 10,000 builds per day. This led to an increase in traffic to Nexus that it just couldn't handle. Periodically, the latency on requests to Nexus would go through the roof and all of our Java builds would grind to a halt until we could get it back up and running. When this happened a few days in a row, we knew we needed to find a better solution. We considered changing the snapshot update policy to something other than always . This would indeed reduce traffic to Nexus, but would cause problems for correctness . For example, let's say someone adds a method to module A and uses that method in module B. In order for module B to compile, it needs to pick up the latest version of module A. This requirement precludes all of the built-in update policies besides always . But i f we could implement a custom update policy, then we could plug in our own logic to tell Maven whether it needs to check for a new snapshot. Maven doesn’t support custom update policies, but we found that we could achieve this sort of functionality by writing a Maven extension. The snapshot accelerator So we started designing a system that allows us to hook into Maven and skip the metadata fetch for a dependency if we know the snapshot hasn't changed. This is a similar idea to the proxy, except that it allows us to bypass the metadata HTTP requests entirely (which is noticeably faster, possibly because Maven isn't great at parallelizing this sort of work). This design also means we don't have to proxy requests to Nexus, which eliminates some complexity and operational issues. We also redesigned the way snapshot versions are tracked so that the system is reliable enough to use in our CI environment. The system is comprised of three parts: A simple HTTP API backed by a relational database which keeps track of the latest resolved snapshot version for each group/artifact/base version A Maven plugin which reports to the API after a new snapshot has been published A Maven extension which hits the API at the start of a build to find all new snapshots and then short-circuits metadata requests for dependencies that haven't changed We have open-sourced this system as the maven-snapshot-accelerator . Putting it all together Now, when a build runs in our CI environment the Maven command looks like: mvn -B deploy com.hubspot.snapshots:accelerator-maven-plugin:0.3:report This will invoke the accelerator plugin after the deploy phase in order to report the new snapshot version to the accelerator API. Next, the version of Maven we use locally and in our CI environment has the accelerator Maven extension installed. The extension keeps its state in the Maven local repository so that it can do incremental updates by fetching a delta from the API at the start of each build. As part of this, we went back to sharing a Maven local repository between all builds on the same server. We also add a few Aether flags when we run Maven which make this concurrent access safer: -Daether.connector.resumeDownloads=false - To prevent one build from trying to resume the download of another concurrent build and potentially corrupting the local repository -Daether.artifactResolver.snapshotNormalization=false - To make Maven use the fully resolved snapshot JARs for everything, which should be immutable and not change out from under us This still isn't technically safe, and given enough concurrency we would probably see issues, but we have a few things working in our favor. The first is that builds are spread across the 150 servers in our Mesos cluster, so concurrent builds on the same server aren't very common. The other thing working in our favor is that dependency resolution is now much faster, so that the window for things to go wrong is much smaller. In fact, since rolling this out to our CI environment a few weeks ago, we haven't seen a single build failure due to local repository corruption. Results Since rolling this out, we haven't had a single Nexus outage. We've also seen faster and more consistent build times, both locally and in our CI environment. Here is a chart showing the volume of traffic to Nexus before ( orange) and after ( green): (As a side note, you can tell from that graph that our engineers work from roughly 10am to 6pm. So next time you're interviewing somewhere, don't ask about work-life balance. Just ask to see their Nexus graphs.) And here is a chart showing the Nexus request latency during the same time period: You can see that each spike in traffic had a corresponding spike in latency, and now both graphs are much more stable. Future Work This setup is working well for us at the moment, but it seems like we're nearing the limit of what can be achieved in terms of speed and scale with Maven. Gradle is attractive, but seems to represent more of an incremental improvement, whereas tools like Bazel, Pants, or Buck are fundamentally different. We plan to evaluate some of these tools to see how they compare in terms of speed, configurability, extensibility, IDE integration, and so on. If you have any thoughts, feel free to leave a comment below and don't forget to check out the maven-snapshot-accelerator on GitHub.", "date": "2017-12-06"},
{"website": "Hubspot", "title": "The Classic \"QA Team\" is Obsolete", "author": ["Michael Mintz"], "link": "https://product.hubspot.com/blog/the-classic-qa-team-is-obsolete", "abstract": "When it comes down to building and deploying quality software, don't be misled into thinking that the classic \"QA Team\" is the best solution for your main line of defense. For an early-stage start-up that may be the only viable option. For anyone looking to be a major player in their ecosystem, there's a smarter way, and that involves evolving your QA team(s) into User Experience (UX) and Test Automation teams. Traditionally, manual QA teams have been responsible for several tasks such as: 1. Creating a test plan based on the product requirements 2. Manual testing / Finding unexpected product behavior 3. Writing down results of the manual testing 4. Filing bugs in an issue-reporting tool 5. Following up on “fixed” bugs to verify they were actually fixed 6. Updating the test plan as new features are added or removed The Classic QA approach isn't good enough anymore, for a few major reasons: 1. QA people tend to be bug-focused. While this may help you figure out if your product does what it's supposed to do, UX will tell you something far more valuable: Does your product perform the way that it should to be attractive to target users? Focusing on the latter will put you at a significant advantage, and that involves several stages such as field research, focus groups, usability testing and beta testing. If you don't have one already, you can form a UX Team to focus on these issues. Here's some info on how we do UX at HubSpot: 8 Tips for Doing Usability Testing at a Fast-Paced Company 2. Manual testing is repetitive and tedious, so QA people might have to go through the same sequence of steps over and over again for multiple variations and software changes. While manual QA may hold up for small-scale systems, this doesn't scale well for more complex ones due to the limitations of humans. Compared to machines, humans think and act slowly. Humans are also more expensive, take up more space, can get distracted, can't stay awake 24 hours a day, can't network with other humans as quickly as machines can with other machines, need to eat, have emotions, etc. Because of these limitations, it can be far more effective to automate most (if not all) of the tasks that humans would normally do manually. Now somebody still has to write the test automation for computers to perform (which may include browser-based integrated tests) and the focus of that can handled by an Automation Team. You may already have developers writing unit tests for your product, which is very smart. Sometimes you may need to create non-test automation to perform various tasks from within a web browser, and you can have your Automation Team write those as well since they'll already be familiar with your collection of automation tools. Here's some info on how we do Test Automation at HubSpot: Automated Integration Testing with Selenium at HubSpot If you're trying to transition from classic QA into UX and Automation, you can break up and modify the six tasks at the top as follows: On the automation side, steps 1 and 6 translate directly into writing the tests. Steps 2, 3, and 5 translate into running those tests. That automation is then able to find issues on its own and do all the logging/reporting for you. As for step 4, you can decide how you want to handle that. You could automate the filing of bugs in a reporting tool, but that has the potential of being a bad idea since you may be filing false positives. At that point, it may be best to verify the test failures manually so that only the real bugs get sent to developers. And make sure you have lots of unit tests in addition to all your integrated ones. As for UX, if they can answer the following six questions about site pages, it's a good start to making useful design improvements: 1. Who is this page for? 2. What problem does this page solve for the user? 3. How do we know they need it? 4. What is the primary action we want users to take on this page? 5. What might point the user to take this action? 6. How will we know this page is doing what we want it to do? Once you put the pieces of the puzzle together, it becomes clear that obtaining product quality requires more than just sending a \"QA team\" on a bug hunt. This is the future. To stay ahead of the competition you have to continue to be innovative and rewrite the traditional rules of getting things done. A good place to start is by improving the process of making quality software. ( Michael Mintz leads the Selenium Automation at HubSpot )", "date": "2013-05-24"},
{"website": "Hubspot", "title": "Lessons and Projects From The HubSpot Open Source Hack Night", "author": ["Dharmesh Shah"], "link": "https://product.hubspot.com/blog/lessons-from-hubspot-open-source-hack-night", "abstract": "Have you ever run into a challenging technical issue and found the perfect answer over on Stack Overflow ?  Or, come across an open source library that already does almost exactly what you were about to spend a bunch of time on?  Yep.  Me too.  Every day.  In fact, if there's a day that I don't have this experience, it means I'm freakin' working on PowerPoint slides instead of writing code. In any case, that's the beauty of an open system.  I'm continually amazed and grateful for the culture of openness that permeates the development and technical community. For the past year, we at HubSpo t have been rewriting our entire development stack. (Side note:  this is not for the faint of heart).  Many times, we've been able to take advantage of open source projects like Hadoop or Backbone.js, but we've also been able to build on top of these to forge new, better (at least for our purposes) solutions. Companies like Twitter, Square and Netflix have open sourced some really useful things recently, and we felt it was our turn to give back as well. So we decided to get together a handful of developers, some Indian food and had an open source hack night. Oh, and by \"we\", I mean Jonathan Kim who organized it all, and is awesome. We learned a few lessons from this experience: 1. Open sourcing code is not as easy as doing a git push . A good open source project also needs documentation, a build/bundling system, integration with the appropriate package manager (maven, pip, npm, etc.) and some community building. Those things actually took us more time than expected, mainly because we had very little experience with it. Getting build-systems setup for Javascript projects was particularly time consuming. Modern front-end development is amidst a renaissance, and a new build/package system is created every day (e.g. npm, bower, ender, component).  If you're planning to host an open source hackathon at your company, take the time to learn about open source distribution and make that easy for your team. Spend fewer calories setting up Grunt compilers and more calories on cleaning up your open source code. 2. E motional hurdles are as challenging as the technical ones. Though most developers believe in open source, they're often a little reluctant to put some of their code out there.  They're not trying to protect intellectual property -- they're just a little apprehensive of complete strangers peering into their code.  Oddly, even though code is code, developers often see it as a very personal expression.  And, some of us (like me) want \"just a couple of days\" to clean up the code to prepare it for release.  You need to help people get over this emotional hurdle. 3. Make it easy.  Invest in infrastructure before-hand. Have a repo ready, a build system figured out and some basic license info for people.  This gives contributors more time to focus on the code. 4. Get some marketing help .  We should have invited a marketer or two to help with the blog post portion of the night. It was something that people put off until the last minute, and having a professional around to help each engineer break the ice would probably have made that process less painful. 5. Don't expect a blockbuster hit .  Although it's possible that a project you open source becomes an instant, world-wide sensation that thousands of developers use -- that's unlikely.  Especially in the early days.  But, that's OK.  Open source is about a culture of sharing and collaboration.  Not every project is going to be a hit.  The idea is to get people into the habit of sharing.  And, I'd argue that knowing a specific tool or project might be released as open source someday gets people to write better, cleaner code. We're just getting started on this process and \"open\" to learning as much as we can.  If you have any experience taking internal tools and projects at your company and releasing them as open source, would love to discuss them in the comments. Meanwhile, here's a list of the projects we released as part of this open hack night. We hope you find some of them useful. Projects we opensourced: astack (Shell) astack is a command line tool we use to quickly get thread dumps from the JVM. There's no complicated setup, and you can get stack traces from the JVM even under heavy load. astack comes with a set of flags, for formatting, finding and aggregating the thread dumps. EasyHibernate (Java) EasyHibernate is a set of base classes and utilities for quickly setting up a Hibernate database layer. It also takes care of common operations, like count , sum and average so you can write DRY code. executr (Javascript/Coffee) Ever wanted to see a code example run live? executr is a jQuery plugin that executes coffeescript in the browser. It comes with a handful of options, but it's extremely simple to get started. Humanize (Javascript/Coffee) Humanize is a javascript object formatter that's been optimized for speed, written in coffeescript and backed by a suite of jasmine tests. Where other libraries only let you manipulate strings, Humanize gives you methods for translating numbers, arrays, and more into human-readable terms. Messenger (Javascript/Coffee) Messenger is the ajax wrapper you've always wanted. It comes with customizable error messages, automatic retries (with a backoff algorithm), and some sexy css styling. Plus it integrates with jQuery and Backbone, so you don't have to modify your existing ajax requests. sanetime (Python) Sanetime was written to DRY up all the common date/time manipulation while offering the most simple, versatile, and intuitive API possible. Give Sanetime a date-like object, and it'll automatically return a consistent time format of your choosing. Sprocket (Python) Sprocket makes it easy to expose normal python functions in a web API through a restful interface. It works out of the box with Django models and provides a mixin and events system for easily adding in reusable, self-contained components into API. teeble (Javascript/Coffee) If you're using Backbone and displaying tabular data, we built teeble for you. Teeble is a light-weight abstraction that allows you to build tables using Backbone views and collections. virtualenvchdir (Shell) The virtualenvchdir tool makes switching python virtualenvs much more pleasant. virtualenvchdir will automatically switch in and out of the appropriate virtualenv as you change directories. What do you think?  Any of the above projects interesting?  Any tips on how we might better run an open source hack night?  Would love to read your thoughts in the comments.", "date": "2013-02-01"},
{"website": "Hubspot", "title": "Leads API Lessons Learned", "author": ["Stephen Huenneke"], "link": "https://product.hubspot.com/blog/bid/58082/leads-api-lessons-learned", "abstract": "In October 2009 we planned and started a migration of our entire leads storage system from MS-SQL to MySQL.  In the process we were going to build a REST ful leads API and build an entirely new user-facing web application to help customers manage and nurture their leads better than ever.  The goals were lofty, but we felt we were going to be successful because we had a good architecture and developers. A year later, after many long nights and continued optimizations,  the Leads API is up and running and the user facing front end is happily serving our 4000+ customers and serve over 1 million API calls per day.  I'm happy with what we built, but of course see plenty of ways we could have done better.  As I've started working on some new API's for HubSpot I've taken a look back at the things we did right and wrong with the leads API and thought I'd share some things I found particularly useful here. What we did right: Mandate internal usage to force real usage, quickly .  We mandated that all apps that weren't deemed part of the lead management suite would have to use the API to interact with leads data.  This forced us to scale to meet our internal customers' demands immediately.  Within a week of launching the first version and migrating the first few applications to use the API instead of database connections, we had over 20k API calls per day.  It was awesome to see our work coming to fruition so quickly and the success built up a lot of confidence in our strategy.  We were able to see scale issues and find bugs in near real time as we combed through logs of errors caused by real-world production leads data.  This was reporting was much faster than even the most comprehensive QA testing or unit testing suites. Iterate quickly to solve problems. We iterated quickly on the problems we found, fixing them and shipping within hours or even minutes of finding a problem.  We setup our error logging to email the leads dev team whenever major errors occurred and we were always shipping bug fixes and improvements several times a day.  The code in production was almost always HEAD or close to it and we built an infrastructure so that no one had any qualms about shipping mid-day.  We were responding to out internal users needs at breakneck speed. Analyze usage and find ways to scale horizontally. When we realized that we were hitting over 20k API calls per hour during peak usage times, and serving hundreds of MB worth of data per hour, it became clear we were going to need more than two small EC2 instances to serve the data. We were hesitant to upgrade the servers, but we realized that the cost of upgrading versus the cost of trying to squeeze every last bit of performance out of the code was unbalanced.  With a choice between dozens of developer hours versus a couple hundred dollars a month for equivalent gains in performance, the scales were tipped pretty heavily in favor of throwing hardware at the problem. What we did not get right: Decouple from resources used by other applications. We noticed a funny thing after a few months.  During peak usage hours, which happened to be during the middle of the night when our internal customers were running scheduled jobs to process big chunks of lead information, we were slowing down our MySQL read-only helper.  We started receiving complaints from our international customers about the front-end being slow to respond during these same hours.  We had been crippling the shared MySQL helper and causing even the most trivial of queries to slow to a crawl for the user-facing lead management tool.  We created separate helpers for the two services and solved the issue easily enough, but it was a big oversight on our part. Construct an allowlist of allowed response fields. We chose to blocklist data fields we explicitly didn't want to serve and filtered those out of our returned JSON responses.  At first, this was great, as we were able to add fields by simply adding them to our objects, while reflection and our JSON serialization did the rest.  But then we realized that new fields were causing issues with deserializing the data on deployed applications with older versions of the objects.  It was easy enough to fix, we changed our deserialization to ignore those errors.  So we fixed the outright bugs, but we've caused some long-running pain and uncertainty about what data is being served and when.  If we added a field at a certain date, then deployed to production at a later point, then deployed dependent projects even later, who knows what version of the object went out where and when.  At any moment someone could add new data to the returned JSON and this undermines confidence in the API as the responses are changing for internal and external customers alike.  We're taking steps to fix this in the Leads API, and have built the Blog API from  the beginning with an eye on allowlisted elements.  Consistent responses and results helps increase users' confidence and that confidence helps them build better software faster. Iterate quickly to solve problems. Yeah, this was also something did wrong.  The other side of the fast iteration coin is that you get caught up in the momentum of your work.  It's hard to take a step back and stop to think about what your one line fix might mean to the dozens or hundreds of consumers of an API.  What about documentation?  What  about unit tests?  These are all tools we use to ensure we are building high quality, reliable software.  Iterate too fast, and too loosely and you find yourself falling behind on keeping up with your own software.  You find yourself in a seemingly endless cycle of bug fixing, deploying, bug finding,  bug fixing, deploying... Struts 2 REST plugin. The Struts REST Plugin is a great tool for building out a RESTful interface for a complex hierarchy of objects.  It handles JSON and XML output by default, requires a small amount of configuration and is generally well written, well tested code.  It's also a terrible  fit for the API we wanted to build.  It's got too many features we didn't need (i.e. XML isn't used by our API consumers internal or external).  It was exceedingly complex to perform tasks that in a normal struts stack would be totally mundane (i.e. be able to stream a response instead of compiling one giant response string in memory and causing heap space errors) Don't just build features for specialized internal users. Internal users wanted more data, more flexibility, faster responses  and complex queries on the leads data.  Building those features was a challenge, and spending all that time concentrating on internal features was time we could have been spending to make the API faster, more reliable, more scalable and easier to maintain.  Those gains would have benefited internal and external users alike.  The rapid iteration on internal-only features certainly helped gain traction and higher usage for the API, but it happened at the cost of improvements for all consumers of the API.  We have a google group for hubspot api consumers now, and its helping us to make better decisions for external developers needs. As I look back on the last year of work I see a lot of mistakes we made that I would make again in a heartbeat.  The API was essentially a proof of concept in the beginning.  It gained traction internally and externally and we responded accordingly.  We probably never took the time to look at the API as we'd built it and ask if it was truly production ready.  That's hard to do when you're fending off bugs left and right, just trying to keep your head above the water.  What I've taken away is to be leaner about features, keep fast iterations, and be more thoughtful about repercussions the choices you make might have.  Prioritizing \"internal use only\" features above public ones should require a hard sell from the parties requesting these features.  You're asking for time the developers could be spending improving the entire app, possibly negating the need for your internal feature entirely.  By no means is the book closed on this we have short-term plans for better performance, higher reliability and greater scalability for this project, and I look forward to all the lessons I'll learn from those improvements.", "date": "2011-01-14"},
{"website": "Hubspot", "title": "Name Dropping: Darling Jimenez, President and Partner at Leading Results, Inc.", "author": ["Francesca McCaffrey (She/Her)"], "link": "https://product.hubspot.com/blog/name-dropping-darling-jimenez-president-leading-results-inc", "abstract": "Name Dropping is a Q&A series that aims to elevate the stories of women and nonbinary people leading in the tech space. The idea came from Angela DeFranco, a VP of Product at HubSpot, who said one way to be better allies is to name drop more women and nonbinary people in discussions of achievement, inspiration, and disruptors in tech, instead of referencing, time and again, the same set of (often male) leaders. This edition of Name Dropping features Darling Jimenez , President and Partner at HubSpot Partner organization Leading Results, Inc . You’re currently President and Partner at Leading Results, Inc., a marketing and advertising agency, as well as their Creative Director and Director of UX. What have you learned about leadership over the course of your career growth? It’s been quite an interesting journey. I think my primary learning is that we often think of leadership as being at the forefront and being the decision maker. But leadership is more about listening, understanding, and nurturing a shared vision. It’s less about leading the way and more about motivating others and providing a space where innovation can thrive. What’s the most interesting or challenging (or both!) project you’re working on right now? The most interesting project I am working on now is our own rebrand. I think COVID-19 redefined a lot of priorities for us and truly gave us a glimpse into the future of marketing, consumers, and business. We are in the process of taking our learnings and future vision and using that to create and mold the vision of the future we want for our own company. Talk about someone who’s been integral to your career, either as an inspiration or a mentor. What did they teach you? (You don’t need to know them personally.) Someone who has been integral to my career and growth is Gary Vee . Gary has been a massive source of inspiration and most importantly the voice I have chosen to listen to when doubt and fear threaten to cloud my belief in my own vision. I think oftentimes realism and what’s practical are my default, but Gary Vee reminds me to be a dreamer and to push to make sure that I am building a company where I get to serve in the ways that bring me joy. You’ve held several different roles over the course of your career, from digital media manager to developer. How did you find your way to UX? I started out as a developer with a huge emphasis on design. I’ve come to realize over time that design is important but user experience is even more so. Function, behavior, and meeting expectations of behavior have grown significantly in relevance. I made the leap as I tried to find ways for users to engage with the content and designs we were creating in a more meaningful way. I think that leap was absolutely the right one. One great example is from watching my daughters play Roblox . If you are not familiar with Roblox, it’s a web game with the worst graphics you could possibly imagine. However, they have created an environment that is interactive and offers thousands of games, including games that imitate other, less readily available, games. My girls absolutely love it. When I ask them how they are able to work through the horrible graphics they immediately reply with answers regarding function that supersede their desire for better graphics. What’s one book you think every UX leader should read? One of my personal favorites is Don’t Make Me Think . I think social media and Amazon have become so successful because they are highly intuitive and help the user accomplish basic tasks without thinking about it too much. That’s the subject of the book: how to reduce friction for the end user by making it as easy as possible to interact with your product/service. You have a degree in computer science and history. How did you choose that focus area, and what lessons have you taken from it throughout your career? My father was a history teacher in the Dominican Republic. Growing up, he would always share long historical accounts and the value of knowing history for the progression of humanity. Since then I became a lover of history and a pursuer of understanding of major historical events that shifted humanity. As I arrived in college I quickly realized that there weren’t too many career choices for me with history alone. I took a single development class and immediately fell in love with coding. I decided to pursue computer science with a focus on artificial intelligence and although I didn’t go that route, I find that the things that I learned in those classes are still very applicable today where technology continues to advance at an incredible pace. The marriage of these two subjects has in many ways shaped my view of the world. I take a look at small shifts in technology and always wonder what the larger impact of that shift will be on the world. My biggest takeaway so far is don’t underestimate how easily one app, one invention, one thought can change our entire world. Who’s one woman or nonbinary person whose name you’d like to drop and why? Someone I would love to name drop is Fatima Dicko . She is a college peer of mine and Founder & CEO of a venture-backed consumer tech company. She’s raised over $1MM to expand mobile marketplaces to college campuses around the country. Though we don’t have an opportunity to speak often, I am always following her career and launches. The journey of entrepreneurship can be so discouraging and it’s always helpful to see other bosses around you doing great work that inspires you to keep going. When the pandemic is over, what are you most looking forward to doing again? When the pandemic is over I am most excited about traveling to Paris! At the start of the pandemic I experienced a lot of anxiety and uncertainty and decided to channel that into something more useful! So I began learning French. I went from 0 French knowledge to being pretty comfortable with intermediate level conversations. I’m continuing to learn the language and would love an opportunity to test my skills an expand my knowledge in a trip! Know another woman or nonbinary person whose name we should drop? Tweet us at @HubSpotDev with ideas. This post originally appeared on Medium . Interested in working with people who care about thoughtful leadership? Check out our open positions and apply .", "date": "2021-03-10"},
{"website": "Hubspot", "title": "Making Security Usable at HubSpot", "author": ["Kenneth Breeman"], "link": "https://product.hubspot.com/blog/making-security-usable-at-hubspot", "abstract": "Security and usability have been at odds with each other since the dawn of time. We usually associate trusted software with clunky interfaces, not an intuitive user experience. This disparity has inspired many people to find clever (and not so clever) ways to work around common security measures. Some of the biggest information security breaches in the last year have been attributed, in large part, to this. We've been working hard to improve both security and usability internally at HubSpot. While we haven't found a perfect balance between the two, understanding their co-dependencies has helped us make our system safer and more user friendly. Usability is critical to security Security and usability are both important: if a system isn't user friendly, people won't use it. If a system isn't secure, anyone might use it. One of the best examples of this issue is passwords. The most secure passwords are long, complex, randomly generated, and almost impossible for the average user to remember. The human brain excels at pattern matching. Patterns are much easier to remember, but passwords following a pattern make it much easier to guess. Requiring regular password changes usually leads to partial password reuse (e.g. password1→password2). Enforcing complex passwords that do not match patterns tends to cause other bad behaviors: passwords on sticky notes, excessive password resets, password reuse across systems, and even bypassing authentication entirely. The ultimate goal is to make accounts very difficult to compromise, but strict password policies can have the opposite effect. Given two paths, people tend to choose the easiest: Why deal with sudo prompts when you can go in as root? Why test with real SSL when you can turn it off entirely? Why use the two-factor enabled VPN when you can install your own remoting software? Why bother with the office web filter when you can use a public proxy? Why struggle to setup office wifi security when you can plug in an open access point of your own? With all of these examples, it's clear that this is a real problem. People like to be efficient and productive, and anything annoying or repetitive in their workflow is going to cause friction. Friction causes frustration, so people will naturally try to avoid it. If you upset your own users while attempting to secure your system, you now have two types of adversaries instead of just one. So how can we increase security without sacrificing usability? I recently spoke at Facebook's Security @ Scale conference about some of the things we've done to improve usability around authentication, authorization, and accounting, and I've shared some of those key learnings below. Authentication Strong passwords are necessary to secure most systems, but they make the user experience difficult. Since reducing security isn't an option here, we need ways of increasing usability: Set reasonable session timeouts to help reduce the repetition of having to type a password over and over. Provide secure password management software to cut down on password reuse across systems and speed up the login process. Give users more control over their own account and reduce work for support staff by providing a self-service portal for password resets and other common account operations. Use secure secret management software such as HashiCorp Vault , Square Keywhiz , or Lyft Confidant to simplify access, and automate rotation and auditing of secrets. Authorization You need rigid security roles for nuclear launch controls, but not everything requires that level of security: Design your permission systems with change in mind. People change roles, roles change scope, systems change as well. Plan for exceptions to the rules, make exceptions a supported workflow. Sometimes it really is better to encourage asking for forgiveness instead of asking for permission. Support role-based access beyond strict organizational hierarchies. Accounting Traditional audits are ineffective in a fast paced company. Small, timely, contextual audits are much more useful than long infrequent ones. Audits must be timely. We’ve found daily or weekly to be a good cadence. If you can't remember what you had for breakfast that day, you probably won't remember why you connected to a random server that day. Context is really important in understanding the implications of a given action. Involve the owners and maintainers of the system being audited. Watch for trends and points of friction. If users are frequently making exceptions to rules, what are their reasons? Are they just being lazy? Are they up to no good? Or is it part of their job requirements? If it's the latter, it probably shouldn't be an exception anymore. Adjust your permissions to match the needs of your users. We've created a ton of automation to fit our needs around authentication, authorization, and accounting. Just like the rest of our product, we regularly evaluate how well things are working, gather feedback from users, and make changes where appropriate. If you work in development I challenge you to look for points of friction in your security and find a way to make it better. Solving for both security and usability is a hard problem. We haven't found the perfect balance yet, but we're certainly working on it.", "date": "2015-12-07"},
{"website": "Hubspot", "title": "Key/Value Pair Struct in .NET and JAVA", "author": ["Mohamed Faramawi"], "link": "https://product.hubspot.com/blog/bid/8233/key-value-pair-struct-in-net-and-java", "abstract": "I was proting some code from C# to Java, that code was using the struct KeyValuePair , this struct is pretty handy when you want to return a single key/value object without defining a Dictionary object that will contain only one element. In Java there is no matching class defined in core Java APIs that match the .NET KeyValuePair class, but such class can be found in the apache.commons.collections API and its called DefaultKeyValue . Although there is another option in Java core APIs, its the java.util.Properties , but i didn't like it.", "date": "2009-07-09"},
{"website": "Hubspot", "title": "Communicating With Your Customers: Crafting The Perfect Email", "author": ["Jonathan Kim"], "link": "https://product.hubspot.com/blog/bid/82800/communicating-with-your-customers-crafting-the-perfect-email", "abstract": "We've been sending emails to our customers for a long, long time, but we've been doing it for so long that we started to suffer from too many cooks in the kitchen. Moreover, our customer emails were something that we seldom used ourselves, so we never had the chance to eat our own cooking. As it were. When we appraised our communication channels at HubSpot, we noticed we had some gems, like the HubSpot Academy emails, and some sore spots, like the Weekly HubFeed. We wanted to start fresh with a vision driven by quality and usefulness: \"Inform and engage our customers with actionable information that will help them make effective, timely marketing decisions, both on- and off-product.\" That was the vision we started with, and we hope to continue to deliver that through all the ways we do messaging. Our First Email From the perspective of a developer, the HubSpot marketing team spends an insane amount of time each each month building PowerPoint presentations for each other. That's partly because at HubSpot, every decision needs to be supported by data , and every month there's a big meeting to show the results of those choices. We think this is a great way to do marketing, but it's also very time consuming. So for our first email, we set out to make this available to everyone and make it as simple and automated as possible. Our hope was that every marketer could simply open this email on Monday morning, download the PowerPoint and head straight to their monthly meeting, confident and well-equipped. The original design for this email was something I first conceived while at Performable. I wanted a short, daily summary that could be quickly scanned and understood. To do that, I leveraged three specific design patterns: Emphasize the big picture. Use color coding to tell the story quickly. Create a strong visual heirarchy to communicate importance. To acheive this, we made the conversion funnel the star of the email. There is little that tells your marketing story more succinctly than the funnel. We accented the percentages with either red or green to show whether things had improved or declined compared to the month before. For rest of the email, we emphasized one big number and grouped things by category to make scaning much easier. The email was intentionally monochromatic so that the percentage changes stuck out even more. We did all we could to make all the links as obvious as possible. Even the big numbers are all clickable, with generous click regions for tablets and mobile devices. After all, our goal was to deliver \"actionable information,\" not just something useful and pretty. Here's the most recent version: The feedback on the email has so far been very positive. Our first release of the email even satisfied our dream scenario: one of our customers wrote us a glowing review, saying how the PowerPoint saved his skin when he had to rush to a meeting he was unprepared for. We've kept the pressure on by releasing two other emails: the Daily Prospects Digest and the Weekly Progress Report (below). We approached both of these emails with the same vision that drove the monthly email, and they've turned out to be big hits with our customers. What We've Learned Know your metrics. We went into this with very clear goals, and we used those metrics to drive our design decisions very strictly. While this sounds limiting, it was actually very helpful. Test before you send. There are a lot of quirks in email design, so it's important to test for them as best as you can. Between the three emails, we easily looked at a couple thousand screenshots of our emails in different email clients throughout the entire design process. Reuse what you've learned. To maintain the quality of future emails, we've created a basic framework and done as much as we can to set the principles for HubSpot emails. When you see an email notificaion, summary, etc. from HubSpot, you can expect to see a very similar interface and the same design patterns at work. If you have any feedback about the emails (don't worry, you won't hurt our feelings :]), please share it in the comments below!", "date": "2012-02-21"},
{"website": "Hubspot", "title": "Eight Questions to Ask in Your Next One-on-One to Get Better Feedback", "author": ["Kerry Munz (She/Her)"], "link": "https://product.hubspot.com/blog/eight-questions-to-ask-your-manager-to-get-better-feedback", "abstract": "As an engineering leader at HubSpot, I run a team of incredibly talented engineers who embrace engineering values like Move Quickly and Iterate as well as Complacency Equals Failure . It’s a high-energy atmosphere fed by agility, quick-thinking, and action. In spite of this, or perhaps because of it, I know just how important it is to step back and take stock, to reflect on your work, your team, and yourself. Otherwise, amidst all of those fast daily decisions, how will you know that you’re on the right path? Or how you could do better? All of this brings me to the subject of feedback. One study from OfficeVibe found that 65% of employees want more feedback . It also found that only 58% of managers feel like they’re giving enough. Are you getting enough feedback? One of my favorite leadership books is Radical Candor , by Kim Scott. Kim developed an approach to feedback based on the balance of caring personally with challenging directly. The cornerstone of the success of Radical Candor is being comfortable giving and getting effective feedback. In an interview Kim emphasized “People just don't give feedback because it's hard and it's scary.” How can you make feedback less hard and scary for your manager? If you’re going to truly grow in your role you need to get into the (very healthy) habit of asking for feedback. It may feel like you’re exposing your vulnerabilities, but what you’re really doing is arming yourself with knowledge all while inviting your manager to be comfortable challenging you empathetically. Allowing your one-on-ones with your manager to devolve into project status updates week after week is cheating you out of some potentially career-defining conversations. So, although tips and tricks for managers on how to give effective feedback are always important ⁠— employees, this one’s for you. Here are eight questions to ask (and one not to) during your next one-on-one that will lead to more feedback, and help you grow better. Before we dig in, though, let’s start with what you shouldn’t ask : The Feedback Inhibitor: Do you have any feedback for me? This may feel like the natural question to ask if you’re looking for more of a growth conversation with your boss. But it’s surface-level at best. It pretty much begs the response “Not that I can think of” or “None at the moment.” It’s not far off from asking “How are you?” and hearing the response “Fine.” If you want to have a real conversation, you need to ask real open ended questions that invite deeper thought. What’s a real question look like, you ask? Read on. 1. Where have I had the most impact this month from your perspective? This one’s a good starting point. It’s a safe question that allows you to build self-awareness ⁠— a positive edit of the classic “Do you have any feedback for me” that’s deeper and more constructive. That said, ask for honesty here. If you aren’t having real impact, find out what needs to change. A good corollary question is “On a scale from 1 to 10, what was my impact this month?” A 1-to-10-style question only begs a one-word answer but always leads to an interesting follow-up conversation around why. 2. What do you think it would look like for me to be twice as good at what I do, or for this project to go twice as well? I love this question because it opens up areas for growth that you may not have known were there. Maybe you completed a project and thought you did an amazing job, but didn’t hear that positive feedback from your boss. This is a bold way to tease out of them, “How could that have gone even better?” Be specific here, and ask for details about communication, execution, results, timing, architecture, how you worked with others, etc. 3. What would a mediocre [insert your role here] do each day? What would a great one do? This is called the Inversion Technique . We often ask about what “great” looks like. But it’s also important to make sure that you’re not tripping into “mediocre.” Having more clarity about what suboptimal looks like can help you to avoid it (and build on it into greatness). 4. If you were away for a month, what do you fear would get dropped, stall, or fail? This is a question that I frequently ask tech leads and engineering leads about their team members, and about themselves. The conversation naturally flows into, “How could someone else take on those responsibilities so they wouldn’t stall?” How your own manager answers this question will reveal to you gaps in your own knowledge, relationships, context, and abilities. Most of all, it’ll give you an idea of the level of trust between you and your manager. A response to this question will show you what you need to work on to become a better co-pilot on the team. 5. Where do you see me get stuck most often? This one’s all about identifying your own blind spots. Do you often get mired in helping other people and neglect your own work? Do you over-research? Get too caught up in perfection? Have a tendency to not ask for help? We all have something, and this is an efficient way of zeroing in and excising the habits that are holding you back. 6. What would I need to learn or improve to take on a project like X? How would you know I was ready? A lot of your inspiration is going to come from your manager or someone further along in their career than you here. Think about a complex project that they recently tackled ⁠— was there a reason they didn’t give it to anyone else on the team to lead instead? Ask your manager, “If I want to run a project like that next time around, what are some skills I need to grow?” The discussion that results is going to shine a light on some gaps in your expertise, yes, but it’s also going to show you what great looks like ⁠— and get you that much closer to it yourself. 7. You’re exceptional at X. How did you get so good at this? This is an awesome question for a manager or an admired peer. The initial answer likely won’t be a surprise: “A lot of hard work.” But the details of what they say will allow you to dig in the same way they did: read the same books, study the same techniques, learn how they approached a problem from square one, not just how they solved it. 8. What’s your biggest challenge? One-on-one time with your manager isn’t just about finding out how you can do better in your role. It’s about looking ahead, and seeing what it means to grow at the next level. Ask this question to get a sneak peak at the exciting challenges you’re going to face down the road. And listen to your manager’s answer with empathy ⁠— understanding what they go through in their own role will bring you closer as a team and give you insight into what their priorities are and another clue to more impact. I’m not numbering this last one, because it’s a given: How do we make sure everyone on our team feels included? This may seem like something a manager should be discussing with your team as a whole, and if they are, great. But you should be bringing it up as well, whether or not your manager makes it a part of your team’s regular conversations. Inclusivity should be on everyone’s minds — it doesn’t just come from the top. There are a number of actions that anyone can take to both build diverse teams and foster inclusion and belonging , and thinking about how you can implement some of them on your own team is a good conversation-starter with your manager. There it is ⁠— a feedback starter pack for great growth conversations with your manager. A reminder here: you shouldn’t plan to ask all of these questions in a single one-on-one. Prep your leader with one or two in advance so they have time to think about their responses. Sprinkle these conversations throughout the year, act on the feedback you receive, and watch yourself grow stronger where you are, and grow closer to where you want to be. So what are you waiting for? All you have to do is ask.", "date": "2020-10-28"},
{"website": "Hubspot", "title": "Social Engineering: Why Managers Should Prioritize Team Bonding", "author": ["Eric Richard (He/Him)"], "link": "https://product.hubspot.com/blog/social-engineering-why-managers-should-prioritize-team-bonding", "abstract": "There are three key ingredients that go into creating a remarkable product culture . The first is ensuring that every person on your development team has an exciting and challenging mission. Then you need to give them the tools, resources, and autonomy to be successful in their mission. The third piece, and arguably the most challenging, is surrounding employees with high-wattage people who they can learn from and bond with. Building those relationships is important from a professional perspective because people learn new skills and strategies from one another. But these relationships are personal, too. Employees are happier at work when they can laugh with and confide in their co-workers. These are the relationships that will last long after employees leave a company. We realized we had work to do on this third piece not too long ago when a relatively new hire said they were feeling unengaged at work because they had hardly interacted with anyone (aside from asking their direct teammates for help) since they had started at HubSpot. Here was a great new hire surrounded by great people, given great tools and a great mission yet they didn’t feel connected to the company or their team at all. That sucks. It turns out that living in a world where you have headphones on and are spending most of your day focused on a screen is fantastic for building product, but not for building that social network. Fortunately, we were able to work with this individual and help them meet more people across the organization. But since then we’ve been talking a lot about how we can ensure that folks, particularly new hires, have the opportunity to form those relationships. People have different styles of getting to know one another and engaging in company culture . That’s why taking a passive approach of just putting people together isn't good enough. As leaders and managers, our job is to create different forums that have different flavors so that everyone within the organization has the right opportunity to meet new faces. To do a better job, we’re keeping what we’ve learned so far top of mind: Size Matters: Our co-founder and CTO Dharmesh Shah is a self-proclaimed introvert. He frequently jokes that big parties and crowded events are his worst nightmares. And he’s not alone. Socializing in big groups is stressful for a lot of employees. There should be opportunities for them to get past small talk with their co-workers that are more their speed. One way we’ve made this happen is by hosting  ‘Meet and Eats’ where folks from different development teams get to go to lunch together in groups of about 4 or 5. The groups are small but varied (they might include engineers, designers, product managers, co-ops, tech leads, or VPs) creating a low-pressure way for employees to get to know product people outside their small teams . Liquid Courage is Overrated: There’s nothing wrong with having office happy hours, celebrating a product launch over drinks, or grabbing beers with your team on Friday afternoon. HubSpot’s no stranger to any of those activities. But when socializing becomes synonymous with drinking, there’s a problem. Not everyone drinks and not everyone wants to drink on, say, a Tuesday or Wednesday. We’ve realized that revolving team outings around cocktails or the beer fridge unnecessarily puts those employees in an awkward position. Even a well-intentioned “Why aren’t you drinking?” can make someone feel uncomfortable. It pays to get a little creative and plan an activity that everyone can look forward to. Employees Know Best: We don’t have a prescriptive development process or tell our engineers how to build product. We just give them the tools and autonomy to make it happen. And sometimes that’s the best way to create meaningful social opportunities for your team. Earlier this year, we were debating whether or not to rent a house on Cape Cod over the summer for our engineering team. (We did this in 2014 and affectionately dubbed the week Cape Code.) We wondered: Is this a vacation? Is this a working vacation? Why do we do this and what should the expectations be of the team? We concluded that our job was not to declare rules or enforce policies. It was to create a promising opportunity and let employees use good judgement. So we rented the house for a week and the team roasted a lamb, played lawn games, got some work done, and cooked homemade pasta (see the action shot above) all of their own accord. The feedback we got afterward suggested that Cape Code put new hires on a fast track to getting integrated into the team and was the best thing we could have done for those social connections. We didn't know that the Cape Code would spark the level of engagement and camaraderie that it did. And we might realize tomorrow that 'Meet and Eats' aren't the best, scalable solution for smaller group outings, or that there's more interest in kid-friendly events than we had originally thought. We're learning as we go but what we've discovered for certain is that team bonding has to be a priority. When leadership is thoughtful about it, e veryone (from newbies to veterans, and from introverts to outgoing leaders) has the chance to build those important relationships. What's been the best way for your to get to know your co-workers? Tell us in the comments below. Oh, and by the way, we're hiring .", "date": "2015-08-20"},
{"website": "Hubspot", "title": "How HubSpot Delivers Email Templates to 900K+ Accounts", "author": ["Mitchell Katz (He/Him)"], "link": "https://product.hubspot.com/blog/email-templates", "abstract": "Back in July, HubSpot released free email marketing tools on top of our already free CRM. As part of these email tools, every portal gets 20 beautiful templates that our Content Design Assets and Email teams designed. These templates can be customized with your content in the drag and drop editor before sending them out. Email templates are just one of many default assets that HubSpot provides to make content creation easy for our customers. There are a handful of different data models that we use to represent the building blocks of the content platform (Templates, Custom Modules, Themes, etc.), and these models are shared across HubSpot. Knowledge Base, Email, and the Content Management System, just to name a few, all use data types stored in the content platform. Because we have these shared building blocks, we also get to benefit from a shared delivery system. There’s a bunch of processing and nuances to the system, but at its heart, it’s just copying the data model from one row in a database table to another. So regardless of whether you’re buying a new pack of landing page templates from the Marketplace or copying a Custom Module from one of your portals to another, it’s all the same back end: the same delivery mechanism. Our asset delivery system works really well when, for example, a developer at a small business builds a template in a developer staging portal and wants to copy it to the production portal. Conversely, when HubSpot builds a new template and wants to deliver the exact same template to 900,000+ portals, it can lead to all sorts of scaling issues. Copying the exact same data to 900,000+ rows of a table all at once can result in a lag on the database replicas, cache invalidation issues with our CDN, etc. Not to mention that it’s a waste of processing time and energy. It’s the same template everywhere, why do we need 900,000 copies of it? Lastly, it’s slow. Delivery of all 20 templates to all 900,000+ portals could take hours, sometimes days. HubSpot development moves fast, we have dozens of microservices deploying at any given time. We want our Content Design teams to be able to build a new template and see it in production as soon as it’s ready, just like the rest of our deployables. Earlier this year, with the launch of our free email tool approaching, we knew we’d be delivering to way more portals. This system had to change, and fast, so the CMS Assets I/O team set out on a mission to re-architect and build a scalable asset delivery system. At HubSpot, we love our open source tools. We’ve open sourced a number of our systems (including Singularity , our scheduler for running Mesos tasks, and Jinjava , our Jinja templating engine for Java). So when we started looking at redesigning this system, we loved the idea of Hollow , a Netflix-built open source tool to propagate read-only datasets in-memory. Hollow follows a basic producer-consumer model. We serialize the content object down to raw JSON and the producer puts it into a topic. Consumers can listen to the topic and when the topic updates, they pull in the newest version of the JSON, re-serialize it, and update their copy of the object with the new version. Hollow is built to be highly scalable by automatically de-duplicating data and optimizing for heap space. It can handle data sets on the order of hundreds of GB, which never would have been an option to store in memory before. Hollow handles data on this scale by calculating the differences in the data whenever the producer receives an update, and only pushing a payload containing the delta of information to the consumers. All this to say that Hollow was the perfect tool for this job. Of course, a complete system migration had to be handled carefully; millions of emails depend on these default assets. All of this re-architecting had to be done without our customers, or our customer’s customers, even noticing. We started by adding a data layer that could decide whether an API request should pull from Hollow or from MySQL. However, now we were maintaining identical data in two separate places. So we built in alerts whenever there was a difference between the database and in-memory. We built in switches to turn off Hollow in case of an emergency, and created fallbacks to pull from the database if a template were missing from Hollow entirely. Once the pieces were in place, we started slowly allowing customer requests to actually pull from Hollow. We used our feature gating system to provide it to 5% of customer portals, and over the course of a week we rolled it out to everyone. Once it was ungated to all, we saw something incredible; template delivery with ZERO database writes. What used to take hours was now instantaneous. Our team has automated Slack notifications whenever a default asset gets changed. We saw our notifications on production systems go from this: To this: We could now safely add and change templates, and actually see the work live in production when we pushed it. We’ve extended Hollow to include many more data types from our content platform, and we’re excited to see what else this tool can do. If this sort of work interests you, or you have more questions please reach out! We’re always looking for talented engineers to help us grow our CMS system.", "date": "2019-10-31"},
{"website": "Hubspot", "title": "Dev Tools at HubSpot", "author": ["Trevor Burnham"], "link": "https://product.hubspot.com/blog/bid/89543/dev-tools-at-hubspot", "abstract": "The first question I got when I joined HubSpot was: \"Air or Pro?\" Every developer here gets a MacBook; the rest of their workspace configuration is up to them. Some requisition a standing desk, or a couple of external displays, or both: But shiny hardware is nothing without great software. Here's a selection of some of our favorite tools, inspired by 37signals' post \" The New Guy's Computer \" : Z shell The standard shell at HubSpot is zsh, paired with an oh-my-zsh theme of your choice . As Professor Frink so aptly put it: \"The colors, children!\" z No relation to Z shell, z is a whip-smart pathname autocompletion script. Instead of typing cd ~/Code/hubspot/secret-project all I have to enter is z sec and I'm there! It's like Alfred (see below) for the command line. DTerm Got a Finder window open? Want to run a shell command in that directory? With DTerm, just hit ⇧⌘↵ and you instantly get a mini-Terminal right in that window. Sublime Text 2 While vim and emacs have their devotees at HubSpot, the hip new editor around the office is Sublime Text 2 . It's speedy, pretty, and easy to customize with Python. Clarify In OS X, ⇧⌘4 followed by spacebar gives you a screenshot of a window, and which is usually all you need. But what if you want to capture the same part of the screen repeatedly? That's where Clarify really shines, allowing you to take \"before and after\" screenshots, annotate them, and export them as a  presentation. (Full disclosure: Clarify is a HubSpot customer.) CloudApp Clarify can upload screenshots to Clarify-It.com for secure sharing, but when I just want to put an image on the web quickly, I drag it into CloudApp in my menu bar. It can also upload screenshots automatically as you take them, and copy the link into your clipboard. Alfred Alfred is an elegant application launcher. I just double-tap ⌘ to bring it up, type the first few letters of the app or folder I want, and I'm there. I use it 47.5 times a day ! Jumpcut / Flycut I have 8GB of RAM, yet my clipboard still only holds one object unless I use a utility like the venerable Jumpcut , or its more feature-ful fork Flycut . 1Password I use 1Password and its accompanying browser extensions to generate a high-entropy password for every site I visit, store those passwords securely, and sync them across all of my devices. That means that if any one site is compromised, I don't have to worry about the rest of my accounts. Did we miss any of your favorite tools? Let us know in the comments.", "date": "2012-08-14"},
{"website": "Hubspot", "title": "Customer-Driven Product Development: Understanding the real problem", "author": ["Matt Bilotti"], "link": "https://product.hubspot.com/blog/customer-driven-product-development-understanding-what-the-customer-really-wants", "abstract": "Every user of your product has valuable insight to offer your team. That’s why it’s imperative that every user who fills out a support ticket gets a thoughtful, human response that goes beyond simply answering their original question. In my last post I argued that all engineers should do their own support. When engineers are answering support tickets, interactions with customers act as a compass to guide product quality improvements and new feature development. In the early stages of product development, users with something to say are your most crucial lens on the world because they’re the ones who will get you to product-market fit. When an engineer or product manager answers your support tickets, you get the chance to dig deep into the root of the problem and have a direct and immediate line to fix the real issue. Getting To The Real Problem David Oates , a designer on the Signals team, says that customer support tickets are a lot like roaches. Seeing a roach in the kitchen is usually an indication that there are thousands more roaches in the basement. Similarly, for every frustrated customer that tells you about a bug in your product, there are likely hundreds more customers affected by the issue that aren't going to write in. When developers and designers have such a close relationship to the customer base, it allows them to understand the customer's frustration firsthand. The alternative is common in product; there are dedicated support reps that relay customer frustration and bugs back to the product team. Getting to the real issue in when a user writes in is not easy. Customers are usually reporting the symptoms of a problem rather than the problem itself, and they often struggle to articulate exactly what they are seeing, so it’s important to engage with that customer and figure out exactly what is going on. Delving into the heart of the issue is worth the time, because it's likely that you are tapping in to a cause of frustration for a number of other users who are having the same problem. What We Do At Signals When we're trying to understand the root problem of a support ticket, we avoid going back and forth over email, which is frustrating for all parties. Instead, we will invite the user to speak with us directly over a screenshare. By inviting the user to show us their problem, and not forcing a solution on them right away, we can get to the real problem faster. This allows you us to: Figure out exactly what their setup is in a live enviroment Hear what they understand to be the problem Hear them explain why they think it’s a problem Understanding what they hoped to be an end-result Once you've established this context, you're ready to dig deeper, and ask: What exactly were they doing prior to the problem arising? What was their train of thought as they were taking the actions that led to their frustration? What other variables could have affected the outcome that your product provided? Just ask why: Why did they click X? Why did they thing Y was going to be the outcome? Why would they have found that useful? Angry Users Are Your Best Friends There are times when you’ll make users angry. It happens. See these situations as opportunities rather than failures. A good support team can turn a raging customer into their biggest advocate, and better off having had the issue than if they had never contacted support. In order to turn these angry users around, you need to treat them as you would your friend (because, after all, they are your friend if they’re using your product). Tell them very calmly that you’re there to help them, that you want to help them, and that you will get to the bottom of their problem. Work around their schedules to fix things for them. Use the entire conversation as a learning experience, not was a way to get defensive about your product. This person is angry about something that likely many other people are frustrated about; they're just the most vocal. Remember, your loudest customer is going to be loud in both good times and bad times. If you put in the effort to wow them, they will reward you with a tweet of satisfaction and a referral to their friends. -- Want to learn more about customer-driven product development? Follow my personal blog at http://bilotti.org", "date": "2014-04-22"},
{"website": "Hubspot", "title": "Mesos, HubSpot, and the Singularity", "author": ["Adam Schwartz"], "link": "https://product.hubspot.com/blog/mesos-hubspot-and-the-singularity", "abstract": "Apache Mesos is one of the core pieces of infrastructure that helps HubSpot developers deploy 300 times a day. In this talk, Tom Petr ( @tpetr ) explains HubSpot's deployment infrastructure and the benefits that Mesos provides. Specifically, he showcases two open source projects: Singularity , a home-grown Mesos framework, and Baragon , an API for manipulating load balancers. Make sure you check out Singularity and Baragon on GitHub!", "date": "2014-04-09"},
{"website": "Hubspot", "title": "Come to HubSpot and Hack a Marketing App! HubSpot Hackathon2 Thursday 2/16", "author": ["Adrian Mott"], "link": "https://product.hubspot.com/blog/bid/81592/come-to-hubspot-and-hack-a-marketing-app-hubspot-hackathon2-thursday-2-16", "abstract": "We've made some great progress on the HubSpot App Marketplace over the past few months, and think it's a fine time to hold our next HubSpot Hackathon.  We're really excited about the possibilities and potential of creating apps on the HubSpot Platform and in the marketplace and are holding another Hackathon, coming up on Thursday 2/16 at 6pm at HubSpot Headquarters in Cambridge, MA, read more on the Eventbrite page here (please sign up!): http://hackathon2.eventbrite.com/ We're also giving out some very special prizes as a part of this Hackathon, including the opportunity to have dinner with Dharmesh Shah, HubSpot CTO and prominent Angel Investor as well as Yoav Shapira, former VP of Engineering at HubSpot and now our VP of Platform Strategy. There's also the opportunity to come in to HubSpot and hack on your app for an afternoon with some awesome HubSpot developers and product folks.  Check out the page linked to above to see how your app can qualify. This event will go late into the night as you might imagine, stay as late as you want of course, but we're also going to be letting any app that goes live within 24 hours of the event to qualify for the prizes. Some of the new features we've implemented and are working on are OAuth support, ratings and reviews and new APIs like Prospects and Keywords. OAuth opens up the HubSpot app marketplace customer base to all HubSpot customers, giving your app great visiblity and potential user base.  Of course, we're also working on billing through the HubSpot Marketplace, but that's not quite ready yet ;).  You can read more about the HubSpot Platform and Marketplace on our new developers site here: http://developers.hubspot.com/ We'll be proving food and drinks for the event, as well as some cool HubSpot shwag for apps that go live at the event. Come hang out with the best developers in Boston and hack apps with us. Hope to see you at the Hackathon!", "date": "2012-01-24"},
{"website": "Hubspot", "title": "Taking Women to the Top of Tech: Q&A with Women Who Code CEO Alaina Percival", "author": ["Hannah Fleishman (she/her)"], "link": "https://product.hubspot.com/blog/women-who-code-ceo-interview", "abstract": "With over 25,000 members in 18 countries, Women Who Code is making a dent in the way companies and communities think about, talk about, and solve for women in tech. “Our programs are focused on giving women in the tech industry the skills, opportunities, and network they need to stay in their careers and help them make it to the top.” That’s how Alaina Percival , CEO of Women Who Code (WWCode), described the organization’s mission to me last week. Alaina stepped up as CEO a few years ago and has grown the nonprofit into a global community that’s propelling women into leadership roles, both in and outside the office. Thanks to questions from engineers on our team, Allison, Meghan, Ollie, and our Director of Engineering, Sharon Chang, I had the chance to get Alaina’s perspective on how companies can advocate for women in tech, her favorite WWCode success stories, and everything in-between. How did you make the transition from marketing to becoming the CEO of a tech organization like WWCode? When I moved out to the Bay Area, I decided I want to give this whole tech thing a try. My background was in brand management and marketing, and I wanted to be part of an early stage startup or have my own startup. So, I was looking at the crossroads of ecommerce and tech because that fit with my background and was working on my own side project. But in the tech industry here, the early people getting hired weren’t marketing people. I realized I should learn to code because it would enable me to make updates to my own project and make me a better asset to a small company. So I started learning to code on my own and by going to community events. I heard that this organization called Women Who Code was going to get started and thought “that sounds great!” I joined before they ever had their first event and really fell in love with the community. I stepped up as a leader very quickly, stuck with it, and have worked to grow it. We’re now in 18 countries and are a 501(c)(3) nonprofit with a mission of inspiring women to excel in technology careers. For a long time, because of my marketing background, I actually thought “oh, I can’t lead an organization about getting women to become engineers.” Being an engineer wasn’t my personal goal so I had to justify it to myself by saying, well, everyone just knows to ask me questions about WWCode anyway. Finally I realized that if an engineer were to lead this organization, then she wouldn’t be able to engineer anymore. So, I think it works out. About 56% of women in technical roles end up leaving their jobs at the height of their careers. Why do you think so many women are giving up on tech? It’s a lot of different factors but one of the big things, I think, is hidden biases. It’s the tiny things that happen on a weekly or daily basis that are so small you’d never complain about a single one of them. But overtime, when you compound them with a wage gap or women not seeing their careers progress like their male counterparts’, you’ll decide to leave when you get put on a tough project, are having a child and have the opportunity not to work, or aren’t getting along with your team or your boss. Whereas if you see there are other women in leadership positions and if you feel you’re paid a salary that’s equal to your male counterparts (and therefore valued by a company at the same level they are valued), you can see that there are opportunities for you to make it to the next level. As a result, you’ll be more likely to stay in your career longer and shoot for those higher goals. What can companies do to get rid of “hidden biases” and create an environment that sets women up for success? I really want companies to be looking at best practices around hiring, onboarding, building structure and that supports women within companies, workplace environment, and career progression. So, transparency around what it takes to get to the next level. Companies should also be self-analyzing. If you look across a company and see that one gender or one socioeconomic class is being paid at a different level, which means that company values people differently, then there’s a systemic issue. That’s when you have women dropping out of the industry which companies, and the industry, can’t afford. To lose a woman for the last 15 years of her career, you’re losing her when she can provide the most value to a company, to the industry, and when she’ll be the best role model to women who are entry- or mid-level in their careers. When a man is assertive, he’s looked at as a leader. But when women assert themselves, the word “bossy” comes to mind. As a female CEO, what’s been your experience with this attitude? I, of course, never like to be perceived as “the bossy one”; it’s not something that's comfortable. But I do have to make decisions and I think that the hardest thing there, for me, is when someone has the expectation that I'm not going to be the authority. I was on a panel once with one of the partners at Y Combinator , Kirsty Nathoo , and she actually said that sometimes she’ll make a decision and people will say “oh, well can I talk to your boss?” and then she’ll immediately say “I am the boss and this is the decision.\" This brings about a dialogue in your mind, though, where you start second guessing yourself. Should I talk to an advisor about this? Should I talk to the team first? I think that’s an extra layer of difficulty that is put on women leaders. Ultimately, you have to be confident that you’re the boss and you made the decision. How do you handle those situations? For me, it’s about being aware that this exists. The tough things to process are the things that you internalize and blame yourself for. So if you think to yourself “this is happening because there’s a hidden bias,\" then it’s a little bit easier to process. But it’ s rarely ever in the moment that I find it hardest; it’s the internal dialogue that I have afterwards. And it’s usually tiny things that start that makes women start second guessing themselves. A couple months ago, a girl told me her team makes fun of her (light-heartedly) because she has her terminal set to pink. I’ve had other women tell me that they were at tech or engineering conferences or conference after parties and people asked them “so, what do you really do?\" or assumed they were a recruiter. If you get told over and over again that you don’t look like you belong, it’s easier to run that internal dialogue through your mind and think “wait, do I belong? Maybe I don’t and that’s why I ran into this problem this week.” Most things are small and they’re not going to send you out of rooms crying or make you file an HR violation. But it’s those things that you come across on a daily basis, the water cooler conversation, that can make you doubt yourself overtime. That’s why finding ways to process these interactions is one of the things that great communities like WWCode can provide for women. What are some of your favorite success stories of women you’ve worked with through WWCode? Tech is a fantastic industry for women and it’s only going to get better and better the more women that we have working in engineering roles. Some of the best stories I’ve heard are about women that transitioned into tech and are making double the salary they were before. A specific success story that comes to mind, though, is about one of our directors in Atlanta. She’s a very smart engineer with a masters in CS, but when she first started out as a director, she was so shy. At the beginning of WWCode events she would say “Hi, my name’s Erica, here’s what we’re doing today, feel free to ask me questions” and then just sit down and wait for people to approach her. But she stepped up as a director with WWCode and started sitting at the front of the room and becoming more vocal. This past year, she got invited to three different tech conferences to speak. She didn’t apply and get her talk accepted, she actually had raised her profile so much by being a leader at WWCode that she was invited. More importantly, she gave a tech talk to a standing room-only-crowd. She’s transitioned to being a leader in the tech industry in general, not just within WWCode, and now she’s a role model to other women. That’s incredible! Are there any other transformations that stand out to you? In our Code Review , we encourage women to participate in the broader tech community so we’re always including upcoming hackathons and conferences. About a year and a half ago, I started asking those hackathons and conferences if they had any women hackathon judges or female keynotes. At first, I heard a lot of “thats a good idea, do you know any?” So, for awhile I had a list of about ten women who had agreed ahead of time that I could give their information out. But now, the response has transitioned to “we have a few but we’d love more.” There was a conference last year that didn’t have a single woman in their lineup when they first announced speakers. We reached out to them right away, privately, to let them know they should include some women on their list. This year, they announced their early speaker lineup and it already had women thought leaders on it. That’s a clear illustration that companies, and in this case conferences, want to be doing the right thing. If we let them know the best practices, they’re going to adopt all the easy solutions and maybe even a couple of the hard ones. So if we can make some of the hard ones easier, or the industry norm, then we’re going to see a big difference. Just having conferences think automatically “oh, i should also have women speakers” is an important shift because it gives women in leadership positions an opportunity to be front and center. Those women are the ones who then get called on by companies for promotions or are brought in as thought leaders; it’s a snowball effect. What’s been your proudest moment so far at WWCode? The thing that I’m proudest of is our global Director network. Seeing women like Laura (co-founder of WWCode Boston) and Erica move into leadership positions as a result of being leaders within WWCode is incredible. They’re getting asked by companies to be thought leaders, getting promoted within their own companies quicker, and being listed or quoted in the press as top women in tech in their area. All these really exciting things are happening for our directors and demonstrating that they are becoming leaders in the larger tech industry. That is absolutely what I'm most proud of. What’s the most effective way for women in engineering to help other women in tech succeed? Advocating for women in their professional lives and pointing out how great they are to someone else. Right now, it’s still a little uncomfortable for women to discuss their successes and a little uncomfortable for society to hear them do it. So, we’re trying to shift that and make it comfortable. We need both women and men really advocating and sponsoring individual women in the tech industry and highlighting when they’ve done something great. On that note, I want to give a huge thank you to Alaina for taking the time to chat with us and sharing her insight. If you want to stay up-to-date on what Alaina and WWCode are up to, subscribe to Code Review here and stay tuned, Boston readers, for a WWCode event here at HubSpot HQ this summer!", "date": "2015-06-08"},
{"website": "Hubspot", "title": "Why our engineering leaders focus on product over process", "author": ["Whitney Sorenson (He/Him)"], "link": "https://product.hubspot.com/blog/hubspots-engineering-leadership-philosophy-part-1", "abstract": "Who was the best manager you ever had? Even though all of us have different people in mind, those people probably have a lot in common. Maybe he really cared about you as a person. Maybe she was a brilliant visionary who always knew how to push you to be better. Maybe their leadership styles were different — but I’d wager that their philosophies were the same. I’m sure it’s even easier to recall the worst manager you’ve ever had — the ones who were driven by ego, or who worshipped a process at the expense of the people, or who didn’t have the context to guide you effectively. It’s not always that people themselves are bad leaders; leadership is a skill, and few are talented leaders without working hard at it. Engineering leadership usually has three things in scope: process, people, and product ( that includes technology and architecture) . Most leaders can fully focus on only one or two of these; it’s nearly impossible to do all three of them well. Each area of focus comes with its own pros and cons. Are you spending most of your day in Scrum meetings, or making sure the iterations are going well and teams are hitting their commitments?  Are you spending most of your day managing under-performers, or coaching reports in 1:1s and talking about career paths? Or are you spending most of your day trying to ensure that your team is building a great product with a great technical foundation? There’s no correct answer, but your choice leads to very different outcomes and styles of leadership. Most companies encourage their engineering leaders to focus primarily on process or on people, and their diagrams might look something like this: But at HubSpot, we expect HubSpot’s engineering leaders to take an active role in building great products and building great teams. HubSpot was a process-focused organization in the early days, but we abandoned it long ago for a couple of specific reasons. Companies that heavily focus on process often do so because they have rigid expectations and looming deadlines. At companies like these, an engineering manager’s job is to create a predictable, reliable engineering team that delivers on what product owners tell them to do. They may spend a lot of their time running a software prediction process, like Scrum, in order to ensure that they’re meeting their commitments. But we have few solid deadlines at HubSpot, which means that we don’t need to subscribe to any specific methodology. But more importantly, we want to avoid a specific anti-pattern that tends to result from process-heavy organizations: a lack of ownership of their product’s success or failure. At many companies, engineering leaders are focused on building teams that can execute, but have no say at all on what they’re executing on. Setting those priorities is the job of Product and Design. There’s no co-ownership — if the team builds the wrong thing, that’s Product or Design’s fault, and in the most extreme cases, engineering leadership does not believe that the success of the product is their responsibility. But at HubSpot, we want everyone focused on building great products. That’s why we invest so heavily in building the relationships between Engineering, Design, and Product ( we call this the Triad, and triads exist from an individual team level up to an organization level). Each of these three people has a different perspective, and each of them has a voice and a vote. We believe that a predictable, reliable engineering team that builds the wrong thing is not a success. The engineering leader ( and the engineers themselves) have to feel ownership and responsibility around what they are building, not just how they are building it. This empowers engineering leaders to focus on figuring out how to make the team more successful, more autonomous, and more bought into their mission rather than meeting the next deadline. By owning the success or failure of the products they work on, leaders are incentivized to do whatever they need to do to build something great. And by modeling that ownership for their teams, leaders can drive that ownership all the way down the stack. Many successful organizations fall on the people-focused side of the diagram. In fact, for a long time, that’s where HubSpot’s engineering leadership f ocused , too. But we started hearing feedback in our quarterly employee NPS surveys that engineers didn’t see a clear path to move up into leadership. As a growing company, that was troubling — so we decided to dig in. We found that engineers were looking at the roles their leaders filled — roles that involved mostly people management — and saw people who were doing completely different jobs than they were. They focused on entirely different problems and had entirely different skills. Many of the engineers we talked to were already Tech Leads ( which at HubSpot is a player-coach role) and they just didn’t see themselves growing into a purely people-focused leadership role. An organizational anti-pattern can develop in engineering teams that focus too heavily on people management: a breakdown of trust between leaders and the people they lead. This most often happens when engineers feel their people managers don’t understand the technical context for their work. This lack of understanding leads to a lack of respect, and in the worst situations, engineers can start to see the people-focused work their managers do as pointless to their day-to-day jobs. Some companies try to get around this by splitting the role of engineering leadership between two people: a people manager, and a technical leader or architect. There are obvious advantages to splitting these roles. For one, it scales better. Because each person has only one job to do, each person can specialize on one piece of the puzzle. That approach isn’t for us. Engineering leaders at HubSpot do both jobs: they are technical leaders and they are people leaders. For one, it’s much more efficient, because when there’s just one engineering leader at the helm of a team, every conversation they have will be relevant and full of context. This means there’s less wasted time hunting for information or making decisions with incomplete data. We care so much about having new engineering leaders understand the context for their teams that we’ve set aside the first few months of their time at HubSpot to build that context. They spend that time joining the teams they’ll eventually lead and learning from them about HubSpot’s product and stack. At the end of this time, they’re much better equipped to take the reins. But more importantly, having two engineering leaders erases autonomy ( and we really like autonomy ). When responsibility is split, situations can arise where managers refuse to deal with them on the grounds that it’s “ not their job”. But if you’re an engineering leader at HubSpot, it is your job — no matter what comes up. That’s because, at the end of the day, your mission is to help your team figure out how to win. If leaders are on the ground — if they’re part of the game — they’ll have an easier time coaching their teams and making plays. Teams have an easier time respecting leaders who are moving the ball; they know their leaders are on their side and their team. We recognize that expecting our leaders to be strong technical and product leaders ( while not neglecting people management) stretches them thin. To be clear, we think people management is important — every engineer at HubSpot deserves an able and engaged manager. But we try to counteract this by making people management as efficient as possible. We use automation and tools to help us do it ( like 15five ) and lean on our team’s HR business partners when we need to. And there’s just no substitute for talking to people, so we make sure leaders set aside some percentage of their time to make sure their employees feel heard and are getting the mentorship and growth opportunities they need. It isn’t easy finding leaders who are attuned to the hopes, fears, and needs of the people they manage, who are adept at helping a team understand and get excited about their mission, and who have a strong technical and product sense. It is aspirational. But we think it’s the model that will help us build the best products for our customers while also building teams that are happy and work well together. And we hope that by developing leaders who engineers can relate to, learn from, and grow into, we’ll be setting our organization up for success as we scale. We’re not sure if this model will serve us well forever, but it’s the model that works for us right now. Interested in learning more? You can read more about the culture of our product team. And if you’re an engineering leader who wants to spend more of your time helping teams build great marketing, sales, and customer success software — we’re hiring .", "date": "2018-03-28"},
{"website": "Hubspot", "title": "Design Ownership for Engineers", "author": ["Simeon Lees (He/Him)"], "link": "https://product.hubspot.com/blog/design-ownership-for-engineers", "abstract": "In HubSpot’s early days, a lot of our designing was done by our engineers. Now, we’re fortunate enough to have a dedicated design organization, and with all due respect to our engineers, our designers have brought with them lots of improvements to the product. This begs the question, does our design team need input from engineers at all? In a world where we have ever-increasing levels of specialization in our roles, it’s easy to think our jack-of-all-trades days are behind us. The designers are the experts in their own field, after all. Right? Yes, and no. At HubSpot, we place a really high value on autonomy . One reason we do so is because it gives people the freedom to do their best work. Another is that, because we work in small, autonomous teams, our job titles are closer to specializations, and we can leverage each others’ insights and feedback to achieve our goals. So, should engineers have input into design? To be clear, the designers are the experts. Not only are they much more clued into our customers’ needs, their bread and butter is taking those complex problems and designing software that’s easy to use. Engineers, on the other hand, can make things that look a little “headache-ey” if given too much free reign (sorry). This isn’t to say that engineers shouldn’t be involved in the design process at all. On the contrary, the UX can be a lot worse off if engineers aren’t involved in the conversation. This won’t take the form of bugs, or even major UI issues, but often more subtle things: A UX that makes sense, but isn’t immediately intuitive A UX that works well for the most cases, but not for those edge cases that customers seem to keep bumping into A usable UX, but one that follows a different pattern than other parts of the app A small detail of a feature that will take a week to build, but doesn’t really provide that much value These kinds of things aren’t really major issues when looked at in isolation. They aren’t bugs ⁠— customers might not ever complain about them ⁠— but they’ll be a constant source of pain for those experiencing them every day. Thankfully, all of them are things that engineers can move the needle on. Enter the feedback loop. Feedback loops are the lifeblood of product teams at HubSpot, and they exist everywhere ⁠— from the small decisions we bounce off each other in our teams, right through to whole product lines that are born from user feedback. One feedback loop we as engineers are very familiar with is pull requests . As with any feedback loop, pull requests are a forcing mechanism for the creator to be honest about any shortcomings of the work. Even the strongest engineers are prone to shipping lower-quality code, let alone mistakes, if they work in silo, and don’t have to explain their work to anyone. Not only that, but providing feedback here is a net-positive, whatever the feedback is; even if the feedback is ill-informed, the reviewer is learning something from the exchange. And if it’s not, that feedback can drive a plethora of improvements, such as: Pointing out mistakes Clearing a misunderstanding of requirements Providing context the creator might not have had Suggesting alternative approaches For these reasons, reviewing pull requests is a win-win. Importantly though, none of these reasons are unique to pull requests. You guessed it ⁠— providing feedback to your designer can drive all of these improvements, and more. At HubSpot, the customer is at the heart of everything we do. We also believe that we have maximum impact when we align our efforts around common goals . It follows that when engineers are invested in the customer’s needs, that’s our best chance of delivering the product they deserve. Engineers can be a voice for the customer by providing design feedback. For the rest of this post, I’ll break this down into some specific ways that engineers can be better partners to our designers. 1. Have an opinion on designs Having an opinion is possibly the most impactful way an engineer can improve design. As well as for all the reasons feedback improves quality, having an opinion signals your investment in the customer experience, and influences those around you to do the same. It can be scary to start giving feedback if you haven’t before. Try to keep it as objective as possible, focus on the customers' needs, and remember it’s ok to be wrong; feedback is a win-win! If it helps, give feedback on the smaller things first ⁠— at least at HubSpot, smaller design decisions are often made in silo, and mistakes may have been made there. 2. Consider how long things will take to build vs. how valuable they’ll be We all care about having impact, but we only have so many hours in the day. It’s important to consider the time something will take to do alongside the value it’ll have for the customer whenever you commit to build something, especially as designers often don’t have that insight. Often there’s a quicker way to achieve the same outcome, which means more time for building other features! 3. Push for patterns Especially for bigger products, it becomes less and less likely that anyone will be familiar with every part of it. Without coordinated efforts to keep patterns consistent, small differences in UX can creep in between different parts of the app, which can become particularly painful for customers. Engineers may be familiar with parts of the app the designer isn’t, and can be advocates for consistency by calling out when a pattern is or isn't used elsewhere. 4. Champion the details The mocks will rarely cover every last detail. Things like edge cases, error states, and accessibility details are often up to the engineer to think about. It's important to make these as solid as the rest of the UX, as they will be experienced by your customers every day. Having great attention to detail will please customers and will often influence your teammates to do the same. 5. Hold your team to high standards All of the above will only serve to improve your work. You can improve the UX of your app even more by holding your team to the same high standards. If you’re looking for where to start, pull requests are the perfect place to do this. As well as reviewing the code, try testing out the UX too, and ask yourself if it is as intuitive, consistent, and easy as it can be. By providing this feedback, you’ll create a virtuous circle where the UX is talked about more and more. Ultimately, what all of these tips boil down to is having empathy for the customer, having empathy for your teammates, and striving for the best quality you can. Though we might have unique job roles and individual responsibilities, a team can be more than the sum of its parts by fostering a culture of productive feedback, and by leaning on each other for ideas. Does working on a team that values symbiosis between design and engineering sound good to you? Check out our open positions and apply .", "date": "2021-01-22"},
{"website": "Hubspot", "title": "Building an Auction App in a Weekend", "author": ["Joshua Tsuji"], "link": "https://product.hubspot.com/blog/building-an-auction-app-in-a-weekend", "abstract": "It's 2014. Everything needs an app, and HubSpot's 5th Annual Charity Auction was no exception. Until this year, our silent auction worked the traditional way: people writing their bids on pieces of paper, walking away, and maybe coming back every once in a while to see if anyone had outbid them. Does this work? Sure. Would it be way cooler (and more fun) to let people bid with a mobile app? Definitely! As it turns out, this isn't a new idea. A number of silent auction apps already exist, and our auction organizers looked into them. A recurring issue with each solution was that they cost hundreds to thousands of dollars. When you're raising sums in the tens-of-thousands range, that's a substantial loss. And despite the cost, most of the \"apps\" were either mobile websites, or built-in apps that simply wrapped the mobile website. Either way, the user experience suffered. Eventually, the organizers asked HubSpot's mobile apps team (that's us!) if we would be interested in taking on the project. The only catch? The event was in three weeks, and we had to keep doing our actual jobs. Reality Check After a quick Friday morning conversation around what exactly the app would need to do, we decided to let them know by Monday whether finishing it in a couple of weeks was feasible. A few signs pointed to yes. First, the app's only users would be HubSpot employees and their plus-ones, who can be trusted to Use Good Judgment . Good Judgment™ includes things like not impersonating other people, or not bidding one trillion dollars on even the most priceless of items. It meant that we could trust users to provide their real email address, and not bother with usernames and passwords. And it saved having to write countless lines of code to defend against malicious users. We also had the existing codebase from HubSpot's iOS and Android apps. The auction apps could borrow heavily from our existing apps, jumpstarting development. HubSpot app vs. the auction app. We're shameless. Finally, we had just discovered Parse . Parse promised to take database persistence, back-end server logic and push notifications out of our hands, hiding those generally unpleasant parts of app development behind their pretty SDKs. Oh, and it wouldn't cost anything, unless our users managed to bid more than thirty times per second . #JFDI At HubSpot, we're big fans of actually doing things instead of sitting around talking about doing things. After our conversation, I blocked off the next few hours to investigate Parse and make sure it actually did what we thought it did. Spoiler: it does (screenshot from after the auction). After spending a few minutes with the documentation, I signed up, created an Item table, and added a couple of Test Objects. Everything looked good, so I created a blank Android project, copied over all of the basics from the HubSpot app, and pulled in the Parse SDK. In theory, retrieving every item would take only a couple of lines of code: ParseQuery<ParseObject> query = ParseQuery.getQuery(\"Item\");\nquery.findInBackground(new FindCallback<ParseObject>() {\n  public void done(List<ParseObject> items, ParseException e) {\n    Log.i(\"AuctionTest\", \"Hello, \" + items.size() + \" items!\"); Log.i(\"AuctionTest\", \"First item name: \" + items.get(0).getString(\"name\") + \".\");\n  }\n}); > Hello, 3 items! > First item name: Test Object 1. That was it! Parse handles the networking, the threads, and all of the other stuff that isn't writing auction apps. Neat. Just to make sure, I created a NewBid table and made sure that writing objects was as easy as reading them: ParseObject newBid = new ParseObject(\"NewBid\"); newBid.put(\"email\", \"jtsuji@hubspot.com\"); newBid.put(\"amt\", 50); newBid.put(\"objectId\", items.get(0).getString(\"objectId\")); newBid.saveInBackground(); It's almost too easy. Putting those two pieces together, we can retrieve all bids for a given item to find its current price: ParseQuery<ParseObject> query = ParseQuery.getQuery(\"NewBid\"); query.whereEqualTo(\"objectId\", itemToPriceCheck.getString(\"objectId\")); query.orderByDescending(\"amt\"); query.findInBackground(new FindCallback<ParseObject>() { public void done(List<ParseObject> bids, ParseException e) { Log.i(\"AuctionTest\", \"Highest bid: \" + bids.get(0).getInt(\"amt\") + \".\"); } }); > Highest bid: 55 In fewer than 15 lines of code, we now had the ability to retrieve all of the auction items, bid on them, and determine their current price. After putting those code snippets into functions and hooking them up to a rough UI, we had a fully-functional auction app prototype - only a few hours after our initial meeting. Convinced that the project was more than feasible, I decided to add as many features as possible over the rest of the weekend. Push It Surely you won't stand for this. Used correctly, push notifications are an excellent tool for engaging your users. Sassy push notifications that name names are even better. The instant notifications led people to bid more frequently: Rapid one-upsmanship, brought to you by push notifications. ...and naming names resulted in a bidding war that saw two friends drive the \"choose a new flavor of yogurt for the kitchen\" item to a staggering $410 in the name of aimless rivalry (and charity!). Clearly, push notifications worked – and they were easy to implement! var query = new Parse.Query(Parse.Installation); query.containedIn( \"email\" , previousWinners.diff(item.get( \"currentWinners\" ))); Parse.Push.send({ where: query, data: { alert: itemBidMsg + \" Surely you won't stand for this.\" ... } }); The logic is simple: If someone was previously winning and no longer is, send them a push. Parse handles GCM tokens, device IDs, and all of the other things needed to actually send the push. You may have noticed the push code is in JavaScript - that's because it's running on the Parse servers using something called Cloud Code. We'll get to that. Scaling Up Requests per second on the day of the auction. The prototype app determined the current price of an item client-side, by retrieving all bids for that item and finding the highest one. Although that worked, it wouldn't have scaled well. We had a total of 97 items. There are at least 700 HubSpot employees. That means if every employee scrolled through the list of items once, we would use: 97 * 700 = 67,900 requests. It gets worse. To refresh the prices, we have to make the requests all over again. If everyone refreshed prices every ten minutes: 97 * 700 * (24 * 6) = way more than 30 requests/second. One possible fix is keeping track of \"highestBid\" and \"highestBidder\" directly in each item, and having the apps edit those two values whenever the user places a higher bid. This eliminates the need for apps to query for bids (since the price is included in the item), dramatically reducing the number of requests. Unfortunately, it's also a very dangerous way to do things. What if a request to change an item's highestBid to $350 arrives after a request to bid $375, due to network latency? The item's price would be updated to $350 and the $375 bid would be lost. What if the $375 bidder backs out, and we need to find out who bid $350? We'd have no way of knowing. Cloud Code Clearly, that's unacceptable. To solve this, we kept the bids table, so that we would have a record of each and every bid placed. We also kept the highestBid and highestBidder fields for items, so that clients never needed to comb through all of the bids to determine an item's price. Parse's Cloud Code feature lets us add JavaScript functions that are called before and after anyone tries to add a new bid. These functions are run on Parse's servers, and the only limitation is that they must complete execution in three seconds. We used this capability to keep the highestBid and highestBidder fields up-to-date: Parse.Cloud.beforeSave(\"NewBid\", function(request, response) { currentBid = request.object; itemQuery = new Parse.Query( \"Item\" ); itemQuery.equalTo( \"objectId\" , request.object.get( \"item\" )); itemQuery.first({ success: function (item) { var date = Date.now(); if (date > item.get( \"closetime\" )) { response.error( \"Bidding for this item has ended.\" ); return ; } // Do the rest of the checks and update the item ... }); Parse.Cloud.afterSave(\"NewBid\", function(request, response) { // Push code }); The beforeSave function checks the previous bids for that item, making sure that the new bid is higher. It also checks that the item is still open for bidding, and a couple of other constraints. If any of these restrictions aren't met, it returns an error and the bid isn't saved. Otherwise, it updates the item's highestBid/highestBidder fields and saves the bid. The afterSave function is called after a bid passes all of the tests and is successfully saved. Here, we send the push notifications to the item's previous winners. The apps refresh the list of items whenever a push is received, ensuring that item prices are up-to-date. Real Data Conversations with app testers revealed that although they loved bidding on Test Object 7, they preferred to bid on items with “actual value”. For this reason, we decided our next step should be importing all of the real items donated by HubSpot employees. Due to the last-minute development of the app, everyone had already added their donations to a page on our internal wiki. This is easy for you to read because you are not a computer. I copied the HTML code for that table into a convenient website that converts HTML to CSV . Then, I opened the resulting CSV in Excel, added a qty column to uniformly represent items with multiple winners, and cleaned up the data manually. Parse allows you to import data directly from a CSV, so the rest was easy. Next year, we’ll have donors submit their items via a web form, which will add it to Parse automatically. Finishing Up Keeping an eye on things with an Angular app. The core functionality was completed by Monday, three days after we learned about the project. We used the next few weeks to refine the bidding logic, improve the app UIs, and write a few tools like the Angular web app pictured above. The silent auction was held at the same time as our holiday party, so hundreds of HubSpot employees were in the same room using the app, getting angry at the outbid notifications, running around trying to find whoever outbid them to convince them to give up, and generally having a great time with it. We raised $28,231 with nearly 1,400 bids placed, and none of that money spent went to supporting the nonexistent costs of the auction app. Parse is free, and our time was our contribution to the charity auction, so there were no costs. Your Turn! HubSpot loves open-source software , so we're open-sourcing this entire project under the name BidHub . We love hearing feedback, and especially love pull requests, so check out our GitHub repos: Use the BidHub-CloudCode repo to set up Parse, clone BidHub-iOS and BidHub-Android to build the apps, and then put the BidHub-WebAdmin page somewhere to keep tabs on everything! We have lots of ideas that we didn't have time to add. If you do one of these and submit a pull request, we will think you’re super awesome! Full bid history in the app, so you can see who's currently winning and watch bidding wars in real-time. $0.99 in-app purchase to customize the outbid notification message. \"joshuatsuji bid $350: Want to fight about it? Lobby. 10 minutes. Be there.\" Set a \"high bid\" and have the app automatically raise your bid up to that limit. Notify donors when their item is bid on. A more fully-featured web admin panel that lets you add/remove items. There's actually some commented-out code in the BidHub-WebAdmin repo where we started that! \"Sudden death\" mode where bidding on an item doesn't close until one minute has passed since the final bid. And if these kinds of projects sound like your thing: We're hiring! Get in touch .", "date": "2014-12-17"},
{"website": "Hubspot", "title": "9 Lessons for New Product Managers", "author": ["Magdalena Georgieva (She/Her)"], "link": "https://product.hubspot.com/blog/9-lessons-from-onboarding-new-product-managers", "abstract": "Product management teaches you to think critically, make difficult decisions, and identify areas of opportunity in tough situations. How product managers develop and grow these skills will vary, though. There’s no blueprint to follow and there’s no secret to success. So how can we help someone get started in this world of product management? What can we do to make sure they’re flexing the right muscles? To set new PMs up for success, we have to give them actionable advice and tangible tasks that help them get their hands dirty within their first few weeks. We’ve welcomed a few new PMs and APMs (associate product managers) to the team recently and have learned some useful onboarding lessons, made a few mistakes, and identified pieces of advice that have helped them hit the ground running. Here are nine key tips we share with new product management leaders at HubSpot : 9 Lessons for New Product Managers from HubSpot Understanding product management: Focus on the problem and seek a quick development cycle. Making decisions: Think through your decisions out loud. Spending your time wisely: Do the work that will support your team the most. Prioritizing your work: Think about the majority of customers. Talking to customers: Accept phone calls and learn to ask open-ended questions. Documenting your learnings: Catalogue what you learn. Measuring value: Find out how helpful your product actually is. Being a team builder: Empower your teammates and collaborate with them. Reinforcing the vision: Keep things simple by revisiting the long-term mission and vision. While these slides cover the fundamentals for both existing product managers and new hires, they can't emphasize enough the most important lesson of all: learn fast . The only competitive advantage you have is your pace of learning. As Matt LeMay put it in \" The Past and Future of Product Management ,\" product needs people who “excel at adaptability and quick thinking — people who are lowercase-a “agile.”", "date": "2015-12-15"},
{"website": "Hubspot", "title": "How Twitter and HubSpot Are Scaling Build Systems", "author": ["Hannah Fleishman (she/her)"], "link": "https://product.hubspot.com/blog/how-twitter-and-hubspot-are-scaling-build-systems", "abstract": "Tech Talk at Night is a chance for engineers to get together and talk about the problems they're solving across the stack. We hosted the second installment of the event earlier this week, featuring talks from Twitter and our own development team about growing pains that come up with build tools as teams and systems scale. First, Jake Ouellette , senior software engineer at Twitter in Cambridge, walked us through why 'Builds Are People Too.' Drawing from his experience working on Twitter's mobile SDK platform, Fabric, he talked about the dangers of failing to maintain your builds and how engineering teams can and should avoid \"build debt\" the same way they would avoid technical debt. Next, Jon Haber , staff software engineer on our Platform as a Service (PaaS) team, closed out the evening with a talk on how and why Jenkins is no longer a match for HubSpot. He introduced Blazar , a new (early-stage) open-source build system the PaaS team has been developing. It detects new projects automatically in Github, improves developer notifications, and proactively builds all branches of a project across the hundreds of repositories at HubSpot. Watch both presentations and audience Q&A here: Stay tuned for the next Tech Talk at Night and in the meantime, check out #TechTalkatNight for photos and highlights from the September event.", "date": "2015-09-25"},
{"website": "Hubspot", "title": "Relieving Backbone Pain with Flux & React", "author": ["Gus Vargas"], "link": "https://product.hubspot.com/blog/moving-backbone-to-flux-react", "abstract": "For the past few years HubSpot has been building single-page apps exclusively with Backbone . And boy, have we learned a lot in the process. Mostly, we've learned that while Backbone is great at what it does, operating at a larger scale and a faster pace means we have bigger problems to solve that require different approaches. Over the past few months we've been experimenting with Flux & React by implementing them in internal tools and small portions of our products. The performance gains we've seen, coupled with the simpler mental model, have convinced us that this is the way we now want to build frontend web applications. In this talk, I go over some of the pain points we're currently experiencing with our frontend apps, and cover a fair bit about how Flux & React can help. Resources Flux Overview React Community Round-up #23 Facebook's Dispatcher", "date": "2014-12-02"},
{"website": "Hubspot", "title": "I’ve Been Doing Retros Wrong for Years", "author": ["Hank Lander"], "link": "https://product.hubspot.com/blog/ive-been-doing-retros-wrong-for-years", "abstract": "And I bet you have, too. Think about your last Retro. (If you aren’t currently running Retros, you can learn more about frameworks, how to incorporate them into your team, and why they are important here .) What was at the center of the conversation? Was it about team productivity? Did you talk about the health of the team? Did team members share how they were feeling? Personally, I fell into the trap of too narrowly focusing on outcomes. I was wrong! As PMs, we are drilled to think about outcomes and one tool we use to drive better outcomes is running Retros. We use the Retro process to motivate and guide our teams to think about improving productivity. However, only optimizing for outcomes can be at the cost of team health. I now believe that the best teams put the same amount of effort into being massively productive as they do building a positive team culture. Defining “the best teams” Before, I (perhaps like you) made the same faulty assumption: I assumed that the best teams (and the ones I wanted to be a part of) were the ones that delivered the most value. This is true, but I missed an important element in my equation. I took the team out of teamwork. I assumed that a team that delivered high output meant that people understood the value and impact of their work, enjoyed working together, and felt challenged and fulfilled as individuals. I didn’t prioritize team health , because I thought it  would take care of itself. I no longer believe this to be true. A team delivering sustained value over the long term with a healthy dynamic requires an intentional focus on team health. So how do you create or ensure you have a high-performing team that can weather the tests of time? Retros done right You can use a tool you already have: Retros! All it takes is 10 minutes, but it starts with unlearning some of the things you were taught early in your career. We are all taught that we should confront issues in a structured way so as to avoid making anyone feel like they are going to get punished or called out. This makes sense as it creates a psychological safe space so we can discuss bad processes or gaps in communication as a team in a calm and composed way. However, it has one huge unintended consequence. It sterilizes a team’s humanity.  By directing the team to act professionally, we ignored the personal. We aren’t output-driven logic machines. We are people. We all have our own unique desires, motivations, and personal situations. Let’s lean into empathy and learn from each other, because that is what makes us stronger as a team. Once you have established a safe, trustworthy environment for your team, I recommend leveling up your Retros and adding dedicated time to discuss team health. This is what I have started doing. At the end of each Retro, I have started asking the team to evaluate their team health on the following four factors: Team Health Questions: Activation : Are you feeling motivated by the work? Decompression : Are you able to disconnect and “recharge” outside of work hours? Resilience : Are you able to recover and remain engaged in a changing and challenging work environment? Team Chemistry : Are you feeling included in the team culture (eg: shared vocabulary, experiences, jokes, etc.)? Solving for motivation and connection I have found that asking these questions has led to responses I never could have predicted. Top performers were suffering from a lack of motivation, which could have led to attrition if not addressed. In this example, by digging in and listening, we were able to tweak the way we do our planning sessions to better tie the big picture to the daily tasks. We now start our planning sessions with the three month vision instead of starting the meeting by discussing KPIs or team metrics. This motivates not only the individual contributor in question, but also the team as a whole. We also heard during our new Retro process that teammates were feeling disconnected in these socially distant times. We used this feedback to create a space to brainstorm new ideas to connect us, especially with new team members. One of the ideas that resonated was Fun Fact Fridays. Now every Friday, people post riddles, brain teasers, or just random facts in Slack. This creates camaraderie and connection with each other that is beyond work or “shop talk.” The importance of putting people first We have found that the new information we are learning during Retros is helping the team address problems in small ways before there are major issues. Most importantly, we are doing this by putting people first. This has not only helped the team grow but also become closer as people. On a more personal note, I feel that talking to my teammates on a more personal level has helped me level up as an individual, as well. So, during your next Retro spend 10 minutes to check in on your team's health. You won’t regret it. Remember: it’s possible to be part of a team that delivers both amazing outcomes and is in it together for the long haul. Want to work with a team that puts team health and productivity first? Check out our open positions and apply .", "date": "2020-11-17"},
{"website": "Hubspot", "title": "Telegram Data Clustering Competition: The Solution that Won Second Place", "author": ["Alex Kuznetsov"], "link": "https://product.hubspot.com/blog/telegram-data-clustering-competition-the-solution-that-won-second-place", "abstract": "Recently Telegram ran a Data Clustering competition where participants were asked to build a prototype of a news aggregation service, similar to services like Google News and Yandex.News . I finished second in this contest (nickname: Daring Frog) using nothing but Python, so decided to share details of my solution in case if someone finds it helpful. You can check out scores per task (thanks to Mindful Kitten ), speed comparison , final leaderboard , code , and play with the live app which looks like this: Live app, available at: https://entry1410-dcround2.usercontent.dev/20200525/en/ 🎯 The Task Full description i s available on the contest page (I recommend glancing over it before reading this post). In a nutshell the task was to produce a binary executable which can perform the following: 🗃 Part 1 — Offline Batch Processing Traverse an input directory and parse all HTML files (articles) in it with news content Detect article language and filter out articles which are not in English or Russian Classify articles into one or several of 7 categories: society , economy, technology , sports , entertainment , science , other Filter out articles which are not news (e.g. how-tos, tips, encyclopedic content) Group articles into threads. Thread is just a collection of articles about the same event Sort articles within a thread by relevance Sort threads by importance 📡 Part 2 — Online Processing with HTTP server Spin up the HTTP server, load its previous state if one exists Index incoming articles Update existing articles Delete existing articles Return top article threads, with optional filters by language, category, and time range Apart from these requirements, Telegram highlighted that “speed is of utmost importance”, asked for binary sizes of 200Mb or less, and required the binary to execute on a standalone 8-core 16Gb RAM Debian GNU/Linux 10.1 machine without a GPU. On top of that it was not possible to test or launch the app on Telegram side prior to submission, so contestants basically had to ensure flawless reproducibility. These requirements were the main factors behind my preference for the simplicity of the algorithms and libraries I used. ✅ Solution Disclaimer: as the contest lasted only 2 weeks, there are numerous oversights and areas for improvement in this solution. I list some of them in Appendix A. 🗃 Part 1 —Offline Batch Processing 1. Preprocessing. Input HTML is read as plaintext. Metatags for the title, description, URL, and publication time are extracted using simple regexes. Basic cleanup is done for the title and description: stripping punctuation and special symbols, lowercasing (but not for acronyms), adding spaces around currency values (e.g. “100$” becomes “100 $”), capping max string length. Words are normalized using lemminflect (for EN) and OpenCorpora (for RU) to improve the quality of categorization and clustering (described below), as it helps to lower the vocabulary size and reduces overfitting. Original texts are kept and used together with cleaned up ones, depending on the task. 2. Language Detection. Language detection is performed using fastText ( lid.176.bin ) library. Language is set to UNK if fastText confidence score is below a given threshold. Additional heuristics (matching on certain symbols and popular phrases) are used for disambiguating corner cases for languages which fastText views as similar to Russian (UA, TG, BG). Preprocessing and language detection are done jointly using 16 threads spun up via multiprocessing package as HTML files can be processed independently. 3. Category Classification. Category classification is done using a simple SGDClassifier from scikit-learn with modified_huber loss. Input to a model is a vector from TfidfVectorizer which is run on a concatenation of the article title, domain, and description, with max length of such text capped at 500 characters. TfidfVectorizer operates on uni- and bi-grams (with NLTK stopwords), uses sublinear TF scaling, min_df=3 , max_df=0.95 , and dtype=np.float32 . For this task a simple SGDClassifier appears to be a great fit: It captures vocabulary breadth very well, which is important since there are many category-specific terms in the world of news and it is often necessary to memorize them based on only a few available examples. E.g. TfidfVectorizer vocabulary size is 142K for RU and 70K for EN what would be considered large for a typical use case but works quite well for capturing the diversity of news. With a simple model like this it’s possible to avoid overfitting even while using such a large vocabulary and a small dataset. It is incredibly fast and supports sparse matrix input. Sparsity means we can 1) efficiently work with large vocab size without the need to pass TF-IDF outputs through the expensive SVD step and 2) there is no need to maintain massive embedding matrices which take up RAM, disk space, and lead to overparameterized models. It is easy to interpret and debug (one can easily trace model predictions all the way to the weights assigned to each vocabulary term). I also considered dozens of other model types — see Appendix B for why they they were not chosen. TfidfVectorizer and SGDClassifier are trained on datasets like Lenta.ru (RU), HuffPost (EN), TagMyNews (EN), News Aggregator Dataset (EN), BBC (EN), Webhose (EN), as well as manually crawled websites for news categories (e.g. technology, auto, weather) which suffered from label shortage in the aforementioned datasets. Training set was additionally enriched using unlabeled sample data provided by Telegram by auto-assigning category labels using article URL information: e.g. if /football/ is in URL of a reputable domain we can attribute it to sports category with very high confidence. Overall, while maintaining a reasonable distribution of examples across classes (roughly matching ratios expected at the inference time), I managed to get ~120K training examples for EN and 313K for RU. In the table below you can see the number and ratio of training examples per category: 4. News Filtering . News filtering is based on a set of heuristics which are simple rules based on the following features: Category classifier (described above) confidence score Number of tokens in the article title / description Presence of special characters Matching on pre-approved or pre-banned words, subword units, or lemmas Title matching certain pre-compiled regexes: how-to articles, bad phrases, bad title beginnings, lists/enumerations (e.g. “10 tips for…”), etc Match on a known bad title pattern. This is a little trick you can use to find templated (e.g. auto-generated) titles, essentially by converting a title to a code (e.g. Music — Lounge. 27.03.2020. becomes W — W. ##.##.####. ) and clustering such codes or just checking most frequent. This takes only a couple of lines of code: You can see detailed rules in the inference script . 5. Thread Clustering . News items are clustered into threads using DBSCAN with the following settings: min_samples=2, eps=0.55, metric='cosine' , which is run on TF-IDF vectors of article titles. TF-IDF vectors are produced using TfidfVectorizer with SentencePiece tokenization function. Just as for news classification, I set dtype=np.float32 for TF-IDF vectorizer to speed things up a bit. TfidfVectorizer and SentencePiece models are trained over all EN and RU sample articles provided by Telegram (~600K per language). SentencePiece model has a vocabulary size of 10K tokens. Additionally, for some tokens (such as geo-related) I boost TF-IDF scores to give them more importance in clustering (this e.g. forces similarly-titled news from unrelated cities to be forced into separate clusters). 6. Article Sorting within a Thread. Within clusters, articles are primarily sorted by relevance (computed as the sum of dot products with vectors of all other articles in the cluster). Secondary and tertiary sorting by domain PageRank and freshness, respectively, is performed as well. When sorting, I ensure that no pair of consecutive articles is from the same publisher, providing a bit of diversity to the feed. For naming the article thread I simply use the title of the top article in a sorted list. All clustering operations are performed on a single sparse matrix and therefore are fairly fast. 7. Thread Sorting. News threads are sorted simply by the product of the number of unique domains in the thread with the combined PageRank of these domains. And if this score is the same for two articles, additional sorting by the number of articles in a thread is performed. Thread category is defined simply as the most frequent category amongst articles in a thread. Domain PageRank was computed using sample articles provided by Telegram for all domains with at least 100 publications (~3K domains). 📡 Part 2 — Online Processing with HTTP server 1. Spin up the HTTP server. For handling HTTP requests a SimpleHTTPRequestHandler is used. Server responds with HTTP/1.1 503 Service Unavailable until resources (such as models, vectorizers, vocabularies, and previous index state) are loaded. 2. Index incoming articles. As articles arrive in a never-ending stream, we basically have to perform real-time clustering, as article threads may expand or change with time. From contest description it was not clear whether we can tolerate any delays on clustering, so I decided to go for the solution in which index and article clusters are always up-to-date. To do this I wrote a naive agglomerative clustering algorithm, similar to SLINK . Step 0: I ncoming article is preprocessed, vectorized, and categorized as described above in the offline section. In case if article is non-{EN,RU} or not a piece of news we save it as such and skip the following steps. Step 1: F or weaving articles into threads we operate on 16-hour intervals (buckets). For a given article its previous, current, and future buckets are fetched, i.e. a 48-hour window is considered (we assume that no article thread will span more than two full days). We need to look into the “future” since it’s possible that some articles arrive with a delay, e.g. if a crawler found an article from yesterday we might want to stitch it to a cluster from today. Step 2: A rticle title tokens with IDF score below a given threshold are picked (i.e. we ignore terms which are too generic). For such tokens, in each of the buckets (past, present, and future) we perform an inverted index lookup to get a subset of previously indexed articles which share one or more terms with the current article. Inverted index is a simple lil_matrix where rows are terms IDs and columns are article IDs — so we can make a lookup by IDs of tokens from TF-IDF vector in order to get IDs of relevant articles, which then can be used to look up vectors (“embeddings”) of relevant articles in the main “embedding” matrix. Step 3: A mongst these article candidates we find the closest article by dot product similarity computed on L2-normalized TF-IDF vectors. If we find an existing article similarity of which is above a given threshold we can assign our new article to the cluster with the existing article. If we don’t find an existing article which is similar enough we create a new cluster. Step 4: L2-normalized TF-IDF vector for the new article is stacked on top of the existing CSR matrix with vectors for previously indexed articles in this time bucket. CSR matrix works great for this use case as it allows for fast multiplication, combines nicely with sparsity of TF-IDF vectorizer, allows for fast v-stacking and row deletes, and overall appears to be the most efficient sparse matrix for this use case. Note that each time bucket has its own CSR matrix what greatly speeds up the dot product (as we can ignore vectors for all other irrelevant time periods) and also ensures that index can scale linearly with time (if we grossly oversimplify and assume constant daily number of news). Step 5: A ll other relevant properties for the inverted index and cluster info (max time, category, list of articles) are updated accordingly. 3. Update existing articles. Article update happens if any of its attributes changed and is carried out by simply deleting and indexing it again. 4. Delete existing articles. Article deletion is straightforward, as we simply wipe all info about this article. One potentially interesting bit here is that we want to delete a row from the “embedding” matrix (with normalized TF-IDF vectors) which isn’t something CSR matrix supports by default. Luckily we can perform efficient in-place deletes like so: 5. Return top article threads, with optional filters by language, category, and time range. This is straightforward, as we only need to iterate over relevant time buckets for a given language and return article threads which belong to a given category within a specified time range. 🛠 Part 3 — Building a Binary Telegram required an executable binary file to be provided in the contest submission. There was also an additional requirement to keep binary size under 200Mb. Therefore I used a separate conda environment with a minimal set of libraries used (only fasttext , numpy , scipy , scikit-learn , sentencepiece ). Using this environment it is trivial to create a lightweight binary executable by pointing pyinstaller to the inference Python script: If you want to run the app on sample data you should be able to do this using a binary produced at this step by running a command like this (following the API described here ): ./tgnews threads \"/path/to/directory/with/articles\" . Or just run it directly using a Python script , e.g.: python tgnews.py threads \"/path/to/directory/with/articles\" . Conclusion In the end, my solution is just a combination of Python , fastText , SentencePiece , TF-IDF , SGDClassifier , and DBSCAN . I find it to be very simple and a bit hacky yet despite this, it has ended up being 2nd by quality and 3rd by execution speed (on par or faster than C++ solutions 🤷‍♂). This simplicity allowed me to do everything on my old MacBook Pro 2012 — something rarely possible in Kaggle-like contests. There are many things which I would’ve loved to do differently and I list some of them below. Hope you’ve enjoyed reading this and learned something new. If you have any questions at all, please reach out to me on LinkedIn . I also highly recommend reading a couple of comprehensive overviews of the awesome solutions that ranked 1st and 3rd in the competition. And of course I’d like to close by thanking organizers for putting this event together. It was a great bit of fun and I definitely learned a lot. 🚀 Appendix A. Potential Improvements Support for parallel requests. At the evaluation stage Telegram team was sending up to 100 parallel requests to the binary which is not something my submitted app supported. Thankfully they could still send requests in a single stream for the majority of the evaluation stages, yet this could not be done for the “Today” mode, so my app fully crashed there. I thought this would disqualify my submission altogether, but probably a strong performance in all other tasks helped with the final ranking. News Filtering should be based on a model and not a set of regex-based heuristics. One idea would be merging news filtering and categorization tasks, as some contestants did ( 1 , 2 ), however there may be benefits in keeping them separate. In either case, there is a need for carefully labeled “not-news” examples, as this is a vaguely defined concept for which little-to-none public data is available. News Categorization model quite obviously lacks depth (i.e. it doesn’t make decisions based on “meaning” but rather bases them on memorizing certain term-category associations). If compute resources permit, it would be useful to combine breadth of the current model with the depth and non-linearities which neural nets bring. This could be done using Wide & Deep models, model ensembles, or other techniques. Pre-trained embeddings could be added across the whole pipeline (news filtering, categorization, clustering). I omitted them fully due to the 200Mb binary size requirement. Other article and publisher features should be used. Using only title, URL, and part of a description is extremely limiting. Current clustering based on exhaustive dot product search should be thrown away in favor of scalable high-performance ANN methods similar to ScaNN , HNSW , and FAISS . This will help support million- and billion-sized indices while keeping latency low. GPUs/TPUs should be leveraged, as well as high memory (RAM) machines to keep relevant parts of the index in memory. Creating a task-specific labeled dataset. It wouldn’t be too expensive to get 100K-1M labels, what should be enough for fine-tuning models trained on public datasets. If budget is a constraint, active learning will help. By not labeling sample articles I likely ran into training-serving skew and all sorts of other unwanted biases. Team from the 1st place labeled articles via raters which let them significantly outrank other submissions in the categorization task. 😢 Appendix B. What Didn’t Work HDBSCAN for batch offline clustering. Typically HDBSCAN is a go-to tool for clustering which scales extremely well and has very high-quality outputs. However here DBSCAN outperformed it in both quality and speed IIRC. BIRCH for streaming clustering (too slow). DenStream for streaming clustering (custom algorithm was more flexible). FAISS for streaming clustering (IIRC, it wasn’t much faster than well-optimized sparse matrix operations, especially at low data volumes). Using float16 (instead of float32 ). Coming from GPU world I thought this is something scipy and numpy can support as well, but unfortunately they don’t , as float16 is not supported on CPU. Other model types for news classification: I tried everything from scikit-learn that works with sparse inputs. No other model type could beat the quality and speed of the simple SGDClassifier . ComplementNB was close or slightly better in performance but lead to a larger binary file size. Other frameworks for news classification ( TF , Keras , PyTorch ): I ruled them out from the very beginning in order to keep binary size small and inference fast. Adding TF to a standalone binary will push it way over 200Mb limit. Loading text files as json or gzip . This is significantly slower than plain old pickle due to the decompression and the need to parse json file. Bypassing news filtering for all articles from top publishers by PageRank. Idea was that maybe they never post non-news content. I was wrong, sometimes there are articles which would be classified as “not news” according to the task description. Using TF-IDF-weighted CBOW fastText embeddings for clustering (instead of sparse TF-IDF vectors). Usually you’ll find that TF-IDF-weighted embeddings (e.g. word2vec ) is a very strong, fast, and simple baseline yet here it was slower and lead to more diluted clusters. EN inflections from WordNet . LemmInflect was a bit better quality-wise. ⚠️ Update (25.09.2020) ⚠️ Issues around “Today” mode have been resolved. Updated app supports up to 100 parallel requests and was significantly sped up by introducing incremental writes to disk, thread locks, and limiting input length. Now it can handle indexing of up to 200 news articles per second, regardless of the index size. Live app is available at https://1410.topnews.com/ . This post originally appeared on Medium .", "date": "2020-11-20"},
{"website": "Hubspot", "title": "Async != Fast", "author": ["Ernie Park"], "link": "https://product.hubspot.com/blog/async-fast", "abstract": "In a recent campaign to improve our front-end web performance at HubSpot, we learned a simple but important lesson: Async != Fast Javascript heavy apps and libraries have become much more prevalent on the web, and HubSpot is no different. We use Backbone on the client which consumes a handful of any of our hundreds of API endpoints via AJAX. We also load third party libraries with script tags at the end of the body. Even though all these scripts and requests are happening asynchronously, it's very dangerous and downright wrong to think that your app won't suffer a performance hit because of them. This means that you cannot just add extra API requests or async script tags without fear of consequence; every request has a cost. Though asynchronous loading means your Javascript can do other things while it's fetching a resource, there are a couple other considerations to keep in mind: 1. Number of Concurrent Requests Browsers have a limited number of requests they can make at a single time. In Chrome for instance, that number is 10. If you have 11 requests happening at once, that 11th one has to wait for one of the first 10 to return. There is also a limit per hostname, so if you're making many requests to your own API, you could be causing waterfall'ing of your requests. You can find browser request limits here . 2. Parse/Eval Time In the case of a Javascript library, your browser still has to parse and evaluate the script after it has been downloaded. Javascript is single-threaded, so this is time spent not doing anything else. Any client-side libs that have a large footprint should set off some alarms. With our synthetic performance monitoring, we recently discovered that one aysnchronously loaded Javascript library was slowing down our app significantly. The graph shows load time of our app over time. In cases where the third party script finished downloading before our internal scripts, it delayed time to interactivity and the execution of our own scripts by nearly a full second. It was essentially a race condition based on how fast the third party script loaded. To fix this issue, we decided the library in question was not important enough to keep so we got rid of it. If we needed to keep it however, we could have tried to defer its loading or wait for some internal hook that says \"it's ok for non-critical elements to load now\". Before you add that latest and greatest Javascript library or add another request to your app, remember that asynchronous does not mean fast. Take the time to understand the performance costs of adding more requests to your page.", "date": "2014-12-09"},
{"website": "Hubspot", "title": "How HubSpot got hooked on Jasmine", "author": ["Anthony Roldan (He/Him)"], "link": "https://product.hubspot.com/blog/why-hubspot-tests-with-jasmine-and-you-should-too", "abstract": "If you had told me ten years ago that I would be writing Javascript professionally in 2013, I would not have believed you. Building things in Javascript has completely changed in the last few years. Remember writing code like this and thinking it was the coolest thing you could do with your website? // THIS IS GONNA BE SO SWEET FOLKS\nfunction initMouseovers()\n{\n    var nav = document.getElementById('mouseovers');\n    var imgs = nav.getElementsByTagName('img');\n    for (var i=0;i Thankfully, those days are long gone. Still, since JavaScript is such a flexible language, it's easy to start build spaghetti code that's a nightmare to maintain even if you are using the latest frameworks. At HubSpot, we try hard to write our front-end code with the following mantra: Good JavaScript code looks like good any code Long gone are the days where a front-end hack that \"just works\" is good enough. The code we're writing on the front end should be just as robust and clean as the code that powers our backend jobs. That is to say, it should: be DRY have clear abstraction boundaries have clearly labeled methods ...and be testable Which brings me to our testing environment of choice for JavaScript: Using Jasmine with JavaScript for Testing Here's what a Jasmine test looks like: describe 'a cow', ->\n    it 'moos', ->\n        cow = new Cow expect(cow.sound).toEqual('moo') Running the test looks like this: Jasmine is meant to make testing easy like that. It provides a suite of matchers like .toBeDefined and .not.toMatch() to make your tests read as much like English as possible. Check out their excellent documentation for some examples. For more complex mocking capabilities (like we use to test AJAX requests without relying on actual calls to an externa API), check out Sinon . The HubSpot Flow We've integrated Jasmine into our core JavaScript development flow, so our developers can run their tests using the same tool they use to resolve their static dependencies, like this: hs-static jasmine --headless\n\nStarting jasmine tests.\n\nFinished\n-----------------\n1 spec, 0 failures in 0.005s.\n\nConsoleReporter finished The tests are run headlessly with PhantomJS on our build boxes, so for the first time it's now possible for us front-end people to break the build if we check in code that doesn't pass tests. Woo hoo! Transitioning to tests One huge hurdle in starting to build tests for an existing project is to figure out where to begin. Writing tests for things that \"already work\" is tedious and often brittle, especially if the code wasn't written with testability in mind. So how are we introducing isolated tests to a huge existing codebase? Well, we start with what's easiest. Pure Functions This is the easiest kind of code to test in isolation: pure functions which have no side effects and no IO. For example: UserObject --> validate() --> true/false\n\nHTML string --> strip() --> plain text string\n\ndeeply-nested list --> flatten() --> flat copy of list Both new and existing code which fits this description will be a snap to test in Jasmine. Your first goal is to test this kind of code only. Start with new stuff, and then add in tests to older code as it breaks. For a great example of this kind of test, have a look at the specs for the Humanize library we recently open sourced. Functions with one side-effect These kinds of tests are a bit trickier, and we recommend not trying them until you have experience writing tests with pure functions. The side-effect is usually a state change which you don't want to happen when running the test. For example: UserObject --> inject() --> boolean\n\n                        --> side effect from jQuery.append()\n\n\n\nTextDocument --> save() --> updated TextDocument\n\n                        --> side effect from jQuery.ajax() Testing this kind of code requires a relatively straightforward invocation of a stub or mock. In both of these cases, you'll want to mock out jQuery functions. Complex Code Now that you know what it's like to test simple code, you can start simplifying all of your code by writing isolated tests for everything. At this point you will know to think twice when you start writing a test which: Requires more than three mocks Has to check the DOM for changes Is too long Code that's easy for a test suite to understand will be easy for a human to understand. Can't rewrite a particular piece of code? Then isolated tests aren't a good idea. #JFTI Unit testing is one of many software development best practices which are just now making a real appearance in JavaScript development. The transition to building tests (or moving to a TDD flow) can be bumpy, but it improves the structure of your code, provides \"free\" documentation for other developers who use your code, and removes that element of fear you feel when others are depending on your code and it's time to refactor. So get in there and test your code!", "date": "2013-02-08"},
{"website": "Hubspot", "title": "Name Dropping: Renee Reid, Staff UX Design Researcher, LinkedIn", "author": ["Francesca McCaffrey (She/Her)"], "link": "https://product.hubspot.com/blog/name-dropping-renee-reid-staff-ux-design-researcher-linkedin", "abstract": "Name Dropping is a Q&A series that aims to elevate the stories of women and nonbinary people leading in the tech space. The idea came from Angela DeFranco, a VP of Product at HubSpot, who said one way to be better allies is to name drop more women and nonbinary people in discussions of achievement, inspiration, and disruptors in tech, instead of referencing, time and again, the same set of (often male) leaders. This edition of Name Dropping features Renee Reid , Staff UX Design Researcher at LinkedIn . When did you realize you loved design? I’d have to take a journey back to my childhood. I really think it started when I was a ballerina. Even though it was costume design, and not necessarily web design, I was just so fascinated with my tutus and the colors. There was something about the sequins and the way that they moved around with the tutu. And I remember sitting with my costumes, constantly looking at the design, and just remembering how they made me feel. And then, throughout my childhood, I was in after-school gifted arts programs for drawing and creating things. So I definitely had an affinity for wanting to create things. Fast forward to my career, and I was in another position and started to tinker with HTML and CSS. And that’s when I realized that creativity can come out in this digital form. That’s when I really started to lean into this idea of creating and designing experiences, that we’re not just about the look and feel of a site, but how to make people do things to make them more productive, or get them to what they need to do and who they need to be. When I look back, it’s basically a partial awakening of something that I’d loved in my childhood that just took form finally as an adult in my career. You’re a Staff UX Design Researcher at LinkedIn. What are some of the most exciting challenges your team is working on right now? What’s great about LinkedIn is that, at its core, it’s about creating economic opportunity for the global workforce. This is something that is already embedded in our day-to-day, and given the present global situation and the pandemic, it’s really elevated what we do as a company. We’re really trying to help connect people with economic opportunity now more than ever, where there are so many people who have been displaced or who need new opportunities. We are elevating the things that we’ve already been doing. In terms of UX, specifically, with the research itself, where we’d usually be doing contextual, ethnographic, or pop-up studies where you’re meeting with members face- to-face, that has definitely changed. And we no longer do in person studies. We’ve had to sharpen our toolkit and conduct research in different qualitative and quantitative ways. We’ve also had to adjust how we do some of our research. Want more from Renee? Hear her thoughts on combatting microagressions in a virtual world on the latest episode of our podcast Culture Happens . Accessibility is such an important part of UX. What would you say to other UX professionals who are looking to make their products more accessible? One of the main things I always call out is that accessibility has to be at the foundation of the process and not an afterthought. This is not something that you can slap on afterward. Some people may argue that considering it at any point of the process is better than nothing at all. And that’s of course true, but I’m a firm believer that at the inception of the idea or problem or solution, accessibility has to be top of mind. And then also with accessibility, there has to be this even broader understanding of inclusive design as a whole. Inclusive design broadens the understanding of groups of people that are not being included in an experience ⁠ — demographics and groups of people that are being overlooked and excluded for various reasons, for example, socioeconomic disadvantages, different tech access, and temporary or permanent disabilities. I think it’s important from academia, all the way to industry, to start at the foundation of where accessibility and inclusive design happen and should happen⁠ — at the design-thinking level all the way through product development. This is hard work. And necessary work. But it has been an established field for years. There are people who have been doing this work for decades and for a long time experts have been expanding this field. We just need to do our due diligence to make sure that we are tapping into these experts who have laid the foundation and leverage their knowledge of accessibility while also learning and implementing better more inclusive design. I think more companies, more organizations are really realizing the importance of both and starting to take a stance on that. How do you stay connected to user and customer feedback? I’m the type of researcher who always keeps their ear to the streets. It’s one of those things that I can’t turn off. I keep up a rhythm of engagement where I may not know when I may need this particular person or archetype with this particular background, but because I’ve stayed engaged with them in some aspect, I can always reach out to them later on to make them part of the research. There’s this saying, “Always be learning.” As a researcher, it really is just that ⁠ — I’m just always learning and listening. I don’t wait to start a research study to then start engaging. It’s a constant cycle of just being aware of communities and spaces that you can always tap into and learn from. I call it “Constant Curiosity.” When you think about the best designers and researchers you’ve worked with, what characteristics did they embody? I’ve been very fortunate to have worked with some incredible designers and researchers over the span of my career. Top of the line. People who have inspired me to be better in my craft, and my day-to-day work. I think one of the consistent traits of both researchers and designers is this authenticity in really creating the best and most optimal experiences that are about exploring the impossible or exploring these big ideas and concepts that take us to a different level. Those designers and researchers don’t box themselves in. They’re able to think outside the box, holistically, and think broader and deeper ⁠ — longitudinally. I just love it when people think like that. Systems thinking is so important, seeing and understanding the whole picture. It’s exciting. They’re into the tactical things of pixels and buttons and polishes, which are important. But they’re also strategic, system-level thinkers. They ask, what does this experience look like for the user, not just in a single feature but across an ecosystem. How does an experience and design look today, and more importantly, what will it look like tomorrow? What could this experience evolve into a year from now? Those are the types of visionary UX practitioners whom I love to work with. You currently serve on two boards, Opportunity Junction and Inneract Project . What would you say to others who might be interested in joining a board? One thing you definitely need to figure out through your research beforehand is what the time commitment looks like. You also want to know what the mission and value the organization is bringing into the community and the world is, and if it aligns with yours. That was something that was really important to me in terms of working with organizations. What I believe in and also was passionate about was aligned with Opportunity Junction and their mission to help people in underserved communities who need job and career re-skilling. The training programs and education and job placement assistance they provide help put individuals on a path to create a stronger economic future for themselves. The other board I am on, Inneract Project, is focused on educating and bringing design to members of underserved communities at an early age, as well as supporting and advocating for the underserved design community through different programs. So two different organizations, but two passions of mine that I believe in and want to devote time to. If you’re researching boards for yourself, especially nonprofits, think about: What are your beliefs? What are you passionate about? What do you want to give back to, and what is something that you can speak very authentically and passionately about when people ask you what you do? Because a lot of these nonprofit organizations need additional resources: time, talent, gifts, all those things. And you will have to be that spokesperson to be able to get people excited about your organization. It’s not a hobby ⁠ — it’s something that is important. And it’s also been really great for me to be able to do some things through these boards that I don’t have a chance to do in my day job. Depending on how boards are set up, there are different committees. There’s a financial committee, and through that I’m able to get really involved in things like P&Ls, and really get a sense of what the financials of a nonprofit look like. Having those skill sets is important. So, if you’re thinking about joining a board, think about what you want to get out of it, too, not just what you want to give to the board. And especially during this time, I would be very explicit about looking into who’s on the board. As a Black woman, I was very selective about, what does this board look like? And what’s the representation on it? And what does this organization believe in in terms of representation? All of that is important. Will you be the first, do you want to be the first and only? How will you change that? Take those facts into consideration when you’re joining a board. On your LinkedIn page, in between your many project management and UX positions, you list experience in the restaurant industry, writing, “I’m listing this experience to show others the path to UX wasn’t a straight line and I even leverage skills I obtained as a hostess and waitress today, as a UX researcher.” What advice do you have for people looking to break into the tech industry with non-traditional tech backgrounds? I thought it was really important to let people know that this journey was filled with twists and turns and ups and downs. It was not a linear path. And that’s something that I’ve embraced. I use this experience as part of my differentiator in the tech space ⁠ — it’s actually a value-add. It makes me unique. One of the things that people will try to do early in their careers, and I did, too, is to create similar patterns. Saying, I want to go to a specific school, I want to set out on a certain career path because I need to get to a certain place. But when I really started to lean into my own journey and accept and own my journey, it just opened up many doors, and it freed me from trying to fit in a box. And these skills, they really do accumulate. For part of my career, I talked to people about pivoting into the tech industry. A lot of people think when you pivot, you have to drop everything that you’ve learned in your past and just acquire all this new knowledge. And I encourage a lot of the people that I mentor and speak with at conferences that pivoting doesn’t mean that you drop everything. Pivoting just means you turn, you take what you’ve learned, and you take it with you while learning more. You can apply skills that have been acquired in previous roles to this new space that you’re entering. My advice to people who are going into the tech space or even non-tech spaces is to be able to connect the dots to these similar attributes from your former position. Leverage that. You’re not starting from scratch, you’re starting from a certain point, and building on that. It makes a difference in how people approach their search. And what employers are looking for are those parallels, things you can build on as you acquire new skills. Putting the waitress job on my LinkedIn profile was important because I I learned so much being a waitress and a hostess. And this is even after getting a degree, this is not something I did during college. I was hit hard in the last recession. And like I say in my profile, I had to take my degree and walk into a restaurant and get a waitressing job. I set my ego and pride aside and was able to gain skill sets as a waitress that I can still use, even today as a researcher, in Silicon Valley. Who’s one woman or nonbinary person in tech you’d like to name drop and why? Without a doubt and without hesitation, Miss Kai Frazier . Kai Frasier is a founder and CEO of an XR/ AR/ VR company in ed tech called Kai XR , and what she is doing is incredible. She is creating AR classroom experiences for children and bringing them literally all over the world, to places where a lot of these students will probably never visit, never be able to see. I shouldn’t say never, but probably in their wildest dream they didn’t think they could see these places. And this is especially important now during this time where people are trying to reevaluate what education looks like. Kai started this company years ago, just out of her own vision of being an educator and wanting to bring a different type of curriculum to students, especially students in cities and underserved communities.She has developed VR field trips all over the world and kids get to see and experience things like the Sistine Chapel in Rome, the ancient Mayan temple in Chichén Itzá, even the Obamas’ portraits at the Smithsonian National Portrait Gallery. What’s also super cool is she has a VR experience that takes kids to UC Berkeley to learn about CRISPR with scientist Jennifer Doudna , who was recently named the 2020 Nobel Prize winner in Chemistry. Kai is such a visionary that after speaking with her, you just come out feeling like you can do anything. That’s what I enjoy about being in her presence and being her sister friend. You don’t see a lot of Black women in the AR and VR field. She is tackling a space that is usually dominated by men, but she’s going full speed with ambition and encouraging others. That, especially, is what inspires me. She deserves the spotlight. She’s doing some incredible work as a founder and entrepreneur and is just an incredible Black woman. She’s a light and an inspiration. What’s your favorite show you’re currently streaming? This is a good one because I don’t watch a lot of television, so when I do it needs to be really good. Just over the weekend I finished watching Cobra Kai and it was just a tip of the hat to a very specific time, a journey through my childhood. All the things of the 80s, and it was so nostalgic. I thought it was going to be cheesy, but it turned out really, really good. And I just finished the last season of Schitt’s Creek . What a fun show. I often break into a Moira accent when saying words, like beh beh (baby). Also, Netflix has brought back several incredible Black sitcoms from the early 2000’s and my favorite I have been watching has been Girlfriends , about four Black women who are friends navigating the ups and downs of life together. I definitely have an affinity for things that are nostalgic like Cobra Kai and Girlfriends. I see a trend emerging here. It’s definitely the researcher in me making the assessment. Know another woman or nonbinary person whose name we should drop? Tweet us at @HubSpotDev with ideas. This post originally appeared on Medium . Interested in working with people who care about thoughtful leadership? Check out our open positions and apply .", "date": "2020-11-13"},
{"website": "Hubspot", "title": "So you want to be a User Researcher? Advice from HubSpot’s UX Research Team", "author": ["Julie Fischer (She/Her)"], "link": "https://product.hubspot.com/blog/so-you-want-to-be-a-user-researcher-advice-from-hubspots-ux-research-team", "abstract": "UX Research seems to be one of those careers: everybody in it is a life-long learner. It’s a great fit for the naturally curious, and for people with a strong investigative bent. I’m lucky to be part of a UX research team at HubSpot whose members strive to collaborate, share lessons learned, and teach each other different ways of working so we can all grow. And as we all remember what it was like to be starting out in the field, we also love to mentor junior researchers as they learn and mature in their career. But I also frequently hear from people who are outside of the UX Research field and are wondering how to break into it. More often than not, these people are ready and willing to put in the time to study up (did I mention it’s an attractive career field for people who love to learn new things?) — it’s just that they’re not sure where to start. In this post, I’ll share the advice I usually give to folks who are on the path towards their first job in UX Research. That advice comes in two flavors: talking the talk, and walking the walk. Talking the Talk Like most careers, UX Research has its own unique vocabulary. If you’re an aspiring researcher, you can give yourself a leg up by learning some of the key terms from the field. Learning the lingo does more than just boost your own awareness and understanding of this type of work — it also lets you have more informed conversations with UX professionals when you’re networking or interviewing. Here’s a quick cheat sheet of useful talking points you’ll hear often in this line of work: UX Research Methods Methods are the processes or procedures a researcher applies to a particular problem space or research question. Becoming acquainted with the following methods is a great way to show you’re familiar with the day-to-day duties of a UX Researcher: Usability testing Interviewing Ethnography (or Field Studies) First-click Testing Card Sorts Tree Tests Diary Studies Remember: when you’re just starting out, it’s OK (in fact, it’s great ) to talk the talk before you’ve walked the walk. For instance, here at HubSpot we’re thrilled when a junior UX Research candidate can give us an example of a method they’ve never used, but that they’d like to try (and why). Even if you don’t have experience with all the methods in the list above, understanding what they are and when you might employ them means you’ll be ready to act when a research project comes your way. Types of UX Research UX Research can take many different forms based on the project’s goals and stage. You’ll often hear about three key types of research: Generative or Foundational Research Strategic Research Evaluative Research It’s worth reading up on these types of UX Research from other sources, but one way I like to explain these three stages is by pairing them to the kinds of research questions they answer. Generative research helps product teams answer questions that fall into the scope of “What should we build?” or “Who are we building for?” Strategic research is the type of research that tackles the the question “ How should we build it?” Evaluative research is more retroactive, looking back at a product that was built and released to users. Evaluative research asks “How well did we build it? How effectively did we solve for our users?” UX Research Stakeholders UX Research isn’t done in a vacuum. One of the most important parts of being a researcher is partnering with the rest of the folks who, in their own way, bring a product to life. They need your research expertise to improve their product, and these stakeholders are intimately affected by and have a stake in your research findings. The particular roles your stakeholders will have vary widely depending on your context as a researcher. But if you’re interested in working in a tech company, like we do at HubSpot, you can probably expect to work closely with folks with the following titles: Product Designers Product Managers Front-End Engineers Back-End Engineers Data analysts or Product Analysts As you learn about the field of UX Research, it can be just as valuable to network with people in the roles above as it is to network with current researchers. Discussing how they work and how they like to work with a UX Researcher can give you a valuable sense of what it’s like to fit in as a member of a product development team. Walking the Walk In most conversations I have with prospective UX Researchers, there comes a point when they ask: What can I do to get some real experience with UX Research? They want to know how to start walking the walk as well as talking the talk. It may seem daunting to get your first taste of user research before landing a UX Research role, and in fact, it’s not strictly required. UX Research is a career field without a single standard way of training. Many people are able to successfully land a first UX Research role through combinations of self-study, taking some classes, or making the case for how their skills and experiences are transferable to UX Research. But if you’re raring to go and want to learn about UX Research by doing, there are some simple ways to practice your core skills, and to show prospective employers that you’ve taken the initiative to do the work on your own. Here are three ways you can get some experience with relevant UX Research skills and methods before landing your first gig. Conduct a Heuristic Evaluation You might be ready to brush up on user research skills, but not quite ready to put the ‘user’ in user research by studying or observing other people using a product. And that’s okay — you can start by applying some systematic and analytical thinking to the assessment of a website or application by yourself. In a Heuristic Evaluation , a site or app is rigorously evaluated and rated against a particular set of guidelines or “heuristics.” One well known set of heuristics used in the field of usability and UX Research are Jakob Nielsen’s 10 Usability Heuristics . As an evaluator in this kind of project, you’ll systematically work through all components of an application and rate them against your chosen heuristics to arrive at a conclusion about how well the application meets those standards. Nielson is a well-known figure in the user research field and just familiarizing yourself with his work will make you a well-read prospective UX Research candidate. But regardless of the heuristics you might use, conducting an evaluation like this gets you thinking clearly and systematically about the design and functionality of a software product. In other words, it gets you thinking like a UX Researcher. User Test Your Favorite App Just because you don’t own a particular website or application doesn’t mean you can’t study how people interact with it. Have a favorite app or website? Or maybe one you don’t think is that great? Get a feeling for how it could be improved by asking some friends to be your users in a usability test of the site. Before you test, familiarize yourself with all the ins and outs of that site or software. Ask yourself what actions are most important to be able to take inside the application. Then, ask to observe your friends as they try to complete those tasks. That’s the structure of a very basic usability test. Bonus points for sending your findings in to the maker of the site or app to provide them with some usability feedback! Offer Your Services to a Local Business or University Business Club If you really want to act as a formal researcher for a project, and have the chance to partner with stakeholders, learn about a team’s research questions, and then tackle those questions as their researcher, there are many worthy projects out there for which you can volunteer your time. Many businesses don’t have the budget or time to employ a UX researcher, but any site, product or software application can benefit from user testing and study. Reach out to local small businesses and find out if they’d like to get a better understanding of how visitors are interacting with their website, and how well they can find the information they need. Or, contact your local university and connect with business, startup, or entrepreneurship clubs. You might find the founders of tomorrow’s next big startup waiting there, looking for someone to help them understand their prospective users or usability test their first product prototype. Be creative, and don’t be shy about letting people know that working together can be a learning experience for you and for them. I hope some of these tips are valuable to aspiring UX Researchers out there. Are there other tips you'd like to add to the list above? Let me know what you think in the comments, feel free to reach out with questions, and stay curious!", "date": "2018-11-16"},
{"website": "Hubspot", "title": "Zach Holman from Github delivers a HubSpot Tech Talk", "author": ["Samuel Siskind"], "link": "https://product.hubspot.com/blog/zach-holman-from-github-delivers-a-hubspot-tech-talk", "abstract": "Zach Holman recently came to HubSpot to give a Tech Talk on GitHub's culture. Check out the video.", "date": "2013-03-29"},
{"website": "Hubspot", "title": "Web Application Challenge Winners", "author": ["Timothy Downs"], "link": "https://product.hubspot.com/blog/bid/57632/web-application-challenge-winners", "abstract": "In November, the Development team here at HubSpot held a competition for Northeastern University students. We tasked them with creating a mash-up of Facebook and Flickr. Specifically, we asked them to use data from a user's Facebook profile as search criteria at Flickr and return pictures the user may find interesting. We had a bunch of great entries and after much deliberation, we were able to come up with 3 winners! Without further ado: First Place - iPad - The Flickr You - Lukasz Dmowski Second Place - iPod Touch - TL;DR - Nicholas Pettazzoni Third Place - Apple TV - Trufac - Christopher Carr Thanks again to everyone that entered! Stay tuned for future programming challenges!", "date": "2011-01-05"},
{"website": "Hubspot", "title": "Your Designers Are Not Artists", "author": ["Jonathan Kim"], "link": "https://product.hubspot.com/blog/your-designers-are-not-artists", "abstract": "The following is an excerpt from a blog post by Keith Frankel ( @thekeithf ). You can read the full article on the Inbound Marketing blog . Design is first and foremost a job of solving problems. Designers see (or are tasked with responding to) a need. They must brainstorm how to best satisfy that need, create the solution, and then send the result out into the world for others to enjoy... Having said that, always keep in mind that the goal of design is, first and foremost, to support the function of your content by providing thoughtful solutions to your problems. In such a way, designers are ultimately responsible for improving the overall quality of a consumer’s experience with your content. Continue to the Inbound Marketing blog for the full story .", "date": "2013-05-23"},
{"website": "Hubspot", "title": "What's Your Commstack?", "author": ["Ernie Park"], "link": "https://product.hubspot.com/blog/whats-your-commstack", "abstract": "When developers are looking for work or evaluating companies, it’s common to ask, “ What’s your tech stack? ” Naturally, people like to stay in ecosystems of technologies or services they have experience with and enjoy. For devs, choices of programming language, PaaS provider, framework, libraries, and OS can make a significant impact on their day-to-day productivity and happiness. This is of course, not unique to developers and engineering stacks. Marketers may stick with their preferred choice of marketing automation tools, sales reps their CRM of choice, etc. However, as COVID has pushed many companies remote, I predict that an equally important question will become commonplace for all job seekers: “What’s your communication stack?” Or perhaps more catchily if it becomes a thing : “What’s your commstack?” Job seekers will increasingly see quality of communication tools as a signal for strong companies. Here are a few categories of communication tools I can think of with some examples of each: Email : GMail, Outlook, Superhuman Video Chat : Zoom, Teams, Meet Async Video : Loom, Jumpshare Chat : Slack, Teams, Jabber Wiki/Knowledge base : Confluence, Workplace, Notion Writing : Google Docs, Dropbox Paper, Notion, Roam Virtual Presence : Teamflow, Branch, Gather Communication tools are of course nothing new, but it will be very interesting to see how these categories evolve with the accelerant of the pandemic. Companies and individuals are being forced to adapt in real time which will lead to innovation and adaptation. I predict new categories will emerge altogether, and eventually we will see consolidation of many of these tools as they inevitably overlap and need to communicate (hah!) with each other. Change will happen relatively quickly as many of these tools don’t require full team adoption to be valuable. Loom is a great example of this where only one champion needs to be a creator and the viewers don’t need an account to consume the content. This could lead to strong bottom-up adoption and viral loops. For employers, I believe we will see increasing brand differentiation, publicity, and marketing based on communication stack and philosophy as a competitive advantage. The tools a company uses in their commstack will become a signal just as prominent as their choice of programming language. My current commstack is Superhuman, Zoom, Loom, Slack, Confluence, and the Google Suite. I strongly suspect when I look back on this post in just a year or two that list might look a bit different. What’s your current commstack? Let me know on Twitter @eipark . This post originally appeared on Ernie's blog . Interested in working at a place that's always leveling up both its commstack and its techstack? Check out our open positions and apply .", "date": "2021-02-11"},
{"website": "Hubspot", "title": "Product Breakfast Recap: How Product Managers Build Trust with Engineers", "author": ["Anna Perko"], "link": "https://product.hubspot.com/blog/product-breakfast-recap-how-product-managers-build-trust-with-engineers", "abstract": "Each month, a group of Boston’s brightest product minds gathers over coffee and pastries to chat about the world of product management. For attendees, it’s not only a welcomed break from the monotonous beer-and-pizza-and-a-panel-discussion meetups, it's an invaluable resource for ideas, advice and mentorship. We had the pleasure of hosting the group’s latest gathering here in HubSpot’s Cambridge office. Product Breakfast usually kicks off with an anecdote or question posed to the group on topics ranging from how to hire a good product manager, to how to get good feedback on your product. The format is casual and everyone participates, newbies and seasoned pros alike. I’m always impressed how everyone just dives in to these interesting questions, sharing advice and stories from their own experience. One of the most valuable parts of these gatherings is that the group includes product professionals from companies of varying size and stage, which creates the opportunity for some serious knowledge sharing. As a PM with a few years under my belt, I find it fascinating and inspiring to hear from folks who’ve had long and successful careers in product. The focus of conversation for the April Product Breakfast centered on how a PM establishes rapport with engineering teams. How can PMs set themselves up for success with an engineering team? What communication styles make for great team cohesion? This is something I’ve thought a lot about as I’ve been diving into my new role with the HubSpot product team, but I wasn’t surprised to hear that this topic is top of mind even for seasoned professionals. Whether your company has been around for 10 years or 10 months, has 2 employees or 2000, culture and communication are important. Here at HubSpot, we know that a truly excellent product team culture hinges on the team’s ability to have full ownership of the product and process. We organize our product team into small autonomous teams consisting of engineers, a designer and a PM, each of which own their respective part of the larger product. A product manager at HubSpot “owns the problem” and helps guide the team of engineers and designers that build solutions. This setup works for us because managers and product leaders put a lot of trust in their teams, a theme that came up a bunch during our discussion. Rose of Invaluable pointed out that a PM has to advocate for her engineering team in order to build trust - be transparent about the vision of the product, show a real business case for what’s being built, and protect the team from unfocused distractions of a feature backlog. Liz of Constant Contact agreed, and explained how she includes her teams on customer calls so that engineers can listen in and hear feedback directly from customers. We all shared this notion that stories from real users are a powerful tool to rally teams around a product vision. But don’t some of these approaches have potential to get pretty distracting for engineers? Maybe, but that’s an important part of the product manager’s role on the team - to keep the team focused on the goal, the vision for the product you’re building. HubSpot’s own Jeremy Crane summarized the morning’s main takeaway when he likened a PM’s role to being a skipper on a sailing rig. It's our job to steer the crew in the right direction. I hear Jeremy's writing a post on this so I'll let him set sail on how to do that. Stay tuned. Thanks to Boston Product for letting us host, and to all the attendees. Check out what else @BosProduct is up to, and hope to see you at the next breakfast!", "date": "2015-05-13"},
{"website": "Hubspot", "title": "Microcopy: The Voice of your Product", "author": ["Elizabeth Dunn (She/Her)"], "link": "https://product.hubspot.com/blog/microcopy-the-voice-of-your-product", "abstract": "Microcopy can make or break your product's user experience. Good microcopy goes beyond just telling your users what they need to do to make your product work -- it engages their emotions, generates trust, deepens loyalty, develops a sense of agency and empowerment, and creates an unshakeable bond between user and product. Done poorly, microcopy can make your user experience go very wrong, very fast. And the toughest aspect of microcopy is often just finding the proper voice for your product, then the applying the appropriate tone for that voice in any given context. Find out how the HubSpot product team approaches voice and tone -- and microcopy in general -- in this Tech Talk from January, 2015. Beth Dunn is chief writer and editor on the HubSpot User Experience team. She writes about microcopy, running, and life in a small house on Cape Cod at bethdunn.com .", "date": "2015-02-05"},
{"website": "Hubspot", "title": "Deep contextual multi-armed bandits: Deep learning for smarter A/B testing on autopilot", "author": ["Mark Collier"], "link": "https://product.hubspot.com/blog/deep-contextual-multi-armed-bandits-deep-learning-for-smarter-a/b-testing-on-autopilot", "abstract": "The machine learning team at HubSpot recently published a paper which we presented at the Uncertainty in Deep Learning Workshop at the Uncertainty in Artificial Intelligence conference. In this paper, we outlined how we’re using machine learning to help our customers do better A/B testing in HubSpot. This technology is now available in HubSpot’s Lead Flows tool, and we’ll soon roll it out to many other areas of the product. In this post, we’ll explain how the technology works and how it will help our users accomplish A/B testing with less effort and higher returns. The Problem with A/B Testing A/B testing is a widely used marketing technique. For example, a marketer might have a few different ideas for what text to display in an advertisement. Instead of blindly guessing, she instead decides to test the versions and see which one performs best. For a period of time, users are randomly shown the different versions of the ad. Once the marketer sees which ad has received the most clicks, she can choose to use that version from now on. HubSpot’s product has offered tools to do traditional A/B testing for quite some time. But there are two big problems with A/B testing, problems that make A/B testing difficult to use in practice and leads to money left on the table: The A/B test user has to decide which version of the advertisement is best after a period of time. But that’s not always so easy — often it’s hard to tell whether the difference between the variations is due to randomness or because one variation is truly better than the other. HubSpot’s Machine Learning team has an effective solution to this problem: Multi-armed Bandits ( MAB ). MABs allow you to run a test continuously, eventually converging to the correct version automatically. This allows our users to set up an A/B and let HubSpot do the rest. Even if most users prefer version A to version B, a smaller (but important) segment might actually prefer version B. For example, suppose that 70% of your traffic is from the United States and 30% is from outside of it. Maybe customers in the US prefer version A, but international customers prefer version B. If you happen to decide to use version A because it performed best overall, you’d be leaving money on the table from your international audience. Our work addresses both of these problems: We would like for our users to be able to set and forget their A/B testing. We’d like to better segment our users’ customers. In the example above, we’d want to show version A to customers in the US and version B to international customers. But you can imagine many more complicated rules: maybe people between the ages of 23 and 30 in the US that use Chrome prefer version B, too. So in order to be truly effective, HubSpot should learn the different subsets that exist when A/B testing. This is where the really cool stuff happens! Set-and-Forget A/B Testing There’s a large subfield of research on MABs. But one simple approach to MABs that works well in practice is called Thompson sampling. Say you run an A/B test for 1,000 iterations, and both variations get sent to 500 users each. 105 click on variant A, and 100 click on variant B. In this case, A seems better, but not by much. Maybe A happened to be sent to more users who were likely to click on it — or maybe A genuinely is better. If we think A is genuinely better, we should exploit that knowledge by showing A to more and more users. But if there’s a still chance that B is better, we want to learn more about B’s performance. So, we should still show B sometimes too. This is the classic exploration vs. exploitation trade-off . We want to make use of what we know about the good variants and also explore variants we still aren’t sure about. We can use probability theory to quantify our uncertainty about the likelihood to click of each variant. In particular we construct probability distributions p(click | show A) and p(click | show B). In order to trade-off between exploration and exploitation using Thompson sampling, each time we’re asked which variant to show, we take a single sample from each probability distribution and show the one with the highest probability of clicking. If we are very confident one variant is clearly better, then that variant will almost always be shown. If our probability distributions are flat (or uncertain), we will show both variants in similar proportions. Below, we simulate data from an A/B test in which the true p(click | show A) = 0.6 and p(click | show B) = 0.4, meaning that A is clearly the better variant. In the below animation, we can see how the estimated/learned probability distribution changes over time and becomes more certain that A is better. We can also see the regret curve for this data. Regret measures the reward we missed out on from not choosing the optimal variant at each decision point. We know A is better, so regret measures the number of clicks we get relative to always choosing A. We can see that early on, the regret shoots up as we show B relatively often. We are plotting the cumulative regret, so the regret adds up over the course of the experiment. As the experiment continues, the estimated p(click | show A) and p(click | show B) become more peaked and separated and we converge on always showing A — so the regret curve flattens out. This is a very easy example for illustration purposes, where the two variants have very different probabilities of being clicked. Here, the regret curve becomes completely flat much more quickly than we’d expect to see in real-world applications. So we can use Thompson sampling to let users set and forget their A/B tests, but in the example above, we still converge on showing only one variant. But when we want to also show variant B to the subset of users who like that best? While Thompson sampling has been around since 1933 , this problem creates an opportunity to infuse some deep learning into the process. Deep Contextual MAB When we want to learn if a subset of the our users prefers A to B (or vice versa), we can assume there are some features which we’ll denote x that describe the user (such as their country, browser, etc). This means we’d like to learn a function p(click | A, x ) and p(click | B, x ), or more simply, we want to take into account the user’s features when deciding which variant to show. An excellent way to model these functions and learn complex “rules” such as if its the weekend, show option A to users from Canada who are using Chrome is by using neural networks. Neural networks allow learning of complex non-linear functions from data without having to encode complex rules. We simply train a neural network to predict whether a user will click, given the features which describe the user ( x ) and the variant A/B as input. Neural networks typically output the expectation of this distribution E[p(click | A, x )]. If we simply choose to show A or B based on the expectation, then we might exploit our uncertain knowledge too early. We want to be able to sample from p(click | A, x ) in order to do Thompson sampling so we can trade off between exploration and exploitation. It turns out that to compute p(click | A, x ) exactly, or even to sample from the distribution, is intractable (not possible) for deep neural networks. Over the years there have been many attempts to figure out an approximation to this distribution, but these methods typically didn’t scale to large datasets and/or large neural networks. Fortunately, there’s recently been a great deal of research in “Bayesian deep learning” which has delivered more scalable approximations to this distribution. In particular, a 2015 paper showed that dropout — a very simple and widely used technique to regularize neural networks by randomly shutting off neurons in the neural network — was, in fact, an approximate Bayesian method. Usually, practitioners only used dropout when training the neural network, turning it off when they wanted to make predictions. This paper showed that if you leave dropout on during prediction, you’re getting samples from an approximate posterior distribution — exactly what we need in order to do Thompson sampling. In addition, a 2017 paper showed that we could learn the dropout probabilities, or the probability of shutting off a neuron. This is called concrete dropout. The cost function to learn the dropout probabilities encourages the network to both be able to predict the data well and give good uncertainty estimates. So to use neural networks to model p(click | A, x ), while simultaneously being able to do Thompson sampling, we simply train a neural network with concrete dropout and leave dropout on at prediction time. When a new user comes in, we input (A, x ) and (B, x ) into the neural network once, then show the variant that has a higher predicted probability of being clicked on. By doing this, you get the power of neural networks combined with Thompson sampling. MAB problems where you are also given features about the user ( x ) are known as contextual MABs, and are widely studied in research literature. But typically, in order to do principled exploration, researchers were forced to use simple linear functions to model the user’s features ( x ). When practitioners used neural networks for contextual MAB problems, they often used epsilon-greedy strategies to do exploration — but these only explore a random fraction of the time, and thus can easily under- or over-explore. We at HubSpot know that to learn a good model of how all these features interact with each other, you need powerful non-linear models such as neural networks, which ruled out linear models. And, to maximise our returns, exploration needs to be calibrated carefully, which ruled out epsilon-greedy exploration. Our work combines the simplicity of Thompson sampling with recent advances in Bayesian deep learning so we can use neural networks to model the joint feature — variant space (X, A) — while still getting principled exploration. Below is a figure from our paper which shows that our approach using concrete dropout outperforms standard dropout and epsilon-greedy exploration. Not plotted is standard Thompson sampling with no neural network (non-contextual MAB), as this approach incurs cumulative regret of 24,048 compared to the worst-performing method on the figure, which has cumulative regret of 1,718. Examples where we can simulate a stream of data are ideal, because we can run experiments repeatedly and compare approaches. But in order to make sure our approach is effective in the wild, we also wanted to evaluate it using real, production data. Currently, DCMAB can be used by our Enterprise customers with our Lead Flows tool . The variants involve four different ways to load a pop-up call-to-action onto the screen. Below, we can see the conversion rate over time for one customer who used DCMAB for a Lead Flow. We see that early in the experiment, during the heavy exploration phase, the conversion rate was in the range of 1.0-1.5%. But as the model learned, the average conversion rate climbed and converged to 1.7%. This means our customer got a 0.2-0.7% increased conversion rate by using DCMAB. Below, we can see an example from another user, whose initial conversion rate was approximately 0.02%. By the end of the time period, that conversion rate more than quadrupled to 0.09%. Neat! But what if I don’t know how to train a neural network? Internally at HubSpot, we have an AutoML tool which automatically builds machine learning models with no human involvement — despite being told nothing about the problem it’s trying to solve. So when you want to use deep contextual multi-armed bandits rather than A/B testing, all the machine learning is automatically taken care of. You get a custom machine learning model trained just on data from your website. The model is periodically retrained as more data rolls in, getting better over time. You don’t have to define the features to use ( x ), just specify the variants as you would with normal A/B testing. Through all this work, we now have a fully automatic alternative to A/B testing which is 1) set-and-forget and 2) can learn that subsets of your users may prefer certain variants that standard A/B testing would discard, maximizing the returns from variant testing with no additional effort. Presently, this tool is offered on a small scale to our Enterprise customers when they use the Lead Flows tool, and we are currently working on rolling out deep contextual multi-armed bandit variant testing to many other areas of the product. If you’d like to learn more about our approach, we’d love to hear from you. Feel free to leave a message in the comments.", "date": "2018-11-26"},
{"website": "Hubspot", "title": "Building a Team of Growth: What I’ve Learned from Failure, Experimentation & Inclusion", "author": ["Chris Miller (He/Him)"], "link": "https://product.hubspot.com/blog/building-a-team-of-growth", "abstract": "When I started my career I couldn’t have told you what growth teams did, let alone imagine working on one of them. But as a founding member of HubSpot’s Growth team I’ve helped build and shape it from the ground up, and now I’m obsessed with helping customers solve problems by finding value in our tools with our growth strategies and data driven experimentation. Here at HubSpot our Growth team helps people discover the value of the HubSpot platform, no matter what their software budget is. No matter who or where you are, it’s our job to connect our solutions to your business problems so you can become a better business owner, team member, marketer, sales rep, etc. In fact in our early days it was our deep knowledge of consumer behavior that influenced us to form the team--we noticed buyers had evolved the way they bought software. They wanted to discover solutions on their own, on their own clock instead of going through the process of talking to a sales rep or asking for a trial. And if they made the decision to buy, they didn’t want to have to deal with negotiating contract terms or signing paperwork. So HubSpot created a free version of our platform and started using data-driven experimentation to tell us where and when to connect customers to features “touchlessly” along their journey. Since 2017 I’ve seen our team evolve into a machine that’s figured out how to innovate on some of the company’s highest impact work. It’s one thing to have a growth mindset as an individual contributor, but it’s another thing for an entire group of growth practitioners to embody it. Here are some of the things I’ve learned in our journey to build a high functioning, innovative growth machine at HubSpot. Our principles drive our success Since the beginning, our team has strived to solve problems for our customers and our business at the same time. One of the ways we keep a customer-first lens as our north star is with simple principles the team developed together. Our users are people, not metrics or a stage in our funnel. Real growth comes from solving user problems, not tricks or “growth hacks.” The best way to solve user problems is by understanding our users’ behavior and motivations. To truly understand users we need clear learnings and clean data. Our principles aren’t just words on a page. They’re how we’ve aligned our mission with the people we’re working for--our customers. They’re the core to defining what we stand for as a growth team. Some people think designing for business growth and a great customer experience is mutually exclusive--you can have one or the other. But we believe the key to running a successful growth team is understanding people and designing experiences that add value, not strategize ways to outsmart them. As we’ve grown together these principles are the connective tissue we use to stay aligned. When we were a new team of five we didn’t need them, or they were unspoken. Soon we grew to three teams across two offices owning a much greater mission and it became challenging to communicate our values at scale. Now we’re seven teams responsible for a substantial portion of annual revenue growth and these are as critical to our operating system as tools like Amplitude and our automated tool for A/B testing copy. (We’ll talk more about the practical application of our principles in an upcoming post. Stay tuned!) Fail fast, fail often At HubSpot, we encourage experimentation and embrace failure. As our Culture Code says, “Remarkable outcomes are rarely the product of moderate risk.” That’s why we solve customer problems best when we allow ourselves to explore and fail. Even a failed experiment points to new opportunities or possibilities for solving a problem we hadn’t thought of. As a growth team at best 30% of your experiments are going to be successful. (And for other growth folks out there if your hit rate is higher you aren’t asking the right questions.) To give you a sense, in 2018 we ran about 150 experiments but implemented just 30 of them and brought in 1/3 of new business revenue. We’ve learned through innovation and implementation that the only time an experiment can be called a failure is if we didn't learn anything meaningful from it. That’s why our mantra is “fail fast, fail often,” because what we learn from a failed experiment is more important than the hypothesis itself. As a team we value curiosity and exploration over perfect outcomes. Traditional product development teams try to prevent failed launches at all costs, but for our team failure is often an outcome that leads us to our biggest success. Over time I’ve realized people who thrive in environments where they’re constantly proven wrong do exceptionally well on our team. As we’ve built the team we’ve realized trust is critical to our success. Almost everything we do is experiment driven so every day we share ideas and brainstorm new hypotheses. We’ve realized we’re more engaged if we feel safe and listened to, so we’ve worked to create safe spaces for creativity. We collect and analyze a ton of data that can be interpreted many ways so it’s important to feel free to challenge each other. A diverse team wins Our mission as a company is to help millions of organizations grow better. In order to do that, we need to grow better as a company, too. Our CEO often says he wants to build a company his kids and grandkids will be proud of, and that means creating a company diverse in experience, ethnicity, gender, background, and thought. We believe in creating an environment of psychological safety where employees can bring their whole selves to work every day because we want to truly walk the walk in creating a culture of belonging. Because not only are diverse teams more successful, they help us grow better as a company. We started the team a few years ago and focused our growth practice at our headquarters in Cambridge. When the business started investing more in us we intentionally expanded to our Dublin office to leverage unique perspectives and experiences. Our work touches customers everywhere--we have buyers signing up for HubSpot from 130 countries and in 6 supported languages. Since our team is exceptionally data-driven we’ve watched the composition of our customers shift steadily to a more global market. We know the future growth of the company is being driven by customers in every market, and to support them we feel it’s important to represent their diversity on our team. Join our growing team It’s been remarkable being a part of this team, watching it transform the way people find value in HubSpot and help small businesses flourish. But looking back isn’t what I’m most excited about; it’s looking ahead to the opportunity in front of us. Because as HubSpot continues to grow around the world, we’re growing too. We’re growing the Growth team so we can help millions of organizations grow better. Want to grow with us? Check out our openings to learn more. The HubSpot growth team is growing! Do you love solving tough problems and helping businesses grow? Are you a designer, researcher, product manager, or engineer? Come join this incredible team. Learn more about what #HubSpotLife is all about by following us on Instagram and Twitter .", "date": "2019-05-29"},
{"website": "Hubspot", "title": "How to Learn Complex Things Quickly: A Guide", "author": ["Chris Baldauf"], "link": "https://product.hubspot.com/blog/how-to-learn-complex-things-quickly", "abstract": "In my 20+ years as a software engineer, I’ve constantly been asked or expected to learn complex things. In his book Deep Work , when talking about the knowledge economy, author Cal Newport writes, “If you can’t learn, you can’t thrive.” New languages and platforms are launched, projects get new requirements, libraries and frameworks release new versions ⁠— in software, the only constant is change. A friend who was recently starting a new role asked “Got any tips to help me learn this new landscape quickly?” When I sent him some very rough thoughts he said they were “gold” and encouraged me to publish them for the world to see ⁠— I hope others can find them even a little bit useful. Disclaimer ⁠— I’m a breadth first, experiential learner. I try stuff and when it doesn’t work, I try something else, moving on to the next step as soon as it ‘works.’ This helps me create an ever clearer mental model with each iteration. This works for me, but I recognize there are many learning styles, and it may not work for you wholesale. Define your goals Break whatever you’re trying to learn down into use cases. Start with bite sized chunks that take a few minutes and build on them incrementally. “Learning python” is too broad. Installing python, printing hello world, installing and using a dependency, reading from a file, etc. are more well-defined, and it’s easier to know when you’re done, therefore helping to reinforce progress. Consider how much you need to learn to accomplish each. Bucketing things into \"need to know more\" and \"skip the details for now\" can be helpful. For instance, I don't know how python dependency management works, but I can rely on it working and make progress without that knowledge. Start by just trying stuff . You might be scared that you’ll screw something up, but in my experience computers are pretty hard to break. Use the mental models that you already have to guess at how it might work. If it doesn’t, then you can respond to error messages. Take breaks . If you’re in the groove and cruising, by all means ⁠— keep in the flow. But if you’re finding that you’re losing steam, moving sideways, or retreading old ground, give your brain a rest. If you defined your goals in small increments, you should be able to walk away feeling like you made some progress and give your brain time to process what you’ve learned. Read the full manual (RTFM), but don’t try to internalize it all Get the gist . If you’re learning something with published documentation, read the intro, the first and last paragraph of each section/chapter, and the first sentence of every paragraph, along with any provided code samples. If you find yourself confused, back up a bit and go deeper as necessary. Heed the callouts . Callouts and tips can be really helpful. They’re often provided in spots where it’s easy to make mistakes. Create a ‘read later’ list . I’ll often find myself curious about how a related part of the system works, but unless it is something I need to know to accomplish the use case I’m focused on, I defer that. I keep a reading list in my todo app, but there are lots of solutions out there. Use ‘getting started’ guides .This is my exception to the “just skim it” rule. Getting started guides are usually aimed at folks just beginning their learning journey and are designed to give you just enough information to accomplish a single use case. Don’t skim them ⁠— read the whole thing and follow along with the provided examples. Check GitHub for boilerplate projects. There’s more than just docs . Videos, podcasts, and livestreams can each be a valuable way to convey information, if they exist. Experiment with different media and find what works for you. Work your way up to watching / listening at 2x speed, but slow down for the interesting parts. Learn to dig (a little bit) deeper So you’ve trusted your instinct and just started, but you immediately run into an obstacle. Maybe it is command not found , NullPointerException , or a 404 on a web page. How can you get more information out of the system? CLI help . Most Command Line Interfaces (CLIs) will return some content for help , --help , or -h . There might be clues about the arguments and their order that could be useful. Dive into the logs . Most systems will log some output, either to standard output on the console or somewhere on disk. Reading the logs can be like reading a story of what the system is trying to do. Crank up the verbosity . If you’ve read the logs and aren’t sure where things are going sideways, try increasing the verbosity of the output/logs. You can often find helpful clues and new areas to investigate that will help get you closer to the problem. Search for error messages. Others may have run into the same issue, and you might find a lead on a Q&A site, like Stack Overflow, discussion or support forums, or open issues in GitHub. Make sure you quote the error message and try removing parts that are specific to your use case vs more general. Read the Source Code . If you have access to the source code of the system, reading it can help you understand how the system expects to treat your use case. Don’t try to understand every line, but use class and method names as signals for the system’s nouns and verbs. For internal tools that don’t have good logging, docs, or help, this may be the only option. Not sure if the code is open source? Try searching for the library in your language’s package manager (npmjs.org for Node.js, pypy.org for python, etc) or try “GitHub {programming language} {package name}” in your favorite search engine. Tip : Give yourself a timebox to avoid turning your investigation into a never-ending spelunking excursion. Decrease the size of your timebox as you gain comfort with the system. If you’re brand new to something, give yourself a few hours. If you’ve been living in the system for months, dial that down to 15 minutes. Don’t be afraid to ask for help Do your homework first - chances are someone has run into this before, especially if you are brand new to this topic. All of the following are good resources for you while trying to find answers: Documentation (see RTFM) FAQs Community forums Chat history Search Make it easy for others to help by documenting the issue and some relevant context. What are you trying to accomplish? What behavior were you expecting, what did you observe? What have you tried? What’s your execution context? (OS, versions, plugins, etc) Here’s an (older) example from real life: https://github.com/Kong/kong/issues/1186 Reflect on the process Summarize and share what you’ve learned - that’s a good habit for all knowledge workers Where did you spend time that didn’t help you get closer to your goal? What would have made it easier for you to learn again? Docs clarifications? Interface changes? Can you fix them (internal or open source) or suggest changes to make it easier for future learners? Summary Learning is an iterative process. Start by defining your goals, and break them down into bite-sized chunks. Get some context by reading whatever docs are available, but don’t try to digest them in one bite. Don’t be scared to try to get more information out of the system. Ask for help when you’ve exhausted your budget, but be very clear about what you’re asking. Create feedback loops to improve your learning process and that of future learners. Now go and learn something new! Interested in working with a team that's just as invested in your learning and growth as you are? Check out our open positions and apply .", "date": "2021-04-08"},
{"website": "Hubspot", "title": "How We Started Treating Frontend Performance as a Feature", "author": ["Adam Markon (He/Him)"], "link": "https://product.hubspot.com/blog/treating-frontend-performance-as-a-feature", "abstract": "A little more than a year ago we realized that HubSpot’s application performance was impeding our users’ ability to complete basic tasks. A s a SaaS product that thousands of business across the globe rely on every day , this was un acceptable. For our CRM product , our core product offering which sees more than 50 million page views a week, a single page load could take upward of 6 seconds for our average user — in aggregate , our users were waiting more than 9 years for that single app to load every week. Since then, our efforts to improve performance have grown from just a few of us playing with code splitting and webpack settings in our free time to two dedicated frontend performance teams and organization-wide standards for creating performant applications. More than a year ago a few colleagues and I began this push for performance and I’m now a member of our CRM Frontend Performance team. Here I’ll cover some of the decisions we’ve made and tools we use on a daily basis to help accomplish the mission of making the HubSpot product as fast as possible. This is not a technical post on how to improve performance, but rather a guide to the decisions made and tools utilized to empower the technical work. Conscious Investment Like many engineering challenges, performance is a goal that is all but impossible to meet without dedicated resources. This is a lesson we unfortunately learned from experience. While a few of us spent several months attempting to improve the speed of the applications we owned and evangelize the importance of performance work to the rest of the organization, we were making slow, if any, progress over the first few months. After more investigation , we discovered this was a resourcing problem. Engineers were interested in performance - they were showing up in droves to technical presentations, asking good questions about performance, and engaging in team-wide discussions daily — but simply didn’t have the hours to devote to extensive application profiling. There were more urgent tasks at hand. Our solution was two-fold. First, we established a platform performance team. This team is responsible for building performance as a top-level citizen into our frontend stack, including everything from more robust synthetic testing solutions to empowering long-lived cross-application static asset caches. Once our platform team had their legs under them, we established a mirroring team on the application side in our CRM — the largest application in HubSpot. By giving full-time dedicated resources to one of the highest-visibility projects at HubSpot, we were able to create a sense of urgency across the organization. With these resources in place and a growing contingent of performance-focused engineers , it was time to get to work. Tracking the Right Thing Before we could start to think about our performance goals we needed to track our performance consistently. Out of the box solutions for monitoring proved to be unhelpful for modern applications, as they don’t understand the intricacies of single-page app frameworks like React. Instead of using browser events like DOMContentLoaded , which don’t know anything about the content in your application or your user's intent, HubSpot has created our own internal metric tracking system that marks pages as successful or failed based on the actual components on the page. The exact implementation has evolved over the years, from our original solution based on CSS selectors to our latest solution which tracks the rendering of “markers” based on React Context , but the core philosophy that page loads are based on the actual content of your app is unchanged. An application team chooses what “success” means based on their own business concerns, but each team places these markers with the same guideline that a page is only successful once a user has all of the information they need to do their job. Monitoring We’ve stood by a core principle in our journey to make HubSpot fast for all of our users: you can’t make fast what you don’t know is slow. While it’s easy to anecdotally say “this app feels slow” or “this interaction has some lag to it,” you have no way to know you’re making progress if you don’t have numbers to attribute to your changes. Similarly, you might not even know what to change without tracking some metrics and profiling your application. Your teams may find value in all or only a subset of the methods below, but it’s important to try all of them to understand what works for you. Each of these types of tracking will answer different questions about your application, and will be applicable at different stages in your journey to make an application performant. Synthetic Monitoring While we’ve found limited value in synthetic monitoring of our application for tracking day-over-day performance regressions, it’s been incredibly helpful for telling us how our performance is trending over time. By running performance tests on the same hardware, network connection, and user account every single test run, we’re able to isolate environment changes that might cause shifts in real user data. These tests run with a cold cache on a regular interval to give us an easy way to track our page load performance over time. A screenshot from SpeedCurve, HubSpot’s current synthetic monitoring solution -- As you can see, a synthetic testing environment, which is essentially just a nice UI around WebPageTest, lets us track performance over time using custom metrics that understand our app architecture. Any quality synthetic solution will even allow you to dig into the actual WebPageTest output so you can dig deeper into network calls, CPU performance, and more. You’ll also notice deploy markers on the chart, letting us pinpoint specific times in history when we made notable changes, to help correlate code changes to performance changes. Real User Monitoring (RUM) Synthetic testing is a great way to track isolated performance, but it doesn’t accurately simulate the hardware, software, or network conditions utilized by our users. RUM allows us to track how real users perceive our app, and the high sample size of real user data compared to a single synthetic run means a single user’s temporary network or device problems are smoothed out by the rest of our users’ data. NewRelic lets us chart our RUM numbers over time, comparing week-over-week to spot trends in our data. -- To accomplish this goal, we use the tracking libraries I described earlier to log success or failure times to NewRelic, our current data aggregation solution. We also track the load time of each specific marker, to allow engineers to track the load time of each particular component on the page. We also log lots of associated data with each page load, including device metrics around CPU and memory, browser version, OS version, asset cache hit rate, and more. This allows us to create really rich analysis around how we can better serve our users. Code-level A/B Testing So far we’ve seen two good strategies for tracking an overall application’s performance over time, but what if we are running an experiment and want to know how much a particular change will affect performance? This is where A/B tests come in very handy. We use the browser’s built-in Performance API to track when a particular task started and ended, combined with our internal feature flagging system (called Gates), and then log those timings to NewRelic. Every time we make a change that may affect performance in an unpredictable way , we’ve encouraged our engineers to run A/B tests behind our feature flagging system. Simply “ungate” some percentage of our customers to a change, track the performance data for a few hours, and then we’ll have an answer. This iterative testing strategy allows us to move very quickly, sometimes shipping 3 to 4 data-driven performance experiments in a single week. A custom NewRelic dashboard tracking a change’s impact on load performance. -- While we can run local profiles to measure these changes ourselves, we often find that our internal tests aren’t necessarily reflective of the impact changes will have in production. In a single case, we saw local improvements of nearly 750 milliseconds for a change that ended up having less than a 100 millisecond improvement on performance in production. RUM allows us to test these changes on customers, and because they’re behind feature flags we can revert back to the old changes instantly if we find an experiment has negative impacts. Goal Setting Once we had a system in place to track performance data, the next step to creating a delightfully fast experience for our customers was to actually define what “fast” means. While it seems like that may be as simple as choosing a target number, as we started to define these SLAs we realized there were lots of other variables we had to isolate. Do we want to measure international users or just start with users in the US? Should we be measuring background tabs? What constitutes a successful page load, and how do we know when a page is done loading? Isolate Inconsistent Variables When we first started measuring our applications’ performance, we ran into lots of problems with inconsistent measurements , both within a single application’s numbers as well as across applications. As mentioned above, variables like foreground versus background tabs created challenges in laying out a consistent set of performance guidelines. We chose to exclude any page visits that loaded in background tabs, as they’re heavily throttled by browsers and aren’t an accurate representation of our performance. We are also currently excluding international users from our SLAs, though we plan to change this in the future. While we don’t currently have international data centers outside of the US, once our backend supports multi-region replication we’ll likely start to include international data in our measurements as that data will become more meaningful, whereas today we’d be measuring our users’ distance from our data center. Set Aggressive Goals While the conventional wisdom suggests choosing smaller, easily attainable goals, we found that without aggressive performance requirements teams would not be as motivated to meet them; the farther away the goal the more motivated teams were to try and meet it. Additionally, we intend to continue to move these targets as more teams get into SLA. While these goals are very aggressive, especially for business applications of our size, we feel that providing a consumer-grade experience of a fast, responsive app is non-negotiable in building modern software. On the frontend we require that 75% of all page loads for an application finish in less than 2 seconds. Teams are taking a myriad of technical approaches to achieve this, from long-lived asset caches to code splitting, and more. On the backend, 75% of API requests must complete in less than 100 milliseconds. In the last year we’ve become keenly aware that frontend performance has a strong correlation with backend performance. Without a performant, properly architected backend there is no way for the frontend to be performant. Additionally, with our new efforts to treat external integrators on our platform as top-level users, API performance has never been more important. Results While the technical details will fill several future blog posts, we’ve been able to combine many strategies including caching expensive work, preventing excessive re-rendering of components, aggregating data fetching via GraphQL or purpose-built aggregator REST endpoints, and aggressive code splitting and JavaScript caching to drastically improve the performance of our applications. Since the start of this project, the number of user-facing apps within the SLA mentioned above has increased from about 5% to nearly 50%, and our apps that aren’t passing are still making notable progress. In one case, our CRM application mentioned earlier, we have seen our 75th percentile load times decrease from around 10 seconds to about 4.5 seconds, and th ose times are continuing to fall. Though we have a long way to go, our teams have made an impressive amount of progress in just one year while simultaneously managing to ship new products and provide value to our customers. We’re excited to see our engineers continue to provide investment in this area and discover new ways to provide fast, delightful experiences to our users.", "date": "2020-01-22"},
{"website": "Hubspot", "title": "What It Was Like Onboarding (and Embedding) Remotely at HubSpot", "author": ["Brian Barbosa (He/Him)"], "link": "https://product.hubspot.com/blog/onboarding-remotely-at-hubspot", "abstract": "Joining HubSpot last August was exciting, but a bit nerve-wracking. I was coming in as a new Director of Engineering, and I had never done an embed before (you can find great write-ups on HubSpot’s embedding process on our Product Blog, from first-hand accounts to the philosophy behind it ) and had never onboarded remotely before. Now six months later, I have onboarded remotely seven times with seven different teams and learned a bunch of little lessons along the way that have helped me navigate a new way of working. Zoom is... intimidating Other than immediate family, it’s been quite a while since I have been in the same physical room with pretty much anyone. Zoom has proven to be a great tool for keeping in touch professionally, but it comes with its own challenges . I found pretty quickly that my default (and the default of most others) was to treat Zoom meetings as formal affairs, only for set agendas and serious business. The problem is that unplanned conversations were lost. How am I going to know about your children? How am I going to make sure that you know Sour Cream and Cheddar is the best Ruffles flavor (great inside joke here, ask me if you want details)? How am I going to know the next thing I need to binge on Netflix? Finding time for unplanned conversations wasn’t happening, so I learned that we have to create them. For me, it helped to just tell people right up front “Hey, I'm new and trying to get to know people. I’d love to chat for 30 minutes, no real agenda.” A lot of times this ended up being about HubSpot, which was great, but it also gave me and my chat partner permission to deviate and have some more organic conversations. Which brings me to my very-related second lesson... Meeting people remotely takes a LOT more effort A few weeks into my HubSpot start, I realized that I wanted to meet more of my fellow HubSpotters and build deeper relationships with them just like I would in person. The team I had embedded on was incredibly welcoming, and I was thoroughly enjoying my time with them, but they were the only people I had met (outside of a few warm greetings on Slack). In order to combat this, I found a few things that helped. First, I set up a regular check-in with my manager to talk once a week. This, coupled with the weekly check-in my engineering buddy had set up, gave me a bit of structure in a world where I was experiencing both an embed and fully remote onboarding simultaneously. Second, I started aggressively scheduling 1-1’s. My embed had a helpful list of people to reach out to, but my initial instinct had been to focus more on embedding with the team and leave more of those for the end of my embed period. However, scheduling these earlier than initially planned really helped me meet people I may have gone months not knowing, and gave me more of a HubSpot social environment. Sustaining team social structures is easier than building them Every team I joined had developed their own cadence, team rhythm, and communication patterns. Some of these teams had been together for a year or more and were fortunate to already have good work and social bonds in place. As a result, they had as few as one team meeting a week. As a newcomer to these teams, however, some of these bonds actually made joining in more difficult. In non-remote environments, my experience has always been that these boundaries naturally shift to accommodate the newcomer through shared lunches, casual desk interactions, and constant face-to-face time. With those gone, I was relying on our team meetings for group interactions. Teams that had daily standups, water cooler meetings and coffee times were a lot easier to get to know (particularly the smaller teams). There is definitely a fine line between meeting burnout and social time, but for a new hire, that simple 15 minute meeting might be important for connecting them to their new team. Being a newbie in Slack can feel overwhelming The final major contact point in a remote world is Slack. I’ll just say it⁠ — HubSpot Slack is a very intimidating ecosystem to join. There are a lot of rules and cultural norms to learn, and every Slack room seems to have 30-40+ people in it. The end result is that many of the rooms (even the team rooms) are very formal and business-only. I found myself REALLY appreciating the rooms where some whimsy or informality was built in.  Some of the examples I found extremely useful: Engineers who frequently posted links to technical articles that elicited debate Weekly check-ins to post pet photos Sharing what everyone on the team did this past weekend A simple good morning when people signed on All these examples gave me not just license, but an excuse to engage in a conversation with team members that helped form meaningful connections. Conclusion A lot of these lessons were surprising to me, even if a bit obvious with the benefit of hindsight. Working remote means being a lot more thoughtful and proactive about interpersonal relationships in ways I had always taken for granted, but some simple course corrections dramatically improved my early experiences here at HubSpot, and might help you improve team health in your own hybrid work environments. Looking for more remote tips? Read our remote productivity hacks for engineers. Interested in working with a team that's just as interested in how you work as what you're working on? Check out our open positions and apply .", "date": "2021-03-25"},
{"website": "Hubspot", "title": "Introducing the Product Operations Associate Analyst Rotational Program", "author": ["Liana Hotte (She/Her)"], "link": "https://product.hubspot.com/blog/product-operations-associate-analyst-rotational-program", "abstract": "On the Product Operations team, we know the path to a data career is never linear. No one was born a data professional and all of our current teammates report needing a bit of “luck” to get that first data job. At HubSpot we’re hoping to make it easier to get into data analytics careers and get experience working in live-data environments. That’s why we’re launching our Associate Analyst Rotational Program . This winter, we’re hoping to find two growth-minded individuals who are excited about data but may not have the “background” or “years of experience” that are standard on analyst job descriptions. So many of us got started in data via spreadsheets and we know first-hand that the jump from SUMIF to SELECT * can be really difficult without the right infrastructure and support. With this new program, we’re breaking down the requirement of “technical experience” so you don’t have to be an Excel, SPSS, SQL, Python, or R wizard to make a big impact. We’re designing this program to teach you the tools you need to get the job done, to make insights and recommendations of unstructured data. We want to give you hands-on experience on querying, analyzing, and reporting on data. We want to provide an accessible and truly “entry-level” role so that we can have a diverse set of perspectives working to make HubSpot’s products successful year after year. We want to help cultivate the next generation of data professionals. We’re looking for folks who Are passionate about finding learnings that are not obvious - like mining for nuggets of truth! Are ready to get their hands dirty into real data and real problems - data cleaning is REAL. Are excited about learning new skills - and know that it takes practice! Strive to understand the reality behind the stats - there are real people behind those 1’s and 0’s! Aspire to be a data-driven influencer. Reporting and visualization is a necessary first step, but that should evolve into making recommendations and advocating for strategy. This new Associate Analyst program will be about 1 year in length, starting with a few months of technical foundations. You’ll get to partake in a lot of the “data lifecycle” -- using tools like Airflow and dbt to get a crash course in doing the “T” in Extract-Transform-Load (ETL), learning how to query a SQL database to mix and match data from disparate sources, and using Looker for the reporting and visualization. You’ll get to fill out your toolbelt with modern, growing data technologies. Next, you’ll spend two 5-month periods in rotations across the Product Operations team . For each rotation, you’ll have an experienced mentor to help you along the way, providing guidance and feedback. Together you’ll be responsible for real projects and be making real impact.  You may be working on understanding what features our customers love/use the most, or modeling opportunities for new product growth. You’ll get experience in handling large datasets, running statistical analysis, creating financial models, and more. You’ll get opportunities to hone your data presentation skills by designing dashboards and sharing your learnings with some of the best Product leaders at HubSpot. So if you’re as excited as we are, apply today to our Associate Analyst Rotational Program . We can’t wait to grow better together with you.", "date": "2020-10-14"},
{"website": "Hubspot", "title": "Building a Sleek, Animated Form with CSS (Tutorial)", "author": ["Robert Campion"], "link": "https://product.hubspot.com/blog/how-to-build-a-sleek-animated-input-form-with-css", "abstract": "When we set out to build the new and improved Website Grader , we wanted something that would be slick, speedy, and powerful. First impressions are everything so creating that look and feel on the homepage was paramount. A key component in making that happen was building an engaging form (the two input fields where users enter their website and email address). This form is the only interactive component on the homepage, and more importantly, the only way users can start using the tool. So, to get that quick and clean feel, we ended up building an animated form. Here's why. Most forms look like the one below with blank input fields and corresponding labels like 'First Name' and 'Last Name'. These work well but the fields and labels remain pretty static as users enter their information and navigate through the form. Using placeholder text instead of labels (like 'Email address' and 'Password' in the example below) creates a slightly more dynamic experience since the prompts disappear when users start typing. But this approach still isn't ideal. Even though using placeholder text instead of labels makes forms shorter, it can also make it harder for users to navigate through the form. We considered the benefits of both approaches and decided to build our own animated form for Website Grader (below). In this form, the input fields contain text placeholders at first and then when a user clicks on a field, that text transforms into a label. Building Your Own Animated Form We u sed an animated label to first act as a placeholder and then transition into a label when required (e.g. when the input element contains a value). Here's a step-by-step tutorial so you can create a dynamic form like the one above: Step 1 First thing's first: we need a label and an input field (let's worry about styling later): Notice how the label actually wraps the input field. With this method, we no longer have to rely on the HTML ‘for’ attribute. If we click anywhere inside the label (specifically, on the div element that contains the label text), focus will switch to the input field automatically. You'll also notice how the label-text element is after the input field in the DOM. This is so we can take advantage of the CSS adjacent sibling combinator to select our new “label” (this will be useful when the input field is active). Step 2 Next, let's move the label text over the input field and then move it above when the input has focus: At first, the label looks like a standard text placeholder. But when focus shifts to the input field, the text moves above it and acts as a label. Simply put, we use the CSS style ' transform: translateY ' to move the position of the text vertically. Step 3 Font plays an important role in making any application sleek, so let’s clean that up a bit: Now, the font size will change from large placeholder text to small label text when the input has focus. We’ve also increased the letter spacing and forced uppercase on the label. Let's use Google Font’s Open Sans to punch up the text a bit, too. Step 4 Now, the input field border interferes with the label which looks a little odd. Let’s spruce that up: Most of the changes here are style related. To summarize, we: Added SASS color variables (see why the naming convention was chosen here ) Darkened the body background color Added ‘ cursor:text ’ to the label to show that clicking it will allow the user to enter text Removed the input border except for at the bottom, where we increased it Increased overall input size using padding and font Expanded the width and changed the label color of the input field when it has focus Step 5 You might notice that the label jumps during transformation from one state to another, and so does the input width. We can fix that by using CSS transitions: The interaction with the input field should feel a lot smoother now. For simplicity, I applied ‘ transition: all 0.3s ’ to both the input and the label text, but you can target specific properties and change the timings however you please ( example ). Step 6 We're almost there. One issue still remains, though. If a value is entered and focus is taken off the input field, the label returns to its original position covering the inputted text: We need a way to detect if a value exists and if it does, stop the label from moving over the input field. Unfortunately there isn't a clean CSS solution; there is, however, a solution. By adding a ‘required’ attribute to the input field, we can utilize the CSS ‘ :valid ’ pseudo class. That way, whenever a value exists in the text field, it will appear valid and we can trigger some different styling: There are cases where this solution doesn’t work and in those cases you can use JavaScript to listen to certain events (e.g. onblur) and act accordingly (by adding specific CSS classes - see an example here ). Step 7 To complete the component, let’s wrap everything up in a form, add another labeled input field, and include a clean call-to-action: Now we have a sleek, animated form with responsive fields. If you have any questions about the tutorial, let us know in the comments and if you want to read more about Website Grader and why we built it, check out this post . Thank you to Brad Frost (whose floating label design was a big inspiration), Hugo Welke (the talented HubSpot designer who brought Website Grader to life), and Francisco Dias (our resident CSS maestro and the peer-reviewer on this post).", "date": "2015-09-01"},
{"website": "Hubspot", "title": "Hadoop World, NYC 2009", "author": ["Dan Milstein"], "link": "https://product.hubspot.com/blog/bid/27047/hadoop-world-nyc-2009", "abstract": "On the train back from New York, where I just caught the very first Hadoop World, NYC conference, along with a few HubSpot friends (Steve Laniel, Owen Raccuglia, Andy Novikov). We're in the process of moving the backend of our Marketing Analytics to Hadoop (that's what I've been working on since I joined HubSpot earlier this year). Overall impression: Hadoop usage is just exploding.  I mean, to some degree, sure, no duh , but, still it was pretty impressive to see how many people, in how many different ways, are building cool stuff on top of Hadoop.  It had the feel of being early on in the curve of exponential growth -- something like I would imagine Linux users felt in 1995. There were, I think, 500 registered participants at the conference -- I'm guessing that next year it will be 1000. Or, as I saw someone twitter: if you're looking for a job, learn Hadoop, because everyone was hiring. Few highlights: Ashish Thusoo 's talk about Hadoop and Hive at Facebook was impressive as heck.  I've had Hive on my \"explore in more detail\" list for a while, and this moved it up to near the top.  As someone with a long-standing crush on the relational model, SQL-like expressions getting translated into MapReduce steps is just plenty sexy. Another tool which I'm going to have to take a closer look at is Sqoop , from Cloudera's Aaron Kimball.  We have exactly the challenge he described early on in his talk -- huge amounts of semi-structured data for which Hadoop is perfect/necessary, but then some fully structured data in an RDBMS which we need to join in.  Sqoop basically gives you a clean and efficient means to get that structured data into your Hadoop job flows.  As he briefly alluded to near the end of the talk, there are still some pretty tricky bits necessary to handle data which updates in the RDBMS, but, overall, Sqoop seems like it could be a very useful tool. Rumor has it that I missed a sensational talk from Yahoo! folks about Social Graph Analysis (multiple people had that blown-away look in their eyes when they talked about it). Several presentations ( Cloudera , Karmasphere , maybe someone else, too), described new desktop apps that are supposed to ease the process of developing, deploying and monitoring Hadoop jobs.  These left me a little underwhelmed -- they were, in part, pretty versions of existing, ugly web pages, or checkbox/drop-down replacements for long command strings. Having now been writing Hadoop jobs for coming up on a year, I will say -- they are tricky to write and debug, and when they run into trouble in the real world, it can be quite hard to figure out what happened.  But I don't really see these GUI tools as making much of a difference -- they may shorten the time to learn how to launch a job in the first place, but I don't see them helping you much in diagnosing what happened when you poured 10 gigs of log files through a job flow running on 100 nodes, and ended up with a result with some errors in it. It's possible that I'm somewhat biased, because our usage of Hadoop has (so far), been all about setting up recurring jobs, rather than one-time or ad-hoc queries. But, in general, the \"build higher-level languages on top of MapReduce\" theme seemed much more promising to me than the \"make submitting jobs prettier\" one. (okay, I sound grumpy to myself -- if you end up looking over my shoulder 2 months from now, and I'm clicking around in Cloudera Desktop, I encourage you to mock me wholeheartedly). Also sat in on a few presentations that focused more on the admin side -- e.g. a barrage of extremely useful tips from Ed Capriolo, of About.com, on how to monitor your cluster's health (he promised to post his slides online, which I would absolutely recommend checking out -- I think he's packaged up some nagios + cacti scripts and configs so that others can download them and get going right away.  I just googled some and found his Join the Grid project -- that may be the source). Overall, it was an excellent day -- a lot of excitement in the room, a real buzz of energy.", "date": "2009-10-03"},
{"website": "Hubspot", "title": "Product Experimentation with React and PlanOut", "author": ["Guy Aridor"], "link": "https://product.hubspot.com/blog/product-experimentation-with-planout-and-react.js", "abstract": "Engineers, designers, and product managers make development decisions every day with the implicit goal of improving some key metric. We want to redesign a page because we believe that it will increase retention by improving the user experience. We want to add a brand new feature or expand an existing one because we believe this will increase product usage by making the product more valuable to customers. Each of these decisions ultimately comes down to answering the question: Does this change actually have the intended effect? This boils down to a matter of causal inference - does making decision X cause Y to happen? In the context of web applications, we’re able to use the gold standard for answering questions about causal inference: randomized experimentation. In larger organizations where marketing, sales, and support can influence user behavior, it becomes especially important to use experimentation as a tool to make product decisions. It, to some degree, isolates you from these external factors. As a result, experimentation is at the heart of product development on the Sidekick team. We are continually iterating on ways that our users can more easily understand and get value out of Sidekick. This experimentation process helps us move faster and with more confidence at all stages of a feature’s lifecycle*. It also enables us to learn more about our user base and apply those learnings to other parts of the product. Most importantly, it helps us craft the future of our product. Finding an Experimentation Framework and Solution Enabling this process, while having it scale across an organization and ensure statistical validity of the tests, requires us to have tools that make it easy to set up, implement, and analyze experiments. In our view, the ideal experimentation framework has the following properties: Users always receive the same parameter values for a particular experiment. Besides resulting in a poor user experience, having different sessions potentially assign different parameter values also makes it difficult to take away any learnings from the experiment. Experiment exposure logging is taken care of for you by the framework so that experiment analysis is painless, predictable, and bug-free. Exposure logging is simply logging which users were exposed to an experiment and what treatments they received. Experiments scale both in terms of the number of experiments you run and in terms of performance as your user-base and product grow. Experimental design, regardless of the complexity of an experiment, should be do-able and understandable by anyone in the organization. The framework should assist in ensuring that experimentation does not slowly end up making your codebase accumulate cruft. Due to these constraints, we began using Facebook’s PlanOut experimentation language and framework in its Python implementation. We found PlanOut to be incredibly helpful, but as we slowly transitioned our infrastructure from server-side rendering to client-side rendering we began to find that passing experiment information and parameters, as well as experiment exposure logging from the server to the client, became cumbersome, slow, and resulted in many avoidable bugs. To accommodate this shift, we decided that we wanted to move from using a Python-based implementation to a JavaScript-based implementation. As a result, we ported and open-sourced a JavaScript implementation of PlanOut that would allow us to define and manage experiments client-side, as well as allow for experiments to be defined through a UI and served in a serialized representation. This implementation has many benefits over our server-side implementation. The first is that it results in almost no performance overhead in running experiments since we don’t have to pass experiment parameters between the server and the client in order to run client-side experiments. This is incredibly important since we care deeply about application performance and degradations in performance can influence some of our important metrics. The second advantage is that it is much easier and less bug-prone to define and implement user interface experiments in the same codebase, which are most of the experiments that we run. Integrating it into a standard single-page app architecture is simple since our implementation of PlanOut was built to fit into this workflow. Each experiment requires a set of inputs in order to determine the corresponding randomized assignment, but in the server-side implementations of PlanOut this was required to be defined when the experiment was initialized. Our implementation allows for the inputs to be registered in the standard bootstrapping of a single-page application instead of only being allowed to be supplied at initialization, which allows the initialization of our experiment classes and registering of experiment inputs to be separate from each other. This makes it possible to easily interact with multiple external services and ensures that we minimize duplicated exposure logging. Using PlanOut to Experiment with Virality One example of how we’ve used experiments on Sidekick is by attempting to influence the number and quality of viral invitations sent. Free users of Sidekick get a month of unlimited notifications if they send their friend an invite with Sidekick and their friend accepts the invite (the friend also gets a free month). One big driver of invitations is an invite suggestions component that allows people to send invites with one click. In this experiment, we want to see if we can get users to send more invites by tweaking certain parameters around the component. In this experiment we don’t want to enroll paying users, so we conditionally un-enroll paying users from the experiment (this takes care of not logging exposure for them). For the remaining free users we implement a 2x3 factorial experiment where the two factors are the number of invite suggestions shown and the wording of the invite CTA. We define the number of invite suggestions we want to show as one experimental parameter to see if the number of invites sent monotonically increases as the number of suggestions increases or if there’s a point at which additional suggestions have no effect or a negative effect. The other parameter chooses between showing a button geared towards a selfish incentive (Invite) and another towards an altruistic incentive (Gift): Running an experiment requires both an experiment definition and a corresponding implementation; as a result we wanted a way to naturally move from experiment definition to experiment implementation. At HubSpot most of our client-side JavaScript applications use React for the view layer of the application, and since many of the experiments we run are user interface experiments, we naturally tried to figure out a way to seamlessly implement experiments in React. The result is a small library called react-experiments . Introducing ReactExperiments The core idea behind the library is that it forms a one-to-one mapping from PlanOut experiment parameters to the props of React components and uses the resulting randomized experiment assignments for a particular user as props for the corresponding component(s). This integrates nicely with PlanOut’s focus on parameters instead of variations. The result makes the connection between definition and implementation more understandable, makes it less likely to have subtle implementation bugs that could invalidate the experiment, and makes the process of continually implementing experiments less susceptible to accumulating cruft. Let’s look at how simple it becomes to implement the preceding experiment using React. Suppose this is the implementation of our code before the experiment: Now, to implement our experiment all we have to do is replace the last line with: We didn't have to touch a single line of application logic to implement this experiment. Not one line . The base of the library is a Parametrize component which powers the rest of the capabilities of the library. For instance, the parametrize higher-order component is a convenience wrapper for when all the relevant props are in the same component. However, when you want to implement an experiment in a component where the props of interest may be in children components you can directly use the base Parametrize component coupled with the withExperimentParams higher-order component around the children components to provide the necessary parametrization of props. Here is an example of utilizing both the Parametrize component along with the withExperimentParams higher-order component. Both the withExperimentParams and parametrize higher-order components provide powerful abstractions for experimentation. In some cases, however, the experiments we want to run involve complete redesigns where it simply isn’t feasible to specify the different range of parameter values between the different designs. For these experiments, react-experiments offers an ABTest component that allows for a declarative way to define different variations within your components. The declarative API will make it obvious to readers of the code that an experiment is going on between a number of variations and what is the behavior of each of those variations. After the experiment is done, it's therefore rather easy to clean-up the \"losing\" components and remove cruft. This component, like the higher-order components, is simply a convenience wrapper around the core Parametrize component. We think that the ability to both design and implement experiments in this manner is powerful compared to other methods. Thinking about product design and development with an experimentation mindset is an asset for any product team and can lead product teams to be more focused on the right things and able to iterate much more quickly. We’ve found that applying this experimentation mindset along with the combination of using PlanOut.js and react-experiments to implement these experiments has had many benefits. We hope that you find the tools that we’ve open sourced helpful for doing the same! * http://onstartups.com/insider-look-at-hubspot-sidekick-growth-approach talks more about how we use experimentation in our growth process. ** Thanks to our PaaS at HubSpot , we didn’t have to worry about not being able to start and stop these experiments exactly when we needed to do so.", "date": "2015-10-22"},
{"website": "Hubspot", "title": "Platform Updates: New Prospects API Released!", "author": ["Adrian Mott"], "link": "https://product.hubspot.com/blog/bid/79315/platform-updates-new-prospects-api-released", "abstract": "We're excited to announce the release of a brand new APIs on the HubSpot Platform: Prospects API .  This API joins the 5 marketing APIs that are already in the HubSpot ecosystem. Prospects API enables developers to access HubSpot customer website traffic data and a variety of data associated with that traffic, including company information, number of visitors and page views, as well as geographic data including city, region, country and latitude and longitude data. All of this data is really useful, especially for integrations and external apps that want to take advantage of traffic data like this. The new Prospects API also integrates with lead data, so as an API user, you can see if a particular company has actually had leads convert through HubSpot as well.  Through the leads API, you can look up these folks by searching for the company they are from. The API also has a search feature that will let you search for prospects by their geographic location (city, region, or country). As a bonus, there's also a typeahead feature that let's you only specify some of a company name in order to get back what you're looking for. Very useful for anyone trying to create and app that can search for prospects, map them, etc... To see some sample output from the API, check out this URL: https://hubapi.com/prospects/v1/timeline.json?hapikey=demo Here's some sample output:", "date": "2011-11-30"},
{"website": "Hubspot", "title": "Mastering the Product Demo ", "author": ["Christopher O'Donnell"], "link": "https://product.hubspot.com/blog/mastering-product-demos", "abstract": "Most product demos are disastrous. Spotty internet connections, software glitches, and fuzzy narratives come to mind. It’s rare to watch or give a product demo that doesn’t feel disjointed and unless product people have a regular platform like Science Fair to practice, improving can be a slower (and more painful) process than it should be. I’ve been responsible for more trainwrecks than I'd like to admit and my biggest learning has been that you can never be too prepared. Some factors are going to be out of your control (someone’s cell phone going off, for example) but there are a handful of ways to optimize for a smooth demo. Here are some learnings to consider next time you’re pitching a product to investors or presenting a new feature to your product organization. Beware the Projector These things are the devil. There are three big challenges with projectors: severely limited resolution, severely limited contrast, and an unpredictable connection to the demo machine. Mitigate the first by bumping up the resolution as much as possible and using browser zoom to position your (web) product correctly. Regarding contrast, be prepared for your product to be less visually impactful than it is on your cinema display; if your product has a dark background with lots of sleek grays (think Spotify), you may need to explain why the app looks like a pile of melted driveway sealant on the big screen. As far as the peripheral connection is concerned, make sure you know how to configure the display and that you've tested that particular projector with the demo machine in advance. Tell Your Development Team It’s shocking how often a fatal flaw in a demo happens because the development team is completely unaware that their product is being demoed. Starting about an hour before the demo, advise your team to stop shipping for that period. It’s painfully obvious to an audience when the presenter is surprised by what’s being projected. Narrate the User Experience The best demos clearly explain what the user’s problem is and how this given product will solve it. The most powerful way to do this is to keep the narrative concise, speak in the first person, and describe the experience as you walk through user flows. By focusing on use cases and illustrating real user feedback, the end-user benefit of all the slick new stuff you’re showing will be obvious. Demo in Production If there are any stakeholders in the room and you demo software that is running locally, you are willfully deceiving them (as far as I am concerned). You might be surprised how sharp the audience’s eye is; I once heard a sales rep catch that a demo was of a QA environment (from the URL). People will notice if you are demoing from localhost or QA, or showing mockups (ew! How could you sleep at night?!) so remember: production software or it didn’t happen. Use Your Own Laptop Or one just like it. If you rehearse on a Mac, demo on a Mac. If you rehearse on a PC, demo on a PC. Switching to an interface and system that isn’t second nature right before giving a demo is going to be much more stressful than you think. Even if you have to swap presenter roles, it’s worth it. And don’t forget these small, quick tricks: For Mac users, be sure to select ‘Enter Presentation Mode’ in Google Chrome. Try to use the same version of the operating system and - bonus tip - clear your browser cache. Make sure you remember any logins or passwords you may need. Better yet, keep yourself signed into any app you’ll need during the demo (if possible). Get There Early If you show up to give a demo and your audience is already seated and ready to go, prepare for a big healthy serving of fail. Ideally, you should give yourself about 15 minutes to prepare before the demo is scheduled to start. Edward Tufte , who’s written extensively about giving presentations, makes this recommendation, too. His point is that getting a sense of the audience as the room fills up can help you stay calm and in control. Maybe people will be standing when you thought they’d sit, or they’ll want to stop and chat with you as they walk in. Preparing ahead of time will give you a chance to pivot and solve last minute issues. Do a Last-Minute Dry Run Test all features within 10 minutes of the demo. Obsessively. Be Clear About Who Has Access Are you demoing beta software? Are these new features in general release? Whatever the status of the product is, be clear about it so you maintain and grow credibility with your audience over time. A simple and effective guideline is to avoid demoing anything that doesn't have at least one active user in the wild. Hardwire Your Internet Connection Really. Wi-Fi can be a finicky thing and you don’t want to be reminded of that when all eyes are on you and your product. Along those lines, beware of Bluetooth. Wireless technologies work much better in empty rooms than in rooms full of fellow web geeks. That one hasn’t burned me (yet), but I learned this lesson at the expense of the GoogleTV team who suffered through a tremendously embarrassing product reveal at Google I/O 2010. Sadly, they hadn't accounted for Bluetooth working once there were 10,000+ techies in the room on their devices. Focus on the Product, Not the Process It’s natural to get invested in the things we make. Development teams spend countless hours building, fixing, and discussing what ultimately gets shipped. By the time a product gets demoed, a lot of love and pain has already been poured into it. But it’s important to check any personal baggage at the door and just tell the story of why the software will make your users’ lives better. That’s all anyone wants to hear. Celebrate Impact Finally, to take your demos to the next level you have to show real impact. Explaining why you did something or what it looks like to the user isn’t enough; you have to demonstrate what the actual result of the work was. The easiest way to do this is to talk about how usage increased, but for your demo to make it to black belt level mastery you need to tie it back to the bottom line. How does this product impact your business? How has it made customers more successful? Here’s how to think about showing that impact: Good: Now, 20% more users are engaging with the feature weekly. Better: Since rolling out these new competing features, sales reps are closing competitive deals 20% more often. Best: Customers are generating 20% more leads from their website with these new landing page improvements. The nerves that go along with giving a product demo will always be difficult to master. But being prepared makes a huge difference in demoing with confidence and minimizing potential potholes. What else helps you prepare for product demos? A variation of this post was originally published on Markitechture , Chris's personal blog .", "date": "2015-08-07"},
{"website": "Hubspot", "title": "Build your software like a Toyota not a Ferrari", "author": ["Dan Abdinoor"], "link": "https://product.hubspot.com/blog/bid/65105/build-your-software-like-a-toyota-not-a-ferrari", "abstract": "Each Ferrari is a work of art that you can drive. The engine and powertrain are derived from the latest F1 racing designs. The suspension geometry is optimized for the speed and conditions of a race track. The carbon-fiber bodywork is hand-laid in molds designed to aerodynamic perfection. The components are assembled by a small workforce of craftspeople.  Photographs are taken throughout the process and provided to the future owner in what is called “The Baby Book.” The end result is a finely-tuned, yet capricious, machine. Each Toyota is an example of modern manufacturing techniques and efficiencies of scale. The engine is the tenth refinement of a ten-year old design. The suspension is designed for rutted asphalt and concrete highway sections.  The interior is a lesson in compromise: How to perform necessary functions while remaining unobtrusive. The components are assembled by a fleet of robots and humans on a perfectly-timed assembly line. The end result is a dependable and predictable machine. If you are fortunate enough to own a Ferrari, you quickly learn to live with the maintenance of such a machine. An oil change with six quarts of full synthetic runs $300; expect to buy a new set of tires each year for $4,000; suspension components are replaced every few years for $25,000. The price for driving a work of art is high and the average usage for an Italian exotic is just 3,000 miles a year. If you own a Toyota, you get a predictable maintenance schedule. There are $30 oil changes and $500 service intervals. Plenty of spare parts are available direct from Toyota or the network of other compatible suppliers. You can get your Toyota serviced just about anywhere. You can push your Toyota to 100,000 miles and beyond. Software and cars are similar beasts. Both are usually considered as objects, whole entities, rather than by the composition of their sub-systems. Cars and software also share similar development tracks: usually there is a sexy prototype to show and then layers of safety checks and compliance tests get added on. Both have to be maintained and repaired, whether on a schedule or because of emergencies. You are probably starting to see my point now. When you build software and systems, you want to build a Toyota, not a Ferrari. The Ferrari of software would leave you troubleshooting complex algorithms, or looking for drivers for an experimental key-value store. Aim for reliability through iteration and refinement. One novel idea at a time is sufficient. Think about how and where failures will occur and plan for them. Identify the parts of your system that might not scale, or might not fit every use-case, and make them easy to replace. Your software should be something you can “drive” every day without a lot of headaches. Building a Toyota is every bit as challenging as building a Ferrari -- the tradeoffs may not seem sexy, but they are worth it. Good software will be just like a Toyota: dependable, efficient, predictable, and in most cases affordable, too. Have you built your software as a Toyota or a Ferrari?", "date": "2011-10-14"},
{"website": "Hubspot", "title": "Easing the Pain of Hadoop with Guice", "author": ["Edmund Jorgensen"], "link": "https://product.hubspot.com/blog/bid/51978/easing-the-pain-of-hadoop-with-guice", "abstract": "If you've used Hadoop for non-trivial jobs, you've probably run into the \"remote construction\" problem.  Since Hadoop ships your code and spins it up in Java VMs on remote machines, you can't pass pre-constructed Java objects into your jobs--you have to bootstrap everything from scratch in the spun-up VM, and the only form of configuration Hadoop makes it easy to pass over is key/value string pairs. One way to use these key/value string pairs is to use them to specify the names of classes to instantiate during setup in the job--this is what Hadoop does itself with its mapper class and reducer class options.  Often this is enough to get the job done.  But recently I have been working on a project to do some web crawling in Hadoop.  The crawler classes and related hierarchies are fairly loosely coupled, and a lot of options (where the boundaries of the crawl are, for example, or how to process the html to discover new links) are expressed as different objects being used during the rather complex construction process of the top-level crawler object.  This design was flexible and successful for local crawls, but, because you can't pass objects into a Hadoop job, it was a real pain to construct a crawler in Hadoop.  Basically for every new combination of options I wanted, I had to create a class that was hard-coded to construct the crawler appropriately, and pass that class name as an option to Hadoop.  In the job's setup code, it would instantiate an object of that class and use it to get the constructed crawler.  That meant every time I wanted to add a new combination of options, I had to add code to my project, rebuild it, and ship the new jars.  A real pain. Enter Guice , Google's framework for dependency injection.  Guice (simplifying slightly) lets you throw a bunch of objects into a mix, indicating which should be used to implement which interfaces, and then constructs your objects for you, making sure that all dependencies are met along the way.  You enable this by creating your own classes that implement Guice's Module interface, in which you \"bind\" your custom implementations to the appropriate interfaces.  Finally, using the @Inject annotation, you tell Guice which constructor dependencies it should attempt to satisfy.  (Guice can do more than this, but this is what it does in a nutshell.)  To make this more concrete, here's a much simplified example: public class DbCrawlModule extends AbstractModule {\n  @Override \n  protected void configure() {\n    //implement the PageSource interface with the\n    //DatabasePageSource class...and so on\n    bind(PageSource.class).to(DatabasePageSource.class);\n    bind(LinkDiscoverer.class).to(DomLinkDiscoverer.class);\n    bind(Crawler.class).to(SimpleCrawler.class);\n  }\n}\npublic class SimpleCrawler implements Crawler {\n  private PageSource pageSource;\n  private LinkDiscoverer linkDiscoverer;\n  //the all-import Inject annotation...tells Guice\n  //to try to meet these constructor dependencies\n  @Inject\n  public RealBillingService(PageSource pageSource,\n      LinkDiscoverer linkDiscoverer) {\n    this.pageSource = pageSource;\n    this.linkDiscoverer = linkDiscoverer;\n  }\n  //...real crawler code\n}\n//wherever your main lives...\npublic static void main(String[] args) {\n    Injector injector = Guice.createInjector(new DbCrawlModule());\n    //here is where Guice creates the dependency graph\n    //and constructs your object for you...this will\n    //create a SimpleCrawler from a DatabasePageSource and\n    //a DomLinkDiscoverer\n    Crawler crawler = injector.getInstance(Crawler.class);\n    //...use your crawler...\n} You see how nicely Guice helps you keep your objects loosely coupled, and hides your implementation details in your Module class.  So how would this work in Hadoop?  At first glance, it looks just as bad as our \"one configuration == one class\" idea, since we'd have to create a custom module for each configuration combination we wanted to use.  But with a little hackery, we can make this more dynamic.  We'll pass a Hadoop configuration string of the form \"<interface1.class>:<implementer1.class>;<interface2.class>:<implementer2.class>\", and use a custom Module to parse that out and perform the binding.  Here is a simplified listing (in the real thing we want to provide for more advanced Guice features like scopes, and provide some support for formatting the string). public class WiringModule implements Module {\n    private Map<Class<?>, Class<?>> classes;\n    /**\n     * Take the class mappings provided in string form and later replicate them in Guice.\n     * \n     * The format of the string should be:\n     * \n     * <implemented class1>:<implementing class1>[;<implemented class2>:<implementing class2>...]\n     * \n     */\n    public WiringModule(String wiring) {\n        classes = new HashMap<Class<?>, Class<?>>();\n        if (wiring != null) {\n            for (String wire : wiring.split(\";\")) {\n                String[] classNames = wire.split(\":\", 2);\n                try {\n                    Class<?> bindClass = Class.forName(classNames[0]);\n                    Class<?> toClass = Class.forName(classNames[1]);\n                    classes.put(bindClass, toClass);\n                } catch (ClassNotFoundException e) {\n                    //abort! abort!\n                    //...\n                }\n            }\n        }\n    }\n    /**\n     * For Guice to call\n     */\n    @Override\n    public void configure(Binder binder) {\n        for (Entry<Class<?>, Class<?>> e : classes.entrySet()) {\n            Class c = e.getKey();\n            Class b = e.getValue();\n            binder.bind(c).to(b);\n        }\n    }\n}\nNow, when setting up a Hadoop crawl job, I can specify from the command line a series of interface to class mappings (and there's a set of defaults as well).  I bundle those up into a wiring string of the format described above, and set a custom Hadoop config key to that value.  In the setup of the Hadoop job, we pull out that wiring string and then do something like Injector injector = Guice.createInjector(new WiringModule(wiringString)); Crawler crawler = injector.getInstance(Crawler.class); //and we're off... If I forget to specify a dependency, Guice lets me know really quickly by throwing an error.  And Guice's extra flexibility comes in really handy when the construction graphs get big, and incorporate constructors with different numbers of arguments, etc.  I just have to make sure all the elements are thrown into the mix, and Guice will \"do the right thing.\" Is this solution--encoding the classes into strings--a little dirty?  Probably.  Has it reduced my pain with Hadoop, and made it easier to take advantage of map/reduce?  Definitely.", "date": "2012-12-10"},
{"website": "Hubspot", "title": "8 Tips for Doing Usability Testing at a Fast-Paced Company", "author": ["Molly Wolfberg"], "link": "https://product.hubspot.com/blog/how-to-do-usability-testing-at-a-fast-paced-company", "abstract": "At HubSpot , we have one of the fastest development teams around. Our dev team continuously deploys code, up to 100 times per day , so our product is constantly changing. This leads to several challenges for us on the UX team, whose job it is to ensure that the software is easy and enjoyable to use. One big challenge we have is to conduct usability testing in this crazy fast environment. As you may know, usability testing is often one of the first things dropped from the \"must have\" list of product release schedules. There are several reasons for this, common assumptions that are made about usability testing: Usability testing takes too long or is too slow Usability testing is too hard to get right We can get the same data in other, easier ways All of these assumptions are common but do not stand up to scrutiny. When done well, usability testing doesn't slow down the release process, it's not too hard to do, and it provides uniquely valuable information about your product that you simply can't get in other ways. So at HubSpot, we've refined our usability testing process to be as fast as possible. We continually test our software with every product team, being sure to implement testing in a way that does not slow any of our developers down. Here are eight things we've learned: 1. Do a complete round of testing in one day In order to keep up with the pace of the software and those developing it, we execute each usability testing sprint in one day. We schedule all the tests in one day, even if it becomes a really long day. This usually means four to five one-hour usability tests back to back, where we can quickly and clearly see the trends among the testers and provide the development team with key takeaways immediately. By keeping the testing to one day, we keep the development teams moving quickly and everyone can schedule around it easily. In addition, by consolidating all the testing to one day we make it easier for the product team members to attend the tests without disrupting other projects. 2. Offer different levels of service Sometimes even one full day of testing is too long or too much on some projects, so we offer several levels of service to our product teams: Support Evaluation - A couple hours of talking and very fast usability testing with several support reps to attack a known technical issue with the software. Our Support folks watch and help customers interact with the software all day long and often see issues earlier than anybody. Consultant Interview - A couple hours talking with several Marketing Consultants to discuss any domain or conceptual issues around the software. Our consultants are helping people do marketing every day and so they are familiar with any issues that crop up. One day sprint - Our typical one day usability testing process that tackles both technical and domain-related issues. Every so often, there won’t be enough time to commit to a complete testing sprint before releasing something new, so offering different levels of service before we ship can make all the difference. 3. Set up a reliable remote testing environment At HubSpot we conduct remote usability testing most of the time. While we do the occasional in-person test when the situation calls for it, we test with our customers all over the globe and remote testing is the only way to do that quickly. It is valuable to get insight and feedback from users from places as diverse as Massachusetts, Ireland, and New Zealand. By remotely testing our users, we’re able to extract the most value out of our one day testing sprints. Some of the most valuable benefits of our remote testing sessions are: Being able to quickly set up three or four tests in a row Saving time and money by not coordinating in-person testing Setting up a test in less than 24 hours Everyone who should view the test can view the test (even those who are working remotely) No shows are easy to overcome Rather than having to coordinate in-person usability testing, which takes days to plan and conduct, we focus on remote testing because it speeds things up considerably. 4. Keep the best users ready at a moment's notice We are in a unique situation at HubSpot: we have first-hand access to all of our customers. We can reach out directly to the people actually using the software at any time. We have a detailed database of testers that we keep current notes on and know which features they use most often. The customers in our usability testing database are ready to help us at a moments notice, so the recruiting process is quick and painless. By creating a database of the best, easily-accessible users we shave lots of time from the testing process. We email them a day or two before the test, and they block off an hour in their schedule. We work with only the most helpful, eager customers for these sprints. Without this ability to recruit awesome users quickly, our testing process would last days rather than hours. 5. Agree on high level tasks and use cases ahead of time A testing sprint cannot be successful without carefully set high-level tasks and use cases prior to the test. Instead of creating the tasks from scratch every time we test, we've created what we call \"product research pages\" to record and archive the use cases for each product. These documents are rich with information and research about each product we have, including things like use cases, user research, competitive research, direct and indirect competitor information, as well as the results of any previous testing we've done. By taking a quick glance at this page, anybody (even those unfamiliar) can quickly get up to speed about everything we know and don't know about a product. So when we need to do any sort of usability testing, a quick glance at a product research page gets us moving quickly. Our product and usability teams work to maintain the product research pages over time so they are always up to date. By having these pages we can draw up a task list for usability testing extremely quickly. 6. Make sure the whole team is in the room During our testing sprints, we make sure the product managers, interface designers and front-end developers are in the room observing and asking questions. The team then has the ability to ask the testers questions about their pain points, expectations and needs. The value for the development team when experiencing the user encountering issues and bugs far exceeds them reading a page of notes or listening to a recording. There is no second-hand information being shared when everyone is present, so the team can immediately move to recommending actionable takeaways after testing. 7. Debrief immediately after testing and create a shared plan To help make the one day of testing even more effective, we hold a debriefing meeting immediately after the last session. In this half hour we discuss observations, trends, bugs, usability issues and any inferences we make about why users did what they did. We also develop actionable takeaways and assign them to different members of the team. By figuring out the next steps after the tweaks, we can decide if more testing is needed or if the feature is ready for the beta group to test out. The whole group is kept in the loop as development progresses. This debrief allows the team to get started immediately implementing the fixes and recommendations decided on the same day of the test. 8. Compile notes & videos Even though we make sure all the right people are in the room for testing, we still often want and need to share the results with the company as a whole.  Once the actionable takeaways are established, it is important to make the findings available to those who weren’t able to attend the testing, usually within 24 hours. At HubSpot, we have an internal wiki where we post all of our findings. A member of the UX team is taking detailed notes during the testing sessions, and those are summarized to show the main points (e.g. 3/3 people could not find the ‘save button’) of the testing, as well as the next steps. We put together a quick video highlighting the key insights for those who don’t have the time to read the notes, which only takes an hour or two. This wrap-up makes it easy for anyone in the company to see the results within a day of the test. Bringing it all together Testing in a fast-paced environment isn’t easy. We often don't have weeks or even days to plan a usability test. Having a successful process in place and knowing how to manipulate it when under pressure is key to releasing the best possible product to customers. While we’re getting pretty good at performing extremely fast usability sprints, there is always room to grow. Stay tuned.", "date": "2013-03-18"},
{"website": "Hubspot", "title": "Designing HubSpot's Content", "author": ["Dan Ritzenthaler"], "link": "https://product.hubspot.com/blog/bid/91762/designing-hubspot-s-content", "abstract": "We've made a lot of changes inside the Hubspot product over the last year. There's been a huge push to create a more consistent and reliable foundation for all of the user interfaces throughout the product. This means attacking all of the areas of the software that exhibit similar behavior and uses, like toolbars, sidebars, footers, and so on. Ideally, these should all look and work in similar ways so that your users don't have to keep teaching themselves how to use each interface from scratch. Unfortunately, when every interface uses the same foundational elements and copy, it can be easy for the user to lose context and get disoriented. In short, different areas in the software that fulfill different needs should look and feel different . To address this problem, we needed the content of these pages to stop hiding in the shadows and become the star of the show. The Content Should Communicate its Purpose Most interfaces in enterprise applications consist only of lists of stuff in tables with columns and columns of data. Out of context, it can become difficult -- if not impossible -- to understand what you're looking at. Many, many applications don't do a very good job of making their content sing. We realized we needed to step it up. Every piece of an interface should be dripping with purpose and should reiterate the value it can offer to the user. Let the Content Make the Screen Special For example, if you were looking through custom event reports, you would need access to a lot of data. But mostly, you'd want know how things have changed over time. Why not visually prioritize this data and add visual signals to help identify important changes? Another big problem with columns and colums of data is that many of your rows will rely on each other to provide them with meaning. For example, an email sent to a small list for a specific purpose will probably convert better than an email sent to a huge list for a general purpose. You'll need to know your delivery size to adequately understand your conversion rate. So we needed to do a better job of organizing data so that we were answering the most critical questions quickly. In a lot of applications, just finding the right object is an important task. Then figuring out what that object accomplished compared to their peer objects is the obvious next step. Becoming More Approachable and Understandable If we can design the content of each application to better reiteratie its purpose and to accomodate the needs of the people looking at it, HubSpot (and the world) would be a much better place. We've already come a long way in this effort over the past year, and this will remain a focus of our design work for the coming months, too. We want our software to be extremely valuable, but at the same time easy and even fun to use. What do you do to help your content speak for itself?", "date": "2012-10-16"},
{"website": "Hubspot", "title": "Quick Guide: How to Put Invisible reCaptcha on Your Website", "author": ["Sophie Legras (She/Her)"], "link": "https://product.hubspot.com/blog/quick-guide-invisible-recaptcha", "abstract": "Google recently released a new way to prevent spam: the invisible reCaptcha. The HubSpot product team is introducing this new tool on all forms in our product soon, because it'll help customers generate more legitimate leads. Want to give it a try? You only need a few steps to add invisible reCaptcha to your website. What is Invisible reCaptcha? You're probably already familiar with reCaptcha, the checkbox you sometimes have to click on before you can submit a form on a website. If the algorithm thinks that you're a human, it will validate the reCaptcha without any further action on your part. If not, it'll serve up a bunch of images that you'll have to categorize before you can continue. Tough on bots, easy on humans So what's invisible reCaptcha? Well, it's actually exactly the same - it just doesn't have a checkbox. In fact, you won't see the field at all. Like with a traditional reCaptcha, an additional challenge will sometimes appear if it thinks you're not a human, but with invisible reCaptcha, this happens when you submit the form (and the submission will really be sent once you validate the image test) instead of when you tick the checkbox. You can give it a try here to see the full behavior. So is it really invisible? Not completely. As Google captures user information from your website, you'll need to warn your users by displaying their Privacy policy and Terms and conditions . This visual is implemented by Google, but there are a few options available (see the section on personalization below). Installing invisible reCaptcha from scratch Let's add invisible reCaptcha to a website. First, we need to register on this page to get an API key. Choose ' Register a new website ', then click on ' invisible reCaptcha '. Entering a domain isn't necessary, but it can help prevent someone from using your key, so we'd recommend entering it if you know where your reCaptcha will live. If you don't want to put a domain, don't forget to uncheck the option in advanced settings. You will get two keys: a public one, which will be used for the front end call, and a private one, for back end verification (which you shouldn't share). Front end steps Now we can really start. First, we'll need to include Google's script: This code contains all the logic for reCaptcha. Then, we can simply bind the captcha to a button: That's the biggest change compared to a traditional Google reCaptcha: the challenge is now deeply linked to the submission. Let's take a closer look at what we just wrote. The class \" g-recaptcha \" is required, since it tells Google JavaScript where to look for reCaptcha's information. Also, don't forget to add your own key as an attribute and change the action to send your form to your endpoint. We now have to make our own \" onSubmit \" function to handle reCaptcha's response. This function will just submit the form, but you can add any validation you want at this point. Keep in mind that everything here will be executed after the person completes the reCaptcha. At HubSpot, we approached this problem a bit differently. We needed our form validation to happen before we displayed any potential reCaptcha to the visitor. For example, if the email address isn't formatted correctly, or if a required field is absent, we want to handle that first, which is why we didn't bind reCaptcha directly to the submit button. Fortunately for us, Google offers a second option, which enables us to treat the invisible reCaptcha as a part of our form: As you can see, the reCaptcha is now in its own <div> and isn't attached to our submit button anymore. The challenge won't appear when the user clicks on this button, but instead whenever you tell it to by calling this function: This gives you perfect freedom on the order in which you decide to run functions. For example, you can call one of your endpoints first, wait for its response, then show the reCaptcha test after. But there are tons of other possible use cases, and you can time the challenge in whatever way works best for your situation. We should note that the \" execute \" function call works perfectly when there's only one reCaptcha rendered on the page. But as soon as you have two of them (invisible or not), they become unusable. Think about it - how would the Google script know which challenge you want to render? The one linked to your first form? Or the second one? Therefore, if you have multiple reCaptchas on a page, you need a way to identify which is which. So here's the solution we chose to implement at HubSpot, because we needed to give customers the ability to put several forms on their pages, with or without reCaptcha. This solution also similar to the way you'd implement a normal reCaptcha, so it might be the easiest solution if you're swapping your traditional reCaptchas for invisible reCaptchas. We add a loading function to the Google script call: We also must be careful not to forget the last parameter, because you'll need it to make several reCaptchas work at the same time. Now let's create our loading function: There are other parameters we could add to this render function, but we'll touch on them later (see the personalization section). You can see that the rendering function returns an ID - it's important to save this. For example, if you code in ReactJS (like we do at HubSpot), this can be an attribute of the state of your component. But whatever language you use, saving it is the important part. Once you do that, every reCaptcha will have a unique ID, known both by our program and by Google. We can then call our challenge by writing: And that's it! Note that you can also reset a reCaptcha (to force your user to complete it again) by calling: In short, these are the steps you need to implement a solution for multiple reCaptchas on your front end: Call the Google reCaptcha script Implement a loading function, that saves the widgetId of your reCaptcha (and that's also where you have the ability to customize it - see the personalization section) Call the execute function whenever you need it (for example, after form validation) Catch the response in a callback function and submit your form Now that our front end is ready, let's check the visitor's response. Backend verification Once we receive our form submission in our backend service, we have to check that the given reCaptcha response is correct. First, how is the response passed to our service? In most cases, an attribute \" g-recaptcha-response \" is added as parameter, and sent through the POST request at submission time. If you'd like to pass the response manually, you can call this function: In any case, you'll receive a response that's a long string of letters and numbers. Then we'll call Google API to check this response: Url: https://www.google.com/recaptcha/api/siteverify Method: POST Body parameters: response: the reCaptcha's response we got on the submission secret: the secret key we were given by the Google admin captcha interface remoteip: the user's IP address (optional) The API's response will look like this: { \"success\": true|false, \"challenge_ts\": timestamp, \"hostname\": string, \"error-codes\": [...] } The most important part is the \" success \" parameter, which gives you the necessary information to accept or reject the submission. As for the other information in the response, the \" challenge_ts \" is the time when the reCaptcha challenge was rendered (ISO format yyyy-MM-dd'T'HH:mm:ssZZ), and the \" hostname \" shows the website where the reCaptcha was solved. In short, all you need to do is: Call Google's API with your private key and the reCaptcha response Check the \" success \" attribute of the API's response Personalization Now that we have invisible reCaptcha working on our website, let's see what options we have to customize it. If we go back to our rendering function: ...in addition to the \" sitekey \" and \" callback \" , there are a few other parameters we can add to this call. \"badge\" This might be the most important customization you might want to do. The badge is the visual that displays Google's terms and conditions. In normal reCaptchas, this is the field containing the checkbox. There are three different badge options that Google offers for invisible reCaptcha: bottomright (default) bottomleft inline The \" inline \" parameter will render the object as close to a normal field as possible. The two other options are very discreet. They render the badge on a bottom corner of your page (left or right, depending on which option you choose). The badge follows your screen as you scroll and an animation shows the full badge (see above) on hover. Just be careful that this badge doesn't cover up anything important on your website! Because we don't know what type of content our customers might have on their pages, and because we use the bottom corners of a webpage for HubSpot's lead flows feature, we chose to keep the badge inline for our customers. It's also helpful to place the badge inline if you want to apply your own CSS to it. But do remember that you agreed to show Google's Terms and conditions when you registered for an API key - so don't hide it, please. And while it is possible to make the badge disappear completely with CSS, we wouldn't recommend it. \"type\" You can also change the type of challenge that will show up: image (default) audio Image reCaptcha Audio reCaptcha Whichever you choose, reCaptcha will show an icon so that users can switch between types, so that the challenge is accessible for everyone. \"tabindex\" This option can be useful if other elements on your page use tabindex and you want to make the navigation easier. The default value is \"0\", but you can change it so that your user can focus on the challenge after a certain amount of \"tab\" hits. Note that the three parameters above also use the \" data- \" prefix if you use a <div> to render your invisible reCaptcha. Language By default, Google's algorithm detects the user's language and applies it to the reCaptcha, but if you'd like, you could override it. To do that, you can add the parameter ( \"hl\" ) when introducing Google Javascript: For example, here it's overriding the language reCaptcha's language to French. The full list of languages and their codes is available here . In conclusion Invisible reCaptcha has worked quite well for us so far. After extensive testing, it doesn't seem less reliable than its predecessor, and it's one less click needed to change a simple website visitor into a lead in our users' databases. And as you can see, the implementation isn't painful as long as you have good documentation. You can also check Google developer's guide for a more thorough explanation of invisible reCaptcha. We hope that this quick tutorial helps you put an invisible reCaptcha on your website in no time. If you happen to have any questions, let us know in the comments.", "date": "2017-09-12"},
{"website": "Hubspot", "title": "Programmatically Personalize a Forwarded Email", "author": ["Jonathan Kim"], "link": "https://product.hubspot.com/blog/bid/78878/programmatically-personalize-a-forwarded-email", "abstract": "This was first posted on my blog ( jonathan-kim.com ). You can check out the original post , if you're interested. The other day, the project manager for my team ( Brian McMullin ) came to me with a simple request: he wanted to change the text of the call-to-action button in one of our daily emails. His research suggested that the people who were receiving that daily email were actually forwarding it on to other people in their organization, so Brian wanted to target them a bit better. But what if we could target them both a bit better? Well today, you can. The code I like it when people get straight to the point, so here's the code. If you want an explanation of how I got it and why it works, please continue reading :] <p class=\"cta1\">\n    This will only appear when reading an original version.\n</p>\n<p class=\"cta2\" style=\"display: none\">\n    This will only appear when reading a forwarded version.\n</p>\n\n<style type=\"text/css\">\n    blockquote .cta1, .WordSection1 .cta1 {\n        display: none !important;\n    }\n\n    blockquote .cta2, .WordSection1 .cta2 {\n        display: inline-block !important;\n    }\n</style> My impromptu research I noticed that many of the forwarded messages I received in the past displayed the original sender's message, but in a slightly different format, usually indented. With that in mind, I emailed the entire development team at HubSpot and asked everyone to forward the email back to me, along with the name of their email client. I even wrangled some sales people into doing it so I could get a good representation from people using Microsoft Outlook. It turns out that all email services take your original message and conveniently wrap it in a div (with a class) or a blockquote, meaning you can use that as a CSS selector . It's so stupidly simple. Show me an example Original version of the email: Forwarded version: How to use it Stick that piece of code in the body of your email (putting it in the head section makes it more susceptible to being parsed out). Then apply the class \"cta1\" to the element you want to show in the original, and cta2 to the element you want to show in the forwarded version. Make sure to also add the CSS declaration \"display:none\" to the elements that have the cta2 class on them, so they're hidden by default. When your recipient is reading a forwarded version of the email, the code snippet will take effect by hiding the original and showing what was previously hidden. Some caveats Believe it or not, Gmail is doing ungodly things to make email design miserable. Campaign Monitor has a really awesome chart showing email compatibility across clients , and Gmail and Android are the worst, perhaps even worse than Blackberry. They don't support external css blocks, which makes this technique completely ineffective. What about just hiding the second call-to-action so it's not awkward? They've thought of that too. Gmail scrubs your email for anything, and I mean ANYTHING, that can hide an element on a page. Here's a short list of the hacks I've tried: CSS \"display: none\" CSS \"visibility: hidden\" CSS \"text-indent: -9999px\" or \"text-indent: 9999px\" CSS \"margin-top: -9999px\" or \"margin-bottom: 9999px\" CSS \"position: absolute\" + \"top: -9999px\" HTML5 \"hidden\" attribute If you find a way to make it work in Gmail, please share. It's true that you can do stuff using server-side requests and header parsing to return different images. If you want to go that route, good luck :P When to use (or not use) this technique If your email list is mostly composedly of Gmail users, you probably shouldn't use this technique. You also probably shouldn't use it to spam people. At HubSpot, over 50% of our email recipients view these emails on some version of Outlook. About 20% view it on Apple Mail, and about 15% view it on an iPhone. Only 6% of our customers actually use Gmail to view our emails. Just the same, it's a good idea to make sure the email still looks natural with both call-to-actions displayed simultaneously. Further reading Hopefully this simple little technique sets your mind ablaze with other ideas to provide value with simple hacks. If you're interested in pushing the envelope in the email sector, the folks at Litmus are doing some pretty amazing stuff . Here's some discussion behind the secret sauce that puts them ahead of the pack in terms of email analytics: http://stackoverflow.com/questions/3224436/how-does-litmus-track-their-email-analytics http://stackoverflow.com/questions/2958926/track-mass-email-campaigns They're my source for the email analytics used in this article. I highly recommend signing up with them and getting solid data on your email demographics and baseline click-through rates before attempting any of the above.", "date": "2011-11-22"},
{"website": "Hubspot", "title": "Misnomers and Confusing Terms in Machine Learning", "author": ["Marco Lagi"], "link": "https://product.hubspot.com/blog/misnomers-and-confusing-terms-in-machine-learning", "abstract": "Like every other field, machine learning has its fair share of misnomers and confusing terms that, for one reason or another, have stuck. Usually that’s not a problem: meaning follows usage. It’s still useful for newcomers to be aware of them, though, so that these terms don’t propagate implicit wrong assumptions about the underlying concepts. Disclaimer: At HubSpot, we use many of the terms listed below within the same context as the machine learning community at large. There is undeniable value in being able to share a common vocabulary. Introduction Strawberries are not berries, the funny bone is a nerve, and Greenland is... mostly not green. Naming things is surprisingly difficult ⁠— words and concepts can be slippery. But changing a name is even harder. Evidence for this is the widespread presence of misnomers that have stuck in all fields of knowledge. While it’s easy to find lists of these terms for dermatology , culinary arts , flutes , and many other topics, I couldn’t find a good one for machine learning, and decided to put together this list with the 25 most confusing terms. A misnomer does not make the current usage of the term incorrect, because meaning follows usage and it evolves through space and time. Most of these terms are here to stay, and that’s OK. While their use has no practical consequences for experts, it can be argued that it’s riskier for newcomers. This is particularly true for people who come from a different background, where those terms might refer to a related concept, and create uncanniness or downright confusion. So hopefully this post doesn’t come across as a case of “Old man yells at cloud,” but more as a reference for disambiguation. One could start with the name of the discipline itself. While I think machine learning is a solid name, the name of the adjacent fields of artificial intelligence (in its current meaning), data mining , and data science are all pretty puzzling. There’s not much intelligence in cognitive automation , the mining refers to the patterns and not the data, and generic data cannot be the subject of science . The debates around these terms are already in the spotlight, so I’ll set these aside and focus on more technical terms. For the terms listed below, the machine learning (ML) definition is taken from canonical ML textbooks when possible (Bishop, Murphy, Goodfellow, etc.). Each term includes a “Confusion” section, which gives some context around the ambiguity, and an “Alternative” section. The latter should just be taken as a potential way to disambiguate the term in your head (i.e. what could have been ) rather than advocacy for change (i.e. what should be ). Here's a handy table of contents if you'd like to skip to a certain section. Section 1. Statistical terms 1.1 Multinomial distribution 1.2 Inference 1.3 \\(R^2\\) 1.4 Multi-armed bandit 1.5 Regression / Logistic regression Section 2. The “model” catch-all 2.1 ML model / algorithm 2.2 Model drift 2.3 Black-box model 2.4 Non-parametric model Section 3. Optimization terms 3.1 Learning rate 3.2 Stochastic gradient descent 3.3 Momentum 3.4 Backpropagation Section 4. Losses and activations 4.1 Cross-entropy 4.2 Softmax / Hardmax / Softplus 4.3 Softmax loss Section 5. Neural networks 5.1 Neural networks 5.2 Multi-layer perceptron 5.3 Input layer 5.4 Hidden layer Section 6. Deep learning 6.1 Tensor 6.2 Convolutional layer 6.3 Deconvolutional layer 6.4 BERT 6.5 RNN gates Conclusion References Section 1. Statistical terms 1.1 Multinomial distribution Confusion . In probability theory, the discrete distributions for \\(k\\) categories and \\(n\\) trials are commonly referred to as: \\(k=2\\),  \\(n=1\\) -- Bernoulli distribution \\(k=2\\),  \\(n>1\\) -- binomial distribution \\(k>2\\),  \\(n=1\\) -- categorical distribution \\(k>2\\),  \\(n>1\\) -- multinomial distribution In practical terms, the Bernoulli distribution is sampled by a single coin flip, the binomial by multiple coin flips, the categorical by a single dice roll, the multinomial by multiple dice rolls (Murphy 2012, page 35). In machine learning, especially in natural language processing, the categorical distribution is often referred to as the multinomial distribution. For example, in order to generate text from a language model, practitioners tend to use the more convoluted multinomial on one trial followed by argmax (Chollet 2018, page 276), instead of sampling from a categorical distribution, which would directly give the index of the class (although possibly slower). Given that np.random.categorical doesn’t exist, I wonder if the semantics and performance of the APIs have contributed to keeping the categorical / multinomial conflation going, or maybe the fact that the output of the multinomial with \\(n=1\\) is a one-hot encoded vector makes it more palatable. Alternative . There was already an established name for the categorical distribution, we could have picked that. 1.2 Inference Confusion . In statistics, inference is the process of estimating properties of the unknown distribution that generates the data at hand, \\(P(X, Y)\\), where \\(X\\) are the features and \\(Y\\) the labels. The goal is to estimate a function \\(f(X)\\) such that (James 2017, page 16): \\[Y = f(X) + \\epsilon \\] where \\(\\epsilon\\) is the error term. In the context of an inference, \\(f\\) is used to understand how the labels are affected by changes in the features. The output of an inference can be either constructing confidence intervals or testing hypotheses about the population parameters (Mann 2010, page 439). In machine learning, estimating properties of \\(P(X,Y)\\) is referred to as training or learning . Inference instead (especially in the deep learning literature) is often reserved for predicting the labels given the features, using an already trained model (Goodfellow 2016, page 262). Therefore, training time and inference time are the two main modes of a model (Goodfellow 2016, page 450). Alternative . The consensus seems to be that prediction would have been a better choice for estimating the labels given the features (James 2017, page 17). 1.3 \\(R^2\\) Confusion . After inadvertently choosing the wrong model, you fit your data \\(y_i\\) obtaining predictions \\(f_i\\), and check the coefficient of determination, \\(R^2\\). And you find out it’s negative. Aside from the fact that you could probably use a better statistic, how in the world is a squared real number negative? There are many definition of the coefficient of determination, but the most general and common is (Mann 2010, page 584): \\[R^2 = 1 - {\\sum_i(y_i-f_i)^2 \\over \\sum_i(y_i-\\overline{y_i})^2}\\] All it takes for \\(R^2\\) to be negative is for the model to be worse than the trivial baseline, i.e. a horizontal straight line corresponding to the average of the data, \\(\\overline{y}\\). It is not necessarily defined as the square of anything. The reason why it’s denoted as \\(R^2\\) is that, under particular conditions, it coincides with the square of the multiple correlation coefficient, \\(R\\) (Wright 1921, page 574). Alternative . Any other symbol would have worked, possibly excluding \\(\\sqrt{R^4}\\). Its inventor, Sewall Wright, used \\(d\\) (Wright 1921, page 562). 1.4 Multi-armed bandit Confusion . I get why slot machines are also called one-armed bandits: they have one lever, they steal your money. But I’ve never seen a slot machine with multiple levers, so calling multi-armed bandit the problem of choosing between different options with partial information (Murphy 2012, page 184) doesn’t really hit the spot. It’s an analogy with no correspondence to common experience. As Andrew Gelman puts it , another reason why this is an “obscure and overly cute” term is that slot machines have negative expected value, so the best strategy would be not to play. Alternative . In the same note, Gelman argues that it’s really just many one-armed bandits , so that could have been an option. Or maybe, since it’s a reinforcement learning problem with actions and rewards but no features, something like stateless reinforcement learning could have worked. In the HubSpot product we have implemented multi-armed bandits so that our users can test different webpage variations. When we asked our users to describe what they thought a feature with that name might do, these were some of the responses: “Create an octopus bank robber. ” “Sounds like it steals bits of information; I'd be hesitant to utilize it for privacy concerns.” And the best one: “Honestly, that name is a little too \"millennial,\" even for me, a millennial. HubSpot is an expensive professional business tool, not a toy.” That’s why we ended up calling it adaptive tests . 1.5 Regression / Logistic regression Confusion . Supervised learning is usually split into classification , prediction of a categorical variable, and regression , prediction of a continuous variable (Murphy 2012, page 3). So why is logistic regression used for classification problems? Because logistic regression is a regression in the statistical sense, but not in the machine learning sense. First, logistic regression is definitely not a classifier, in that it does not output a class but probabilities (i.e. a continuous output). It’s only when a decision rule (e.g. a probability threshold) is chosen and applied to the output that we can convert one to the other, but this step is not part of the modeling process . Second, it can be argued that the problem is not with the term itself, but with the use of regression as the prediction of a continuous variable. In statistics, this term is defined as the estimation of the relationships between a dependent variable and one or more independent variables (Mann 2010, page 565). This means that, in statistics, regression : Refers to the analysis rather than the goal. The goal can indeed be to predict a quantity, but it might also be to explain a relationship. Does not require the dependent variable to be continuous. It could very well be categorical. Alternative . Calling it logistic model might avoid all this ambiguity (James 2017, page 131). Section 2. The “model” catch-all This section includes terms where the word model is used in place of a more appropriate ⁠— or at least less ambiguous ⁠— noun. 2.1 ML model / algorithm Confusion . The standard definition of an ML model is distinct from that of an ML algorithm (Murphy 2012, page XXVIII). It is the artifact created by the training process, i.e. an algorithm trained to recognize certain types of patterns (see also Microsoft and Amazon API docs). And yet the concepts of model and algorithm are usually not differentiated. Sometimes the former definition is considered too narrow, and ML model is meant to be the ML pipeline deployed to production, including feature transformation (Schelter 2018). To add to the confusion, the term machine learning algorithm is also pretty ambiguous (Deisenroth 2020). One might be talking about the system that makes predictions on input data (i.e. the estimator), or the system that allows the parameters of the estimator to minimize empirical risk (i.e. the training process). Alternative . The terms machine learning model / algorithm are intrinsically fuzzy and hard to pin down. Providing more context when they are used would probably be enough to disambiguate. 2.2 Model drift Confusion . Several practitioners, both in industry and academia, refer to the degradation of a model’s performance over time due to a shift in the feature and/or label distributions as model drift (e.g. Nelson 2015, Kang 2018). This might be confusing because the model isn’t drifting at all. In fact, that’s the whole problem! As the features or labels shift away from the training distributions, the model doesn’t follow the drift. Alternative . The terms covariate shift and data drift typically refer to changes in the distribution of features, so they’re not a great substitute for the more general phenomenon. The term concept drift might work (Žliobaitė 2010), although it is often reserved for shifts in the distribution of labels . Given that an example in machine learning is defined as “an instance (with its features) and a label,” example drift or generically distribution drift may have worked better. 2.3 Black-box model Confusion . The term black box model is often used to refer to the lack of interpretability or explainability of a machine learning model (Murphy 2012, page 585). This is especially true in deep learning, where models are non-linear and have many parameters. But even the most basic model (say a linear regression with two features) can be fairly hard to interpret if the features are correlated, or if they have different units (King 1986, page 669). Nevertheless, I think black box model is not a great term, not because of the black box part, but because of the model part. The internal workings of machine learning models are in general entirely transparent. One could follow the computation arbitrarily closely, without finding anything hidden or uninspectable about how the model produces its output. Models are clear boxes. It’s true that we have yet to understand in a reductionist way how features are globally combined to reach a prediction. But this is evidence that those models are emergent complex systems, not that they are inscrutable. Alternative . What’s really missing is not the logic of how we get from the input to the output, but how that logic maps to our own causal narratives. So black-box mapping instead of black box model here might have been a more accurate name, albeit pretty goofy. There are actually a couple of cases where the term black box model is completely appropriate: either when the model is not available for inspection, or when black box doesn’t refer to the algorithm itself, but to the system the algorithm is trying to model. These cases are not how the term is commonly used. By the way, black box is also definitely a misnomer for its own traditional reference, the flight recorder, which has to be brightly colored for obvious reasons . 2.4 Non-parametric model Confusion . There are actually two things that can be confusing about a non-parametric model . The first one is the non-parametric part, which doesn’t mean the model has no parameters. It means that the number of parameters is not fixed: they grow with the size of the training set, like in k-nearest neighbors (Goodfellow 2016, page 115) or uncapped decision trees (Murphy 2012, page 270). The second one is the model part, as usual a loaded term. In statistics it can refer to the data generation model or to the estimator, while in machine learning it usually refers only to the estimator. So one can have a dataset produced by a non-parametric data generation model fitted by a parametric machine learning model, and vice versa. Alternative . Maybe non-parametric algorithm would cut the ambiguity in half… or would it ? Section 3. Optimization terms 3.1 Learning rate Confusion . The learning rate is regarded as one of the most important levers to tweak during training: “If you have time to tune only one hyperparameter, tune the learning rate.” (Goodfellow 2016, page 429). In machine learning and optimization, the gradient descent algorithm can be written as (Goodfellow 2016, page 85), \\[w_{t+1} - w_t = -\\epsilon \\nabla E(w_t)\\] where the weights \\(w\\) that minimize \\(E\\) are to be estimated, and \\(\\epsilon\\) is the learning rate. While it’s true that when this parameter is very small the model learns slowly, there is no necessary connection between a large value of \\(\\epsilon\\) and learning quickly. If the rate is set to a value that is too large, the system might become unstable, and not learn at all (Goodfellow 2016, page 295). If we interpret “rate” as meaning the amount of learning done per iteration, then the real learning rate should be the derivative of the generalization error w.r.t. time, which can change even if is \\(\\epsilon\\) kept constant. The metaphor leaks left and right. Alternative . Maybe just step size , as it is sometimes known (Goodfellow 2016, page 311), would have been a better name for \\(\\epsilon\\), although the whole term \\(\\epsilon \\nabla E (w_t)\\) might be a better candidate for step size. 3.2 Stochastic gradient descent Confusion . The idea of stochastic gradient descent (SGD) is to apply the gradient descent algorithm on a random example (or minibatch) of the training data (Goodfellow 2016, page 152). SGD is an unbiased estimator of the gradient, so, in expectation, one recovers the full gradient descent. While this is enough to guarantee convergence, it means that the vector returned by SGD is not guaranteed to be the descent direction of the loss landscape at that point. In general, the sometimes-descent will be along a deviated direction that depends on the particular example (or minibatch) at hand. Alternative . SGD does add stochasticity to the GD algorithm, in that sense the term works. But since it’s part of the bigger family of stochastic approximation methods, maybe it would have been less confusing if approximation wasn’t dropped: Stochastic Approximation of General Gradient of at-this-point-Expected Descent (SAGGED). 3.3 Momentum Confusion . This is mostly for people coming from physics, where the momentum is the product of mass and velocity of an object, \\(p=mv\\). In machine learning and optimization, the most naive member in the family of gradient descent algorithms is the steepest descent, as seen here . This can be very slow. In particular, when the system finds itself in a ravine of the loss landscape, it starts oscillating mostly in the direction of the steep walls, making little progress over time. The authors of the original backpropagation paper (Rumelhart 1986) introduced therefore a momentum term , \\[\\Delta w_t = -\\epsilon \\nabla E (w_t) + \\alpha \\Delta w_{t-1}\\] The analogy here is clear: \\(\\Delta w_{t-1}\\) is the speed in the weight space, the mass of the object is set to \\(1\\), and the hyperparameter \\(\\alpha \\in [0, 1)\\) controls the importance of the term. While the authors didn’t give a name to this last parameter in the original paper, it is usually referred to as the momentum hyperparameter (Goodfellow 2016, page 298), which then is often truncated to momentum (Chollet 2018, page 51). But using a synecdoche here leads to weird consequences, where a “momentum” \\(\\alpha\\) is multiplied with the “speed” \\(\\Delta w_{t-1}\\) to give… kinetic energy? Alternative . It can be demonstrated that there is a deeper analogy between the equation above and the Newtonian equation for a point mass \\(m\\) with coordinates \\(w\\) moving in a medium with friction coefficient \\(\\mu\\) (Qian 1999), which leads to \\[\\alpha = {m \\over m + \\mu}\\] which means that \\(\\alpha\\) plays the role of an effective mass, not momentum. So if one sets the mass to \\(1\\) and writes the hyperparameter as a reciprocal, a more appropriate name could be friction coefficient . While \\(\\alpha\\) could have a better name, it’s amazing that the name for the momentum term \\(\\alpha\\Delta w_{t-1}\\) was so well given that it’s even more precise than the authors’ original intent. Not only does it look like a momentum; under particular circumstances, it is one. 3.4 Backpropagation Confusion . While the name is pretty apt for the algorithm that efficiently computes the gradient of the loss function with respect to the weights of the network (Rumelhart 1986), it might be a bit too generic. There are a number of alternatives that still rely on propagating a signal backwards through the network, starting from the output layer. For example, backpropagating desired states (Plaut 1986), target values (Lee 2015), perturbations (Scellier 2017), activations (Choromanska 2019), etc. There’s a second source of ambiguity, where this term is often used to include not only the algorithm to compute the gradient, but also the whole learning algorithm, including, for example, the gradient descent part (Goodfellow 2016, page 204). Alternative . For the first source of confusion, maybe loss gradient backpropagation might have worked better? The second usage just seems unnecessary. Section 4. Losses and activations 4.1 Cross-entropy Confusion . In information theory, the cross-entropy for a probability mass function \\(q\\) relative to another distribution \\(p\\) with same support is defined as (Goodfellow 2016, page 75): \\[H(p,q) = -\\sum_x p(x)\\log q(x)\\] In machine learning, this is often used as a loss function, where \\(p(x)\\) represents the empirical distribution of the label, and the given distribution \\(q(x)\\) is the predicted value of the current model. There are no further assumptions on the particular distributions at hand. And yet, several authors use this term only when \\(q(x)\\) is the output of a logistic or softmax function (Goodfellow 2016, page 132), that is to say either a Bernoulli or a Boltzmann distribution (Bishop 2006, page 206). The generic negative logarithm of the likelihood function is instead referred to as an error function (Bishop 2006, page 23). Alternative . Probably less confusing to stick with the information theoretical terminology. 4.2 Softmax / Hardmax / Softplus Confusion . The softmax function, commonly used as the last activation function of a neural network among other things, is usually written as (Goodfellow 2016, page 81): \\[softmax(x)_i = {e^{x_i} \\over \\sum_j e^{x_j}}\\] The effect of this transformation on the vector \\(x\\) is to: Squash each component in the interval \\((0, 1)\\) Normalize the sum of the components to \\(1\\) Amplify (usually) the largest components, and suppress the rest. This means that the output will be a soft version (i.e. a smooth approximation) of the one-hot encoded representation of the argmax of the original vector, not of the max function. For example, \\[softmax([1, 0.5, 0.2, 5]) = [0.02, 0.01, 0.01, 0.96] \\sim [0, 0, 0, 1]\\] The real version of the softmax is the LogSumExp (also called realsoftmax , I kid you not), and it would be: \\[realsoftmax(x) = \\log (\\sum_i e^{x_i})\\] Another theory is that the softmax function is called such because the one-hot encoded representation of the argmax is sometimes called hardmax . Not only is this equally confusing, but most likely softmax came first, and the term is being retrofitted. A similar problem arises with softplus , named this way because it’s a smooth approximation of the rectifier, also written with the plus superscript notation (Goodfellow 2016, page 68), \\[softplus(x) = \\log (1 + e^x) \\sim rectifier(x) = x^+ = max(0, x)\\] which is confusing since the plus function has nothing to do with it. Alternative . The soft part of these names makes sense. It’s the function they are trying to approximate that can create confusion. Softargmax and softrectifier would have been more precise. If you can’t shake the feeling that all these terms feel very 1984, you’re not alone. As an alternative, the output of the softmax is also known as the Boltzmann distribution in physics, and as the Gibbs measure in mathematics. Given that information theory has already borrowed entropy from statistical mechanics, maybe we could have called it the Boltzmann function. 4.3 Softmax loss Confusion . Not only is there confusion around cross-entropy and softmax , but to complicate things further they’re often taken as synonyms! Softmax loss (maybe defined first in Liu 2016 ) is essentially the contraction of softmax activation on a dense layer followed by cross-entropy loss — just take the first and last word. It kind of reminds me of the joke where the scientist says: \"My findings are meaningless if taken out of context\" and the media reports: “Scientist claims her findings are meaningless” Alternative . There’s already a name for the cross-entropy loss ⁠— it would have been less confusing to stick with that. Section 5. Neural networks 5.1 Neural networks Confusion . As François Chollet puts it , “[Neural networks] are neither neural nor networks. They're chains of differentiable, parameterized geometric functions.” The term has stuck as a reference to natural neural networks, by which they were partially inspired, but there’s no evidence they might be a plausible model of the brain (Chollet 2018, page 8). And yet, I think the term is able to convey a useful structure of the representation, both conceptually and visually, in the same way that the term decision tree does. Alternative . “Differentiable, parameterized geometric functions” is probably not the way to go. Not sure why I read them all, but there are other... interesting ideas from Chollet’s twitter thread: functionchain (in the wake of blockchain ), multi-layer modeling (possibly a bit too close to multi-level marketing ) and my favorite, chain train . 5.2 Multi-layer perceptron Confusion . A multi-layer perceptron (MLP) is not a perceptron with multiple layers. It’s a neural network (sorry, Chollet) that contains many perceptrons (sort of), organized in layers. Peeling the onion, it’s a function composed of simpler functions that maps some set of input values to output values (Goodfellow 2016, page 5). A multi-layer multi-perceptron network, if you will. The reason why even this term is not rigorous enough is that usually perceptrons use a step function as activation, while the nodes of an MLP use continuous activations, which allows its weights to be trained with backpropagation. Also, usually perceptrons are thought of as linear classifiers, while MLPs are thought of as non-linear regressors or probabilistic classifiers. The “usually” above is because a plethora of variants for these algorithms exist. But even considering all of them, an MLP is not a P with ML. Alternative . Sometimes an MLP is simply referred to as a feed-forward neural network (Murphy 2012, page 563), although this term is more general, and comprises in principle any directed acyclic graph trained with backpropagation (Goodfellow 2016, page 168). Maybe stacked logistic regression would have been more appropriate or, again, my favorite: plain chain train . 5.3 Input layer Confusion . The standard presentation of a multi-layer perceptron includes the statement that this architecture is composed of at least three layers of neurons: an input layer, a hidden layer , and an output layer (Haykin 2009, page 21). An artificial neuron (sorry again, Chollet) is supposed to 1) receive inputs, 2) combine them (often linearly), and 3) produce an output (often non-linearly). Instead, the neurons in the input layer start with a value, do nothing, and hand it off to the next layer. They perform no computation, and the already precarious abstraction of an artificial neuron becomes even more problematic. Most textbooks recommend not counting it in the number of layers of a network (Bishop 2006, page 229). Alternative . Whatever. 5.4 Hidden layer Confusion . Some textbooks report that hidden layers are named this way because this part of a neural network is not seen directly from either the input or output of the network (Haykin 2009, page 22). The name is confusing because hidden layers are not any more hidden than the internals of any other machine learning algorithm. As in the black box discussion, they are entirely transparent. Maybe this term is still around because, in an alternative context, one can think of them as representing latent concepts not explicitly present in the training data (Goodfellow 2016, page 6). Alternative . Given that latent variable is more common than hidden variable (see the number of hits on Google Scholar for the former versus the latter ), maybe latent layers would have been slightly less confusing. Section 6. Deep learning 6.1 Tensor Confusion . In machine learning, a tensor \\(T\\) is a multi-dimensional array (Goodfellow 2016, page 33), i.e. the generalization of a matrix to an arbitrary number of axes. So if a matrix size can only be \\(m \\times n\\), a tensor can be \\(m \\times n \\times p \\times ...\\) In physics, on the other hand, a tensor is an element of a tensor product that behaves in a particular way under a change of coordinates. A tensor is something that transforms like a tensor (Zee 2013, page 313). In formula (Dodson 1991, page 105), given a vector space \\(X\\) and its dual \\(X^*\\) \\[T \\in X \\otimes X \\otimes ... \\otimes X^* \\otimes X^*\\] This definition implies that if the dimensionality of \\(X\\) is \\(d\\), tensors can only be of size \\(d \\times d\\), or \\(d \\times d \\times d\\), etc. In fact, a physicist is familiar with: the inertia tensor (\\(3 \\times 3\\)) the stress tensor (\\(3 \\times 3\\)) the electromagnetic field tensor (\\(4 \\times 4\\)) the permutation tensor (\\(n \\times n \\times ... n\\) times) In principle, one could define a tensor to be an element of any tensor product \\(X \\otimes Y\\), but that’s not how physicists (and most mathematicians) talk about it. So while all physics tensors are machine learning tensors, the reverse is not true. The machine learning definition has retained only the “multi-dimensional array” aspect of the original one, and relaxed every other constraint. The reason might be that the notation and tools of tensor calculus were convenient to keep around, or that other fields adjacent to ML had already generalized the concept, or both. This is a great example of how a concept can evolve over time without changing name. Alternative . In computer science, the generalization of a matrix is often just called a multi-dimensional array , although dimension in this context refers to the number of indices needed to specify an element and not to the total number of elements. Another term was coined in the mid 1980s by Moon and Spencer: holor (Moon 1986). It didn’t quite stick though. A search on Google Scholar reveals that only about 1,000 papers have chosen to use this term as of today. Had it been adopted more broadly, now we might have HolorFlow and Holor Processing Units . 6.2 Convolutional layer Confusion . In mathematics, the convolution over a matrix \\(A\\) with a kernel \\(K\\) is defined as (Goodfellow 2016, page 332): \\[S(i,j) = \\sum_m \\sum_n A(i-m, j-n)K(m,n)\\] while the cross-correlation over the same objects is defined as: \\[S(i,j) = \\sum_m \\sum_n A(i+m,j+n)K(m,n)\\] The difference between the two operators is just the reflection of one of the two functions. They both involve sliding the kernel across the matrix (e.g. an image), but convolutions flip the kernel while cross-correlations don’t. In fact, for the sake of simplicity, many animations around the web that try to explain convolutions really display cross-correlations. How about the implementations of convolutional layers in common libraries ⁠— do they use convolutions? No. Both TensorFlow and PyTorch implement the simpler cross-correlations instead of convolutions. Does it matter for model performance? Also no. The parameters are learnable, and if convolutions were implemented instead, the layer would just learn the flipped orientation (Goodfellow 2016, page 333). Alternative . As far as I know there is no term for their superset, so sticking with one of the two seems like it was the best option. Convolutions are more common in computer vision than cross-correlation, so that might be a reason the term was chosen. Either way they would have been called CNNs! 6.3 Deconvolutional layer Confusion . In mathematics, the deconvolution is a process that tries to find the original function \\(f\\) that was convolved with a filter \\(g\\) to give the output \\(h\\), \\[f*g=h\\] if the output and the filters are known. In machine learning instead, the term has been used as a synonym for transposed convolution (see Zeiler 2010 ), which is an entirely different operator . Alternative . Sticking with transposed convolution would have made the most sense. 6.4 BERT Confusion . In the Bidirectional Encoder Representations from Transformers, the confusing bit might be the bidirectional part. The encoder of a transformer looks at the whole sequence at once using self-attention, there’s really no directionality involved. Alternative . It’s been suggested that non-directional would be more appropriate. So... NERT? 6.5 RNN gates Confusion . A gate, in recurrent neural network parlance, is defined as a unit that applies a logistic sigmoid to an input vector, squashing its elements between 0 and 1 . The activated vector is then multiplied element-wise with another vector, effectively selecting how much of each component is let through to the next step. The function of the gates is to protect and control the cell state. A common LSTM layer is composed of three gates: information gets into the cell thanks to the input gate , stays in the cell thanks to the forget gate , and exits the cell thanks to the output gate . The most confusing term is the forget gate. If one follows the above logic, when an element of the activated vector is \\(1\\) it means that the component will be completely retained. So the action the gate controls is to remember, not to forget. Alternative . A better name for the forget gate might have been remember gate (or keep gate , as it is sometimes referred to). Input gate and output gate are not confusing, but maybe better names would have been write gate and read gate . Conclusion Knowing why a term is confusing can shed light not only on subtleties of meaning, but also on the history of the underlying concept it represents. It’s also a great excuse to strike up a conversation at parties, tell people they’re wrong, and implicitly claim your superiority. Speaking of which, a training set is definitely not a set. Interested in working with a team that's just as interested in how you work as what you're working on? Check out our open positions and apply . References [Bishop 2006] Bishop, C. M. (2006) Pattern Recognition and Machine Learning . Springer. [Chollet 2018] Chollet, F. (2018) Deep Learning with Python . Manning. [Choromanska 2019] Choromanska, A. et al (2019) Beyond Backprop: Online Alternating Minimization with Auxiliary Variables . arXiv. 1806.09077 [Deisenroth 2020] Deisenroth, M. P. et al (2020) Mathematics for Machine Learning . Cambridge University Press. [Dodson 1991] Dodson, C.T.J. et al (1991) Tensor geometry . Springer. [Goodfellow 2016] Goodfellow, I. et al (2016) Deep Learning. MIT Press. [Haykin 2009] Haykin, S. (2009) Neural Networks and Learning Machines . Pearson. [James 2017] James, G. et al (2017) An Introduction to Statistical Learning . Springer, 8th Edition. [Kang 2018] Kang, D. et al (2018) Model assertions for debugging machine learning . NeurIPS MLSys Workshop. [King 1986] King, G. (1986) How Not to Lie With Statistics . American Journal of Political Science. 30 : 666–687 [Lee 2015] Lee, D. H. et al (2015) Difference Target Propagation. arXiv. 1412.7525 [Mann 2010] Mann, P. S. (2010) Introductory Statistics . Wiley, 7th Edition. [Moon 1986] Moon, P. et al (1986) Theory of Holors: A Generalization of Tensors . Cambridge University Press. [Murphy 2012] Murphy, K. (2012) Machine Learning: A Probabilistic Perspective . The MIT Press. [Nelson 2015] Nelson, K. et al (2015) Evaluating model drift in machine learning algorithms . IEEE, CISDA. [Plaut 1986] Plaut, D. C. et al (1986) Experiments on Learning by Back Propagation . Technical Report CMU-CS-86-126. Carnegie-Mellon University. [Qian 1999] Qian, N. (1999) On the momentum term in gradient descent learning algorithms . Neural networks. 12 : 145–151 [Rumelhart 1986] Rumelhart, D. E. et al (1986) Learning representations by back-propagating errors . Nature. 323 : 533–536 [Scellier 2017] Scellier, B. et al (2017) Equilibrium Propagation: Bridging the Gap Between Energy-Based Models and Backpropagation . arXiv. 1602.05179 [Schelter 2018] Schelter, S. et al (2018) On Challenges in Machine Learning Model Management . IEEE Data Eng. Bull. 41 : 5-15 [Wright 1921] Wright, S. (1921) Correlation and causation . Journal of Agricultural Research. 20 : 557–585 [Zee 2013] Zee, A. (2013) Einstein Gravity in a Nutshell . Princeton University Press. [Žliobaitė 2010] Žliobaitė, I. (2010) Learning under Concept Drift: an Overview . arXiv. 1010.4784", "date": "2021-02-18"},
{"website": "Hubspot", "title": "Eric Richard, SVP of Engineering at HubSpot, Named a Great Leader for All by Great Place to Work®", "author": ["Nadia Alramli (She/Her)"], "link": "https://product.hubspot.com/blog/eric-richard-great-leader-for-all", "abstract": "Today, Eric Richard, HubSpot’s SVP of Engineering, was recognized as a Great Leader For All by Great Place to Work® . This award recognizes much more than just his achievements in his SVP role, though. Eric’s the Co-Executive Sponsor of our Women@HubSpot Employee Resource Group, and a loving father and husband. He’s also an advocate and ally for diversity, inclusion, and belonging at HubSpot and in our community. And, he’s one of the most humble and empathetic leaders I’ve ever had the pleasure of working for. Here are a few reasons why: Always Be Growing, Always Be Listening Before my first day at HubSpot, Eric was committed to helping me succeed. During the three months between accepting my offer and my first day, he spent the time onboarding me via email. Days, nights, weekends, he tirelessly answered all of my questions. We talked about the company, the product, and team strategies. No question was stupid or out of bounds. I would ask a simple question, and he would answer with a paragraph. I was floored by how he was investing in someone who hadn’t even started yet. That level of support from a leader was absolutely incredible. In my mind, I hadn’t even shown my value, and here he was, answering my questions and encouraging me. Eric has always made me feel empowered to do my best work by including me in every conversation, so that I always have the information I need to solve complex challenges within our product for our customers. He leads by listening, creating a space of psychological safety that allows his team to feel confident speaking up, sharing ideas, and giving him feedback so he continues to grow right alongside us all. Baking Diversity, Inclusion, and Belonging into Our Team Culture As a leader on the Product and Engineering team , Eric’s very vocal about the importance of emphasizing diversity both within our teams and during the hiring process. And I’ve seen how this commitment has paid off. Eric was brought into HubSpot six years ago with a mission to scale the size of the Engineering team and the breadth of the products we build. In addition to shepherding impressive growth, Eric has never let the focus on diversity fall to the wayside. (You can learn more about how we’re moving the needle on representation in Product and Engineering in HubSpot’s 2020 Diversity Report .) Of course there’s still a long road ahead, but Eric’s work has made traveling that path even smoother. One thing he instills in every leader, manager, and individual contributor is the understanding that creating an inclusive workplace where everyone feels as though they belong isn’t just something to talk about: it’s part of our job. To this end, we’ve written diversity and inclusion into HubSpot’s Engineering Leadership values under Eric’s guidance, including bullets on fostering a sense of team and mission through “strong, inclusive team-building” and the importance of “representing our mission, culture , and commitment to diversity, inclusion, and belonging to candidates.” In this spirit, our team has taken the opportunity to clearly communicate all of the ways current HubSpot Engineering employees can be allies. The latest on our internal Wiki, “No More Excuses: Actionable Ways You Can Impact Diversity, Inclusion, and Belonging Today,” includes everything from attending employee resource group meetings and volunteering for events put on by HubSpot’s Diversity, Inclusion, and Belonging team to asking how you can help the recruiting team with sourcing and hiring diverse candidates . One thing I especially admire about Eric’s mission as SVP is to lead by example—he knows it’s not just about what he does, but also about how he helps the employees he leads to become better people, both at work and in their own lives. Amplifying Other’s Voices In my first one-on-one with Eric, he said, “I want you to question the status quo. I want you to come in with your own ideas and feel like you can challenge me.” The idea that a leader would say that to a new hire on their very first day stuck with me. Anyone who gets to know Eric, though, knows that making a space for others’ voices to be heard is just a part of who he is. Whether he’s interviewing female engineering leaders through HubSpot’s Name Dropping Q&A series , or encouraging all employees to take part in discussions for our Diversity, Inclusion, and Belonging Book Club series, he epitomizes HubSpot’s values of HEART found in our Culture Code and reminds us all of something that can be too easy to forget: when it comes to fighting inequality, there should be a shared responsibility for everybody to participate. Congratulations again to Eric for being recognized as a Great Leader for All by Great Place to Work! All of us at HubSpot are so lucky to learn from such a humble and empathetic leader who cares so deeply about creating a workplace where everyone feels welcome. I’ll leave you with Eric, in his own words, talking about what this year’s International Women’s Day theme, “Each for Equal” means to him.", "date": "2020-03-05"},
{"website": "Hubspot", "title": "Open-Plan Offices", "author": ["Zack Bloom"], "link": "https://product.hubspot.com/blog/open-plan-offices", "abstract": "Open Plan Offices Generally Suck, Scientists Prove http://t.co/1fgLifZRI4 #duh — Joel Spolsky (@spolsky) September 19, 2013 At HubSpot all but a handful of our 600 employees work at open desks, including the executive team. In fact, we've taken it a step further an introduced shared desks and lockers for workers who don't need any sort of private space whatsoever. So are we fools following trend rather than the wishes of our workers? Are our employees lying to us when they claim that the open offices lead to more collaboration and create a more communal atmosphere? In an open plan office, conversations happen in person. When everyone has a separate office, more conversations happen over email or IRC. We believe that the face to face communication is the best way to build great things. Culture and conviviality is born from spending time with people, plain and simple. If we weren't in close contact, it wouldn't happen as much. On a personal note, all due respect to Mr. Spolsky, but walking in to 'my office' and closing the door is the antithesis of what I am looking for in a work environment. I love building great software, but great software gets written at Starbucks and in garages every day, a private room is certainly not a requirement. The most rewarding experiences I have had in software have come from working with others, without that it would all be much less rewarding. Ground Rules You need to be comfortable with wearing headphones. Most people listen to music, some white noise, but they are critical. It's a good idea to begin an interaction over chat (\"have a few minutes?\"), before walking over to someones desk. You need meeting rooms. Private, loud or embarrassing conversations need to happen every day, people need a place to go. You have to like the people you work with to like an open-plan office.", "date": "2013-09-18"},
{"website": "Hubspot", "title": "4 Questions To Ask Before Starting Your Career in Product", "author": ["Peter Casinelli"], "link": "https://product.hubspot.com/blog/4-questions-to-ask-before-starting-your-career-in-product", "abstract": "Thinking about your career after college can be an intimidating process. I recently graduated from Boston College and joined HubSpot’s engineering team so it wasn’t long ago that I was interviewing for my first job out of college and wondering, like millions of undergraduates today, where I would start my career. During college, “career decisions” are short term; internships usually last a few months throughout the year or over the summer. The great thing about an internship is that if you realize the company isn’t necessarily for you, you have the flexibility to leave at the end of the summer. In the real world, it’s important to find a place to start your career that fits you best; somewhere you will want to stick around after three months and, most importantly, at a place that allows you to grow, learn, and make an impact. I know my decision to work at HubSpot was the right one because nine months later, I am still excited to come into the office every day. So, I want to share some questions that are important to consider while searching for the best place to start your product or development career. 1. What technology stack will I be using? For my first job, I wanted to work for a company that was using the latest languages, frameworks, and tools to build great products. That’s why when I interviewed for a development position, I always asked about the company’s technology stack. Ask your interviewers to elaborate on which languages and tools the front end and back end engineers most commonly use to build their applications, and whether they are exploring any newer technologies. You may not have a perfect understanding of which languages or technologies you prefer yet, but by identifying their tech stack, you can research other companies using the same technologies to gauge if they are on the cutting edge or behind the times. In my experience, it was clear from the responses to these questions whether or not a company was always improving and finding better ways to solve problems for their customers, or if they were stagnant and potentially approaching technical or product bottlenecks. You want to be working with technology that gives you the freedom to contribute new ideas, be creative, and ultimately grow your technical skills faster. On the Sidekick team, our front end stack includes CoffeeScript and Backbone.js, and our back end stack includes Python, Java, and Kafka. Recently, our leading front end engineers at HubSpot explored Relieving Backbone Pain with Flux & React and released an open source store for Flux . As a result, our team is integrating these new front end technologies in areas where we can improve our product’s speed, reliability, and functionality for our customers. 2. Will I love spending my time on this product? In college, you had limited time in each class Monday through Friday and throughout the week, you started and finished homework assignments for several classes. In fact, you were never talking about or working on the same thing from the morning to the evening every day. A fundamental question I asked myself when considering HubSpot was- will I want to spend all of my time working on this product? Your time is important, so make sure you spend it on something that you love and are passionate about. Think about who your product’s users will be. Do you want to build new features, answer support tickets, and fix the issues facing these customers? Do you want to fix different problems for different customers? Or, do you want your users to be other engineers at the company for whom you can build amazing infrastructure that enables them to create the next best product? You might not know the answers to these questions, but I recommend joining a company where these options are available. On Sidekick, I work on the core product team but also get to answer support tickets and fix bugs for our customers. We work on problems that directly affect users and paying customers, and we can see the impact our contributions have on our product and customers. Not only do I get to help our customers every day, but I often collaborate with our support and sales teams. All of these aspects of my job are an important part of why I love my job. 3. Who will I be working with? Since we have time on our minds, have you thought about the fact that you’ll be spending all of your time working on a product with other people ? People starting their career often focus on salary, vacation time, or perks. But the reality is that you will spend more time with your coworkers than you will with your family, friends, or roommates. That’s why it is unbelievably important to find a place where you love the product and the people who are working on it. When Drew Houston, the CEO of Dropbox, gave a Commencement address at MIT in 2013, he said: \"They say that you're the average of the 5 people you spend the most time with. Think about that for a minute: who would be in your circle of 5?”Follow this mentality when you are interviewing for jobs. Ask about your potential coworkers. Who will be managing you? What are they currently working on and what have they worked on in the past? Will you be in an environment where people will help you grow, and you will help others grow? At HubSpot, I get to work alongside incredibly intelligent problem solvers (who I actually like spending time with outside the office, too). My tech lead has a PhD and Masters degree in CS from MIT and reviews my code, and our marketing, sales, and product efforts are led by a group of HubSpot VPs that founded Sidekick and share their experiences with the entire team. As a result, I am becoming not only a better software engineer, but also have the ability to grow and learn about running a successful business. 4. Will I be working towards achieving my goals? Throughout this entire process, understand the goals you want to achieve at your full time product or development position. Do you want to start your own company some day? Or, do you want to become a product lead or senior level engineer? Again, you don’t need to have definitive answers to these questions, but consider where you might see yourself in one, three, or five years and strive towards finding a place where your time is spent on achieving these personal and professional goals. Why? Because that mindset provides a simpler and easier way to consider different opportunities; will company A give you the opportunity to reach your goals? Will you be spending time learning the skills and working alongside people that will help you reach these goals at company B? You may have noticed that I mentioned several questions for you to use both before and during the interview process. None of them were about salary, vacation time, or if there are ping pong tables at the office. You’ll find that when you start your career, working with the right technology stack on an interesting product with amazing people trumps anything else. Not only will you love what you do, but you will also spend your time achieving your new goals and aspirations.", "date": "2015-03-31"},
{"website": "Hubspot", "title": "3 Interesting Marketing Product and App Ideas", "author": ["Adrian Mott"], "link": "https://product.hubspot.com/blog/bid/84486/3-interesting-marketing-product-and-app-ideas", "abstract": "I've spent some time this week going over some of the awesome ideas that HubSpot users throw our way on our UserVoice collaboration website ideas.hubspot.com .  I must say, I've been very impressed with the level of thought and detail that has gone into the ideas that are popular on the site.  Our customers rock. In fact, some of the most interesting ideas I found closer to the bottom of the list.  I'm not sure that these ideas are  not more popular because they're not quality, I just think people don't see them because UserVoice has pagination in its user interface and these ideas get lost much like search results on page 2 and 3 get lost.  It's something to think about - is pagination broken?  Oh well, that's another post entirely... My point for writing this post was to surface some of the ideas that I found in the depths of the ideas bucket. There are seemingly lots of opportunities for developers who are interested in creating a marketing app of any sort to pick one of these up and run with it.  Remember, HubSpot marketing apps cover a VERY wide range of subjects, like lead generation, social media (yep, it's marketing!), analytics, SEO, blogging, etc... the list goes on. Provide video analytics within HubSpot - This idea was originally written to integrate Vimeo Pro with HubSpot, but I think it can go further.  Professional marketers are constantly trying to make forays into the video space, and much of the time it's very difficult to measure the results from a video that is produced.  The leading video hosting providers (YouTube, Vimeo, Brightcove, Wistia, etc...) have excellent APIs that provide analytical information that marketers everywhere are after.  An app like this on HubSpot would be an excellent difference maker. Show Leads that have Blog Comments - This connection is an excellent example of a way to connect one's blog with leads that are converting.  A small analytical app like this one would go a long way in letting marketers know who to target with middle of the funnel techniques like lead nurturing, and who is already converted as a lead.  Also, this app could be relatively easy to implement, using the HubSpot Blog and Leads APIs. Create an E-book builder app - This idea actually comes from someone on our marketing team, and is too good an idea to pass up offering here. Ebooks are one of HubSpot's most successful lead generation mechanisms.  Yet they are not quick to build and our customers are intimidated by the thought of creating ebooks . So this idea has everything to do with making that process easier. There is a tool like this for Wordpress , I'd love to see something similar on HubSpot.", "date": "2012-03-27"},
{"website": "Hubspot", "title": "Meet the Movers and Makers: Maja Djordjevic, Senior Software Engineer", "author": ["Rajathurai Nagarajah"], "link": "https://product.hubspot.com/blog/meet-the-movers-and-makers-maja-senior-software-engineer", "abstract": "Name: Maja Djordjevic (pronounced Maya Georgey-vich; it’s Serbian) Role: Senior Software Engineer (Dublin office) What are you reading right now? Zero to One – I saw it mentioned so many times online and picked it up. It’s by Peter Theil, one of the PayPal founders, all about how to invent new things and bring them to market. How do you like your coffee? Strong, short and Italian. On a bad day or weekend, make that a cappuccino. Why did you decide to study Computer Science? I love to work out problems, so when I was checking out the degrees available at the University of Belgrade, the two obvious choices were Maths and Computer Science – I was lucky enough to find a uni that let me major in both! They also qualified me to teach kids in both disciplines, but right now I really enjoy being the one learning and working on my craft, so you probably won’t find me in front of a classroom soon. What does your typical day look like at HubSpot? (What projects are you working on? What kinds of meetings do you have?) I spend most of my time in the code cave. HubSpot is great because of how little overhead there is – I spend very little time in meetings or my email inbox. Most of the time I’m writing code, investigating bugs, and watching our error-reporting dashboard. I work on the email team, and mostly focus on the backend (Java & Python), while the rest of the team makes the frontend look great (in React & Backbone.) The rare meetings I have usually involve catching up with my small team to figure out what’s next. How is the engineering culture at HubSpot different from other companies you've worked at? The speed we get code in front of customers is what’s special. At my last company, we worked on a big release for 3 years before shipping it to customers. Here, I can code a fix and have it in front of a customer in 10 minutes. Our engineers deploy hundreds of times a day, a little bit of HubSpot at a time. We have a policy to make sure new engineers code and deploy a bugfix or feature on their very first day; this really embodies our GSD (Get S%&* Done) attitude. What's your favorite thing about our Dublin office and team? I love the size of the team. I know everyone here, there are ~20 engineers in Dublin right now, but we get to work on these big, interesting problems for a lot of customers. It’s like a startup with none of the downsides. What's been your proudest moment at HubSpot so far? (Don't be shy!) Every year I go to INBOUND (the inbound marketing conference in Boston, hosted by HubSpot)and I meet customers who are starstruck to meet a developer that makes their email tool. And every year, I am so amazed and proud that I was part of building this best-in-class software that people love to use. Want to get to know more movers and makers? Be sure to check out Síle Brehony's in case you missed it!", "date": "2015-07-21"},
{"website": "Hubspot", "title": "Why We’re Building HubSpot’s Next Big Product in Dublin", "author": ["Christopher O'Donnell"], "link": "https://product.hubspot.com/blog/why-were-building-hubspots-next-big-product-in-dublin", "abstract": "When we opened a HubSpot office in Dublin five years ago, there were no plans of starting a product team. We were going to invest in sales, marketing, and customer service to grow our customer base and community in Europe, not in software development. And we would have made a huge mistake. The product team in “DubSpot” is 70+ employees and counting today, including engineers, product managers, product designers, and product leadership. They build some of HubSpot’s core software that over 31,000 customers use including our email tool, mobile applications, and freemium products. Now, we’re building our third line of business completely out of Dublin, the Customer Hub that’ll launch in 2018. In Europe alone, the customer service space is a €3.2 billion market. That’s nearly double the market for marketing software. There’s a ton of opportunity globally to introduce a customer service platform to our customers and community that’s inbound , that changes the way people think about customer support. So how’d we go from no plans of building software in Dublin to growing a core product team there? I think it’s more than just “talent”, it’s the hard and soft skills that tech talent has brought to the table from day one. The inaugural engineering team was small but mighty. Most of them came from big companies like Microsoft and IBM, and yes they were strong developers, but they were hungry, too. They wanted to get their hands on real customer-facing applications. Today, they’re tech leads in our Cambridge and Dublin offices. It’s not just that we’ve been able to hire product people, it’s that the product people we’ve hired in Dublin are ambitious, creative, and hilarious. I don’t go to Dublin as much as I’d like to (my kids are both under four, and they’re pretty cool) but when I do, we.have.the.craic. And over the next few years, we’re going to invest a lot in scaling that craic across the product org. Not only is engineering talent strong in Ireland, but we’ve hired amazing design, UX, product management, and analytics people to the team over the past two years. Not to mention, leadership with Barbara McCarthy and Sile Brehony running engineering and product respectively in DubSpot. And we plan to double down there. We’re trying to drive a really modern go-to-market strategy that looks more like Atlassian than some bigger corporations, by building out a growth R&D team to offer more free products and self-service support and sales. Most of that is happening in Dublin. When I think about why we started a team in Dublin and why we’re bullish on growing it over the next few years, it’s because of the people. The talent is bar none, and I think we’ll see more and more orgs moving core product to Ireland as a result. It’s a good time to be a tech company in Dublin, but I think it’s an even better time to be a product person. We’re currently hiring a Director of Product in Dublin. If you, or someone you know, is interested, visit the job opening here .", "date": "2017-11-06"},
{"website": "Hubspot", "title": "The Design Process That Helped Us Ship a New Product in 11 Weeks", "author": ["Jonathan Meharry (He/Him)"], "link": "https://product.hubspot.com/blog/design-process-ship-a-new-product-in-11-weeks", "abstract": "Talk to any engineering team about their process and you’ll hear a common theme: speed. There’s an entire culture around shipping fast and deploying constantly. But getting an MVP out the door isn’t just about making sure it works. It also has to have a valuable user experience. That’s why it’s critical to have a design process that doesn’t just keep up with development, but helps designers stay one step ahead. Designers should play a key role in every iteration of a product from concept to launch, and beyond. I saw how much of an influence that can have on a final product while working on Tally, a light-weight app we created to get feedback from our customers. We use it all the time internally to help us gauge how customers react to new features in the HubSpot product. When we started, we had 11 weeks to design and build the app for our scheduled release. Our Engineers were in our Dublin, Ireland office while our Product Manager, UX Researcher, and myself were at HubSpot headquarters in Cambridge. Because of the distance and tight time frame, we had to come up creative ways to share ideas to make sure we were constantly aligned. Sketching to Set the Pace The clock was ticking so we had to keep it simple. Starting with too many features would mean rushing to the finish line and result in a weaker user experience. Cutting everything you can at the beginning enables you to focus on making a few features really great. As we narrowed down ideas, I would do some rough sketches on paper to clarify those ideas visually. I took pictures of the sketches with my phone, uploaded them to inVision ( our favorite ), and linked them together. I was then able to share a link to the sketches in our HipChat room and the team could click through the flow. This made it incredibly easy for everyone to visualize how the app would work early on and work on iterations together. Collaborating around sketches allowed us to do this very quickly and define the scope of the entire app with a matter of days. The added benefit was that we could imagine how the product would look once we were done, getting everyone energized around the same goal. There was more momentum once we saw what we were working toward. Early sketches of Tally There’s something immediate about drawing out an idea and sharing it with someone. Even if it’s rough, a sketch provides definition and sparks questions. Questions like, “It looks like we removed several buttons, are we taking away those features?” Design plays an important role in simplifying the problem. And the simpler a design, the faster you can build it. Communication is the Most Powerful Design Tool With all the screens defined and the overall flow in place, we then moved on to high-fidelity mockups. As I designed the mockups, I would replace the sketched versions of each screen. That way, everyone could keep going back to the same place to see how the design was evolving and be part of the process the whole time. Turning sketches into high-fidelity mockups After all the screens were designed, it was a matter of turning that into an actual product that looked like the designs. Sometimes, things can break down a bit at this stage. The designer “hands off” the designs and hopes the developer gets it right and knows the intent behind everything we were thinking. At first, we had some back and forth. A developer would ask me questions about details, like colors or font sizes, so we decided that it would be easier if they had the original design document to work off of. I design with Sketch, so I just sent over the Sketch app files. This ended up working really well. They were able to inspect all the elements and easily export anything they needed. I think we were able to remove a ton of friction from our process by keeping an open dialogue like this every step of the way and by getting everyone on the same page early. The more we communicated, the better the end product started to look. Sometimes that meant working together to figure out the best plan of attack, other times it was as simple as sending a design file with an icon on HipChat right when they needed it. I even made a few UX related pull requests on GitHub to try and compliment their workflow. Things like this take minimal effort but can make a developer's life way easier. Staying engaged throughout the process did two things: it helped keep the execution aligned with the design and helped me to build trust with the developers. When design is integrated really well within an engineering team, it not only helps ship stuff fast but also ships a delightful user experience. Fast Design Doesn’t Have to Be Bad Design On a weekly basis, it’s not uncommon to hear someone say “I love Tally!” We even had someone that uses Tally a lot give a presentation titled, “Tally: A Love Story”. It doesn’t just work, users actually love using it. That response is a result of all the little steps we took to get to production; if we didn’t take a scrappy, collaborative design approach, Tally would have been a totally different experience. Tally in action It also helped to have amazing developers. It made executing designs much easier because they could infer interactions from the static mocks, injecting their creativity into the process. Their execution inspired my design and my design their execution. That’s why if you’re a designer, you shouldn’t underestimate the power you have to influence the direction of a product. The minute you put something on paper, it becomes a reality that people can talk about it. Then you can gather feedback, iterate on ideas that are tangible, and work closely with your team to bring that idea to life whether you have 3 months or 3 weeks. Sometimes design can be seen as something that slows engineering down. At HubSpot, we know that design should do the exact opposite. Smart product design simplifies problems, freeing up engineers to ship even faster without sacrificing quality.", "date": "2015-04-02"},
{"website": "Hubspot", "title": "Principles for good engineering leadership", "author": ["Whitney Sorenson (He/Him)"], "link": "https://product.hubspot.com/blog/hubspots-engineering-leadership-philosophy-part-2", "abstract": "In our recent post about how we do engineering leadership here at HubSpot, we shared our philosophy about what engineering leaders should focus on. We encourage our engineering leaders to be primarily product-focused (and, to a somewhat lesser degree, people-focused) rather than spending most of their time driving a process or managing people. This kind of leadership stands in stark contrast to the kinds of leaders who primarily care about administering and health-checking teams, or are on the hook for making sure their employees did the things they were supposed to do. But expecting our leaders to focus on both product and people isn’t easy. As part of our process to expand our engineering leadership, both by promoting internally and hiring externally, we wanted to identify and distill the leadership qualities that we’ve found to be most effective. By focusing on these seven principles, leaders can make sure they’re building healthy teams and great software. What we’ve outlined below certainly isn’t a set of explicit rules or a checklist of behaviors. Rather, we’ve found success in aligning our leadership efforts towards a specific style and mission, while leaving space for leaders to interpret and play to their strengths. We think leaders should: 1. Build trust, respect, and empathy, and use that as a base to deliver radical candor. We’re big on Radical Candor here at HubSpot. We believe it’s the best way to help each other learn and grow. Radical candor means that you give the people you manage guidance (both in praise and in criticism) directly. And you do it directly, and quickly, because you care about them as people. You must deliver that guidance from a base of trust and respect, because if you don’t, your praise can feel insincere and your criticism can feel aggressive. When you take the time to build that base in an authentic way, the people who work for and around you are much more likely to feel like you’re a strong supporting character in their careers. That support will make you considerably more likely to get your message across. 2. Foster a sense of team and mission. HubSpotters consistently rank their team and co-workers as their favorite thing about working at HubSpot. This doesn’t happen by accident; building strong, inclusive teams with cohesive social bonds takes a massive amount of forethought and work. But that forethought and work is an integral part of leading a team, because having strong teams is paramount to our success as a company. Evidence has shown time and time again that teams who work well together are happier, more productive, and retain better. But building a strong team isn’t enough, because a team without a mission is like a sailboat without a mast. Leaders should be able to instill a strong sense of mission in their teams, and those missions should be feasible and compelling. A team’s mission is like a north star — it can keep that team moving in the same direction, together. 3. Have strong working relationships across the organization, from the tech leads and the individual contributors who report to them, to the product managers and designers their reports work with, to their peers & the executive team. As our organization becomes increasingly complex, cross-team collaboration becomes more and more of a challenge. Leaders help act as the connective tissue between teams, and build relationships that help them reach across organizations in order to deliver results. Good leaders will have a high-level overview and a deep understanding of the work going on around them so that they can connect people who need to be connected and break down silos. 4. Understand our customer and business needs. We think engineering leaders should be active participants in developing our product strategy, because our main goal as a team is to deliver products that solve real needs for our customers. Leaders should deeply understand the customer — their needs, pain points, and motivations — because it’s hard to guide a team when you don’t thoroughly understand who you’re solving for and why. Furthermore, engineering leaders have counterparts in Product and Design, and without product context, it’s difficult to relate to those counterparts and to prioritize work effectively. If you don’t know how important a new feature will be to customers, it’s hard to determine whether refactoring part of the codebase is more important. Good leaders will have enough context to understand the impact of these tradeoffs. 5. Understand how we build and why. We want leaders to deeply understand our technical strategy primarily because it allows them to develop empathy for the teams and the problems they’re solving. That empathy helps them understand the technological headwinds that might make a team’s mission more difficult, or the constraints that could turn a viable solution into an inviable one. Understanding how things are built lets leaders identify how and when to coordinate with other teams, and helps them effectively guide their teams in tackling technical challenges. This means that leaders should also cultivate a gut feeling about what’s simple and what’s complex, or when we should move quickly and invest in the product and when we should slow down and take the time to invest in the platform. Leaders can then better advise teams to undertake long-term work when they’re on the right path, and encourage teams to move quickly when they’re still figuring out the best path forward. Developing that deep understanding is the best way leaders can help their teams grow to do the same. 6. Represent our mission, culture, and commitment to diversity, inclusion, and belonging to candidates. Recruiting is integral to our growth, and leaders can make a big impact when it comes to recruiting and hiring the next generations of builders and leaders. During the hiring process, candidates should have access to the leaders they’ll be working with every day, and accordingly, those leaders should be adept at conveying our culture and values. That scope of access is a big advantage in an extremely competitive hiring market. 7. Get team members and candidates excited to take on new challenges. Because we’re growing, and quickly, our teams are constantly shifting and changing as new employees join and new missions and teams are spun up. Leaders need to embrace this change. And because leaders have a better overview of what’s in the works, they should always be looking for opportunities for their team members to take on new challenges and grow. This means that they need to know the people on their team deeply, so that they have a good sense of what opportunities will be a good match for someone’s skills and interests. And when those opportunities arise, they need to be able to encourage their reports to try new and sometimes difficult things. The principles outlined above are aspirational — no one is a perfect leader, and no one gets leadership right all the time — but we hope these principles will help our leaders guide their teams to deliver great software to our customers, and help us build a company where the people who create that software enjoy doing it. If you’re an engineering leader who’s excited about these principles, and thinks they fit your leadership style? We’d love for you to get in touch — we’re hiring . Or, if you’d like to learn more about our team and how we build software, check it out .", "date": "2018-04-04"},
{"website": "Hubspot", "title": "Introducing HubSpot Custom Objects", "author": ["Dylan Sellberg (He/Him)"], "link": "https://product.hubspot.com/blog/custom-objects", "abstract": "Data is the engine of a business. The vast majority of businesses invest significant energy in ensuring their data can be used to its fullest potential to provide value. No two businesses are alike though, especially as your business grows and complexity increases to meet the needs of customers. For those businesses who have grown to that level of complexity, many of them with HubSpot as their primary source of data, they need a customizable solution. Today, as part of our newest suite of Enterprise features, we’re taking a huge step to ensure the HubSpot product meets the needs of your business: custom objects . With custom objects, we want to give those businesses the opportunity to build a data schema that works exactly as they need it to. Our philosophy with custom objects Our product development philosophy at HubSpot centers around ease of use. With every release, we ask ourselves⁠ — “how can we deliver a powerful product while maintaining our gold standard ease of use?” Custom objects were no different. We had to find the sweet spot between a fully customizable database and maintaining ease of use… a magic trick of sorts. A second component of our product development philosophy at HubSpot is to ship early and often. We build features with minimum functionality our customers need and work forward from there. This lean approach to product is what allows our team to ship dozens of impactful updates each day. However, with custom objects we were forced out of our comfort zone, taking a different path. A customizable database can’t provide much value if it’s not powered by the entire HubSpot platform, so we built custom object functionality into the product far and wide ⁠— delivering on a broad set of use cases from Day 1. How it works Exactly how you’d expect. The funny thing about a custom object is that it may seem “custom” to us at HubSpot, it’s certainly not considered “custom” to your business. These data points are a core piece of your business just like anything else. You’ll find custom objects are built with that in mind. Custom objects, no matter where you’re using them in HubSpot, are designed to look, feel, and act exactly like any other object you’re used to. The CRM record for a custom object is practically indistinguishable from your existing CRM records. When using a custom object in workflows, the automation capabilities are nearly identical to those you’ve been using already. Building reports for custom objects works exactly the same way as it has for all other objects. With custom objects, we hope you’ll come to notice that everything just works , exactly as you’d expect it to. There are guardrails where you need them. Architecting a database is no small task. It’s also an ever-evolving one. As your business grows, you need your CRM to meet your growing needs. Every decision is an important one with long-term implications, and we know that sometimes mistakes are made that become a headache to backpedal on. We have a responsibility to do everything we can to mistake-proof, or Poka-yoke , the HubSpot product. Custom objects are a key piece of a CRM implementation so we really doubled down here with mistake-proofing functionality. You’ll notice custom objects can only be defined via API. This guardrail ensures the individual making long-term decisions about the architecture of your database is informed and skilled enough to make a decision of that magnitude. We’re also limiting the number of custom object types a customer can have to 10. More objects are available for purchase, but we wanted to set a reasonable limit for the core product that could protect you from building a database that’s nearly impossible to understand. When doing research for the development of custom objects, we talked to people who have implemented custom objects in other CRMs. They all gave us the same resounding feedback: They overcomplicated their setup and it hurt their business in the long run. With API-only definition and limited object types, we’ve installed guardrails to keep you from experiencing that same pain in the HubSpot CRM . What’s next There’s so much to cover with this release, it’s certainly one of our largest to date. We’re not done yet: the months ahead will have us continuing to double down on making custom objects widely available and extremely easy to use across the product. We’ve only scratched the surface of the potential the HubSpot CRM has to bring to your business. We’re going to continue our relentless focus on bringing power to our CRM without burdening you or your team with difficult to use software. We hope you discover that our first release of custom objects has fulfilled that promise and allows your business to create a powerful CRM that helps you grow better. Sound like the power and flexibility your team has been looking for? Learn more about the HubSpot CRM here .", "date": "2020-09-22"},
{"website": "Hubspot", "title": "Tom Petr is a HubSpotter", "author": ["Elizabeth Dunn (She/Her)"], "link": "https://product.hubspot.com/blog/bid/84985/tom-petr-is-a-hubspotter", "abstract": "Name: Tom Petr Role: Developer at HubSpot Superpower: Metabolizing Caffeine Tom Petr is a developer on the HubSpot Application team, which means he spends his time sweating the details on stuff like the HubSpot login, navigation, notifications, and dashboard. In short, he works on a bunch of things that are close to any true HubSpotter's heart. But none more so than Tom's. Tom comes to us by way of Microsoft, having proudly toiled in the Cambridge NERD Center for two years before joining the HubSpot team. He was born and raised not far from here in Acton, Massachusetts, and studied Computer Systems Engineering at UMASS Amherst. His hero is everybody's favorite number theorist Carl Friedrich Gauss, who Tom says was just \"an all-around badass. Technology as we know it wouldn't exist without him.\" And HubSpot as we know it wouldn't exist without you, Tom. Or at least, we'd have fewer prank hacks popping up all over our internal chat server. And then where would we be? Go ahead and hassle Tom Petr on Twitter at @tpetr . He loves that.", "date": "2012-04-09"},
{"website": "Hubspot", "title": "Customer Empathy Sessions: A tool for better understanding your users", "author": ["Gráinne Smith (She/Her)"], "link": "https://product.hubspot.com/blog/customer-empathy-sessions-a-tool-for-better-understanding-your-users", "abstract": "If you’re a designer, engineer, or product manager building software today, you likely interact with users a lot. You probably run interviews with your customers to identify their wants and needs. You probably collect and analyze qualitative and quantitative user feedback on your product. And you probably conduct usability sessions in order to build useful, usable, and delightful software. We do these things (and more) at HubSpot. The user sits at the heart of how we build our products. And yet, we weren’t always getting things right — even the easy things. Why we need our team to feel our customers pain With a product that spans a full suite of marketing, sales, and customer service tools, and a product team in the hundreds, it’s sometimes difficult to catch every rough edge in our user experience. Sometimes our engineering team would miss silly bugs before a product went out into production. Sometimes the place one team's app connects to another team's app didn’t quite have the smoothest user experience. We realized that while we interacted with customers often, our interviews and research sessions were usually centered on a specific topic, like a new feature. When our engineers QA tested a certain feature before releasing it, they sometimes missed certain edge cases when they didn’t use it the way our customers do on a daily basis. In short, our team’s deep expertise in the tools sometimes led to blind spots — places we didn’t realize were rough edges because we just weren’t seeing the software as our users (especially our less experienced users) do. And so we went to the drawing board. How we could get our team closer to the everyday workflows that our users took in our tools? How could we see our product the way our users do; not just the pieces of the puzzle we were currently working on, but the complete picture? How could we use our product for real? To solve this problem, we developed a method we called a customer empathy session. These sessions are a simple way to help your team spot small bugs or user experience splinters your customers see every day. Below, we’ll outline how to run your own customer empathy session, and give you some templates and tools that will make it easy to try it with your own team. What is a customer empathy session? At its simplest, a customer empathy session involves having a product team take a specific part of their app and try to use it like a customer would. We often set up these meetings over lunch to make sure that the largest number of people can attend. We then give the group a few tasks to complete and a customer persona and scenario to embody for the duration of the session. We invite everyone to these sessions. Researchers, engineers, product experts (our support counterparts), content writers, product managers, technical leads, product designers and data analysts are all included and all complete the same tasks. How to prepare First, you need an agenda . While customer empathy sessions are less formal than usability tests, it pays to do your legwork ahead of time and be prepared. In our case, we ran mock sessions to ensure that we got the timing correct before we brought everyone into the room. We time-boxed each task and made sure everyone moved on to the next one even if they weren’t quite done with the previous one. We also created a collaborative document for taking notes. We sent that doc out to the whole team, and asked everyone to fill it out as they noticed things during the session. We broke the doc down in to the structure of the session, which made it easier for people to find their place and easier for us to analyze the results afterwards. We also asked everyone to take a screen recording of anything off they noticed as part of this process where they could. This resulted in crystal-clear documentation for bugs and UX issues after the session. While ordering treats is optional, sharing cookies or ice cream with your colleagues is a great way to start the session out on a happy note. While the point of the exercise is to personally experience the pain points our customers feel when using our tools, this should be a positive exercise — it’s a time to get the team together and everyone’s thoughts and opinions down on paper. Finally (and most importantly), you should do everything you can to stay as close to your users’ experience as possible. After some trial and error, we’ve found a few methods that work quite well: Give everyone a persona and scenario to embody for the duration of the session In our latest empathy session, we wanted to test an on-boarding experience in our new email drag-and-drop editor, so we wrote up a persona and scenario that aligned with the experience of a novice user. We called our persona James. James is brand new to using HubSpot, but he’s heard great things about it. He’s found an email template online that he really likes, and he wants to try to recreate it in HubSpot, but update it a little to match his brand. We chose this scenario because it’s something that we hear constantly from our customers — they look online for email inspiration, find an email they like, and use it for inspiration in their own email marketing. We gave each participant a template we’d found online, and asked everyone to try to recreate their template in the email editor. Everyone had 20 minutes to build their email template. That’s certainly a tight deadline, but building out templates to pixel-perfection under a tight deadline is something our email users have to do every day. By working with these constraints, every member of the team was able to empathize with our users a little bit more. Add realistic restrictions Our product team is used to working on and seeing the product on large Thunderbolt or retina displays — but that’s not typical of our users’ experience using the tools. In order to work under the most realistic conditions, we pulled data on the average window heights of our email users. The majority of our users had window heights of 938, but there were a lot of users with a height of 626 or 657 — in other words, quite small. To really step into our users’ shoes, each participant was assigned a window height that they weren’t allowed to adjust for the duration of the session. Though the email tool doesn’t receive very high usage on the iPad, we’ve heard from our customers of certain cases where an email marketer needs to get an email out, but might only have access to their iPad. So, we asked some participants to use iPads for the whole session. Include tasks that use external tools As much as we’d like to believe that our customers can use HubSpot for the entirety of their work, the truth is that they actually use a huge number of external tools to get their jobs done. Through monitoring customer sends, we know that our users need to leave the email app quite a lot to get the content that they want to include. The following example shows 4 different customer emails using our editor with Google map images linking to their office locations: James would need to jump through quite a few hoops in order to do this: from the editor, he’d need to open a new tab, navigate to Google maps, search for his company address, screenshot the Google map image of his company’s location, go back into HubSpot’s email editor, drag in an image module, upload the Google map screenshot, go back into Google maps to retrieve the URL for that location on the map, go back into the email editor, and paste in the URL in order to hyperlink the image. Whew! That’s just one example of a case where our users need to leave the app to get the content that they need. We wanted all participants of our empathy session to really get a feel for this type of flow, so everyone was assigned an additional task that they had to complete during the session. Each of these tasks are common tasks that users perform every day outside of HubSpot’s email tool. Adding these tasks to the scenarios gave us a much more realistic idea of how our customers use the product — jumping from tab to tab, trying to find the information they need, and dragging it back into HubSpot. These tasks gave us all the chance to empathize with our users further. The results After running a few of these sessions, we were able to document a huge number of bugs and usability issues in a really short amount of time. This meant we were able to fix these issues before we user tested our new flows, and before they were released to customers. But more importantly, these sessions let everyone on our team better understand our users, and their workflows and struggles. As one of our Engineers commented: “I normally just use the product to work on specific features in silo, but these empathy sessions make me use HubSpot as a customer. That helps me to see the bigger picture a lot better.\" In summary, to make sure you get you really get your whole team to feel customers pain, you should: Get everyone in the room together Make sure you're prepared well in advance so you don’t misuse your teammates' time Use scenarios to really embody the persona Get people to do specific tasks Make sure the tasks are realistic of what customers see and do, including where they're located and what device they're using Think outside of the journey — where customers go next and what they do after they leave your product Food always helps! If you're interested in running your own customer empathy session, we invite you to use any of the templates we’ve created below. We’ve found that these sessions are most valuable before a release or before user tests, but they’re also valuable for finding bugs and usability issues you might not be aware of in existing software. We hope these sessions give you one more strategy to get closer to your customers and continue to erase your blind spots. Feedback template Agenda template Scenario template", "date": "2019-01-29"},
{"website": "Hubspot", "title": "Making our life better with Hudson (?)", "author": ["Wassaf Farooqi"], "link": "https://product.hubspot.com/blog/bid/48832/making-our-life-better-with-hudson", "abstract": "It's been about 10 months since I joined HubSpot.  One of the first things I started doing in my first few months here was to make our Hudson environment happier.  Get it running  in some decent shape, get the unit test building, and get it emailing in cases of real failure.  We made some significant progress on it.  We now have over 70 Java projects in our Hudson environment.  We even have our production python code unit testing happily in Hudson!  We also have an extremely annoying flashing light in our dev area when a build has failed test.  At some point in the future, I want flashing lights from poor code coverage/code quality also, but thats a bit down the road. Unfortunately, our Hudson setup is a bit sad in some areas.  We are using it as a means to run unit test on checkin, but we aren't doing any jar deploys.  Without deploying, scaling our hudson environment horizontally has been a problem.  We scaled it vertically - a bigger server and more executors, but now there are random issues with fingerprint files going bad. The biggest headache has been our massive dependency chain.  Project Z depends on Project Y which depends on Project X.  Hudson does wonderful things to help with this, especially with maven projects (which all our java projects are). When code is checked in, project X builds, and then project Y builds, followed by Project Z.  Now we can see when Patrick deletes code in project X that he broke Project Z.  It's a disaster the other way around.  Project X and Y are both checked in at the same time, and Hudson decides to build them both.  Well, Project Y needed somethign new from project X, so project Y fails and our lights start flashing.  The other annoying one is if Project Z is building, and Project X decides to start building.  Project X builds faster than Project Z ,and does its 'mvn install' while project Z is running.  A bunch of tests now fail in project Z. I'm sure a lot of our problems can be solved by taking the effort to make sure we can deploy the jars and not mess up local environments or test environments.  With jar's deployed, the 'mvn install' won't overwrite a jar file in use.  It will also let us scale horizontally, which has it's whole set of bonuses! For now, Hudson is a mixed victory for us.  We gain a great deal by the test running, but we do so with a decent amount of headaches.  Hopefully we can fix these and have more happy fun times with Hudson in the future! For more information about Hudson, check here .  It's free, [mostly] wonderful, and there is a plugin for almost everything!  In fact, I'll make a post about all the wonderful Hudson plugins we use at some point in the future.", "date": "2010-08-02"},
{"website": "Hubspot", "title": "How to Implement Inclusive Recruiting Practices to Build a More Diverse Team", "author": ["Jared Williams (He/Him)"], "link": "https://product.hubspot.com/blog/how-to-implement-inclusive-recruiting-practices-to-build-a-more-diverse-team", "abstract": "This article pairs with the latest episode of the HubSpot podcast Culture Happens , featuring HubSpot Campus Recruiting Manager Colleen Grant, VP of Engineering Jared Williams, and Engineering Lead Zoe Sobin. Hiring a diverse team is critical to building good software. The advantages of diversity apply to all teams, of course, but when you’re building software, having diverse perspectives in the room leads to a stronger product . Your customers aren’t homogenous, so why would your team be? More importantly, building a diverse team is simply the right thing to do. Unfortunately, building diverse teams is something the tech industry has historically struggled with. At HubSpot, we’re no different. But we’ve decided to tackle this challenge using a unique approach: treating the problem like a customer problem. What does that mean? For us, it’s using a data-driven approach to find gaps in our recruitment, hiring, and retention practices, and finding creative solutions. After all, not having a diverse team says more about your own sourcing practices than the actual talent out there. As HubSpot Product VP Andy Pitre says, “If we are truly hiring the best people, we’ll end up with a more diverse company, because talent is equally distributed. The issue is if we’re only hiring the best people we know.” Here’s a look at some of the strategies we’ve implemented, what we’re working on now, and how you can tailor them to grow your own teams in an inclusive way. Re-examine how candidates get their foot in the door A year or two ago, If you applied to HubSpot for an engineering role, a recruiter would review your information and they’d decide whether or not to do a non-technical phone screen or decline to move forward. If you made it through the resume review and the phone screen, they’d then move you to an automated coding test, or right to an interview with our team. As we reviewed applicants that we previously decided to pass on, something clicked: we were letting our biases do the filtering instead of giving applicants the chance to speak for themselves. In a lot of cases that meant we were looking for certain buzzwords or experience on resumes, or not giving fair opportunity to applicants with non-traditional backgrounds. At our scale, it’s impossible to have conversations with every single person who applies, so we needed something to help folks stand out, but our gut feeling wasn’t enough. Our automated coding test is a straightforward web programming question that asks candidates to retrieve data, process it in some way, and post a response. It typically takes less than an hour to complete. We decided to run an experiment: instead of declining to move forward if a candidate doesn’t pass the resume review, send them the coding test. If they pass the test, continue on as normal. 🎧 Listen to the episode Almost immediately, we began interviewing and hiring applicants that we previously weren’t giving a second look. This shift in process was so successful that we now rely much less on resume reviews, and send most applicants through this process by default. There’s still room for improvement, but this was an important step in holding ourselves accountable, and not blocking the entrance for candidates based on our biases. Re-examine how you interview This part of our story begins with our co-ops. For the past few years, the team in charge of hiring for product internships at HubSpot has seen a significant increase in the diversity of incoming classes: majority minority groups with a growing percentage of female engineers. This year, we welcomed our first majority-female co-op class. The question quickly became, how can we scale these results from the campus recruiting team to the whole org? Enter slate interviewing. Over the years, as we evolved our campus recruiting process, we moved to conduct all of their interviews in consolidated batches, instead of spreading them out over weeks or months. They would see all of their candidates in a single week and then make a decision. First, this model’s a time-saver. Rather than having dozens and dozens of interviewers, each conducting a small number of interviews, we would have a much smaller number of interviewers, and we would sign them up as full time interviewers for a week. Most importantly, though, it’s a more equitable way of judging talent. Instead of making decisions on a per-candidate basis, we’d wait until the end of the week, and then we would pick the best candidates and make offers to them. Doing this allowed us to have a consistent set of interviewers asking a consistent set of questions, who could compare candidates against one another and make determinations about which candidates were best. At the end of the week, when an interviewer had asked the same question to five or ten candidates, it was pretty easy for them to be able to identify which candidates performed best. While we started this process with our co-ops and interns, it was natural to expand it to our new grads as well, and as of today, we’ve moved most of our hiring for all roles over to slates. As we’ve made this transition, candidate response has been positive. Not only do they receive a timely response about their application, they also receive the same preparation from recruiting and go through the same process as every other candidate, ensuring a level playing field. Implement the Rooney Rule For those unfamiliar with it, the Rooney Rule is simple: you must commit to interviewing diverse candidates for every leadership role that opens up in your organization. The iteration in effect at the NFL states ethnic minority candidates must be included in interviews for all open head coaching jobs. Most corporations adopting the rule for their own orgs, HubSpot included, specify that gender diversity must also be reflected in the mix. Critically, this is not a mandate on whom to hire. It’s just that chances are, if you’re not following Rooney in your interview process, you’re self-selecting homogeneity. Seek out a diverse set of perspectives and then make your selections based on qualifications. We started applying Rooney to all of our leadership positions, and now are expanding it to nearly all roles. As with our diverse class of incoming co-ops, the results have made it clear that if we’re not including gender-diverse and minority candidates in the interview process, we’re not always getting the best candidate for the job. Be deliberate This directive might seem at odds with the speed at which recruiters are often under pressure to fill roles. There are times, though, when you truly need to go slow to go fast. First, your recruiting team should pay attention to where they’re sourcing candidates from. Are you looking at companies with diverse workforces, and inclusion and belonging programs you admire? If you’re a campus recruiter, are you visiting schools with diverse student bodies? Years ago a dominant part of our campus recruiting was based around our co-op programs (3-6 month student embeds within our company). We had great success with these programs and the handful of universities that offered them, becoming one of the employers of choice on their campuses. But as we took a step back, we realized that there were a relatively small number of schools that offered co-op programs, and we were substantially limiting the pool of students we could go after. So, we added internships into our mix. This allowed us to go after virtually any campus program. And it allowed us to choose schools that had great computer science programs and diverse student bodies. You also need to be willing to stop and reflect. The recruiting process is a funnel, and at every step along the way, either you’re filtering a candidate out, or they’re filtering themselves out. You need to look at each of the steps, and say, am I filtering out candidates because of bias on my end? And are candidates filtering themselves out because they’re not having an inclusive interview experience? Which brings me to my final point: Don’t forget inclusion Most importantly, you need to remember that recruiting is only half the equation. You need to build inclusion and belonging if you want to retain your new hires. A Catalyst study found that employees from minority groups are much more likely to leave a job if they don’t feel a workplace is inclusive. Building inclusion is a process ⁠— you can’t just flip a switch. But there are some key elements that can help you make progress: Hold managers responsible for the atmosphere on their teams: Make it clear to your managers that inclusivity should be top of mind for them, whether that’s through training sessions or online resources. Give them concrete steps to take to make sure everyone on their team feels like they belong, and make “building diversity and inclusion” an item on their performance reviews. Encourage upper level leadership to be transparent: Leaders should be vocal about the importance of diversity and inclusion⁠ — their capacity to set the tone cannot be underestimated. But perhaps the most important thing leaders can do is show that they are taking the time to listen and learn about these topics, rather than preaching or teaching. Think about ways in which your org can use its voice to amplify the voices of others, such as through HubSpot’s Q&A series Name Dropping , which highlights the stories of women and nonbinary leaders in tech. Hire a diversity, inclusion, and belonging program manager: This person lays the foundation and figures out where the gaps are. Critically, even if you hire a diversity manager, it’s not to move the entire problem onto their plate. All team members, from VP to individual contributor, should feel they have a stake in this. Invest in employee resource groups and mentorship programs for underrepresented groups: Make sure that employees know they’re encouraged to start their own employee resource groups , and when they do, make sure there’s buy-in from leadership. As an example, our CISO is the co-sponsor of our Women @ HubSpot group. On the leadership side, look into kickstarting more formal employee mentorship programs as well. Both initiatives help balance opportunities across a team and encourage the kind of connections that help employees grow in their careers. Acknowledge what's going on in the outside world: During COVID-19, think about how you can build inclusivity in new ways. Encourage team members to take time to recharge, and if you’re a leader, “take time off loudly,” as a signal to others that it’s ok to do so. Consider creative ways to build inclusivity remotely⁠ — on a video call, think about having each team member share something meaningful to them that they keep in their home workspace. And most importantly, recognize that everything that’s going on in the outside world, from racial injustice to the COVID-19 pandemic, affects everyone on your team differently. Be empathetic and responsive to requests for help or time off. These steps will put you on the path to a more inclusive future team and product. At HubSpot, we’re far from done, but we’re in this for the long game. And remember, even if you don’t run a recruiting team or lead a product org, anyone has the power to contribute to diversity, inclusion, and belonging . Listen to this and more episodes of Culture Happens on iTunes, Spotify, or Google Podcasts.", "date": "2020-08-04"},
{"website": "Hubspot", "title": "Boston Scalable Architecture Meetup: A Night of Learning", "author": ["Gabriela Lanza"], "link": "https://product.hubspot.com/blog/boston-scalable-architecture-meetup-a-night-of-learning", "abstract": "One of the best things about tech is the sheer number of people who just want to build things, and build them well. This means that there's a lot of sharing in the tech world — we share how we're building with new technologies, how we redesign our products, how we structure our teams. In Boston alone, there are a number of software companies building really cool products. So we decided to design a night for engineers all over Boston to learn how teams build reliable, scalable software for diverse workloads and environments. And who better to partner with than Wayfair, who builds ecommerce software, and Toast, who makes point-of-sale and management software for restaurants. In aggregate, Wayfair, Toast, and HubSpot touch millions of customers, and on that journey, we've all had unique scaling challenges. If you'd like to share in a little of that learning, we've posted the slides from our three speakers below. Adam Baratz, Director of Engineering at Wayfair Click here to view this presentation Andrew Yoon, Senior Software Engineer at Toast Click here to view this presentation Jacob Hilker, Senior Software Engineer at HubSpot Click here to view this presentation", "date": "2018-04-20"},
{"website": "Hubspot", "title": "Life on the HubSpot Product Team EXPOSED", "author": ["Samuel Siskind"], "link": "https://product.hubspot.com/blog/201211life-on-the-hubspot-product-team-exposed", "abstract": "Ever wonder if it's fun to work on the Product team at HubSpot? Spoiler alert: It totally is.", "date": "2012-12-12"},
{"website": "Hubspot", "title": "Product Leadership Lessons Every New Manager Can Use", "author": ["Louise Bernstein (She/Her)"], "link": "https://product.hubspot.com/blog/product-leadership-lessons-for-new-managers", "abstract": "How do you effectively lead people who are natural leaders? As a Group Product Manager (or GPM) at HubSpot, I’m constantly asking this question. I’m part of a product team called the Revenue Product Group, and our mission is to help HubSpot become an experience disruptor at scale. My team's focus within this mission is making every touchpoint a customer has with a HubSpot employee delightful. Like many product managers (PMs) I took a nonlinear path into the field, but not by chance. I believe PMs carve a path, often unintentionally, toward the seat that drives product change. We find our way by instinct to the room that steers the ship. That’s why I often reflect on that key question: How do you effectively lead natural leaders? Over the past fifteen years in my career, I’ve had the opportunity to learn a lot about what it takes to go from managing products to managing product people. People who are entrepreneurial, self-starters, and passionate problem solvers. My answer to this question is in constant iteration. But there are principles I’ve come to lean on for not only managing product managers, but for helping them grow, too. These are three of the principles that I believe any product leader or GPM can use to lead, scale, and grow a team of natural leaders. 1. An Autonomous Culture Takes Work Product managers are innate problem-solvers. They don’t want you to give them a map to figure out how to get from point A to point B; they want the autonomy to chart their own course. While the pressure to deliver value is constant, and it can be tempting to tell your teams what to do, shortcutting into boss-mode shortchanges everybody's growth. Instead, as a product leader, you want to create a product culture that PMs can use as a backbone to make sound decisions along that autonomous journey. I believe you need a multitude of things to make guided autonomy work, but if you do nothing else, my three fundamentals include; a shared vision, psychological safety , and guardrails. My first component for making guided autonomy work is a no brainer: having a shared vision. In fact, Harvard Business Review argues that “the only visions that take hold are shared visions — and you will create them only when you listen very, very closely to others, appreciate their hopes, and attend to their needs.” Creating a vision together as a team strengthens collaboration and the team's ability to have true ownership over their work. The second two are important ones. Teams thrive in an environment where they feel psychologically safe ⁠— an environment where they can share ideas and take risks without fear of judgement, while also having guardrails to guide them that are made up of team and product principles, KPIs and yearly themes for how you go after your vision. 2. Adaptability Is Key in Helping People Grow As a GPM or product leader, you’ll be managing and coaching a team with varied levels and years of experience simultaneously. Therefore, being comfortable adapting a different approach for developing and supporting new and more experienced talent is important. For newer PMs, this means mentoring and teaching them what you know. It means helping them to remove biases, teaching them to think long term, understanding strategy, and building them up. For more experienced PMs, it means clearing a path for them to do their best work and being there as a sounding board on how to approach tough scenarios. Don’t underestimate the importance of differentiating between these two groups within your team, and make sure to adapt your coaching style accordingly. 3. Everyone Should Know What Success Looks Like Measuring success in Product Management is not ‘paint by numbers.’ It’s hard, especially when you’re new in a product leadership role. Brandon Chu, VP of Product & GM of Platform at Shopify, explained why : “PMs are notoriously difficult to evaluate for a few reasons. In general, they write no code, produce no designs, achieve no sales quotas, and manage no support tickets.” While it’s tough to navigate in the beginning, you’re responsible for setting clear expectations of what success looks like. My definition of success includes the product outcomes a PM has driven ⁠— how have customers’ lives improved and how has that helped our business grow? And very importantly, what value has a PM added to the team and our product culture? How you derive success will of course vary, but what matters is that you’re clear upfront about performance expectations and how PMs on your team will be measured. While my path to product management may not have been deliberate from the outset, my choice to go into people management was. HubSpot's Chief Customer Officer, Yamini Rangan, says that “leadership is like a mountain without a top”. In other words, you’ll never be done growing as a leader. PMs are natural leaders and I love the challenge of evolving my leadership style to accelerate their path to get there. Finding your groove as a product leader can be hard, but by creating a culture built on guided autonomy, and focusing on helping your PMs grow, I promise you’ll be leading and scaling a strong team of natural leaders in no time.", "date": "2020-06-11"},
{"website": "Hubspot", "title": "A World of Underpriced Apps - The Software App Cost Debate", "author": ["Adrian Mott"], "link": "https://product.hubspot.com/blog/bid/82164/a-world-of-underpriced-apps-the-software-app-cost-debate", "abstract": "I've been doing some thinking lately about apps and how they're priced in comparison with other daily expenses, and it just seems like some people in my experience have the wrong impression of the costs of software.  Perhaps this is rooted in the free software movement, or in the fact that much of the software on the web and on our phones today is in fact free, and has been for years - but this is a notion that I don't totally agree with. Don't get me wrong, I'm all about free and open in terms of software development practice (yes, I belong in the bazaar group ), but free and open have become terms that pertain to a platform's openness with their data accessibility (and potentially even their source code for some), not to the cost of the software or apps built on top of that platform. Software developers should feel that it's ok to charge for software.  Hell, it takes a lot of work to create software, developers should get paid for what they do, whether part of a company or individually.  The reason for this is not only because developers incur cost and time to ship and maintain software, but because in most cases, that software adds value to its users. Let me break it down for you like this with 2 scenarios that most of us probably find ourselves in fairly often: Scenario 1: You're out with some work colleagues, it's a Tuesday - 3pm and you're in need of some coffee. Your colleague recommends a great new coffee shop around the corner from your next meeting - \"great espresso\" they say, it's a no brainer, you head on over.  When you get there, you discover that they have a great new special drink with \"new mocha infused coffee beans\" from Guatemala and you can't resist, despite the $5.50 price tag.  When the cashier rings you up, you hardly even notice the price of the coffee before shelling over the dough.  As you taste the coffee, your expectations are somewhat let down - the barista had watered down the coffee a bit, but by the time you notice, you have to run to your meeting and can't ask them to make you a better brew.  Oh well, you drink half and throw the rest away - a fairly disappointing experience overall, but hey, it's just coffee :) Scenario 2: You're on your lunch break, it's a weekday around 1pm. You've just finished a good lunch with your co-workers and are headed back to your desk to crank through the afternoon. You sit down and quickly pull out your Android tablet and notice a new app in the marketplace that you remember your friend telling you about: \"hours of fun\" he said, \"oh, and Alec Baldwin got kicked off a plane for refusing to turn ot off or something\". The price tag reads $1.99 and the screenshots you can see look awesome. You want to try it, but it's $1.99 and you hesitate, not yet ready to commit because of the price.  After putting your tablet down and thinking about it for a while, you decide to buy it later and it turns out to be loads of fun, you literally play it most chances you get when you have free time.  A whole $1.99 well spent. Hopefully these two scenarios will put some things in perspective for you the next time you're hesitant to try a new app that you know will add value, but are hesitant because of the price.  Or perhaps the next time you're in line at Starbucks ready to buy that $5 coffee.  It can be hard to measure ROI at times, but for paid apps, it's time to give more of them a chance to add value to your daily routine at and away from work.", "date": "2012-02-14"},
{"website": "Hubspot", "title": "How I Became A Director of Engineering at HubSpot (By Becoming A Software Engineer Again)", "author": ["Nadia Alramli (She/Her)"], "link": "https://product.hubspot.com/blog/external-eng-onboarding", "abstract": "Before joining HubSpot, I had been at my previous job for 11 years. I had worked my way up from software engineer to senior director of product engineering. During that time, I benefited from all of the technical expertise and context that growing in the same company for over a decade affords you. I had truly helped build the products there from the ground up. When I was approached about the position at HubSpot, I was excited about the idea of doing things differently and learning something new. At the same time, I was concerned about starting in a leadership role at a different company where I didn’t have the strong technical domain experience that I’d leaned on before. It wasn’t until I was further along in the application process, though, that I got truly hooked on the idea of working for HubSpot. That was when I learned about HubSpot’s engineering onboarding process . Every external engineering leader hired at HubSpot goes through an “Embedding Process” for their first several months. During that period, they are treated exactly the same as any software engineer joining the team. No privileged access to information, no managerial responsibilities, no expectations beyond being a software engineer. They take the same training courses and go through the same onboarding process as everyone else. After that, they’re “embedded,” working as a software engineer switching between different teams and disciplines for time periods ranging from a couple of months to a couple of weeks. The whole process takes five to six months. When I was hired, I was excited to go through this experience, though not without a healthy dose of nerves. I’d heard of other companies like Google and Facebook approaching leadership hiring in this way, but I’d never been through a process even remotely similar. Now, I’m on the other side. I’m finished with my embedding and am transitioning into my role as an engineering director. Through the process, I had the chance to work with eight teams over a six month period, both in my home office in Dublin and in HubSpot’s headquarters in Cambridge. I met amazing engineers across the company and learned a lot about who I wanted to be as a leader at HubSpot. Here are some of my takeaways. Be curious In the beginning of the process, the hired engineering lead only has access to the same information as their software engineer peers on the team. No leadership documents or slack channels, no email exchanges between directors. At first, this was difficult to get used to. From my old job, I was used to looking at things from a leadership level and trying to solve for the team. The engineering SVP running the embedding program told me, “You’re going to itch to take on leadership responsibilities, but don’t do it. The team needs you to be where you are right now.” That made an impression on me. There was a lot to be learned, it turned out, from being cut off from the leadership information flow in the beginning. It made it clear to me where engineers’ blindspots were. It also meant that I was truly starting at square one. On a scale of zero to ten, my curiosity meter is at a 15 at all times, so I needed to get my information elsewhere, and that meant my teammates. Every person on the teams I worked with mentored me and answered my questions. I found that they grew more comfortable with me as soon as they saw that every question I asked came from a place of genuine curiosity and a desire to get better. My curiosity often took me on the hunt for information. It didn’t stop with my teams or projects, either. I had a wonderful journey learning from people in various functions — from shadowing customer support calls, to learning about UX design and product management best practices. I would come to every meeting with a list of questions and often leave with a list of names for people I could contact to learn more about each topic. This endless curiosity proved essential to my embedding process and I continued to carry it with me after settling into my leadership role. Resist imposter syndrome One of the hard truths of embedding is that, even though you’re a strong engineering leader and that’s why you’ve been hired, you’re not necessarily going to be a great engineer. For most of us going through this process, it’s been a long time since we started our careers as software engineers. My specialty is backend distributed systems, and here I was embedding with frontend teams just as often as backend ones. Everything has changed so much in the frontend space over the past 10 years that what little experience I do have there was irrelevant. That was a huge struggle for me. I was ok with making some mistakes, but I wanted to show that I was pulling my weight for my team and getting everything done. There were times when I felt like I didn’t know anything. When those hard times hit, my team was always there for me. They’d say, “Nadia, we’ve all gone through the same troubles before. It took us a long time to get around problems like this, too.” It’s not all about the tech stack Maybe the biggest misconception about an experience like this is that companies do it because they want external engineering hires to spend time in the trenches learning the tech stack. While this is one of the reasons behind the embedding process, it’s far from the most important. Yes, my embedding experience was a great way for me to learn the intricacies of HubSpot’s tech stack, and the time spent learning our product details and guiding principles was incredibly helpful. But the most invaluable part of the experience was the relationships I built with my fellow engineers. By the end of each embedding, the engineers on my team weren’t intimidated by me. I was one of them. They corrected my mistakes, they taught me things I didn’t know. I made close friendships where people could be honest with me, joke with me, mess around. Most importantly, I have an empathy for them that I’m going to carry into my leadership role. If I’d been thrown into my role right away, we wouldn’t have had the time to build that trust. Go out of your comfort zone As I mentioned earlier, my experience before HubSpot was on backend distributed systems. So naturally I was most comfortable when embedding on backend teams. However, I resisted the temptation to stay in my comfort zone. That meant going out of my way to ensure that I was embedding on an equal number of frontend teams where possible and taking on a variety of tasks to ensure as much exposure to new challenges as possible. In some cases, I bit off more than I could chew, and on one occasion I had to give up the task that was assigned to me. However, that didn’t stop me from pushing over and over again to challenge myself in new areas with varied projects. It was important to me to experience as much as I could during that period, including the use of our various development tools and experiencing any challenges or difficulties first hand. All in all, I could not be more grateful to have gone through this process for my first six months at HubSpot. As a leader here, you’re responsible for a large span of projects, and specific domain expertise is not necessarily relevant to the problem at hand. It’s important to have a handle on the whole tech ecosystem at the company so you’re able to innovate from within the pre-existing infrastructure, and it’s also priceless to spend the time on the ground as a member of the team in order to build trust with the people you’re eventually going to be managing. The fact that HubSpot is making such an investment in onboarding engineering leaders is a testimony to how it strives to create an excellent employee experience at all levels. New managers go through a more thoughtful, in-depth training experience coming in, and employees get a more empathetic and adaptive leader as a result. You may be coming in as an expert, but there’s so much more to learn. This article was originally published on Medium .", "date": "2019-09-26"},
{"website": "Hubspot", "title": "What We’ve Learned from Hiring (and Almost Hiring) Engineers", "author": ["Whitney Sorenson (He/Him)"], "link": "https://product.hubspot.com/blog/what-we-ve-learned-from-hiring-and-almost-hiring-engineers", "abstract": "Recruiting and team building are the biggest challenges facing any growing technology company today. Hiring creative and driven people to build your product can easily mean the difference between customer happiness and customer churn. Companies who don’t invest in culture, opportunities for growth, and access to interesting technical projects have a tough road ahead of them. But the market is ridiculously competitive, and great engineers, designers, and product people have never had an easier time finding compelling work. HubSpot has been voted a top place to work year after year, our Culture Code has over 1.8 million views, and engineers have complete ownership over the product. Still, those qualities are just the table stakes. They don’t make recruiting easy. In my 4+ years at HubSpot, I’ve seen first-hand how hard it is to attract and retain great people. I helped hire a good part of our product team after HubSpot acquired my former company Performable, traveled to Dublin to recruit and set up our product team there, and have spent the past 6 months working daily with the product recruiting team. I’ve learned a lot of lessons along the way from other leaders, recruiters, and the hard way: from candidates. We once had a candidate who offered to pay his own travel costs, so we thought, sure, why not? We didn’t end up giving them an offer and they left a negative review on Glassdoor calling us “cheap”. We were kicking ourselves afterward. That was cheap. Companies should always cover costs, review or no review. It’s just the right thing to do. The “yelpification” of recruiting has made one thing crystal clear: Companies can’t fake a remarkable recruiting process. The only way to become a magnet for talent externally is to be thoughtful about hiring internally. We still have a ways to go, and many more mistakes to make, but these learnings have helped us improve when it comes to finding and interviewing talent, and creating a positive candidate experience. Even with huge incentives, referrals take work. Cash incentives don’t motivate everyone in the same way. Frankly, some engineers would rather pay money to avoid feeling salesy or socially awkward by reaching out to friends or former colleagues. We’ve found that helping them think through referrals and strategies for contacting people is more effective than posting a huge bonus and waiting for applications to come flying in. We hosted a Q&A earlier this year where top employee referrers talked about how they qualify and reach out to referrals, and more regularly, we sit down with engineers one-on-one to talk through who they have in mind, where they might be a good fit, and what the best way to start the conversation with them is. Candidates know way more about the interview process than they used to. Sites like Glassdoor and Quora make it pretty easy for candidates to know which companies are going to ask what during an interview. Nearly all of our engineering-specific questions have been “leaked” online at some point. This can be very costly if your questions are easily crackable; candidates end up having a big advantage over the interviewer. We’ve started leaning towards interactive design questions which don’t have one “correct” answer and programming questions which don’t rely on tricks. That way, the focus is on getting to a solution, not the solution itself. So far, we haven’t needed to iterate too much on the in-person questions (our automated, online coding tests are a different matter). Teaching interview questions shouldn’t be like playing telephone. When we introduced some standard interview questions to help apply a fair and consistent hiring bar, we wrote up the details of the questions and had a few interviewers shadow one another to get comfortable with asking them. While it should have been predictable, years later the standard questions were anything but. Variations between “generations” of interviewers who had been taught by other interviewers were extreme. While it makes sense to allow interviewers some leeway to develop a personal style, driving consistency helps improve candidate experience and reduce poor hiring outcomes (hiring the wrong people, not hiring the right ones.) We’ve recently introduced large-scale training and more thorough write-ups to improve. Computers are more natural than whiteboards. Interviews are naturally uncomfortable; candidates are nervous, in a new environment, and meeting tons of new people. If we can do anything to switch them from thinking of it as an interview, and move towards a more normal work setting, we should. Using a computer instead of a whiteboard for technical questions can make a huge difference in their performance. It’s not fair to the candidate to not get an offer because they were too nervous to solve a problem or work through a question. Not to mention, the best way to get a sense of what it would really be like to work with a candidate is to give them an opportunity to display their skills in as close to a real-life setting as possible. Detailed interview feedback is worth the extra time. It’s tempting to skip filling out internal interview feedback when the decision on a candidate is a definite and unanimous yes or no. But this has come back to bite us many times, as interviews are not always one-time affairs. Candidates re-apply or become great fits a few years later, and having accurate and detailed feedback from their earlier interviews makes it way easier to pick up where you left off and avoid a few awkward conversations. Terse summaries like “I like this person” or “They were okay” aren’t as helpful two years after the post-interview meeting when the context was still fresh and top of mind. More importantly, giving candidates rich, actionable feedback creates a more positive experience, whether they get an offer or not, by turning their interview into a valuable learning experience. Internal feedback forms should always be evolving. Getting the most helpful feedback from interviewers means you need to iterate and experiment with your feedback form. For example, we realized that if you ask a ton of questions, some people will spend a tremendous amount of time answering all of them in detail. You’re better off having a handful of open-ended sections rather than asking for paragraph-sized responses on every possible topic. Give interviewers a handful of prompts and a single place to answer. Instead of asking about coding ability, analytical ability, communication skills, and culture fit separately, you could ask “ Technically and culturally, what was remarkable about the candidate?” Interviewing is a learned skill. The first interview I ever conducted was for IBM. I had no idea what I was doing and made up all of the questions on the spot. Not surprisingly, the outcome was useless: I truly didn’t know if we should hire the candidate or not. Even worse, the candidate probably had a terrible experience, too. Interviewing is pretty hard, and strong interviewers usually have a lot of experience calibrating themselves. This is one of the key reasons we do post-interviews, have future interviewers shadow experienced interviewers, and recently started running workshops on certain questions and common pitfalls. Not only does it help the team get aligned on hiring decisions, it gives interviewers an opportunity to learn from each other. Offer speed matters. The sooner you can extend an offer, the better. Giant tech companies tend to move slowly and can take weeks, even up to a month, to follow up with a candidate with a decision. For engineers, that’s a bad sign of bureaucracy. Time and time again, moving fast has been a big advantage for us in the acceptance stage. A few engineers got a call with an offer on their way home from their interview and they still say that the quick turnaround was a strong testament to how much we value talent. As we grow, this will become harder and harder to do, so it’s important we do everything we can to continue making offers as quickly as possible. You can’t win them all (but you should try). Lastly, one of the biggest learnings we’ve had is that sometimes it’s not you, it’s them. There are a ton of factors that go into an engineer’s career decisions and companies can’t influence all of them, no matter how hard we try or optimize for that candidate’s success. We’ve lost engineers at the last minute and had a really hard time figuring out why, but we can’t go into crisis mode and re-evaluate our entire process every time someone doesn’t accept an offer. What’s important is that recruiting is a priority and feedback is taken seriously. Attracting remarkable product people will never be easy, but it’s critical that we’re constantly learning how we can improve our candidate experience. So, on that note: We’re hiring (and yes, we’ll pay for travel).", "date": "2015-11-09"},
{"website": "Hubspot", "title": "Health Tips for Programmers", "author": ["Chris Keller"], "link": "https://product.hubspot.com/blog/bid/49239/health-tips-for-programmers", "abstract": "Programmers are definitely part of a work place demographic not known for being stereotypically healthy.  You sit all day, repetitively use your fingers in ways they weren't designed, stare at an artificially lit object, in an artificially lit room, and probably are munching on some artificial food while washing it down with an artificial liquid.  Can you spell recipe for disaster over the long haul? I stumbled upon a great article by a programmer who used to be in the army, and over the years figured out how to maintain his health, even while sitting all day. The article is long but here are the general maladies he provides some advice on: Pain in your wrists from Repetitive Strain Injury (RSI). Problems with your eyes from staring at moving print for extended periods. Back problems from poor posture, especially in the lower back and upper shoulders. Bowel and urinary issues from not crapping and pissing when you should. Dehydration from drinking too much caffeine and not enough water. Problems with hemorrhoids and the prostate from sitting too much. Yep, I'm gonna go there. Vitamin D deficiency from lack of sunshine. Sleeping disorders from staying up late and drinking too much coffee. General stiffness and soreness from a lack of stretching in general. As mentioned, the article is a bit longer, but if anything, a good read and hopefully you'll take away one or two things to change in your daily routine. At HubSpot, taking a break to do something active is highly encouraged (we have people who run, play basketball and squash), in addition to making sure you have an environment that's ergonomic and comfortable for you. One day they might approve my request for a retractable roof so I can get my Vitamin D while coding, but in the meantime, I'll settle for a jog in the summer sun at lunch time. Now get up for 5 minutes or stretch before reading the article, you'll feel better. http://sheddingbikes.com/posts/1281257293.html", "date": "2010-08-08"},
{"website": "Hubspot", "title": "G1GC Fundamentals: Lessons from Taming Garbage Collection", "author": ["Eric Abbott"], "link": "https://product.hubspot.com/blog/g1gc-fundamentals-lessons-from-taming-garbage-collection", "abstract": "HubSpot engineering is a Java shop invested heavily in microservices and continuous deployment. Java is not only used to run our thousands of deployables, but also our queues ( Kafka ) and Big Data solution (HBase). Keeping all these JVMs performant while providing a good user experience has forced us to dig deep into Garbage Collection (GC), particularly the Garbage First Garbage Collector (G1GC). Motivation Interestingly enough, the initial motivation for monitoring GC performance was not the elimination of performance issues. At the time, the goal was to shrink the overall RAM footprint of our applications to reduce the number of servers and save $$. The responsible way to shrink heap involves monitoring GC performance to know how low to go. Representative metrics were identified and collected out of the GC logs, and we started experiments to reduce the heaps of larger applications. GC metrics were not even two weeks old before the first performance issue was found. Out of a cluster of application instances, one would randomly start to have response times 2x the norm or higher. With a bit of poking around it was determined the new metric for overall time spent in GC correlated with the slow response times. With the y-axis in millis, the graph below shows a single instance start spending 25s of wall clock time in GC for each reporting interval. At 60s apart, 25s/60s or 40% of the reporting interval the JVM was in GC and not doing any useful work. The issue was successfully resolved through GC tuning alone which at the time was both shocking and depressing, as it more or less ruled out the idea that GC \"just worked\". The above situation is representative of the \"too much time spent in GC\" scenario, and below we have the \"individual latency too high\" scenario. Here again the y-axis is millis and the metric being graphed is the longest individual GC time per reporting interval. This REST API application is regularly pausing for 10s+. For reference, the memcached operation timeout is set to 1s and front end requests timeout after 5s. Poor User Experience The types of GC problems that directly affect our customers fall into the following three categories. Extended periods of slow response time (too much time spent in GC) Random high latency spikes 5s+ (individual long GC time) Traffic based OOMs (Out Of Memory) The first two categories have been described already and are relatively straightforward. The last category, traffic based OOMs, involves a grey line and a fair bit of handwaving. OOM failures happen in Java when the JVM does not have enough heap to cover the amount of live data currently being used by the application. By labeling some OOMs as traffic based, we are attempting to differentiate between apps that are hopelessly misconfigured and consistently crash after some short period of time vs. those that run fine for long periods of time (days) yet OOM randomly due to traffic conditions. The OOMs in the former camp can be eliminated with more heap, those in the latter camp can be reduced or eliminated through GC tuning. Actions Over the past few months tackling GC issues we've taken the following actions. Collect GC metrics for all applications Setting safe GC parameter defaults Set alerts to detect when apps are in GC Hell Define and detect requests of unusual size (R.O.U.S.) Dive deeper into G1GC Introduce G1GC lectures and training for all backend devs Create a tool for fine grained G1GC log analysis ( gc_log_visualizer ) Tune REST API instances Tune Zookeeper Tune Kafka Tune HBase Now that the dust has settled and HubSpot has a good handle on GC, and G1GC in particular, we’re ready to share our hard earned lessons with the following information on the nuts and bolts of G1GC. Topics and Overview The goal of the following information is to provide the necessary G1GC knowledge to effectively monitor, troubleshoot and tune any given G1GC installation (of Oracle's JDK versions 1.8.45-1.8.65, other versions may/will vary subtly). The topics will cover broad foundational principles as well as detailed looks at individual features, starting with more theory and ending with more details. Jump to: Concepts and Architecture Regions Starting to Tie it All Together Concepts and Architecture Continued Understanding Mixed Events Humongous Objects More Concepts and Final Thoughts Concepts and Architecture G1GC (Garbage First Garbage Collector) is the low latency garbage collection algorithm included in recent versions of both OpenJDK and Oracle Java. Like other Java GC algorithms, to reclaim heap space G1GC must halt all application threads, a process referred to as stopping-the-world (STW) or pausing (a GC pause). There are two main STW characteristics that affect the applications running on a JVM, the duration of individual pauses, and the overall time spent in STW. G1GC is geared towards consistently short STW times and will naturally spend more overall time in GC than the other most popular collector, ParallelGC. A lot more can be written on the uses and differences of G1GC and ParallelGC than will be included here. At HubSpot, we use G1GC for any JVM that is in the path of a user's browser, and ParallelGC for everything else. In effect we are saying user experience will be better with consistently fast requests, while async processing throughput will be better/cheaper with ParallelGC. This initial section will introduce a few of the core concepts and architectural decisions present in many modern day garbage collectors, as well as implementation details specific to G1GC. The GC Epoch What it means to be a Generational Collector The significance of G1GC's regions How Evacuation style collectors work and how they defragment heap How Tenured space can be collected in subsets instead of all at once Humongous objects, the downside of G1GC's regions G1GC's ability to resize the heaps each epoch The significance of Free space The GC Epoch A full circuit of the garbage collection life cycle is called an epoch. The following diagram highlights the events of concern to this document. App Threads Started - This event triggers the start of the application code after which real work gets done. GC Triggered - Something triggers the need to reclaim unused heap space. App Threads Stopped - Application threads need to stop at a java safepoint in order for heap space to be safely reclaimed. Real work stops here. Heap Reclaimed - The GC algorithm determines what occupied space is no longer being used and reclaims that space. Heap Sizes Adjusted - If heap spaces are adjustable, they will be adjusted based on current conditions. The application threads are started in the 'App Threads Started' state, at which point the JVM begins running the application code and does what would be considered useful work. Eventually GC is triggered through an event such as a heap filling up and the JVM halts all the application threads in order to reclaim no longer used heap space. After the heap is reclaimed the heap sizes may be adjusted, then the application threads are started once more. Generational Collector Generational collectors are based on the following statements both being mostly true: Data that is very young will not survive long Data that is old will continue to exist Consider a simple Java web server application as it just starts up. The init sequence will load the logging mechanism, the connection pools, perhaps pre-initialize some data/caches, determine what endpoints it will accept and so on. Post warm up, the application receives and fields a never-ending supply of REST calls. Each REST call may include decoding/parsing the http request into Request/Response objects, DB/memcached calls, marshalling of data into json and finally streaming the data through the Response object. One set of data will hang around for the life of the application server, the other will exist for a brief instant. Old and Young generations are designed specifically to handle those two types of data based on their longevity characteristics. The connection pools, logging metadata, endpoint information and caches would exist for long periods of time in the Old generation, while shorter lived transient data from REST API calls would briefly reside in the Young generation. The usage pattern of the generational collector is to allocate all new objects in the Young generation and promote objects that live long enough into the Old generation. G1GC has two types of heap in the Young generation, Eden and two Survivor spaces labeled To & From. The Survivor spaces exist in order to weed out transient data that manages to survive through an epoch cycle or two. The Old generation in G1GC is comprised of a single heap space named Tenured, and the two names (Old/Tenured) are often used interchangeably. Regions The defining feature of G1GC is the region, a small independent heap. G1GC divides the total heap into homogenous regions that are logically combined into the traditional heaps Eden, Survivor and Tenured. These multiple smaller heaps cost more in overhead (cpu/ram) but are quite flexible and provide the following benefits: Allows Tenured to be collected in portions, which caps latency Allows generations to be easily resized as necessary Auto-defragging with evacuation-style collections The following illustration shows 64 regions logically grouped into Eden (E), Survivor spaces (S) and Tenured (T). The remaining empty regions are considered Free space. Region sizes are not changeable and must be a power of two between 1MB - 32MB, inclusive. If not explicitly set on the command line via -XX:G1HeapRegionSize=#m, the region size will be set such that there are the optimal 2k or more regions on startup. The heap size of the JVM on startup is the minimum heap, so to keep things simple HubSpot always sets min heap to be the same as max heap when using G1GC. The following table shows the region size that will be chosen based on the minimum heap size should the region size not be explicitly set. Min Heap Size Region Size heap < 4GB 1MB 4GB <= heap < 8GB 2MB 8GB <= heap < 16GB 4MB 16GB <= heap < 32GB 8MB 32GB <= heap < 64GB 16MB 64GB <= heap 32MB Object allocation > Region The primary pain point to the breaking apart of heap into isolated Regions is the large allocation, where large is relative to the Region size. How should G1GC handle an allocation that is 3x larger than a Region itself? G1GC names these problem allocations Humongous objects, and it must be noted that a Humongous object is single allocation such as a byte[30 * 1024 * 1020] and not a String[1024] pointing to String objects of length 30k each. A few key points about Humongous objects: Humongous object size ≥ (G1HeapRegionSize/2) They’re allocated in contiguous regions of Free space They’re instantly added to Tenured Evacuation style collections In G1GC reclaiming space is done by copying live data out of existing regions into empty regions. The regions the data came from are considered empty at the end of the process and will become Free space. This evacuation process will naturally defragment as data is continually consolidated into empty regions. 4 types of heap space Harkening back to the illustration of regions, we end up with 4 types of heap space to be concerned with. Eden, Survivor, Tenured and the regions not part of the other three (Free). Eden Consists of objects allocated since the current epoch started Resized for each epoch to be between -XX:G1NewSizePercent (default 5) and -XX:G1MaxNewSizePercent (default 60) All new objects are allocated in Eden, except Humongous objects Empty at the beginning of each epoch Survivor Survivor From consists of objects that have survived at least one epoch Survivor To is allocated but empty during the epoch Each object in survivor has a counter for the number of epochs survived Objects surviving long enough get promoted to Tenured Survivor To space is resized as a ratio (-XX:SurvivorRatio, default 8) of the current Eden size Tenured Consists of Working set + Humongous objects + fragmentation (Reclaimable and Un-reclaimable heap waste) Garbage-collected in batches during qualifying epochs Free Consists of regions not allocated to any logical heap Humongous objects are allocated from Free regions, which then become Tenured Starting to Tie it All Together The initial section introduced the foundational concepts of G1GC, this section will switch gears and focus on how the pieces work together and become more than the sum of their parts. Walking through the simplest epoch of a REST application server will provide insight into: Why G1GC's approach to the Young generation is efficient for transient data How and why Survivor space is useful The usefulness of evacuation How regions are used The driving force behind STW times Epoch lifecycle of a Minor GC event The vast majority of G1GC use cases at HubSpot are REST API applications that talk to multiple data sources and communicate via json objects. For this example assume traffic volume around 100 requests/second with individual requests averaging 50ms. 10,000ft View The basic mechanics of an epoch ending in a Minor GC event are summed up in the following illustration. Eden starts empty and is filled with new data allocations. Eden fills up triggering the end of the epoch and the Evacuation phase. The live data in Eden and Survivor From is moved (evacuated) into Survivor To space, with the exception of any data promoted from Survivor From to Tenured. After the Evacuation phase, Eden and Survivor From are devoid of live data and reclaimed. Details The epoch starts with Eden and Survivor To space regions allocated and empty. Survivor From space contains some objects tagged with their survival counts. The useful work the application threads are doing is gradually filling Eden's regions with new data. At some point, Eden runs out of available space and an allocation request fails. Application threads will be stopped at their next safe point, such as an allocation request. At this point the clock is ticking as no useful work is being done. A number of GC worker threads (-XX:ParallelGCThreads) begin concurrently scanning through all the places heap pointers can exist (threads/stacks/registers) for pointers to live objects in the heap. Objects traced back to... ...Tenured: are ignored ...Eden: are evacuated into Survivor To space with survival counter 1 ...From, and Survival counter + 1 > tenuring threshold: are promoted to Tenured Survival counter + 1 <= tenuring threshold: are evacuated into Survivor To space with survival counter incremented Evacuation includes both copying an object into a new region and updating all pointers to that object. Once scanning has completed and all the live objects have been evacuated, by definition all the objects left in Eden and Survivor From space are not referenced, are not live and can be safely reclaimed as Free space. Survivor To is renamed to Survivor From. Eden's size is recalculated and regions are allocated from Free space. The new Survivor To is calculated off of Eden's new size and again regions are allocated. The application threads are then allowed to continue from where they left off. To-space overflow and To-space exhaustion To-space overflow happens when the Survivor To space cannot accommodate all the surviving data from Eden and the Survivor From space. When this happens the overflow data is added to Tenured in regions pulled from Free space. Should there not be enough available regions in Free space for this, To-space exhaustion occurs. Recovering from To-space exhaustion involves rolling back all evacuations up to that point and initiating a Full GC. Survivor space At the end of the epoch, Survivor space is filled with objects like these: Transient request data from active http requests Recently cached data Changes/updates to long lived objects (eg conn pools) Because GC events are triggered by activity (active threads servicing http requests), we expect there will always be data of the first category in each epoch. The goal of Survivor space is to keep that transient data from making it into Tenured, where it would be expensive to remove. Having the other two categories of data bounce back and forth a few times between Survivor spaces is a cost associated with keeping transient data out of Tenured. Length of STW In this example, actions taken while the application threads were stopped include: Scanning stack/application threads/registers et al Copying objects from one region to another Updating pointers Scanning stack regions and updating pointers are probably not time intensive operations, however copying an object from one memory location to another (memcpy) can take some time. So it ends up that the driver of STW time is the size and amount of objects that are copied. The size and amount of objects being copied, if extrapolated from the previous Survivor space section, is driven by the number and activity level of http requests that are active at the point in time that GC is triggered. Now this is an interesting piece of data. Consider that most http based applications servers will receive traffic at a relatively even distribution over a given period of time. For example, during a five minute period, an app server could field an average of 100 requests/sec, with each request averaging 50ms. The average concurrency (active threads processing in parallel) for this period of time would be 5. So at any given point in time during the 5 minute period, we'd expect a Minor GC event to take however long it takes to copy the transient data for those 5 active and concurrent http requests. Effects of Eden size Given that the STW time is driven by the concurrency of the http application and that GC events are 30s apart, what would happen if we grew or shrunk the size of Eden? With the STW time fixed against the concurrency, doubling the size of Eden will result in GC events happening every 60s instead of every 30s, cutting the frequency of total GC events and probably overall time spent in GC in half. The opposite would happen by shrinking the size of Eden by 50%, GC events would come twice as frequently, and we'd be spending twice the amount of overall time in STW. At HubSpot we have found it to be a universal truth* for our REST API instances that the more Eden we can allocate the better. Individual STW times are unaffected, and overall time spent in STW drops. *Caveat: On a couple of rare occasions increasing Eden bumped up STW times, but dropped back down to the expected level after enabling parallel reference processing via -XX:+ParallelRefProcEnabled. Takeaways (for REST API servers) Survivor spaces are buffers to keep transient data out of Tenured Regions + Evacuation == defragmentation Stw times are driven by the copying of objects, and are thus driven by the amount and size of data held by each http request x concurrency Doubling Eden will halve the overall time spent in GC Eden size doesn’t affect individual STW times* *HBase instances with heavy block cache churn are an exception, as would be any other data source with a constantly refreshing large cache. On the other hand, we found that both Kafka’s and ZooKeeper’s individual STW times were not affected by Eden size. Concepts and Architecture Continued... Running through the simplest G1GC epoch has hopefully provided enough context that pieces are beginning to click into place. Next up are the different types of GC events along with how they’re triggered. Types and Triggers of GC Events During normal operation GC is triggered through need/activity, as in an application thread needs space and none is available. External forces can instigate Full GC events, commonly through jcmd and jmap for diagnostic purposes. Common triggers are: Eden full Free space cannot accommodate a Humongous object Humongous object allocated successfully and GC event conditions met Externally initiated (jcmd, jmap, Runtime.gc()) The happy path here is for GC events to only be triggered when Eden is full or a Humongous object is allocated successfully and certain conditions are met. This happy path involves only Minor and Mixed events. Full GC events are likely to exceed the max desired STW and need to be avoided. Humongous objects are often a liability as lots of Humongous objects will increase the likelihood of running out of Free space, which would trigger a Full GC. The types of GC events are as follows Minor: Eden + Survivor From -> Survivor To Mixed: Minor + (# reclaimable Tenured regions / -XX:G1MixedGCCountTarget) regions of Tenured Full GC: All regions evacuated Minor/Mixed + To-space exhaustion: Minor/Mixed + rollback + Full GC In a smoothly running application, batches of Minor events alternate with batches of Mixed events. Full GC events and To-space exhaustion are things you absolutely don't want to see when running G1GC, they need to be detected and eliminated. For http applications and many other types of applications, Evacuation of Eden (Minor event) is strictly a function of concurrency and request data sizes. In other words, to reduce Minor STW times, either reduce data loaded/munged/sent or reduce concurrency. So for maintaining short STW times, the variable factor is the reclaiming of Tenured space. G1GC's approach is to reclaim Tenured in bite sized chunks, and has a whole host of support levers allowing fine grained control. Understanding Mixed Events This next section is focused on how Tenured is cleaned and will provide insight into: The conditions necessary to start a Mixed event The conditions necessary to end a Mixed event cycle Why Mixed events come in batches Why we need to know the working set size How to-space exhaustion could occur 10,000ft View At the end of each Minor event, a check is made to determine if it's time to consider cleaning Tenured. If the check passes, a Multi-Phase Concurrent Marking Cycle (MPCMC) is kicked off. As per its name, the MPCMC will run concurrently with the application threads to produce a set of liveness metadata (amount of reclaimable space) for each Tenured region. At the beginning of the next GC event following the completion of the liveness metadata, a different check is made against the amount of reclaimable data. If there is not enough reclaimable data, the liveness metadata is thrown away and the event is a Minor one. If there is enough reclaimable data, the GC event is a Mixed event. The subsequent GC events will also notice the presence of the liveness metadata and decide whether or not to be Mixed or Minor based on how much reclaimable Tenured space remains, with any decision to run a Minor event clearing the liveness metadata. Detailed Walkthrough Mixed GC events can only occur when the liveness metadata exists. The liveness metadata is generated by a run of the MPCMC. The MPCMC is initiated at the end of a Minor event, which is where we will start. A Minor event is in progress, the Eden/From spaces have been emptied and resized and the application threads are still stopped. At this point, G1GC will make a check to determine if the MPCMC should be kicked off or not: 100(Heap currently used Total available heap) > -XX:InitiatingHeapOccupancyPercent Since the check is made after Eden/From have been evacuated, the check is basically asking if Tenured's current size exceeds a configurable threshold (45% by default) of the total heap. If this check passes, a snapshot of the data (threads/stacks/registers/etc) that was used to trace pointers into Eden/Survivor From is taken and given to the MPCMC, which will run on -XX:ConcGCThreads. The application threads are then given the go ahead, and the MPCMC and the application go on about their business in parallel. The MPCMC run times have been observed to range from 50ms to 5s or more. Most apps at HubSpot under 8GB heap usually complete MPCMC runs in 100-800ms. The MPCMC does work similar to the work done during Minor events, tracing pointers into heap. In this case however the pointers into Tenured are the ones of interest. Each Tenured object that is found this way is marked as live. Again similar to the tracing of objects in heap during the Minor event, objects in Tenured that are not found via tracing are considered unreferenced and not live and can be reclaimed. At the end of the MPCMC each region will have a liveness value, as in what percentage of the total space in the region is live data. Collecting a region with 18% liveness would net 82% of a region added to Free space. The MPCMC will not be interrupted by Minor GC events, though a Full GC would negate the need for liveness data and abort the MPCMC. After the liveness metadata has been created, the existence of the metadata will be noticed by the next GC event and a Reclaimability check will be made to decide if the GC event should be a Minor or Mixed one. Should the Reclaimability check fail, the metadata is thrown away. Reclaimable To determine the amount of data that can be reclaimed by collecting Tenured, G1GC starts by creating a list of reclaimable Tenured regions. The list only includes regions with liveness ≤ -XX:G1MixedGCLiveThresholdPercent (default 85), and follows natural ordering based on liveness (ie lowest liveness first). The total bytes that would be reclaimed by collecting just the regions in this list is then tallied, and is divided by the total heap to get a percentage. If that reclaimable percent ≥ -XX:G1HeapWastePercent (default 5), the Reclaimable check passes. It is interesting here to note that there is a distinction between Reclaimable and unreclaimable heap waste in Tenured. If 20% of the heap consisted of Tenured regions with liveness of 86%, that would be .2 * .14 = .028, or around 3% of the heap that is wasted and unreclaimable. Garbage First If the check passes, the GC event will be Mixed, and the algorithm will next determine how many and which Tenured regions to collect in addition to Eden/From. Choosing which Tenured regions to collect is how the algorithm got its name, the regions to be collected are the ones with the most garbage in them (least liveness, the regions at the head of the Reclaimable list). Determining how many regions to collect is a bit more complex and at a high level has three steps involving a floor, an adder and a ceiling. Floor -> Start with the floor by evenly dividing the total work Adder -> Add more regions if time permits Ceiling -> Cap regions with a hard limit of total heap space The starting number of regions will be: length(Reclaimable Region List) -XX:G1MixedGCCountTarget Additional Tenured regions will be collected if doing so can be done under the target pause time of -XX:MaxGCPauseMillis. Finally, the number of Tenured regions to be collected will be capped at the -XX:G1OldCSetRegionThresholdPercent (default 10%) percentage of total heap. Multiple Mixed Events After determining the number of Tenured regions to collect, that number of regions will be popped off the front of the sorted Reclaimable Region List and collected along with Eden/From. Since the liveness metadata already exists, there won't be a check to determine if the MPCMC should be kicked off before completing the GC event. The GC event ends and the application threads continue from where they left off. At the next GC event, once again at the beginning of the event the existence of the liveness metadata is noted, and the Reclaimability check is made. There are differences between this Reclaimability check vs. the previous: A bunch of the Tenured regions with the most garbage have already been collected There could be newly added Tenured regions without liveness metadata Should the check succeed again, there will be another Mixed event that will collect some portion of the remaining Tenured regions with the most garbage in them. At this point, somewhere around 2/G1MixedGCCountTarget of the Reclaimable regions with the most garbage in them have been collected. This process will continue until the amount of reclaimable space as listed in the liveness metadata is less than the allowable waste set by G1HeapWastePercent. At this point the Reclaimability check will fail, the liveness metadata will get tossed, and the next GC event will be a Minor one. Unless G1HeapWastePercent is set to 0, we expect to run fewer consecutive Mixed events than the target count. Inherent To-space Exhaustion Vulnerability Consider the following illustration showing two separate Mixed event cycles. The liveness metadata is generated at the tail end of the MPCMC. For the entire period between the end of those MPCMCs, new Tenured regions will not have metadata, and will not be eligible to be reclaimed. The danger is that during the period in between MPCMCs, Free space gets entirely engulfed into Tenured through to-space overflow or Humongous objects. At HubSpot the underlying cause of to-space exhaustion is usually related to a burst of Requests Of Unusual Size (R.O.U.S.). R.O.U.S. detection will be elaborated on in a future post. IHOP and the Working Set Now that there is some context behind the Mixed event lifecycle, we can dig a little deeper into the repercussions of the InitiatingHeapOccupancyPercent (IHOP) parameter. For an application such as an http REST API server, there is expected to be a relatively stable amount of Tenured data. This chunk of data, or Working Set, could consist of, but not limited to, any of the following: Object caches Singletons Connection Pools Thread Pools Metrics Let's consider one of these REST API servers with a total heap of 1GB, and a working set of 256MB, or 25%. With the default IHOP of 45%, Mixed events should be triggered immediately after Tenured is 45% full, as there would be 25% working set and 45-25 = 20% waste in the heap, well above the default G1HeapWastePercent of 5%. After the cycle of Mixed events complete, we'd expect to see the Tenured size (Working Set + waste) to be around 30% of total heap. Now consider a similarly configured REST API instance with a working set of 5% of the total heap. Mixed events won't trigger until Tenured is 45% full. There's lots of wasted heap between the 10% low end of Tenured (5% working set + 5% allowed waste) and the high end at 45% when Mixed events finally occur. Next consider another similarly configured REST API instance with a working set of 75% of total heap. With IHOP at 45%, each and every Minor GC event will trigger an MPCMC if one is not already started. Mixed events will begin as soon as Reclaimable hits the threshold. In this scenario, MPCMC is running almost constantly, and Mixed events are evacuating lots of regions to reclaim little space. To make matters worse, these evacuations are more expensive than evacuations of regions with mostly non-live data. To efficiently utilize resources and STW times, it's highly recommended that IHOP be tuned per application. At HubSpot we aim for IHOP to be around Working Set + G1HeapWastePercent + 10-15%. If Mixed event cycles are 5 minutes apart, we lower IHOP, and if Mixed event cycles are 5 seconds apart, we raise IHOP. Humongous Objects At this point the majority of the functionality and architecture of G1GC has been flushed out, with the exception of the biggest weakness/complexity, the Humongous object. As mentioned previously, any single data allocation ≥ G1HeapRegionSize/2 is considered a Humongous object, which is allocated out of contiguous regions of Free space, which are then added to Tenured. Let's run through some basic characteristics and how they affect the normal GC lifecycle. The following discussion on Humongous objects will provide insight into the downsides of Humongous objects such as: Increase the risk of running out of Free space and triggering a Full GC Increase overall time spent in STW Humongous objects draw from the Free space pool Humongous objects are allocated out of Free space. Allocation failures trigger GC events. If an allocation failure from Free space triggers GC, the GC event will be a Full GC, which is very undesirable in most circumstances. To avoid Full GC events in an application with lots of Humongous objects, one must ensure the Free space pool is large enough as compared to Eden that Eden will always fill up first. One usually ends up being over cautious and the application ends up in a state where the Free ram pool is quite large and never fully utilized, which is by definition wasting RAM. Humongous objects are freed at the end of an MPCMC Up until around Oracle jdk 8u45, it was true that Humongous objects were only collected at the end of runs of the MPCMC. The release notes for versions of Oracle 8u45-8u65 have a few commits indicating some, but not all, Humongous objects are being collected during Minor events. Humongous objects that are only collectable at the end of a MPCMC will increase the requirements for reserved Free space or be more likely to trigger a Full GC. Humongous objects kick off MPCMC early In an effort to reduce the space wasted by unreferenced Humongous objects, the MPCMC is run more often when Humongous objects are present. Each Humongous object allocation will run the IHOP check detailed in the Mixed event section. This time around however, the check is not run after Eden/From have been cleared, which makes it much more likely that an MPCMC will be kicked off. The check will not be run if an MPCMC is already in progress or if the liveness metadata exists. Heap currently used Total available heap > IHOP If the check passes, a Minor event is immediately started, no matter if Eden was 3% or 93% full. This characteristic only has an effect during the Minor event cycle, during the Mixed event cycle the MPCMC will not be rerun by Humongous object allocations. As such, during Minor event cycles, Free space will be more quickly reclaimed from unused Humongous objects than during the Mixed event cycle. Overall then, it's probable that the duration of the Mixed event cycle will determine the peak Free space required to avoid To-space Exhaustion. Defending against Humongous objects There are two main strategies, which are often used in parallel, in defending against poor GC behavior due to Humongous objects. The first defense is to increase the G1HeapRegionSize such that fewer allocations qualify as Humongous objects. One can get scientific about picking the region size by running a GC log through a helper script . Be warned however, the G1GC algorithm is optimized to work with 2k regions and enlarging the region sizes such that there are only 128 regions may not result in better behavior. The second defense as alluded to earlier is to increase the Free space such that Eden will fill up first. The parameter -XX:G1ReservePercent (default 10) was created to allow a configurable floor on Free space, however there are caveats to this option as laid out in the section 'Controlling heap sizes'. More Concepts and Final Thoughts Now that we've gone through Mixed GC and the complications Humongous objects introduce, let's conclude by digging deep into a few concepts touched on earlier but left for later. Controlling Heap Sizes What are ideal heap allocations, and how are the heaps configured? The following list is a recap what has been learned so far with a few new facts thrown in. Eden size does not affect Minor STW times (except for apps with giant, churning caches) Tenured consists of the Working Set + G1HeapWastePercent The larger Eden is, the less overall time spent in STW Humongous objects/R.O.U.S. are mitigated through larger amounts of Free space Eden is configured as a range from G1NewSizePercent (default 5) to G1MaxNewSizePercent (default 60) InitiatingHeapOccupancyPercent (default 45) controls when Mixed events will start G1ReservePercent (default 10) will attempt to apply a lower bound on Free space For HubSpot's many REST API instances, as well as a few other services (Kafka and ZooKeeper), the ideal configuration is: IHOP 10-15% higher than the Working Set + G1HeapWastePercent Free space 10% Eden using the rest of the space (see below) MaxGCPauseMillis 50% higher than the average Minor GC time Complication - Not meeting MaxGCPauseMillis target The -XX:MaxGCPauseMillis (default 250) parameter is used to control the size of Eden. Should the target time consistently be met, the maximum size of the Eden range will be used. Should the target rarely/never be met, the minimum of the Eden range will be used. In theory the Eden value chosen could be somewhere in the middle of the range, but in these situations at HubSpot we generally see the chosen Eden size flap back and forth between the max and the min rather than stabilize in between. In the case where the MaxGCPauseMillis target is not being met, one can either increase the Eden lower bound G1NewSizePercent or increase the MaxGCPauseMillis target. Increasing the MaxGCPauseMillis target has proven to be the safer option because the lower end of the Eden range does not respect G1ReservePercent. Complication - G1NewSizePercent overrides G1ReservePercent The algorithm to choose the Eden size looks vaguely like the following: if (recent_STW_time < MaxGCPauseMillis) eden = min(100% - G1ReservePercent - Tenured, G1MaxNewSizePercent) else eden = min(100% - Tenured, G1NewSizePercent) Notice that G1ReservePercent is not a factor if the MaxGCPauseMillis is not being met. If the goal is to dedicate as much heap as possible to Eden, consider the following scenario. The MaxGCPauseMillis is not being met. Tenured generally sits around 15%, IHOP is set to 30%, the Eden range is the default 5-60%. A G1ReservePercent of 15% is considered safe as occasionally 5% of the Free space is occupied through To-space overflow. The goal for Eden is to use all unused space, which in this case would be 100% - 15% G1ReservePercent - (15-30% Tenured) = 55-70% range. If we do nothing, an Eden size of 5% will be used, which will result in lots of overall time spent in STW. If we set min Eden in the range of 55-70%, consider the heap distribution if a traffic spike or Request Of Unusual Size raises Tenured to 40%: 40% Tenured + 55-70% Eden = 95-110% The G1ReservePercent was previously set to 15% to add enough buffer to handle the common occurrence of To-space overflow of 5%. With min Eden set to 55%, there would only be 5% left of Free space for some period of time, greatly increasing the chances of To-space exhaustion. Complication - Humongous objects and/or R.O.U.S. If an application has many Humongous objects and/or R.O.U.S., increase the buffer of Free space set by G1ReservePercent. As per the previous section, there are a few caveats to consider when attempting to reserve a specified amount of Free space. Comments on -XX:MaxGCPauseMillis The effects of MaxGCPauseMillis are much more subtle than the name suggests and are primarily seen in two places: Helps choose the Eden size on each epoch. Not meeting the MaxGCPauseMillis goal will result in the minimum end of the Eden range to be used. Meeting the goal will result in the max size being used. Practical experience shows Eden gets set at the ends of the range and rarely anywhere in the middle. This has a major effect on overall time spent in STW as an Eden of 5% will run GC 12x times more frequently than an Eden of 60% of heap. Extends the cap on # of tenured regions that can be collected in a given Mixed GC event. The result could be slightly few Mixed GC events for slightly larger individual STW times of the remaining Mixed GC events. Setting MaxGCPauseMillis does not in any way guarantee that all STW times will be under the configured value. G1GC is complex and for many use cases will require a bit of tuning to get the desired results. In our experience poorly tuned G1GC can provide a much worse user experience than ParallelGC. All in all, G1GC has provided a ton of value for HubSpot, but only after we shifted our mentality from set-and-forget to active monitoring and tuning.", "date": "2016-04-14"},
{"website": "Hubspot", "title": "The Product Management Skill Stack", "author": ["Angela DeFranco"], "link": "https://product.hubspot.com/blog/the-product-management-skill-stack", "abstract": "In college, my Information Systems professor told my class about a career path that sounded perfect. It involved working with technology, making strategic business decisions, problem-solving, collaborating across teams, and a whole lot of responsibility. It was a position that seemed so general in scope that any smart, willing person (that was me!) could do it. As it turns out, I wasn’t alone in feeling that way about a job in product management - and now it seems like everyone these days is thinking about starting a career as a product manager. Seven years and multiple roles later, I've realized that my professor’s definition of what a product manager is and does is actually pretty vague. Some product managers do all of those things, while others have a completely different set of responsibilities. That’s probably because depending on your industry, company size, and so on, a product manager's day-to-day job can look really different. And frankly, I don’t see that changing anytime soon. Every time I meet with someone who's interested in the world of product management, whether it’s a new grad or fellow HubSpotter, they all have a different idea of what it would be like to be a product manager. To me, the primary responsibility of a product manager is to make sure my team builds a solution that provides value for our customers . They make products that people will love and even (hopefully!) pay for. That's how a product manager adds value to HubSpot, and that's the impact on which we measure product managers here. But that’s still sort of vague, isn’t it? To help break things down, these are the skills and perspectives that I’ve noticed make for successful product managers. (Not surprisingly, these are also what our product organization is usually looking for when interviewing and hiring a new product managers). The Product Manager Skill Stack Market Knowledge : A strong understanding of the product you're building and the space it's competing in. Product Knowledge : An understanding of how something gets built, and how to fail quickly and learn from those failures. Technical Knowledge : The ability to grasp the intricacies of the technology and its constraints (or the ability to code yourself) in order to earn the trust of your developers, designers, and others on your team. Customer Knowledge : The ability to both intimately and holistically know and understand the users you're building product for. I believe the best product managers out there have thoroughly developed all four of what I refer to as the \"product manager skill stack”. Associate Product Managers (or APMs, which are first-time product managers - not an entry-level job!) typically have keen potential or deep knowledge in at least one of the skills. At HubSpot, our APMs usually come from internal departments, places where they’ve gotten to know the business, our customers, our culture, or our product extremely well. Still, some internal candidates have a hard time demonstrating they have the skills they'll need to be successful, so we work with them to nurture those skills over time. That was me a few years ago. I was told that I wasn't ready to be a product manager, so I worked on strengthening my product management skill stack and demonstrating it to the team. It was one of the best and most humbling lessons of my career. Learning more about what a PM does at HubSpot , what it takes to get into product , and what types of questions I should be prepared for in my interview certainly helped prepare me for one of the most rewarding yet challenging roles I’ll likely ever have. If you're a recent grad or if you've never worked with a product organization, it's nearly impossible to develop a deep competence in one of those skill areas, let alone all four. Even if you're a computer science major who's started and exited a startup (giving you at least two of those four skills), you're still competing for product management jobs with people who have done that two or three times over in a varied career. If you’re a student or a professional looking to enter into an APM program, I’d recommend doubling down on developing one of those skills at a company you’re interested in working for first. That might mean starting in a customer support position (like I did) or sales role, which are much easier to break into without a technical background. Lastly, if you’re serious about getting into product management, you should definitely reach out to product managers at your company or product people in your network to chat. Don't go into the conversation blind; set yourself up for success and make the most of the time. Before you grab coffee, for example, try finding a product problem that you’re seeing in your role to bring to the discussion. That way, you'll have something concrete to talk about, and the person you're chatting with can get a sense of how you would approach challenges. That way, you can skip the “So what does a product manager do?” types of questions (which you likely already know the answer to) and get to the heart of it. The Product Problem Prioritization Process Once you’ve successfully demonstrated the skills above and secured a role as a product manager, you’re likely going to be asking… now what? Much of product management involves evaluating problems, prioritizing work, and deciding what to build. Of course, every product manager has their own style. Personally, there are four different perspectives I use to evaluate challenges when I'm figuring out the most valuable way my product team can spend their time. I like to call this framework the Four Lenses of Product Problem Prioritization (yes, it's a mouthful). The four lenses are: Market Lens : How will the market react to the solution to this problem? Is it old news? Does it stave off a potential disrupter? Do our competitors not think like this? Is the market sentiment shifting? Are our prospects seeking this solution in the market? Business Lens : How will the solution to this problem impact your company globally? Is solving this problem aligned with our brand and our mission? Does it help the company? Will building this allow a key company initiative to run better or more effectively? Technical Lens : Do we need to prioritize the solution immediately because something might break? Is focusing on fixing something now going to allow us to build better solutions in the future? Conversely, is something really cool and shiny going to take on a lot of tech debt for years to come? Customer Lens : How will the majority (usually over 80%) of customers respond to this? Is this a high-impact feature for a small subset of customers? How many support cases is this problem driving and what is the impact of prioritizing a solution? Will it make our customers more successful? Will it make them better at their jobs or happier in their lives? How do we know? Only after you’ve looked at a problem through all four lenses can you truly get a sense for the scope of impact and the magnitude of what you’re about to take on. If you only look at a problem through only one of those lenses, it can mean that you end up building the wrong solution, wasting your company’s money, and even hurting your team's morale. For example, if you’re a product manager and you prioritize something that was really hard to build, questionably valued in the market, and an amazing solution for only 6% of customers, you run the risk of losing some of the goodwill and trust that you’ve built with your engineers and designers over time. Just like in life, it’s good to zoom out and evaluate a situation from multiple perspectives before jumping in. If you’re a fellow product manager reading this - hello!  Let's chat in the comments about how you approach product problems differently, or if you have a different set of skills that have helped you be successful in your job. And if you’re an aspiring product manager, please let us know - we’re hiring and we’d love to hear from you.", "date": "2017-11-01"},
{"website": "Hubspot", "title": "Name Dropping, Kelsey Janda, VP of Design, Hudl", "author": ["Francesca McCaffrey (She/Her)"], "link": "https://product.hubspot.com/blog/name-dropping-kelsey-janda-vp-of-design-hudl", "abstract": "Name Dropping is a Q&A series that aims to elevate the stories of women and nonbinary people leading in the tech space. The idea came from Angela DeFranco, a VP of Product at HubSpot, who said one way to be better allies is to name drop more women and nonbinary people in discussions of achievement, inspiration, and disruptors in tech, instead of referencing, time and again, the same set of (often male) leaders. This edition of Name Dropping features Kelsey Janda , VP of Design at Hudl . When did you first decide you wanted to go into design and why? I was incredibly young! I knew I wanted to be a designer at 10 years old. Usually, people stumble into it later. I started studying information design in magazines. Instead of being wowed by the writing or the photography, the large drop caps and headlines pulled me in. I wanted to design provocative type like that. I would literally tear the pages out and tape them on my wall. Kids usually hang band posters, which I did, but I also hung up magazine layouts so I could try to recreate them. Later, I designed MySpace templates for friends and friends of friends. I loved crafting the layouts and creating cohesive color schemes. In high school, I joined journalism as a way to design. I didn’t want to write, I just wanted to make the newspaper look more like a magazine. During the same time, my brother was going to school for graphic design. I talked to one of his professors to figure out what steps I needed to take in high school to become a designer. He said I needed to take art classes to get into art school (there weren’t many design programs at this time). I panicked because I had never been good at drawing or painting but I picked it up quickly. After high school, I went to art school and the rest is history. You’re currently VP of design at Hudl. What’s one of your favorite design projects you’ve worked on with the team? One of my favorite things about Hudl is that we ship incredibly fast. Which means I’ve been able to design a lot in the last six years here. Hudl Assist is definitely a favorite. It’s a service that gives teams and coaches time back. Teams send us their game and our analysts will break it down, tagging objective data. It’s a huge relief for coaches, especially, because it means after the game they’ll have stats ready to digest instead of having to tag it themselves. I was on the cross-functional team creating the tagging product and interfaces for teams to submit their games. We started with basketball in 2015. Now, we provide this service for football, soccer, lacrosse, ice hockey and volleyball teams. It was humbling (and really fun!) to design a system that has scaled to so many sports and has become core to our business. What is one quality that you think every leader should have in order to generate impact and lead effectively? Vulnerability, hands down. I believe vulnerability is one of the fastest ways to build trust. And leaders need trust to generate impact and lead effectively. If you could change one thing about your career so far, what would it be? I go back and forth on this. I want to say that I’d tell myself to slow down. But if my husband or anybody else who knew me heard me say that, they’d laugh. I’m quite ambitious even if I don’t let myself see it. I hire people who found design in their second career. They didn’t necessarily go to design school or know they wanted to be a designer when they were 10 years old and it makes me wonder what would have happened if I would have slowed down a bit. However, I am where I am today and I’m so grateful. I work with the best and I want to continue building one hell of a design team who loves serving people (customers, users, and each other). How do you stay close to customer feedback? I try to weave it into my daily schedule and even start my day with it. I read their opinion through NPS feedback or surveys, look at engagement, sentiment and renewal dashboards and talk to my team who talks to their users daily. But there really is nothing that beats hearing feedback from customers directly just by talking with them (either on a sales or support call or a check-in). We have a Slack bot that shows who’s conducting interviews around specific products or features in a day. This makes it easy for me to sit in and listen. Accessibility in design is top of mind for many of today’s users. What advice do you have for design leaders looking to improve in this space? Become BFFs with your legal team. Accessibility is currently mandated state by state and country by country. As design leaders, it’s core to our role to understand accessibility needs. If you don’t have an in-house legal team, see if you have a lawyer on retainer. Sit down with them and ask them to explain the regulations. Build accessibility into your design system, too. Miranda Bouck , Lead Product Designer of Uniform (Hudl’s Design System), designs components that follow WCAG guidelines so it takes some of the lift off our design team. Who is one woman or nonbinary person in tech you would like to name drop and why? I’m going to name two. The first is Leigh-Ann Bartsch . She’s a Design Director at Policygenius . We used to work together at Hudl. She is a fantastic design leader. I personally define design as problem solving. Leigh-Ann’s ability to distill the problem down without making a customer or user speak in our technical language is powerful. That’s a skill that develops with time and experience. The other is Sally Carson . She’s Head of Product Design and User Research for Duo Security at Cisco . We met at Within , a design retreat for women in design leadership positions. She encouraged me to go for the VP of Design position at Hudl. I admire her leadership and grit, especially in the security industry, which is male-dominated. Do you have a favorite sport you’re looking forward to playing, watching, or just gathering data for when everything gets back to normal? So, spoiler alert: I’m not a huge sports fan. I started working for Hudl because I love solving problems for people. With sports, I get to serve customers and users who are diverse. They live all over the world, some who play, some who are fans, coaches or parents, young and old. However, I love the energy at games. Seeing a community come together to cheer people on is magical. Is there anything else you’d like to add? I would definitely love to plug Hudl for anybody looking for a job . Hudl is an amazing company that cares a lot about their employees. One of our values is we’re a family. It’s been really awesome to see us live that value through COVID-19. Know another woman or nonbinary person whose name we should drop? Tweet us at @HubSpotDev with ideas. This post originally appeared on Medium . Interested in working with people who care about thoughtful leadership? Check out our open positions and apply .", "date": "2020-12-07"},
{"website": "Hubspot", "title": "Why paying developers like salespeople looks a bit too much like a piece-rate system", "author": ["Steve Laniel"], "link": "https://product.hubspot.com/blog/bid/35234/why-paying-developers-like-salespeople-looks-a-bit-too-much-like-a-piece-rate-system", "abstract": "Patrick's post stimulated a lot of discussion here at HubSpot. I contributed one email to the discussion, which Yoav has asked me to post here: I feel compelled to mention a book that has had things to say to every part of this thread: Managerial Dilemmas: The Political Economy Of Hierarchy . I reviewed it on my blog . It's all about the theoretical troubles in building an organization that works, where everyone is lashed together and focusing on the same goals. Patrick's suggestion sounds troublingly like the piece-rate system mentioned in that book (and in the review). I'd recommend the book, anyway, if you're interested in some fun theory behind these questions.", "date": "2010-12-10"},
{"website": "Hubspot", "title": "Why We Built Our New CMS on a File-Centric System Instead of a Database-Centric One", "author": ["Mitchell Katz (He/Him)"], "link": "https://product.hubspot.com/blog/new-file-centric-cms-for-developers", "abstract": "Earlier this year, HubSpot announced the launch of our new CMS Hub , an integrated, deeply powerful, and easy-to-use content management system. The goal going into creating this product line was deceptively simple: give marketers the ease of use they want, and developers the tools they needed to make a powerful web experience. First, a little context. In the large field of CMS products available to companies, there’s often a stark tradeoff between power and ease-of-use. Options run the gamut from page builders with minimal developer tools to complex enterprise solutions that require dedicated developers and are so complicated that few companies are able to get their full value from them. In between those extremes, there are platforms that offer set themes and plugins more friendly to marketers, as well as static site builders that developers love because they can build in them in the tools and languages of their choice. The issue is that none of those solutions offer both simplicity and power. It’s that combination that developers and marketers need to create great business websites. The magic lies in serving both highly technical ‘backend’ users and less technical people who need to comfortably be able to work with content without worrying about \"breaking the website.” Recently, we wrote about how HubSpot CMS brings this magic to solving for marketers’ needs . Now, it’s time for us to delve into the changes that we made to solve for developers. First up: the implementation of the developer file system. The building blocks of content Websites in the HubSpot CMS are built off of several types of building blocks: Modules are a way for marketers to use a codeless UI to build their page in a WYSIWYG editor, Templates provide the base files for a page, be it HubL/HTML, CSS, or JS. All of these get bundled up into a Theme, which provides common styling across your website and works as a top-level package for the other asset types: Pages on a website are represented as objects in our Content database -- these object instances contain references to themes, templates, and modules used on a page as well as the configuration of those objects. All these asset types as well as the Content objects are all represented as rows in our large MySQL Content database and references are handled, essentially, by foreign key ids. While this is a common pattern for web applications, it doesn't match the way developers are used to working with their web assets. Our solution to this had historically been requiring developers to use an online IDE to build sites on the CMS, called Design Manager. But as engineers ourselves, we knew what developers really wanted: to use their local machine to write code, have source control, use their favorite IDE and build tools, etc. So the solution was pretty clear: if we wanted to create a better experience for developers on the HubSpot CMS, we needed to start representing these building blocks as actual files. And although that doesn’t sound like too crazy of an idea, we’d built years of code off of the object system and we couldn’t completely overhaul the internal workings of the CMS. Finding a solution in files Our solution to this came to be known as the ContentFileMapper. We created canonical definitions for how to represent Templates and Modules as files, and created a service to turn local files into the objects understood by the rest of the CMS. Some things were more straightforward than others. Templates were pretty close to real files already, just source code plus some metadata. We created a system of annotations to set the important metadata and then you can create a Template with just an HTML file: Image is from our opensource boilerplate repo: https://github.com/HubSpot/cms-theme-boilerplate/blob/master/src/templates/about.html Modules, however, were much more complicated. A module is built out of module-specific CSS, JS, HTML/HubL, and it provides specific fields to be set in the UI. We needed a way to define all of these components locally, plus have them bundled together. An example module in the Design Manager IDE shows all of the different components that need a way to be defined So the mapper defined a special folder suffix (.module) and specific file types contained within that folder: module.css, module.html, module.js, meta.json, fields.json. Combined, the mapper can turn these local files into a full module object for the rest of the HubSpot CMS. We kept building out these local file definitions and it unlocked a world of possibility for us. Because we now represent everything with files in a traditional folder tree, it means we could stop using foreign key IDs to cross reference assets and use their paths. It means that developers can store their files in GitHub and have real source control. It means that assets can actually be pulled down from one HubSpot portal and uploaded to another without needing any shenanigans with changing references to IDs that would have been automatically regenerated in the old world. Creating this mapping layer from files to objects has allowed HubSpot CMS developers to have much more power with the HubSpot CMS.", "date": "2020-08-18"},
{"website": "Hubspot", "title": "Taking lessons from agile development home", "author": ["Wassaf Farooqi"], "link": "https://product.hubspot.com/blog/bid/58544/taking-lessons-from-agile-development-home", "abstract": "I learned quite a bit in the software world can be applied to the real world as well.  Today, we will talk about one project which I've managed to totally screw up due to poor story planning. The overall epic was this - I got some snow wheels/tires for my car, and was going to store the summer wheels/tires at my parents or in-laws garage at some point in the next few weeks.  In the meanwhile, I'd put them in a corner of my house.  Today, I worked on the story of \"Move the wheels from the car to my house so that I can use my trunk until I make time to go to parents house\".  The problem was in my tasking.  I looked for what I thought to be the most efficient way to solve this story, but not thinking about the risks to the overall epic. My tasks were: Move car to front of house where snow is clear Move all tires to the front porch Bring one tire at a time up to spot in second bedroom where they can live. It seems pretty reasonable.  I wanted to do it his way so I wouldn't have to go inside and outside and change shoes/track snow in the house.  This unfortunately was a huge mistake.  I did not complete the research story of \"exactly how heavy is a tire+wheel\".  Instead, I got a feel for it bringing them to the front porch and thought \"Not bad\".  BUT - when I brought the first one up two flights of stairs in the house, I realized this was going to be tough.  After bringing the second one up, I'm now exhausted, and am in a half complete story.  The rear tires are 15 pounds heavier than the front tires.  The story is half done.  Getting the tires back in the car will be a pain now.  I don't want to bring them back downstairs. So - what should I have done?  Realize how heavy the rear tires were and then break the story down even more!  If I treated each tire, or even the first tire as an individual story, it would be easier for me to have backed out.  I could have decided \"Well - bringing all of these out of hte car and upstairs is a terrible idea.  Let's think of a new story, ie - find a friend local who has a garage to store these at temporarily\" Or even try make time today to just bring them to a parents house and complete the epic. My takeaway - even in agile development, don't forget about the end goal that the stories come to.  If a task makes progress but doesn't make sense, stop and replan.  Don't finish something for the sake of finishing something.   So what are your stories of life lessons where better planning and making stories smaller would have been better for you?  Also, any advice on hiding these from the Mrs. so I can just leave them at my home?", "date": "2011-01-23"},
{"website": "Hubspot", "title": "Name Dropping: Dea Mandery, Senior Director of Agile Coaching, Hudl", "author": ["Francesca McCaffrey (She/Her)"], "link": "https://product.hubspot.com/blog/name-dropping-dea-mandery-senior-director-of-agile-coaching-hudl", "abstract": "Name Dropping is a Q&A series that aims to elevate the stories of women and nonbinary people leading in the tech space. The idea came from Angela DeFranco, a VP of Product at HubSpot, who said one way to be better allies is to name drop more women and nonbinary people in discussions of achievement, inspiration, and disruptors in tech, instead of referencing, time and again, the same set of (often male) leaders. This edition of Name Dropping features Dea Mandery , Senior Director of Agile Coaching at sports analytics company Hudl . What does a typical day entail for you? My top priorities at Hudl are coaching the ScrumMaster chapter (SM), serving as a member of the Product Leadership Team, and coaching squads or individual contributors that are seeking Agile advice. As ScrumMasters, we work hard at practicing the Scrum framework as intended: a simple process framework to rapidly do work and get feedback on it. We don’t complicate it. I talk about this simplicity with new hires at Hudl. Each time I do, I Google Scrum to see how many results pop up. When I first started giving the new hire presentation a couple of years ago there were just under 5 million results. Doing a quick search now, what do I get? 16 million. New add-ons seem to spring up every day. We focus instead on solving the problems the framework uncovers head-on. It’s difficult work, but worth it. It fits well with our company value of being “Respectfully Blunt.” We aren’t perfect at practicing Scrum and we’re always working to improve. But our SM Chapter likes to say “We have good problems to solve.” These good problems take up the bulk of my day. I also coach on a daily basis. I prefer embedding with a squad or business unit and focusing on them for a longer period of time. I’ve had to learn the hard way — and am still learning — to avoid giving a little bit of advice to a lot of people. I also avoid “inflicting help.” It’s very tempting sometimes, but focusing instead on concerns or requests for help that bubble up from squads or business units themselves yields better outcomes. How has going fully remote during quarantine changed the way you work? Are there any improvements you’re going to carry over once once things are back to normal? For me personally, not a lot has changed. I often found myself in video calls and Zoom meetings before the pandemic because we’re a global company. We have ScrumMasters working in Omaha, London, Sydney (Australia, not Nebraska), Boston, and Den Bosch in the Netherlands. Zoom calls were our go-to for bi-weeklys, chapter meetings, and Scrum events. The most challenging part for most Hudlies was quickly figuring out a work from home setup while sharing space with school aged children (and extra duties), spouses working from home, and roommates working from home. That’s probably true of most companies, but to ease that strain we were able to get equipment from local offices, had a WFH equipment stipend early in the pandemic, and leaned into our unlimited time off benefit. I think our familiarity with Zoom and our global distribution of people, coupled with company support, made it easier for us than many companies. There have been some good things to come out of this that we’re going to carry forward. One of the most positive things is having a better sense of awareness of how remote employees feel. While we were good at the technology to enable remote working, a lot of people had never or rarely worked remotely before. We have many fully remote and internationally distributed Hudlies who routinely joined meetings on Zoom and would be staring at a conference room full of people. It was difficult to see who was at the far end of the table, or figure out who was speaking. Internet lag, and getting off mute quickly made it challenging to contribute without interrupting and being behind. Our level of awareness is so much greater now regarding how difficult it can be to work remotely. It’s been an eye-opening experience, and it’s something that will be top of mind and change how we work when we return to the office. Your educational background is in Agricultural Economics. What was your career journey into technology like? I’m an accidental ScrumMaster, and it was definitely a journey! I didn’t know much about technology when I was in college. The closest thing in my Ag Econ major was going to computer labs to complete my assignments in Lotus 123. We had to know our way around macros and formulas pretty well, but it was a far cry from programming. A lot of my coursework was around modeling and data sets, and I’ve always been drawn to analytics; those skills are still helpful to me today, but I didn’t decide to become a ScrumMaster when I completed my degree. After college I went into banking where I did a lot of credit analysis, some loan origination, and then became a lender. During that time, I responded to an interesting Sunday newspaper ad and ended up getting a job in online learning. I found technology intrigued me. The job involved development of new programming that could be delivered mostly online, with short face to face sessions woven in. I was so fortunate that during that period of time there was a huge emphasis in improving both access to and validity of online learning. There were a lot of audiences craving it: rural audiences, military members, medical professionals, and of course — people working full time that wanted to complete or advance their education. This interest allowed for a lot of experimentation and reimagining education. I loved the ability to try things out (early days of prototyping?) and get feedback from students on how it worked. We did very interesting work and had a lot of talented people, but I was constantly stumped by why we had such a difficult time getting project work done. We routinely found ourselves in a long cleanup phase that was frustrating and tiring and demoralizing for the team. We got better at it, but didn’t figure out how to be good at it. Shortly after my time in higher ed, I was laid off during the Great Recession. I found myself looking for jobs and responded to an ad to help out a ScrumMaster and accidentally became a ScrumMaster myself. Right away I was hooked because I could see how the framework helped teams succeed in a way that wasn’t possible in previous project work that I’d struggled to improve. I’ve been a ScrumMaster ever since and have helped several companies with agile implementation. Think about the best engineers or product people you’ve ever worked with. What qualities did they have? Natural curiosity and willing skepticism. The natural curiosity to try solving a problem a few different ways, sometimes by taking their hands off the keyboard and thinking deeply about a problem. The engineers that don’t necessarily code first to solve a problem tend to be the most innovative. Willing skeptic isn’t my term; but it’s one that made sense early on in Scrum implementations I was working on. I don’t expect anybody to just accept what I tell them about Scrum. Those who are skeptical, but willing to give it a try, usually get the most out of it. I’ve also noticed that engineers with these traits are good team members. They are usually willing to not only be a specialist at what they do, but also to become a generalist at something else. Maybe that’s because of natural curiosity. What are some of the most interesting challenges your team is trying to solve right now? We’re in a market that stopped in its tracks a little under a year ago. Sports halted at the beginning of the pandemic. Most have started again, but our market is still far from normal. We learned during this strange time how to make our product useful in new ways while our customers adapted how they play sports. We’ve never been through a period of time where teams weren’t playing, and it was scary. We didn’t know how long it would last. We still don’t know how far away normal is for our customers, and what parts of their new workflows will become permanent. The biggest challenge was pivoting to the needs of our customers so frequently. We believe we’re coming out of the stop in sports with improved products and poised to serve our customers even better than we were before. Who’s one woman or nonbinary person in technology you’d like to name drop, and why? When I look at my bookshelf there are many influences, specifically in learning Scrum. Many of those people I’ve listened to at conferences and on podcasts as well. Diana Larsen comes to mind, and Esther Derby as well. I don’t know them personally, but they’ve certainly influenced how I work. Early on, I got their books because I learned one of the major success factors of a Scrum team is great squad dynamics. Building the right squad, with the right skill set and mix of personalities, then keeping that intact and healthy as long as you can is a lot of the magic. Their contributions in that area have been a huge influence in how I work with individual squads and how I coach. They are great at the mechanics of Scrum as well, but their work and influence on psychological safety and squad dynamics helped me a great deal. I can think of two different times this week where their influences got my ScrumMaster/ Agile Coach spidey senses tingling and thinking: Hmm, there’s something else going on underneath this. This is not how this squad or this person normally acts or behaves, and there must be something else going on. I was able to get a one-on-one Zoom with them and talk through what’s really going on here. And sure enough, we uncovered something that was a big process hiccup, which led to a misunderstanding we were able to smooth out. Without their influence, I would probably pay more attention to delivery and impediment removal. I encourage anyone who’s interested in Agile coaching to read anything they can from them, listen to them, and follow them. What book do you think every product leader should read and why? The Art of Doing Twice the Work in Half the Time , by Jeff and J.J. Sutherland. It breaks down the end goal of Scrum. Even if you’re not interested in Scrum, but interested in better efficiency and curious about what might be slowing you down, this is a great book. The other is Inspired , by Marty Cagan. If you’re in a product company, this is a must read. As I was reading his book, I was thinking, Oh, yeah! All the really good product owners I’ve ever worked with do these things!! . He does an excellent job of giving examples and laying good product work out in practice. It quantified so much for me about what my really fantastic product owners had been doing. We don’t have project managers, and we don’t have product owners at Hudl. I dug really deep into this book because product management is so different than product ownership for an internal project — like migrating to a new system. I had worked on products in the past, but I couldn’t articulate what set good product managers and companies apart. No matter what role you have in a product company, this is a must-read. How have you gotten creative with your plans this year during quarantine? The most creative thing we did was rethink a high school graduation party to be safe and socially distant. The biggest hit was individually wrapped hotdogs, like you get at a concession stand. Why do they taste so much better coming out of that wrapper? Know another woman or nonbinary person whose name we should drop? Tweet us at @HubSpotDev with ideas. This post originally appeared on Medium . Interested in working with people who care about thoughtful leadership? Check out our open positions and apply .", "date": "2021-04-09"},
{"website": "Hubspot", "title": "Tuning G1GC For Your HBase Cluster", "author": ["Graham Baecher"], "link": "https://product.hubspot.com/blog/g1gc-tuning-your-hbase-cluster", "abstract": "HBase is the big data store of choice for engineering at HubSpot. It’s a complicated data store with a multitude of levers and knobs that can be adjusted to tune performance. We’ve put a lot of effort into optimizing the performance and stability of our HBase clusters, and recently discovered that suboptimal G1GC tuning was playing a big part in issues we were seeing, especially with stability. Each of our HBase clusters is made up of 6 to 40 AWS d2.8xlarge instances serving terabytes of data. Individual instances handle sustained loads over 50k ops/sec with peaks well beyond that. This post will cover the efforts undertaken to iron out G1GC-related performance issues in these clusters. If you haven't already, we suggest getting familiar with the characteristics, quirks, and terminology of G1GC first. We first discovered that G1GC might be a source of pain while investigating frequent “...FSHLog: Slow sync cost: ### ms...” messages in our RegionServer logs. Their occurrence correlated very closely to GC pauses, so we dug further into RegionServer GC. We discovered three issues related to GC: One cluster was losing nodes regularly due to long GC pauses. The overall GC time was between 15-25% during peak hours. Individual GC events were frequently above 500ms, with many over 1s. Below are the 7 tuning iterations we tried in order to solve these issues, and how each one played out. As a result, we developed a step-by-step summary for tuning HBase clusters that you can find and follow here . Original GC Tuning State The original JVM tuning was based on an Intel blog post , and over time morphed into the following configuration just prior to our major tuning effort. Xmx32g -Xms32g 32 GB heap, initial and max should be  the same XX:G1NewSizePercent= 3-9 Minimum size for Eden each epoch,  differs by cluster XX:MaxGCPauseMillis=50 Optimistic target, most clusters take  100+ ms XX:-OmitStackTraceInFastThrow Better stack traces in some  circumstances, traded for a bit more  CPU usage XX:+ParallelRefProcEnabled Helps keep a lid on reference  processing time issues were were  seeing XX:+PerfDisableSharedMem Alleged to protect against bizarre linux  issue XX:-ResizePLAB Alleged to save some CPU cycles in  between GC epochs GC logging verbosity as shown below was cranked up to a high enough level of detail for our homegrown gc_log_visualizer script. The majority of graphs in this document were created with gc_log_visualizer, while others were snapshotted from SignalFX data collected through our CollectD GC metrics plugin . Our GC logging params: -verbosegc -XX:+PrintGC -XX:+PrintGCDateStamps -XX:+PrintAdaptiveSizePolicy -XX:+PrintGCDetails -XX:+PrintGCApplicationStoppedTime -XX:+PrintTenuringDistribution Starting Point: Heap Sizes and Overall Time Spent in GC With the highly detailed GC logs came the following chart of heap state. Eden size is in red and stays put at its minimum ( G1NewSizePercent ) , 9% of total heap. Tenured size, or Working set + waste, floats in a narrow band between 18-20gb. With Eden a flat line, the total heap line will mirror the Tenured line, just 9% higher. The black horizontal line just under 15GB marks the InitiatingHeapOccupancyPercent (aka “IHOP”), at its default setting of 45%. The purple squares are the amount of Tenured space reclaimable at the start of a mixed GC event. The floor of the band of purple squares is 5% of heap, the value of G1HeapWastePercent . The next graph shows a red “+” on each minute boundary and stands for the total percent of wall time the JVM was in STW and doing no useful work. The overall time spent in GC for this HBase instance for this time period is 15-25%. For reference, an application tier server spending 20%+ time in GC is considered stuck in “GC Hell” and in desperate need of tuning. Tuning #1 Goal: Lower Total Time in GC - Action: Raise IHOP One aspect that stands out clearly in the previous graph of heap sizes is that the working set is well above the IHOP. Tenured being higher than IHOP generally results in an overabundance of MPCMC runs (wastes CPU) and consequently an overabundance of Mixed GC cycles resulting in a higher ratio of expensive GC events vs cheap GC events. By moving IHOP a bit higher than Tenured, we expect fewer Mixed GC events to reclaim larger amounts of space, which should translate to less overall time spent in STW. Raising the IHOP value on an hbase instance, the following before/after (above/below) graphs show that indeed the frequency of Mixed GC events drops dramatically while the reclaimable amount rises. Considering that at least half of Mixed GC events on this instance took 200-400ms, we expected the reduced amount of Mixed GC events to outweigh any increase in individual Mixed GC times, such that overall GC time would drop. That expectation held true, as overall time spent in GC dropped from 4-12% to 1-8%. The following graphs show before/after on the STW times for all Mixed GC events. Note the drastic drop in frequency while individual STW times don't seem to change. Result: Success This test was considered successful. We made the change across all HBase clusters to use a significantly larger IHOP value than the default of 45%. Tuning #2 Goal: Lower Total Time in GC - Action: Increase Eden Fixing the IHOP value to be higher than working set was basically fixing a misconfiguration. There was very little doubt that nonstop MPCMC + Mixed GC events was an inefficient behavior. Increasing Eden size, on the other hand, had a real possibility of increasing all STW times, both Minor and Mixed. GC times are driven by the amount of data being copied (surviving) from one epoch to the next, and databases like HBase are expected to have very large caches. A 10+ GB cache could very well have high churn and thus high object survival rates. The effective Eden size for our HBase clusters is driven by the minimum Eden value G1NewSizePercent because the MaxGCPauseMillis target of 50ms is never met. For this test, we raised Eden from 9% to 20% through G1NewSizePercent . Effects on Overall GC Time Looking at the following graphs, we see that overall time spent in GC may have dropped a little for this one hour time window from one day to the next. Individual STW times Looking at the STW times for just the Minor GC events there is a noticeable jump in the floor of STW times. To-space Exhaustion Danger As mentioned in the G1GC Foundational blog post , G1ReservePercent is ignored when the minimum end of the Eden range is used. The working set on a few of our HBase clusters is in the 70-75% range, which combined with a min Eden of 20% would leave only 5-10% of heap free for emergency circumstances. The downside of running out of free space, thus triggering To-space Exhaustion, is a 20+ sec GC pause and the effective death of the HBase instance. While the instance would recover, the other HBase instances in the cluster would consider it long dead before the GC pause completed. Result: Failure The overall time spent in GC did drop a little as theoretically expected, unfortunately the low end of Minor GC stw times increased by a similar percent. In addition, the risk for To-space exhaustion increased. The approach of increasing G1NewSizePercent to reduce overall time spent in GC didn't look promising and was not rolled out to any clusters. Tuning #3 Goal: Reduce Individual STW Durations - Action: SurvivorRatio & MaxTenuringThreshold In the previous tuning approach, we found that STW times increased as Eden size increased. We took some time to dig a little deeper into Survivor space to determine if there was any To-space overflow or if objects could be promoted faster to reduce the amount of object copying being done. To collect the Survivor space tenuring distribution data in the GC logs we enabled - XX:+PrintTenuringDistribution and restarted a few select instances. To-space overflow is the phenomenon where the Survivor To space isn't large enough to fit all the live data in Eden at the end of an epoch. Any data collected after Survivor To is full is added to Free regions, which are then added to Tenured. If this overflow is transient data, putting it in Tenured is inefficient as it will be expensive to clean out. If that was the case, we'd need to increase SurvivorRatio . On the other hand, consider a use case where any object that survives two epochs will also survive ten epochs. In that case, by ensuring that any object that survives a second epoch is immediately promoted to Tenured, we would see a performance improvement since we wouldn’t be copying it around in the GC events that followed. Here’s some data collected from the PrintTenuringDistribution parameter: Desired survivor size 192937984 bytes, new threshold 2 (max 15) - age 1: 152368032 bytes, 152368032 total - age 2: 147385840 bytes, 299753872 total [Eden: 2656.0M(2656.0M)->0.0B(2624.0M) Survivors: 288.0M->320.0M Heap: 25.5G(32.0G)->23.1G(32.0G)] An Eden size of 2656 MB with SurvivorRatio=8 (default) yields a 2656/8 = 332 MB survivor space. In the example entries we see enough room to hold two ages of survivor objects. The second age here is 5mb smaller than the first age, indicating that in the interval between GC events, only 5/152 = 3.3% of the data was transient. We can reasonably assume the other 97% of the data is some kind of caching. By setting - XX:MaxTenuringThreshold=1 , we optimize for the 97% of cached data to be promoted to Tenured after surviving its second epoch and hopefully shave a few ms of object copy time off each GC event. Result: Theoretical Success Unfortunately we don't have any nice graphs available to show these effects in isolation. We consider the theory sound and rolled out -XX:MaxTenuringThreshold=1 to all our clusters. Tuning #4 Goal: Eliminate Long STW Events - Action: G1MixedGCCountTarget & G1HeapWastePercent Next, we wanted to see what we could do about eliminating the high end of Mixed GC pauses. Looking at a 5 minute interval of our Mixed GC STW times, we saw a pattern of sharply increasing pauses across each cycle of 6 mixed GCs: That in and of itself should not be considered unusual, after all that behavior is how the G1GC algorithm got it's name. Each Mixed GC event will evacuate 1/ G1MixedGCCountTarget of the high-waste regions (regions with the most non-live data). Since it prioritizes regions with the most garbage, each successive Mixed GC event will be evicting regions with more and more live objects. The chart shows the performance effects of clearing out regions with more and more live data: the Mixed event times start at 100ms at the beginning of a mixed GC cycle and range upwards past 600ms by the end. In our case, we were seeing occasional pauses at the end of some cycles that were several seconds long. Even though they were rare enough that our average pause time was reasonable, pauses that long are still a serious concern. Two levers in combination can be used together to lessen the “scraping the bottom of the barrel” effect of cleaning up regions with a lot of live data: G1HeapWastePercent : default (5) → 10. Allow twice as much wasted space in Tenured. Having 5% waste resulted in 6 of the 8 potential Mixed GC events occurring in each Mixed GC cycle. Bumping to 10% waste should chop off 1-2 more of the most expensive events of the Mixed GC cycle. G1MixedGCCountTarget : default (8) → 16. Double the target number of Mixed GC events each Mixed GC cycle, but halve the work done by each GC event. Though it’s an increase to the number of GC events that are Mixed GC events, STW times of individual Mixed events should drop noticeably. In combination, we expected doubling the target count to drop the average Mixed GC time, and increasing the allowable waste to eliminate the most expensive Mixed GC time. There should be some synergy, as more heap waste should also mean regions are on average slightly less live when collected. Waste heap values of 10% and 15% were both examined in a test environment. (Don’t be alarmed by the high average pause times--this test environment was running under heavy load, on less capable hardware than our production servers.) Above: 10% heap waste; below: 15% heap waste: The results are very similar. 15% performed slightly better, but in the end we decided that 15% waste was unnecessarily much. 10% was enough to clear out the \"scraping the bottom of the barrel\" effect such that the 1+ sec Mixed GC STW times all but disappeared in production. Result: Success Doubling G1MixedGCCountTarget from 8 to 16 and G1HeapWastePercent from 5 to 10 succeeded in eliminating the frequent 1s+ Mixed GC STW times. We kept these changes and rolled them out across all our clusters. Tuning #5 Goal: Stop Losing Nodes: Heap Size and HBase Configs While running load tests to gauge the effects of the parameters above, we also began to dig into what looked like evidence of memory leaks in a production cluster. In the following graph we see the heap usage slowly grow over time until To-space Exhaustion, triggering a Full GC with a long enough pause to get the HBase instance booted from the cluster and killed: We've got several HBase clusters, and only one cluster occasionally showed this type of behavior.  If this issue were a memory leak, we'd expect the issue to arise more broadly, so it looks like HBase is using more memory in this cluster than we expected. To understand why, we looked into the heap breakdown of our RegionServers. The vast majority of an HBase RegionServer’s Tenured space is allocated to three main areas: Memstore : region server’s write cache; default configuration caps this at 40% of heap. Block Cache : region server’s read cache; default config caps at 40% of heap. Overhead : the vast majority of HBase’s in-memory overhead is contained in a “static index”. The size of this index isn’t capped or configurable, but HBase assumes this won’t be an issue since the combined cap for memstore and block cache can’t exceed 80%. We have metrics for the size of each of these, from the RegionServer’s JMX stats: “memStoreSize,” “blockCacheSize,” and “staticIndexSize.” The stats from our clusters show that HBase will use basically all of the block cache capacity you give it, but memstore and static index sizes depend on cluster usage and tables. Memstore fluctuates over time, while static index size depends on the RegionServer’s StoreFile count and average row key size. It turned out, for the cluster in question, that the HBase caches and overhead combined were actually using more space than our JVM was tuned to handle. Not only were memstore and block cache close to capacity—12 GB block cache, memstore rising past 10GB—but the static index size was unexpectedly large, at 6 GB. Combined, this put desired Tenured space at 28+ GB, while our IHOP was set at 24 GB, so the upward trend of our Tenured space was just the legitimate memory usage of the RegionServer. With this in mind, we judged the maximum expected heap use for each cluster’s RegionServers by looking at the cluster maximum memstore size, block cache size, and static index size over the previous month, and assuming max expected usage to be 110% of each value. We then used that number to set the block cache and memstore size caps ( hfile.block.cache.size & hbase.regionserver.global.memstore.size ) in our HBase configs. The fourth component of Tenured space is the heap waste, in our case 10% of the heap size. We could now confidently tune our IHOP threshold by summing the max expected memstore, block cache, static index size, 10% heap for heap waste, and finally 10% more heap as a buffer to avoid constant mixed GCs when working set is maxed (as described in Tuning #1). However, before we went ahead and blindly set this value, we had to consider the uses of heap other than Tenured space. Eden requires a certain amount of heap (determined by G1NewSizePercent ), and a certain amount (default 10%) is Reserved free space. IHOP + Eden + Reserved must be ≤ 100% in order for a tuning to make sense; in cases where our now-precisely-calculated IHOP was too large for this to be possible, we had to expand our RegionServer heaps. To determine minimum acceptable heap size, assuming 10% Reserved space, we used this formula: Heap ≥ (M + B + O + E) ÷ 0.7 M = max expected memstore size B = max expected block cache size O = max expected overhead (static index) E = minimum Eden size When those four components add up to ≤ 70% of the heap, then there will be enough room for 10% Reserved space, 10% heap waste, and 10% buffer between max working set and IHOP. Result: Success We reviewed memory usage of each of our clusters and calculated correct heap sizes and IHOP thresholds for each. Rolling out these changes immediately ended the To-space Exhaustion events we were seeing on the problematic cluster. Tuning #6 Goal: Eliminate Long STW Events - Action: Increase G1 Region Size We’d rolled out HBase block cache & memstore config changes, changes to G1HeapWastePercent and G1MixedGCCountTarget , and an increase in heap size on a couple clusters (32 GB → 40+ GB) to accommodate larger IHOP. In general things were smooth, but there were still occasional Mixed GC events taking longer than we were comfortable with, especially on the clusters whose heap had increased. Using gc_log_visualizer, we looked into what phase of Mixed GC was the most volatile and noticed that Scan RS times correlated: A few Google searches indicated that Scan RS time output in the GC logs is the time taken examining all the regions referencing the tenured regions being collected. In our most recent tuning changes, heap size had been bumped up, however the G1HeapRegionSize remained fixed at 16 MB. Increasing the G1HeapRegionSize to 32 MB eliminated those high scan times: Result: Success Halving the G1 region count cleared out the high volatility in Scan RS times. According to G1GC documentation, the ideal region count is 2048, so 16 MB regions were perfect for a 32 GB heap. However, this tuning case led us to believe that for HBase heaps without a clear choice of region size, in our case 40+ GB, it’s much better to err on the side of fewer, larger regions. Tuning #7 Goal: Preventing RegionServer To-space Exhaustion - Action: Extra Heap as Buffer At this point, our RegionServers were tuned and running much shorter and less frequent GC Events. IHOP rested above Tenured while Tenured + Eden remained under the target of 90% total heap. Yet once in awhile, a RegionServer would still die from a To-space exhaustion triggered Full GC event as shown in the following graph. It looks like we did everything right—there’s lot’s of reclaimable space and Tenured space drops well below IHOP with each Mixed GC. But right at the end, heap usage spikes up and we hit To-space Exhaustion. And while it’s likely the HBase client whose requests caused this problem could be improved to avoid this*, we can’t rely on our various HBase clients to behave perfectly all the time. In the scenario above, very bursty traffic caused Tenured space to fill up the heap before the MPCMC could complete and enable a Mixed GC run. To tune around this, we simply added heap space**, while adjusting IHOP and G1NewSizePercent down to keep them at the same GB values they had been at before. By doing this we increased the buffer of free space in the heap above our original 10% default, for additional protection against spikes in memory usage. Result: Success Increasing heap buffer space on clusters whose HBase clients are known to be occasionally bursty has all but eliminated Full GC events on our RegionServers. Notes: * Block cache churn correlates very closely with time spent in Mixed GC events on our clusters (see chart below). A high volume of Get and Scan requests with caching enabled unnecessarily (e.g. requested data isn’t expected to be in cache and isn’t expected to be requested again soon) will increase cache churn as data is evicted from cache to make room for the Get/Scan results. This will raise the RegionServer’s time in GC and could contribute to instability as described in this section. Chart: % time in Mixed GC is in yellow (left axis); MB/sec cache churn is in blue (right axis): ** Another potential way to tune around this issue is by increasing ConcGCThreads (default is ¼ ParallelGCThreads ). ConcGCThreads is the number of threads used to do the MPCMC, so increasing it could mean the MPCMC finishes sooner and the RegionServer can start a Mixed GC before Tenured space fills the heap. At HubSpot we’ve been satisfied with the results of increasing our heap size and haven’t tried experimenting with this value. Overall Results: Goals Achieved! After these cycles of debugging and tuning G1GC for our HBase clusters, we’ve improved performance in all the areas we were seeing problems originally: Stability: no more To-space Exhaustion events causing Full GCs. 99th percentile performance: greatly reduced frequency of long STW times. Avg. performance: overall time spent in GC STW significantly reduced. Summary: How to Tune Your HBase Cluster Based on our findings, here’s how we recommend you tune G1GC for your HBase cluster(s): Before you start: GC & HBase monitoring Track block cache, memstore & static index size metrics for your clusters in whatever tool you use for charts and monitoring, if you don’t already. These are found in the RegionServer JMX metrics: “memStoreSize” “blockCacheSize” “staticIndexSize” You can use our collectd plugin to track G1GC performance over time, and our gc_log_visualizer for insight on specific GC logs. In order to use these you’ll have to log GC details on your RegionServers: -Xloggc: $GC_LOG_PATH -verbosegc -XX:+PrintGC -XX:+PrintGCDateStamps -XX:+PrintAdaptiveSizePolicy -XX:+PrintGCDetails -XX:+PrintGCApplicationStoppedTime -XX:+PrintTenuringDistribution Also recommended is some kind of GC log rotation, e.g.: -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles= 5 -XX:GCLogFileSize=20M Step 0: Recommended Defaults We recommend the following JVM parameters and values as defaults for your HBase RegionServers (as explained in Original GC Tuning State ): -XX:+UseG1GC -XX:+UnlockExperimentalVMOptions -XX:MaxGCPauseMillis=50 This value is intentionally very low and doesn’t actually represent a pause time upper bound. We recommend keeping it low to pin Eden to the low end of its range (see Tuning #2 ). -XX:-OmitStackTraceInFastThrow -XX:ParallelGCThreads = 8+(logical processors-8)(5/8) -XX:+ParallelRefProcEnabled -XX:+PerfDisableSharedMem -XX:-ResizePLAB Step 1: Determine maximum expected HBase usage As discussed in the Tuning #5 section , before you can properly tune your cluster you need to know your max expected block cache, memstore, and static index usage. Using the RegionServer JMX metrics mentioned above, look for the maximum value of each metric across the cluster: Maximum block cache size. Maximum memstore size. Maximum static index size. Scale each maximum by 110%, to accommodate even for slight increase in max usage. This is your usage cap for that metric: e.g. a 10 GB max recorded memstore → 11 GB memstore cap. Ideally, you’ll have these metrics tracked for the past week or month, and you can find the maximum values over that time. If not, be more generous than 110% when calculating memstore and static index caps. Memstore size especially can vary widely over time. Step 2: Set Heap size, IHOP, and Eden size Start with Eden size relatively low: 8% of heap is a good initial value if you’re not sure. -XX:G1NewSizePercent=8 See Tuning #2 for more about Eden sizing. Increasing Eden size will increase individual GC pauses, but slightly reduce overall % time spent in GC. Decreasing Eden size will have the opposite effect: shorter pauses, slightly more overall time in GC. Determine necessary heap size, using Eden size and usage caps from Step 1: From Tuning #5 : Heap ≥ (M + B + O + E) ÷ 0.7 M = memstore cap , GB B = block cache cap , GB O = static index cap , GB E = Eden size , GB Set JVM args for fixed heap size based on the calculated value, e.g: -Xms40960m -Xmx40960m Set IHOP in the JVM, based on usage caps and heap size: IHOP = ( memstore cap ’s % heap + block cache cap ’s % heap + overhead cap ’s % heap + 20 ) -XX:InitiatingHeapOccupancyPercent = IHOP Step 3: Adjust HBase configs based on usage caps Set block cache cap and memstore cap ratios in HBase configs, based on usage caps and total heap size. In hbase-site.xml: hfile.block.cache.size → block cache cap ÷ heap size hbase.regionserver.global.memstore.size → memstore cap ÷ heap size Step 4: Adjust additional recommended JVM flags for GC performance From Tuning #3 : -XX:MaxTenuringThreshold=1 From Tuning #4 : -XX:G1HeapWastePercent=10 -XX:G1MixedGCCountTarget=16 From Tuning #6 : -XX:G1HeapRegionSize = #M # must be a power of 2, in range [1..32]. Ideally, # is such that: heap size ÷ # MB = 2048 regions. If your heap size doesn’t provide a clear choice for region size, err on the side of fewer, larger regions. Larger regions reduce GC pause time volatility. Step 5: Run it! Restart your RegionServers with these settings and see how they look. Remember that you can adjust Eden size as described above, to optimize either for shorter individual GCs or for less overall time in GC. If you do, make sure to maintain Eden + IHOP ≤ 90%. If your HBase clients can have very bursty traffic, consider adding heap space outside of IHOP and Eden (so that IHOP + Eden adds up to 80%, for example). Remember to update % and ratio configs along with the new heap size. Details and further suggestions about this found in Tuning #7 . Further reference: G1GC Fundamentals (HubSpot blog) Understanding G1GC Logs (Oracle blog) Tuning HBase Garbage Collection (Intel blog) This blog post was co-authored by Staff Software Engineer Eric Abbott .", "date": "2016-05-10"},
{"website": "Hubspot", "title": "Our first non-Salesforce.com CRM integrations", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/58496/our-first-non-salesforce-com-crm-integrations", "abstract": "HubSpot has had Salesforce.com CRM integration available in its main product for a while.  We think it's a good idea to track customer information in a CRM, because otherwise it's easy to forget details like the last time you spoke to the customer, or the last support issue they had, or when to follow up next.  You can read more about the benefits of this connection in a blog article by the Lexnet Consulting Group: \" 5 Reasons to Integrate HubSpot with Your CRM \". A few months ago, we opened up the HubSpot Leads API to the public, after it had been used internally for a while.  We specifically hoped to get more CRM integration possibilities, beyond the original Salesforce.com integration, and thankfully, our hopes are starting to materialize. We have already had a number of custom-developed integrations to various CRMs.  These are listed on the public documentation page at docs.hubapi.com .  They include the  majority of the top 30 or so most popular CRMs at the moment. So what's new?  Glad you asked! We now have at least two integrations that are not custom-developed, but packaged such that you can download them and configure them via a normal human-friendly user interface.  No developer time needed! The first one was built by Ben Smith , a HubSpot employee, and it connects HubSpot to the SugarCRM system.  In fact, it was just featured as Sugar's \" Project of the Month \" for January 2011.  Please check it out and let us know what you think!  If you don't have a CRM at all, Sugar is a great first one to use, as it's nearly free and contains a lot of features. The second such integration one was written by a HubSpot partner, Lynton Web Solutions , and it connects HubSpot to the NetSuite system .  You can learn all about this connector on the NetSuite SuiteApp site . We'd love to hear feedback from people using these integrations.  We also want to develop more such integrations over the next few months. Please note that HubSpot Support does not support these integrations at this time, as they are external to our product.  However, the HubSpot Platform / API discussion group , which is open to the public, is a great venue to ask any questions you might have regarding these software packages.", "date": "2011-01-21"},
{"website": "Hubspot", "title": "Michael Amirault is a HubSpotter", "author": ["Elizabeth Dunn (She/Her)"], "link": "https://product.hubspot.com/blog/bid/86932/michael-amirault-is-a-hubspotter", "abstract": "Name: Michael Amirault Role: Developer at HubSpot Superpower: Buffalo chicken mac and cheese Michael Amirault is an engineer on the HubSpot email team. Right now he's working on building systems to support customers who use third-party apps integrated with their HubSpot email tools. But he keeps busy with a lot of different projects around here. Michael is a senior at Northeastern University on his third co-op. He'll be working at HubSpot until the end of August. His two previous co-ops were at IBM in Littleton MA, and at Intuit in San Diego CA.", "date": "2012-05-21"},
{"website": "Hubspot", "title": "Modular Backbone", "author": ["Zack Bloom"], "link": "https://product.hubspot.com/blog/modular-backbone", "abstract": "At HubSpot we build libraries to try and fix issues with how we build software. One issue which kept cropping up was the tendency for 'base' Javascript View and Model classes to accumulate all sorts of random functionality as well-intentioned developers added to them over time. Making tools public doesn't help anyone if the additions aren't understood by the development team. However well intentioned or brilliant the additions might be, making tools public doesn't help anyone if the additions aren't understood by the development team. Not only that, but shoving more and more into the same classes makes for a complicated, interdependent, mess. Our library, Mixen , exposes a single function. The function takes any number of classes, and composes them into a single class you can extend from. The composition is such that it's as if each class extended the one before it, meaning any method calls will travel through the entire stack, allowing any module that needs to to hook into any method it needs. Mixen has allowed us to build smaller, more targeted libraries which do just one thing, well. Mixen has allowed us to build smaller, more targeted libraries which do just one thing, well. We hope it can clean up your code as well. Mixen is only a few dozen lines of code, so you should be able to take a peek and decide if it's right for you very quickly. You can start playing with Mixen right now in jsfiddle.", "date": "2013-11-04"},
{"website": "Hubspot", "title": "Take as much time off as you need, and autonomy", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/33028/take-as-much-time-off-as-you-need-and-autonomy", "abstract": "As of today, there is a new HubSpot vacation / time-off policy: take as much time off when you need, when you need it. No paperwork, no forms, no special accounting.  Let your teammates know.  That's it.  No fine print, no exceptions. Why did we do this?  I could try to explain with my own reasoning, but I would not do as good a job as Dan Pink ( @DanielPink ), in this awesome and inspiring TED Global 2009 talk: I am a big believer in what Pink says.  Especially for the type of work we do on the engineering team at HubSpot, which is highly creative, we should trust our teammates with autonomy as much as possible.  This is one big step in that right direction. This specific talk I actually didn't know about until yesterday, when my colleague Prashant Kaw pointed it out on our wiki.  Thanks, Prashant! But there are two related references, one directly called out in the TED presentation and one not, that I'm familiar with and highly recommend.  The first is Dan Ariely , who was one of my teachers at MIT, and his range of talks, videos, blog posts, and publications.  Ariely has an active blog, and practically all his papers are publicly available, including this one from 2005 that is referenced in the presentation. The other resource not in this TED talk is the Netflix culture / philosophy presentation , available on Slideshare, which we've talked about in the past.  It, too, is excellent and well worth reading through.  Coincidentally, HubSpot now has the same vacation policy as Netflix ;) Culture View more presentations from Reed Hastings . Many companies will tell you a lot of things you want to hear when you think about working there.  But at very few companies is the level of flexibility, enlightment, and open-mindedness not just high, but pervasive in thole organization including the complete management team. That's what it takes to make a difference in people's work lives which translates into personal lives.  It's not some HR-friendly talk about \"work-life balance,\" but the real thing. And this is just one of many reasons I'm happy to work here.", "date": "2010-01-01"},
{"website": "Hubspot", "title": "What the Best Product Manager Candidates Say During an Interview", "author": ["Magdalena Georgieva (She/Her)"], "link": "https://product.hubspot.com/blog/what-the-best-product-manager-candidates-say-during-an-interview", "abstract": "Whether you’re trying to break into the world of product management or have been part of it for years, interviewing for a product manager role is hard. There’s no one right answer to any question because there’s no one right way to do product management. The skills and perspectives that would make you a great PM at one organization might not translate at others. But there’s one thing that is true across the board and that’s that preparation can make or break an interview. Talking to some PMs on my team and interviewing PM candidates over the past few years, we’ve started to see a handful of themes that have made interviewees stand out. They’re not just bright, they’ve done their homework and know how to demonstrate their strategic thinking. So while product management at HubSpot is different than it is at other companies, these are universally valuable guidelines that I think can help candidates leave strong impressions anywhere. 1. Know the Product Well Enough to Critique It Do your due diligence to research the company you're interviewing with. If you can, use their product through a trial, watch a demo, and spend time exploring their website. We sometimes interview PM candidates who don’t have a clear understanding of what our software does even though all the information (like trials, free tools, videos, detailed product pages) is available to them. It’s not hard to do your homework, and if you want bonus points: Develop opinions on what you think works well and what could be better based on some of the key use cases you identify. Don’t get too stuck on UI and aesthetics but focus on jobs-to-be-done and flows. 2. Ground Your Strategic Thinking in an Example Walking through an example is a great way for your interviewers to gauge how much experience you have, but more importantly, to see how you think. Consider the product problems you worked on in previous roles and how you prioritized, socialized and addressed them. Was it in a mature product or a brand new product? Does the example demonstrate your product vision or the ability to follow through and execute? If this is your first venture into product management, what was a side project you worked on that exercised those skills? Illustrate your skill set through the best example that helps interviewers picture you in the role. 3. Know Why You Like or Dislike Specific Products One of the most popular questions companies ask PM candidates is to share a product you like or don’t like, and the reasons for that opinion. This isn’t about the specific product at all and it shouldn’t get personal. It should demonstrate your critical thinking and whether you can identify real problems. It will show that you are observant, have opinions, and are analytical in your evaluation of product management. For example, one of my favorite tools is Duolingo because it’s goal- and persona-driven. It presents a staged approach to learning based on the user’s goal. Before you start using it, users have to self-identify as a type of learner - casual, serious or very ambitious - which personalizes their experience with the app. It helps users reach their goal but doesn’t make them feel guilty if they aren’t quickly collecting points. In this way, it’s a very guilt-free, easy and customized way to engage with the app while working toward a goal. Look at the products and apps you use, your friends use, or that you read about and look at them from an objective product management view. Why is it valuable for users? Why isn’t it? 4. Show That You’re a Maker Christopher O’Donnell, VP of Sales Products at HubSpot, has taught us to look for a maker when we interview PM candidates. What does this mean? Well, it’s exactly what it sounds like. Is the candidate a creator of things? These things could be hobbies like playing in a band, making jewelry, or writing a cooking blog. If a candidate spends their free time passionately, then they’ll probably carry that passion over to product development and could inspire those around them to create, too. If you have a hobby or side project that you’re passionate about, talk about it. Don’t worry about whether it’s relevant or quirky; you’d be surprised by some of the stories we’ve heard in interviews that made us realize a candidate has that critical piece of maker DNA. 5. Talk About Your Failures The best product lessons are learned through making painful mistakes. That’s why Andy Pitre , one of our senior PMs, likes to hear candidates talk about times they fell short and what they learned from that experience. What was a time that you took too long to release something? When you didn’t talk to enough users? When you didn’t have the right data to make informed decisions? How did that affect what you were building? How have you changed your approach to avoid the same missteps now? Interviewers want to see that you can make mistakes gracefully and use them as a learning opportunity. So, be honest about what went wrong and how you're using that lesson to improve today. In the wise words of Nelson Mandela, “The greatest glory in living lies not in never falling, but in rising every time we fall.” 6. Lean into Your Strength PMs have different superpowers from technical knowledge to previous product management experience, to strong domain expertise or a solid understanding of the primary customer, to knowledge of the company culture. Angela DeFranco , a PM here, suggests carefully considering which strength you would bring to the table and lean on it. For example, you may not have a ton of technical background but you might know the customer persona really well which will give you an advantage over other candidates. Ultimately, you want to be able to earn the respect of your team with this superpower. 7. Be Curious in Your Questions Strong PM candidates are generally good listeners and ask thought-provoking questions. Jeremy Crane , VP of Marketing Products at HubSpot, said \"My favorite interviews are the ones where the conversation just flows as a series of questions and answers back and forth.” This usually happens because a candidate is curious and passionate, both critical product management skills. Jeremy added, \"When interviewees have good questions, I consider that the measure of true curiosity.\" Don't worry too much about googling which questions to ask before your interview. Instead, be engaged in the conversation and dig in when something piques your curiosity. At HubSpot, for example, a question like \"How many product packages do you have?\" is weak because this is information you could have found online. But the question “How do you decide how to package each product tier?\" is more interesting because it will reveal a process, get the interviewee to think deeper, and spark discussion. Asking good questions also demonstrates that you are actually using the interview as a learning opportunity. \"If I feel like they are trying to learn something just sitting there with me versus just trying to get a job, I know they are truly interested in curiosity-driven learning,\" added Jeremy. These are just some of the things we like to hear in our interviews with potential PM hires. Do you have any specific questions that you’ve asked, or have been asked, and would recommend? Are there questions you aren’t sure how to answer? Let me know in the comments and I’m happy to help!", "date": "2016-03-16"},
{"website": "Hubspot", "title": "Size Matters: Why Growth Happens on Small Teams", "author": ["Jeremy Crane"], "link": "https://product.hubspot.com/blog/size-matters-why-growth-happens-on-small-teams", "abstract": "...I intend to go on doing just what i do! And, for your information, you Lorax, I’m figgering on biggering and BIGGERING and BIGGERING and BIGGERING - Dr. Seuss, The Lorax In the technology world, we spend an awful lot of time thinking about and striving for growth. At the risk of turning poor old Theodore Seuss Geissel in his grave, I think this a good thing. Thinking about growth, the right kind of growth, can drive teams to create tremendous value. But there's a catch: not all growth is good growth. Operating under an assumption that in order to grow, all things must grow may result in the opposite happening.  We have a fundamental belief at HubSpot that small teams have the biggest impact; growing the size of our individual technical teams would be the bad kind of “biggering”. So, for us, when it comes to structuring and cultivating teams, size matters. A lot. Finding the Magic Number Every company will have their own variation of what ‘small’ means. Amazon uses the two pizza rule (if you need more than two pizzas to feed a team, then the team is too big.) For us, small looks like one and a half pizzas. Our prototypical team is five people: one Tech Lead, two Developers, one Designer, and one Product Manager. This team of five, led by the Tech Lead, owns a meaningful area of the product, such as our blogging platform or our marketing automation tools. And by own, I mean OWN. They answer to no one about the specifics of what they work on day-to-day or what their priorities are. While the teams are small, their challenges are anything but. In most cases, a team of five is responsible for building an area of our application that other companies might call on the skills of 10X (or more) the number of developers. The rule of five-to-a-team is not absolute. We have some teams that are slightly bigger and others that are smaller. But we do aim for that magical five. We've fought very hard over the years to make this team size stick even while we have grown dramatically as a business, a company, and a product team overall. This is incredibly hard but fundamentally important to our culture . The Big Benefits of Small There's something really special about what a small team can accomplish if they're given the autonomy to own all aspects of their part of the product. Small teams can move quickly and be more nimble; changing direction based on customer learning is much easier when there are only five people to get up to speed. It's also much easier for everyone on the team to stay close to the customer and get that ever-important primary customer feedback. Not surprisingly, members of a small team have a greater ability to make an impact on a daily basis. If you're one of the three Developers building the social media tools at HubSpot, you can be pretty sure that your individual contributions are going to matter a heck of a lot to our customers. The broader benefits of small teams go beyond the team itself, like clear accountability. Knowing who’s responsible for success and slip-ups is easy because there’s such a strong sense of ownership. If you have an organization with high accountability but weak ownership, you have a recipe for low-risk tolerance and probably very little innovation. And if you have an organization with strong ownership but little accountability, you most likely have a poor ability to execute. On our Product Team, it's very clear who owns every aspect of the product and infrastructure, and the accountability for success rests squarely on the same shoulders. Our small teams are tremendous enablers of this. On the squishier side of things, small teams enhance a sense of bonding and belonging. When you're five people against the world trying to surmount big challenges, it's easier to pull together, support, and push each other. Strong, tightly knit teams with a good balance of skills enhance the performance, productivity, and happiness of the individuals on that team. Strong interdependence within a team is a tremendous motivator, while simultaneously providing a sense of importance and belonging. We all want to matter and work on things that matter. But All is Not Magical in the World of Small Teams As with all organizational approaches, there are trade-offs. The biggest challenge inherent in small teams is in executing big sweeping changes across the entire product. We have around 20 teams working on our core product, depending on how you account for things. When we want to do something as simple as change the skin of our overall product, it's much harder than it would be if we were one big team with a more traditional, hierarchical structure. Don't even get me started on the challenge of something like introducing user-customizable access-level controls. A small variation on this sweeping change challenge is simply keeping all of the teams aligned and focused on a consistent user experience. It's not uncommon for one team to be ahead of another team on a particular shared product element. This can lead to a disjointed user experience if it's not managed carefully. The fact that our Product Team is located in two offices, on two different continents, can exacerbate this challenge substantially. We've tackled these challenges in a few different ways and are always learning what works and what doesn’t. Mostly, we invest heavily in communication on multiple levels to keep teams talking and we focus on ensuring that we have DRIs (directly responsible individuals) for everything. In particular, we lean on Designers and PMs from different teams to be connecting and staying aligned. If a team needs extra support, a manager will step in and help them get unstuck. We don't outline a particular solution -- we just identify the problem and push the teams to solve it. The bottom line is everyone needs to know what their counterparts are working on and where they are headed. This doesn't mean we have schedules full of status meetings. We just talk to each other... a lot. While it's easier for small teams to come together with a shared mission, the condition of this benefit is that every member of the team needs to be a good culture fit. A single personality mismatch can spell disaster for a small team. We spend an obscene amount of time at HubSpot thinking about what types of people complement each others' skills and who works well together. We also move very quickly to make changes when it's clearly needed. Deeply understanding the people on your teams -- their skills, their motivations, their drive -- is critical in this environment. Finally, we are growing like crazy and are constantly hiring new developers. This means that we need to find ways to create new teams without disrupting all of the important cultural components. What we've arrived at is a method of requiring a sort of mitosis of our existing teams. We ensure that newbies are paired with old timers so that they can get infected with the HubSpot approach to product development. Just like organs in the body, we need each of our teams to be able to function with other teams even as they excel in their own focus area. In the end, it all comes down to the people. That's why we put so much energy into building and cultivating our teams. Figgering on Biggering There is no one-size-fits-all team or organization. The structure of your teams should be such that the most important outcome comes naturally to your organization, then you can put your energy into everything else. At HubSpot, we value speed of innovation and ownership above all. This means that we have to put serious energy into some things that don't come naturally to us. So be it. That's how we all grow. The bottom line is that, for us, small teams are the path to successful and sustainable growth. And that's the kind of “biggering” even the Truffula trees might be happy about.", "date": "2015-04-09"},
{"website": "Hubspot", "title": "The HubSpot App Marketplace (Part 4): Tools to Build with and Platform Vision", "author": ["Adrian Mott"], "link": "https://product.hubspot.com/blog/bid/75590/the-hubspot-app-marketplace-part-4-tools-to-build-with-and-platform-vision", "abstract": "With the HubSpot App Marketplace just a few months old, we've been really happy with not only the amount of development that's happening on the HubSpot Platform, but also the amount of HubSpot customer adoption that we've seen to date.  HubSpot App Marketplace apps have been installed by over 70% of HubSpot customers and trial users to date.  There are over 30 apps in the marketplace with some really exciting new apps coming soon including a new PPC spend analysis app, a webinar integration app and a new press release app. I also wanted to highlight some tools for developers that will help aid interaction with HubSpot's APIs.  Apps that integrate with HubSpot's APIs have proven to be the most valuable to customers and have had the highest adoption rate to date.  We thought that creating wrappers for these APIs would help the development community use our APIs, so enter hubspot.github.com - the HubSpot Development Tool Chest. Today, we have wrappers for Python (called PySpot), Ruby (called rHAPI) and PHP as well as some other tools that we like including a Twitter Bootstrap sandbox (more on this later). We'd love to hear what you think about the wrappers so we can improve them to make it easier for developers to work with the APIs. I also wanted to share a slide deck form the recent HUGS Conference (HUGS stands for HubSpot User Group Summit).  The deck lays out some vision for the Platform in general, includes some information about future APIs that are close to coming out as well as some other useful ideas for building apps.  Enjoy! HubSpot Platform and APIs", "date": "2011-09-29"},
{"website": "Hubspot", "title": "Using CocoaPods to Modularize a Big iOS App", "author": ["Anthony Roldan (He/Him)"], "link": "https://product.hubspot.com/blog/architecting-a-large-ios-app-with-cocoapods", "abstract": "Update, as of February 2017: I wrote this article three years ago and probably get an email once a month asking if that's still how we're building our mobile app. The tl;dr is that it isn't, but our mobile Tech Lead David Langley wrote an update with why we've moved away from it and what we're doing today . Selecting the right architecture for your mobile app is a pretty big deal. It will shape your daily workflow, frame the problems you face, and can be a huge asset or huge liability. HubSpot's app is fully-featured. It's an analytics app, a social media app, an email app and a contacts management app (with more to come) all coexisting under one roof. As we set out to build this fairly complex app last summer, we knew we had to have an architecture that'd scale with it. We actually build each sub-app as a fully complete standalone app, then use CocoaPods to integrate them into the main app. In the screenshots below, you can see how each sub-app - Sources, Dashboard, Social Media, is actually both a standalone iPhone app as well as an app that can be brought into the menu of the main app. This gives us a few huge advantages: Most critically, we're very easily able to ensure that the primary branch of each sub-app is ready to ship, and can pull in specific versions of sub-apps in a snap. We spend a lot more time building and a lot less time merging. Each individual app's sandbox makes it very easy to iterate within the sub-apps and spend minimal time integrating with other apps. If you've worked on an iOS team of more than one, you've undoubtedly had gross .xcodeproj merges. While they are resolvable , they're a pain -- this lets us sidestep them almost completely. We are able to individually deploy each app if necessary -- this is amazing for doing usability testing on an individual app level. We could ship the app to our testers earlier before “glue” features like navigation were complete so we could get high quality, targeted feedback. Because user flows between sub-apps are only done with URL-based routes (more about this later), it means that routes are built-in and documented -- instead of searching through a pile of UIViewControllers for the right way to instantiate a particular view, there’s a well-defined route. This is useful when building meta-functionality like walkthrough tutorials or new push notifications. This architecture has been a huge timesaver for us in building multifaceted iOS apps with a team of more than two people. Sound like your jam? Read on. Learning from the Web The inspiration for splitting up our mobile app into sub-apps came from the successes we've seen with HubSpot's web architecture. HubSpot's web app architecture is built for development-speed and scalability. As my colleagues have written, we use a variety of tools and techniques to let us collectively deploy about 300 times a day . This is critical, as HubSpot's product suite consists of several loosely coupled but very different applications -- analytics, social media, email, blogging, and reporting tools. On the web, we can build, test, and deploy small sections of the HubSpot app independently -- including backend APIs and jobs written in Java, front end CoffeeScript projects, and Python projects. Why not do the same for mobile? CocoaPods: Use It. CocoaPods , the excellent dependency management solution for iOS, is key in bringing everything together. A multi-app architecture may be overkill for your use case, but CocoaPods certainly is not -- even if you're just bringing in a handful of 3rd party libraries for usage tracking, view components, or networking -- investing the few minutes to set it up is fully worth your time. The ruby gem-like syntax makes integrating open source components into an app nearly seamless. Core libraries and shared resources like login, styling classes, and API/credential persistence and access are built as independent projects with Kiwi tests and a podspec file. We publish them to our private CocoaPods repository and include them in our actual fully-built applications. However, we take it a step further by building each sub-app -- all of Social Media, Email, or Sources, for example -- as a separate project with a podspec, then build them all into a single app using CocoaPods. This means we can ship test versions of a single feature internally, and can move quickly with breaking changes in a single app without worrying about breaking the big build for other developers working in other unrelated sub-apps. The Podfile for our aggregate app, therefore, looks like: Gluing it all Together Astute readers will notice we've used a couple of open source tools in our main application that are key in gluing the sub-apps together, IIViewDeck and JLRoutes . To make it so that we don't have to provide information in the base app about the different menu items and routes each sub-app can handle, each sub-app provides a single class that implements an HSBaseApp protocol with a few methods: An example implementation is: We use routes to handle incoming push notifications, and we use the same scheme to link across sub-apps within the main app -- as is the case when we link to Contacts from Sources or Social Media, for example. HSRoutingDelegate has a little bit of magic in it for passing around the currently active UINavigationController so we can push on top or create a modal in a route based on context, but otherwise it's a simple wrapper for JLRoutes' excellent block-based syntax. What else can we do? In the long run, we'd like to grow past our simple Kiwi test for some shared libraries and build in KIF tests so each version of a subapp passing Kiwi and KIF tests is built in a continuous integration setup and we can pick known good versions of each to ship for each release of the main application. How do you organize large iOS apps with multiple developers? Is there a better way? We'd love to hear from you!", "date": "2014-02-04"},
{"website": "Hubspot", "title": "A Beginner’s Guide to Building Your First Personal Programming Project", "author": ["Nadia Alramli (She/Her)"], "link": "https://product.hubspot.com/blog/personal-programming-projects-beginners-guide", "abstract": "Over six thousand. That’s how many internship and co-op candidates we review every year for HubSpot’s Product & Engineering team . We seek a diversity of experience and interests in choosing our final cohort, but there is one thing most of our successful applicants have in common: personal programming projects. These projects can take on any form. An app to find the time your next bus is arriving. A chrome extension to hide spoilers for your favorite tv show. The topic doesn’t matter. The initiative it takes to create something does. With that in mind, let’s get building! Here are some suggested steps for embarking on your own personal programming project. Step 1: Choose Something You Love to Do Side projects aren’t only for early-career engineers. Take me, for example. In my free time, I love to crochet, which is the art of creating textiles using a hook. But one of the main challenges I faced in the beginning was the human-error factor in crochet pattern designs. Sometimes the directions don’t lead to the desired end result. Instead of accepting this as an unavoidable reality of crocheting, I turned to my own experience as an engineer. I could use the tools I had mastered in my everyday work to help me with my hobby. I wrote a Python application that could parse, validate, and generate crochet patterns , saving me time by catching mistakes before I published them. Here’s an example of one of the patterns I created using the code I wrote: This particular pattern is for a specific size of crocheted cube, which, once I stuff it, looks something like this: Add a few flourishes, and voilá! The final product might seem like it has nothing to do with coding, but writing that application saved me tons of time and trouble. I took something and made it better with engineering. So, what do you enjoy doing outside of work? Chances are, there’s a repetitive or error-prone part somewhere in there that you can use your coding skills to improve. Even better, got a cause or a local charity that you support? How about renovating their website or building them a cool mobile app or helping the cause with a project? You would be both supporting your favorite cause and investing in your career! Step Two: Find Your Tools and Your Community First, set yourself up with a public GitHub account (if you’re new to it, here’s a guide to getting started with git and GitHub ), and start filling it with projects you’ve already completed. If you’re still in college, this is a perfect place for school projects to live. Next, find yourself a community of fellow coders, whether it’s a group of friends or something more formal than that. While it’s perfectly legitimate to work on projects solo, being part of a community can raise your game in ways you might not realize. Being able to bounce ideas off of one another and give each other advice and support can be invaluable. If you’re not sure where to start, research hackathons and workshops offered in your area (for when social distancing is over, of course). Several of them have online options, including HubSpot’s Build Your First Web App Workshop . Step Three: Don’t Be Afraid to Get Started Remember, the product you’re building can be anything. It’s not the “what” that matters so much as the “how.” Here are some examples of what teammates of mine have built: A blog to to teach beginners how to program A chrome extension to hide Game of Thrones spoilers from your Facebook feed A scraper to track Netflix watch history and a web app to find the best movies from your favorite actor or actress An app to find the time your bus is arriving at the stop nearest you Most importantly, your project doesn’t need to be perfect. And here’s a little secret: it doesn’t even need to work. Even a failed project is better than no project. The lessons you learn from that failed project and the fact that you attempted to do it, especially if it’s a difficult task, make you stand out. So get going⁠ — it’s never too late! Spending time on personal projects shows that you’re passionate about learning and growing your programming skills. You have boundless potential. It’s time to tap into it. If working with a team that’s always interested in learning and growing sounds great to you, check out our open Product & Engineering positions .", "date": "2020-05-20"},
{"website": "Hubspot", "title": "Meet the Movers and Makers: Michael Axiak, Principal Software Engineer", "author": ["Hannah Fleishman (she/her)"], "link": "https://product.hubspot.com/blog/meet-the-movers-and-makers-michael-axiak-principal-software-engineer", "abstract": "Name: Michael Axiak Role: Principal Software Engineer What was the last book you read? I just finished David McCullough’s The Wright Brothers . While it may be a bit biased, I really enjoyed learning about their humble pursuit to build what they knew could exist. In addition to the focus on the brothers themselves, it’s easy to feel a sense of wonder for the early 1900s. Here was a time when automobiles, the telephone, radio and relativity were all new. It definitely makes one wonder about the speed of innovation today and if we’ll feel at all similarly about the progression of AI and automation. How did you get into programming and what brought you to HubSpot? I was really lucky. In third grade a classmate came back from “Computer Camp”. He had brought a Basic book and when he shared it, it was love at first sight. For fifth grade we had to do a presentation on a “How To” book and I tried to teach my Borland C++ book. I distinctly recall having a lot of trouble due to my inexperience with math -- I really wanted to understand how functions and types worked, but all I knew how to do was really basic math. I just loved that I could solve actual human problems with code. In middle school another friend got me introduced to a local gaming shop that wanted a (cheap) program to manage the different computers as kiosks that needed to be locked down whenever people weren’t paying. This involved laying out requirements and iterating with the owners as I built the project. Fast forward a decade and change, I spent the summer of 2012 working on a failing startup. At the summer’s end, I decided I wanted to focus more on code and less on the business. HubSpot was described to me as this virtual playground of autonomy. Three years later, this playground is still very much alive today. What sorts of problems are you solving in your current role? I work on three sorts of problems. The first is building realtime backend systems. This usually involves finding the limits of CAP and exploiting it to give us the best throughput or reliability that we need. Most of my work here has been around collecting and organizing event data -- whether the data is generic or from our email system. The second sort of problem I’m solving is basic data analysis. Our customers perform lots of actions and there are different sorts of questions we can ask about those actions. Are there any marketing patterns that help our customers? Is there a better way to look at CPU and network utilization across our dense graph of microservices? Lastly, and this is something that I do whenever the need arises, is that of API hygiene. Some of our systems are hard to use correctly. I’ve built a few shim libraries that take into consideration assumptions that work well at HubSpot, and simplifies the API for the rest of our developers. Two examples of this include our Kafka libraries and a streaming/batch library much of our Contacts backend uses for processing data. Tell me about someone on our team who you love working with. I think this is a popular opinion here, but I love working with Jonathan Haber . He and I actually worked together in a previous job, and he’s one of the most practical engineers I’ve ever encountered. One of the best at finding the simplest, most elegant solutions to the problem at hand. When he was in the process of leaving his previous job (and about to start a new job) I told him he has to rescind his other offer and work for us. How would you describe our Development HipChat room in 3 words? I’m going to cheat and describe our “Java Ranchers” room: “Anything But Java”. Generally people go into that room to discuss an issue related to their java service, but it often devolves into why we should be using Groovy, Clojure, or C. Most of the developers have a love-hate relationship with the language given its size and relative verbosity. (Though, I see less of that today with Java 8 .) What’s been your most rewarding moment at HubSpot so far and why? The most rewarding in recent memory was when another team was able to use an efficient rate limit service I built to cut the amount of work an event system does in half. When building it, I knew it would be useful for a lot of things, but I didn’t foresee the particular use case. It was fun to see another team integrate without much difficulty. Finally, the hardball question. I’ve heard you have some mean dance moves so what song should we put on if we want to see them in action? Hah. My peak dance moves don’t reveal themselves for any particular song -- they depend on the environment. That being said, I was honored to play a part in a choreographed dance for a friend’s sangeet. Anything else you want to share? I think it’s hard to understand how much HubSpot walks the walk when it comes to autonomy and transparency. In the three years I’ve been here, I’m continually surprised at how much the leadership team engages everyone on strategy, tactics, and culture. It’s easy to overlook when comparing jobs (do I even need more autonomy?), but HubSpot is great at giving people ownership over their work . Stay tuned for our next Mover and Maker, and be sure to check out our Q&A with Senior Software Engineer Maja Djodjevic to get to know more of the HubSpot engineering team.", "date": "2015-09-28"},
{"website": "Hubspot", "title": "Lessons Learned from Last Week's S3 Outage", "author": ["Jonathan Haber (He/Him)"], "link": "https://product.hubspot.com/blog/lessons-learned-from-last-weeks-s3-outage", "abstract": "Like many companies, we were affected by last week's S3 outage . We were surprised, however, by the extent of the impact to our systems. It was a bit of a wake-up call, and we realized how much of a failure point S3 had become for us and how little we were doing to protected ourselves against S3 downtime. We know that network calls will inevitably fail, so we use patterns like circuit breaking and bulkheading for our service-to-service requests, MySQL queries, HBase RPCs, Kafka writes, and so on. Our calls to S3, however, didn't have these protections. This post will cover some of the lessons we're going to apply to our codebase in order to insulate ourselves against any future S3 outages, and also introduce a new library we wrote to help us get there. Lesson 1: Centralize creation of S3 clients When we looked around our codebase, we realized access to S3 wasn't centralized or standardized at all; each service was doing its own thing. We had a mix of JetS3t and the official AWS Java SDK; some apps configured timeouts and retries, while most used the defaults. One of the things we've discovered over time is that the easiest way to make sure best practices are followed is to bake them in so that you get them automatically. We've found that an effective way to achieve this is to centralize client creation into a shared internal library. This makes life easier for users, while allowing us to transparently add behavior that we think is beneficial. And because everyone is going through the same code path, if we want to make changes in the future we just need to update the code in one place and it will take effect for everyone. Next, we'll cover some of these best practices that are going to be baked into our S3 client creation. Lesson 2: You probably don't want the default timeouts During the outage, we saw some APIs fail that we didn't expect to. We expected that the endpoints that hit S3 would fail, while the other endpoints would continue serving traffic. In reality, some of our APIs stopped serving traffic entirely. When we investigated the issue, we found that the endpoints hitting S3 were taking a very long time to fail, causing requests to pile up and exhaust our API's HTTP thread pool. The end result was that the few endpoints that hit S3 took down the entire service. After noticing this, we checked the client timeouts being used. The AWS Java SDK has a default socket timeout of 50 seconds and JetS3t's is 60 seconds. In addition, the AWS Java SDK will retry errors up to 3 times by default and JetS3t will do 5 retries. This means that when S3 is having issues it will take much longer to fail than we want. To fix, we dropped these timeouts way down so our worst-case latency is much lower. Lesson 3: Use circuit-breakers and bulkheading to fail better Beyond tighter timeouts, we also need a way to short-circuit S3 when it's down so that we fail fast and reduce our chances of cascading failure. We could tell our engineers to wrap all of their S3 calls, but this is tedious and doesn't take advantage of the single code path we discussed before. Instead, we want to bake in this behavior so that all calls to S3 automatically get these protections. To achieve this, we wrote a helper library called S3Decorators (on GitHub here ). This library provides an injection point for intercepting all calls to S3, which can be used to add logging, track metrics, inject failures or latency for testing, or to wrap each call with Hystrix or Failsafe (to our knowledge, the most popular Java libraries implementing the circuit breaker pattern). We've provided ready-to-use implementations for Hystrix ( here ) and Failsafe ( here ) to make it easy to get started. It's as simple as: And now every S3 call is wrapped in a Hystrix command. Conclusion Despite last week's outage, S3 is still incredibly reliable. For the majority of our services, the remediations we're putting in place to fail quickly and safely in the event of an S3 outage will be sufficient. There are, however, some critical services within our infrastructure that need to withstand a single-region S3 outage. For these use-cases, we're investigating strategies like cross-region replication or syncing data to another provider such as Google Cloud Storage. We need to be careful, however, as it is easy to unintentionally add additional failure points that would end up decreasing, rather than increasing, our availability. If you have any tips, tricks, or feedback feel free to leave a comment below.", "date": "2017-03-08"},
{"website": "Hubspot", "title": "Boston Lean Startup presentation about HubSpot", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/72630/boston-lean-startup-presentation-about-hubspot", "abstract": "Last night I presented some details about how we at HubSpot apply the Lean Startup principles to our daily work.  Thanks to the Boston Lean Startup Circle organizers ( @msmamet and @hackerchick ) for setting up a great forum. I couldn't include every detail, as we do a lot.  There were great questions along the way from a fairly sizable audience, and I wish I had a video of the talk, but for now, the embedded presentation below will have to do. I also didn't cover any Lean Startup basics.  I do have plenty of links in the presentation for further study.  Start with Eric Ries' \" Startup Lessons Learned ,\" and go from there. Lean Startup at HubSpot View more presentations from Yoav Shapira You can download the original PowerPoint presentation from SlideShare.  It has a bunch of links and further information in the Speaker Notes section.  Also, it looks a little nicer: for some reason the Slideshare online conversion is not perfect. Major thanks to Dan Milstein ( @danmil ) and Jeremy Katz ( @katzj ), who are mentioned and even pictured in the presentation. Questions and comments are welcome.  We've made many mistakes and we learn all the time.  We've love to learn from you.", "date": "2011-08-26"},
{"website": "Hubspot", "title": "Why Product Planning Fails", "author": ["Christopher O'Donnell"], "link": "https://product.hubspot.com/blog/why-product-planning-fails", "abstract": "One of the most common questions I get from folks looking to optimize their product team's performance is: what's the right development process for us to use? After talking with them, I’m constantly left with the impression that most product leaders think they should be running Agile (note the capital “A”) frameworks like Scrum. The problem is, they can’t confidently say why. All that matters is that they have a clear-cut plan. I’ll let you in on a secret: there is no universal approach to product planning. The process for building a new light rail switching system for the Denver RTD will look a great deal different from the process driving a team that’s trying to make the next DoodleJump. Every team has different goals, end users, and rhythms. Trying to apply a method like Scrum across the board just won’t work- you can’t fit a square peg in a round hole. Picture this. There once was a group of college roommates living in a row house in Baltimore and over time, their house inevitably started to get a little messy. They made a plan to stay on top of cleaning by assigning each roommate a set of chores and putting a schedule on the fridge to see that they got done. This way, everyone was accountable for pitching in on real chores like washing the dishes, sweeping the floor, vacuuming the living room, etc. Until one day when one of the roommates added ‘Make Crystal Light’ to the schedule. What’s wrong with this picture? We may not all be children of the ‘80's so let me fill you in: making Crystal Light is not a chore. It takes about 15 seconds, tops. But, because this task was checked off the schedule constantly, it looked like this person was outperforming everyone else. The problem with pre-defining your product team's framework and tasks for a given period of time, and then measuring success based on whether or not they were completed, is that it encourages a sort of sandbagging and Crystal-Light-making. Teams often wind up doing less as time goes on, while getting better and better at celebrating their supposed \"increased velocity.\" This is why I find the process of \"planning poker\" extremely flawed. It puts too much focus on defining and predicting success, and not enough on whether or not you’re actually achieving it. Instead, what teams should be doing is taking stock of their unique needs. The ‘right’ methodology will depend on your goals, end user, and talent. The biggest influence on your product development process should be the people at the core of it, the makers, not what everybody else is doing. Starting without a process and solving workflow problems as they arise, while letting talent and culture set the tone, is a decent way to go. It might not be the universal answer most product leaders are looking for, but organizing the development of software products isn’t one-size-fits-all. The sooner they embrace that, the sooner they can GSD.", "date": "2015-02-17"},
{"website": "Hubspot", "title": "Automated Integration Testing with Selenium at HubSpot", "author": ["Michael Mintz"], "link": "https://product.hubspot.com/blog/bid/88880/automated-integration-testing-with-selenium-at-hubspot", "abstract": "You need to be able to test an application in the same way that a user would use it... and despite the apparent disadvantages compared with unit testing, integration testing is a necessary part of a balanced QA plan for maintaining product robustness. Sure, unit tests are great for checking the individual components of a system, but what if your system relies on many different components working together in unison? In cases where unit tests just won't see the big picture, that’s where integration testing comes in. When you're dealing with web apps, this may include a cross-browser examination of user-facing functionality for usages like site navigation, pressing buttons, filling in forms, and so on. Selenium is an excellent solution for handling this, and one that's worked particularly well for us. At HubSpot we maintain a continuous deployment environment in which new features are pushed to production all the time. Automated browser-based regression testing with Selenium and the WebDriver API helps to ensure that our code changes don't break the builds. Multiple programming languages are supported for use with Selenium, so once the framework was installed, we chose Python for writing our tests in. Once the tests get written and committed to GitHub , our continuous integration server ( Jenkins ) picks up the tests and runs them at regular intervals. In order to run the tests, Jenkins accesses the Selenium Grid Hub , which manages our available web browsers that live on Amazon EC2 instances in the cloud. If there are any errors at runtime, it becomes really easy to track down problems because screenshots get saved along with error output. Jenkins then sends us email notifications so that we can be alerted of any issues right away. (Above/left - Generic example of Jenkins in action. You can see which jobs are building and their status.) (Above/right - Generic example of Grid Hub in action. You can see the status of machines and which browsers are running Selenium tests.) Here, we have both a QA and a Production development environment. As new features get pushed to QA to be tested before reaching Production, a post-deploy script instantly kicks off the associated Jenkins jobs so that we can determine if anything broke. This also becomes a good time to write new Selenium tests for features being added. If all tests pass (not just Selenium, but also all our unit tests, etc), then it’s safe to deploy code to Production. One weakness of Selenium is that changes to the UI can break tests even if there’s no regression because Selenium performs checks based on the CSS selectors of the web page being tested. That’s why failures don’t necessarily mean something broke. To avoid these false positives, tests may need to be updated as changes to the application code occur. With good planning during test creation, you can write tests that are more adaptable to the visual changes in an app so that tests stay robust during code pushes. There may be a tradeoff between test quality and speed of test creation. Quality is generally the better path to take in the long run. We use a MySQL DB to store a lot of the data that we gather from Selenium test runs so that we can run queries against tables later for figuring out patterns and other useful information. The tests also access the DB where needed. For example, let's say there's a test for checking that emails get sent out at the start of the next business day. Rather than having a test running for that long, the test stores the subject of the email in the DB and when the test runs again the next day it checks if an email with that subject was received by the given email address. In other cases where the wait time required is much smaller (e.g., 20 minutes) we can still use our delayed test system for keeping our servers available for other tests during the waiting period. (Above - A quick look at some of the tools we use for testing.) With all of its adaptability and functionality, Selenium has proven itself to be a powerful solution for integration testing. We also use several other tools and services for testing our applications, including Pingdom , Sentry , Nagios , and more (some internally made); not to mention all those unit tests we have everywhere. Testing is a big deal, and that's no exception at HubSpot. It’s vital for us to keep our applications robust because we're not in the business of forcing our customers to be involuntary beta testers. With multiple apps contributing to HubSpot’s integrated marketing solution, there’s no shortage of testing to be done, and it’s one of the ways we try to give our customers the best user experience possible. ( Michael Mintz leads the Selenium Automation at HubSpot )", "date": "2012-07-19"},
{"website": "Hubspot", "title": "Growth Doesn't Stop When You Get The Job", "author": ["Richard Ng Villalobos (He/Him)"], "link": "https://product.hubspot.com/blog/growth-doesnt-stop-when-you-get-the-job", "abstract": "Why you should absolutely, definitely, and confidently apply to join the Product Operations team. If you’re considering applying for an analyst position in the Product Operations team , this post is for you. If you’re passionate about analytics, want to drive influence through data, and aspire to be at the forefront of knowledge, there is absolutely no reason why you shouldn’t apply. I fully understand the disheartening, stressful nature of applying for jobs. There are often endless amounts of applications we have to go through. We experience emotional and physical drainage from feeling worthless and underqualified. Our fear of rejection is often validated by constantly hearing about how we need more experience to get a job but also need a job to get that experience. Our leadership team is trying to bridge this gap by shifting our mindset toward the future. In designing our roles, my colleagues place an emphasis not on what is but what can be. It’s all about growth, and we’re here to help. Reasons why you are a great fit Building your brand and doubling down on your strengths One of the things I’ve loved the most about working at HubSpot as an analyst has been working and succeeding in my own way. We’re not pressured to contribute to the company’s growth in a replaceable manner. We get to contribute in our own unique and meaningful ways. Part of being a dedicated analyst for a team means that you get to build unique sets of relationships with stakeholders. You can also specialize in a subject matter, whether that is a part of the product or a specific skill. In the process of doing this, you build your own brand. Growing with the support of your team As part of the team, you will be formally supported by a variety of colleagues with different skill sets, backgrounds, and experiences. From mentors at a more senior level, to product leaders, to fellow analysts who have walked the runway, there is no shortage of community support. You will not be alone in navigating the complex and dynamic environment that is HubSpot as well as our fast-growing product operations team.. Additionally, chances are that whatever statistical programming language you need help with, whatever tool you need to learn, or whatever fancy quantitative method you need to apply, there will be someone there to support your growth. We’ve had team readouts about everything from stakeholder management and SaaS economics to more specific topics on data science and the state of our data infrastructure. We are constantly looking for ways to help each other grow effectively, especially as our team gets larger over time. Some parting words: To be successful, you will need to learn quickly and deeply, adapt to new environments and processes, and build long-lasting relationships. It might not be easy, but everyone on our team got to where they are today with some level of support. Let us be part of that journey for you. Does the Product Operations team sound like the place for you? Check out our open roles on HubSpot's career site .", "date": "2020-10-29"},
{"website": "Hubspot", "title": "Announcing The HubSpot $30k Developer Referral Bonus", "author": ["John Nagro"], "link": "https://product.hubspot.com/blog/30k-developer-referral-bonus", "abstract": "HubSpot is home to some incredibly awesome engineers, developers, and designers who work tirelessly to create a product our prospects, customers, and leads love. But to disrupt marketing as we plan to do and continue to delight our customers, we need even more exceptional contributors to join our team. That’s where you come in: HubSpot has always had a $10,000 bonus for referring people to the dev team. Today, I’m excited to announce that we are upping the ante and increasing the bonus to $30,000. If you know someone, go to our referral page to refer them now. HubSpot is committed to building the best engineering team in the world. It starts with finding the world's best talent, but it doesn't end there. HubSpot employees enjoy a lot of perks. Take a peek inside our company culture . Because we ship our code daily. Because we keep meetings to a minimum, and we work on projects that make a difference in people's lives, all over the world, all with the support and camaraderie of a small, dedicated team. Specifically, we’re looking developers who: Love Autonomy: Our one overriding rule is “use good judgment.” So we’re looking for people who like to push their own projects forward, like to make their own vacation schedules, and want to contribute to our vision, mission, and goals. Love Shipping Code: The pace we maintain on the product team is incredibly high. We deploy code more than 100 times every day, and that’s just on an average day. Love Big Projects: Our team is fully empowered to solve for the needs of our customers, so you don’t have to wade through red tape or permission slips to get things done. We just figure out what’s the right thing to do, and then we do it. Know somebody who sounds like this? You lucky, lucky devil. Introduce us. Please? The person you are referring must actually know you when we contact them. It can't be a surprise to them. No one likes uncomfortable moments with strangers. If you do, and we end up hiring them, we’ll thank you with a big, fat check for $30,000.", "date": "2013-05-22"},
{"website": "Hubspot", "title": "Science Fair v3, also known as Sprint 21 Review", "author": ["David Gallant"], "link": "https://product.hubspot.com/blog/bid/37768/science-fair-v3-also-known-as-sprint-21-review", "abstract": "As some of you know, an important part of the Scrum framework is the Sprint Review.  This is when a number of things happen, including the Scrum teams demonstrating their work to the rest of the company. At HubSpot, we wanted to make this more dynamic, open, and interesting than a simple series of PowerPoint presentation or even regular demos.  So we created what we call the \"Science Fair\"-format Sprint Review. It's pretty simple.  Each team gets a table in a big open conference room, and they can do what they wish to best demo their work.  They can use laptops, screens, arts and crafts, whatever they want.  There has to be at least one person manning their \"booth\" for the duration of the Science Fair, which is two hours. Visitors can come and go as they please, and spend as little or as much time as they wish with each team.  This is a fantastic opportunity for people who have a lot of meetings, calls, or other work to attend just for a little bit, without feeling bad about it. As part of our culture of transparency, these meetings are actually open to anyone.  You are all welcome to join us.  If you're in the Boston area, send me a note, and we'll get you set up. Resident HubSpot DJ and Support Engineer David Gallant shot a video of me walking around the Science Fair yesterday.  We also took some still photos.  These are below. Enjoy!", "date": "2010-04-02"},
{"website": "Hubspot", "title": "Embrace and Replace: Migrating ZooKeeper into Kubernetes", "author": ["James Kebinger (He/Him) and Paul Furtado (He/Him)"], "link": "https://product.hubspot.com/blog/zookeeper-to-kubernetes-migration", "abstract": "We recently migrated hundreds of ZooKeeper instances from individual server instances to Kubernetes without downtime. Our approach used powerful Kubernetes features like endpoints to ease the process, so we’re sharing the high level outline of the approach for anyone who wants to follow in our footsteps. See the end for important networking prerequisites. Traditional ZooKeeper Migrations ZooKeeper is the foundation of many distributed systems, allowing them a powerful platform to rendezvous to take attendance and form clusters. Behind the scenes, it relies on a comparatively basic approach to forming clusters: each server instance has a config file listing all of the member hostnames and numeric ids, and all servers have the same list of servers, like this: server.1=host1:2888:3888 server.2=host2:2888:3888 server.3=host3:2888:3888 Each server has a unique file called myid to tell it which numeric id it corresponds to in that list. Adding and removing hosts can be done as long as a key rule isn’t violated: each server must be able to reach a quorum, defined as a simple majority, of the servers listed in its config file. The traditional way to migrate a ZooKeeper server to a new instance involves, at a high level: Configure and start a new host with “server.4=host:4…” in its server list Update the config files on the existing hosts to add the new server entry and remove the retired host from their server list Rolling restart the old hosts (no dynamic server configuration in the 3.4x branch) Update connection strings in clients (perhaps just changing CNAME records if clients re-resolve DNS on errors) The downside of this approach is many config file changes and rolling restarts, which you might or might not have solid automation for. When we set out to move ZooKeeper to Kubernetes we started thinking about this approach, but figured out an easier way. Safer too, because in our experience each new leader election has a small risk of taking long enough to bring down the systems relying on them. New Approach Our approach involves wrapping existing ZooKeeper servers in Kubernetes services and then does one-for-one server-to-pod replacements using the same ZooKeeper id. This requires just one rolling restart to reconfigure existing ZK instances, then shutting down the servers one by one. We won’t get into the weeds on the ways to configure Kubernetes topologies for ZooKeeper here, nor the low-level readiness checks, because there are many ways to do that with various pros and cons. The concepts discussed below work the same no matter the top-level topology. We’ll proceed in five steps: Complete prerequisites to ensure our ZooKeeper cluster is ready to migrate Create ClusterIP services in Kubernetes that wrap ZooKeeper services Configure ZooKeeper clients to connect to ClusterIP services Configure ZooKeeper server instances to perform peer-to-peer transactions over the ClusterIP service addresses Replace each ZooKeeper instance running on a server with a ZooKeeper instance in a Kubernetes pod For each of the steps below, we’ll include a diagram of our infrastructure topology. The diagrams will contain only two ZooKeeper instances for ease of understanding, even though one wouldn’t want to ever create a cluster with fewer than three. Complete Prerequisites Starting with a working ZooKeeper cluster, we’ll want to ensure that services on the host are capable of communicating with our Kubernetes cluster. We include a few ways to accomplish that at the end of this article. Figure 1: Our starting state. A two-instance ZooKeeper cluster and some clients Create ClusterIP Services Create a ClusterIP service with matching Endpoint resources for each ZooKeeper server. They should pass the client port (2181) as well as the cluster-internal ports (2888,3888). With that done you should be able to connect to your ZooKeeper cluster via those service hostnames. Kubernetes ClusterIP services are useful here because they give you static IP addresses that act as load balancers to backend pods. In this case we're using them with a 1:1 mapping of service to pod so that we have a static IP address for each pod. Figure 2: Our cluster, with ZooKeeper still on physical hardware, is reachable via ClusterIP Services Reconfigure Clients Once you’re able to connect to your ZooKeeper cluster via Kubernetes ClusterIP services, this is a good time to pause to reconfigure all your clients. If you’re using CNAME records in ZooKeeper connection strings, change the DNS records. Restart all the clients if they don’t have recent clients that will re-resolve DNS entries on connection failures. If you’re not using CNAME records then you’ll need to roll out new connection strings and restart all client processes. At this time, old and new connection strings will still work. Figure 3: Clients are now communicating with our ZooKeeper cluster using ClusterIP service instances Reconfigure ZooKeeper Instances Next up, we’ll make our ZooKeeper servers do their peer-to-peer communication via those ClusterIP services. To do this, we’ll modify the config files to incorporate the addresses of the ClusterIP services. It’s also essential to configure the zk_quorum_listen_all_ips flag here: without it the ZK instance will unsuccessfully attempt to bind to an ip address that doesn’t exist on any interface on the host, because it's a Kube service IP. server.1=zk1-kube-svc-0:2888:3888 server.2=zk2-kube-svc-1:2888:3888 server.3=zk3-kube-svc-2:2888:3888 zk_quorum_listen_all_ips: true Rolling restart those hosts and now we’re ready to start replacing hosts with pods. Figure 4: ZooKeeper instances are now communicating with their peers using ClusterIP service instances Replace ZooKeeper Hosts with Pods One server at a time we’ll do the following steps: Select a ZK server and its corresponding ClusterIP service Shut down ZK process on the server Start a pod configured with the same server list and myid file as the shut-down ZK server Wait until ZK in the pod has started and synced data from the other ZK nodes That’s it, your ZooKeeper cluster is now running in Kubernetes with all of the previous data. Figure 5: Cluster after one round of pod-replacement. ZK1 is now running in a pod without ZK2 knowing anything has changed Networking Prerequisites For these steps to work well, there’s some network setup to handle. You need to take steps to ensure the following: Kubernetes pod IP addresses need to be routable from all servers that need to connect to ZooKeeper All servers connecting to ZooKeeper must be able to resolve Kubernetes service hostnames Kube-proxy must be running on all servers that need to connect to ZooKeeper so that they can reach the ClusterIp services These can be accomplished in a few ways. We use an in-house network plugin similar to Lyft's https://github.com/lyft/cni-ipvlan-vpc-k8s plugin or AWS's https://github.com/aws/amazon-vpc-cni-k8s which assign AWS VPC IP addresses to pods directly, instead of using a virtual overlay network, so all of our pod IPs are routable from any instance. Overlay networks like flannel ( https://github.com/coreos/flannel )  would work too, as long as all of your servers are attached to the overlay network.", "date": "2020-04-08"},
{"website": "Hubspot", "title": "Becoming a Tech Lead: How I've Balanced Coding with Coaching", "author": ["Skyler Whorton"], "link": "https://product.hubspot.com/blog/tech-lead-balancing-coaching-with-coding", "abstract": "In an engineering organization with many small teams , it’s important to develop technical leaders who can be both successful engineers and effective mentors. Depending on the company, team, or person, there’s a lot of variation in what that looks like in practice. At HubSpot, our definition of a tech lead (TL) clearly states: They should spend most of their time on the product, not on people. TLs are responsible for onboarding new engineers and helping them excel in their roles. But this alone shouldn’t be a TL’s full-time responsibility. Why, then, is it a common gripe from new TLs that they no longer have enough time to code? It can be hard to strike a balance between servant leadership and remaining a productive individual contributor. It’s taken me time to get comfortable with it. What’s helped during my first year as a TL is this guiding mantra I learned from my manager: Strive to be a force multiplier for others. This means finding ways to dramatically increase your peers’ effectiveness to pay off in dividends over time. When you empower your team, not only do you reclaim your time as an individual contributor, but your teammates will do amazing things all on their own. ( Tweet this ). There’s no silver bullet for any team’s situation. These are some learnings that have worked for me that might help you get back on the path to being an successful individual contributor and an effective leader. Teaching Your Team to Fish Shortly after becoming a TL, I realized that I was approaching every question from my team as if it were my sole responsibility to find the answer for them. I had embraced the idea of servant leadership a little too tightly. As you might imagine, being this involved in every non-trivial question consumed a lot of time. Why would you default to taking your own time to investigate something that you can teach your bright teammates to do for themselves? Nowadays, I try to be the street map rather than offering to be the chauffeur. I’m quick to admit when I don’t know something off the top of my head--which is usually--but I’ll describe what I would do next to find out, or who else in the organization would be able to help. I’ll likely make an introduction between those two people or give an impromptu crash course in a new tool to help them solve the problem. I’m a fan of this strategy because it keeps ownership of the problem and solution with the person who asked the question. It also has exponential benefits over time for people on your team: They learn how to use tools to answer their own questions (metrics, monitoring, debugging, internal tools, etc.) They learn how to consult new resources where there are answers to many other future questions (code search, internal wiki, knowledge base, external documentation, etc.) They meet new people in the company and create new relationships At this point, my teammates have a variety of skills and knowledge that I don’t have. Given the time it would take me to learn all those things on my own, the team and our product is far better off because I didn’t insist on absorbing the same knowledge before they did. Teaching the team to fish and empowering them to use the tools at their disposal to solve problems is essential to helping the team scale and achieve greater results. Forgetting the Role of Atlas In Greek mythology, Atlas was the god who was condemned to hold the Earth apart from the heavens. On a much smaller scale, I see some similarities between Atlas and the role of the TL on a team like mine. As a TL, I feel joy watching my team become invested in exciting new features, fun technical challenges and their expressed career interests. It’s a thrill for me when we demo new features or score big performance wins and my teammates were responsible for 100% of the code. (Those are the heavens that I wish upon my team.) In reality, the area of the product I work on has its fair share of interrupting tasks on a weekly basis. They’re unplanned, could be time-sensitive, and often don’t have a clear solution. These may be support issues reported by customers, reliability concerns or internal requests from other teams in the company. (That’s the Earth from which I feel compelled to protect my team.) An engineer on my team recently told me how much she had enjoyed having the opportunity to be heads-down on learning to use a new framework and applying it to a major redesign effort. This should sound familiar to anyone who’s heard the productivity rule du jour that makers need long spans of uninterrupted time to be most effective. Hearing that, who would ever want to interrupt this person with a bug? The eventual downside to this approach is that taking on all of the grunt work yourself work can quickly devolve into an endless game of catch-up. You may provide your team with the cone of silence they need to focus on bigger problems, but how will you be able to make time to tackle your own projects, think strategically, and help your teammates grow? It’s something I’m still figuring out, but I’ve found that it helps to match each incoming issue to each team member’s skills and expertise. If they’re already familiar with the relevant code, it should be a much easier context switch for them to set aside their main project at a convenient time. If time and bandwidth allow it, I’ll even pass along issues to an engineer unfamiliar with the problem as an opportunity for them to branch out. If I’m ever in doubt, before clicking “Assign” in JIRA, I’ll plainly ask, “Hey, do you have time to look at this support issue in the next 1-2 days?” The goal here is to start a transparent and collaborative discussion about priority, urgency, and to set expectations about what should be done next. My main goal is to keep the pain of maintenance aligned with each team member’s responsibility to ship high-quality work. The team will come to expect that they’re on the hook for changes that they made. They’ll also be consulted for help on things they’ve worked with before, so it’s in everyone’s interest to take the time to really understand the code rather than shipping drive-by bug fixes. Finally, I would also argue that it’s in the team’s best interest to feel these types of pressures occasionally. When there are a lot of bugs or a backlog of technical debt, having everyone on the team own these things will also give them the satisfaction and feeling of ownership that comes with cleaning up old messes. It takes time for a team to build up the skills and confidence to collectively handle any interruptions that may come up. It’ll be a hard-learned lesson for the TL, however, if engineers on their team are never asked to own their work, switch contexts, or solve something outside of their comfort zone. Trying to serve the role of Atlas, in the long run, is a load that’s not worth bearing. It’s much better to share it with the team. Sharing Your Pet Rocks As engineers, we like solving puzzles. It can be tempting to call shotgun on a new problem and spend time secretly thinking about how to solve it. Although intellectually gratifying, it’s not the way to get things done well or quickly. The following example shows just how motivating an interesting puzzle can be to others. Over the past few months, we noticed that our Java project took longer and longer to build. Even after we moved our project’s build from Jenkins to Blazar , which should have given us a nice boost, something was still wrong in our project. In the situations where the long wait mattered the most, though, the issue at hand took priority over digging into build times, so it ironically didn’t get the attention it needed. Not having the time for this at the moment, but wishing the build were faster, I took all the details I had and dropped them into an issue in our team’s GitHub repository. I went back to what I was doing and thought I would get back to it on a rainy day. That day never came because an engineer on my team quietly took notice. Two weeks later, he took the time to debug the problem without being prompted to do so and shaved a full 10 minutes off our build time. This earned him the gratitude of his team and the speed boost made us all more productive. It might not have happened this naturally if I had hoarded my knowledge of the problem. In this case, passively detailing a high-impact problem was all that was needed to motivate this person to solve the issue. Best of all, the problem was solved a lot sooner than if I had decided to keep it to myself. I make sure to file details for problems like this in a place where the team can see them, like in GitHub or in our Trello board. In my latest effort to communicate with the team, I’ve started sending the team a brief quarterly recap and preview of our biggest projects and why we care about them. Whenever it comes time to give a new task to someone on my team, I usually find that it’s already familiar and they may already have thoughts on how to approach it. Freely and openly sharing knowledge about the team’s challenges has helped the team’s overall readiness and to get things done in a more timely manner. And, you know what? I don’t miss those pet rocks one bit. Coding More, Worrying Less Balancing TL responsibilities with effective individual contribution can be overwhelming at first. Most importantly, consider what you can do to invest your time in a way that will lead to force multiplication . By focusing your effort upfront on autonomy, ownership, and communication on your team, I hope you’ll find over time that you spend more hours coding and fewer on day-to-day team overhead.", "date": "2016-04-12"},
{"website": "Hubspot", "title": "Tooling We've Built for Managing 3,000+ Microservices", "author": ["Jonathan Haber (He/Him)"], "link": "https://product.hubspot.com/blog/backend-tooling", "abstract": "Over the past few years, HubSpot has continued to rapidly grow its engineering team. We've seen corresponding growth in terms of lines of code, number of services, and volume of data. To help support this growth, we have a group of engineering teams called Platform Infrastructure. These teams are dedicated to making HubSpot engineers more efficient while also improving the security, reliability, and performance of our product. This includes focus areas like build and deploy, monitoring and alerting, and database operations. Over time, Platform Infrastructure has grown to 90 engineers, spread across 24 teams. I work on one of these teams, called Backend as a Service, which is focused on improving our backend tech stack. This post will cover some of the tools, libraries, and frameworks our team has built in support of this mission. Still monoglot For some context, pretty much all backend code at HubSpot is written in Java. Staying monoglot has allowed us to invest all of our resources into making our Java stack exceptional. It also means engineers can move teams or projects with less ramp-up time because everything uses the same tools, libraries, and frameworks. In addition, debugging and operational knowledge is transferable, which is an important skill set that can take a long time for an engineer to develop. This includes skills like interpreting a thread dump, navigating a heap dump, tuning the garbage collector, or debugging why one out of every thousand requests is slow. We may eventually need to go polyglot on the backend, but we think there are big advantages to staying monoglot as long as possible. Standardization and centralization Our backend stack is comprised of different \"primitives\" that product teams can mix and match like Legos to build larger systems. These include things like REST APIs, Cron jobs, Kafka consumers, Hadoop jobs, Spark jobs, and more recently, gRPC and GraphQL APIs. Each of these primitives has corresponding code to integrate it into our stack. We've been working to centralize all of this code into a single repository called Bootstrap (not to be confused with the frontend toolkit). So if you want to make a new REST API, you would add a dependency on bootstrap-rest, which provides a straightforward, fluent interface for defining your API. For example, here are a few lines of code that define a simple REST API: This creates a production-ready REST API with monitoring, dashboards, alerting, etc. In addition, we try to ensure that each module in the Bootstrap repo has a corresponding testing module so that there is a clear way to write idiomatic tests. The net result is that the barrier to creating a new microservice is tiny. As a companion to the Bootstrap repo, we have a repo called Connect, which aims to centralize client code for connecting to the various datastores we use. Within this repo, there is a separate module for each datastore. These libraries handle the basics like authentication and metrics, but are also expected to add guardrails and resiliency. This could include strategies like rejecting expensive queries before they hit the database, or using circuit breakers to fail fast when the database is having issues. In addition, as we learn new lessons during outage postmortems, we are able to apply these lessons to the Connect repo and every service at HubSpot benefits. Overall, we've found this pattern of standardization and centralization extremely beneficial. Overwatch With so many services constantly being built and deployed, it's a challenge to keep track of what's currently deployed as well as what it depends on. To help manage this, we have an internal system called Overwatch. Overwatch stores metadata about all deployed services and their dependencies and lets you query against this data. You can ask questions like \"which deployed services were built before timestamp X?\" or \"which deployed services depend on library Y version < Z?\" Our build and deploy systems also integrate with Overwatch, which is a powerful integration that enables things like our \"bad builds\" feature. The way this works is that if you realize a particular commit in a library has a nasty bug, you can mark that build as \"bad\" in our build UI. Once you do that, our deploy system will prevent people from deploying anything that depends on the broken version of that library (and optionally notify teams via Slack if they've already deployed something using it). Config We also often want to extract configuration values from our code and make them externally configurable. This could be something like the size of a thread pool, or the timeout on an HTTP request. We want to be able to change these values without needing to push a change to source control and wait for a rebuild. To handle these use cases, we built an internal configuration system called Config. The Config workflow begins with developers defining their config options via an XML file that gets checked into their GitHub repo. We picked XML because it means that we get really good IDE support for code completion and validation simply by publishing an XSD. At build time, this config file will generate Java classes that you can use in your code to access the latest config values. This is convenient for users and also provides compile-time validation of the properties being accessed, which is a big improvement over our previous configuration system that required runtime lookups using magic strings. There is also a UI where you can create targeted overrides for any config option, which will take effect within a few seconds. And because the config options are typed, we can prevent invalid values from ever making it into the system. Additionally, because config options must be accessed via these generated Java classes, we can use the classpath to infer what config options are available to each service. This allows us to create a view in our Config UI that is customized to each service, showing only the config options that apply to it: What we're working on next In addition to all of these existing tools, our team is working on some significant improvements to our backend stack. The biggest of these projects is the upgrade to Java 11, which has been a bit of a rollercoaster (looking at you, Spark). We're also investigating automated code formatting using prettier-java . Finally, we've integrated Error Prone into our build process and will begin leveraging it to catch, and automatically fix, problematic code patterns.", "date": "2019-11-21"},
{"website": "Hubspot", "title": "First Recipients of 10k Refer A Friend Bounty", "author": ["David Gallant"], "link": "https://product.hubspot.com/blog/bid/64875/first-recipients-of-10k-refer-a-friend-bounty", "abstract": "On January 24th , the first shot was fired in a Boston battle to find great developers.  Our ammo to find great talent was a bounty of $10,000, which could be awarded to anyone with a qualified referral. Submit contact information for a referral This week at the HubSpot Science Fair, jumbo checks were awarded to referrers of our first three employees who were introduced to our team through this program.   On the first day of each month, all of our development teams present their past month's accomplishments to the company and local Boston friends, customers, and advisors. We will be presenting two more jumbo checks next month to two additional referrers. Dan Vidal of ArtVenue HubSpotter Joe Khurana HubSpotter Bryan Beaudreault", "date": "2011-06-06"},
{"website": "Hubspot", "title": "Six Tips to Ace an Analyst SQL Interview", "author": ["Jennifer Lin (She/Her)"], "link": "https://product.hubspot.com/blog/six-tips-to-ace-an-analyst-sql-interview", "abstract": "The most common technical interview that analysts face, especially early in their careers, is the SQL interview. It has a bad reputation as a profoundly awkward experience, but from a recruiting perspective, it remains a good way to answer two questions: Is this candidate able to independently write logic to pull data successfully and efficiently? Are they able to interpret the data appropriately? These interviews (assuming they're live, rather than take-home, or interviews) usually go something like this: An interviewer introduces two or three simple tables, often relevant to their business. The interviewer asks a question that can be answered by those tables. The candidate writes SQL on a whiteboard, in a Notepad file, or some other place that may or may not be able to process SQL. Candidates are encouraged to \"talk through\" their logic as they write their query and answer the question. The series of questions becomes more difficult, since the first few are often structured to give the candidate time to become acquainted with and ask questions about the data. If you're concerned about a SQL interview or have struggled through them, here are some tips that have helped me throughout my career: 1. Accept the fact that it could be awkward, and that's okay. SQL interviews often remind me of exams in school, except someone is carefully watching me as I work. It adds a level of stress that simply doesn't exist in the day-to-day of most analysts. Here are a list of behaviors that people may find awkward, but are completely okay during a SQL interview: Silence Starting sentences over because what you're describing is hard to put into words Not making eye contact Stating what may seem obvious 2. Take great notes, especially about the format of the tables. (Bring pen and paper just in case.) I struggle to remember the structure of new tables, even simple ones. Write the table formats down in an accessible place, and ask the interviewer any questions you might have. Missed the name of one of the columns? Confused about what something means? Not sure if the table is on a per user or per account basis? Ask. Remember that your interviewer is a resource, and it's their responsibility to be clear on the premise of the problem. 3. Say what you're thinking. Ask to take a moment if you need time to put your thoughts together. Although these questions often have \"right\" and \"wrong\" (and \"efficient\" and \"inefficient\") solutions, a SQL exercise is about logical reasoning. Interviewers give out partial credit for your line of thinking, but if you never express it, the interviewer has no idea what happened. A helpful framework to use when describing your approach can be to: Do Example Confirm the objective and your understanding. Ask any questions if necessary. I need the mean revenue of customer group A and customer group B to understand which group typically spends more on our products. Explain any initial thoughts or approach considerations. I need both table A and table B, the first for revenue, the second for what group a customer belongs to. Because table A is a list of transactions, I'll need to aggregate up first. Explain the different parts of your query as you write them. This part of my query sums the revenue for each customer in table A. I want to nail this down before I join to our group type data. Once finished, look over your work and describe the query holistically. I summed revenue data for each customer in this first section before joining in the customer type data from a separate table by customer ID. I then calculated the mean revenue per customer by customer group here. Remember to answer the question itself. Group A has a higher mean revenue, but it would be interesting to see if this group is big enough that we should focus more on them than on Group B. If you've never had to explain how you wrote some SQL, take some time to practice doing so. In the interview itself, it's also okay to ask for time so that you can speak more clearly about the steps you've gone through or determine your next step. 4. Remember that some things don't matter. SQL interviews are rarely designed to test someone's ability to remember details in syntax, how quickly they type, how nicely they write, or any number of factors that simply aren't relevant to success as an analyst. Memorizing the syntax of a `case when` statement in the type of SQL we use won't hurt you, but we don't test for things that are easily solved by a Google search. Interviewers usually aren't trying to trick you either (after all, databases aren't usually designed to trick analysts). We just want to make sure you can build the logic (and/or see the flaws in your logic) to get the data you need. 5. Write your SQL for clarity. As an interviewer, I'm sometimes afraid that I won't be able to read or understand a query and panic any time I see a long nested query. If it's difficult for you to write, it's likely difficult for me to read. Although there is no need to stress over the details of your SQL formatting or note-taking, it's helped both me and my interviewers to invest here. Indent where it helps, label what different parts of your query do, give new columns practical names, and use `with`/CTE statements to break up your query instead of using nested queries. Notes like \"assuming X is distinct\" or \"condition assumes none of these values are negative or zero\" are helpful reminders both for your interviewers and yourself of the query's underlying logic. This skill is also great to demonstrate, since this kind of organization and documentation is important for an analyst out in the wild. We do, after all, revisit our own queries and share queries with each other. 6. Practice, especially with joins. When it comes to a SQL interview, there is no substitute for being really good at writing SQL to pull data. Practice! Far and away, joins are the most common \"difficult\" part of a query to handle because it tends to be the most common, abstract statement we use that has the real ability to ruin absolutely everything. Visuals such as these can help: Images from: https://www.w3schools.com/sql/sql_join.asp Other common statements that are likely to appear are `group by` (and their associated aggregations), `case when,` and `union`. In my personal experience, SQL exercises are focused on fundamental logic, since more complicated statements can be learned fairly quickly (and sometimes done through more simple statements). And that's it for the tips. Good luck! Interested in becoming an Analyst at HubSpot? Apply to one of our open Analyst positions today!", "date": "2020-10-23"},
{"website": "Hubspot", "title": "Working on the same code is like having roommates", "author": ["Chris Keller"], "link": "https://product.hubspot.com/blog/bid/49199/working-on-the-same-code-is-like-having-roommates", "abstract": "One of the perks in Engineering at HubSpot is that you get to work in small teams.  Most developers like this for a variety of reasons, but for many, that would include \"There's not too many people touching the same base of code\". With that said, I ran into some funny examples the other day where the analogy \"Working on the same code is like having roommates\" and inspired this post. Obviously any good engineering team has some coding conventions, but it's always funny to see people's preferences come out nonetheless in their own code.  One of these is the curly brace for function definitions, do you put it on the same line, or the next line? One of my colleagues is notorious for moving my curly braces to the next line even when it doesn't matter.  It's a style preference and he exhibits it, but then I thought, this is similar to when someone feels like the TV remote should be on the TV stand and not on the couch (where it probably always falls into the cushions). I then noticed a change in my code where a predefined function was substituted for some custom code I needed in that exact instance and here I thought, I forgot to leave a note on the fridge explaining not to touch that line of code. You can see how these examples could continue, but the point is that whenever you're managing a code base with other people, you have to remember that people's habits and preferences will always be displayed, and to not get too frustrated by those things.  Establish as many coding rules up front as you can that don't take a year to learn. Have any funny examples like this yourself?  Keep up the clean coding.", "date": "2010-08-06"},
{"website": "Hubspot", "title": "Why We Traded Scrum for “Science Fair” to Build HubSpot", "author": ["Christopher O'Donnell"], "link": "https://product.hubspot.com/blog/hubspot-product-science-fair", "abstract": "We broke up with scrum about six years ago. Agile development served us well in startup mode, but as we added more seats, opened new space, and launched new tools, it actually started to stunt our product culture’s growth. Take autonomy, for starters. We think engineers should have complete autonomy over their code and part of the product. And even though scrum is designed to protect developers from the demands and distractions of your CEO, marketing team, sales team, etc., it can actually tie their hands. There’s no trust being built between product and the rest of the company; sprints end up more like transactions than conversations. The other piece is that it became unrealistic to have a one-size-fits-all dev process across the org. Every small development team “owns” a different part of HubSpot; there’s an email team, a blog team, a social media tools team, a CRM team, etc. So there’s really no monolithic way of planning that would work for every team. They all have different challenges. So we said, scrum, it’s not you, it’s us, and moved to an “ad-hoc” development process. A big reason we’ve been able to make that work for the past six years, though, is because we took pieces we liked from agile. We liked the live demos and the contract, so-to-speak, they created between product and the rest of the company. Today we have a different tool for empowering autonomy within product teams and relating their progress back to the larger org. That tool’s called HubSpot Science Fair. Replace baking soda volcanoes with live software demos and you have a HubSpot Product Science Fair (sort of). Science Fair is a monthly, company-wide demo showcase from product teams to share what they’ve been building over the past month. We only present real working software and product managers have to identify whether it’s in beta, alpha, gated-to-X, or live to the public. They can present a new product or feature, improvements in UX, reliability, or stability. The first Science Fair was almost ten years ago, and some elements look a little different today. For example, in the early days, we would only present new features. Now, we don’t just celebrate new tools but improvements to reliability and incremental developments that make a big different in a customer’s experience. Another more recent change is that we’re moving from team-based demos to theme-based demos. So instead of having every product manager demo their part of the app, this last Science Fair was focused solely on reporting. That way, we can all rally behind one big mission and really dig into how it influences other parts of the app. (We think this new themed approach was a success; one data point was an excited cat .gif our co-founder and CTO shared with the caption ‘Today was the HubSpot Science Fair. It's hands-down one of my favorite days of the month. But this time, it was even favoriter.’ ) The only ‘guideline’ that hasn’t changed over the years is that whatever is presented at Science Fair has to show real customer impact. That could look like anything from a customer quote to a measurable decline in customer support tickets; it doesn’t matter how it’s backed up but there needs to be some tangible insight into how it’s making our customers’ lives better. Lastly, while customer experience is paramount, Science Fair experience gets a nod, too. Every Science Fair has a “host” runs point on the agenda, scheduling, A/V, and ordering something more exciting than pizza. For example, one of our senior engineers, Greg, made hundreds of his famous Dump Truck dumplings for Science Fair once so the bar has been set pretty high. The same is true for costumes. Hosts aren’t required to dress up, but product manager Lars raised the stakes at April’s Science Fair . How Science Fair Helps Us Build Software (and Trust) Science Fair is helping us become more of a product-driven company every month. It’s one of the tools driving speed and ambition behind product teams, it’s the platform for celebrating developer impact on customer happiness, and it really shows you how much power product people have. Think about it: Every month, the exec team comes to Science Fair (our CEO typically is front and center, no pressure), and spends an hour listening to these front line product folks about how their teams are going to impact the bottom line. That’s powerful. Giving product teams that level of autonomy has created a really strong foundation of trust between product and the rest of the company. I think a lot of what slows development down as companies grow comes from a lack of trust at a leadership level. Instead of focusing on a shared mission, leaders can let politics trump progress. That’s why we default to transparency, and Science Fair is on the front lines of that. Product teams don’t try to hide their failures or overly celebrate the successes. By walking the company through a problem, the solution, and how it will make our customers’ lives better, Science Fair gives every team at HubSpot a raw glimpse into how product is moving the needle on our overall mission. In that way, Science Fair is kind of like a company-wide trust fall. Really. I’m our VP of Product, and a good percentage of work demoed at Science Fair is stuff I’m actually seeing for the first time. And it works; that trust between product and our leadership team helps product people move fast and work independently of red tape. Just like it was when we were in grade school, Science Fair is an education; both for the organization and for our product team. We get to teach other departments what’s coming down the pike and how we’re driving customer success, and we’re constantly teaching each other how to be storytellers and show impact. I guess what I’m trying to say is, I don’t see HubSpot breaking up with Science Fair any time soon.", "date": "2017-06-14"},
{"website": "Hubspot", "title": "Kirk Hlavka: Introducing the Product Operations Associate Analyst Rotational Program", "author": ["Kirk Hlavka (He/Him)"], "link": "https://product.hubspot.com/blog/kirk-hlavka-introducing-the-product-operations-associate-analyst-rotational-program", "abstract": "", "date": "2020-10-14"},
{"website": "Hubspot", "title": "4 Lessons for Smoother Technology Migrations", "author": ["Emil Sit"], "link": "https://product.hubspot.com/blog/four-lessons-for-smoother-technology-migrations", "abstract": "Sooner or later, every technology organization faces a necessary evil: migrations. Maybe the old system is not scaling or the implementation is too brittle to adapt to a new feature. Maybe it’s not capable of interoperating with newer systems. Whatever the reason, t he time will inevitably come to migrate part of your application from one implementation to another. Performing migrations can be a thankless task. The old system, flaws and all, works. And, everyone expects the new system to do everything the old one does, in addition to whatever new functionality is required. Even if users can be moved to the new system incrementally, people don’t have much patience for products behaving differently and functionality being broken or missing. This is something we learned the hard way this past year. My team is one of the teams that maintains the infrastructure behind HubSpot’s Sidekick product, a freemium tool that provides email productivity tools such as email open and click tracking. Over the past year, we made two big migrations. First, in order to achieve a better balance of performance, cost, and control, we moved our primary storage for our email open and click feature from one data storage platform to another. This required copying and transforming hundreds of gigabytes of data and building an entirely new pipeline to process clicks and opens into the new storage system reliably. Second, after several months of manually modifying settings in our billing backend to support our new Sidekick for Business product and pricing, we re-wrote much of our billing system to standardize and automate handling of multiple pricing levels. This required significant changes to our team membership flows and internal accounting. Neither of these migrations were seamless. We followed the general principles behind our known tactics for safely rewriting a big API (such as gating and routing traffic incrementally), but we neglected to do a few things that could have helped us avoid a few potholes. So, here are four lessons we learned from these Sidekick migrations that will hopefully make your next migration a smoother process. Understand What the Old System Did and Why One big challenge in technology migrations is knowing everything the old system does and why. Over time, a code base accretes little tweaks and hacks that help it deal with edge cases that come up in a production system. Like scar tissue, this code is critical in keeping the product functioning smoothly, but as people join and leave teams, and as products evolve, it’s hard to keep track of the cuts that led to scarring in the first place. Without a team that knows the old system inside and out, important things can get lost in the migration. Something important did get lost when we were migrating our open and click tracking system: the suppression of notifications when you open your own emails. Although the job of our tracking system is to tell our users when someone has opened an email that they’ve sent, users don’t want to be notified when they open their own emails. So, an earlier team had built special checks to detect when users open their own email and discard that notification. When my team built the updated pipeline, we didn’t realize this and didn’t build in these checks when we initially rolled out the new system. Users immediately began complaining and we had to scramble to fix the problem. This was only one of several instances of “scar tissue” that ended up getting lost in translation during the migration and causing us problems. When we started our billing migration, we knew we needed to be more careful. We dug into the code and wrote a basic specification of the system. Writing the spec helped us document what needed to be done and why, and forced us to think through what we may have otherwise overlooked during the migration. While we certainly didn’t get everything right, having the document as a reference made a huge difference in glitch-proofing our process as much as we could. Engage All Stakeholders Early On As you start exploring the system’s behavior, you might discover that different people depend on it in different ways. It’s natural to involve other technical teams and management in the migration process, but we realized that non-technical parties, from your social media team to your support staff, from your salespeople to your finance department, should be clued in from the get-go. The goal is to understand what’s important to them so you can keep an eye on it from the technical side. These stakeholders interact with your systems every day and have their own special tricks or patterns for getting their jobs done. In fact, over time, you’ve probably built a variety of little tools that they’ve become dependent on. Migrations are designed to improve the system for your customers (e.g. better performance, more features) but if the new system breaks or eliminates those tools, you’ve done the opposite for your internal stakeholders. Changing their workflows without warning means your technical team will be bombarded with questions that stakeholders used to handle themselves. For example, when we re-engineered the billing system, we changed the semantics of some details on the internal billing administration page, and broke the ability for support to make certain account adjustments. As a result, our support team was often confused about how to interpret what they saw on the page for a given account, and was also unable to rectify common problems that they had previously been able to handle. Needless to say, this led to a lot of stress for everyone. By being more explicit about changes and keeping tooling changes in line with product changes, we could have made this much easier for everyone. Do your team and stakeholders a favor by communicating the migration early on and keeping them in the loop throughout the process. An added benefit of working with other stakeholders is that they may help you spot problems that you didn’t even think to check for in testing. In our case, it’s often a race between our social media team and our support reps to see who gets the first word from customers that something is off after we deploy some new code. And one time, our finance department quickly pinged us when we “forgot” to enforce our freemium product limits for a week. Phew. Detect Behavioral Differences On that note, a powerful strategy for finding problems during a migration is to identify key business metrics and set up alerting on those metrics. Often, alerting focuses on technical problems: is your 99th percentile response time spiking? Are there too many server errors? However, a vast spectrum of product failures do not trigger these alarms. One example of a business metric we use concerns our user onboarding process. During onboarding, we show a new user how to send a tracked email and what it is like to receive a notification. Based on historical data, we know how many people should experience this interaction each hour. If it doesn’t happen at the right rate, we know we’ve broken something. Because anomaly detection can be difficult, just setting thresholds for extremely abnormal behaviors can be helpful (e.g., if zero new users receive a notification, that’s a bad sign). This means thinking about your business metrics before you start coding. Business metrics tend to be more robust to technology change than technical metrics because you still need to provide the same business value even if your technical implementation is changing. Another technique is to compare end-to-end output, if possible. If you are changing your data source, make sure the user rendered output remains the same. Here, “same” can mean anything you want—you can literally compare the rendered output pixel by pixel or you can just make sure there are certain div elements that contain the right text. For developers, it can be very helpful to have a mechanism that forces the application to use the old component or the new component at runtime. We used a secret URL to allow us to view user activity data using both the new and the old data stores as a way to detect issues and verify fixes. Prepare your Infrastructure and Architecture for Iteration Having a plan, working with stakeholders, and monitoring key metrics lets you catch problems before or as they happen. But, there will still be things that slip through the cracks. That’s why it’s important that both your infrastructure and your application’s architecture supports rapid iteration. Our billing system and email tracking pipeline were initially part of a more monolithic system, so despite HubSpot’s microservices architecture and deployment infrastructure , we could not deploy pieces of it independently and big changes were risky to deploy. This was frustrating because, as we migrated users and data incrementally (in both cases!), we found a lot of edge case and anomalous data that would not work properly in the new system. These were not even cases that you can really plan for: you often won’t know the kinds of weird data you and your users have put into the system over the years until you try to migrate it. To address this, we improved our architecture by extracting these components from our monolithic system, enabling us to iterate more quickly. Our email tracking pipeline now has many incremental processing stages that can be independently and reliably deployed. We extracted our billing system’s UI into a separately deployable front-end component, so we could make front-end improvements without having to worry about changes being coupled to our larger monolithic system. In both these cases, it benefited ourselves and our users when we could improve, tweak and test our systems more quickly and safely. These four lessons have helped us manage the constant technology change involved in operating a SaaS product. What do you do to help ensure successful technology migrations?", "date": "2015-06-23"},
{"website": "Hubspot", "title": "New Blog API (beta): access your blog data and blog analytics", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/58065/new-blog-api-beta-access-your-blog-data-and-blog-analytics", "abstract": "Last week we rolled out a new public HubSpot API, the Blog API, in beta form. This API, as its name suggests, provides you with access to your blogs hosted on the HubSpot product, and related data such as blog posts, blog comments, and blog analytics. For the impatient, here is a quick link to the Blog API docs .  Go build something ;) This is the second public API we've launched here at HubSpot, and we definitely incorporated some lessons learned from the first one, the Leads API .  Hopefully you will find this API easier to use than the Leads API, and by the way, we're building a v2 of the Leads API as well. One nice thing about this API is that it can use a standard format, AtomPub , to exchange its information.  The AtomPub spec is reasonable, and once we saw that Google (Blogger), WordPress, MoveableType, and others were using this interchange format, we implemented it as well. The API, like the Leads API, is REST-style in spirit.  It's not perfect, and this initial version does not support all the verbs or operations we'd like, but it's a good start and we'll add more in v2 of the API later on. The full blog API documentation is public, and the discussion group is where we hang out, answer questions, etc. We hope to see some cool and useful applications built on this API, such as a tool to import blogs from WordPress or other providers to HubSpot, a tool to export HubSpot blog data to another location, mobile apps (iPhone, Android, etc.) to draft blog posts and get blog data, and more.", "date": "2011-01-17"},
{"website": "Hubspot", "title": "HubSpot's approach to front-end development: Part 2", "author": ["Timothy Finley"], "link": "https://product.hubspot.com/blog/front-end-development-2", "abstract": "In part 1 about HubSpot’s approach to front-end development, we talked about common issues with sharing front-end code (JS, CSS, etc) across teams and how dependency management can help. However, dependency management of front-end code is a relatively new thing. There have been a few projects that have started taking that path, but developers haven’t yet taken into account how front-end web code is subtly different from typical desktop or server-side code . For the past year at HubSpot, all of our web apps have been built using something we call Asset Bender (historically we’ve also called it Static3). And it is a crucial piece of infrastructure that helps us ship better, more consistent web apps even faster. So what is Asset Bender ? Asset Bender isn’t a single tool. Rather, it is a suite of several tools that work in concert. It includes: A dependency management system for Javascript and CSS A local server, package manager, and precompiler Build tools that optimize and link the project's dependencies A server-side runtime that allows on-the-fly dependency updates Dependency management by magic URLs At its core, Asset Bender performs dependency management by changing existing URLs in your code and inserting version numbers. I like to call these \" magic URLs\" because this conversion happens automatically, without any intervention on your part. For example, let’s say that you had some URLs like this in your code: /* CSS */\nbackground-image: url(/app1/static/img/background.png)\n\n// Javascript\njQuery.get(\"/app2/static/js/some-code.js\")\n\n<!-- HTML -->\n<a href=\"/app3/static/html/page2.html\">Page 2</a> After getting built and deployed by Asset Bender, they might look like this: /* CSS */\nbackground-image: url(/app1/static-1.7/img/background.png)\n\n// Javascript\njQuery.get(\"/app2/static-3.42/js/some-code.js\")\n\n<!-- HTML -->\n<a href=\"/app3/static-2.13/html/page2.html\">Page 2</a> I’m jumping over a lot of steps here, but bear with me. The basic idea is is that asset URLs in code look like: /<app-name>/static/<asset-path> . And when deployed they look like: /<app-name>/static-<resolved-version>/<asset-path>. Version numbers In Asset Bender, version numbers have two parts, a major and a minor version number ( <major>.<minor> ). Like other versioning systems, the major number denotes significant, breaking changes. And it is each application’s responsibility to increment the major version number for “major” changes. On the other hand, the minor version number is for what it seems, “minor” updates that are backwards-compatible. However, unlike major version numbers, you never need to manually increment minor version numbers. Instead they are automatically incremented every single build. So the version numbers that come out of our Jenkins builds look like this: 1.1, 1.2, 1.3, …, 1.9, 1.10, 1.11, … Having these automatically increasing minor version numbers can lead to some pretty silly versions (we have ones like 2.5764), but it works well with our “constantly shipping” philosophy. Not only would it be a pain in the butt to make developers have to manually change the minor version number frequently, but it also makes every single build referenceable . That gives us a lot of flexibility when depending on specific versions or rolling back. Now that you understand the basic building blocks—version numbers, and versioned URLs —let’s start to walk through the various pieces of Asset Bender. It all starts with the local dev server. The local server You start the dev server with a simple command, bender run . By default, that starts up a local HTTP server on port 3333 that logs to your terminal. But it does more than just serve files, it will also: Compile SASS, CoffeeScript, Handlebars templates, and others Combine multiple files and/or directories together into a single Javascript or CSS file Automatically adjust your asset URLs to point to the exact version of the dependencies you’ve downloaded Also, it is useful to note that all of the above are done on-the-fly with each request. That means that: You don’t have to run any other filesystem watcher processes Errors are in-your-face in the browser You never run into the dreaded, \"I pressed refresh but my changes didn't show up\" issue (which can tend to happen with large, complicated SASS files). An example project Let’s say you are working on a local project called app1 that has a directory structure like so: app1/\n  static/\n    static_conf.json    -> Configuration (dependencies, etc)\n\n    img/… \n    coffee/\n      app.coffee        -> Javascript entry point\n      main.coffee       -> Most of the app code\n      some-plugin.js    -> A custom jquery plugin\n\n    sass/\n      app.sass          -> CSS entry point\n      other-styles.css  -> More styles And here are the contents of app.coffee and app.sass (the main two assets that your app includes): app.coffee #= require ./some-plugin.js\n#= require_tree /other-app/static/js/components/\n#= require ./main.coffee app.sass //= require ./other-styles.css\n//= require /another-app/static/sass/shared/base.sass\n\n@import \"/another-app/static/sass/shared/contants.sass\"\n\n#my-awesome-app\n  // best styles ev4r! … If you’ve ever used Rails 3.x before, this will be familiar (Asset Bender is built on top of Sprockets , which powers the Rails Asset Pipeline ).  But for those of you that haven’t, those require directives act as a preprocessor to include other files or a directory full of files inline into the current file when served. Also, they can refer directly to SASS or CoffeeScript, compiling the contents before inlining it. That’s cool, but it is standard with Rails. The thing that Asset Bender brings to the table is referencing files in other projects (those lines with other-app and another-app above). Depending on your setup, you may or may not have the source for other-app and another-app checked out on your machine. But for now, let’s assume app1 is the only project you’ve checked out.  How will this code get access to those projects? Installing dependencies As things are right now, if you requested http://localhost:3333/app1/static/coffee/app.coffee or http://localhost:3333/app1/static/sass/app.sass , you’d get an error because those dependencies haven’t been downloaded yet. However, you can solve that by running bender update-deps . Tha t command will look at the configuration of app1 (aka static_conf.json ) and download the latest version of each dependency to a local archive folder. So, after running that command in our example, the archive folder might look like this: ~/.bender-archive/\n    other-app/\n      recommended   -> version “pointer” file\n      edge          -> version “pointer” file\n\n      static-2.19/  -> specific version of other-app’s source\n        js/…\n\n    another-app/\n      recommended   -> version “pointer” file\n      edge          -> version “pointer” file\n\n      static-1.6/   -> specific version of another-app’s source\n        sass/… We will talk about those pointer files later. The important thing to understand now is that the archive folder collects specific versions of Asset Bender dependencies. This is roughly similar to how Python modules end up in the site-packages/ folder or JARs installed by Maven end up in ~/.m2/repository/ . Also, the Asset Bender server will automatically serve those dependencies. That means you can visit a URL like http://localhost:3333/other-app/static-2.19/js/components/some-file.js (notice that dependencies need to be referred to by a version number). Bringing it all together OK. Now that those dependencies are installed, we can successfully request app.coffee and app.sass from app1 . And when you hit http://localhost:3333/app1/static/coffee/app.coffee , Asset Bender will interpret this line: #= require_tree /other-app/static/js/components/ as: #= require_tree /other-app/ static-2.19 /js/components/ Essentially, Asset Bender recognizes when you are referring to a dependency and automatically replaces the appropriate version. And version replacement can happen practically anywhere: in compiled SASS and CoffeeScript code, in require directives and SASS @import statements, and in any plain HTML, JS, or CSS you might have. All of this simply means that you never need to worry about versions in your code, Asset Bender will handle it for you. And if you ever need to upgrade to newer versions of your dependencies, all you need to do is run bender update-deps again. Continue on to part 3 (available soon) to learn more about Asset Bender’s internals, how those versions get resolved, and how all of this works on production. But, if you’d like to skip ahead and see a preview of the code, you can check out the Asset Bender repo on Github (but don’t worry, we’ll get to it if you keep on reading).", "date": "2013-04-15"},
{"website": "Hubspot", "title": "Video: Latest Developments: Dispatches from our Product Team", "author": ["HubSpot Product Team"], "link": "https://product.hubspot.com/blog/webinar-latest-developments-dispatches-from-our-product-team", "abstract": "Every week at HubSpot, we put on an internal event called Tech Talk, where our engineers share all the latest about what they’ve been up to and their peers get a firsthand look at the future of the HubSpot product. Now, you can go behind the scenes, too. In this video, you’ll learn about the latest HubSpot product updates and how we built them, straight from our engineers themselves. Get the inside scoop on our engineering principles, our latest projects, and what's coming next. Speakers: Mitchell Katz, Tech Lead, CMS Assets IO The CMS Assets IO team provides building blocks for the CMS without needing developers to build them. Mitchell speaks about how we shifted to using real files to represent these building blocks, then used these file representations to rearchitect our default asset distribution system and marketplace to be more scalable and far less complex. Isabel Porto, Tech Lead, Mobile Sales (Android) Antonio Pinho, Senior Software Engineer, Mobile The Mobile team allows our mobile app users to scan their business cards into HubSpot CRM and paste meeting/attachments links directly into WhatsApp and other apps. Isabel and Antonio discuss how we build Mobile features at HubSpot. Kevin Moses, Tech Lead, FinTech Making Billing HubSpotty: How we enabled our FinTech teams to ship code at lightning speed while remaining reliable and compliant. This session was recorded on November 19, 2020 .", "date": "2020-12-02"},
{"website": "Hubspot", "title": "The Five Whys and Continuous Improvement", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/14517/the-five-whys-and-continuous-improvement", "abstract": "At HubSpot, we've big believers in continuous improvement.  We hire stellar people, but no one is perfect.  No team is perfect, nor any process, nor any piece of code. One of my favorite things about Scrum is the end-of-sprint team retrospective.  Each Scrum team meets, just the pigs, in private.  They spend a little bit of time (or as long as they want) talking about what worked well, what didn't, why things worked (or not), and how to make it better next sprint.  The outcome is a set of specific, concrete changes the team can try in the next sprint. The Five Whys is a closely related concept.  It's also about continuous improvement, one form of which is called Kaizen , from the Japanese word.  I first learned about the Five Whys in graduate school, but then was reminded of it by Eric Ries, in his excellent Startup Lessons Learned blog. The Five Whys is a fairly quick, transparent, and efficient way to do root-cause analysis.  At HubSpot,  the dev team does this for really serious bugs.  It typically takes 30-60 minutes, and the outcomes is always satisfying.  This works well for me, since I'm not a fan of long meetings and process just for the sake of process. One thing we believe is that \"people need to be smarter\" is not acceptable outcome or improvement.  People will always make mistakes.  No one is perfect, no code is perfect, no process is perfect.  It's all about making things better and preventing future errors at every level. In the future, we might start sharing the result of Five Whys analysis here.  We may not be able to publish every single detail, because some data is customer-specific and thus confidential.  But we'll try to be transparent about the process, the problems, our findings, and related metadata. Would you find that interesting or valuable? Do you or your company practice this sort of analysis? If so, have you found that it's worth the time? Do you know anyone who's sharing their problems and findings in public like this?", "date": "2009-08-07"},
{"website": "Hubspot", "title": "Working with Shaded Guice", "author": ["Ian Marlier"], "link": "https://product.hubspot.com/blog/working-with-shaded-guice", "abstract": "HubSpot's Product team writes much of our backend code in Java, with Google Guice providing depedency injection. We've created modules to handle most common tasks, modules which we can access with no more than an @Inject annotation. Recently, though, we've been working with Elasticsearch , and have run into an issue reusing our existing modules.  Elasticsearch also uses Guice, but it uses a shaded version; instead of importing com.google.inject.*, it imports org.elasticsearch.common.inject.*.  When evaluating dependencies for injection, Elasticsearch requires modules that extend org.elasticsearch.common.inject.AbstractModule, instead of com.google.inject.AbstractModule.  As our existing modules extend com.google.inject.AbstractModule, Elasticsearch isn't able to use them directly. We ended up working around this by creating a new module, extending the org.elasticsearch version of the Guice AbstractModule, which instantiates a com.google.inject.Injector instance and provides the shared modules that we need.  This ends up looking like this: package com.hubspot.elasticsearch.plugin.lib;\n\nimport org.elasticsearch.common.inject.AbstractModule;\nimport org.elasticsearch.common.inject.Provides;\nimport com.hubspot.config.HubSpotConfigModule;\nimport com.hubspot.other.OtherModule;\n\npublic class BaseInjectorModule extends AbstractModule {\n\n  private com.google.inject.Injector baseInjector;\n\n  @Override\n  protected void configure() {\n    this.baseInjector = com.google.inject.Guice.createInjector(\n            new HubSpotConfigModule(),\n            new OtherModule());\n  }\n\n  @Provides\n  public HubSpotConfig HubSpotConfigProvider() {\n    HubSpotConfig hsConfig = baseInjector.getInstance(HubSpotConfig.class);\n    return hsConfig;\n  }\n\n  @Provides\n  public Other OtherProvider() {\n    Other otherThing = baseInjector.getInstance(Other.class);\n    return otherThing;\n  }\n} Having done this, we can install the module in the context of our Elasticsearch plugin, by overriding the modules() method of org.elasticsearch.plugins.AbstractPlugin: package com.hubspot.elasticsearch.plugin.MyPlugin;\n\nimport org.elasticsearch.plugins.AbstractPlugin;\nimport org.elasticsearch.common.inject.Module;\nimport org.elasticsearch.common.collect.Lists;\nimport java.util.Collection;\nimport com.hubspot.elasticsearch.plugin.lib.BaseInjectorModule;\n\npublic class MyPlugin extends AbstractPlugin {\n\n  @Override\n  public Collection<class<? extends Module>> modules() {\n    Collection<class<? extends Module>> modules = Lists.newArrayList();\n    modules.add(BaseInjectorModule.class);\n    return modules;\n  }\n} The end result of this work: we're able to reuse our existing code, and maintain consistency in how we resolve dependencies, despite the shaded version of Guice being used in Elasticsearch. We took this approach because there wasn't an obvious canonical solution.  We're curious, though: how have other people solved this problem?  We can't imagine that we're alone in having run into it.", "date": "2014-03-24"},
{"website": "Hubspot", "title": "Approaching Diversity and Inclusion in Hiring as A Design Problem", "author": ["Libby Maurer (She/Her)"], "link": "https://product.hubspot.com/blog/diversity-inclusion-design", "abstract": "It’s no secret that much of the tech industry has struggled to build diverse organizations and teams. HubSpot, with more than 3,000 employees, has faced this same challenge. But instead of throwing up our hands and saying Well, that’s just how things are, our UX team decided to treat the problem like any customer problem--only this time, we were solving for ourselves. We decided to apply our design thinking methods and approach the challenge in a user-centered way. We set out to use the data-driven approach ingrained in our Culture Code to identify holes in our recruiting, hiring, and retention practices, and layer qualitative research on top. Through this initiative, we identified HubSpot’s three biggest areas for improvement. We realized that referrals were hurting instead of helping our diversity goals, found issues in our interview process that weren’t inclusive of candidates from underrepresented minority groups, and identified ways to retain more women and people of color. In this article, I’ll share the results of our research and highlight the steps we took to conduct it, leaving you with a guide for how to execute similar user-focused research to identify holes in your own practices. The Referral Problem One of the reasons we’ve been able to keep pace with HubSpot’s rapid growth is a steady stream of referrals from current employees (within the UX team alone, we’ve seen +30% growth since 2016). If you’re growing a team as quickly as we are, this may resonate with you. As in most tech hubs, networks are deep, and employees often jump at the chance to recruit former teammates. And at HubSpot, we have gone out of our way to encourage referrals, especially in times when there’s a need to fill roles quickly and regularly. But then we took a step back to think about what, aside from allowing us to fill roles quickly, our large number of referrals was doing. Statistically, employee referrals are known to benefit certain populations while doing a disservice to underrepresented groups. A 2017 study by Payscale found white men are up to 12% more likely to be hired through referrals than any other group. Conversely women of color benefit the least from referrals, 35% less likely to receive a job offer from that same referral. This means that employee referrals often work against diversity because of peoples’ implicit bias to recommend people who look and act like themselves, which often negatively affects minority groups. In light of this data, we wanted to run a comprehensive analysis on where our hires were coming from. The numbers spoke for themselves: since 2016, about 50% of hires on our team were referrals from HubSpot employees. We hired an additional 12% of our workforce internally, with the rest of new hires coming from inbound applications or passive sourcing. Between our referred candidates and internal hires (60%) we realized we were at high risk of sabotaging our efforts by not actively choosing interviewees for their diverse backgrounds and skill sets. So we reframed our referral strategy. We didn’t want our team to stop referring qualified, talented people who could make a big impact at HubSpot. But we decided to commit to a more purposeful approach. We put together a set of resources for hiring managers and team members to rethink the way we ask for referrals. For instance, we trained our team in a concept called “ aided recall ”—which involves crafting a specific recruiting ask, like “great women content designers you’ve worked with” rather than a general ask—in order to drive more specific and more diverse candidates. We also shifted to more proactive sourcing to balance out the referrals. Now, for any given position, we strive for an equal mix of referrals, inbound applicants, and sourced candidates, giving us much more control at the top of our funnel. We uncovered another interesting data point as we collected perspectives from hiring managers about how they thought about referrals: We learned our referral and interview process itself was unfriendly to minority and inexperienced candidates. We realized that no matter how diverse the top of our recruiting funnel was, if folks from underrepresented backgrounds didn’t make it through the funnel, all this work wouldn’t matter. That’s why we went about creating a better interview experience. A Better Way to Interview Interviewing is the most crucial step in the recruiting process, and it’s important to get it right. But we’d gotten direct feedback that our interview process was giving people from underrepresented backgrounds the perception that HubSpot wasn’t the place for them. Aside from that specific piece of feedback, we had very little data because candidates weren’t filling out our post-interview surveys. So Lauren McKenzie, then head of our User Research, partnered with our recruiting team to run a lean research study. Their goal was to find new opportunities to collect feedback about the candidate journey--just like we do for customers--and map out areas to improve communication, messaging, and process. We reasoned candidates might be more open to giving feedback directly to a researcher who wanted to improve their experience in real-time. While the exercise was aimed at helping all candidates in the pipeline, it was especially sensitive to the ways in which our current process wasn’t optimized for candidates from underrepresented groups. First, Lauren reached out to candidates who were midway through the interview process. She also reached out to a separate cohort of candidates who had gotten offers and hadn’t yet started, as well as those who hadn’t gotten an offer. She made sure we had a balanced distribution of people from different ethnicities, genders, and experience levels. She pulled out the common themes by creating an Experience Map of candidates’ experiences in our hiring process. From these interviews, we found that even in the interview process, candidates who were referred by teammates often had an advantage over non-referrals. They had more context about the company and role, leading to an uneven playing field because they could prepare to talk very specifically about how their skills would be additive to the role. Now, we can’t prevent employees from sharing information with referrals but we can ensure all candidates and interviewers receive the same information going into the interview. So our recruiting team created an interview prep guide for every candidate. It encourages them to do research in certain areas and gives them a sense for topics they’ll likely be asked, helping all candidates prep better for the interview. We also created guides for interviewers themselves, which include specific behaviors and competencies to screen for and suggested questions to remove bias from the process. Most importantly, we wanted to avoid the notion of “culture fit” as a proxy for potential. To make the interview experience more thoughtful, inclusive, and consistent, we’ve created a standard set of questions for interviewers like “Tell me about a time when you made someone else look brilliant.” The key is consistency, so interviewers are all using the same standards to judge potential for “culture add,” instead of going with their gut on the outdated idea of “culture fit.” Lauren’s candidate journey map also indicated we were screening out inexperienced candidates. This led me to challenge how were hiring for potential. Because we hire for specific, technical skills, we’d chosen to require specific competencies for many roles in order to move fast. But as we evolve, we decided to experiment with recruiting for potential. So we launched a small-scale mentorship program for associate UX practitioners where we provide education and on-the-job experience. We ran a slate of 30+ junior UXers and sought out those who had a strong vision for learning design and research, but didn’t necessarily have the experience or portfolio to land their first UX job. After an 18-month apprenticeship, we evaluate these employees for a specialist role in either design or research. With fewer restraints on competencies and sourcing candidates internally and externally, we’ll have more flexibility to control our funnel. Retention, Retention, Retention Recruiting and hiring more women, people of color, and other underrepresented groups doesn’t solve an organization’s diversity challenges. This is where belonging comes in. I believe belonging is the output of a diverse and inclusive culture. As the saying goes, if diversity is being invited to the party and inclusion is being asked to dance, I believe belonging is the feeling you get when you’re at the party dancing with everyone there. There’s evidence to back this up, too. A recent Catalyst study found that employees from minority groups are 40% more likely to want to leave a company if they feel on guard against potential biases while in the workplace. If these employees don’t feel free to express themselves in an authentic way, they’ll leave and you’ll be right back where you started. In order to understand where HubSpot could create an environment that promoted a sense of belonging, Loe Lee, a design lead, collaborated with stakeholders in the organization to run anonymous interviews with people who identified as either underrepresented or part of the majority at HubSpot. The issue of inclusion is personal and complicated—we saw this in the huge range of feedback. And because inclusion is so individualized, we realized that the belonging piece of the puzzle was much harder to solve, because it was so much bigger and more nebulous. There were a number of themes we pulled from this research, but one of the most interesting pieces of feedback was around unseen diversity. There are many visual traits, like race, gender, and age, that impact a person’s inclusion experience. But there are also many other less obvious areas—like cultural background, ability, socioeconomic status, neurodiversity (like autism or ADHD), veteran status—that also have a significant impact on the degree to which people feel they belong in the workplace. We realized that this was a crucial area we hadn’t paid much attention to, and that we needed to widen our fairly narrow definition of diversity, socialize the presence of more unseen forms of diversity, and work harder to recruit new talent that represents these diverse perspectives. This is still an area where we’re learning and growing as an organization, and we will continue to do so. The reason is simple. Diverse teams win, period. We’re building a platform for customers in 130 countries and localized in 6 core languages (in reality many more), in both developed and emerging markets. Striving to model the diversity of our customers in our own teams gives us the best possible chance of building a product that solves their needs. To start, we’ve intentionally sought candidates who speak other languages, have lived around the world or grew up outside of the U.S., have had careers outside the tech industry (like the military), and identify as LGBTQ or neurodiverse. While many of these details aren’t things that we can (or should) ask candidates to disclose, we’re working to create a safe space and opportunity to disclose these things during the interview process if they choose. For instance, we now have a representative from one of our employee resource groups in each interview loop, coaching interviewers about how to listen, meeting offsite in a casual environment (like coffee shop), ask what the candidate values in an inclusive environment. Through these three strategies—by looking at the quantitative data, and designing user research studies where our candidates and employees were the participants—we got a much clearer idea of where we could improve our diversity and inclusion efforts. By analyzing this problem like a design challenge, and taking a human-first approach, we avoided treating it like an issue a one-off initiative could fix. Instead, we are creating a culture in our organization where we look at our diversity and inclusion efforts as a long game where meaningful, sustained improvement will take lots of little iterations over time. Just like the way we build product. This post is based on a talk delivered at Grace Hopper Celebration 2019 .", "date": "2019-10-10"},
{"website": "Hubspot", "title": "An Intro to Git and GitHub for Beginners (Tutorial)", "author": ["HubSpot Product Team"], "link": "https://product.hubspot.com/blog/git-and-github-tutorial-for-beginners", "abstract": "New to git? Follow the steps below to get comfortable making changes to the code base, opening up a pull request (PR), and merging code into the primary branch. Any important git and GitHub terms are in bold with links to the official git reference materials. Step 0: Install git and create a GitHub account The first two things you'll want to do are install git and create a free GitHub account. Follow the instructions here to install git (if it's not already installed). Note that for this tutorial we will be using git on the command line only. While there are some great git GUIs (graphical user interfaces), I think it's easier to learn git using git-specific commands first and then to try out a git GUI once you're more comfortable with the command. A note: 95% of other online git resources and discussions will also be for the command-line interface. Once you've done that, create a GitHub account here . Git and GitHub A quick aside: git and GitHub are not the same thing. Git is an open-source, version control tool created in 2005 by developers working on the Linux operating system; GitHub is a company founded in 2008 that makes tools which integrate with git. You do not need GitHub to use git, but you cannot use GitHub without using git. There are many other alternatives to GitHub, such as GitLab, BitBucket, and “host-your-own” solutions such as gogs and gittea. All of these are referred to in git-speak as “remotes”, and all are completely optional. You do not need to use a remote to use git, but it will make sharing your code with others easier. Step 1: Create a local git repository When creating a new project on your local machine using git, you'll first create a new repository (or often, 'repo', for short). To use git we'll be using the terminal. If you don't have much experience with the terminal and basic commands, check out this tutorial (If you don’t want/ need a short history lesson, skip to step three.) To begin, open up a terminal and move to where you want to place the project on your local machine using the cd (change directory) command. For example, if you have a 'projects' folder on your desktop, you'd do something like: To initialize a git repository in the root of the folder, run the git init command: Step 2: Add a new file to the repo Go ahead and add a new file to the project, using any text editor you like or running a touch command. `touch newfile.txt` just creates and saves a blank file named newfile.txt. Once you've added or modified files in a folder containing a git repo, git will notice that  the file exists inside the repo. But, git won't track the file unless you explicitly tell it to. Git only saves/manages changes to files that it tracks , so we’ll need to send a command to confirm that yes, we want git to track our new file. After creating the new file, you can use the git status command to see which files git knows exist. What this basically says is, \"Hey, we noticed you created a new file called mnelson.txt, but unless you use the 'git add' command we aren't going to do anything with it.\" An interlude: The staging environment, the commit, and you One of the most confusing parts when you're first learning git is the concept of the staging environment and how it relates to a commit. A commit is a record of what changes you have made since the last time you made a commit. Essentially, you make changes to your repo (for example, adding a file or modifying one) and then tell git to put those changes into a commit. Commits make up the essence of your project and allow you to jump to the state of a project at any other commit. So, how do you tell git which files to put into a commit? This is where the staging environment or index come in. As seen in Step 2, when you make changes to your repo, git notices that a file has changed but won't do anything with it (like adding it in a commit). To add a file to a commit, you first need to add it to the staging environment. To do this, you can use the git add <filename> command (see Step 3 below). Once you've used the git add command to add all the files you want to the staging environment, you can then tell git to package them into a commit using the git commit command. Note: The staging environment, also called 'staging', is the new preferred term for this, but you can also see it referred to as the 'index'. Step 3: Add a file to the staging environment Add a file to the staging environment using the git add command. If you rerun the git status command, you'll see that git has added the file to the staging environment (notice the \"Changes to be committed\" line). To reiterate, the file has not yet been added to a commit, but it's about to be. Step 4: Create a commit It's time to create your first commit! Run the command git commit -m \"Your message about the commit\" The message at the end of the commit should be something related to what the commit contains - maybe it's a new feature, maybe it's a bug fix, maybe it's just fixing a typo. Don't put a message like \"asdfadsf\" or \"foobar\". That makes the other people who see your commit sad. Very, very, sad. Commits live forever in a repository (technically you can delete them if you really, really need to but it’s messy), so if you leave a clear explanation of your changes it can be extremely helpful for future programmers (perhaps future you!) who are trying to figure out why some change was made years later. Step 5: Create a new branch Now that you've made a new commit, let's try something a little more advanced. Say you want to make a new feature but are worried about making changes to the main project while developing the feature. This is where git branches come in. Branches allow you to move back and forth between 'states' of a project. Official git docs describe branches this way: ‘A branch in Git is simply a lightweight movable pointer to one of these commits.’ For instance, if you want to add a new page to your website you can create a new branch just for that page without affecting the main part of the project. Once you're done with the page, you can merge your changes from your branch into the primary branch. When you create a new branch, Git keeps track of which commit your branch 'branched' off of, so it knows the history behind all the files. Let's say you are on the primary branch and want to create a new branch to develop your web page. Here's what you'll do: Run git checkout -b <my branch name> . This command will automatically create a new branch and then 'check you out' on it, meaning git will move you to that branch, off of the primary branch. After running the above command, you can use the git branch command to confirm that your branch was created: The branch name with the asterisk next to it indicates which branch you're on at that given time. A note on branch names By default, every git repository’s first branch is named `master` (and is typically used as the primary branch in the project). As part of the tech industry’s general anti-racism work, some groups have begun to use alternate names for the default branch (we are using “primary” in this tutorial, for example). In other documentation and discussions, you may see “master”, or other terms, used to refer to the primary branch. Regardless of the name, just keep in mind that nearly every repository has a primary branch that can be thought of as the official version of the repository. If it’s a website, then the primary branch is the version that users see. If it’s an application, then the primary branch is the version that users download. This isn’t technically necessary (git doesn’t treat any branches differently from other branches), but it’s how git is traditionally used in a project. If you are curious about the decision to use different default branch names, GitHub has an explanation of their change here: https://github.com/github/renaming Now, if you switch back to the primary branch and make some more commits, your new branch won't see any of those changes until you merge those changes onto your new branch. Step 6: Create a new repository on GitHub If you only want to keep track of your code locally, you don't need to use GitHub. But if you want to work with a team, you can use GitHub to collaboratively modify the project's code. To create a new repo on GitHub, log in and go to the GitHub home page. You can find the “New repository” option under the “+” sign next to your profile picture, in the top right corner of the navbar : After clicking the button, GitHub will ask you to name your repo and provide a brief description: When you're done filling out the information, press the 'Create repository' button to make your new repo. GitHub will ask if you want to create a new repo from scratch or if you want to add a repo you have created locally. In this case, since we've already created a new repo locally, we want to push that onto GitHub so follow the '....or push an existing repository from the command line' section: (You'll want to change the URL in the first command line to what GitHub lists in this section since your GitHub username and repo name are different.) Step 7: Push a branch to GitHub Now we'll push the commit in your branch to your new GitHub repo. This allows other people to see the changes you've made. If they're approved by the repository's owner, the changes can then be merged into the primary branch. To push changes onto a new branch on GitHub, you'll want to run git push origin yourbranchname. GitHub will automatically create the branch for you on the remote repository: You might be wondering what that \"origin\" word means in the command above. What happens is that when you clone a remote repository to your local machine, git creates an alias for you. In nearly all cases this alias is called \" origin .\" It's essentially shorthand for the remote repository's URL. So, to push your changes to the remote repository, you could've used either the command: git push git@github.com:git/git.git yourbranchname or git push origin yourbranchname (If this is your first time using GitHub locally, it might prompt you to log in with your GitHub username and password.) If you refresh the GitHub page, you'll see note saying a branch with your name has just been pushed into the repository. You can also click the 'branches' link to see your branch listed there. Now click the green button in the screenshot above. We're going to make a pull request ! Step 8: Create a pull request (PR) A pull request (or PR) is a way to alert a repo's owners that you want to make some changes to their code. It allows them to review the code and make sure it looks good before putting your changes on the primary branch. This is what the PR page looks like before you've submitted it: And this is what it looks like once you've submitted the PR request: You might see a big green button at the bottom that says 'Merge pull request'. Clicking this means you'll merge your changes into the primary branch.. Sometimes you'll be a co-owner or the sole owner of a repo, in which case you may not need to create a PR to merge your changes. However, it's still a good idea to make one so you can keep a more complete history of your updates and to make sure you always create a new branch when making changes. Step 9: Merge a PR Go ahead and click the green 'Merge pull request' button. This will merge your changes into the primary branch. When you're done, I recommend deleting your branch (too many branches can become messy), so hit that grey 'Delete branch' button as well. You can double check that your commits were merged by clicking on the 'Commits' link on the first page of your new repo. This will show you a list of all the commits in that branch. You can see the one I just merged right up top (Merge pull request #1). You can also see the hash code of the commit on the right hand side. A hash code is a unique identifier for that specific commit. It's useful for referring to specific commits and when undoing changes (use the git revert <hash code number> command to backtrack). Step 10: Get changes on GitHub back to your computer Right now, the repo on GitHub looks a little different than what you have on your local machine. For example, the commit you made in your branch and merged into the primary branch doesn't exist in the primary branch on your local machine. In order to get the most recent changes that you or others have merged on GitHub, use the git pull origin master command (when working on the primary branch). In most cases, this can be shortened to “git pull”. This shows you all the files that have changed and how they've changed. Now we can use the git log command again to see all new commits. (You may need to switch branches back to the primary branch. You can do that using the git checkout master command.) Step 11: Bask in your git glory You've successfully made a PR and merged your code to the primary branch. Congratulations! If you'd like to dive deeper, check out these more advanced tutorials and resources: https://training.github.com/ Github’s official git cheat sheets! Handy for remembering the everyday commands you’ll use. https://learngitbranching.js.org/ Confused or intrigued by git’s branch system? That just means you’re human! It’s one of the deepest parts of git, but also arguably the most powerful. Understanding the branch model gives you git superpowers, and this tutorial gives you a way to learn git branches in a visual, intuitive way. https://git-school.github.io/visualizing-git Another tool for exploring git visually. This one is more of an open-ended sandbox than learngitbranching.js.org https://github.com/jlord/git-it-electron A desktop application that helps you learn git through challenges you have to solve. It has a series of levels, each requiring you to use git commands to arrive at a correct answer. https://github.com/Gazler/githug If you liked git-it, Githug is another puzzle-based tutorial designed to give you a practical way of learning git. I also recommend finding some time to work with your team on simulating a smaller group project like we did here. Have your team make a new folder with your team name, and add some files with text to it. Then, try pushing those changes to this remote repo. That way, your team can start making changes to files they didn't originally create and practice using the PR feature. And, use the git blame and git history tools on GitHub to get familiar with tracking which changes have been made in a file and who made those changes. The more you use git, the more comfortable you'll... git with it. (I couldn't resist.) *This post was originally published in October 2015 by Meghan Nelson, then a senior software engineer at HubSpot. It has since been updated by the HubSpot Product Team. Interested in working for a product team that values autonomy and transparency? Check out our open positions and apply .", "date": "2020-12-03"},
{"website": "Hubspot", "title": "On Bad Hacker News Titles", "author": ["Zack Bloom"], "link": "https://product.hubspot.com/blog/on-bad-hacker-new-titles", "abstract": "Yesterday we posted one of our open source projects to HN, and ended up on the front page for most of the day .  The biggest complaint in the comments was that we had chosen a bad title for our posting.  Yet the post was very successful, it lead to 10k+ views, and 700 stars of the project on GitHub.  So would we have done even better with a better title, or was the bad title part of the secret of our success? An old advertising formula tells that customer's satisfaction is the quotient of what they actually got and what they expected to get.  In other words, if you want to increase satisfaction (in this case upvotes), you need to improve the actual content, or lower expectations .  This, of course, assumes that your title is good enough that people will click through and it won't get editted by the mods. We haven't found a way to test this theory yet, but if you do, let us know!", "date": "2013-02-27"},
{"website": "Hubspot", "title": "Technorati, why are you so slow?", "author": ["Yoav Shapira"], "link": "https://product.hubspot.com/blog/bid/6273/technorati-why-are-you-so-slow", "abstract": "Over the past few days I made two requests to Technorati , one that I imagine is very common and the other maybe a little less common. The first, very common, request, was to claim a blog. The new HubSpot dev team blog , in this case. There is a simple form and workflow for this on Technorati.com, and I imagine many hundreds of people do this every day. Maybe more. They give you a random string of text, and you have to put it on the front page of your blog. Done in 20 seconds. Then you click a button that says \"I've done it,\" and they supposedly verify that you have. They say it will take up to an hour. It's taken two days so far, and without any response or update. I don't see why it should take more than a few seconds: the time to scrape the web site, search for the unique string text they gave me, and update their database. Voila, it's done. The second request I made was to use their API . We haven't used it until now, but it looks promising, and we'd like to experiment. So I promply sent a nice email to the address specified on their API page. No response, not acknowledgment, nothing so far. You'd think they'd jump at the chance to make some money. Technorati, can you please move it? ;)  Your web serving is nice and fast, but everything else is annoyingly slow.", "date": "2009-06-28"},
{"website": "Hubspot", "title": "My Unconventional Path to Becoming a Software Developer", "author": ["Cian Mac Mahon (He/Him)"], "link": "https://product.hubspot.com/blog/unconventional-path-to-becoming-a-software-developer", "abstract": "Lots of people want to become developers who, like me, didn't go to school for computer science. The good news is: It can be done. Some of the most talented engineers and familiar entrepreneurs behind successful tech companies taught themselves to code. But, that doesn't mean it's easy. I was working on the support team at HubSpot when I started learning how to build software in hopes of becoming an engineer and I quickly realized you can't just dabble in programming. You have to go all in. If you're passionate about building product and solving problems, then the long nights and early mornings are well worth it. But teaching yourself the skills is only half the battle. Becoming a professional engineer at a product company without a traditional CS background (alongside some of the best and brightest developers there are) comes with a pretty big professional and personal learning curve. Looking back at my journey, these are some of the biggest lessons I took away from making the career move. Mentors Make All the Difference As long as you have time and an internet connection, getting your skills and knowledge to a solid base level is something you can do on your own. But to take those skills to the next level, you need a mentor who recognizes your potential and gives you the opportunity to show it. Irregular chats with my mentor, Steve ( a tech lead on our Leadin team ), are what convinced me that I truly had a shot at being a professional engineer. He was honest but hopeful; it was going to be a very tough process with a nearly insurmountable learning curve without any real educational supports. But Steve assured me that if I showed aptitude and an appetite to learn, it might actually work. A good mentor quickly realises what it is you need to learn and helps you find the best resources to grow. Bottom line: You should get one. Unglamorous Work Works No matter what you want to do, plan to get there in steps, rather than in one giant leap. Find what skills will make you most attractive to your dream employer and take on projects that will help you develop them. Build tools to make your life easier, websites for local shops and your friend’s businesses, and do as much freelance work as you can. No matter what the pay is. As you build your portfolio you build your skillset, and that's priceless. Experience Can Surprise You If you have an interest in building product, chances are many of your pre-existing skills will transfer to development. For example, if you work in a customer support role like I did, your fast-paced problem solving skills will help you debug code. Similarly, if you’re a designer you’ll have an innate understanding of how customers will interact with any product you work on. Every time you face a problem, take a step back and ask yourself if you have any (seemingly) unrelated experience that can help you work through it. Imposter Syndrome is Real … For Everyone There isn’t really any way to solve the problem of imposter syndrome . Since you came from a non-traditional CS background, you’re going to run into concepts and terms you’ve never heard, but that everybody around you understands. This will happen daily, if not hourly. This doesn’t make you a bad programmer; it just means you didn’t have the benefit of a four year program. You shouldn’t let this make you feel like an imposter, and you’ll find that most of your colleagues would jump at the chance to explain things to you. For me, joining the HubSpot engineering team had always felt a like a pipe dream. The people that I saw were at the top of their game. They had years of experience and graduated top of their classes at the top universities. They wrote best-selling books, gave packed talks at tech conferences and meet-ups, and had oppressively high StackOverflow scores. Working with some of the best developers out there is intimidating. But take a step back and you’ll see that no one knows everything there is to know about programming. Your smartest coworkers still need to ask for help. You’re not the only one who has a lot to learn. Sleep Will Be a Luxury If you decide you want to make a career change and become a software engineer, you need to have passion. You can't half-ass it. You will work hard, you won't sleep, and you'll miss out on weekends and parties because you were learning. That's why you have to be sure you're passionate about what's on the other side and if that's going to be worth it to you. I'm happy to say I went all in and haven't looked back since.", "date": "2016-05-26"},
{"website": "Hubspot", "title": "Client-side Performance Monitoring", "author": ["Zack Bloom"], "link": "https://product.hubspot.com/blog/client-side-performance-monitoring", "abstract": "Studies at Google and Amazon have shown that even 100ms of extra load time can have a dramatic effect on your conversion rate.  So how fast is your site? You can measure it on your computer using Chrome DevTools or YSlow, but how fast is it on your user's actual computer or mobile device?  It's not hard to find out. Manifesto Now that the APIs are available , there is no reason to not be monitoring web app performance from the client. The data you get reflects the experiences of your actual users, not some artifical testing environment, and it doesn't require a complex virtualization environment.  In just a couple lines of code you will have powerful analytics you can use to optimize your site and to ensure your performance doesn't regress. If you have a tool for monitoring client-side performance not listed here, please let us know . Services and Tools Google Analytics Google Analytics provides an API which can be used to manually track how long a javascript task takes. For example, to track how long it took for an ajax request to complete: var startTime = new Date; $.ajax({\n  url: 'some/url',\n  success: function(){\n    var elapsedTime = new Date - startTime;\n\n    _gaq.push(['_trackTiming', 'some/url Load Time', elapsedTime]);\n  }\n}); Tracking all of the requests your page makes is possible by wrapping the XMLHttpRequest object.  It's also a good idea to use performance.now() , rather than new Date , when possible, and you'll need a way of turning urls into meaningful keys.  Take a look at a tool like Bucky for a proven example. Caliper.io If you use Backbone.js or Ember, there is a paid service called Caliper.io which can automatically measure the performance of parts of your app. Caliper works by hooking into the routes your user navigates to and the events you bind onto views.  Whenever an event or route is triggered, it sends the time to the Caliper servers. New Relic New Relic is a paid service which can do general monitoring of your servers. Part of their offering is what they call ' Real User Monitoring ' which measures client-side performance.  Real User Monitoring is enabled by inserting a javascript file (or instructing New Relic to insert it for you).  Take a look at their FAQ for more detailed instructions. Bucky We at HubSpot built a tool to push performance data from the client into Statsd or OpenTSDB.  If you are using one of those tools to monitor your server-side performance, it might be a good idea to add Bucky to monitor your client-side performance. Drop one script tag in, and it will send data on every page load and AJAX request to your monitoring tool.  You can also manually monitor any javascript using Bucky. Bucky is the only open-source and self-hosted service on the list, so far.", "date": "2013-10-10"},
{"website": "Hubspot", "title": "The Possibilities of “And” — Prioritizing Usability Alongside Feature Growth", "author": ["Libby Maurer (She/Her)"], "link": "https://product.hubspot.com/blog/usability-alongside-feature-growth", "abstract": "Many of us can identify with using business software that has a robust feature set but is painful to use. Or perhaps it’s easy to set up and configure with the help of a support team but becomes a guessing game when you’re actually trying to get the job done. Either way, setting up a business’ tech stack can seem like a no-win game of “or” where you have to choose either power or usability, but rarely both. At HubSpot we believe in the possibility of “and,” with ease of use equally weighted with a powerful set of features. We value transparency at HubSpot so here’s some real talk: Saying this is easy, doing it is difficult. As the VP of our UX team I’ve led us through releasing several new product lines and a rapidly diversifying user base, and I can tell you there’s a reason most business software falls short in usability… it’s really hard . Especially with a one-size-fits-all platform like HubSpot that serves a range of industries and users. We insist on a high bar for usability because it’s the right thing for our customers. How we drive usability We pull a combination of levers to put usability into focus as our platform increases in complexity. These levers are intentionally diverse; some are cultural, some process oriented, some foster shared values, others are supporting systems. We drive usability in five ways: Agree usability is a core value & commit to a shared definition Understand the difference between usability & utility Nurture a customer-obsessed culture Operationalize, resource, and measure usability Leverage a common design language Each of them contributes to reaching the level of usability our customers value (and expect!) from HubSpot. Here’s a deep dive into these five main drivers. 1. We agree usability is a core value & commit to a shared definition. Last year our Product Leadership team committed to a hierarchy of needs , known as our “Mainsail,” that has become our operating system. Usability has its own layer, and together with security, reliability, and performance they comprise the fundamentals of the Mainsail . This is powerful because it created a shared commitment among engineering, product, and UX leadership that we value usability, and together we will support investment in it. Adding usability to our Mainsail was one step; next we put a lot of thought into what we mean when we say “usability” to give us a frame for how we should think about usability. We researched many definitions and looked at a lot of customer data to come up with this definition to frame usability at HubSpot: Usability is the measure of discoverability, learnability, efficiency, and accessibility in using the HubSpot platform to accomplish a user's goals. The four attributes we’ve chosen — discoverability, learnability, efficiency, accessibility — are core themes we consistently hear in customer feedback. Some users value one more than another (we know efficiency is top of mind for sales reps while marketers value learnability) but in general they’re universally important across our entire customer base. These attributes illuminate opportunities for moments of delight in our design. And tactically, the usability definition also serves as the basis for how we measure and categorize usability issues (discussed below). We future-proofed the definition too — it’s intentionally flexible, which allows us to calibrate as the platform evolves. We consider it inclusive of all populations, like developers using our APIs, people using our free products, customers who operate across country borders in many languages, and those working with physical or cognitive impairments. 2. We understand the difference between usability & utility. One of the keys to keeping our usability value pure across more than 80 front end teams is differentiating utility and usability. A utility improvement is functionality that adds net new value to our tools; a usability improvement improves an existing workflow or completes functionality that a user expects. But why would we draw this line? We’ve found it’s common for product teams to be compelled or incentivized to build new features instead of fixing or iterating on existing functionality. So drawing a line between usability and utility is a helpful guardrail teams can use to prioritize their roadmaps, and gives them the agency to figure out how to incorporate both . As you can imagine, that line is often more gray than black and white, and that’s expected. The goal is not to perfectly separate utility and usability 100% of the time; instead over time we want teams to build the discipline to debate it among themselves. Whenever I hear the utility/usability debate it’s a signal we’re keeping usability — and our customers — at the forefront of our priorities. 3. We nurture a customer-obsessed culture. When I think about why we value ease of use, it’s clear our focus on usability is rooted in a culture of putting customers at the center of our world. Several main customer feedback arteries pump real-time customer feedback to every single employee. By freeing this data, we reinforce a culture where the customer voice is omnipresent. For employees who aren’t customer-facing in their primary job function, we encourage partnerships with our support and services teams who summarize customer feedback trends. Keeping these channels accessible and well-groomed serves an important purpose; it’s how we’ve learned that ease of use is very important to our customers. And these channels keep us aligned on top themes, like usability, that are supremely important to them. It’s a theme we’ve studied and dissected carefully, especially as our user base evolves. We’re close enough to the feedback that we can see small and large shifts in customers’ expectations about usability, which helps us address them with the right teams quickly. 4. We operationalize, resource & measure usability efforts. The decision to establish a shared definition of usability and free customer feedback needs to be supported by an action plan to be effective. So we’ve taken measures to operationalize usability and help teams hold themselves accountable for keeping a pulse on how they’re doing. Accountability is very important at HubSpot because it’s how we honor one of our most beloved values: autonomy. We don’t want teams to ask for permission to shift their focus to usability. We empower them to make the call on their own. We log usability issues just like we log bugs in the software, and these issues can be created by anyone in the company. Everyone from the support team to our CEO weighs in! Each issue is assigned to the team that is primarily responsible for it and they categorize and estimate the severity of the issue. Based on that calculation if a team reaches a certain threshold of usability issues, it’s a sign they should shift from new feature development to improving usability. We provide monthly reporting on the volume of usability issues per team, and that too is available for anyone in the company to view. Incorporating feedback from customer channels and inviting broad participation is so powerful; there is remarkable transparency in our operating system. It also shows a truth we have embraced — usability is always a work in progress. And that creates an inherent incentive to strive for power and ease of use. Along with logging usability debt and assessing impact, we’ve developed a number of ways to measure ease of use. I talk to many design leaders who find this daunting, and I’ve been there too. But we’ve leaned into a trick that greatly simplifies it. It comes down to measuring what matters to our customers . We asked users to tell us the most important tasks they do in HubSpot, and then we benchmarked the usability of those tasks. The results of this benchmarking study directed us to a few areas where we were confident we’d be improving the experience for a large cohort of users. When we measured the most traveled paths in our platform it gave us tremendous clarity and helped frame usability issues from the customer point of view instead of guessing where our usability potholes exist. We’re also mindful of the “build to close deals” product development strategy where usability debt can sneakily accrue over time. It seems like many enterprise software solutions take a wrong turn when they get in the habit of building features to close deals. The trouble is, when you exclusively design for decision makers you risk neglecting the people actually using the tool. We know HubSpot customers represent small and large teams. In many cases the people deciding to buy HubSpot are users. But that’s not always the case; this year, for example, we are building more features for our enterprise customers. For them the distance between users and the people choosing the software is great. So we’re extra vigilant about maintaining a high bar for usability and guarding against this bias by involving real users in our discovery research. We invite them to participate in looking at early concepts to give feedback and in the process we inevitably uncover new ways to add value. Our approach and investment in discovery yields a continuous feedback cycle that keeps us hyperconnected to users. This seems like user research 101, and it is. But it’s remarkable how quickly we sacrifice the basics when revenue is on the line. 5. We leverage a common design language. In 2015 a subset of our design team (back when the team could fit around one table!) started talking about how to achieve consistency at scale. First they established a design language for the product that was consistent with HubSpot’s brand. Soon after, HubSpot’s first design system , Canvas, was born. The team also developed a process for every designer on the team to contribute to it, run by a rotating centralized volunteer team. Since then Canvas has undergone a number of iterations and the way we operationalize it has transformed too. This year we’re forming a small, dedicated design infrastructure team to fully own the operations and process necessary to shape shift Canvas as the user base and our team evolves. Design systems are known to help distributed design teams achieve consistency — a very real and practical reason to use them. But we understand that the consistency Canvas affords us is really in service of our macro usability goals. We believe consistency is one driver of usability, so the investment in keeping Canvas a living, breathing system is an investment in achieving the power/ease of use value HubSpot is known for. Breaking the Tyranny of Or What does it really take to go to market with a robustly featured product that honors ease of use, too? For us it’s a combination of culture, a shared definition of usability, a sustainable operating system, deploying the right measurements, and a common design language. When we align on these levers across our whole organization the possibilities — for us, for our users, for our product — are endless. If you’re jazzed about working on a team that’s making business software easy and powerful, we’d love to hear from you. We’re hiring for product designers, content designers, and researchers; check out our careers page at https://www.hubspot.com/careers/product-engineering . This post originally appeared on Medium .", "date": "2020-01-21"},
{"website": "Hubspot", "title": "HubSpot Partner Spotlight: Kevin Dean, CEO, ManoByte", "author": ["Francesca McCaffrey (She/Her)"], "link": "https://product.hubspot.com/blog/hubspot-partner-spotlight-kevin-dean-ceo-manobyte", "abstract": "Some of the best perspectives on HubSpot's product come from those who use it every day. In this interview series, we profile HubSpot partners, providers, and customers, and ask their thoughts on what our product team should keep in mind while solving for them, and where the future of the industry lies. In this installment, we chat with Kevin Dean, CEO of sales and marketing automation company ManoByte . How did you first come to work with HubSpot's products? I was searching for a solution for stabilizing our company's revenue. What's the biggest challenge your team is facing right now? Scaling profitability. What advice do you have for anyone working toward being a CEO one day? Understand people, their strengths, their weakness, and how to inspire them. You've worked in eCommerce, sales, marketing, consulting⁠ — how do you stay close to your customers? Regular calls to understand their challenges. In your opinion, what's the most important thing for HubSpot's product team to keep in mind when solving for customers? Flexibility, ease, and stability. At HubSpot, we put an emphasis on crafting a product that is both simple and powerful. Can you tell us about what that means for you in your day-to-day work? We leverage the technology without dedicating too much time to doing so while solving business problems. What do you think is the future of B2B software? More consolidated features, making it harder to differentiate. Interested in working with a product team that solves for marketers, salespeople, and developers alike? Check out our open positions and apply .", "date": "2021-04-29"},
{"website": "Hubspot", "title": "HubSpot Interns Take On the HackerRank Intern Cup", "author": ["Diane Yang"], "link": "https://product.hubspot.com/blog/hubspot-takes-on-the-hackerrank-intern-cup", "abstract": "As a summer intern, my primary goal is to learn as much as I can during my tenure here. So, when I heard that Hubspot was planning to enter the HackerRank Summer Intern Coding Cup , I couldn't wait to find out more. HackerRank , the programming competition site built by the team at Interviewstreet , hosts real-time coding contests throughout the year. This particular one was heralded as a three-hour machine learning challenge just for teams of summer interns. It sounded cool, but as I skimmed the contest details, self-doubt swirled through my mind. I had little prior knowledge about machine learning, I had never used HackerRank, and I had never coded in a competition setting. In short, I was terrified. That's when I made up my mind to sign up. I long ago discovered that the fastest way to learn is to do things that scare you, and the Intern Cup was no exception. It definitely helped that HubSpot gave us a lot of support. In the weeks leading up to the contest, we prepared by undergoing a boot camp led by one of the full-time employees. We studied common machine learning techniques and worked through some of the problems on HackerRank. So when the competition finally dawned, we felt prepared. The team consisted of me , Ze'ev Klapow , Julian Salazar , and Tianyu Liu . We assembled in one of the company conference rooms, ready to hash out some code. For most of us, this was our first immersion into such time-crunched competition coding. And as we would soon find out, it requires a very unique mindset. Although we had studied a lot beforehand, there are some things that only experience can teach you. For example, we had to drop some cool ideas in the interest of creating a finished product. And let me tell you, it wasn't easy to let go. As hackers, we delight in finding the smartest, most effective solutions, but that day we were limited to a three-hour deadline. That said, we ended up doing better than we ever expected. We placed a very respectable 15th out of 68 teams, landing us squarely in the top quartile of submissions. Not bad for a bunch of rookies! I'm not exaggerating when I say that participating in the Intern Cup is one of the best decisions I've made all summer. Time and time again, my experiences keep reinforcing the idea that you should take on challenges that intimidate you. If you don't try, those things will always seem scary. But if you do, your hard work will often be rewarded.", "date": "2013-07-23"},
{"website": "Hubspot", "title": "JavaScript Modules at HubSpot", "author": ["Trevor Burnham"], "link": "https://product.hubspot.com/blog/javascript-modules", "abstract": "Trevor is the author of Async JavaScript, now available from PragProg . We deal with a huge amount of JavaScript in the HubSpot front-end: over 1,000 files split across dozens of projects. In this article, I'll talk about how we're organizing this code into modules now, the pros and cons of that approach, and how we're starting the transition to a radically different approach. The Present: Static Builds Each top-level directory of app.hubspot.com (like \"/content\" and \"/contacts\") has its own JavaScript bundle. These bundles are built with an internal tool called Static3. Static3 takes our raw JavaScript, CoffeeScript, and Handlebars files, then compiles, concatenates, and minifies them into bundles using Sprockets. We upload the bundles to a CDN for fast delivery. Each bundle gets a unique version number and is served with far-future HTTP headers, so browsers will cache the bundle until there's a newer build. The concatenation means that our customers get reasonably fast script load times, since there's only one HTTP request involved, and very fast load times when moving around between builds. On the other hand, we do about 20 builds a day, and those JavaScript bundles are big enough to add noticeable lag. (The bundle for \"/contacts,\" for example, weighs in at about a megabyte. Minified.) A bigger problem with the static bundle approach is that it's made sharing front-end code across projects difficult. Static3 lets us bring in JavaScript modules from other projects, but modules written for a particular project typically rely on libraries, templates, and cached data that live in that project—and those dependencies aren't listed explicitly within the module. Instead we have a single project-wide namespace, and we do something like this: /* contactModel.js */\nhubspot.contacts.Contact = Backbone.Model.extend({\n  // ...\n});\n\n/* contactView.js */\nhubspot.contacts.ContactView = Backbone.View.extend({\n  model: hubspot.contacts.Contact\n  // ...\n});\n\n/* contacts.js */\n//= require backbone.js\n//= require contactModel.js\n//= require contactView.js\n// ... Now if we want to display a ContactView in another project, we need to bring in Backbone.js, the Contact model, and ContactView, in that exact order. That means a lot of duplication and, worse, makes it easy for the Contacts team to break the dependent project by adding new requirements on their end. We can ameliorate this by using Sprockets to list dependencies directly in modules, like so: /* contactModel.js */\n//= require backbone.js\nhubspot.contacts.Contact = Backbone.Model.extend({\n  // ...\n});\n\n/* contactView.js */\n//= require backbone.js\n//= require contactModel.js\nhubspot.contacts.ContactView = Backbone.View.extend({\n  model: hubspot.contacts.Contact\n  // ...\n});\n\n/* contacts.js */\n//= require contactView.js\n// ... But that's only a partial solution. For one thing, there's no enforcement: A coder can easily forget a dependency that the project already brought in, and they won’t notice until other projects break. Plus, Sprockets only works for purely static dependencies. What about, say, data that needs to be fetched from the server before a ContactView can be rendered? That’s why we’ve started to move toward a pattern that’s been sweeping the JavaScript world: Asynchronous Module Definition (AMD) . The Future: AMD Modules AMD is a simple but powerful idea: Each JavaScript file has a “define” function that names the module, lists its dependencies, and a callback that runs when all of those dependencies (and their dependencies in turn) are loaded. The most popular AMD implementation is the async loader library RequireJS . Using AMD discourages you from using a global namespace. Instead, you take what you need as callback arguments at the top of the module, and return the module’s export from the callback (called the “factory”). Here’s how we’d rewrite our last example: /* contactModel.js */\ndefine('contactModel', ['backbone'], function (Backbone) {\n  var Contact = Backbone.Model.extend({\n    // ...\n  });\n  return Contact;\n});\n\n/* contactView.js */\ndefine('contactView', ['backbone', 'contactModel'], function (Backbone, contactModel) {\n  var ContactView = Backbone.View.extend({\n    model: contactModel\n    // ...\n  });\n  return ContactView;\n});\n\n/* contacts.js */\ndefine('contacts', ['contactView'], function (Backbone) {\n  // ...\n}); This is more verbose than the Sprockets approach. Also, AMD definitions for some libraries (like Backbone) have to be patched in manually. But those are small prices to pay for increased reusability and maintainability. AMD is a terrific long-term solution to our JavaScript organization problem. There are a couple of hurdles we’ll have to get over before we can go full-on AMD, though. First, how do we concatenate modules without Sprockets? We don’t want to put the burden of loading all of our JavaScript on RequireJS, because that could mean hundreds of Ajax requests just to render the page. We need to combine those scripts before serving them to the user. RequireJS has an optimizer that can do just that, but that’s only going to work after we’ve converted all of the modules in a project to AMD. And relatedly, how can we have AMD-style modules that depend on modules defined in the old style? The Transition: hubspot.define & hubspot.require A month ago, our own Brad Osgood solved this problem by writing simple define/require functions that create, and look for, both global namespace definitions and AMD-style definitions. So we can replace hubspot.contacts.ContactView = Backbone.View.extend({\n  model: hubspot.contacts.contactModel\n  // ...\n}); with hubspot.define('hubspot.contacts.ContactView', ['backbone', 'hubspot.contacts.ContactModel'], function (Backbone, ContactModel) {\n  return Backbone.View.extend({\n    model: ContactModel\n    // ...\n  });\n}); without having to make any other changes. That hubspot.define definition looks for an object called hubspot.contacts.ContactModel and creates an object called hubspot.contacts.ContactView. We’re still using Sprockets for concatenation. So for now, this is mostly window dressing. (We do get some small benefit from only executing modules when they’re needed.) But once every module in a project uses hubspot.define, we’ll be able to drop Sprockets and enjoy all the flexibility that AMD has to offer.", "date": "2012-12-18"},
{"website": "Hubspot", "title": "CoffeeScript Tricks", "author": ["Zack Bloom"], "link": "https://product.hubspot.com/blog/coffeescript-tricks", "abstract": "At HubSpot, I'm fortunate to work with some CoffeeScript experts .  I've picked up a few tricks, most of which aren't mentioned in the docs . Try Without Catch One of my first confusions with CoffeeScript was why it always required you to assign the 'catched' error to something, you couldn't have a catch and just drop the error object on the floor. Turns out you can do one better: try\n  thisMightThrowAnError()\n\nbutThisDoesntCare() try {\n  thisMightThrowAnError();\n} catch (_error) {}\n\nbutThisDoesntCare(); Destructuring Arguments It's common in CoffeeScript, as in Javascript, to pass objects as options to methods. This get's even easier when you use destructing assignment. This is a great way to get the clean binding of positional arguments while maintaining the flexibility of an object. myMethod = ({size, weight}) ->\n  @cost = size * weight myMethod = function(_arg) {\n  var size, weight;\n  size = _arg.size, weight = _arg.weight;\n  return this.cost = size * weight;\n}; You can couple that with the 'this' shorthand: class Ball\n  constructor: ({@size}) -> Ball = (function() {\n  function Ball(_arg) {\n    this.size = _arg.size;\n  }\n  return Ball;\n})(); It gets even better when you use the object shorthand notation: size = 55\nnew Ball {size} size = 55;\nnew Ball({\n  size: size\n}); The shorthand style is particularly nice when it comes time for you to define module.exports : module.exports = {start, stop} module.exports = {\n  start: start,\n  stop: stop\n}; You can even use the shorthand with object properties: return {@id} return {id: this.id} Static Methods In Javascript, functions are objects, and classes are just functions, meaning you can attach static methods to your classes: class MyModel\n\nMyModel.get = _.memoize ->\n  new MyModel It turns out that CoffeeScript has a syntax for just this situation: class MyModel\n  @get: _.memoize ->\n    new MyModel MyModel = (function() {\n  function MyModel() {}\n  MyModel.get = _.memoize(function() {\n    return new MyModel;\n  });\n  return MyModel;\n})(); Anonymous Functions One of the classic bugs folks encounter in Javascript is forgetting that only functions have scope, so anything assigned in a for loop, for example, may have changed when it comes time for callbacks to fire. The do keyword can be used to call a function immediately, passing it it's arguments from the outer scope. for dog in dogs\n  do (dog) ->\n    setTimeout ->\n      console.log \"Dog:\", dog _fn = function(dog) {\n  return setTimeout(function() {\n    return console.log(\"Dog:\", dog);\n  });\n};\nfor (_i = 0, _len = dogs.length; _i < _len; _i++) {\n  dog = dogs[_i];\n  _fn(dog);\n} You can use the default argument value to create variables which will only live in the inner scope. do (x=3) -> letsRock(x) (function(x) {\n  return letsRock(x);\n})(3); You can also use this trick to call functions as you create them: do check = ->\n  if waitingOn is 0\n   done()\n\nsetTimeout check, 50 (check = function() {\n  if (waitingOn === 0) {\n    return done();\n  }\n})();\nsetTimeout(check, 50); Reverse Iteration Since CoffeeScript 1.5.0 it's been possible to iterate through a list in reverse: for car in cars by -1\n  start(car) for (_i = cars.length - 1; _i >= 0; _i += -1) {\n  car = cars[_i];\n  start(car);\n} Splats Most CoffeeScript developers know about splats, but not all know that they can appear anywhere in the argument sequence. (name, children..., cb) -> var __slice = [].slice;\n(function() {\n  var cb, children, name, _i;\n  name = arguments[0], children = 3 <= arguments.length ? __slice.call(arguments, 1, _i = arguments.length - 1) : (_i = 1, []), cb = arguments[_i++];\n}); For one of our favorite CoffeeScript tricks, take a look at Mixen .", "date": "2013-11-25"},
{"website": "Hubspot", "title": "Zack Bloom is a HubSpotter", "author": ["Elizabeth Dunn (She/Her)"], "link": "https://product.hubspot.com/blog/bid/84852/zack-bloom-is-a-hubspotter", "abstract": "Name: Zach Bloom Role: Developer at HubSpot Superpower: Beginner's Luck Zack Bloom has joined the HubSpot Product Team, and man are we glad he did. We were starving for some good barbeque. When he's not slaving over a hot, sauce-slathered firepit, Zack's busy working on the HubSpot Contacts UI. He's also doing some pretty slick work on extending the usefulness of dynamic lists, which we think is pretty swell of him, too. The delightful Mr. Bloom comes to HubSpot by way of West Bloomfield, Michigan, where he was born and raised to be the fine, upstanding gent he is today. He was, as far as we can tell, uncommonly diligent in his studies at Lawrence Technological University, which doesn't sound nearly as impressive until you remember that that's where the guy who designed the DeLorean also went to school. So that's awesome. When he's not wonking away at a keyboard with his HubSpot buddies, he's pursuing his love of charcuterie and the aforementioned barbeque, which we'll admit makes him pretty damn popular among the carnivorous crowd. He also plays the drums, when drumming is what's called for. Follow Zack on Twitter , check out his pics on smugmug , or go bug him to post more cool stuff on his blog . Welcome to HubSpot, Zack!", "date": "2012-04-05"}
]