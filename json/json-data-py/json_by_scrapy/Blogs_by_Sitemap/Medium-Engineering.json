[
{"website": "Medium-Engineering", "title": "engineering onboarding processes at medium", "author": ["Laura Godinez"], "link": "https://medium.engineering/engineering-onboarding-processes-at-medium-368095116ac3", "abstract": "Sign in Laura Godinez Oct 20, 2020 ¬∑ 5 min read A couple months into Medium working fully remote, I started thinking about our engineering onboarding processes and looking for any holes that we needed to fill, especially now that we were all off-site. There were some things that, as an organization, we were adjusting to‚Äîpairing through Zoom, for instance, or using online tools like Miro for retros‚Äîand onboarding seemed like it could use some attention. With the help of Shruthi Adappa , I got to work on what needed to be changed or improved and what else we needed to include. Efficient o nboarding is key. As stated in this Deputy blog post , onboarding helps with employee retention rates, clarifies and sets expectations for the new hire‚Äôs role, and lowers employee stress. Having things in place like onboarding classes and customized new-hire checklists shows new hires that you care about them and want them to have the resources they need to succeed. These resources also enable new hires to master their roles at a faster rate. While we had some valuable processes in place, we found the following things through research that gave us ideas of what we could improve. Presenting information in different formats increases a person‚Äôs chances of retaining this new information. Say, for example, your company has an onboarding class on your front-end stack; it may be helpful to have written documentation for what‚Äôs covered in that class so the new hire can reference it in the future. High-quality onboarding handbooks give new hires a view of what they can expect to learn and provides them with future resources. Customized onboarding checklists give new hires structure and help them see their progress. The mentor or onboarding buddy is ideally another engineer on the team the new hire will be joining. This person‚Äôs priority is to be available for the new hire‚Äôs questions, help them set up, and guide them through their first projects. The amount of assistance the onboarding buddy will provide depends on the level of the new hire. All the other available onboarding resources are less helpful if the new hire has to search for them on their own. Both the manager and onboarding buddy should have their own checklists to help them complete necessary tasks before the new hire joins. Some of these tasks include: Getting the new hire into Slack groups and calendar groups. Setting up initial 1:1s with teammates. Assigning an onboarding buddy. Having a set of projects that the new hire could start on. Collecting feedback from everyone involved in the onboarding processes (new hires, onboarding buddies, managers, etc.) is helpful to continue iterating and improving what‚Äôs in place so things will be better for the next round of people who join. We have recurring onboarding classes that happen every two weeks. In the past, the new hire took whichever classes the manager thought they needed within the first two weeks of joining. An improvement we decided to make to these classes was giving the manager and onboarding buddy freedom to have the new hire take these classes at some point within their first 30 days of joining. This gives the new hire more time to dive into parts of the code that these classes cover and attend the classes whenever they‚Äôd benefit from them most. We also decided to record all the onboarding classes, which gives new hires another learning option and creates a resource for existing engineers who need a quick refresher. We have an engineering handbook compiled of multiple resources that we believe all engineers could benefit from (setting up your dev environment, linking out to more specific handbooks, etc.), but this handbook, and others like it, hadn‚Äôt been thoroughly edited in about two years. These are living handbooks that we allow anyone to edit if they‚Äôd like, but because nobody explicitly owned the handbooks, there was a lot of outdated information. As part of making sure these handbooks stay up to date, we assigned points of contact (POCs) who have the knowledge to update information when necessary. The other benefit of having POCs is that new hires now have someone specific to go to if they have questions about a certain topic. We also encourage new hires to update any outdated or incorrect information in our documentation. We updated resources on the checklists and made some adjustments so that it could be as remote-friendly as possible. We used to have only one survey for new hires. It contained mostly open-ended questions, and we rarely received any submissions. Now we have a more in-depth new-hire form, and we‚Äôre working on surveys for the engineering manager and onboarding buddy to use in future iterations. We are finding new ways to make sure these surveys are filled out in a timely manner. We will also continue to have a dedicated Slack channel for onboarding discussions and suggestions, and we take any feedback we receive and update our onboarding processes accordingly O nboarding for an organization will never stay the same. Some company-wide practices could change, or engineering could abandon a technology as a whole, and these changes will need to be reflected through the onboarding processes. The last time we revamped our onboarding documentation, it had everything it needed, but that was more than a year ago, and now we‚Äôre working fully remote, which is something we didn‚Äôt expect! We will have to continue finding ways to learn and adapt to the ever-changing ways that companies are accustomed to, so we can make sure we are providing incoming co-workers with everything they need. https://www.deputy.com/blog/what-is-onboarding-and-why-is-it-important https://blog.rstankov.com/onboarding-software-engineers-remote-at-product-hunt/ https://arc.dev/blog/remote-developer-onboarding-experience-7z0iu5fu3h#start-with-a-manager-onboarding-checklist-(not-a-remote-developer-onboarding-checklist! ) https://foxbox.com/blog/how-we-onboard-our-remote-engineering-and-product-management-team/ https://blog.spendesk.com/en/remote-employee-onboarding Engineer @Medium 301 301 301 Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2020-10-20"},
{"website": "Medium-Engineering", "title": "code reviews at medium", "author": ["Christine Donovan"], "link": "https://medium.engineering/code-reviews-at-medium-bed2c0dce13a", "abstract": "Sign in Christine Donovan Jul 12, 2019 ¬∑ 5 min read Engineering teams have different norms and policies when it comes to code reviews. It can be frustrating to join a team and not know what is expected, or to operate with old assumptions and discover that they are at odds with a new team. In an effort to make it easier for engineers who come from different companies, we wrote down some of the features of our code review culture. Note: We use Git and Github fo r version control, so when we‚Äôre talking about code reviews, we‚Äôre mainly talking about Github pull requests. Also, we have a tool that integrates Github and Slack, so many of our Github notifications come through as Slack notifications. At Medium, engineers have to get their code approved by at least one other engineer before committing it to the codebase. We enforce this requirement with settings in our Github repository . We have a handful of in-house scripts to standardize our Git workflow, and one of these scripts is responsible for creating a pull request. Most of the time, engineers use this script to create their pull requests. (If you are curious, this repo is the open-source version of these scripts.) Our pull request script includes a list of the Github usernames for all the engineers at Medium. Faced with many options, who should an engineer choose as a reviewer? In general, we try to to make sure that engineers are working in pairs or groups on projects, and one of the benefits is that engineers have built-in reviewing buddies. If an engineer is working on a project like this, it‚Äôs natural for them to tag these people on their PRs. If an engineer has been working on something in isolation, we encourage them to tag engineers from their team, who are more likely to be aware of the work they‚Äôre doing. If an engineer has been working on something that falls outside of their team‚Äôs domain, we suggest that they do a git blame to see who‚Äôs recently worked on the same files, and get their perspective. In some cases, other people are automatically assigned as reviewers, in addition to the reviewers that an engineer chooses. We have a few configurations that will auto-tag certain people in certain files. The key thing to know is that the auto-tagging is designed for increasing visibility versus getting approval. The rule stated at the beginning still applies: code only needs an approval from one other engineer (any engineer). How many reviewers should be assigned? I‚Äôve seen this vary. I would say the average is two or three. But I‚Äôve also sent PRs to a single person, and sent PRs to my entire team (~6 people). We don‚Äôt have hard requirements for adding descriptions to pull requests. We only require that: if you are making a change that affects the UI, include a screenshot of the UI. That said, anyone who is reviewing code will need to figure out what is changing and why it‚Äôs changing. To facilitate this, engineers do often add descriptions, either in the PR itself or in a comment. In general, we think it‚Äôs good to consider what people may or may not know about your PR, and aim to give them context so that they can help you. We also think it‚Äôs useful to look over your pull request, and see if there are places where someone might ask, ‚ÄúWhy did this need to change?‚Äù An engineer can consider adding preemptive comments in Github (or updating the code if that feels called for). Our engineering team values and encourages the combination of small PRs and quick reviews. In this section, I‚Äôll talk about what I mean by quick reviews. In later section, I‚Äôll talk about what I mean by small PRs. Most of my PRs get reviewed within a couple of hours. We recommend that a PR should be reviewed within 4 hours. This guideline doesn‚Äôt mean that every reviewer has responded within a few hours; it means that at least one reviewer has responded within a few hours. Note: this only applies to PRs that are submitted in working hours. We don‚Äôt expect (and don‚Äôt want) engineers to be reviewing code outside of working hours. But what if code doesn‚Äôt get reviewed within a few hours? Or, maybe, it did get reviewed, but there was feedback to address, and now it needs a second pass from the reviewer. In both situations, an engineer will add a comment to their PR that says ‚Äúptal‚Äù (the lightning bolt emoji will work as well). PTAL stands for Please Take A Look or Please Take Another Look. When this comment is added, our Slack integration tool will send a notification to all reviewers. The notification will tell them that the author is asking them to ‚Äúplease take another look.‚Äù We use PTAL frequently, and it‚Äôs understood way to let other engineers know that a review is needed (again). Maybe an engineer wrote ‚Äúptal,‚Äù but there‚Äôs still no responses on their PR. Or, maybe this code is especially urgent, and it needs attention sooner that the average PR. In general, we think of the author as being responsible for getting the review that they need. We ask engineers to remember that other engineers want to help and be responsive, but some days and some workloads don‚Äôt allow for it. That‚Äôs why it‚Äôs good to escalate when someone is sensing that their PR has slipped through the cracks. One example of escalation is dropping the PR in a Slack channel and asking if anyone has time to review. Another example is pinging reviewers directly. We encourage engineers to figure out the best way to escalate a PR that needs attention. At Medium, we strive to build things in small units. We want to break our code down as much as possible and submit small, digestible PRs. By doing this, we can review quicker and move faster. Okay, but what is a small PR? One way to think about it is in terms of conceptual changes, not lines of code. For example, changing the name of a variable might cause changes in many files, but it is still small because it is a single concept ‚Äî updating the name of a variable. We try to minimize PRs in terms of conceptual changes. We have an unofficial company motto of ‚Äúsafe to try.‚Äù This is motto is about feeling free to make a call without needing consensus or certainty (as long as it won‚Äôt be really bad). I think this motto influences our code review culture as well. When we‚Äôre reviewing code, we don‚Äôt act like gatekeepers; we aim to help our co-workers do what it is they‚Äôre trying to do. We also value the Reasonable Person Principle. It‚Äôs pretty self-explanatory; it‚Äôs about starting with the assumption that another person is acting from reasonable intentions. This principle reminds us to see each other as humans first, and be generous in our interpretations of one another. 1.2K 5 1.2K 1.2K 5 Software Development Code Review Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2019-07-22"},
{"website": "Medium-Engineering", "title": "rex mediums go recommendation microservice", "author": ["Miles Hinson"], "link": "https://medium.engineering/rex-mediums-go-recommendation-microservice-e077bc9582a", "abstract": "Sign in Miles Hinson Dec 17, 2020 ¬∑ 9 min read Editor‚Äôs note: This blog post was originally written in early 2019. It gives a great overview of why we built Rex and how it initially worked, but a lot has changed since then. Look for future stories on how Rex has evolved over time. At Medium, we‚Äôre focused on delivering the best stories t o the users most interested in them. We want to provide as many high-quality stories for our users as possible and have them ready as soon as they open Medium, whether on the site, in the app, or in emails. You‚Äôll often see them in the form of a list of stories (which we call a ranked feed). However they‚Äôre using Medium, users can scroll through a ranked feed of stories, searching for the best story that fits them at that moment. In March 2018, the recommendations team at Medium began to explore how we could improve our ranked feeds. We knew we wanted a feed that could quickly deliver as many personalized, high-quality stories as possible for a given user. However, as we delved into the parts of our code powering our ranked feed, we realized that our feed was neither quick to render nor sourcing as many stories as we felt it should. As an example, our homepage feed could take up to seconds to create, and we could not rank as many candidates as we‚Äôd like: only around 150 stories. There are hundreds of thousands of incredible stories on our platform ‚Äî we want to be able to source recommend as many candidates as possible whenever a user goes to Medium. In order to build a recommender system that could source many stories and do so quickly, we decided to go back to the drawing board and build an entirely new service from scratch. Before delving into how we built it, we should take a look at the problems with the old one that were holding us back. One issue was technical debt: As we first made small tuneups to our recommendations system back in March ‚Äô18, we found that testing and verifying each change was far more time-consuming than we‚Äôd like. Bugs would pop up that were difficult to catch in tests and reproduce. It was clear that if we wanted to move more quickly and test new recommendation strategies, we would at least need a major refactor of the code that existed. However, the biggest issue was language choice. Much of Medium runs within a Node.js monolith, including the code that used to power story recommendations. Node, despite its many strengths, it wasn‚Äôt the best tool for this particular task. Node is single-threaded (at least, it is how we use it at Medium). There are no concurrently running operations: All requests are scheduled via a system called the event loop. When a request makes an I/O call, it goes to the back of the event loop and yields use of the CPU to the next request in line. This is great when the computation done per request is pretty simple. Unlike in a synchronous I/O world‚Äîwhere a request might still hold the CPU while waiting for the I/O operation to complete‚Äîthe CPU is never idle, and no request is hogging the CPU for too long a time. When we have requests that don‚Äôt demand too much uninterrupted time of the CPU, we see Node at its finest. The top example in the diagram above is such an example. This is not the case when fetching all the data to put a ranked feed together. Sourcing the stories we want to rank, getting the data to rank many stories, using different ranking services to order those stories effectively: This is just some of the heavy lifting happening for each request to form a ranked feed. Each of these subtasks makes many I/O calls themselves. Hence we‚Äôre often giving up the CPU to other requests, and when we have the CPU, we‚Äôre holding it for a long time. Making matters worse, when we give up control of the main thread, other requests could be taking the CPU a while as well, causing our request to build a feed to get slower and slower. In short, we‚Äôre putting heavyweight operations in a runtime environment that‚Äôs optimized for much more quick and simple tasks. If we wanted to build a more performant recommendations system, Node probably wasn‚Äôt the answer. With all this in mind, the recommendations team at Medium decided we had to make a change. Thus was born a new service at Medium: the recommendations microservice Rex. Before delving into how Rex works, it‚Äôs useful to clarify two things: What we mean by microservice. Why we chose Go as the language for Rex. With respect to the first, I highly recommend reading this story by a former Median, Xiao Ma, for thoughts on microservices , but as a TL;DR: We want our recommender system to be deployable separate from the rest of the codebase. Developing in a new microservice makes the test/ship/deploy process far quicker. As for the second, we considered a few languages, but we landed on Go for the following reasons: More efficient use of the CPU . While Node is single-threaded, Go is much better suited for the combination of I/O and CPU-intensive operations required to build a ranked feed. Splitting our work onto separate Goroutines means we can avoid the issue of the CPU getting hogged by one single request and other requests getting starved. Opinionated . Go makes it pretty hard to write ‚Äúbad‚Äù code. A typed language that is also highly opinionated in terms of code styling means that even a newbie to Go (which I was when we started writing Rex) can quickly start writing clean and readable code. Prior experience with Go . While much of Medium‚Äôs codebase is written in Node, we already had a few smaller-purpose microservices in Go. Adding another microservice in a language that we as a company have familiarity with makes building and maintaining this new service much easier. We‚Äôve talked a bit about the motivations for building Rex and what language we wanted to use. How does Rex actually work? The generation of the Medium feed can be described in seven basic steps: aggregating, preprocessing, annotating, ranking, postprocessing, caching, and validating . We source stories we think a user will enjoy, and we understand users may like stories for different reasons. For example, you may always read stories from authors or publications you follow. Or perhaps you really like technology and always want to read stories in the technology topic . For your feed, we have many different story providers, each of which provides you with stories we think you‚Äôll like for a particular reason. The three stories here were surfaced for the following reasons: From your network : This story was published in a publication I follow ( 500ish ). Rex sources the top-performing stories from publications I follow (like with topic-based providers, we look at stories in a publication many users have read and clapped on). Based on your reading history : Based on the stories I‚Äôve read and clapped on so far, users with a reading history similar to mine have also liked this story. Finding users with a similar reading history to mine and making recommendations based on those is a technique called collaborative filtering, which Rex relies on to find high-quality stories for each user. Photography : I followed the photography topic, so for my homepage, Rex sources some of the top-performing stories in this topic (that is, the stories in the photography topic that many people have read and clapped on), and adds them into my feed. Once we‚Äôve aggregated these high-quality stories for the user, we filter out stories we think may not be suitable for a user at a given time. Maybe we‚Äôve sourced a user a story they‚Äôve already read ‚Äî there‚Äôs no need to show them the same story twice. We may add a preprocessor to remove stories the user has read before. During the preprocessing step, we use different preprocessors to filter out stories, with each preprocessor filtering for a particular reason. Once we‚Äôve amassed a group of stories we think a user will like, we have to rank them by how much we think a user will like each story. Before we can rank them we have to fetch a significant amount of data from our data stores to get all of the necessary information (for example, who is the author of a story, what topic is the story in, how many people have clapped on this story, etc.). We calculate most of the features we need for ranking stories via offline Scala jobs and store them in two tables that we query at the time of feed creation. This allows us to minimize the number of I/O calls we‚Äôre making when assembling all the necessary data. There‚Äôs information about each particular user ‚Üî story pair that can‚Äôt be calculated offline and has to be checked online (for example, does the user for whom we‚Äôre generating a feed follow the author of a particular story?), but precalculating the features lets us do much of the work beforehand. Once we‚Äôve gathered all the necessary data to rank each story, actually ranking the stories depends on what ranking strategy we use. We first transform the results from the annotation step into an array of numerical values and pass each story and set of values to another Medium microservice that hosts our feed-ranking models. This separate microservice assigns a score to each story, where the score represents how likely we think the user is to read this particular story. A lot of great work has gone into building Medium‚Äôs model-hosting microservice as well, but that‚Äôs a tale for an upcoming Medium Engineering story. üòâ After ranking stories, there are often some ‚Äúbusiness rules‚Äù we may want to apply. Postprocessors apply story-ranking rules that ensure a better user experience. For example, we‚Äôll see the top of a user‚Äôs feed dominated at times by a single author, single publication, or single topic. Because we want a user to see a more diverse set of authors, publications, and topics represented, we added a postprocessor that prevents a single entity from dominating the top of a user‚Äôs feed. Once we‚Äôve finished generating the feed, we store the feed in Redis , an in-memory data store, for future use. We don‚Äôt necessarily want to show a new feed every time the user visits Medium. This could make for a confusing user experience if they‚Äôre visiting Medium often in a short amount of time. Hence, after generating a feed, we store the feed in Redis for a short period of time. If we‚Äôre reading our feed from the cache, some of the stories in the cached ranked-feed list may no longer be suitable for candidates. For example, if I follow and subsequently unfollow a given author, I should remove stories from that author from my feed if stories by that author are in my cached feed. The validation step filters out potentially unwanted stories from the cached feed, stories that may have been suitable candidates when we first created it. When we first rolled out Rex, the benefits were immediately clear. Instead of ranking 150 stories, we can rank 10x that amount for a given user, and creating a new feed in Rex takes less than one second for 95% of requests. üéâ üéâ üéâüéâ üéâ üéâüéâ üéâ üéâüéâ üéâ üéâüéâ üéâ üéâüéâ üéâ üéâüéâ üéâ üéâüéâ üéâ üéâüéâüéâ Just as great is how easily extensible this service is: Plugging in a new type of provider (for sourcing different story types) or testing out new business rules/preprocessing rules is a straightforward process and lets us easily test out new strategies to make recommendations at Medium the best they can be. Rex is a continuously evolving service ‚Äî the work described here laid the foundation for making recommendations at Medium better. Within Rex, we‚Äôve experimented with new ranking models, new strategies for ‚Äúcold-start‚Äù users, new tests related to our collaborative filtering algorithms, and much more. In addition, we‚Äôve expanded Rex to power recommendations across more and more surfaces across Medium, and making sure that Rex has the ability to scale gracefully with the extra workload has posed an awesome challenge in and of itself. There‚Äôs never a shortage of new and impactful recommendation and machine-learning challenges to tackle at Medium. If you‚Äôre interested in working on recommendations systems that affect millions of people each day, we‚Äôd love to talk with you . Knicks fan and pie enthusiast. Engineer @Google, alum @Medium 558 2 Thanks to Kyle Mahan , Xiao Ma , and Jonathan Fuchs . 558 558 2 Recommendations Go Node Medium Engineering Cool Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2020-12-17"},
{"website": "Medium-Engineering", "title": "the ghost in the hashes", "author": ["Heather A"], "link": "https://medium.engineering/the-ghost-in-the-hashes-55ef1e3a86ef", "abstract": "Sign in Heather A Jun 30, 2019 ¬∑ 6 min read This was originally published on Medium‚Äôs internal instance, to explain a persistent bug to other engineers. On November 29, 2018 Dan Benson did a major upgrade to our production tech stack. He upgraded us from Node 6 to Node 8. Node.js is the JavaScript-based server environment we use for most of our existing backend. Everything went well and we were happy to be using the latest and greatest, with all the performance improvements that came along. Shortly afterwards, we s t arted getting some sporadic test failures that couldn‚Äôt be explained by any code changes. The error messages were always like ‚ÄúTypeError: X is not a function‚Äù. Where X is something that is definitely a function. This was disquieting to me. In my head, JavaScript was cannibalizing random functions at will. Perhaps Node 8 was using a new machine learning-based garbage collector? Or there were ghosts. We eventually noticed the pattern that these disappeared functions were all methods of Shepherd graph nodes. Shepherd is a Node dependency injection framework that we wrote several years ago that we have rapidly diminishing knowledge about. This was good because it meant it was less likely to be a JavaScript ghost, and more likely to be something we could fix in Shepherd. However, no one got the time to actually look into Shepherd. A couple months later, I was on The Watch ( Medium‚Äôs on-call rotation ) again and the errors were still happening. The random test failures were causing us to have to look into and re-run tests regularly. The bug even caused issues in production occasionally, always on one instance, forcing us to manually take the bad instance out of our production gang. We had to pass down the knowledge from Watch to Watch ‚Äúif you see ‚Äò is not a function ‚Äô, just rerun the tests‚Äù I filed an issue for it to log the occurrences. I looked at the Shepherd code, and felt overwhelmed. My Watch cycle came and went without a fix. S oon after my Watch cycle, Lyra dropped this comment in on the issue: I did a little spelunking in Shepherd today. The only thing I‚Äôve found that directly depends on V8 is CompiledNode.generateHashes , which uses an npm module we wrote called oid , which includes a C++ native extension . The package Lyra was referring to, oid , provides an API for getting a hash of any JavaScript object or primitive. This hashing code is written in C++ as a V8 extension, V8 being the underlying JavaScript engine that Node uses. Shepherd uses oid to get hashes of Shepherd graph nodes. These hashes are used to cache nodes, ensuring that nodes which have the same handler function are only run once per built graph, and the result cached. This lead made so much sense. One of the biggest things that would change with a Node upgrade would be an underlying upgrade to V8. It also made sense that ‚ÄúgraphNode.X is not a function‚Äù may crop up if you accidentally replaced a graph node in the cache with another which didn‚Äôt define a function named X. Lyra and Kyle found that oid was depending on another library, nan , that had its own v8 extension. That dependency was on an older version of nan . Kyle upgraded oid so that it would build nan ‚Äôs new version along with oid . Everyone was very excited about the upgrade. However, the ‚ÄúX is not a function‚Äù failure cropped up right away after the upgrade went out. We were all very sad. People returned to their regular work. Another month went by, full of ghosts. Waiting around one day, I decided to get Shepherd running locally and debug more. I picked up with the trail that Lyra left ‚Äî looking into the hashes. Once I got Shepherd set up, I added some console.log() s to the the hash generation code. I spun up our graph tests and immediately noticed something odd. The hash values for objects were low, much lower than the values for string graph nodes. They were in the millions. I‚Äôm no hashing expert, but the values just seemed too low. I created a little test Node script that looked like this: And ran it on my current Node 8 setup. Then I switched to Node 6, compiled oid for that, and ran it again. There was a clear difference: Node 6: 1777246106 Node 8: 1314340 I ran it several times to similar results. I saw that oid was using a V8 method for objects called GetIdentityHash() . The V8 docs didn‚Äôt say much for this method, other than that it wasn‚Äôt guaranteed to be unique. V8 is open source though, and has a mirror on GitHub . I searched there for ‚ÄúGetIdentityHash‚Äù and started from there. I ended up at this line of code which implied the hash was 21 bits. Indeed, every time I ran it, the hash stayed under 2¬≤¬π. Empirically, it seemed like the hashes were 31 bits before. Where did those 10 bits go?‚Ä¶They stole them! üò±üò±üò± To use for storing the length of something. It was clear this wasn‚Äôt long enough of a hash for us, so it was time to move on. I searched Google for advice on implementing object ids, and the internet suggested using a WeakMap , where the keys are your objects, and the values are increasing integer ids. This actually makes the id for an object completely unique ‚Äî even better than before. I submitted a pull request implementing this. Since Shepherd is open source, I tagged Nick Santos on the review, a former employee who was involved in Shepherd. He gets really excited about odd bugs , so he was excited about this one. He wrote a test for us that failed if there was a collision after creating a certain number of graph nodes. He found empirically that it would usually take just under 2000 graph nodes before the first collision. Theoretically, it‚Äôs a case of the birthday problem . So, even if there‚Äôs only a 1 in 2¬≤¬π chance of collision between two particular nodes, the chance of some two nodes colliding in a group of nodes is much higher. The chance of some two nodes colliding in a group of 100 nodes is about 0.2%, in 500 is about 5%, and by 2500 is about 75%. In contrast, if the hash were 2¬≥¬π, the chance of some two nodes colliding in 2500 nodes would be about 0.1%. With the fixes in, Kyle upgraded and published all of our packages. We haven‚Äôt seen the bug since. Of all the issues here, I think maybe the core one was depending on oid , and in turn getIdentityHash() . Both of these APIs called out that they weren‚Äôt guaranteed to be unique, and there could be a collision between two different objects. Moreover, neither specified how big the hash values were. Ideally, you would use an API with a contract for the length of the hash, so that you can judge how likely collisions are for your particular use case, and the number of bits doesn‚Äôt change from underneath you. However, it‚Äôs hard to know what the options were when this original code was written. I also think about how long it took us to fix this bug. It was a constant background issue for 4 months. I wish that I‚Äôd dove in deeper on the first Ghost Watch I was on. From there, it was passed down through The Watches. If you couldn‚Äôt debug it within a Watch cycle, you had to move on back to your product work. Bugs and product areas that are in no-persons land is an ongoing issue for us imho, much like the Hash Ghost was. Lover of all things computational 471 471 471 Software Engineering Ghosts Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2019-11-25"},
{"website": "Medium-Engineering", "title": "scaling email infrastructure for medium digest", "author": ["Penny Shen"], "link": "https://medium.engineering/scaling-email-infrastructure-for-medium-digest-254223c883b8", "abstract": "Sign in Penny Shen Sep 29, 2020 ¬∑ 10 min read The Medium digest is a daily email containing a personalized list of stories that‚Äôs scheduled to arrive between 8 a.m. and 9 a.m. user‚Äôs local time. Timely delivery is important to us because we want our readers to start their days with the digest. Kind of like your morning newspaper! We send millions of digests every day, and digest generation creates one of the heaviest loads on our resources. Making sure they continue to arrive on time as our reader base grows has been challenging. If there‚Äôs a bottleneck somewhere, digests are normally impacted first. Our e m ail infrastructure, built on top of Amazon‚Äôs Simple Queuing Service (SQS), did a commendable job handling the growing volume, but we finally hit its limit toward the end of 2019. In the following months, we worked on a series of improvements to our email infrastructure that enabled us to send 282% more digests . This post describes our journey from discovering the limit, iterating on the improvements, to finally bringing life back into our email infrastructure. Before we dive into the issues we encountered, let‚Äôs take a look at the lifecycle of a digest first. In order for digests to arrive at 8 a.m. user‚Äôs local time on time, we trigger digest generation for users in a specific time zone six hours before the scheduled send time. For example, we start generating digests for Pacific time at 2 a.m. Pacific time. We check which time zone to generate digests for every 10 minutes. If you‚Äôre wondering why we don‚Äôt check every hour, which is presumably when we go from one time zone to another, there are two reasons. First, not all time zones are one hour apart ! Second and more importantly, we randomly divide users in each time zone into six 10-minute buckets. This way, each bucket contains fewer users, and we lose fewer digests if the generation for that bucket fails to start for whatever reason. With that said, let‚Äôs look at the different events involved in generating and sending a digest: Shard events: Every 10 minutes, a Jenkins job triggers the upstream shard event, which is then fanned out into 256 downstream shard events. Each downstream shard event iterates through a shard of the user email table for the current time zone bucket and emits a digest generation event for each user in the shard. Generation events: Generation events do the heavy lifting of looking up the information needed for a digest. Send events: Once an email is generated, it‚Äôs passed to Sendgrid, the email delivery service we use, via a send event. Sendgrid takes care of actually delivering the email to the reader‚Äôs inbox. All digest events were processed by a single queue so that digest events won‚Äôt block other events from being processed. Around September to October 2019, we saw that the digest delivery time was getting delayed, and it was getting significantly worse every day. We dug into it and found that the queue responsible for handling digest events was approaching its processing limit. Normally, we‚Äôd have some downtime throughout the day, during time zones with fewer Medium users, when the queue is processing at below the maximum rate of 500 events per second. As digest send volume grows, the downtime was starting to disappear: In other words, the number of events the queue has to process over one day is approaching the maximum number of events the queue can process at its maximum processing rate. If we go beyond the limit (which we did by the end of October 2019), the queue will remain backed-up forever because we add more events than we can process every day. The most obvious solution was to bump up the processing rate, but due to digest‚Äôs scale, that would require us to significantly increase resources for underlying services, which is costly. We wanted to see if we could optimize our email infrastructure before shelling out the big bucks. As described earlier, all digest events were processed by the same queue. The problem with this approach is that when the queue gets backed up, a generated digest can‚Äôt get passed onto Sendgrid right away because the send event gets added all the way to the back of the queue. (Although SQS doesn‚Äôt guarantee FIFO order, events still get processed roughly in the order they are put in.) The first thing we did was putting send events onto their own queue. Since send events are fast compared to most other email events, this new queue is unlikely to get backed up, and a generated digest can be handed to Sendgrid without further delay. With this change, we got a decent amount of breathing room, as around 20% of the events on the original queue were send events. We were off the hook for now, but this was a Band-Aid rather than a solution, as we were still close to our limit. In fact, with an influx of users in the first half of 2020, we reached the limit again by June 2020. An important best practice for email deliverability is to ‚Äúsunset‚Äù inactive recipients , which means to only send emails to users who have been active with your products in the last few months. Following this rule, we only send digests to users who have either opened an email or visited Medium in the last 45 days. Previously, we handled evaluating whether a user has been sunsetted in the generation event itself. This means we were processing one generation event for every user who has ever signed up for a Medium account . However, most of the generation events we process don‚Äôt actually translate to send events. In fact, we only send emails to 1/4 of all users we try generating for . We check whether we should send each digest in the very beginning of the generation event, so the generation events that don‚Äôt become send events (presumably because those users have been sunsetted) are effectively no-op. Even though these no-op events are relatively fast, they can still cause the queue to get backed up because we rate-limit each queue by number of events per second . For example, even if 100% of events are no-op and we finish processing the whole batch in the first 100ms, it‚Äôll still wait the full one second before picking up the next batch of events. Seeing this, the first thing we decided to do was to process events for active users only. We added a lastActiveAt field to our user email table and updated it every time a user becomes active. Then, when we‚Äôre querying the table to decide who to generate digest for, we only query for those who were active in the last 45 days according to the lastActiveAt field. This doesn‚Äôt sound too hard! We put in the necessary changes behind a flag and started ramping up percent of events processed using this new strategy. As we ramped to 50%, we started seeing a significant increase of errors from Rex, the recommendations service we rely on for personalizing stories in the digest. Upon closer inspection, we realized that the request pattern from our offline-processing service to Rex had become more bursty with short peaks every 10 minutes, which causes Rex to thrash as it continually scales up and back down within each interval. This is because all the no-op events for sunsetted users effectively served as a buffer and smoothed out the request pattern. Without these no-op events, every generation event resulted in an actual request to Rex, and Rex was doing poorly under this new pattern. We were able to spread out the generation events so that the request pattern to Rex is more even, reducing thrashing. The difference for traffic pattern to Rex is shown below: We accomplished this with two changes‚Ä¶ SQS allows each event to be delayed up to 15 minutes . In order to evenly spread out generation events, we went with a naive approach of: We deployed the randomized delays, but the request pattern was still uneven. This was because this approach assumed we were processing each batch of shard events every 10 minutes, when in fact they often get processed in bunches when the queue is backed up: To resolve this, we separated the shard events onto a dedicated queue so they can be processed promptly. The difference in how new events are added onto the queue is shown below: Even though the traffic was now smoother, we were still seeing some Rex errors during times when we went from processing almost no generation events to processing at maximum rate (since we have consecutive time zones where one has very few users and a neighboring one has a lot of users). This was because, without the no-op events as buffer, we were still sending Rex a higher number of requests per second. In fact, we were effectively tripling the number of requests to Rex, and Rex simply wasn‚Äôt able to scale up fast enough. To alleviate this, we lowered the max processing rate from 500 to 250, since we no longer have to process at 500 now that we have fewer events to process. In addition, we gave Rex more resources and tuned the configuration so it auto-scales better with the new request pattern. With all these changes, we were finally able to fully ramp up generating digests for active users only. We ended up reducing the number of generation events by 70%. Even with this change, we noticed around 22.5% of all generation events are still no-op (that is, they don‚Äôt become send events). This is likely because email settings were turned off for those users, or the accounts may have been deleted or suspended. At the end, comparing the number of digests we were sending when we hit the limit to the projected maximum number of digests we can send under the improved infrastructure (assuming 22.5% of all generation events continue to be no-op), we can now process around 282% more events than before . We don‚Äôt expect to hit the limit again for at least another few years. When working with queues, it‚Äôs generally a good idea to separate different types of events onto different queues so they can be managed separately. On the other hand, it‚Äôs also good to avoid overengineering and only split events out onto separate queues when a concrete need arises. Making traffic patterns as even as possible makes autoscaling underlying services easier. We also found that more predictability (in our case, by moving shard events onto a separate queue) with when new events come in help us make better decisions. It‚Äôs hard to try to adjust the traffic pattern when you don‚Äôt even know when the new events will come in. With microservices, you can‚Äôt assume services you rely on are ready when you are. Making sure they are configured properly to handle your load can be challenging. The difficulty is compounded if your team doesn‚Äôt own those services. It can be hard to diagnose and fix issues in services you don‚Äôt own, as they can look wildly different from the services you‚Äôre familiar with. Our team doesn‚Äôt own Rex, and our attempts at trying to figure out how to scale Rex ourselves did not end up well. We simply weren‚Äôt familiar with it enough. In the end, we decided to ask the Recommendations team to review our plan and communicated with them closely throughout our ramp. With enough context, they were able to help us figure out how to scale Rex. We learned that as much as we didn‚Äôt want to bother other people, working directly with the teams that own those services is the best way to make sure you don‚Äôt break them. As noted above, around 22.5% of the generation events are still effectively no-ops. We can further reduce the number of events we need to process by recording email settings and user status (suspension, deletion) in the User Email table. If we do reach the limit again, increasing processing rate back up to 500 (or even higher) is still an option. We will need to make sure Rex and its underlying services can handle the higher processing rate. Part of the difficulty for bumping up processing rate is that even with spreading out events within each 10-minute chunk, digest to Rex traffic can still go from processing very little to processing a lot as we move across time zones, causing Rex to have to scale up significantly in a short amount of time. We can make the digest to Rex connection more stable either by increasing processing rate slowly (for example, instead of going from 10 to 500 in one minute, go from 10 ‚Üí 20 ‚Üí 40 ‚Üí 80 ‚Üí ‚Ä¶ ‚Üí 500 over a few minutes) or allowing digest requests to be retried safely. Software Penguineer 1.1K 2 Thanks to Bo Chean , Kyle Mahan , Tony Meng , and Heaven Chen . 1.1K 1.1K 2 Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2020-09-30"},
{"website": "Medium-Engineering", "title": "counting your followers", "author": ["An Vu"], "link": "https://medium.engineering/counting-your-followers-facbfafe45d9", "abstract": "Sign in An Vu Nov 24, 2020 ¬∑ 12 min read A recent wave of users have questioned the validity of the displayed number of followers on their profiles. At one point, their follower number increased, some even by the thousands, but then a few weeks later went back down to around where the user originally remembered. Some users were concerned: Were their profiles hacked? Did a wave of users suddenly follow and then unfollow them? The answer is no‚Äîit was a data problem. When Medium started to shif t toward more relational content , we noticed that some users were missing authors in their ‚ÄúLatest From Following‚Äù section, which should show the followed collections and authors that had recently published. Since this wasn‚Äôt true for all users, we had to look into the data that drives this section of Medium. Upon investigation, we noticed a discrepancy in a key column that the ‚ÄúLatest From Following‚Äù section uses that the rest of Medium does not. In turn, a backfill had to be done so the key column would properly reflect a user‚Äôs followings. After the backfill finished, users started reporting an uptick in followers and the number of people they have followed, even though they had not followed any new users. That‚Äôs when we noticed that the original backfill had done its intended purpose while also breaking it. A backfill is supposed to be the process in correcting data or making the data whole without modifying its existing core components. The first backfill did fix the key column needed for the table that ‚ÄúLatest From Following‚Äù depended on, but it also ended up modifying another table that contained the displayed number of followers on a user‚Äôs profile. Due to this error, another backfill had to be done to bring the numbers back to the users‚Äô real amount of followers and followings. To get some context, let‚Äôs do a deep dive of what currently happens when you follow a user, the error that prompted the need for the backfill, what was done for the first backfill and why it failed, and the second backfill that fixed it. Three things ultimately happen when you press that green button: You create or recreate a Medium relationship with that user. In this context, a Medium relationship is an indication of whether or not a user is following another, regardless of which platform the follow originated from. (More on this later.) You increase the number of users you follow. You increase the number of followers for the followed user. There are two tables in AWS DynamoDB that formulate the data: the user relationship table and the user stats table . The user relationship table has the following columns: user_id (the user doing the following) target_user_id (the writer who was followed) twitter_followed_at (the timestamp of import from Twitter) facebook_followed_at (the timestamp of import from Facebook) medium_followed_at (the timestamp of follow on Medium platform) medium_unfollowed_at (the timestamp of unfollow on Medium) latest_followed_at (the aggregation of all the timestamp columns) The user stats table has the following columns: user_id (the user in question) followers (the number of users the given user follows) followees (the number of users who follow the given user) When a user chooses to follow an author, an entry is created for that relationship, if it doesn‚Äôt exist already, in the user relationship table . This relationship would fill the current time into the medium_followed_at column, as well as the latest_followed_at column. Additionally, in the user stats table , the number of followers for the author and the number of follows for the user who clicked the follow button is incremented by one. When a user chooses to unfollow an author, the existing entry for the relationship is updated. In the user relationship table , latest_followed_at is set to zero, while medium_unfollowed_at is set to the time the user unfollowed. In the user stats table , the number of followers for the author and the number of follows for the user who clicked the follow button is decremented by one. The code for the logic looks something like the following: The function takes in the user_id , target_user_id , the social_type (Twitter, Facebook, Medium, or Unfollow), and the current time as an epoch timestamp , which is essentially the number of seconds elapsed since January 1, 1970, at midnight (00:00:00) in the UTC time zone. The function then ascertains which user relationship table columns to fill based on the social type and places the data into that table. Afterward, it takes the same user_id and target_user_id to updates the users‚Äô followees and followers , respectively. Prior to 2016, users had the ability to import their Facebook friends and Twitter follows to Medium. Upon import, a relationship is created for the two users and the related columns of twitter_followed_at and facebook_followed_at were updated to the time of import. The user stats were also incremented by the number of imports. At this point in time, the latest_followed_at column did not exist, and Medium relationships were calculated in the backend by grabbing the largest timestamp from twitter_followed_at , facebook_followed_at , and medium_followed_at , and making sure the aggregated timestamp is greater than medium_unfollowed_at . The code to calculate whether or not the user of the given user_id is following the given target_user_id in the relation looks like the following: This function takes in a relation that has all the data for a single Medium relationship in the user relationship table ( user_id , target_user_id , twitter_followed_at , facebook_followed_at , twitter_followed_at , medium_unfollowed_at ) and returns True if the user in question ( user_id ) is following the given author ( target_user_id ) or False if they aren‚Äôt. To this day, Medium still uses the code above to aggregate the user relationships that are shown on your follow pages. The top number, indicating number of followers, is taken from the user stats table while the list of followers is taken from the user relationship table . Following the removal of Twitter and Facebook imports, the engineering team needed a faster way to keep track of Medium relationships. Thus, latest_followed_at was born and is supposed to be the source of truth for a Medium relationship; the single column would make it easier to ascertain whether or not the relationship between two users exist. With this new column, a backfill was ran to populate it. latest_followed_at was supposed to be populated with the max of the followed_at timestamps ( twitter_followed_at , facebook_followed_at , medium_followed_at ) or zero. latest_followed_at is zero only if the max of the followed_at timestamp is less than medium_unfollowed_at . Some examples: John imported their following of Jane from Twitter on November 21, 2020, at 5:30PM UTC. This means their twitter_followed_at is set to November 21, 2020, at 5:30PM UTC. Their latest_followed_at would be on November 21, 2020, at 5:30PM UTC. Joe imported their following of John from Facebook on November 20, 2020, at 10:34AM UTC but then unfollows John on November 21, 2020, at 3:12PM UTC. This means their facebook_followed_at is set to November 20, 2020, at 10:34AM UTC, and medium_unfollowed_at is set to November 21, 2020, at 3:12PM UTC. With the new column, latest_followed_at is set to zero since twitter_followed_at and medium_followed_at are zero by default and medium_unfollowed_at is greater than facebook_followed_at . Jane imported their following of Joe from Twitter on November 10, 2020, at 8:45AM UTC, then unfollows Joe on November 20, 2020 at 10:50AM UTC, and finally refollows Joe on November 20, 2020 at 12:00PM UTC. This means their twitter_followed_at is set to November 10, 2020, at 8:45AM UTC; medium_unfollowed_at is set to November 20, 2020, at 10:50AM UTC; and their medium_followed_at is set to November 20, 2020, at 12:00PM UTC. With the new column, latest_followed_at is set to the value of medium_followed_at . The max of the followed_at timestamps is medium_followed_at , and since medium_followed_at is greater than medium_unfollowed_at , latest_followed_at is set to medium_followed_at . While developing the new interface, we noticed that ‚ÄúLatest From Following‚Äù was missing authors or had authors that shouldn‚Äôt be there. With the new relational Medium, we became heavily reliant on the user relationship table and the latest_followed_at field and realized that‚Äôs where the problem was. While the relationships existed, the data was not properly consolidated; some of the Twitter, Facebook, and Medium followed_at fields were not ported over to the latest_followed_at field, and some unfollows were not properly reflected. This may have been because the backfill to fill the column was incomplete, there might have been some migration issue where the backfill was run before the social media imports were turned off, and maybe there was a backend code hiccup where the unfollows didn‚Äôt zero out the latest_followed_at field. Regardless, with this finding, a backfill was in order to set the column straight. To start the backfill, we needed to query the existing data and find the Medium relationships that needed to be fixed. Given that the data is found within DynamoDB, querying millions of entries on nonindexed columns is next to impossible. As such, we have hourly batch jobs that port the data over into Snowflake, our data warehouse. With the data in Snowflake, querying the data becomes less of a burden. First, we queried the database for all user/author pairs that didn‚Äôt have the Twitter, Facebook, or Medium follows ported over into the latest_followed_at column. We were looking for any relationships where latest_followed_at is set to zero even though the max of the followed_at timestamps is greater than medium_unfollowed_at . The query looked like the following: We ran a second query to find all the user/author pairs that didn‚Äôt have the proper unfollow relationships. The erroneous relationship would be one where medium_unfollowed_at is greater than the max of the followed_at timestamps but latest_followed_at is not zero. The query looked like the following: The queries returned more than 180M rows combined, and the resulting datasets of the user_id and target_user_id were sent to S3 as comma-separated value (CSV) files that we will then use for backfilling the data. Each row in the CSV files is sent to Amazon‚Äôs Simple Queuing Service (SQS) as an individual message. The messages are then picked up by our event processors. The event processor takes in the user_id and target_user_id and grabs the relation from the database. The processor does another computation of the latest_followed_at to make sure what we found in Snowflake is still the case in Dynamo. Based on the value of the calculated latest_followed_at , the processor utilized the existing Medium codebase and called the function mentioned above ( putUserRelationship ) to update the user relationship table appropriately. The function we used in the backfill had the following return statement: This updates the user relationship table and subsequently takes the user_id and target_user_id , which we had just performed on, and updates their follow counts via the function call this._updateUserCounts . This means that for the 180M relations we had updated, we had also accidentally incremented that many follow stats for Medium users. Even though the user relationship table originally had discrepancies in data, the user stats table did not. With the completion of this backfill, we had corrected the errors in user relationship table but introduced errors in the user stats table . We had flipped the tables, so to speak. With the newly created issue, we had to run another backfill to rectify the data. Since the user relationship table in Snowflake was updated hourly to properly reflect the table in DynamoDB and it had been a couple weeks since the initial backfill, the list of the original 180M relations that we had fixed were lost. So, what did we do? We couldn‚Äôt take the number of followers and followees from the user relationship table at face value since they can be ephemeral; it does not account for any possible new follows or unfollows that may happen between the batch job into Snowflake and the time the backfill updated the data in Dynamo. If we had taken the numbers from the user relationship table as is, we would have potentially created more errors in the user stats table . Instead, we took the difference of followers and followees between the user relationship table and user stats table and added the difference to the user stats table in the backfill. By adding the difference to the data to the user stats table, we will undo the accidental increments from the first backfill. To simplify, it would look something like: The query to find the difference looked something like the following: Essentially this query finds the true number of followers and followees for a user from the user relationship table based on the fixed latest_followed_at and subtracts the current user stats from the user stats table . The results for a user who had their number of followers increased from the first backfill might look like this: This means when the user is passed to the second backfill, their number of followers in the user stats table will decrement by 10,324. Similar to the initial backfill, this one goes through the same workflow. For this backfill, the user_id , number_of_followers , and number_of_followees are sent as a message, and the processor will take the three fields and update the user stats table . Again, we used existing code that would update the table with the delta. We made sure there were no follow-up callbacks this time around. With the completion of the second backfill, all numbers on a user‚Äôs profile now properly reflect their relationship with other users. The main learnings from this: Thoroughly look through your code to make sure your intent is going to be executed. Save the data prior to the backfill as a keepsake of your adventures (and in case anything goes awry). Double check that your backfill fixed/completed the data as intended. Go through your draft; check your code. Double check that your intent is clear and well executed. If the existing function putUserRelationship was not used the way it did, the false increase in the user stats table would not have happened (beware of callbacks!) and the second backfill would not have been warranted. Save the shitty first draft, the data prior to the backfill. This data is what you worked from and what you‚Äôre trying to improve. Keeping it for after the backfill completion allows for data comparison; we want to make sure all the rows in the first draft are modified after the backfill. With our backfill endeavor, the initial data would have been helpful with the second backfill and to calculate the difference without pulling in data from the user stats table . Do a final look through; make sure the backfill has completed/fixed the data as intended. One reason we had to run the backfill that conked the numbers was because the initial backfill to complete the ‚Äúnew column‚Äù latest_followed_at was incomplete. There were some relationships where the latest_followed_at column did not properly reflect the aggregation of the other timestamp columns. Treat your backfill like you do your Medium posts: Write, check, save, and check one last time. Make sure to hit the ‚Äúfollow‚Äù button and watch the logic in action. 431 2 Thanks to Mopewa , Laura Godinez , Penny Shen , and Alaina Kafkes . 431 431 2 Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2020-12-16"},
{"website": "Medium-Engineering", "title": "code2040 2019 offsite", "author": ["Miranda Durham"], "link": "https://medium.engineering/code2040-2019-offsite-236768037357", "abstract": "Sign in Miranda Durham Aug 26, 2019 ¬∑ 2 min read It was a BIG day. Our CODE2040 crew left the office for a day of adventure! Only one of us had ever truly experienced a segway before. Some of us excelled, some of us were terrified, and all of us bonded. We met in Oakland on Skyline Blvd. and took time getting ac c limated by cautiously moving about a parking lot. After settling into our new two-wheelers, we cruised around looking at views and dodging branches until we made it to the Chabot Space and Science Center. Some kids at the summer camp yelled some things at us, and we were on our way. A couple of hours rolling through the redwoods had us exhausted. Luckily, Miles had booked a ramen+mochi class at Kaori‚Äôs Kitchen . It‚Äôs the 7th week of our 10-week internship program, and we‚Äôll be sad to see the 2019 internship program end. Misiel, Aleida, and Chris ‚Äî we‚Äôll remember this summer always! ebp @Medium // in the hangout 223 1 223 223 1 Internships Code2040 Engineering Team Building Fun Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2019-08-26"},
{"website": "Medium-Engineering", "title": "graphql medium tech talk videos", "author": ["Sasha Solomon"], "link": "https://medium.engineering/graphql-medium-tech-talk-videos-a4812932abf3", "abstract": "Sign in Sasha Solomon Oct 31, 2018 ¬∑ 1 min read Last week, Medium hosted our first ever GraphQL Tech Talks! Thank you to everyone who attended! It was great being about to share what we‚Äôve learned and chat with the GraphQL community. üéâ For those who weren‚Äôt able to attend, we have good news. We were able to get videos of all of the talks! üò± üìπ üó£ Here they are. Enjoy! software engineer @twitter, previously @medium. doing scala + graphql. pokemon gym leader. potato compatible. @sachee 348 1 348 348 1 GraphQL Apollo React Android Software Engineering Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2018-10-31"},
{"website": "Medium-Engineering", "title": "engineering growth at medium", "author": ["Medium Engineering"], "link": "https://medium.engineering/engineering-growth-at-medium-4935b3234d25", "abstract": "Sign in Medium Engineering Jul 1, 2019 ¬∑ 3 min read Over the years, Medium Engineering (in partnership with our People Operations team) worked to improve the process to evaluate our engineers growth and their impact on the organization. We‚Äôve shared some of our thinking and approach to this process in the past, and are happy to hear that other companies are using their own adaptations of this model! As we continue to learn, we are now on our third iteration of this process, and are excited to share with this community some key takeaways. At its core, our mission at Medium is to build the best possible product, so while we won‚Äôt be updating this post with each new iteration of our growth framework, we are still engaged in conversations about what it means to grow as an engineer, what increasing scope looks like for different kinds of leaders, and how we can be fair in our evaluation strategy. The bullets below give an overview of how we are trying to continuously improve our process so that we can build a robust, flexible, and inclusive team: Focus on describing behaviors you can observe, teach, and evaluate in your rubric criteria. Conversations about growth and impact should be ongoing, and no one should be surprised by information communicated at the time of their assessment. Studies have shown that the positive feelings associated with getting a raise are only temporary, and that long term satisfaction is much more closely tied to personal development. This is another reason why we have chosen to frame our conversations around growth. We value a growth mindset , and are intentional about this being reflected in our rubric Traditional methods of assessing people, and often the language that is used to describe them ‚Äî ladders, slots, boxes, etc. ‚Äî are primarily concerned with giving someone a level or categorizing them in some way. We instead craft a framework that centers around the growth of an individual, and supports them in the kind of career that they both want to have and that also benefits the business. Therefore, we talk about what others may call a performance assessment in a way that anchors on growth and uses a tool (the rubric) to define how to progress, and how we measure and reward that progress. A key measure of success for any assessment system is whether it treats employees equitably, and rewards their work appropriately, regardless of race, gender, age, or any other personal identifiable indicator. A strong rubric will incentivize the kinds of behaviors that we want to see in the team, and recognize the different kinds of value that people add. It‚Äôs important to connect hiring and growth progression to our company values, so we hire, incentivize, and reward what we value throughout the employee lifecycle. There are many paths to a successful career, and diverse experiences and strengths together make for a robust and flexible team. Titles typically serve three purposes ‚Äî helping people understand that they are progressing, vesting authority in those people who might not automatically receive it, and communicating an expected competency level to the outside world. Execution: The best idea in the world is worthless without great execution. Delivering great software products in teams requires rallying people behind an idea, strong technical leadership throughout the project, a focus on quality, and excellent communication to keep everyone aligned. Management: Effective, formal people management is crucial to getting the most out of a team, building for the future, and providing stability during organizational change. Ideally, we would have a completely objective rubric, with simple Yes/No decisions made about clear, concrete tasks. This isn‚Äôt really possible, but it‚Äôs important to get as close as possible. Of course, subjectivity invites the possibility, and likelihood, of bias so an effort needs to be made to ensure the rubric is applied as evenly and fairly as possible. How do you capture communication objectively? How do you capture selflessness? We base our criteria on scopes of influence, which help paint a picture of how a specific skill can grow over time to impact more people or more surfaces. We have learned so much going through this process, and want to thank our community for their questions and conversation on this topic! We are the @Medium engineering team 563 6 563 563 6 Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2019-07-01"},
{"website": "Medium-Engineering", "title": "graphql medium tech talks", "author": ["Sasha Solomon"], "link": "https://medium.engineering/graphql-medium-tech-talks-f1d1b34399da", "abstract": "Sign in Sasha Solomon Oct 19, 2018 ¬∑ 2 min read Medium has been working with GraphQL for over a year now! We‚Äôve built out our GraphQL server on top of our existing backend in such a way that, with the help of Protocol Buffers, we have been able to make progress migrating to React.js and a service oriented architecture without hindering product development! üßÄ üçá 6:00pm ‚Äî 6:30pm ~ snacks + chatting üë©‚Äçüíª üë®‚Äçüíª 6:30pm ‚Äî 8:00pm ~ tech talks ü§î üëã 8:00pm ‚Äî 8:30pm ~ closing, questions, + chatting Here‚Äôs a bit more about the talks and our speakers! üó£ Jon is an Engineering Manager and a software engineer at Medium. He‚Äôs been working on the Platforms team helping bring Medium‚Äôs web client to the future with Apollo, React.js, and his expert knowledge of Medium‚Äôs internals. Sasha is a Team Lead and software engineer at Medium. She‚Äôs been working on the Platforms team building Medium‚Äôs GraphQL server and helping migrate Medium to GraphQL and a service oriented architecture. Most recently, she spoke at GraphQL Europe about Medium‚Äôs migration and will be speaking at Scale by the Bay in November. Dan is a lead engineer on the mobile team at Medium specializing in Android development. He‚Äôs been at the forefront of migrating Android to GraphQL and helping the mobile team move forward with code generation and reactive programming. software engineer @twitter, previously @medium. doing scala + graphql. pokemon gym leader. potato compatible. @sachee 620 2 620 620 2 GraphQL Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2018-10-19"},
{"website": "Medium-Engineering", "title": "graphql server design medium", "author": ["Sasha Solomon"], "link": "https://medium.engineering/graphql-server-design-medium-34862677b4b8", "abstract": "Sign in Sasha Solomon Nov 2, 2018 ¬∑ 4 min read A while ago, we told the story of how we are migrating to React.js and a service oriented architecture with the help of GraphQL . Now, we want to tell the story of how the structure of our GraphQL server helped make our migration much smoother. We had three things in mind when we began designing our GraphQL server: It should be easy to alter the shape of th e data We currently use protocol buffers as a schema for data that comes from our backend. However, the way we use our data has changed over time, but our protobufs haven‚Äôt caught up. This means that our data isn‚Äôt always the shape that the clients need. It should be clear what data is for the client Within our GraphQL server, data is being passed around and exists in different stages of ‚Äúreadiness‚Äù for the client. Instead of mixing the stages together, we wanted to make the stages of readiness explicit so we know exactly what data is meant for the client. It should be easy to add new data sources Since we are moving to a service oriented architecture, we wanted to make sure it was easy to add new data sources to our GraphQL server, and make it explicit where data comes from. With these things in mind, we came up with a server structure that had three distinct roles: Fetchers, Repositories (Repos), and the GraphQL Schema. Each layer has it‚Äôs own responsibilities, and only interacts with the layer above it. Let‚Äôs talk about what each layer does specifically. Fetchers are for fetching data from data sources. The data that is fetched by the GraphQL server should already have gone through any business logic additions or changes. Fetchers should correspond to a REST or preferably a gRPC endpoint. Fetchers require a protobuf. This means that any data that is being fetched by a Fetcher must follow the schema defined by the protobuf. Repos are what the GraphQL schemas will use as a data representation. The repo ‚Äústores‚Äù the cleaned-up data that originally came from our data sources. In this step, we hoist up and flatten fields and objects, move data around, etc. to change the data shape to be what the client actually needs. This step is necessary for moving from a legacy system because it gives us the freedom to update the data shape for the client without having to update or add endpoints or their corresponding protobufs. Repos only access data retrieved from Fetchers and never actually fetch the data themselves. To put it another way, Repos only create the shape of the data we want, but they don‚Äôt ‚Äúknow‚Äù where we get the data from. The GraphQL Schema is the form our data will take when it gets sent to the clients. The GraphQL schema only uses data from Repos and will never access Fetchers directly. This keeps our separation of concerns clear. In addition, our GraphQL schema is completely derived from our Repo objects. The schema doesn‚Äôt alter the data at all, nor does it need to: the Repo has already changed the shape of the data to be what we need, so the schema just needs to use it and that‚Äôs it. In this way, there isn‚Äôt confusion about what the data shape is or where we can manipulate the shape. The data‚Äôs shape becomes more like what the client needs as it passes through each of the distinct layers. It‚Äôs clear where the data comes from at each step and we know what each piece of the server is responsible for. These abstraction boundaries mean that we can incrementally migrate our legacy system by replacing different data sources, but without rewriting our entire system. This has made our migration path clear and easy to follow and makes it easy to work towards our service oriented architecture without changing everything at once. software engineer @twitter, previously @medium. doing scala + graphql. pokemon gym leader. potato compatible. @sachee 1.7K 5 1.7K 1.7K 5 GraphQL Microservice Architecture Infrastructure Software Engineering Microservices Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2018-11-02"},
{"website": "Medium-Engineering", "title": "microservice architecture at medium", "author": ["Xiao Ma"], "link": "https://medium.engineering/microservice-architecture-at-medium-9c33805eb74f", "abstract": "Sign in Xiao Ma Oct 17, 2018 ¬∑ 16 min read The goal of microservice¬π architecture is to help engineering teams ship products faster, safer, and with higher quality. Decoupled services allow teams to iterate quickly and with minimal impact to the rest of the system. At Medium, our technical stack started with a monolithic Node.js a pp back in 2012. We have built a couple of satellite services, but we haven‚Äôt created a strategy to adopt the microservice architecture systematically. As the system becomes more complex and the team grows, we moved to a microservice architecture in early 2018. In this post, we want to share our experiences of doing it effectively and avoiding microservice syndromes. First of all, let‚Äôs take a moment to think about what microservice architecture is and is not. ‚ÄúMicroservice‚Äù is one of those overloaded and confusing software engineering trends. This is what we at Medium think what it is: In microservice architecture, multiple loosely coupled services work together. Each service focuses on a single purpose and has a high cohesion of related behaviors and data. This definition includes three microservice design principles: Single purpose ‚Äî each service should focus on one single purpose and do it well. Loose coupling ‚Äî services know little about each other. A change to one service should not require changing the others. Communication between services should happen only through public service interfaces. High cohesion ‚Äî each service encapsulates all related behaviors and data together. If we need to build a new feature, all the changes should be localized to just one single service. When we model microservices, we should be disciplined across all three design principles. It is the only way to achieve the full potential of the microservice architecture. Missing any one of them would become an anti-pattern. Without a single purpose, each microservice would end up doing too many things, growing as multiple ‚Äúmonolithic‚Äù services. We will not get the full benefits of the microservice architecture and we pay the operational cost. Without loose coupling, changes to one service affect other services, so we would not be able to release changes fast and safely, which is the core benefit of microservice architecture. More importantly, issues caused by tight coupling could be disastrous, e.g., data inconsistencies or even data loss. Without high cohesion, we will end up with a distributed monolithic system ‚Äî a messy set of services that have to be changed and deployed at the same time in order to build a single feature. A distributed monolithic system is often much worse than a centralized monolithic system because of the complexity and cost of coordination of multiple services, sometimes across multiple teams. In the meantime, it‚Äôs also important to realize what a microservice is not : A microservice is not a service that has a small number of lines of code or does ‚Äúmicro‚Äù tasks. This misconception comes from the name ‚Äú micro service‚Äù. The goal of the microservice architecture is not to have as many small services as possible. Services could be complex and substantial as long as they meet the above three principles. A microservice is not a service that is built with new technology all the time. Even though the microservice architecture allows teams to test new technology more easily, it is not the primary goal of microservice architecture. It is totally fine to build new services with the exact same technology stack, as long as the team benefits from decoupled services. A microservice is not a service that has to be built from scratch. When you have a well-architected monolithic app already, avoid getting into the habit to build every new service from scratch. There might be opportunities to extract the logic from the monolithic service directly. Again, the above three principles should still hold. At Medium, we always ask the question of ‚ÄúWhy now?‚Äù when making big product or engineering decisions. ‚ÄúWhy?‚Äù is an obvious question to ask, but it assumes we have unlimited people, time and resources, which is a dangerous assumption. When you think about ‚ÄúWhy now?‚Äù, you suddenly have a lot more constraints ‚Äî impact to the current work, opportunity cost, overhead of distraction, etc. This question helps us prioritize better. The reason why we need to adopt microservice now is that our Node.js monolithic app has become a bottleneck, in multiple ways. First of all, the most urgent and important bottleneck is its performance. Certain tasks that are computational heavy and I/O heavy are not a good fit for Node.js. We have been incrementally improving the monolithic app, but it has proved to be ineffective. Its inferior performance prevents us from delivering better products without making the already-very-slow app a lot slower. Secondly, an important and somewhat urgent bottleneck of the monolithic app is that it slows down the product development. Since all the engineers build features in the single app, they are often tightly coupled. We can‚Äôt make nimble moves to change one part of the system because it may affect other parts as well. We are also afraid of making big changes because the impact is too big and sometimes hard to predict. The entire app is deployed as a whole, so if deployment is stalled because of one bad commit, all the other changes, even if they work perfectly fine, cannot go out. In contrast, a microservice architecture allows teams to ship, learn and iterate much faster. They can focus on the features they are building that are decoupled from the rest of the complex system. Changes can get to production much faster. They have the flexibility to try out big changes safely. In our new microservice architecture, changes go out to production within an hour and engineers don‚Äôt worry about how it may affect other parts of the system. The team also explores ways to safely use production data in development¬≤, which has been a daydream for many years. All of these are especially important as our engineering team grows. Thirdly, the monolithic app makes it difficult to scale up the system for particular tasks or isolate resource concerns for different types of tasks. With the single monolithic app, we have to scale up and down the entire system for the more resource-hungry tasks even though it means the system is over-provisioned for other much simpler tasks. To alleviate these issues, we shard different types of requests to separate Node.js processes. They work to a certain extent, but won‚Äôt scale because, again, these micro-versions-of-the-monolithic-service are tightly coupled. Last but not least, an important and soon-to-be urgent bottleneck is that it prevents us from trying out new technology. One major advantage of the microservice architecture is that each service can be built with different tech stacks and integrated with different technologies. This allows us to pick the best tool for the job, and more importantly, do so in a fast and safe way. Adopting the microservice architecture is not trivial. It could go awry and actually hurt engineering productivity. In this section, we will share seven strategies that helped us in the early stage of adoption: Build new services with clear value Monolithic persistent storage considered harmful Decouple ‚Äúbuilding a service‚Äù and ‚Äúrunning services‚Äù Thorough and consistent observability Not every new service needs to be built from scratch Respect failures because they will happen Avoid ‚Äúmicroservice syndromes‚Äù from day one One may think adopting a new server architecture means a long pause of product development and a massive rewrite of everything. This is the wrong approach. We should never build new services for the sake of building new services. Every time we build a new service or adopt a new technology, there must be clear product value and/or engineering value. Product value should be represented by benefits we can deliver to our users. A new service is required to make it possible to deliver the values or make it faster to deliver the values compared to building it in the monolithic Node.js app. Engineering value should make the engineering team better and faster. If building a new service does not have either product value or engineering value, we leave it in the monolithic app. It is totally fine if in ten years Medium still has a monolithic Node.js app that supports some surfaces. Starting with a monolithic app actually helps us model the microservices strategically. A big part of modeling microservices is to model their persistent data storage (e.g., databases). Sharing persistent data storage across services often appears to be the easiest way to integrate microservices together, however, it is actually detrimental and we should avoid it at all cost. Here is why. First of all, persistent data storage is about implementation details. Sharing data storage across services exposes the implementation details of one service to the entire system. If that service changes the format of the data, or adds caching layers, or switches to different types of databases, many other services have to be changed accordingly as well. This violates the principle of loose coupling . Secondly, persistent data storage is not service behaviors, i.e., how to modify, interpret and use the data. If we share data storage across services, it means other services also have to replicate service behaviors. This violates the principle of high cohesion ‚Äî behaviors in a given domain are leaked to multiple services. If we modify one behavior, we will have to modify all of these services together. In microservice architecture, only one service should be responsible for a specific type of data. All the other services should either request the data through the API of the responsible service or keep a read-only non-canonical (maybe materialized) copy of the data. This may sound abstract, so here is a concrete example. Say we are building a new recommendation service and it needs some data from the canonical post table, currently in AWS DynamoDB. We could make the post data available for the new recommendation service in one of two ways. In the monolithic storage model, the recommendation service has direct access to the same persistent storage that the monolithic app does. This is a bad idea because: Caching can be tricky. If the recommendation service shares the same cache as the monolithic app, we will have to duplicate the cache implementation details in the recommendation service as well; if the recommendation service uses its own cache, we won‚Äôt know when to invalidate its cache when the monolithic app updates the post data. If the monolithic app decides to change to use RDS instead of DynamoDB to store post data, we will have to reimplement the logic in the recommendation service and all other services that access the post data as well. The monolithic app has complex logic to interpret the post data, e.g., how to decide if a post should not be viewable to a given user. We have to reimplement those logics in the recommendation service. Once the monolithic app changes or adds new logics, we need to make the same changes everywhere as well. The recommendation service is stuck with DynamoDB even if it is the wrong option for its own data access pattern. In the decoupled storage model, the recommendation service does not have direct access to the post data, neither do any other new services. The implementation details of post data are retained in only one service. There are different ways of achieving this. Ideally, there should be a Post Service that owns the post data and other services can only access post data through the Post Service‚Äôs APIs. However, it could be an expensive upfront investment to build new services for all core data models. There are a couple of more pragmatic ways when staffing is limited. They could be actually better ways depending on the data access pattern. In Option B, the monolithic app lets the recommendation services know when relevant post data is updated. Usually, this doesn‚Äôt have to happen immediately, so we can offload it to the queuing system. In Option C, an ETL pipeline generates a read-only copy of the post data for the recommendation service, plus potentially other data that is useful for recommendations as well. In both options, the recommendation service owns its data completely, so it has the flexibility to cache the data or use whatever database technologies that fit the best. If building microservices is hard, running services is often even harder. It slows the engineering teams down when running services is coupled with building each service and teams have to keep reinventing the ways of doing it. We want to let each service focus on its own work and not worry about the complex matter of how to run service s , including networking, communication protocols, deployment, observability, etc. The service management should be completely decoupled from each individual service‚Äôs implementation. The strategy of decoupling ‚Äúbuilding a service‚Äù and ‚Äúrunning services‚Äù is to make running-services tasks service-technology-agnostic and opinionated, so that app engineers can fully focus on each service‚Äôs own business logic. Thanks to the recent technology advancements in containerization, container-orchestration, service mesh, application performance monitoring, etc, the decoupling of ‚Äúrunning service‚Äù becomes more achievable than ever. Networking. Networking (e.g., service discovery, routing, load balancing, traffic routing, etc) is a critical part of running service s . The traditional approach is to provide libraries for every platform/language. It works but is not ideal because applications still need a non-trivial amount of work to integrate and maintain the libraries. More often than not, applications still need to implement some of the logic separately. The modern solution is to run services in a Service Mesh. At Medium, we use Istio and Envoy as sidecar proxy. Application engineers who build services don‚Äôt need to worry about the networking at all. Communication Protocol . No matter which tech stacks or languages you choose to build microservices, it is extremely important to start with a mature RPC solution that is efficient, typed, cross-platform and requires the minimum amount of development overhead. RPC solutions that support backward-compatibility also make it safer to deploy services even with dependencies among them. At Medium, we chose gRPC . A common alternative is REST+JSON over HTTP, which has been the blessed solution for server communication for a long time. However, although that stack is great for the browsers to talk to servers, it is inefficient for server-to-server communication, especially when we need to send a large number of requests. Without automatically generated stubs and boilerplate code, we will have to manually implement the server/client code. Reliable RPC implementation is more than just wrapping a network client. In addition, REST is ‚Äúopinionated‚Äù, but it can be difficult to always get everyone to agree on every detail, e.g., is this call really REST, or just an RPC? Is this thing a resource or is it an operation? etc. Deployment . Having a consistent way to build, test, package, deploy and manage services is very important. All of Medium‚Äôs microservices run in containers. Currently, our orchestration system is a mix of AWS ECS and Kubernetes, but moving towards Kubernetes only. We built our own system to build, test, package and deploy services, called BBFD. It strikes a balance between working consistently across services and giving individual service the flexibility of adopting different technology stack. The way it works is it lets each service provide the basic information, e.g., the port to listen to, the commands to build/test/start the service, etc., and BBFD will take care of the rest. Observability includes the processes, conventions, and tooling that let us understand how the system is working and triage issues when it isn‚Äôt working. Observability includes logging, performance tracking, metrics, dashboards, alerting, and is super critical for the microservice architecture to succeed. When we move from one single service to a distributed system with many services, two things can happen: We lose observability because it becomes harder to do or easier to be overlooked. Different teams reinvent the wheel and we end up with fragmented observability, which is essentially low observability because it is hard to use fragmented data to connect the dots or triage any issues. It is very important to have good and consistent observability from the beginning, so our DevOps team came up with a strategy for consistent observability and built tools in support of achieving that. Every service gets detailed DataDog dashboards, alerts, and log search automatically, which are also consistent across all services. We also heavily use LightStep to understand the performance of the systems. In microservice architecture, each service does one thing and does it really well. Notice that it has nothing to do with how to build a service. If you migrate from a monolithic service, keep in mind that a microservice doesn‚Äôt always have to be built from scratch if you can peel it off from the monolithic app. Here we take a pragmatic approach. Whether we should build a service from scratch depends on two factors: (1) how well Node.js is suited for the task and (2) how much it costs to reimplement in a different tech stack. If Node.js is a good technical option and the existing implementation is in a good shape, we peel the code off from the monolithic app and create a microservice with it. Even with the same implementation, we will still get all the benefits of microservice architecture. Our monolithic Node.js monolithic app was architected in a way that make it relatively easy for us to build separate services with the existing implementation. We will discuss how to properly architect a monolithic later in this post. In a distributed environment, more things can fail, and they will. Failures of mission-critical services, when not handled well, could be catastrophic. We should always think about how to test failures and gracefully handle failures. First and foremost, we should expect everything will fail at some point. For RPC calls, put extra effort to handle failure cases. Make sure we have good observability (mentioned above) to failures when they happen. Always test failures when bringing a new service online. It should be part of the new service check-list. Build auto-recovery if possible. Microservice is not a panacea ‚Äî it solves some problems, but creates some others, which we call ‚Äú microservice syndromes ‚Äù. If we don‚Äôt think about them from day one, things can get messy fast and it costs more if we take care of them later. Here are some of the common symptoms. Poorly modeled microservices cause more harm than good, especially when you have more than a couple of them. Allow too many different choices of languages/technology, which increase the operational cost and fragment the engineering organization. Couple running services with building services, which dramatically increases the complexity of each service and slow the team down. Overlook data modeling and end up with microservices with monolithic data storage. Lack of observability, which makes it difficult to triage performance issues or failures. When facing a problem, teams tend to create a new service instead of fixing the existing one even though the latter may be a better option. Even though the services are loosely coupled, lack of a holistic picture of the whole system could be problematic. With recent technology innovations, it is a lot easier to adopt the microservice architecture. Does it mean that we should all stop building monolithic services? No. Even though it is much better supported by new technologies, microservice architecture still involves a high level of complexity and complication. For small teams to start, a monolithic app is still often a better option. However, do spend the time to architect the monolithic app in a way that is easier to migrate to a microservice architecture later when the system and the team grow. It is fine to start with a monolithic architecture, but make sure to modularize it and architect it with the above three microservice principles (single purpose, loose coupling and high cohesion), except that the ‚Äúservices‚Äù are implemented in the same tech stack, deployed together and run in the same process. At Medium, we made some good architecture decisions early on for the monolithic app. Our monolithic app was highly modularized by component, even though it has grown into a very complex app with the web server, backend services, and an offline event processor. The offline event processor runs separately but with the exact same code. This makes it relatively easy to peel off a chunk of business logic to a separate service, as long as the new service provides the same (high-level) interface as the original implementations. Our monolithic app encapsulated data storage details at the lower levels. Each data type (e.g., a database table) has two layers of implementation: data layer and service layer . The data layer handles CRUD operations to one specific type of data. The service layer handles the high-level logic of one specific type of data and provides public APIs to the rest of the system. Services don‚Äôt share data store between them. This helps us adopt microservice architecture because implementation details of one type of data are completely hidden from the rest of the code base. Creating a new service to handle certain types of data is relatively easy and safe. The monolithic app also helps us model microservices and gives us the flexibility to focus on the most important parts of the system, instead of modeling all the microservices for everything from the ground up. The monolithic Node.js app served us well for several years, but it started slowing us down from shipping great projects and iterating quickly. We started to systematically and strategically adopt the microservice architecture. We are still in the early stage of this journey, but we have already seen its benefit and potential ‚Äî it dramatically increased the development productivity, allowed us to think big and make substantial product improvement, and unlocked the engineering team to safely test new technologies. It is an exciting time to join Medium‚Äôs engineering team. If this sounds interesting to you, please take a look at our job page ‚Äî Work at Medium . If you‚Äôre particularly passionate about microservice architecture, you may want to take a look at these two openings first: Senior Full Stack Engineer and Senior Platform Engineer . Thanks for reading. Drop us a message if you have questions or want to discuss more how we started adopting the microservice architecture. The original version of this post was published on Hatch, our internal version of Medium. Thanks to Kyle Mahan , Eduardo Ramirez , Victor Alor , sachee , Lyra Naeseth , Dan Benson , Bob Corsaro , Julie Russell , and Alaina Kafkes for their feedback to the draft. ¬π In this post, we will use the word ‚Äúmicroservice‚Äù in two ways, (1) referring to microservice architecture and (2) referring to one service in microservice architecture. ¬≤ Accessing production data in development is a double-edged sword. It is definitely debatable, but it is very powerful if we can do it safely. To be clear, we don‚Äôt test with other users‚Äô data. Engineers only use their own accounts. We take user‚Äôs privacy very seriously at Medium. Chief Architect @Medium. Serving Engineers. Teaching Machines. The ultimate goal of tech is to help us live better. Built @PatternInsight PhD @IllinoisCS UCSD 15K 51 Thanks to Alaina Kafkes , Julie Russell , Kyle Mahan , and Dan Benson . 15K 15K 51 Microservices Infrastructure Software Engineering Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2018-10-19"},
{"website": "Medium-Engineering", "title": "fred and rabbit a cautionary tale about passwords", "author": ["Julie Russell"], "link": "https://medium.engineering/fred-and-rabbit-a-cautionary-tale-about-passwords-51429157117d", "abstract": "Sign in Julie Russell Apr 10, 2018 ¬∑ 3 min read A post for engineers and the technically astute to share with less technical friends and family, brought to you by the Department of Technical Comfort & Security at Medium (previously known as IT). One day, Rabbit frantically hopped over to his friend Fred. Rabbit‚Äôs ears were sticking straight up in alarm, ‚ÄúFred! I just got an email that there was suspicious activity on my RoughageAndMore.bun account! What do I do?‚Äù Fred puffs up a bit and says, ‚ÄúIt‚Äôs okay Rabbit, we can figure this out. Have you changed your password on RoughageAndMore.bun yet?‚Äù ‚ÄúNo! Sh o uld I do that now? My password is carrot1 *. What should I change it to? How will I remember my new password if it‚Äôs not carrot1 ?‚Äù Fred thinks for a moment, his beak twisting to the side, ‚ÄúRabbit, are you using this password on all of your websites? Even your BunMail and HutchBank accounts?‚Äù ‚ÄúYes! But how will I remember RoughageAndMore.bun if it has a different password?‚Äù ‚ÄúRabbit, it‚Äôs a big risk to use the same password on all of your web accounts. HutchBank and other companies do what they can to prevent BadCharacters unauthorized attacks on their systems, but it‚Äôs possible that any website‚Äôs password database could be compromised.‚Äù ‚ÄúFred, that‚Äôs scary! What can I do?‚Äù ‚ÄúI use a password vault, Rabbit. I use the password generator in the vault application to create a different complex password for every website. I only have to remember one password ‚Äî the one to the password vault.‚Äù ‚ÄúFred that sounds amazing! Can it be that easy?‚Äù ‚ÄúIt‚Äôs pretty easy once you get used to using it. And even if it‚Äôs a couple more steps, I know that even if a BadCharacter breaks into the password database of one site, that they don‚Äôt have my password to all the others I use. Then when I get an email of suspicious activity on one account ‚Äî like RoughageAndMore.bun, I just need to change the password on that account.‚Äù ‚ÄúFred, I‚Äôm so excited! Can you help me setup a password vault now?‚Äù ‚ÄúI‚Äôd love to, Rabbit.‚Äù They waited while the application downloaded and installed on Rabbit‚Äôs Carrotosh computer. ‚ÄúIt‚Äôs installed! Now what?‚Äù ‚ÄúChoose a complex password for the vault.‚Äù ‚ÄúCan I use carrot1 ? It‚Äôs complex, right, since it has a number in it?‚Äù Fred shook his head no, the feathers on the back of his neck ruffling slightly. ‚ÄúRabbit, carrot1 is easy for an experienced BadCharacter to guess. It‚Äôs a dictionary word, it‚Äôs all lowercase, and it has a single number.‚Äù Fred was silent for a moment, looking up to the left. ‚ÄúI have an idea. What is your favorite song?‚Äù Rabbit blushes, ‚ÄúAll the single rabbits!‚Äù ‚ÄúGreat! Let‚Äôs use that as your password!‚Äù ‚ÄúPasswords can have spaces?‚Äù ‚ÄúYes!‚Äù ‚ÄúAnd this is hard to guess?‚Äù ‚ÄúIt‚Äôs much harder to guess than carrot1 !‚Äù A half hour later, Rabbit had changed his passwords on his most important sites with his credit card and bank information, and of course, RoughageAndMore.com. All of them were unique and 15 or more characters, including special characters, numbers, and upper and lower case letters. ‚ÄúRabbit, the hard part is done. Next, as you go to each website you visit, logon and then use the password generator to create a new, unique password. Your password vault will save the list for you.‚Äù Next Fred showed Rabbit how to backup the password vault to the file backup service, FileBurrow.bun. ‚ÄúFred, thank you so much!‚Äù Rabbit relaxed his shoulders and sighed, his ears relaxing beside his head. ‚ÄúI wonder though ‚Ä¶‚Äù ‚ÄúWhat, Rabbit?‚Äù ‚ÄúWhen will my delivery of cabbage arrive? I wanted to make that for dinner tonight.‚Äù Do you care about security? We do too. Come work with us ! *Not Rabbit‚Äôs actual password. Please do not post your passwords on the Internet. Board Member of NaNoWriMo nonprofit, member of Alabama Street Writers‚Äô Group, & Engineering Manager at Medium. Opinions are all and always mine. 411 1 411 411 1 Security Medium Engineering Password Security Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2018-04-12"},
{"website": "Medium-Engineering", "title": "improving ios intangibles with tactical", "author": ["Alaina Kafkes"], "link": "https://medium.engineering/improving-ios-intangibles-with-tactical-f744fbff033e", "abstract": "Sign in Alaina Kafkes 6 days ago ¬∑ 8 min read In the days of lore and legend that precede my employment, Medium operated under the decentralized organizational philosophy of holocracy . Though leadership has long since shifted to a more hierarchical structure, vestiges of holocracy lurk in unexpected places. One such remnant is iOS tactical , a (bi)weekly gathering of iO S engineers (for more details, jump to ‚ÄúWhat‚Äôs in a tactical?‚Äù). Despite its arcane origins, tactical is by no means obsolete: it remains instrumental to building and maintaining a high-quality app, codebase, and developer experience. I believe that any organization ‚Äî even one without holocratic origins‚Äîwould reap the same benefits from investing in regular role-specific tacticals. Why round up all of the iOS engineers to chat? Since we‚Äôre so few in number at most companies, we tend to get fractured across multiple product teams. Team fissures foment communication fissures, which cause important intangibles ‚Äî a cohesive user experience, a newcomer-friendly codebase, et cetera ‚Äî to fall through the cracks. Tacticals shield products and interpersonal connections from atrophy. I aim to demonstrate how engineering organizations can harness iOS (or other role-specific) tacticals in order to advocate for and actualize improvements to their app and day-to-day work. To start, I‚Äôll outline the format of the tactical I run at Medium. I‚Äôll then share three anecdotes that showcase how tactical effected real change. I‚Äôll also expound upon how tactical helps distributed teams foster the greatest intangible of all: community. The tactical explainer on the holocracy website raises more questions than it answers, so I‚Äôll start to explain the iOS tactical I run at Medium with what the iOS engineers actually do during it: We share high-level details about our work. We ask questions and seek help. We make others aware of pain points. We announce cool things that we‚Äôd like the team to know about. We propose ideas and solicit advocates and collaborators. We commit to taking action before the next tactical. Addressing these needs in an ad hoc manner may seem good enough, but regular tactical-prompted reflection bands iOS engineers together with the intention/attention needed to foster and sustain a better user, developer, and iOS community experience. How does a typical tactical play out? I facilitate them using the following meeting template: I kick things off with a two-part check-in , equal parts ‚Äúwhat‚Äôs up?‚Äù and ‚Äúwhat are you working on?‚Äù We use check-ins to better orient our team-and-pandemic-siloed selves in the Medium iOS universe, proactively identifying areas of potential conflict or collaboration. I ensure that every iOS engineer speaks during the check-in in the hopes that, once they‚Äôve broken the verbal ice, they‚Äôll feel more comfortable voicing their ideas throughout the meeting. We continue to set context by taking a look at our latest crash reports, backlog of iOS-specific technical stories , and relevant company dashboards. I file the top crash as a bug in Jira so that product managers can prioritize and assign it accordingly. We review the action items ‚Äî tasks that one or more iOS engineer(s) said they‚Äôd like to work on ‚Äî recorded during the last tactical. Were they all completed, and, if not, are they still relevant? We whittle down the list and copy outstanding actions over to the current tactical‚Äôs notes. I then segue the meeting into a discussion-oriented phase. I gather my teammates‚Äô tensions , short phrasal representations of things that they wish to talk about with the greater group. Tensions tend to tie into one of the bullet points that I listed earlier: Is some class in dire need of a refactor? Did someone learn a cool new functional programming trick? Should we drop support for an old iOS version? Each of these questions merits a tension. Tensions can be compiled by verbally cycling through participants and asking whether they‚Äôd like to share a tension or pass, or by setting aside time for us all to type our own tensions in a shared document. In either tension-collecting process, I aim to mitigate the potential fear of being the first or only person to voice opinions. We talk through tensions one at a time. I cede the (cyber)floor to the tension‚Äôs author and try to shepherd the ensuing discourse so that it culminates in an action item. Not all tensions lead to action items and that‚Äôs fine! But the action items that do arise via group discussion give us all a greater stake in the stewardship of Medium iOS. We conclude the meeting with a check-out . Like check-ins, check-outs grant everyone the opportunity to speak up, but with a different focal question: ‚Äúhow‚Äôd this meeting go?‚Äù Sometimes check-outs devolve into unrelated chatter, which is perfectly okay: tacticals are as much about team-building as the user-facing product. Now that I‚Äôve synopsized the tactical‚Äôs raison d‚Äô√™tre and sketched out its format, I‚Äôll share a few positive outcomes from the iOS tacticals I‚Äôve led at Medium. A new iOS engineer at Medium rolled into their first tactical with fresh-eyed perspective: it‚Äôs 2019 ‚Äî why weren‚Äôt we writing more Swift? This gave us Medium veterans pause ‚Äî why weren‚Äôt we writing more Swift? ‚Äî and pushed us to plan for a more Swift-forward developer experience. We committed as a collective to write all new classes, protocols, structs, and other types in Swift. A few weeks later, another engineer suggested that we use Swiftify , a service that converts Objective-C code into Swift code, to speed up the migration. Despite initial hesitation, we moved forward with Swiftify with the caveat that, since Objective-C patterns do not always align with Swift idioms, we‚Äôd have to audit our Swiftified changes individually and through the pull request review process. We all volunteered for another shared action item: convert one or more short (around or less than 150 lines of code) Objective-C files to Swift using Swiftify. We also updated tactical itself to better suit the needs of our Swift migration period. We tacked on an additional question to the check-in: ‚Äúhave you rewritten any noteworthy files in Swift?‚Äù One engineer wrote a script that compared the number of lines of Objective-C and Swift code in our codebase, and generated a new line graph to share at the beginning of each tactical.We were delighted to see the lines inch ever closer to convergence. Tactical provided that new iOS engineer with a receptive forum in which to express their concerns that, in the era of Swift, Medium‚Äôs codebase languished in the land of Objective-C. Without tactical and at another organization, their early feedback might‚Äôve been stymied. What‚Äôs more, our shared commitment to Swift engendered opportunities for us work and learn together across team and project boundaries. Synergy and shared knowledge were the stuff of our iOS solidarity. A recurring tension at iOS tactical derives from how we work with designers to turn their mock-ups into in-app realities. Several different tensions have arisen and been quashed with one-off action items. We‚Äôve improved our app users‚Äô experience with a service that ensures developer conformance to the design system via easy-to-use Swift methods; view test coverage for key screens like the sign in/up flow; and a semi-annual accessibility knowledge-sharing session. We also self-organized an internal book club for Thinking in SwiftUI and, after some reflection, started to incorporate SwiftUI into new screens. However, I must admit that, in its current state, iOS tactical is no match for the massive undertaking that would be unifying UI/UX. It‚Äôd take more time and resources than us iOS engineers have available for side projects. When and whether tactical-driven action items get slated into sprints is an ongoing tension (heh) I have with tactical itself. I invite those who try out tacticals after reading this blog post to mull over this challenge with me in the comments. Meta-tensions aside, tactical gives Medium‚Äôs iOS engineers a dedicated time to synchronize on how we build and test new features, which cultivates a more consistent user experience. Tactical helps level the playing field for new engineers, seeking their input as soon as they‚Äôre comfortable sharing it. I already mentioned that a new iOS engineer propelled us to Swift-first development at one of their first tacticals, but even smaller contributions from newcomers have made their mark. Last summer, we asked new engineers to help compile a list of confusing classes and components in our codebase. This gave me the fodder to codify an iOS onboarding curriculum, which I then sought feedback on at a future tactical. Six new iOS engineers have since been onboarded with this curriculum, and some of them have even enhanced it after encountering issues. A few more fledgling changes deserve a mention. Our current move towards a more modular codebase has been spearheaded by new iOS engineers. Some have also used tactical time to clarify our processes: just last month, a recent hire sparked a lively discussion on how we select pull request reviewers. Yet another checked off a long-lived action item by documenting how to manually upload dSYMs files to Firebase when our automatic CircleCI job fails. New iOS engineers make waves at Medium. While they were all thoughtful and diligent engineers coming in, I‚Äôd wager that getting asked to contribute as soon as their first tactical fired them up and quickly turned their proposals into actions. Their early participation also facilitates (if not accelerates!) our team‚Äôs transition from forming to storming to norming to actually performing . Tactical makes space for novel takes. I‚Äôve exemplified how tactical has made meaningful refinements to Medium‚Äôs iOS user and developer experience. I‚Äôve also hinted at another intangible that tactical has nurtured: an iOS community. Tactical empowers engineers to care about things beyond the scope of a single sprint or project, galvanizing them to adopt a custodial mindset towards the workplace (as well as the codebase and the user base). We reach out for help when stuck and make ourselves available when others falter. We notice and celebrate each others‚Äô successes. We assume good intentions when reviewing pull requests. In short, we hold our fellow iOS engineers in high regard. Regularly collaborating in tactical underpins our trust in one another. Though no meeting is a panacea for an organization‚Äôs needs, I wholeheartedly maintain that engineering groups akin to the Medium iOS engineers ‚Äî small in number and often divided across product teams ‚Äî stand to benefit from regular tacticals. As I have illustrated, a well-run tactical enriches both the end user‚Äôs experience of a team‚Äôs product and that team‚Äôs quotidian work. Give tactical a go and follow up with me in the comments to let me know how you like it! iOS engineer, writer, and general glossophile. she/her. 365 1 365 365 1 Ios Development Team Building Stewardship Community Developer Experience Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2021-05-12"},
{"website": "Medium-Engineering", "title": "the case of the eternal blur", "author": ["Alex Kimi Wolfe"], "link": "https://medium.engineering/the-case-of-the-eternal-blur-ab350b9653ea", "abstract": "Sign in Alex Kimi Wolfe May 2, 2018 ¬∑ 12 min read This story documents a bug fix, a particularly elusive one. The kind you encounter when trying to build something in a stack where the original architects were brilliant, but no longer around, and maybe didn‚Äôt completely agree on how some fundamentals should work together. Damn, it would be satisfying to rewrite the stack one day , but until then you have to navigate + make the best of what you‚Äôve got. It‚Äôs probably the skill I‚Äôve developed most working at Medium. So Brad + I have bee n working on these elevated collection pages + posts for a small eternity. We forked the post page, ripped out all the cruft, and made this rad index page that shows off all the posts in the collection with some branding. We‚Äôve had a few different collection concepts on Medium, but this one is optimized for our editorial team to showcase some of the collabs they‚Äôve been working on, like Unruly Bodies with Roxane Gay. We identified the last stray bugs, patched them, and I made some time for some purely engineering improvements I couldn‚Äôt squeeze into our first version before I bounced for üå¥ hawaii üå¥ for a bit of workcation. One of these improvements was to make that giant blue Unruly Bodies cover image progressive + to have a nice placeholder for it while it loads. (Before, the text would jankily shift to the right on first render, then the image sloooowly painted in over mediocre connections) Our progressive image code takes a super tiny version of the image that loads in quickly + blurs it out as a placeholder until the real one is ready. This unfortunately synonymous with when javascript is ready, but it‚Äôs still way better than a jagged paint-in. We used to only use this image treatment on our post page (rendered in the backend) and for horizontal images. I moved the template generation code over to the client, flipped the logic on its side to support vertical images and was extremely pleased with myself. Top of the next morning, our valiant editorial team files a bug with me over slack. The issue is a weird one, transient, and I can‚Äôt reproduce at all. The blurry placeholder image loads in fine but then is never swapped with the real asset. I give up for the evening, üôè for transience and eat a spam musubi on the beach for dinner + fall asleep. Design + Editorial do not give up trying to help me conjure this eternal blur on my laptop, and are on it top of the morning. Brad + Euni notice the issue only happens at very specific browser sizes and seems to happen reliably in one window size vs another. Equipped with something to look for, I brace myself to flail around some of our more ancient code. THE SCENE Alright before we delve into the progressive image code looking for view height clues, let‚Äôs set the scene of this heinous bug crime. This page looks pretty basic, but there are a few moving parts that have some fairly interesting front-end components. There‚Äôs the full bleed progressive image , and also an infinite scroller that handles pulling in new pages of posts. There‚Äôs also a footer that scrolls into view after you reach the end of the potentially infinite div full of posts. (The code for the footer only exists stashed on an in-progress branch on my computer at the time.) All of these components (and my fledgling footer code) subscribe to two services: DomMonitor and ElementTracker . These are singleton services, that intercept scroll events and read element positions in a performant way that doesn‚Äôt trigger a re-paint. These two are key to the rest of this rabbit hole, so lemme quickly flesh them out for you. ElementTracker is a clever piece of code by Daryl Koopersmith that‚Äôs a cornerstone of how we handle scroll events in our web client. Basically scrolling is trash, the browser emits events constantly, and even accessing an element‚Äôs layout properties to see where it is on the page can trigger a repaint. If you‚Äôre constantly triggering repaints while scrolling tied to the native scroll event you‚Äôve got yourself some choppy garbage animations. üóë ‚ò†Ô∏è üóë ElementTracker ‚Äútracks‚Äù elements by measuring their start position, keeping track of user scroll actions, and estimating where they‚Äôll be on the page given the scroll delta and the current viewport. It then hooks into window.requestAnimationFrame , (which if you‚Äôve ever done canvas animation will be familiar), which is only emitted when the browser does a natural repaint, and piggybacks on that to do our element checks. This is a key optimization in our rendering, because it avoids the excessive repaints in the naive approach. The draft W3C interaction observer API does something similar and I‚Äôve been dying to mess with it, but our version works on IE and is fairly battle tested. ElementTracker sits on top of our DomMonitor service that does the heavy lifting of listening to the browser‚Äôs real scroll events and emitting the optimized versions we use for our code. SLEUTHING Alright back to the bug at hand, our image loading code. Progressive images are loaded when ElementTracker is ‚Äúrefreshed‚Äù, e.g. on throttled scroll or a performant repaint. I dig into the event handler, and it dictates we decide whether we need to load an image by extending the viewport by 3x (which captures a page above and below), and then we check to see if there are any progressive images within that extended viewport. If so, it triggers some javascript to load the full-resolution image + implement the swap. Our image is smack in the middle of the viewport + this code is also run once when the ProgressiveMediaLoader is activated. We should be fine for triggering an interception/image load. But it also seemed like a sensible place to start debugging and sanity check. I print out the viewport + the rect that represents my progressive image Instead of accurately representing the elongated viewport, the ProgressiveMediaLoader on the index page is looking waaaaaay to the left. The bounds for the image are also way off! Ahh damn. They‚Äôre like a hair‚Äôs width apart. It‚Äôs probably a pixel rounding thing on certain screen sizes triggering an overlap. But why are these rectangles so recklessly flinging themselves into the void?? Why is this happening only to me?? I get a shaved ice to fend off my existential crisis and eat it on the beach. FLASHBACK: a week earlier euni: oh hey alex aztec yoga is getting cut off, it‚Äôs only showing 10 posts. me: damn, this page used to pull down every post in the sequence async, and i just put in some real paging. 10 posts come down now with the first page load, and the rest are supposed to come in on scroll. me: let me see what‚Äôs up with these scroll events euni: cool, we‚Äôre rolling out 15 posts for unruly bodies on monday, can we fix it by then? me: for sure ( this conversation is summarized + semi fictional üòÇ) FLASHBACK (bug inception!! don't stress, quick pagination detour) : Lists of thing that paginate on infinite scroll is Medium‚Äôs bread + butter. The code patterns for this are pretty set, I just broke them trying to be clever with this layout. We‚Äôre under time pressure for a fix so I want to patch it fast. Despite the most ominous sounding warnings I could cook up, we‚Äôre supporting some text baked into images here. Full bleed split screens kind of look like garbage as they get more square, especially if you have to be super careful never to clip your image. It‚Äôs also way too wide to kick the layout to tablet. I wanted to use flexbox for more granular responsive rules, I needed an overflow-y: scroll on the posts div to make it work, it was all fine. Until we needed a second page of posts for the first time and I realized the posts div wasn‚Äôt triggering the scroll event it needed to request more items. The InfiniteScroller code that appends the next page of items at the end of the list ALSO uses ElementTracker / DomMonitor to check whether we need to load in a new page. They decide what element to check for events on by querying this method on the master Screen component, that coordinates all our lesser components, which always tells them to watch document.body . Since I made the overall layout fixed, this is no good. document.body isn‚Äôt actually the one scrolling, the element that contains the post is. Scroll events don‚Äôt bubble for performance reasons, and our event listener for scroll‚Ä¶..is wrapped so deeply in our custom api that changing it to capture would be a bit of a nightmare. This is unfortunate since we do find the correct scrolling element, and theoretically set InfiniteScroller to watch it. However, when it calls this._infiniteScroller.attachToScreen() here, I nfiniteScroller ignores its scrollElement and just relies on whatever the Screen‚Äôs instance of DomMonitor (the service that intercepts all scroll events) is watching, which is always document.body . Looking deeper, the scroll element for InfiniteScroller really is only used for measuring, and not for grabbing events off of. This seems like an obvious bug caused by loosely coupled components bound with a layout that demands behavior that we haven‚Äôt had to accommodate before. I move things around so that BaseScreen.getScrollingElement returns the post elements container for this screen vs. document.body . Paging works and we‚Äôre gooood tooo goooo üëç PRESENT DAY: BACK ON THE TRAIL OF THE ORIGINAL PROGRESSIVE IMAGE BUG Alright so I‚Äôm pretty sure I caused the eternal blur myself with my quick fix for paging. By setting the scrollingElement to the posts container waaay off to the right, all of the other pieces of code (including ProgressiveImageLoader ) that rely on the Screen returning document.body broke. Somehow that culminated with apparating my bounds check we use to see if an image is in the viewport way off to the left, I‚Äôm not going to question it too much cool. cooooooool. Alright, rather than changing this semi global scrollingElement that a bunch of random code relies on to fix paging, it would have been a much stronger pattern to wrap up koop‚Äôs note on the effectively useless method in InfiniteScroller . I want to set a private scroll handler for paging that watches my overflow-y: scroll container vs relying on the same global domMonitor events on document.body as everything else, so I go ahead and do that. This allows me to have my overflow-y: scroll element that I needed for the precious layout, but no other service or component has to know. A lot of the web client is littered with mostly finished just in case api endpoints. InfiniteScroller has one of these that just claims it will attachToElement , passing in a specific element vs the attachToScreen . It‚Äôs perfect. I point it to my overflow-y: scroll element. Progressive images load in reliably + beautifully + paging works on my element on Hatch. I‚Äôm very satisfied, eat a bowl of poke on the beach and go to bed THE NEXT DAY ‚Ä¶..my patch breaks paging on the homepage, so Eduardo reverts it. THE SAGA CONTINUES ok so i check out the homepage and ‚Ä¶.it‚Äôs definitely still attaching itself to document.body like it should. So there‚Äôs got to be some difference between the private scroll listener + the domMonitor one that‚Äôs breaking infinite scroll there. Errr it looks like chrome is cancelling our deferreds we‚Äôre shooting off on scroll that checks to see if we need to load more items. I check the convenient ‚Äújust in case‚Äù api call I hooked my code up to earlier. It set‚Äôs a private scroll handler, but the throttling behavior is kind of wonk. It‚Äôs definitely triggering chrome to physically block these this.onScroll calls which would summon the next page of posts. I can remove the delay, but then we lose the optimizations we get from throttling, and potentially get choppy scroll animations again. Ooooook. This attachToElement api in InfiniteScroller is only used one other place and is probably old/out of date. DomMonitor obviously has an up to date and working version of scroll throttling, that this api call was probably deprecated in favor of. It would be annoying to rewrite, and weird to have two places with that logic. I should probably abstract it into a shared throttled scroll handler and then also do a gradual rollout so I don‚Äôt inadvertently break a different part of the site‚Ä¶ I eat another poke. I look sagely into the infinite void of stars where they meet the waves. The infinite void that definitely doesn‚Äôt scroll and instead just exists in peace. Ok at this point there are 3 ways to fix this horrible slew of problems. Re-implement domMonitor ‚Äôs throttled scroll into InfiniteScroller . InfiniteScroller will be a real component tightly coupled to the div it‚Äôs adding posts/streamItems to. It will also work with horizontal scroll (like in a carousel) if we ever want to do that in the future. Re-implement the way ElementTracker looks at the viewport. It probably should use the actual viewport and not derive it relative to the scrolling element (which caused the broken negative left bounds earlier) when deciding whether a progressiveImage is in view. ‚Ä¶..re-write my template so it scrolls with goddamn document.body The void stares back from behind my eyes and I choose option 3, to restructure my html ‚ò†Ô∏è üíÄ üëª so the image is fixed and document.body is the one that scrolls like the rest of medium.com . You don‚Äôt get nice flexbox image widths but max-width: 45% is roughly what it was doing most of the time and is definitely good enough. I put a horrible placeholder div that lives under my fixed one that keeps the text pushed to the right and somewhat flexed. ‚Ä¶I‚Äôm also going to patch solutions 1. and 2. even though they are no longer relevant to this layout but because hot damn there probably will be a case where I have to make infinite scrolling work in an isolated element, like a future carousel of doom‚Ä¶..a death carousel full of progressive images. I re-write my dockable footer‚Ä¶..haaaah remember that feature‚Ä¶‚Ä¶‚Ä¶.and it‚Äôs easier this time since I don‚Äôt have to account for apple‚Äôs native rubberbanding on the FOOTER‚Äôs scroll events when I hit the bottom of my overflow-y: scroll div, since it can just naturally live on the bottom of document.body and I can look for the border between the two. I flip the switch to roll out the finished project + my sweeping rampage of bug fixes across all collections to all users. I lay down on my own grave. if you too would like to brave the eternal fires of our web client, and help it emerge like a phoenix from the ashes, come work with us magical girl + engineer @coinbase. Formerly @medium 690 4 Thanks to Kiera Wolfe and Julie Russell . 690 690 4 JavaScript Webclient Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2018-05-02"},
{"website": "Medium-Engineering", "title": "code2040 2018 boat trip", "author": ["Mike McGhie"], "link": "https://medium.engineering/code2040-2018-boat-trip-ef9b86faec23", "abstract": "Sign in Mike McGhie Oct 25, 2018 ¬∑ 2 min read This summer we got to host several amazing interns from Code 2040: Alexis, Christina, Dmitri, Michael, and Nichelle. Heading into the final month of the internship we decided it was time to get on a boat. We car-pooled from the bay up to Lake Berryessa and spent a day grilling, laughing, jet-skiing and being merry on a 14 person pontoon. In the midst of eating salmon burgers and artisanal chips we learned a few lessons about life. Here are a couple of them: Thanks to the int e rns, the hosts, and Medium for the good times and facilitating deeply enriching experiences. Engineer at Medium 81 81 81 Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2018-10-25"},
{"website": "Medium-Engineering", "title": "to the future black history makers in tech", "author": ["Michael Barrett"], "link": "https://medium.engineering/to-the-future-black-history-makers-in-tech-6e87513605b4", "abstract": "Sign in Michael Barrett Feb 26 ¬∑ 4 min read Black History Month is coming to a close this week. Like many others, I‚Äôve used this month to celebrate Black culture and the achievements of Black pioneers. While we often celebrate Black history-makers from the past, I want to take some time to look to the future. After all, history is being made every day. The young people of today will be the leaders of tomorrow, and maybe that Black history-maker will be you. I‚Äôm Michael, and I‚Äôve been a software engineer for about 2 years. My family is from Jamaica and I grew up in New Jersey. At Medium, I get to build new features for our iOS app and support a platform for writers and publications around the world, including our in-house publications like Zora , Level , and Momentum . In a world that is increasingly digital, where social apps define how we connect and interact with one another, software engineering can be a high-impact way to help shape the world we live in and leave a mark in history. I know firsthand how this industry can feel out-of-reach and exclusive, and how as a beginner it can feel like you will never know enough to be a real software engineer. So, apart from building great things here at Medium, I aspire to make it a little easier for the next young person who looks like me to feel represented and to feel empowered to pursue their wildest dreams in tech. I‚Äôve asked some of the other Black engineers here at Medium to share some of their inspirations, experiences, and advice with you. If you‚Äôre on the fence about diving into the world of software engineering, or if you‚Äôve just started your journey and wonder if you have what it takes, hopefully some of these words from my colleagues will inspire you to keep going. By pursuing your dreams and building a better future, you too can make your mark in history. Mopewa Ogundipe, Senior Software Engineer, 4+ years: I got into engineering and computer science because my older brothers are both engineers and I grew up watching them tinkering with our household appliances. I love this field and have stayed in it because I haven‚Äôt found anything that beats the feeling of having an idea, building or coding it, and then putting it in someone‚Äôs hand and watching them use it. Nichelle Hall, Software Engineer, 1.5 years: My parents always wanted me and my siblings to be engineers. In high school, I took Chemistry and had a hard time in the class. I remember Googling engineering majors without chemistry, and Computer Science popped up in the search results. This planted a seed. I wasn‚Äôt quite sure what Computer Science was, and I assumed it had to do something with fixing printers. A couple of summers later, I signed up for an engineering apprenticeship program for high school students at the Philadelphia Naval Yard. My mentor didn‚Äôt have anything planned for me and my cohort. For security reasons, the Naval yard has very limited WiFi and I didn‚Äôt have the clearance to use it. Instead, I used the time to look through the O‚ÄôReilly Python books that were lying around and learn about Computer Science. I spent the summer going through the book‚Äôs coding exercises with the other teenagers. I made some friends and had some fun, so I decided to stick with it. Ifedayo Famojuro, Data Engineer, 1 year: I became an engineer because it made me feel empowered. Coding is self-actualizing! My engineering skills allow me to take an idea from inside my head, and give it form so that others can interact with it. I always found this really cool, and would definitely recommend that anyone else searching for that feeling of empowerment, look into becoming an engineer. David Osemwengie, Senior Production Engineer, 9 years: Never stop learning! There is so much to learn and there are plenty of free resources on the internet. You would be amazed how far in the industry you can get just by having the initiative to learn. Another piece of advice is to take rejection as a learning opportunity. As many rejections as I have encountered during my career, I took the time to figure out where my weaknesses were and focused on improving those areas. This will build character and make you a resilient engineer! Misiel Rodriguez, Android Engineer, 2 years: You probably relate to the feeling of entering your CS major classes and not seeing anyone that looks like you (or a select few). Listen I hear you; that feeling is real and sometimes continues in to the industry, but I‚Äôm here to tell you even in those spaces, you still belong. Don‚Äôt let that deter you away from your love for tech or passion for building things. We‚Äôre in these spaces because we worked hard and we deserve it! Also, peep these organizations/fellowships whose missions revolve around helping us navigate these spaces: Code2040 (shoutout #F8OfTech), /dev/color, and ColorStack to name a few! hyper typer 541 541 541 Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2021-02-26"},
{"website": "Medium-Engineering", "title": "2 fast 2 furious migrating mediums codebase without slowing down", "author": ["Sasha Solomon"], "link": "https://medium.engineering/2-fast-2-furious-migrating-mediums-codebase-without-slowing-down-84b1e33d81f4", "abstract": "Sign in Sasha Solomon Mar 21, 2018 ¬∑ 4 min read Five years ago, Medium was built using the latest tools and frameworks by people who had experience with those tools. It‚Äôs time that we update these tools and frameworks. However, migrating an entire system to new tools and frameworks isn‚Äôt an easy task. And doing that while not impacting feature development? That‚Äôs even harder. So, how would you migrate off of your existing system, without hindering feature development, but also incrementally gain the benefits of the new system along the way? We began by testing out different frameworks and technologies and figuring out which ones deliver on the dimensions we care about. Improve the developer experience, making it faster and more intuitive Improve the performance of Medium With these goals in mind we asked ourselves the following questions when assessing tools and frameworks: Does the tool/framework have an active and responsive community? Is the tool/framework relatively mature (e.g. used in production elsewhere)? Is the tool/framework intuitive and easy to use? Does incorporation of the tool/framework have the potential to increase performance? Does the tool/framework give us a easy migration path? Are the engineers who will be using the tool/framework excited about it? We settled on using React.js on the client and using GraphQL as an interface between the client and services that encompass our business logic. Next, we worked out our order of operations. How can people start using this new system as soon as possible ‚Äî and certainly before it‚Äôs complete ‚Äî but also how can we avoid infringing upon development of new products? We decided on a design with two parts: Part 1 : First, we migrate a subset of pages in our old web client to React.js, with our old client still in place and functional. We use GraphQL as the interface between this new client and our old API service. We are able to display pages on both the new and the old system because we direct traffic at the proxy layer depending on the route being hit (e.g. if you navigate to the profile page, you are seeing our new system, but the post page uses our old system). You can see examples of this in the wild right now, including the user profile page and Series for web ! Our old API connects to different databases and contains a lot of business logic. That would be a lot to migrate in one shot. By using our old API as our data source, we avoid needing an immediate major server-side rewrite and are able to incrementally migrate our client. This means we are able to migrate client-side code to the new system without negatively affecting product development. It also gives product engineers the flexibility to begin working with our new tools sooner and be able to provide value as soon as possible. We also use the data description ‚Äî defined in protobufs ‚Äî from our legacy API as a schema for interfacing with GraphQL. In this way, we are able to be strict about the data we let through our system, which makes it easy to know what data is available, what type it is, and whether it will be present. It also means we set ourselves up perfectly for a future where we use gRPC . Part 2 : The next phase is to start chipping parts of our server-side code into services. In doing this, we can start reaping more of the benefits of using GraphQL since our services will be simpler, more modular, and more performant. Because all of the GraphQL infrastructure is already in place, we can easily have GraphQL talk to new services via gRPC, without worrying about supporting the old API (since these new services will be completely separate). We‚Äôll be able to use the new services in conjunction with our old API until each piece is separated into its respective service. Again, in doing this, we don‚Äôt affect product work while we migrate our systems over, as the old systems will still be in place. Also, the backend changes are transparent to users of the new GraphQL API. This makes the transition almost seamless. Once we‚Äôve transitioned the old API into new services that use gRPC, we‚Äôll be able to retire our legacy API completely. We‚Äôve completed most of the migration for Part 1, and things are looking great! We‚Äôre getting started on Part 2 soon, and are looking forward to‚Ä¶ ~ the future ~ EDIT : For those asking, We are using Apollo Client as our GraphQL client-side framework and using Sangria as the framework for our GraphQL server. We plan on writing more in depth about how our web client and GraphQL server are architected and how they use these technologies in future posts. Stay tuned! ‚ú® If this all sounds super cool and you want to be a part of it, come work with me ! software engineer @twitter, previously @medium. doing scala + graphql. pokemon gym leader. potato compatible. @sachee 5.2K 7 Thanks to Xiao Ma and Julie Russell . 5.2K 5.2K 7 GraphQL React Software Architecture Software Development Infrastructure Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2018-11-02"},
{"website": "Medium-Engineering", "title": "breaking up big fred", "author": ["Jean Chung"], "link": "https://medium.engineering/breaking-up-big-fred-407751e58625", "abstract": "Sign in Jean Chung May 6 ¬∑ 5 min read One of Medium‚Äôs most well-used and beloved internal services is Fred Penguin, our unofficial mascot and homegrown Slack bot. Every day, Medians use Slack commands like fred helpdesk my laptop is broken! to file support tickets with IT or fred hi5 @lyra to publicly celebrate or thank their teammates. For years, Fred was not owned by any single team, with engineers across the company contributing features or bugfixes whenever they found the time. Over the years, Fred‚Äôs resp o nsibilities have grown to include a great many tasks. Some of these are essential to many Medians‚Äô daily workflows, like notifying us when a teammate requests a code review on Github or comments on a Jira ticket we‚Äôre working on. As a monolith, rather than delegating some of its tasks to other services, Fred insists on handling everything by itself. If one of the umpteen things Fred is trying to do doesn‚Äôt go as planned, it can take down Fred completely, disrupting work at Medium for many. It was November 2, 2020, and Fred was dead. To be more precise, Fred was ceasing to respond to any requests. When even health check requests were failing (Are you there, Fred? It‚Äôs me, Kubernetes) , Kubernetes would restart Fred. This was happening over and over until Fred got stuck in a crash loop. When a service breaks, one of the first places we look is its logs. We‚Äôre a detective investigating a murder case, and if we‚Äôre lucky, the victim was a prolific Twitter user whose last tweet reads, ‚ÄúSo I‚Äôm in the library and Professor Plum just walked in with a giant pipe in hand and a murderous glint in his eye???‚Äù But when we looked in Fred‚Äôs logs, we found that it was dying silently, leaving nary a clue behind. As a result, it was difficult to determine which of Fred‚Äôs many parts was causing its untimely and repeated demise. To make things worse, we were only running one instance of Fred in production. We generally run multiple instances of most of our services, automatically scaling up or down based on our needs in a given moment. For a service as highly trafficked as the Medium.com backend, relying on one instance would be like a busy restaurant relying on a single employee to greet, serve, cook, bartend, bus, and wash dishes. Even if it‚Äôs not strictly necessary in order to handle the quantity of requests a service receives, running multiple instances of a service increases its reliability , or the likelihood that the service will be available when we need it to be. It‚Äôs the infrastructure equivalent of not putting all of our eggs in one basket. Fred1‚Äôs stuck in a crash loop? No worries, Fred2‚Äôs got us covered! Unfortunately, we couldn‚Äôt run more than one instance of Fred. The problem boiled down to two of Fred‚Äôs features: processing Slack events and executing cron jobs. Slack events are the Slack triggers that cause Fred to respond (i.e. any of Fred‚Äôs commands), and cron jobs are code that is executed on a given schedule. Each Slack event and cron job should be handled exactly once, but with multiple Freds running, the same Slack event or cron job could be handled once by each Fred, resulting in duplicate messages. To get around this problem, we decided to split Fred into different versions, with each version responsible for a subset of Fred‚Äôs tasks. This meant selectively turning certain features on or off in each version of Fred. Today, we have 4 different versions of Fred running in production: one for handling Slack events and cron jobs, one for handling Github integration, one for handling Jira integration, and one for handling all other HTTP requests. The version of Fred that handles Slack events and cron jobs can still exist only once. However, the other versions of Fred are free to multiply. We currently run two instances each of Github Fred, Jira Fred, and HTTP Fred, so our total comes out to 7 instances of Fred running in production today. We took the decomposition of Fred one step further by creating a new microservice to handle one small function of Fred: managing Medians‚Äô identity data related to Slack, Github, and Jira. In the future, we plan to continue breaking out some pieces of Fred into their own services. We don‚Äôt know exactly why Fred was getting stuck in crash loops in November. But today, Fred‚Äôs future is much brighter. First, having entrusted our proverbial eggs to many different Fred-baskets, we‚Äôre much less likely to experience a total Fred outage again. If something goes awry with our Jira integration, our Github notifications will continue to work, and vice versa. Second, if one version of Fred keeps going down while the others are fine, we‚Äôll have a better idea of where to start investigating the problem. Third, my teammate Bob Corsaro created SLOs for Fred, so in the future it will be easier for us to detect when Fred is running into trouble. The issues we faced with Fred illuminated quintessential pain points of monolithic architecture. When so many distinct functions are handled by a single service with code that is closely intertwined, the service can become brittle and difficult to debug. While a microservice architecture comes with its own tradeoffs, decomposing a monolith by creating boundaries between discrete responsibilities can be an effective way to reduce and isolate the risk of each of those parts. building things right here 368 368 368 Monolith Microservices Software Development System Architecture Penguins Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2021-05-07"},
{"website": "Medium-Engineering", "title": "building series for web", "author": ["Alex Kimi Wolfe"], "link": "https://medium.engineering/building-series-for-web-319925de3665", "abstract": "Sign in Alex Kimi Wolfe Feb 9, 2018 ¬∑ 2 min read The first week of January this year Engineering was left to its own devices for the time honored tradition of following your own heart, and developing features for Medium that personally interest you ‚Äî hackweek! . This year Emma Zhou , Herzog and I with our powers combined are so excited to present to you Series for Web We launched Series on the Medium mobile apps la s t year as an immersive experience that that integrated gorgeous transitions, video, and gifs. I love writing them since they feel way more casual, and it‚Äôs much easier to control the pacing of a story + develop narratives over time. We wanted to maintain that same level of visual polish when porting them over to desktop web. Fortunately our amazing Infrastructure team has been working on a new React stack we got to try out for hackweek that made managing the user states + animations infinitely easier. ‚Ä¶Unfortunately we did not hack together support for embedding series into the home page of our engineering blog so here we are. I‚Äôve written up a riveting behind the scenes exclusive peek at this triumph of engineering in series form, please check it out ‚ú® and let us know what you think! magical girl + engineer @coinbase. Formerly @medium 265 3 265 265 3 Series Medium Hackweek React Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2018-02-09"},
{"website": "Medium-Engineering", "title": "use a dev domain not anymore", "author": ["Daryl Koopersmith"], "link": "https://medium.engineering/use-a-dev-domain-not-anymore-95219778e6fd", "abstract": "Sign in Daryl Koopersmith Nov 28, 2017 ¬∑ 17 min read In the course of my work I sometimes test features on unreleased, upcoming versions of browsers. Earlier this week I opened up the upcoming version of Chrome only to find that the Medium‚Äôs development environment ‚Äî the system we use to build Medium every day ‚Äî wouldn‚Äôt load. Instead, all I saw was this error: Our development environment worked in the stable version of Chrome, so there had to be something different about this new version. After some sleuthing, I figured out what had changed. Our development domain name, standard.dev , wouldn‚Äôt work in the new version of Chrome unless we accessed it through a secure connection or changed the name. As I read more about the issue I learned that it‚Äôs not just Chrome, and we‚Äôre not the only ones who face this problem. Every programmer who tests their website using a domain that ends in .dev will be affected. In every major browser. Within weeks, thousands of development websites will stop loading, reduced to frowny page icons. This is the story of that change. The story of how the internet grows and bends and brushes up against its past from time to time, sending off sparks. It begins in 1969. A long time ago, in a network, far far away, a great adventure took place! Out of the chaos of new ideas for communication, the experiments, the tentative designs, and crucible of testing, there emerged a cornucopia of networks. Beginning with the ARPANET, an endless stream of networks evolved, and ultimately were interlinked to become the Internet.‚Äù RFC 2468, Part 1 B efore the internet, before domain names, and before I was born, there was the ARPANET ‚Äî the little network that could. What started as a network that bridged four research centers in the western United States became the foundations of the internet we know today. The ARPANET connected computers called hosts together using giant, wired routers called Interface Message Processors (IMPs) . These routers served as the nodes of the network, and allowed the research centers to communicate with one another. To send a message to another host on the network you needed to know its address, the unique number of the host and IMP. An address was like a telephone number: meaningless and impossible to remember. So researchers solved the problem the same way our phones do ‚Äî they created an address book. This address book was called a hosts file. By 1973, the ARPANET had grown tenfold, spanning the United States and adding IMPs across the Atlantic in Norway and London. Host files were becoming unweildly. Programmer and composer L. Peter Deutsch wrote , ‚ÄúIt seems about time to put an end to the absurd situation where each site on the network must maintain a different, generally out-of-date, host list for the use of its own operating system or user programs.‚Äù Instead, ARPANET researchers decided to give each host an official name and distribute one master hosts file, HOSTS.TXT , maintained by the researchers at the Network Information Center ( NIC ). This change was critical because it changed the purpose of the hosts file. Instead of acting like your cell phone‚Äôs list of contacts, it acted as a public phone book. As the network grew, even HOSTS.TXT became unwieldy. In the mid-1980s, researchers created a new, decentralized system for managing and organizing host names at scale. They called this the Domain Name System (DNS), and it introduced two key concepts: hierarchy and resolution. The first major concept of DNS introduced was a new, hierarchical style of domain names. Instead of navigating to an address like NYT-COOKING , you‚Äôd navigate to cooking.nytimes.com . This would allow related websites to be grouped together. In our New York Times example, their main site is www.nytimes.com , their cooking app is cooking.nytimes.com , and their Medium publication is open.nytimes.com . With the DNS hierarchy, it‚Äôs clear that all of these websites are related. But what about the ‚Äú.com‚Äù part? That‚Äôs a top-level domain (TLD). DNS was created with only a handful of top-level domains, served to classify sites by purpose. Names like .gov, .edu, and .org are fairly straightforward. And .com, the most ubiquitous TLD of them all? .com stands for ‚Äúcommercial.‚Äù The process to create a new TLD was exceptionally strict, and would remain that way for almost thirty years. Creating TLDs also served another purpose ‚Äî they facilitated the migration from ARPANET addresses to proper domain names. Every host name on the ARPANET was given a temporary domain name with the .arpa TLD. Domains like NYT-COOKING automatically became nyt-cooking.arpa when accessed using DNS, so the entirety of the ARPANET was still accessible when DNS was first implemented. The second major concept of DNS introduced was domain name resolution. Instead of relying on a hosts file on your own computer, your computer would ask a domain name server to resolve a name into an address on the network. That way, the address was (almost) always up to date. But the hosts file persisted. It remained your own personal list of addresses, used to augment the DNS results. Programmers could add an entry to the hosts file if they wanted to override the domain name server, which became especially useful for testing network-related code. The introduction of domain name servers also introduced a problem. What if you were writing code (or later, building a website) that wasn‚Äôt connected to the network yet? How could you test it? Programmers introduced the concept of a loopback address to solve this problem. With a loopback, a host could send traffic to an address and receive that same traffic as if it had come from another machine. This allowed them to test their code without connecting to any name servers. When IPs were introduced, the loopback address was named localhost and added to every computer‚Äôs host file. It remains the de facto address for testing websites to this day. W hen Medium was created, we used localhost for the address of our development server. It was simple, ubiquitous, and easy to set up. But as Medium grew from a basic website into a network, our needs changed. By 2015, our use of localhost was causing issues. When we added a way for users to log in to Medium through Facebook, Facebook wouldn‚Äôt allow us to test the feature with localhost as a URL. At the same time, we decided to allow publications to write on Medium using their own domain name instead of medium.com . Splitting our platform across multiple domains was not a small amount of engineering work. This included adding multiple fake domains into our development environment to test our new code and mimic the real world. We decided to use our hosts file (and later, a fake domain name server called dnsmasq ) to create fake custom domains and transform localhost into standard.dev . We‚Äôre not the only ones to rename localhost . Over the years web services became increasingly complex, requiring programmers to simultaneously run multiple interconnected services to test their code. localhost began to lose its significance. Each service runs on a different port, written as a number at the end of the domain name. Your website might run on localhost:3000 , your interactive tests at localhost:4002 , your events service on localhost:5000 , etc. At some point the ports become meaningless numbers. So, like phone numbers and IP addresses, we give our services names. These names don‚Äôt point to real websites, but that‚Äôs why we have a hosts file. We add our new names to the hosts file and override the domain name server for testing. (This isn‚Äôt the only way to solve this problem ‚Äî there are many solutions at varying degrees of scale, but we‚Äôll save them another story.) A handful of engineers chose standard.dev because .dev was a common suffix, and our engineering configurations already supported it. Mostly, the engineer who proposed the name enjoyed the pun on ‚Äústandard deviation.‚Äù Mission accomplished. üá∫üá∏ A lmost three years later, a commit to Chromium (the open source project behind Chrome) would throw sand in the gears of our development environment. If we didn‚Äôt fix the issue before it spread, our development website would stop loading in major browsers and potentially disrupt engineering across the organization. Frowny page icon, indeed. What changed? Chromium forced all domains with the .dev TLD to only respond to secure connections. Let‚Äôs break this down. What is a secure connection, and why would a browser force a website to be secure? Security wasn‚Äôt baked into the original blueprints of the internet. In 1994, HTTPS was created as a secure, encrypted alternative to HTTP, the default, unencrypted communication standard. (The ‚ÄòS‚Äô stands for secure .) At first, HTTPS was primarily used for financial transactions. As the internet wove through the fabric of society the stakes became higher, and privacy became increasingly important to the public. By early 2017, over half of traffic in both Firefox and Chrome was encrypted. HTTPS evolved since 1994, continually playing a cat-and-mouse game against security vulnerabilities. In 2009, security researcher Moxie Marlinspike introduced a technique called SSL-stripping, which silently downgrades a HTTPS connection into an insecure HTTP connection. To counter this attack, browsers introduced HSTS (HTTPS Strict Transport Security), a way for a website to declare that communications should always be secure and use HTTPS. But HSTS came with a chicken-and-egg problem. How will the browser know that all communications should be secure if it hasn‚Äôt communicated with the website before? The browser‚Äôs first request to the website might be unencrypted, at which point the website will reply that the browser should encrypt everything. By that point, it might be too late. Browsers added a solution for this too. The Chromium team maintains a list of websites that should always have HSTS enabled, and they bake that list into the browser. That way the browser knows all communication with the website should be secure before the first request occurs. They call this the HSTS preload list . Every major browser includes an HSTS preload list based on the list maintained by the Chromium team. When a change is committed to the Chromium list, it slowly trickles out to Chrome, Firefox, Opera, Safari, IE 11, and Edge. How familiar. Chromium‚Äôs HSTS preload list is HOSTS.TXT all over again ‚Äî except this time instead of host names and network addresses, the list is full of domain names and security instructions. The list is also subject to many of the same issues as the original HOSTS.TXT . It takes time to distribute the list to each browser, and time for the browser updates to trickle down to us, the users. We‚Äôre also starting to see the effects of scale. Today, this list is a cumbersome 41,000 lines long. (Medium is on the list, by the way.) This brings us back to the Chromium commit. The commit behind all this ruckus was a simple change: engineers added one new line to the list. That line forces secure communications for the entire .dev TLD. Encryption just became mandatory for every website that ends in .dev. It makes sense to force secure connections for a website and all its subdomains, but why force connections for a whole TLD? How can anyone even enforce that? And of all the domains, why the .dev TLD? ‚ÄúSomeone had to keep track of all the protocols, the identifiers, networks and addresses and ultimately the names of all the things in the networked universe. And someone had to keep track of all the information that erupted with volcanic force from the intensity of the debates and discussions and endless invention that has continued unabated for 30 years. That someone was Jonathan B. Postel, our Internet Assigned Numbers Authority.‚Äù RFC 2468, Part 2 A fter the DNS was introduced in 1985, the responsibility of managing hosts and addresses didn‚Äôt disappear, it shifted. Each top-level domain was managed by a ‚Äúregistry‚Äù who decided how its domains would be allocated and registered. But who managed the TLDs? That fell to IANA ‚Äî the Internet Assigned Numbers Authority. (If there‚Äôs anything to take from internet history, it‚Äôs that all early technical organizations use abbreviations that unfurl into dry, literal names. There‚Äôs a kind of humor in it. Given the internet‚Äôs roots in academia and government, I can‚Äôt say I‚Äôm surprised.) IANA was first established in 1988. The name sounds grandiose, but this authority was the province of just two people ‚Äî Jon Postel and Joyce K. Reynolds. Postel was a key figure in the creation of the internet: he was the editor of the Request for Comments (RFC) series that documented and specified the internet since its inception in 1969 and the co-author of the foundational RFCs that described the DNS. Postel had been informally handling the names and numbers since the early days of the ARPANET, so at first IANA was practically an honorary title. As the internet grew, the duties of IANA became increasingly critical. After a botched initial attempt to privatize domain name allocation in 1994, the management of domain names and their addresses was handed off to a new, nonprofit organization in December 1998. This organization was aptly named ICANN, the Internet Corporation for Assigned Names and Numbers. Sadly, Postel did not live to see IANA integrated into ICANN. He died in October 1998 of complications from heart surgery, and Reynolds continued their work as a part of ICANN. Vint Cerf, a fellow internet pioneer, memorialized Postel in RFC 2468 , entitled ‚ÄúI REMEMBER IANA.‚Äù ‚ÄúJon, our beloved IANA, is gone. He has left a monumental legacy for all Internauts to contemplate. Steadfast service for decades, moving when others seemed paralyzed, always finding the right course in a complex minefield of technical and sometimes political obstacles.‚Äù RFC 2468, Part 3 O ne of the principal disputes surrounding DNS was the management of TLDs. Adding country-code domains like .fr or .uk was straightforward, but how do you decide what to do with other domains? These domains, known as generic TLDs (gTLDs), were trickier. In 1998, the US Dept of Commerce wrote a white paper advising the new organization on this problem: ‚ÄúThe challenge of deciding policy for the addition of new domains will be formidable. At least in the short run, a prudent concern for the stability of the system suggests that expansion of gTLDs proceed at a deliberate and controlled pace to allow for evaluation of the impact of the new gTLDs and well-reasoned evolution of the domain space.‚Äù In the short run, this remained the case. But in 2011, that all changed. The ICANN board of directors voted to lift almost all restrictions on TLDs, paving the way for almost any word to be registered as a TLD. You might be familiar with all the new and fancy domain names going around: things like medium.engineering , pizza.cool, and cool.pizza. These are the byproduct of this change. Each gTLD is operated by a registry, who decides how their domain names are allocated and managed. The decision to lift restrictions on TLDs resulted in an explosion of registries and a TLD gold rush. (Unlike the California gold rush, this one came with a $185,000 application fee ‚Äî not to mention requiring the technical knowhow and funding necessary to run a registry in the first place.) The .dev TLD is just one of over one thousand top-level domains added to the internet since 2013. A week ago, I didn‚Äôt even know .dev was a real gTLD. Historically it‚Äôs just been the realm of programmers who need a fake domain for testing. The domain never really existed, we just told our computers to pretend it does. But the .dev gTLD does exist. And guess who owns it? That‚Äôs right. It‚Äôs Google. Suddenly, it all makes sense. Who can decide to make an entire TLD secure? The registry that manages that TLD, of course. And that‚Äôs what Google chose to do with .dev . W hy does Google own the .dev domain? Luckily, we can ask them for ourselves ‚Äî those $185,000 applications for gTLDs are made public, and Google‚Äôs is a work of art. ‚Äú18(a). Describe the mission/purpose of your proposed gTLD. The proposed gTLD will provide Google with direct association to the term ‚Äúdev,‚Äù which is an abbreviation of the word, ‚Äúdevelopment.‚Äù The mission of this gTLD, .dev, is to provide a dedicated domain space in which Google can enact second-level domains specific to its projects in development.‚Äù Translation: Google wants to use .dev for themselves. ‚Äú18(b). How do you expect that your proposed gTLD will benefit registrants, Internet users, and others? Given its intended use by Google, the .dev gTLD will best add value to the gTLD space by remaining completely closed for the sole use of Google.‚Äù Translation: The best use of .dev is for it to belong to Google and no one else. ‚Äú18(c). What operating rules will you adopt to eliminate or minimize social costs? Members of the public will not be able to register domain names in this new gTLD.‚Äù Well, that‚Äôs one way to minimize social costs. Snarkiness aside, Google has a reasonable explanation for securing . dev. They have a consistent track record of pushing for security across the internet, especially for their own data. This pushing often takes the form of acquiring infrastructure, securing it, and encouraging others to follow their lead. Securing .dev is simply an extension of that agenda. In the late 2000‚Äôs, Google released their own web browser (Chrome), operating system (Android), and public domain name server . Within years, each would grow into the dominant player in its field. Coupled with infrastructure investments in the billions , Google began to steer the direction of the internet at large. By the time the first gTLD applications were submitted in 2012, Google had locked down a massive portion of the world‚Äôs internet infrastructure in every arena. But they were missing a piece. Despite owning the browser and the DNS, Google didn‚Äôt own the registry, because until then it wasn‚Äôt possible to own a registry. Operating a registry would allow Google to secure another segment of critical internet infrastructure. A system is only as secure as its weakest link, so Google aims to control and secure as many links as it can. When ICANN changed the rules, Google was ready. When applications opened for gTLDs in 2012, Google didn‚Äôt just apply for .dev . They applied for 101 gTLDs , including .google , .play , and .app . However, Google wasn‚Äôt the only company to apply for many of these gTLDs. For some applications, it took years for applicants to negotiate who would end up with the rights to the name. Google‚Äôs application for .dev was pending for over a year. Finally, in December 2014, their application for .dev was granted. In 2015, Chromium added the entire .google TLD to the HSTS preload list with little fanfare. It was the first and only TLD entry in the list for two years, until .dev was added in September and shortly followed by .foo , .page , .app , and .chrome ‚Äî all Google-owned gTLDs. The source code includes classic encouragement for others to follow their lead: ‚ÄúAt the moment, this only includes Google-owned gTLDs, but other gTLDs are welcome to preload if they are interested.‚Äù As far as I can tell, there‚Äôs no easy way around this change. Chrome‚Äôs HSTS admin panel helpfully warns, ‚Äúyou cannot delete preloaded entries,‚Äù and I‚Äôm inclined to believe them. The HSTS preload list ensures all communication with a website is encrypted. If you could remove a website from the list, then you could send an unencrypted request to that website. This would compromise the purpose of the list and be a major security risk. If you‚Äôre using a .dev domain, there‚Äôs some urgency around fixing this issue. Commits take around ten weeks to land in Chrome‚Äôs stable branch and the .dev change was committed to Chromium on September 15th‚Ä¶ ten weeks ago. The commit in question has been in the beta channel for over a month. This change will land in Chrome soon and other browsers shortly thereafter. To solve the problem in the short term you have one of two options. You can either enable HTTPS in your development environment or change your development domain. These options may vary in difficulty depending on your circumstances. Enabling HTTPS is easier when you‚Äôre dealing with a real website with a domain that you own. In that case, you can get a certificate that says ‚Äúyes, I am the owner of this website and it is secure.‚Äù Unfortunately, development websites are fake, so you need to manage your own security. This involves creating what‚Äôs called a ‚Äúself-signed certificate‚Äù for your development website. Like a small child, your operating system believes in ‚Äústranger danger‚Äù and doesn‚Äôt trust self-signed certificates. This is because anyone could make one. So once you create your certificate, you also need to teach every computer that accesses the development environment to trust that certificate. (You trust yourself, right?) Otherwise your browser will yell that your development environment is unsafe and insecure and hates puppies. This can be a painful process if you don‚Äôt have a process for installing code on development machines. In Medium‚Äôs case, when I discovered this issue we already had a working self-signed SSL certificate and a good process for managing development machines. I wrote a snippet of code to automatically trust our certificate on macOS and updated our development environment to enable HTTPS by default. While this is a reasonable short-term solution, developing on a public, active TLD doesn‚Äôt seem like the best idea in the long-term. This solution is more of a stopgap ‚Äî it‚Äôs a good idea to change your domain too. The other option is to change your .dev domain and never look back. But what domain could we migrate to? With the gTLD gold rush, is anything safe? As it happens, there are two contenders: .localhost and .test . In 1999 RFC 2606 reserved these, along with .example and .invalid for just this purpose. After the gTLD boom, RFC 6761 reaffirmed and clarified their usage in 2013. There are two key differences in usage ‚Äî software is encouraged to recognize .localhost domains as ‚Äúspecial‚Äù and alter its behavior accordingly. However, software should treat .test as it would any other domain. Keep in mind that these are guidelines, so the only way to know whether your new domain will work properly is to test it on your code, along with all the services integrated with your code. Changing your domain might be as easy as changing a line or two in your configuration file, or as difficult as changing thousands of lines of code across your codebase. You‚Äôll also need to make sure your computer knows how to handle .localhost and .test domains. Our favorite host file is still relevant and up for the job (and the dnsmasq tool is an excellent solution for this as well). T hose of us using .dev may feel wronged, but ultimately we were squatting on a domain that was not our own, and was not protected for our use. Now we‚Äôre paying the cost. But that‚Äôs not to say we‚Äôre at fault either. It‚Äôs easy to place the blame on programmers. Why didn‚Äôt we just use the reserved domains in the first place? The answer is that we didn‚Äôt know ‚Äî and it‚Äôs okay not to know. For all our efforts to educate ourselves, there will always be more to learn. The internet contains far more than any person can know. That‚Äôs what we built it for, after all. It‚Äôs also easy to place the blame on Google. Who are they to lock down a frequently-used fixture in the software community? It may have been a little tone-deaf for Google to acquire .dev for internal use, but then again, if Google hadn‚Äôt enabled HSTS for the whole TLD most programmers would be none the wiser. And they weren‚Äôt the only applicant for the .dev TLD either. This is just another step down a predictable path. The last player in this drama is ICANN, the organization that enabled this change. Lifting restrictions on gTLDs is akin to opening Pandora‚Äôs box ‚Äî once you loosen constraints on a software system, it‚Äôs difficult to reverse course. ICANN could‚Äôve written stricter rules for new gTLDs, but rules are tricky to get right. We‚Äôve known this was a thorny issue since before ICANN existed. Conflict and a few broken eggs were inevitable. There‚Äôs a line in I REMEMBER IANA that sticks with me. ‚ÄúHe leaves a legacy of edited documents that tell our collective Internet story, including not only the technical but also the poetic and whimsical as well.‚Äù The days of the ARPANET seem simultaneously quaint and grandiose ‚Äî a handful of people laying the foundation for a network that would go on to be used by half the world and considered a human right . Their work and the problems that come with it persist to this day. The evolution of the internet has been a messy, incremental affair, and there‚Äôs no reason for that to change now. In the meantime, some of us have domain names to change. ‚àû 12.9K 28 Thanks to Joy Chen and Jamie Talbot . 12.9K 12.9K 28 Internet Google DNS Medium Tech Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2017-11-28"},
{"website": "Medium-Engineering", "title": "mapping mediums tags", "author": ["Heather A"], "link": "https://medium.engineering/mapping-mediums-tags-1b9a78d77cf0", "abstract": "Sign in Heather A Jan 24, 2018 ¬∑ 9 min read This was originally published Jan 18, 2018 on Hatch, Medium‚Äôs internal instance, to explain a hack week project to the company. When you publish a post on Medium, you‚Äôre prompted to add labels to your post that describe what your post is about. These tags are mostly free-form. Authors can write whatever they think describes their post. As far as data goes, these tags are a gold m ine. Authors are labelling their posts with a succinct word or phrase that other people understand. We can (and have) used these tags to inform our algorithms for showing content and organizing it. However, there are big issues with tags that limit their usefulness. One of the issues is that tags are scattered. At this point, authors have defined over 1 million unique tags. Many tags are essentially duplicates of other tags, or are so close that they have the same audience. Here are some examples: Global Warming = Climate Change Hillary Clinton = Hilary Clinton (common misspelling) Poetry = Poem = Poems = Poetry on Medium Startup = Entrepreneurship = Startup Lessons = Founder Stories To computers, each tag is just a string of text and by default they don‚Äôt have meaning or relatedness. This makes it hard for us to wield them cohesively in algorithmic battles. Instead of each tag just being represented by a string, what if we could represent it by its qualities and how it relates to other tags? When we talk about people, we don‚Äôt compare them by their names, rather we describe and compare them by the many qualities they have. People are ‚Äúmultidimensional‚Äù to us. What if tags were too? We‚Äôre going to take the word ‚Äúmultidimensional‚Äù literally, and represent each tag by a vector of numbers in a multi-dimensional vector space. First of all, what is a vector? For the sake of this project‚Äôs Python code, a vector is just a fixed-length array of numbers. However, you can interpret this list of numbers in different ways. You could interpret it as a point in space (e.g. (5,3) is the point that is offset 5 along the x-axis and 3 along the y-axis in 2-dimensional space). However, sometimes it‚Äôs more useful to interpret it as a vector with direction and magnitude, the ones you might remember from Physics class. It‚Äôs confusing. I recommend this short video explanation . If we could represent tags with vectors then we could compare them by distance or plot them to visualize the clusters they form. Spoiler: we‚Äôre going to do just that. But how do we find the meaning of these thousands of tags in a way that can represented by vectors of numbers? We do this by training a machine learning model using our tag data. The training data I used was the tags of 500,000 ‚Äúreliable‚Äù public English Medium posts. I pretended each post‚Äôs tag list was a ‚Äúsentence‚Äù (where each tag is a ‚Äúword‚Äù), and fed those into a training algorithm which usually takes real sentences and learns vector representations of words. I used gensim ‚Äôs word2vec implementation for this, and I specified that these vectors should have 100 dimensions. I won‚Äôt go into details about how the training algorithm works, but essentially it figures out a tag‚Äôs vector values by looking at the tags that are used along with it on posts. You can read more about the algorithm here . Algorithms such as word2vec are said to ‚Äúembed‚Äù entities (like tags or words) in a multi-dimensional vector space, and as such, these kinds of vectors are also known as ‚Äúembeddings‚Äù. If you‚Äôre googling for more information about all this, you‚Äôll want to search for ‚Äúembeddings‚Äù. After a few minutes of training, we get the vectors for every tag at our disposal. Let‚Äôs check one out. Here‚Äôs the vector for ‚ÄúClimate Change‚Äù: Great. Don‚Äôt worry, you shouldn‚Äôt understand what these numbers mean. I couldn‚Äôt even tell you myself. Unfortunately, it‚Äôs not even as simple as saying ‚Äúthe X th dimension represents Y quality and the value is how much the tag expresses that quality‚Äù. Rather, the dimensions work in concert to represent information about the tags. It‚Äôs easier to see what‚Äôs going on by comparing vectors. One thing we can do is find tag vectors that are close to each other. Here, we interpret them as vectors with direction and magnitude in order to compute the cosine similarity between them: We can also do arithmetic on our vectors to jump around the vector space. Here we average the ‚ÄúTech‚Äù vector with ‚ÄúEducation‚Äù to land in the vicinity of EdTech tags: Now we can try ‚ÄúFine Art‚Äù + ‚ÄúCities‚Äù to get ‚ÄúGraffiti‚Äù: ‚ÄúProgramming‚Äù + ‚ÄúGaming‚Äù is ‚ÄúGame Development‚Äù: We can also solve analogies, like this one, which is essentially \"Education\" is to \"EdTech\" as \"Agriculture\" is to _ : The fact that we can perform this basic arithmetic and reliably get these results indicates that we‚Äôve learned some ‚Äúlinear regularities‚Äù of the tags. People have found similar , but more linguistic, regularities in word embeddings obtained by training word2vec on real words and language. We can also plot the tag vectors. Now, we switch to interpreting them as points in space. However, since we can‚Äôt visualize points in 100-dimensional space, we‚Äôll have to reduce them to two dimensions. To do so, we don‚Äôt just take the first two dimensions of the vectors and call it a day. Rather, we try to preserve some information from all of the dimensions, and keep points which are close in the 100-dimensional space close in the 2d space. There are a myriad of ways to do this ‚Äúdimensionality reduction‚Äù. One that is particularly good for visualization is t-SNE . The plot of this 2d tag space is large, even if we‚Äôve limited it to only tags which have more frequent usage, so we‚Äôll take a closer look at some smaller regions of it. Places are invariably clustered together, and often grouped by geography. Some places are located within other topical clusters. Virginia and Alabama are in the US Politics cluster. European and Asian countries are located in the Travel cluster. African countries are with non-profit and development tags. You might be wondering where ‚ÄúSpring‚Äù is. On Medium, more people are talking about software frameworks named Spring , than the season, so it‚Äôs located near Java tags in the computer programming cluster. Previously, we trained a tag embedding model using English posts only. If we train one using Portuguese posts, then we can relate Portuguese tags to each other. Other than being really cool, there are several possible downstream uses for these tag vectors now that we have them. There are many sets of tags on Medium that mean the same thing (e.g. ‚ÄúScience Fiction‚Äù and ‚ÄúSciFi‚Äù). Tags which mean the same thing are usually very close in the vector space. This could help us identify duplicate tags and normalize them. Aside from helping us organize the tag space itself, these tag vectors could be used to help solve other prediction problems with machine learning. Machine learning algorithms take vectors as input features . We could include tag vectors in any place where knowing the post‚Äôs tags might help with a prediction. Being able to use these ‚Äúdense‚Äù expressive vectors instead of the alternative for tags ‚Äî sparse one-hot-encoded vectors ‚Äî should improve the algorithms‚Äô ability to predict. The beginning of TensorFlow‚Äôs word2vec doc describes why these vectors are better. The tag representations we‚Äôve learned aren‚Äôt perfect. Here are some things we‚Äôd need to consider for future usage of tag vectors at Medium. There‚Äôs an issue that we‚Äôve already seen with the ‚ÄúSpring‚Äù tag: ambiguity. ‚ÄúSpring‚Äù has at least two meanings on Medium. Many people use the tag for poetry about the season, but others use it for posts about the Java programming framework. We need to automatically detect that there are two distinct representations to learn: ‚ÄúSpring (season)‚Äù and ‚ÄúSpring (programming)‚Äù. This problem is called ‚Äúword-sense disambiguation‚Äù. Luckily, it‚Äôs an area of active research . People have discovered negative stereotype biases in word embeddings (e.g. ‚Äúboss‚Äù relates more strongly to ‚Äúhe‚Äù than ‚Äúshe‚Äù). I‚Äôve been thinking about what this would mean for our tags. Obviously, these tag embeddings are completely at the whim of how people choose to use tags on Medium. We‚Äôre bound to have some undesirable algorithmic bias . Since countries represent groups of people, I thought it might be undesirable to associate countries with topics in some circumstances. African countries are quite close to charity tags. Puerto Rico = hurricanes, as far as tags are concerned. For any downstream use case, we‚Äôd have to consider this. De-biasing embeddings is an area of active research as well . If we find some tags that we know to be counterparts in another language, then we can train a cross-lingual model that embeds the tags from both languages in a shared vector space, so they could be directly compared. We‚Äôre learning the ‚Äúmeaning‚Äù of these tags based on the tags that are chosen alongside it by authors, using word2vec . This was chosen because it was easiest to implement end-to-end. It‚Äôs possible that learning the vectors using other information would produce more effective vectors for us. For example, we could learn them using reading behavior instead of tag context. It‚Äôs also possible that it would find very similar relationships. If you‚Äôre interested in learning more about embeddings and the algorithms used here, I‚Äôd recommend these resources: Original word2vec paper . The algorithm used to train word vectors, which we repurposed to train tag vectors. Linguistic Regularities in Continuous Space Word Representations (pdf). All about the neat analogies and arithmetic you can do with word vectors. Original t-SNE paper (pdf). The dimensionality reduction technique used to take our 100-dimensional vectors down to a 2d visualization. Deep Learning, NLP, and Representations . If you already know a bit about neural networks and how they work, this post has a great explanation about how embeddings (including word vectors) are trained as a side effect of solving another task. Word embeddings in 2017: Trends and future directions Lover of all things computational 1.8K 12 1.8K 1.8K 12 Machine Learning Word2vec Embedding ML Case Studies Eng Blogs Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2021-02-10"},
{"website": "Medium-Engineering", "title": "ios technical deep dive", "author": ["Eugenia Dellapenna"], "link": "https://medium.engineering/ios-technical-deep-dive-2bfaaea75bfe", "abstract": "Sign in Eugenia Dellapenna Oct 6, 2017 ¬∑ 5 min read On Tuesday, September 20, the mobile team released version 3.3 of the Medium iOS app to the App Store. That same day, Apple released the official version of iOS 11 to the world. Through an unfortunate combination of factors, the app started crashing on launch for users running iOS 11. The official postmortem for that crash can be found here . The goal of this post is to dive deeper into the technical details of what caused the crash. When the Medium iOS ap p launches, it makes a network request to the /_/ios/config endpoint to authenticate the session for the current user and fetch config options. The app was crashing while making this network request, which means that it crashed before people even got past the splash screen üòû. This is relevant part of the stack trace of the crash from Crashlytics: The app was crashing when constructing the URL of the request, specifically when setting the port: This is unexpected since the net request layer of our app is some of the oldest code in the entire codebase, and this particular line of code hasn‚Äôt changed in the last 9 months (when we upgraded some of this code while dropping support for iOS 8). It‚Äôs clear that something changed in iOS 11 that caused this code to start crashing. From the stack trace, you can see that the issue is that self.port is an instance of NSString (actually, a private subclass of NSString , but that doesn‚Äôt really matter). However, NSURLComponents expects port to be an instance of NSNumber (which is an object wrapper for primitive numeric values in Objective-C). When the port is set, NSURLComponents calls a method that NSString doesn‚Äôt implement, causing the app to crash. At this point, you may be thinking to yourself, ‚ÄúIsn‚Äôt Objective-C a statically typed language? Shouldn‚Äôt the compiler have prevented something like this from happening?‚Äù The answer to that is Objective-C is statically typed‚Ä¶ to an extent. The type system is actually relatively dynamic , thanks to the influence of Smalltalk . Objects can be cast from one type to another without any validation from the compiler. In this case, since the port property of NetRequest was defined as an NSNumber in its interface, the compiler treated the object as an NSNumber and didn‚Äôt complain when it was set as the port on NSURLComponents even though it turned out to be an instance of NSString at runtime. The next thing to look at is where this port value is coming from and to see if there‚Äôs anywhere where we could be implicitly casting an NSString to an NSNumber . In the case of the iOS config request, the NetRequest is initialized with data from our AppConfig file, which returns the port in the following method: The infoDictionary in AppConfig is read from our app‚Äôs Info.plist file, which we configure with .xcconfig files. This allows us to run the app against local, staging, or the production versions of Medium, depending on which build configuration we‚Äôre using. NSDictionary objects in Objective-C return values as type id by default. Type id is a special type in Objective-C that‚Äôs directly inherited from Smalltalk. It‚Äôs basically shorthand for any type of object pointer, and it‚Äôs the basis for most of the dynamic typing in Objective-C. The compiler allows you to call any method that it knows about (i.e. that it can see the method declaration for) on an object of type id . In this case, it‚Äôs also allowing us to return an object of type id as the return value of a method that says it returns an NSNumber , without any additional casting or validation. In the case of this crash, the value in the dictionary was an NSString , but it was getting implicitly cast to an NSNumber when it was returned from this method. Once you know this, the fix for the crash becomes obvious. You simply need to explicitly convert the NSString object into an NSNumber : What‚Äôs less clear is what actually changed in iOS 11 to cause this code to start crashing. It‚Äôs difficult for us to know for sure since we can‚Äôt see what changed in Apple‚Äôs internal implementations. However, I was able to verify that the object returned from the infoDictionary was also an NSString when running the app in Xcode 8, so it‚Äôs likely that this was always the case and we just happened to get lucky in previous versions of iOS and have it still work. With this in mind, I think the likely culprit is in a change in the implementation of -[NSURLComponents setPort:] . It‚Äôs possible that in previous iOS versions, it was calling integerValue or a similar method on the passed in NSNumber . This method also happens to be implemented by NSString , so everything would have worked fine even though the wrong type of object was being passed in. In iOS 11, something changed so that eventually _getValue:forType: got called on the NSString , which it doesn‚Äôt implement, causing the crash. One possible clue is this update in the Foundation Release Notes for iOS 11 : The hash method is now correctly implemented, so NSURLComponent objects may now be used as dictionary keys. Maybe fixing the hash method is what broke our app üò±. The more mysterious factor is why this crash wasn‚Äôt happening consistently for everyone who had upgraded to iOS 11, and why this crash didn‚Äôt happen in version 3.2 of the app, even though the code that was crashing was exactly the same between the two versions. A lot of Medium employees had been running our app on the iOS 11 beta for months without issue, so we‚Äôre still not entirely sure what happened. VP, Product Engineering @Medium 386 6 Thanks to Xiao Ma . 386 386 6 iOS Medium Crashlytics Mobile iOS 11 Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2017-10-06"},
{"website": "Medium-Engineering", "title": "starting fargate", "author": ["Bob Corsaro"], "link": "https://medium.engineering/starting-fargate-c11abd6aa532", "abstract": "Sign in Bob Corsaro Dec 4, 2017 ¬∑ 3 min read For the past year at Medium we‚Äôve been using ECS to deploy containers to AWS. When Amazon announced FARGATE earlier this week, we were really excited. It promises to solve a bunch of issues we experience with the current stack. This is the story of getting a FARGATE service up and running using our internal deployment system, BBFD. BBFD is an internal CLI and continuous deployment tool that we use to build, package, test and deploy our Docker services. Hopefully this post can save anyone else trying to retrofit FARGATE some time and headache. BBFD u s es CloudFormation , but if you aren‚Äôt and just using the AWS API, the AWS API calls match CloudFormation documents pretty accurately, so it should be easy to adapt the code snippets to the API. Looking at the updated API docs, it seemed pretty straight forward. Update the ECS Service ‚Äôs LaunchType to FARGATE and away we go. Service(LaunchType=\"FARGATE\", ...) Not Quite. üí© FARGATE requires ECS Task network mode ‚Äúawsvpc‚Äù. We haven‚Äôt adopted awsvpc yet. It allows each container to have it‚Äôs own networking configuration instead of sharing the ec2 container instance‚Äôs. We will have to adopt it along the way. This requires adding a NetworkConfiguration to the Service object. Ok. Cool, ready to rock! ‚Ä¶ üí© The ‚Äúawsvpc‚Äù mode doesn‚Äôt allow service roles. Since we are using ELBs to load balance our container services, we have a ‚ÄúRole‚Äù defined in the Service description. We had to remove it when using awsvpc. Maybe now it will ‚Ä¶ üí© It turns out we will also need to make some modifications to our Task Definition . Tasks need to be ‚ÄúFARGATE‚Äù compatible. This is done by adding RequiresCompatibilities to your definition. There isn‚Äôt a lot of documentation about what this means, but I think it‚Äôs a macro to setup the right ‚ÄúCompatibilities‚Äù for the task /shrugs. We‚Äôll also need to change NetworkMode to ‚Äúawsvpc‚Äù. Let me just ‚Ä¶ üí© OK, so with FARGATE, we‚Äôll need to define our memory and cpu requirements at the TaskDefinition layer and not (just) the ContainerDefinition layer. It‚Äôs pretty strict about what combinations are allowed . The documentation is a little unclear about what type of values are expected, but strings containing integers is what worked for me. We also need to define an ExecutionRoleArn . I‚Äôm assuming this is in place of the old Service Role we removed earlier. The ExecutionRole contains one policy, the default AmazonECSTaskExecutionRolePolicy policy. It‚Äôs gotta work now ‚Ä¶ üí© The ‚Äúawsvpc‚Äù mode can‚Äôt register an a ‚Äúinstance‚Äù type target group, so we had to modify our target group to be of type ‚Äúip‚Äù. TargetGroup(TargetType=\"ip\", ...) And‚Ä¶. üéâüçæ In retrospect, it would have been nice if Amazon had made a little guide for all the knobs that need to be turned (pun intended), but alas, it only took an afternoon to get something working. There‚Äôs still a bunch of Ops-y concerns we have about FARGATE before it‚Äôs ready for prime time, but I‚Äôll leave that for another day. 3/30/2018 We are in the early stages of modernizing our build/deploy pipeline and rebuilding our container infrastructure on k8s. Visit https://jobs.lever.co/medium to apply. BBFD uses troposphere to generate cloudformation documents and deploy them to various environments. Troposphere is a little behind on the API, so we had to roll some resources of our own to use the new API. This isn‚Äôt exhaustive. We only added the properties that we are using. If you want something less experimental and more ‚Äúcorrect‚Äù, you could use the generator scripts in the troposphere repository. I haven‚Äôt tried them. Medium.com Hacker [email¬†protected] 276 276 276 AWS Fargate Ec DevOps Docker Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2018-03-30"},
{"website": "Medium-Engineering", "title": "continuous improvement", "author": ["Brian Zotter"], "link": "https://medium.engineering/continuous-improvement-f8f9fabd67dd", "abstract": "Sign in Brian Zotter Dec 20, 2017 ¬∑ 4 min read Continuous improvement is a core value of our culture here at Medium. Recently, we introduced a new RCA process to help us better understand why things go wrong and how we can improve our service and processes. RCA stands for Root Cause Analysis. The goal of the analysis is to identify the root causes of an incident so it can be learned from and the incident can be prevented in the future. An incident can be unexpected downtime, an out of bands release or just about any other unplanned event with negative consequences. This is not to point fingers and not to assign blame! One such method in determining the root cause is the 5 Whys . This method was developed by Taiichi Ohno and used by the Toyota Motor Corporation to uncover the cause of manufacturing defects. 5 Whys is simply just repeating the question ‚Äú Why?‚Äù until you can‚Äôt go any further and a root cause(s) is identified. The exact number of Whys is not important but 5 is usually enough! The real root cause should point toward a process that is not working correctly or does not exist. You might have heard the phrase ‚Äú people do not fail, processes do‚Äù . Again, we are not looking to find who was at fault. It‚Äôs important that there is trust in the team and everyone feels they can contribute freely towards the analysis. The root cause should be framed so it may be corrected by the completion of actions. Actions often include the creation of a new process. Ideally the actions would prevent the incident from happening again but that‚Äôs not always possible or practical. You can also consider actions to help identify the issue earlier so you can react quicker. Incident: Users were experiencing slow page load times. Why? ‚ÄîRequests were hanging in the back end Why were the requests hanging? ‚Äî The database was under increased load Why was the database under load? ‚Äî We released a new feature that required data from a new table and that query was slow Why is the query slow? ‚Äî The new table is a missing an index ACTIONS Add an index to the table (Owner: Alice) You shouldn‚Äôt stop when you find the first cause and action. You can branch off at any level and keep going. 5a. Why is the index missing from the table? ‚Äî The new feature wasn‚Äôt tested under load before release ACTIONS Add a performance test for this feature (Owner: Bob) Consider updating launch checklist to require performance tests for big features (Owner: Xin) There can be more than one cause when answering a particular ‚ÄòWhy‚Äô. 5b. Why is the index missing from the table? ‚Äî The author(and the reviewer) didn‚Äôt have experience in database performance. 6. Why was the index missed in a code review? ‚Äî The caretaker list for this part of the code no longer includes someone experienced in database performance. ACTIONS Update caretaker list for schema code (Owner: Upeka) Schedule engineering brown bag talk for schema performance (Owner: JZ) Notice that these actions are a combination of process, code and communication changes. It‚Äôs critical that every action is complete-able and has only one owner. Having one owner makes it very clear who has the ball. Actions like ‚Äúmore testing‚Äù or ‚Äúincrease documentation‚Äù are cop-outs. They are not measurable so it‚Äôs hard to mark them done. Don‚Äôt be trapped, there are usually real insights if you keep going. Sometimes asking, ‚Äò Why did the process fail?‚Äô, helps to keep you on track. A good facilitator can really help here. They are good at asking slightly different questions to generate new lines of thinking. A good facilitator will also encourage diverse participation that will uncover weaknesses seen from other perspectives. Our RCAs are conducted by the team that is responsible for the feature or area that was involved in the incident. We also invite anyone else that was affected or participated in the diagnosis or resolution. The meetings are run as follows. Pick a facilitator and note taker State the incident Ask the Whys Repeat Identify and assign actions Communicate learnings Step 6 is critical. The actions will prevent this specific problem from happening again but the real leverage comes in spreading the learnings from this one particular failure so other similar type failures can be prevented in the future. We publish a summary along with the actions on Hatch, our internal version of Medium. The simple template we use looks like this. Incident (What happened, when, how long) Whys Actions w/ owners Don‚Äôt play the blame game. Focus on continuous improvement. Make the exercise inclusive across departments. Keep digging and see if you can uncover more causes for each why. Share the learnings with the broader organization. Remember that things go wrong. Accept, embrace, and learn from it. 427 Thanks to Xiao Ma . 427 427 Software Development Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2017-12-20"},
{"website": "Medium-Engineering", "title": "an engineering spooky story", "author": ["Nathaniel Felsen"], "link": "https://medium.engineering/an-engineering-spooky-story-9b1d7c1dedb2", "abstract": "Sign in Nathaniel Felsen Oct 31, 2017 ¬∑ 4 min read You may have already heard the saying ‚Äú You don‚Äôt have a backup until you tested that you can restore it. ‚Äù As it turns out, that saying is true but not enough‚Ä¶ Recently, I screwed up big time with a small pull request: At Medium, we use Jenkins quite a lot, and by quite a lot, I mean, way too much‚Ä¶ Among those ‚Äúcreative‚Äù use cases, we use it to trigger our ETL pipelines jobs for our data scientists and some of our analytics tasks. Because of the nature of those tasks, the hosts running them tend to frequently run low on disk space. To avoid a possible bad situation where we would completely fill up the root partition, I created the pull request above to move the Jenkins tmp directory to a new location on /media/ebs0/tmp which happens to be a separate EBS volume. You might be familiar with EBS volume, which are extra virtual disk partitions that AWS let you attach and mount onto your systems. We often use those on some stateful services such as our build systems. The cool thing about EBS volumes is that you can create snapshots of your volume and this makes it a good solution for backups (more on that later). To make it explicit, we like to mount those volumes in the /media/ directory and give them the explicit names ebs0, ebs1, etc‚Ä¶ Here, at Medium, we take advantage of it and create hourly snapshots of those ebs0 volumes on important systems. In addition to moving the tmp directory to that new location on the ebs0 volume, I also meant to make tmpwatch clean up that new tmp directory. If you are not very familiar with the tmpwatch command, know that this is the magic command that cleans up your /tmp directories. The functioning of it is very straight forward: It simply looks recursively through all the directories provided in the command and recursively removes files which haven‚Äôt been accessed for a given amount of time. Most Linux distributions use it in a cron job to periodically free up space in the /tmp volume. This is also what we use and in the 2nd change of the pull request, you can see me adding a new path to the tmpwatch script. Sadly, that‚Äôs where I screwed up. Instead of cleaning up the /media/ebs0/tmp directory, I asked tmpwatch to look at the entire /media/ebs0 Because tmpwatch is configured to delete files not accessed for a few days, the issue manifested itself after about 3 days. After realizing the issue, and past the usual pain in the stomach that comes with those sad discoveries, we started to breath again knowing that those volumes are backed up. As any good Ops practitioners, we go over occasional disaster recovery exercise which includes restoring our backups. We somewhat felt that we should be able to recover from that but that‚Äôs when we discovered a second issue. As it turns out, we were only keeping 40 backups of those volumes and since we do an hourly backup, this meant, we only kept less than 2 days worth of backups. Whenever we tested restoring our backups, we always took the first available backup but never thought of looking at how far back we can restore those volumes. The issue being like 3 days old, but the oldest backup we had was less than 2 days old and all files that had not been accessed for a while where already gone. Basically, none of the backups we had could help us recovering. Long story short‚Ä¶ it took about 2.5 days for 3 engineers to recover from that mistake and we now make sure to keep one month of backup. If you can‚Äôt read *this*, it‚Äôs probably because of me‚Ä¶. 387 Thanks to Xiao Ma and Dan Benson . 387 387 Engineering Infrastructure Halloween Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2017-10-31"},
{"website": "Medium-Engineering", "title": "how do you like them apples", "author": ["Alaina Kafkes"], "link": "https://medium.engineering/how-do-you-like-them-apples-bcf70b8a38d6", "abstract": "Sign in Alaina Kafkes Oct 13, 2017 ¬∑ 5 min read I kicked off my career at Medium as an iOS software engineer. This has come as a surprise to many of my friends, who know how much I love playing with Python and that I‚Äôve exclusively written HTML, CSS, and JavaScript in my internships and open source contributions. So why am I doing iOS development? I want to dabble i n a broad array of engineering roles before I make a deep dive into any one of them. I once wrote Swift code for a zombie running app in Northwestern‚Äôs Delta Lab: that taste of iOS development convinced me to give it a try in production. Over seven weeks at Medium, I‚Äôve climbed the steep learning curve to working competency in iOS development. I‚Äôll chronicle my journey, and share with you my thoughts on iOS programming from the lens of a predominantly-web developer. When I first opened up Medium‚Äôs iOS codebase, I felt like I had just woken up in an alternate reality. Methods were suddenly called messages. Classes were outnumbered by interfaces, protocols, and properties ‚Äî whatever those meant. Syntax drowned in square brackets. So went my introduction to Objective-C. Although it is in the C family of programming languages ‚Äî which I am familiar with ‚Äî it borrows from Smalltalk , a language implemented in the object-oriented and reflective programming paradigms. The term ‚Äúparadigm shift‚Äù literally applies here. I spent my first week adjusting to the stylistic choices and best practices behind Objective-C programming. Reading this Objective-C cheat sheet catalyzed many ‚Äúaha!‚Äù moments that I had when sifting through the codebase. The first pull requests I submitted to Medium‚Äôs codebase were changes to the application view, or the user interface. At that point, I still felt iffy about my Objective-C skills, so it was nice to be able to visualize what I created by running the iOS simulator. The thing that struck me most about front-end iOS development was how straightforward and pleasant vertical alignment felt. I swear that I have to Google how to vertically center a div (or other CSS element) every couple of months. text-align is memorable, but the witchcraft StackOverflow comes up with to achieve vertical alignment is too much for my mind. Somehow, in Objective-C, vertical alignment becomes a carefree pastime. To vertically center a UILabel in a UIView, all I need to do is grab the midY ‚Äî the Y-coordinate at the center of the UIView ‚Äî and slap the UILabel on top of it. Of all the wonderful aspects of iOS development, the ease of vertical alignment tops the list. It‚Äôs the little things that warmed me up to this new engineering frontier. In my fourth week at Medium, I picked up a task that centered around creating a new view and its corresponding logic to certain Medium stories. I knew the basics of model-view-controller (MVC) ‚Äî or, at least, which of the model, view, and controller can communicate with one another ‚Äî but only at a conceptual level. I remember reading that the controller can set and update the view. This is the case in Medium‚Äôs codebase: for a given class, the controller instantiates a view object. When I had to create a button, however, I realized that I had no clue how to pass information back up from the view to the controller. Wouldn‚Äôt it be bad to make the view depend on the controller and the controller depend on the view? After some documentation hunting, I found out about delegates . I learned that I could create a delegate that represents the controller so that I could access controller messages (methods) in the view. Using this delegate, I was able to seamlessly hook up a user‚Äôs button press action to trigger the appropriate controller method. To me, an iOS novice, delegation still feels like a cool trick for passing information up the application hierarchy. Weaving delegates up a chain of views and controllers had the added benefit of making me feel more comfortable with the structure of Medium‚Äôs codebase. I noticed that an OCMVerify test that wasn‚Äôt passing after I made some changes to a message. I had added a new parameter to that message, and now, this OCMVerify test was highlighted in an ugly Xcode red. OCMVerify is a message in the open source iOS testing library OCMock. OCMock. The word ‚Äúmock‚Äù in OCMock refers to a technique in testing in which the programmer tests units (objects, messages, etc.) that are similar to the given unit, but with fake, oversimplified dependencies. A mock unit is an imitation of that unit. The test that I had made fail instantiated a mock message and then used OCMVerify to ensure that the messaged had been called. What I found fascinating about this is that the ability to check if a message has been called means that these Objective-C tests can detect changes at run-time. How rad is that? Back to my failing test. Upon researching the purpose of OCMVerify , I fixed up the test case by adding in a new parameter to the mock message that accepted any type of object. This allowed me to account for the places in the code where this parameter was nil. Upon recompiling the tests re-testing, this unit test passed! I had seen mocking and unit testing in previous web development internships, but parsing through the OCMock library and seeing how it has been used in Medium‚Äôs iOS codebase hammered home the concepts. But, to be fair, these recent testing epiphanies may be due to Xcode‚Äôs unusually comprehensible error messages rather than the superiority of iOS development tests. Though my learnings have felt small in the moment, writing them down sequentially demonstrates the sheer breadth of the iOS skills that I‚Äôve gained in a short period of time. I‚Äôve covered a lot of ground in iOS development, which means that I‚Äôm now asking as many questions of breadth (what is Grand Central Dispatch?) as of depth (behind the abstractions, how does Grand Central Dispatch work?). I mention Grand Central Dispatch (GCD) because that‚Äôs the next iOS concept that I‚Äôm mentally tackling. I look forward to the rabbit hole that I‚Äôll fall down while learning about it, and to the cascading growth that I‚Äôll undergo as an iOS engineer from learnings like GCD and beyond. This blog post was originally published on Chronicles of a Junior Dev , where I‚Äôve been writing about my first year as a software engineer. To be updated about new posts in the Chronicles of a Junior Dev saga, follow me on Twitter . iOS engineer, writer, and general glossophile. she/her. 423 423 423 iOS Software Development Learning Mobile Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2017-10-13"},
{"website": "Medium-Engineering", "title": "some things i value in engineering teams", "author": ["Chris Fry"], "link": "https://medium.engineering/some-things-i-value-in-engineering-teams-bd851e877ada", "abstract": "Sign in Chris Fry Feb 20, 2017 ¬∑ 2 min read Note ‚Äî this was originally published internally to medium engineering I was riding in on the bus today and it struck me that I should be clear about things I value with you all since you are just getting to know me. First and foremost I value learning for both teams and peo p le. Learning cultures are resilient, fun and rewarding. Plus they build better stuff because they learn from what they do. Learning involves some form of time boxing, releasing and retros. So I‚Äôm a huge fan of getting product in front of users and being honest. You can spend a lot of time debating but one of the most clear ways to get feedback is to release often. Building software is a team sport and the best teams are resilient, collaborative, driven and work to create in ways that everyone feels supported and heard. I‚Äôm a fan of a version of occam‚Äôs razor for engineering solutions ‚Äî ‚ÄúAmong competing hypotheses, the one with the fewest assumptions should be selected.‚Äù My version is this ‚Äúthe simplest solution is probably right and try it first‚Äù. When confronted with a problem find the straightest line to the solution, build that and then iterate. It‚Äôs often easy to pre-build infrastructure for things you don‚Äôt need. I‚Äôm also a fan of putting the user first and considering our users in everything we do. Rigor ‚Äî the build should never break, write tests first and write lots of them, the tests should always pass at 100%. Remember most code is written once and read 100s if not 1000s of times. So focus on clean simple code that does the job and can be easily understood. Pride ‚Äî we should all feel that the medium codebase is ours to make better and that we can work on all pieces of it. This doesn‚Äôt mean that we won‚Äôt have specialists or people that know more about certain areas but there should be no fear in giving feedback and touching other parts of the system. Fight the entropy of the codebase by making it slightly better with every commit. Delete code & systems we don‚Äôt use. Refactor. Would love your feedback‚Ä¶. Rolling, building, breathing 101 1 101 101 1 Software Development Engineering Medium Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2017-02-20"},
{"website": "Medium-Engineering", "title": "", "author": ["Emma Zhou"], "link": "https://medium.engineering/-b10bec20de1d", "abstract": "Sign in Emma Zhou Aug 22, 2017 ¬∑ 8 min read Back in the heady days of early July 2017, I was tasked with adapting the Medium üíö system into something that allowed variable input . With the binary üíö button, users could tell us when they liked a story, but we wanted to know how much they liked it, in comparison with other stories. In theory, this new data would allow us to surface truly good content over shiny clickbait. It was also the first piece of a larger project to open up our partner program and start paying Medium writers ! The Medium üíö system worked like this. On w eb, iOS, and Android, we had front-end components that rendered the button everywhere: on post listings, user profile pages, responses, topic pages, and in a few places on every post page. When you tapped it, it sent a üíö request to our backend. The request handler for üíö updated a field on the UserPostRelation table to indicate that this user had recommended this post, then emitted an event that fanned out to do many more things, like send push/activity feed/email notifications, update post stats, update author stats, send data to our recommendations pipeline, send data to our social graph database‚Ä¶ We decided to keep most of this infrastructure in place and patch our new multi-recommendation system into it as far upstream as possible, to minimize backend changes as we experimented on the front-end. Conveniently, we already had a field on UserPostRelation that we were using to store how many times a user clapped for a Series . In my project planning, I allocated two weeks (out of five) to design and prototyping experimentation. So while I built an ugly but functional button and connected it to our backend, Jess , Herzog , Peter , and Wolfe came up with all this cool stuff! A week in, Tess did some user research. People thought the designs that looked like rating systems required too much cognitive effort, so we moved away from those. Everyone loved Herzog ‚Äôs cute animations though, so they stayed. After our two weeks of fun, it came time to make some hard calls. What would the new icon be? How many times could a user recommend a single post? What number would we show next to the button ‚Äî how many times it was recommended, or how many different people recommended it? Would the new action be only for our members? Internal opinion was‚Ä¶varied. Some people wanted recommends to be capped as low as 3 per person per post. The prototype I released internally had a cap of 100. Some people wanted no cap at all, like claps in Series . For the number to show next to the button, we got an impressive quantum full house of preference: recommends, people, both, neither . üíö felt like a great icon when the recommend system was binary, but nobody wanted to give 20 üíös, let alone 50. We considered üí° (too erudite), üíß (too divorced from sentiment), and üéâ (too frivolous). Ev , who has the world‚Äôs driest sense of humor, half-jokingly (I think) suggested we should make a tree that grew bigger the more you recommended, and eventually produced knowledge-apples. I, naturally bad at narrowing scope under the best of circumstances, had a stressful week. I coped by gathering advice from everyone in sight. Kathryn , our head of marketing, told me something really insightful: that internal opinion, though it seemed all over the map, was actually divided into two camps: Camp 1 imagined that the new action would be lightweight and easy to perform, that each recommend would be a drop in an ocean, and that people would want to keep expressing their appreciation until it felt right . Camp 2 thought the new action should be more weighty and meaningful, that each individual recommend should carry significant value, and that people would want to think carefully about exactly how many recommends they gave. People‚Äôs preferences tended to align with their camp. I was staunchly Camp 1, so I wanted a high cap, I wanted an icon that felt like something you could give 5 or 15 or 40 of, and I wanted to show the total number of recommends (even if it was giant). I conveyed Kathryn ‚Äôs insight to our valiant and wise product manager, katie . katie understood immediately, and further intuited that both camps were valid but the real danger lay in the lukewarm compromise in the middle. Within 12 hours, she put out an internal Medium post explaining the phenomenon and declaring that we were going with Camp 1: üëè icon, capped at 50, showing total clap count, going out to everyone. And we were re-aligned. Since claps are stored on a different field in the UserPostRelation table than recommends, we needed to backfill them from recommend data. Otherwise, every post written pre-üëè would suddenly show zero engagement. I dedicated three cavalier sentences to this integral part of the project in my tech spec and handed it off to my Code2040 intern, Dmitri , on his second week. I forgot about backfilling claps on author stats (which power our stats pages) and post stats (which are used everywhere). Each of these additional backfills was actually two backfills, one for summed totals and one for time-series data. The original UserPostRelation backfill also turned out to be more complicated than I thought, spanning 30 million objects and requiring sharding. Within a week, Dmitri had eclipsed me in knowledge of our events and stats pipelines. Within three weeks he‚Äôd finished writing code for all five backfills. He spent the remaining time on the project capacity-planning with the dev ops team and shepherding backfills through dev, staging, and production, all the while casually picking off tasks from all over the rest of the stack. 30 million üëè for Dmitri , the most extraordinary intern in the universe. This project involved keeping a lot of different kinds of data in sync, so, unsurprisingly, we spent a lot of time fielding reports of data bugs. On our internal version of Medium, people would clap for a post, come back later, and their claps would be gone. Sometimes they saw errors in their browser. Sometimes their claps would appear in post totals, but their name wouldn‚Äôt show up in the list of applauders. Once the backfills were complete, we started chasing down reports in earnest. We eventually untangled and fixed three separate bugs: We used to allow people to recommend 100 posts per day. In the vast majority of cases, people were hitting üíö once per post, so we rate-limited per request. Once someone hit their limit for the day, we started sending back 429 ‚Äôs. When we launched üëè internally and before we implemented a reasonable batching strategy, people were suddenly hitting their daily limit after interacting with just two posts. Worse, we were updating the number of people who clapped (on post stats) and the number of claps a user gave (on UserPostRelation ) in different places in the code. The former was hitting the rate limit; the latter was not. Kyle and Dmitri fixed this by changing the rate limit to only count a first clap, and reordering code so that even when the rate limit was hit, data wouldn‚Äôt get out of sync. I hurriedly implemented better batching. We knew we were going to have a graduated rollout for üëè, so there would be some time when üíö and üëè would have to co-exist. We made sure üëè was backward-compatible, but we separated üíö and üëè flows by user . People who got üëè early but still had old mobile clients with üíö could briefly increment post totals from their apps without affecting their own UserPostRelation clap count. Dmitri heroically debugged this while the rest of us napped after a team hiking trip. Herzog and I put in a fix the next day to check client versions on incoming requests. This was maybe the weirdest bug we found. A whole bunch of posts showed up with 1 clap from -1 people. When we dug in, we found that all of their post stats had recent changes at the exact same timestamp. Our data platforms team found the culprit: we recently deactivated the account of a prolific spammer, and somewhere in our data pipeline a non-idempotent event to decrement post stats got sent twice, leading to the -1 people counts. We also weren‚Äôt decrementing claps on user deactivation, resulting in the single orphaned claps. We rolled üëè out to our iOS and web beta groups first, then to 10% of our users. Initial reactions were mixed, with the main complaint being that üëè seemed pointless. But interestingly, quite a lot of people correctly guessed that they would become an important signal when Medium started to pay writers. Good work, product prophets! We launched üëè to 100% last week, and the Medium Partner Program is rolling out today to a small initial group of writers and publishers. You can learn more here , or apply here to start writing! This was an amazing project to be a part of, and I‚Äôm super proud of the work we did! ‚ù§Ô∏è to Herzog , Dmitri , katie , Jess , Peter , Wolfe , and Dan , the DREAM TEAM. Software @Neuralink 6.4K 4 Thanks to Jamie Talbot , Lyra Naeseth , katie zhu , Madeline Birdsall , and Xiao Ma . 6.4K 6.4K 4 Software Engineering Product Development Webclient Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2017-08-22"},
{"website": "Medium-Engineering", "title": "inline code", "author": ["Emma Zhou"], "link": "https://medium.engineering/inline-code-cc32ff2d463", "abstract": "Sign in Emma Zhou Nov 1, 2016 ¬∑ 6 min read I wrote this on Hatch on Sept. 22, 2016. Presented here with minor edits for clarity. See Hatching Inside Medium for more context. Check it out: you can create inline code on Medium now! The invocation is ` + any other character . You should see the backtick disappear, and your character should appear as inline code. WYSIWYG! Yay. Keep typing, then exit the mode by typing another ` . You can also select a piece of text and then hit ` to convert it into inline code üò± OK. Now I‚Äôll g o through some recent history, some implementation details, and one million edge cases üôå Fun fact: we tried three different invocations for inline code before settling on this one. The internal-only implementation we had for a while was actually most similar to how it works now: ` to enter the mode, and another ` to exit. Pros: familiar and intuitive to engineers. Cons: there‚Äôs no way to get two literal backticks in the editor, and on international keyboards, backtick followed by another character makes a diacritical character (like √®), and we would be overwriting that behavior. When we started talking about polishing inline code for release, we talked through these tradeoffs and initially decided on the super unsatisfying invocation cmd-opt-` , both as a way to enter and exit the mode, and as a way to convert selected text. Joe wrote up a product spec, and we built and released this version internally. The response was lukewarm. One night Marcin pinged me on Slack and told me that cmd-opt-` was not working for him. His keyboard was the same as mine, and it was weirdly only breaking in Chrome. We debugged unsuccessfully for a few hours, then decided, hell, there wasn‚Äôt anything special about cmd-opt-` . We already have a bunch of cmd-opt-n shortcuts in the editor, including cmd-opt-6 for code blocks. Why not cmd-opt-7 ? cmd-opt-7 was working. So, for a hot second it was going to be cmd-opt-7 . Marcin quickly proposed a better solution: go back to backticks, but instead of a backtick throwing you into the mode right away, we would wait for another character. Then , assuming no diacritical magic, it would convert that character and put you in the mode. You exit the mode by typing another backtick, but only on the rightmost edge of an existing piece of inline code (this way you can still have backticks within inline code: ` , and you can also write strings of literal backticks: ```). Koop suggested that selecting a piece of text and hitting ` should convert it to inline code, much like selecting a piece of text and hitting ( or \" wraps it. This is way better. Our editor does a fair bit of smart text substitution. For example, if you type a < followed by a 3 , we remove both characters and insert a ‚ù§. We accomplish this by always looking for the final character in these sequences. In the <3 case, we look for 3 , and then we construct a paragraph model to check the character before it, to see if it‚Äôs a < . Since 3 doesn‚Äôt really come around that often, this is fine. But the equivalent check for inline code would be triggered by any ASCII character between 33 and 126 (basically every keystroke in the editor), so instead of creating a paragraph model every time, we first dig through goog.dom.TextRange and manually check if the previous character was a backtick. The insertion code, when called, further ensures that our backtick was preceded by either a space or the beginning of a paragraph, then deletes the backtick and the following character, and re-inserts the character marked up as <code> . We have a plugin that handles most of our formatting keyboard shortcuts (including cmd-b for strong , cmd-i for em , and cmd-k for links ), so it wasn‚Äôt hard to create a new keyboard shortcut for inline code, and then pass the shortcut through IFF 1) something‚Äôs selected, or 2) we‚Äôre at the right edge of a piece of inline code. That‚Äôs pretty much it! And now for the part that took up 90% of engineering time on this project: edge cases! There were a bunch of them, and some of them were pretty weird. Here are the big ones: How does inline code interact with other elements in the editor? Can it exist within headings, quotes, code blocks, or image captions? No, we decided, it can‚Äôt. Turns out this disabling (for inline code, and also for other markups like strong and em ) happens entirely in CSS. That way, you can convert a piece of text containing inline code into a heading and back, and it will preserve the inline code, but not display it within the heading. We disabled smart text replacement within inline code. That‚Äôs the thing I talked about earlier that converts <3 into ‚ù§. It also converts quotes to the curly kind, two adjacent hyphens into an emdash, and it calls up a typeahead popover when you type a @ . None of these things are great when they happen in inline code. We had to explicitly make inline code copy and paste-able, since we‚Äôre pretty opinionated about the sorts of things you‚Äôre allowed to paste into the editor. But since we use <code> tags to display inline code, once it was possible to copy and paste from one Medium article to another, we also got the ability to paste code from Github (and other places that use <code> tags) for free! We decided that inline code would be sticky on the right, but not the left. In other words, when you type immediately adjacent to a piece of inline code on the right, the new text you type will be absorbed into the inline code. On the left, it won‚Äôt. For a while, up and down arrow keys were behaving really strangely around inline code. When going down, instead of going past inline code onto the next line, the cursor would stop at the beginning of every piece of inline code, then the end, and then continue. Nick helped me debug this: turns out, when you hit the down arrow in our editor, we actually create a fake cursor that advances character by character looking for the correct place to put the cursor on the next line. When the vertical location of the current position is not the same as that of the previous position, we assume we‚Äôre on a new line. But since inline code is rendered in a different font and different size than regular text, advancing into a piece of inline code was making us think we had reached a new line when we hadn‚Äôt. We fixed this by making the vertical position comparison a little fuzzier (anything within 10px counts as the same line). There‚Äôs one more edge case we identified, but decided not to address for now: the blinking cursor doesn‚Äôt always reflect stickiness correctly at the edges of inline code. For example, when you type a backtick to exit the mode, the cursor doesn‚Äôt move outside the gray padding box. There‚Äôs a whole other engineering blog post here, but TLDR: we try to maintain a one-to-one mapping between possible cursor positions and offsets in our paragraph model. But when you‚Äôre on the right edge of inline code, we would ideally have two cursor positions, one inside the markup and one outside. These two cursor positions map to the same offset in the paragraph, which causes all sorts of problems. Someday we will come back and fix this. Cool. Now you know everything I know. Go forth and inline code ! üéâ Software @Neuralink 321 19 Thanks to Joy Chen , Nick Santos , Joe Polastre , and Bobbie Johnson . 321 321 19 Programming Productivity Webclient Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2016-11-03"},
{"website": "Medium-Engineering", "title": "the inexorable march of tech", "author": ["Colin Vernon"], "link": "https://medium.engineering/the-inexorable-march-of-tech-34f2c5e87dff", "abstract": "Sign in Colin Vernon Jan 6, 2017 ¬∑ 4 min read When I talk about building software, I like to use the metaphor of a garden. You put a bunch of energy into architecting, planning and building your garden, then one day it‚Äôs finished! And then from that day forward, you need to continually work on it; weeding, cutting, turning the soil, preparing for changes in season, sweeping, everything one does to keep a garden in good shape. Pair this with another mental model I am fond of: On the right is new, sh i ny, R+D-type tech. In the middle is the stuff we know and love, stable, reliable and well-adopted; it‚Äôs the stuff we work with on a daily basis that is the core of what customers depend on. On the left we get into the weeds of older, rustier stuff, either shoddily built or hurriedly maintained, or based on frameworks that have gone out of fashion, or proof-of-concepts that got put to production and never revisited for robustness. Wherever they start out on the spectrum when built, the key here is that the x -axis is like a conveyor belt, slowly moving left, pushing all tech through this spectrum at an unstoppable crawl. The way to keep things from falling off the left is to keep tending them back towards the middle, like our garden. I call this the Inexorable March of Tech. Now, let‚Äôs imagine the most magical of circumstances: you launch something new and shiny today, it works 100% perfectly, no hacks where made in the creation, and all engineers are super happy about how it was built. Even in this entirely impossible fictitious perfection ‚Äî even then ‚Äî upon deployment this tech drops down onto the conveyor belt of the Inexorable March of Tech, and even if no feature requests are made and nobody touches anything [again impossible], it will eventually move through the stages of relevancy and eventually become technical debt to the organization. A friend of mine who is a CTO-type and serial entrepreneur once gave me a great quotable quote about the difference between a green and veteran CTO: all else being equal, the experienced CTO does not to feel guilty about technical debt . It is as inevitable as it is difficult to precisely define. It‚Äôs how you deal with it that counts. So now how do we deal with it? We are launching a new effort in Engineering to try to quantify our efforts in the spectrum I‚Äôve laid out above. The 3 zones of my theory above can map to a new way we‚Äôre trying to think about project allocation & prioritization: üöÄ = future/shiny/r+d/Big Bets üî® = core feature work/stable tech üí∏ = weeding/tech debt reduction The weight of these 3 types of work is going to be a big point of discussion in the near future. I believe we should usually have the largest portion in core feature work [pushing the business forward], and comparable amounts of future-forward and debt reduction [refactoring etc]. This is not true of individual teams, but should hopefully be true when looking at the whole org, and over time [more on this below]. Without opening up for bike-shedding, Maybe 70% features, 20% debt, 10% exploration? If we have too much üöÄ, we may not be delivering enough üî®. If we don‚Äôt have enough üöÄ, we will end up with too much üí∏ in the future. Similarly, if we have too much üî®, we will end up with too much üí∏ in the future. If we don‚Äôt have enough üî®, we won‚Äôt be pushing the business along. This is really key. If we have too much üí∏, we have done either too much üî® or not enough üí∏ in the past. If we have not enough üí∏, again we will just have more üí∏ to do in a future cycle which will take away from the important üî® and üöÄ. A few things I want to surface, keeping in mind that we want to have the bulk of our work in the üî® zone: Don‚Äôt feel bad about always having a chunk of üí∏ in your workflow. It‚Äôs not a sign of bad engineering in the past, it‚Äôs normal and natural and an important part of making sure we also have time for üî® and üöÄ in the future. Plus ‚Äî like gardening ‚Äî it‚Äôs good for the soul. Don‚Äôt feel guilty about technical debt. Don‚Äôt feel ‚Äúfrivolous‚Äù about pushing for more üöÄ, it will keep us young and will keep us balanced in the Inexorable March of Tech. If we only do üî®-type work we will inevitably have our tech too heavily weighted towards üî® and üí∏, and we will always feel trapped in the past. Smart, continual investments in üí∏ and üöÄ together allow us to keep strong üî®-focused delivery of stable, awesome user features. All of this is also balanced over time: it‚Äôs ok to take a quarter to focus more on üí∏, and then readjust in the following quarter so that overall we feel like it‚Äôs a healthy balance. Product, Design and Engineering; Entrepreneur 13 13 13 Technical Debt Software Development Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2017-01-06"},
{"website": "Medium-Engineering", "title": "mediums dynamodb data source for apache spark", "author": ["Travis Crawford"], "link": "https://medium.engineering/mediums-dynamodb-data-source-for-apache-spark-62c6599a6dfd", "abstract": "Sign in Travis Crawford Oct 7, 2016 ¬∑ 2 min read Medium‚Äôs tech stack includes DynamoDB for our production data, and Apache Spark for backend data processing. We need a fast and reliable integration between these systems to support our data warehouse. Talking with data engineers at other companies, this is a common pairing and we all have somewhat similar internal tools making these systems play well together. We‚Äôve open-sourced our DynamoDB Data Source for Apache Spark with the goal of making DynamoDB & Spark easy to use together for everyone. Key features: Load a DynamoDB table as a DataFrame or RDD. Scans the table in parallel per Amazon‚Äôs recommendations . Rate limiting support. Scanning DynamoDB t ables in parallel is particularly beneficial because they are partitioned, requiring parallel scans to take advantage of all your provisioned read capacity. We have observed significant scan time improvements when switching to the parallel scanner. Our primary use-case at Medium is using Spark to backup DynamoDB tables to S3. Separate Spark jobs restore the backups ‚Äî JSON files on S3 which Spark has great support for ‚Äî into a variety of systems, including Redshift and Databricks . We chose this approach (rather than Data Pipeline) so our ETL and analysis jobs have a common look & feel, keeping things simple for our users and developers. We start our backup jobs with a command similar to: DynamoDB table scans work by defining a set of ScanSpec ‚Äôs, or description of what data to scan, including which portion of the table to scan, and which projections and/or filters to apply. This data source creates ScanSpec‚Äôs in the Spark driver based on the provided configuration, then distributes them to cluster workers where the table is scanned in parallel. As a convenience, we provide a backup job that writes the data set to any supported filesystem. For more control, you can use the table scanner as a library. As a NoSQL database, DynamoDB does not strictly enforce schemas. However, if all records in a table share a schema it may be useful to load the table as a DataFrame. Here‚Äôs an example running SQL on a DynamoDB table. Notice how no schema was provided ‚Äî it‚Äôs inferred by sampling some records in the table. You can optionally specify the schema if needed (we generate ours from protobufs). You can perform any DataFrame operation on the data that was scanned from the DynamoDB table, such as continued analysis, or saving to S3/Redshift. Interested in helping move Medium forward? We‚Äôre hiring! Data Platform Lead @Medium 253 3 Thanks to Satya Boora and Xiao Ma . 253 253 3 Big Data Spark Dynamodb Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2016-10-07"},
{"website": "Medium-Engineering", "title": "emoji in the editor", "author": ["Emma Zhou"], "link": "https://medium.engineering/emoji-in-the-editor-806d6e026258", "abstract": "Sign in Emma Zhou Jun 19, 2017 ¬∑ 4 min read Last week I was blocked on product development, so I added an :emoji: typeahead to the Medium editor, because I was tired of ^‚åò[space] ing. üôÖüïí Try it out! Type a colon, followed by the name of your favorite emoji into any Medium post. (Here‚Äôs a cheat sheet .) We already implicitly allow emoji in the editor. We even gracefully handle multi-character emoji like üë®‚Äçüë©‚Äçüë¶‚Äçüë¶ and üá¶üá∫ when you backspace and arrow around. Which‚Ä¶ git blame ‚Üí Nick Santos , obviously. üôè The Medium editor has a bunch of plugins, which translate key and mouse input into editor commands. They also sometimes draw other editor UX. (Like typeaheads!) A few typeaheads already exist in the editor, including the ones for @mentions and post tags. Each one is its own editor plugin, but they all extend the root TypeaheadPlugin . So I created a new class called TypeaheadEmojiPlugin , and overrode the following methods: linkifyCommand and unlinkifyCommand , which add and remove the temporary HTML markup we put on :query strings. (That‚Äôs what turns the text green as you type.) shouldLookup , which determines whether we do a query, and shouldLinkify , which determines if we try to add the query markup. Both are checked on most keypresses, and both look for a colon preceding the cursor, with no spaces or punctuation in between. shouldLinkify additionally checks if the query markup is already there, so we don‚Äôt add it twice. requestData , which happens when shouldLookup is true. For user mentions, we send a request to our backend. For emoji, we just wrap a call to emoji.getMatchingEmoji in a Deferred. extractData , which by default tries to unpack a response with a value key. We don‚Äôt need this, because we didn‚Äôt send a request. So we just take the raw data straight from requestData and return it. tokenCommand , which does the actual keyword ‚Üí emoji replacement when a typeahead item is selected. We find the preceding colon, remove it and everything between it and the cursor, and then insert the selected emoji. In addition to being able to :start_typing to call up a list of emoji, we also want fully formed emoji strings like :100: to be replaced with üíØ. Like all of our other smart text replacements, that means listening for the last character in the sequence, : , and then checking the preceding characters for an emoji keyword. We perform a replacement when: There‚Äôs another colon preceding the one that triggered this check, and only non-space and non-punctuation characters in between (so hello :no_mouth: should trigger, but :YOLO. WOOO: should not). The string between the colons matches an emoji keyword. The starting colon has a space before it. In a testament to the cleanliness of Medium‚Äôs editor code, everything I described above took me about five hours to do, unit tests and all. I then proceeded to spend two full days looking through different sets of emoji keywords, and trying to figure out which emoji are supported by which macOS versions. I initially tried using canonical unicode names, but there are some really bizarre ones. :smiling_face_with_open_mouth_and_tightly_closed_eyes: , for instance, which I and most other emoji-capable humans know as :laughing: üòÜ I ended up cannibalizing the keywords available on Github, found here . For ease of searching (and smaller file size), I massaged that list into an object of alias ‚Üí emoji pairs. I kept an eye out for macOS emoji support documentation, but didn‚Äôt find much. Going off a hodgepodge of release notes, iOS rumors, and old Stack Overflow answers, I cobbled together the following timeline: At some point in the distant past (~OS X Lion), emoji support is introduced. üò¨ üëª üîÆ There are two OS X updates that just add more flags. üáÆüá≤ üáØüá≤ üá≥üáø There is an emoji update with El Capitan (10.11.1), which corresponds to iOS 9.1 and adds support for Unicode 7 and 8. ü¶Ñ üèçüçø Sierra (10.12) comes out at the same time as iOS 10, with a bunch of new emoji that don‚Äôt really map to any Unicode version, and are largely differently-gendered versions of existing emoji. üï∫üïµÔ∏è‚Äç‚ôÄÔ∏è üë©‚Äçüë©‚Äçüë¶ After a bit, Sierra (10.12.2), along with iOS 10.2, adds support for Unicode 9. ü•ë ü¶ä ü•É So, those are the version cut-offs I‚Äôm going with. For non-üçè machines, we‚Äôll provide the base set (everything pre‚ÄìEl Capitan). My first push of emojiKeywords.js failed lint checks, because you can‚Äôt have duplicate keys in an object, and there were two turkeys ü¶É üáπüá∑ (now :turkey: and :turkey_flag: ). There are 1462 emoji keywords total on Medium. Some are repeats, like :tangerine: , :orange: , and :mandarin: üçä I added a vanity alias for my favorite emoji, because I can never remember what it‚Äôs called. üòê ‚Üê This is now :pokerface: Software @Neuralink 553 10 Thanks to Xiao Ma , Lyra Naeseth , and Jamie Talbot . 553 553 10 Emoji Productivity Webclient Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2017-06-19"},
{"website": "Medium-Engineering", "title": "a new chapter", "author": ["Chris Fry"], "link": "https://medium.engineering/a-new-chapter-ed05f344bc4a", "abstract": "Sign in Chris Fry Jan 31, 2017 ¬∑ 1 min read After two years of investing, advising, and traveling I‚Äôm excited to get back to work. Today I start at Medium as head of engineering. This is a challenging job in many ways, not the least of which is by nature I‚Äôm not a writer and I like to communicate in short, clipped sentences ‚Äî more Steinbeck than Joyce. While I was off I realized I missed three things about work: 1) being surrounded by smart, creative people; 2) solving hard problems everyday; and 3) having a purpose greater than myself. Over the l a st month Ev Williams and I started talking about coming and helping Medium full time, I realized it was time to get back into the fray and that Medium would allow me to get back to the things I missed. I‚Äôm grateful to Ev for the opportunity to bring new ideas and perspectives to the world. As I‚Äôve gotten started I‚Äôve been lucky to spend time with Dan Pupius and the team at medium. Dan has done an exceptional job preparing the way for me. I want to preserve the special nature of the team Dan has created and be true to his legacy by focusing on the people that make medium great. Time to get started‚Ä¶ Rolling, building, breathing 122 7 Thanks to . 122 122 7 Leadership Media Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2017-01-31"},
{"website": "Medium-Engineering", "title": "in which code2040 and medium hold a writing workshop for software engineers", "author": ["Joy Chen"], "link": "https://medium.engineering/in-which-code2040-and-medium-hold-a-writing-workshop-for-software-engineers-cdce08c051ac", "abstract": "Sign in Joy Chen Sep 22, 2016 ¬∑ 6 min read After work on August 8 2016, a Tuesday evening, a little more than 60 people gathered at the Medium offices for an unusual event: a writing workshop. Who are they? They‚Äôre software engineering interns, college-age, brillian t and motivated. This description comes first-hand, because we‚Äôve had the pleasure of hosting three of them at Medium this summer. ‚ù§ CODE2040 helps to connect companies with black and Latinx students for internships. This year, the fifth year of the program, there were more than 80 fellows working all around the Bay Area. On this particular evening, we played host to more than 40 who were based in San Francisco. Twenty of my coworkers came along to help. :) Because CODE2040 fellows are software engineers, the majority of the volunteers hailed from Medium Engineering , but we had representatives from the Design Team , Product, Recruiting, and HR‚Ä¶ basically everyone. We were there to support, by being facilitators, sounding boards, copy-editors, and cheerleaders. Our goal for the evening was to practice storytelling through writing. This was our mission statement: To leverage technology to raise the voices of the fellows, and help them craft their story ‚Äî capturing personal and professional development through highlighting their journey as well as their professional qualifications. To kick off the workshop, we discussed what storytelling in today‚Äôs world means, and how it can fit into a professional context. Some examples we roped in included Isis Anchalee ‚Äôs You May Have Seen My Face on BART ‚Äîa great example of using writing to give a fuller, personal context on an important issue‚Äîand Tyler Hedrick ‚Äôs Good debugging is putting yourself in your user‚Äôs shoes , as an example of technical writing that showcased the very human, fallible, and creative process of working in software. When we asked the fellows ‚ÄúWhy do you write?‚Äù we got a whole range of eloquent, honest answers. This set a welcoming, positive tone for the rest of the evening, when we broke up into small groups to commit ideas to the screen. That‚Äôs enough of my words. Here are some of theirs instead: It started as a dream in a way. I walked out of the car and behind me was my little brother and sister. He looked up at me through the glass window, eyes wide open. ‚ÄúDon‚Äôt go‚Äù, he said adorably while turning his glance away. I knew I had to leave. It felt like a golden opportunity. A gold rush perhaps. [‚Ä¶] I knew that I was going to be spending eight hours a day with people who [‚Ä¶] could help me grow not only as an engineer but as a individual. [‚Ä¶] I sat down with a senior engineer who told me I could pick his mind apart. Poor soul. He had no idea what he had gotten himself into. ‚Äî victoranyirah in The First Two Days I got to the bank, deposited the money, paid some debts, got on another cab and quickly returned to the airport. Business as usual, I was back in the game after half an hour‚Ä¶or so I thought. Check this out. I got back into the line and, when it was my turn to pay, my card kept on getting declined. [‚Ä¶] I called the bank it turned out that I had deposited so much money and payed so many debts and they thought something had stolen my card and was using it for fraudulent transactions. Oh boy‚Ä¶ ‚Äî David Justo in The misadventures of a young tired sophomore trying to get to San Francisco In the midst of all this pressure [‚Ä¶] I was pretty concerned about making sure that I would not embarrass myself. I didn‚Äôt want to be the reason that people would say ‚Äúthat‚Äôs why we don‚Äôt hire black people.‚Äù [‚Ä¶] [T]he most valuable piece of advice I received was something I heard over and over again; relax, have fun and ask questions! An internship is primarily to learn and hone one‚Äôs skills. Once that hit home, I [‚Ä¶] was infinitely more productive and [‚Ä¶] I loved my job. ‚Äî Fredrick Kofi Tam in Two years here, tons of Slacking off in San Francisco Love & programming: it‚Äôs a strange pairing. But from my freshman year of college, when I first wrote HelloWorld.java, programming felt like asking out my crush: terrifying yet exhilarating, perhaps an interaction doomed to failure but a mission forever worth undertaking nonetheless. Programming, like love, takes time. It requires patience, the ability to healthily handle frustration, the willingness accept setbacks, and the self-awareness of knowing when to take a break. ‚Äî Miles Hinson in Odi Et Amo: When Love Meets The Art of Programming Dear 1st day of Internship self, Don‚Äôt be scared. [‚Ä¶] Do things you‚Äôve never done. Take risks. Remember that all the fun and success lies outside of your comfort zone. Talk in every meeting. Suggest ideas and solutions. Speak in front of a room of people. Speak to people who have executive positions within your company. ‚Äî Brianna Fugate in Dear 1st day of Internship self The great thing about community is that it follows you no matter where you go. If you‚Äôve got something in common, miles and miles away it will still bind you with people you may have never met before in your life. Similar to if any of us Fellows saw someone with a CODE2040 logo on, we‚Äôd run up to them smiling as if we‚Äôve known each other forever. ‚Äî Scott Paillant in Adventure Is Everywhere If You Can Find It [E]verything was new. For a girl who used to compare herself to others in the sense of what they‚Äôve accomplished, how far they‚Äôve gone, and the opportunities they‚Äôve had, this was a big step. That same girl was assigned to a huge project, responsible to perform a very scary change in the system, where any error could be crucial. But now here I am, finished my project almost 1 month before my internship ends. The changes went into production and everything is working perfectly. That‚Äôs when I discovered I was always capable, always brave, always motivated, always a dreamer, and always ready for any challenge. ‚Äî Anna Oikawa in Summer of discoveries Special thanks to Madeline Bermes & Amanda Chiachi for event organization, Dan Pupius for setting up and manning a portrait booth (the star attraction, where the loudest laughter came from), and Code2040 staff & fellows for being the friendliest, neatest guests. ‚ù§ Engineer @Samsara. Formerly @Medium, @scoutdotfm, and Affective Computing @medialab @MIT. ‚ù§ science, words, humans. 45 45 45 Code2040 Diversity Events And Press Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2016-09-22"},
{"website": "Medium-Engineering", "title": "simple style sheets", "author": ["Anton"], "link": "https://medium.engineering/simple-style-sheets-c3b588867899", "abstract": "Sign in Anton Sep 28, 2016 ¬∑ 6 min read What happens when you drop the ‚ÄúC‚Äù from CSS? At Medium, we‚Äôve been experimenting with a new way of using CSS to style our user interface components: a few months ago we started using small, atomic, and non-cascading classes instead of the usual BEM modifiers. The result is that we have a slightly more awkward but much more robust system of styling visual components. CSS has only one global scope. There are no namespaces, no local scopes: if you define a class‚Äîsay author‚Äî to use on the story page, you have to be very careful to not to re-use the same class anywhere else because the same set of rules will be applied there as well. For generic components this is OK and even desirable: a Medium button should look pretty much the same on any page, after all. The complexity hides, as it always does, in the gray area of pretty much : what if you want a button to look slightly different but just on this one single page. Maybe here‚Äîjust here‚Äîit makes more sense for it to not have a border? In traditional CSS you would try to solve this problem with selector specificity: if your button should look different just on this page, you can overwrite its properties by constructing a selector specific to the page. But what happens if you want to share these additional properties across multiple cases where the button is used‚Äîbut not all of them? What if you want to make buttons components that can sometimes be borderless? To do this, we adopted a notation called Block Element Modifier . BEM allowed us to have a button (defined by a class button ) that contained a label ( button-label ) that was sufficiently name-spaced to avoid conflicts with other labels such as form-label, link-label, and so on. We could also customize components and sub-components by adding modifiers to them. We could have borderless buttons defined by a combination of button and button--borderless classes . The BEM notation was a very clever idea but our team struggled to scale it well. One case where things became particularly gnarly was setting offsets. To lay out components on the page you need offsets which often depend on the environment where they are being applied. What do you do when Design asks for an offset of 10 pixels on the story page but an offset of 20 pixels on the home page? We used to use modifiers, such as button--padded, but quickly realized that we needed to be more specific. We started to add more specific modifiers and after a little while ended up with lots and lots of them. And, to add insult to injury, a big chunk of them were all doing the same thing. We had dozens of CSS classes applying same rules to different elements: The world we ended up with was a place where base classes described what elements were (a button, a menu) while their modifiers could describe either their looks or behavior (a button with top margin of 10 pixels). This was very confusing, especially for people who were not well-versed in the history and details of our usage of CSS. To make things even more confusing, sometimes components didn‚Äôt behave the way you expected them to behave from reading their declared classes. You would see a primary button with classes button and button--primary expecting it to look just like any other primary button on the website. But that wasn‚Äôt always the case. Some pages and components were overriding the components and modifiers that made primary buttons, for example, have different colors and offsets. And if you were to modify the original button--primary you wouldn‚Äôt even know that you broke something unless either a bug was filed or you searched the codebase and carefully read all instances where the classes in question were mentioned. One answer to this would be to strictly enforce the use of modifiers. We tried this approach and ended up in an episode of The Twilight Zone where nothing made sense anymore: button--primaryAndDarkGrey. And god forbid you‚Äôd want a padding on that. It was also never clear when properties were overriding each other. You‚Äôd have a list--borderless making assumptions about padding for its items and if you wanted more padding you‚Äôd need to add list--itemPadded making everything even more confusing. It was impossible to tell how deep modifiers go with their assumptions. Finally, trying to solve these problems with BEM introduced lots and lots of code duplication. Generally speaking, most components behave the same way: sometimes they have borders, sometimes their text is dark grey, sometimes they are hidden. With BEM, every component had to re-declare this over and over again. In the screenshot above there are two identical classes‚Äî creditCardForm--marginTop20 and row--marginTop20 ‚Äîthat simply add a top margin of 20 pixels to whatever element they‚Äôre applied. The solution we‚Äôve been experimenting with reduces CSS to its bare minimum and doubles down on Soy , our templating language. I learned about this idea from a blog post by Adam Morse titled CSS and Scalability . Initially I dismissed it because I didn‚Äôt like his tone but, thankfully, I‚Äôve been trained well by Nassim Taleb‚Äôs books to look past holier-than-thou writing. So I re-read the post a couple of times and the idea grew on me. What if we reduced CSS to the smallest possible components that only described what elements looked like and how they behaved, and moved the rest onto Soy? Take this simple piece of code for example: We could try to make it a component or a sub-component (is this a label? is this label different from dozens of other labels on our website?) or we could say that it‚Äôs an element with a left offset of 10 pixels and text that uses our regular UI font. In future, if we want to make text yellow, we‚Äôll simply add u-textColorYellow and move on with our day. This code is robust. Unless someone goes in and changes u-marginLeft10 to have an offset of 20 pixels, this component won‚Äôt suddenly look different because of changes to an unrelated piece of CSS code. But this code is awkward. If we go all-in with this approach, every button element will look like this: You get the idea. We can hide this behind our templating language: You‚Äôll still simply call views.ui.buttons.generic to render a button but debugging might get more difficult. After more thought and some experimentation, we found a middle way: get rid of modifiers, leave non-atomic CSS only for low-level interface components (buttons, links, lists, and so on) and have the rest use these very specific atomic classes. The code below renders a button and adds top margin of 10 pixels to it on bigger screens and 20 pixels on extra small screens: This approach drops the ‚ÄúC‚Äù from CSS and turns it into a simpler, flatter, and more robust language. It might not be pretty or very clever but it does something incredible: it allows me to leave the office every day without worrying that somewhere, on a page nobody has touched in ages, a button broke down again. Trust & Security Engineering at Medium. For issues with your account, email [email¬†protected] . 416 18 Thanks to Nick Santos , Dan Pupius , Daryl Koopersmith , Bobbie Johnson , and Stephanie Yeung . 416 416 18 CSS Web Development Webclient Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2016-09-28"},
{"website": "Medium-Engineering", "title": "8 lessons from nsnorth 2016", "author": ["Eugenia Dellapenna"], "link": "https://medium.engineering/8-lessons-from-nsnorth-2016-643161507f36", "abstract": "Sign in Eugenia Dellapenna Jun 8, 2016 ¬∑ 9 min read A few weeks ago I attended NSNorth , a small, single track, iOS developer conference in Toronto . The talks were mostly non-technical and focused on subjects related to developing great apps. Topics ranged from how designers and developers can work more effectively together to which features were added to UIKit in iOS 9. Here are the top lessons that I learned while at the conference (in the form of a listicle!): This is a theme that came up i n several talks, including the keynote. We have a tendency to focus on technology as an end in and of itself. We all get excited about using the newest languages, the newest frameworks, the newest databases. However, technology and code are just tools for solving problems. In the end, what really matters are which problems you choose to solve. Technology alone won‚Äôt save the world. ‚Äî May-Li Khoe The keynote was given by may-li khoe , the Director of Design at Khan Academy. She also previously worked at Apple for 7 and a half years on the Human Interface Device Prototyping team (she helped design 3D touch, among other cool things). Because of her experience working at Apple, people ask her all the time what she sees the future of technology looking like. She turns this question back on them and asks ‚Äúwhat do you want the future to look like?‚Äù The decisions that we make today have the power to shape the future, which means that we have to be mindful about creating impactful, inclusive products. Before you start building anything, ask yourself why you want to build it. Once you figure out why you want to build something, figure out how you will build it. The why and the how ultimately decide the what. Too often, people decide what they are going to build without having a clear picture of why they‚Äôre building it. Jon Edwards had a similar message in his talk, where he discussed developing products for niche markets. If your product puts technology before people and focuses on innovating over providing real value to customers, then you will be easily out competed by someone else. Instead, if you focus on providing the most value (but in an innovative way), you can stay ahead of the competition. Put people before technology. Ayaka Nonaka gave a talk about NSLayoutAnchor , UILayoutGuide , and UIStackView , which are new classes that were added to UIKit in iOS 9 (that we can finally start using after iOS 10 comes out and we drop iOS 8 support!). NSLayoutAnchor provides a more concise way to add constraints to views without using the ridiculous initializer on NSLayoutConstraint. It also provides extra type safety and will throw compiler errors if you try to create a constraint that doesn‚Äôt make sense, e.g. adding a margin constraint between the y-axis of one view to the x-axis of a different view (though it will only throw the error in Objective-C, not Swift). You may know of UILayoutGuide from the layoutMarginsGuide property on UIView. But it turns out that they can be used for more than that! Let‚Äôs say, for example, that you want to center a bunch of subviews in respect to their superview. You could add them all to a container view and then center that container view in the superview. The problem with this is that you‚Äôre adding another view to the view hierarchy just for layout. It also messes with the responder chain. Your other option is to add them all to a layout guide and center that in the superview. The layout guide was built exactly for this use case, doesn‚Äôt clutter up the view hierarchy and doesn‚Äôt mess with the responder chain. Lastly is UIStackView, which is for stacking views vertically or horizontally. This is something that should be really easy but is actually annoyingly complicated. Once you start thinking in terms of UIStackViews, you start seeing them everywhere! For example, UIStackView could help simplify the the layout of the recommend/response count icons in the related reads view, since it would take care of not adding the margin in front of the response bubble if the recommend count was hidden. In fact, the entire view could be a stack view of stack views! Jonathan Rhyne talked about the importance of storytelling for branding and marketing your product. According to the narrative paradigm , ‚Äúall meaningful communication is a form of storytelling‚Äù, and stories provide a way for us to comprehend the world around us. We can learn a lot from brands that tell compelling, emotional narratives to sell their products (e.g. Apple, Tom‚Äôs shoes). Therefore, when marketing your product, don‚Äôt just give a list of features. Instead, create a narrative around your product: why you built it and what problems it solves for your target audience. Put people at the center of your story and give your product a supporting role. Tom Creighton talked about ways for developers and designers to work together in harmony. I actually think that this is something that we do pretty well at Medium, but I still enjoyed this talk (particularly the husky slide!). One thing you often hear in the industry is that ‚Äúdesigners should code‚Äù to better collaborate with developers. However, this distracts from the true problem of communication that exists in many organizations. In the end, it doesn‚Äôt matter if a designer knows how to code or if a developer knows how to use photoshop, as long as they can communicate with each other how they like to work and come to a shared understanding. For example, if a designer likes to provide mocks in the form of a Sketch file, and the developer is able to work with that, then that‚Äôs fine for that particular team. If the developer doesn‚Äôt want to install Sketch, then they should work together to find something that works better for them. It all comes down to empathy and communication. Here are a bunch of tips for more effective collaboration between dev and design (many of which we already do at Medium): Provide constructive criticism, and not just within your own discipline. We all have viewpoints and ideas that can help improve the product. Just make sure that your feedback is specific and actionable. Communicate your preference for how things are delivered. If you prefer having specs with exact pixel measurements, say that instead of being annoyed when the designer doesn‚Äôt provide you with one. Put designers and developers next to each other in the same space (this was the context of the husky slide üòÉ). This helps promote communication and empathy. There‚Äôs no time too early to start collaborating cross discipline. Engineering constraints can help inform design in terms of what‚Äôs feasible or what‚Äôs easily achieved, and knowing the design early on can help inform engineering decisions. Share knowledge about how things work and why decisions were made. This often happens by accident, but could be a more mindful part of how we work together. Following these tips could help us have a more positive experience working together, and could help improve project outcomes as well! Zev Eisenberg gave a lightning talk about BonMot , which is a cool library for formatting strings in iOS. This is something that we do A LOT in our app and is a fairly complicated part of our codebase. As a result, I think I took more photos of slides during this talk than all of the other talks combined, even though it was less than 10 minutes long. Although it‚Äôs unlikely that we‚Äôll replace our existing system for rendering text in the app, I think we could still learn a lot from this library‚Äôs approach. In particular, it has support for formatting localized strings, which is something that we‚Äôll have to deal with in the near future. ‚ÄúCharting‚Äù is a term coined by Robleh Jama (who gave this talk). It is ‚Äúthe act of climbing the top charts of the App Store.‚Äù Robleh is the CEO of Tiny Hearts Studios, which built Pocket Zoo, Wake Alarm and Next Keyboard, all of which have appeared in the top charts. Robleh‚Äôs tips for charting are as follows: Build a great product (duh). It should either be the best in its category or solve a unique problem. Get featured prominently in the App Store. Apparently an App Store feature is equivalent to $100‚Äì300k in marketing, and is a major key to charting. An important aspect of this is building strong relationships with representatives at Apple and Google. If you have a paid app, becoming the free app of the week can also provide a major boost, but there are strict requirements that your app has to meet to be eligible. Get press coverage in highly trafficked publications on launch day (e.g. product hunt, tech crunch, etc.). Robleh used Medium(!) to build a press kit that he sent around to different outlets before launch day. Invest in a great promo video. Cross promote apps within your other apps. During the launch of Next Keyboard, Robleh made his older apps free and added in-app promos to prompt users to download the app. Here‚Äôs Robleh‚Äôs Medium post about his Medium hosted press kit: medium.com This was the title of the last talk of the conference, given by Pamela Pavliscak . The talk discussed the ways that algorithms follow us around the web, trying to characterize us based on our past behavior. The algorithms inevitably come up with a creepy, frankenstein version of you, obsessing over tiny details (like that one search you performed over a year ago), while missing important pieces of information. As a result, people try to game the system by browsing in private mode or creating multiple profiles to reflect different aspects of their lives. Including human input will provide a better experience for the end user of your product, since algorithms will never get it completely right on their own. It‚Äôs like how we decided to build curated collections for the Medium homepage! Pamela does a much better job of summarizing her talk in this article: uxmag.com She‚Äôs also an active writer on Medium: medium.com The organizers live updated a wallet pass throughout the conference to communicate to the attendees. I had no idea that passes were so fully featured. It included a full schedule of the conference and a map to the venue on the back, and updated to show the current speaker during each of the talks. They even updated it at the end of the conference with a personalized thank you and our jumping group photo. Overall, it was a really great conference, and I had lots of conversations with very interesting people. It was especially refreshing to get out of San Francisco and to see the amazing work that everyone is doing outside of our little bubble. I would like to thank Medium for letting me use my education budget to attend the conference, and I would like to encourage more people at the company to take advantage of this awesome benefit! VP, Product Engineering @Medium 42 42 42 Startup Tech Mobile Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2016-06-09"},
{"website": "Medium-Engineering", "title": "engineering interviews what we screen for", "author": ["Jamie Talbot"], "link": "https://medium.engineering/engineering-interviews-what-we-screen-for-af2d84122417", "abstract": "Sign in Jamie Talbot Jun 9, 2016 ¬∑ 4 min read We recently undertook a project to improve Medium‚Äôs engineering interview process. As part of that, I wrote this document to describe the qualities we are seeking in engineering candidates. It was originally published to Hatch, our internal version of Medium, on February 26, 2016. For more information about Medium‚Äôs practice of making internal documents public, see Hatching Inside Medium . This is the actual document used by Mediu m to define the criteria we look for in engineering candidates and has replaced the version on Hatch as the source of truth. If you apply for a job at Medium , these are the criteria on which you can expect to be judged. Preface: Refining our process Part 1: What we screen for Part 2: What we don‚Äôt screen for Part 3: Grading rubric This guide is up for continual improvement. Suggestions are welcome for improvements in clarity and precision. However, it is unlikely that the headline capabilities and categories will be changed, unless there are significant new learnings. At a high level, we care about three things when considering whether to hire an engineering candidate. Can they build software? Can they learn and teach? Are they aligned with our values? Each high-level heading is assessed in six categories. The rationale for each is discussed below. This is the engineer‚Äôs core responsibility to the organisation. We prefer to give employees problems to solve, rather than solutions. It‚Äôs high leverage and allows us to move faster as an organisation. If we hire people who can‚Äôt solve problems, we will fail. We have a healthy sense of urgency. We need the candidate to be able to translate their solutions into code without much friction and quickly grok other people‚Äôs code (when working in their language of choice). We want Code Reviews to be focused on the validity of the approach, not basic coding issues. We want to give our employees ownership. Successful engineers need to be able to unblock themselves, search for answers before asking for help, and make reasonable decisions within their scope without seeking consensus. This doesn‚Äôt mean they need to work in isolation ‚Äî seeking input to help solve hard problems is important ‚Äî but they should be able to drive projects forward, and work independently as needed. Understanding how common data structures and algorithms work ‚Äî and how to evaluate their trade-offs ‚Äî are important fundamentals of being able to design good solutions, even if the ability to implement, say, a hash table, is unimportant for the vast majority of roles. Broadly speaking, for most positions we are looking for the appropriate usage of data structures to solve a problem, rather than intricacies or computer science trivia. A more in-depth understanding may be required for certain specialised roles. Coding in a team is hard, and relies on software being structured in a reasonable way, making use of reusable components, and sensible abstractions. We need engineers who, at a senior level, can design these abstractions and describe how they fit together, and who, at a junior level, understand why these abstractions are important and understand how complex systems are constructed. Much of a programmer‚Äôs job is being told, either by a compiler or during code review, that their code is incorrect or incomplete. It requires perseverance. Building a product to a deadline, where there aren‚Äôt always clear answers requires determination. Someone with a growth mindset will see obstacles as challenges, not barriers. Resoluteness is not about tolerating abusive work environments, but about working diligently in the face of hard problems. Candidates who are eager to learn and capable of doing so will develop faster. Candidates who can teach us something about the world or ourselves will help us become more effective as an organisation. Asking ‚Äúwhy?‚Äù and seeking answers are crucial parts of building something new. We want employees who are curious about the world and seek to understand it. Intellectual and emotional curiosity drives creativity. Employees who are self-aware and aware of their surroundings ask more questions and make more connections. They have more tools at their disposal to solve problems, and can recognise underlying patterns in systems. They are capable of self-reflection, which enables them to grow. They recognise when others require help, support, or feedback, and when someone delivers critical feedback to them, they are capable of being receptive to it. An empathetic organisation makes it easier to employ the reasonable person principle . Empathy minimises the desire to blame, and helps an employee recognise when someone needs a hand, or deliver feedback in a way that it will be heard. Empathy for users of our product helps ensure we build a platform that solves real needs, and helps us work in such a way that respects the time and energy of our colleagues, by considering them when writing code or designing interfaces. Communication is key to everything we do at Medium, whether through describing ideas, discussing approaches, presentations, status updates, or a myriad other avenues. The ability to communicate an idea, and to understand communicated ideas is of critical importance to ensure a well-aligned, agile team. Although we favour individual action and do not seek consensus, the problems we are trying to solve and the vision we are trying to execute are too big for one person to do alone. Every project will involve multiple people, and employees have to be able to work with one another to be effective. We each have a particular view of the world, but when too many of us have the same perspective, we risk designing incomplete solutions that ignore those who are in our collective blind spot. Each new perspective we can add to the company helps us bridge the gaps between ourselves and the world, and can expose us to ideas that when combined with our own experience, enable us to create something new . Build trust Do hard things Instigate change Level up Time is precious Have fun Ev has previously described these in depth. Ex-gaijin, kangaroo-loving software simian from Merrie England, building @Mailchimp and @Pinian. Formerly @Medium and @StumbleUpon. 649 2 649 649 2 Medium Engineering Interviewing Values Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2017-12-22"},
{"website": "Medium-Engineering", "title": "engineering interviews what we dont screen for", "author": ["Jamie Talbot"], "link": "https://medium.engineering/engineering-interviews-what-we-dont-screen-for-4381cfdfa703", "abstract": "Sign in Jamie Talbot Jun 9, 2016 ¬∑ 5 min read We recently undertook a project to improve Medium‚Äôs engineering interview process. As part of that, I wrote this document to describe qualities that we aren‚Äôt specifically seeking in engineering candidates. It was originally published to Hatch, our internal version of Medium, on February 26, 2016. For more information about Medium‚Äôs practice of making internal documents public, see Hatching Inside Medium . This is the actual document used by Medi u m when hiring engineering candidates and has replaced the version on Hatch as the source of truth. If you apply for a job at Medium , you can use this to see criteria for which you will not be negatively judged if they are lacking. Preface: Refining our process Part 1: What we screen for Part 2: What we don‚Äôt screen for Part 3: Grading rubric This guide is up for continual improvement. Suggestions are welcome for additional capabilities that should be considered unimportant, as are those for improvements in clarity and precision. However, it is unlikely that any of these categories will be removed, unless there are significant new learnings. There are any number of qualities, competencies and achievements that we could screen a candidate on. However, many of those qualities traditionally prized by tech companies have no causal relationship to the candidate‚Äôs future performance. This document lists some of the capabilities that are commonly part of assessment criteria at other companies, but which we do not specifically look for in candidates. None of the following areas are negative. However, screening for them can cause us to focus on factors that are tangential or outright unimportant to job performance. There are many fine candidates who will do well at Medium (and current colleagues who are already doing well!), who might be missing all or most of them. When interviewing, you may record the existence of these qualities ‚Äî provided they are supported by observable facts ‚Äî if you feel they substantially contribute to a person‚Äôs overall suitability, but you may not count a lack of them against the candidate. A ‚Äúgood‚Äù school doesn‚Äôt mean the candidate will succeed in their role. The entry practices of many schools are still discriminatory by economic status, race and/or gender. Many excellent engineers did not study computer science in school. Many very accomplished people did not even attend or finish school, cf. Ev. A high GPA is nice. It shows the candidate was able to work at a high level for an extended period of time. A low GPA in isolation is not a strong signal of anything. The college experience for many requires making compromises based on the practicalities of life. For senior candidates, a GPA is basically meaningless. (I got a higher GPA than Dan , for instance, but‚Ä¶ so what?) For junior candidates, project work is more illuminating. Many companies show excessive positive bias or deference to candidates who have previously worked at major companies like Facebook, Google or Amazon. While these companies are known to have generally good engineers, they are large enough to have bad ones as well, and their hiring practices are such that many qualified candidates are rejected. A long stint at a major company like these can even in some cases be detrimental as many problems are already solved for engineers, a luxury that is not usually available at a startup. Finally, these candidates may also have distorted views on what constitutes ‚Äúsuccess‚Äù for products, be less comfortable with uncertainty, or have views on deployments and the application development lifecycle that are not aligned with the needs of a smaller company. Candidates with large companies like these on their resumes should be interviewed as we would any other candidate. It is not important for you to feel like you could be friends with a candidate. We are not building a family, we are building a team. A good working relationship, the ability to collaborate, and mutual respect are sufficient. We tend to want to ‚Äúhave a beer‚Äù with people who are like ourselves, which can lead to homogenous teams. Requiring a candidate to have contributed to open source projects is prejudicial. Many candidates do not have the time to contribute to open source projects because they need to work to support themselves or their families. In addition, many open source projects have toxic cultures that are off-putting to many candidates. Finally, it‚Äôs not a great filter to kick out everyone who doesn‚Äôt want to work on software for free in their off-hours. It is not important for most candidates to be able to implement a red-black tree from scratch. It is not important for most candidates to know what a Fibonacci Heap is if they‚Äôve never encountered one. It is not important for most candidates to be able to reverse a linked list on the spot. A high level knowledge of time and space complexity, the ability to research, learn and integrate different approaches, and recognition of trade-offs is in most cases sufficient. (In specialized positions, the importance of this might vary.) It is not a requirement that the candidate know JavaScript or Go. For all but the most specialized roles, interviews should be technology-agnostic. You should instruct the candidate to use the language they are most familiar with. We want candidates who have the ability to make a decision and back it up with sound reasoning. However, confidence as an isolated trait is not necessarily positive. Many candidates will have difficulty demonstrating confidence in an interview setting (for marginalised candidates, see also stereotype threat ). Specifically screening for confidence disproportionately favours white men. Finally, many of the most self-aware people actually appear to lack confidence because they recognise how much they don‚Äôt know. The opposite is also true . Culture fit is a polite way of saying ‚Äúbe like us‚Äù. If we‚Äôre looking for people who fit in with what we already have, we risk closing ourselves off to new perspectives, and building a homogenous team that suffers from groupthink. Note that culture fit is distinct from alignment of values, and the addition of new perspectives, which are valuable criteria. If someone can #DoHardThings and help us connect to a community who we don‚Äôt really understand, they are a potentially valuable resource for us, even if (and perhaps especially if ) they make us feel uncomfortable by forcing us to confront our prejudices. Ex-gaijin, kangaroo-loving software simian from Merrie England, building @Mailchimp and @Pinian. Formerly @Medium and @StumbleUpon. 413 2 413 413 2 Medium Engineering Interviewing Values Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2016-08-09"},
{"website": "Medium-Engineering", "title": "mediums engineering interview process", "author": ["Jamie Talbot"], "link": "https://medium.engineering/mediums-engineering-interview-process-b8d6b67927c4", "abstract": "Sign in Jamie Talbot Jun 9, 2016 ¬∑ 3 min read For a growing company, interviewing is one of the most important tasks employees are asked to do, but one challenge is that interviewers don‚Äôt always feel adequately qualified to assess candidates. Lacking shared standards, it‚Äôs easy to rely on gut feeling and subjective impressions, which can depend on mood and incorporate many forms of potential bias. Many agree that the technical interview process is broken . At Medium, we‚Äôve long recognised th e need to be intentional in our hiring process and have been thinking about how to improve it for most of the company‚Äôs existence . At the beginning of the year, we decided to put renewed effort into improving Medium‚Äôs process for hiring engineers, updating our existing selection criteria and creating a rubric to help provide consistency across interviewers. While we have never based our hiring decisions on certain potentially misleading criteria like college name or GPA, we took the opportunity to make factors like this explicit and spell out what we do and don‚Äôt care about. This is important to ensure we maintain these principles as we grow rapidly. We‚Äôve been using these guides for the last few months and are excited about the results we‚Äôve seen so far. The eng team did a day-long off-site in April to understand the rationale, get familiar with the material, and develop interview questions. We continue to provide ongoing coaching to our interviewers, and iterate on the rubric itself. Today, we‚Äôre excited to share our hiring documentation for everyone to see. We are releasing four documents we put together under a Creative Commons Attribution Share-Alike license: The rationale for refining our process What we look for in candidates What we don‚Äôt look for in candidates How we grade candidates To ensure our own accountability, the public rubric and rationale will be the actual guides that we use to judge candidates; as of today, there is no different internal copy. Following the lead of our legal team‚Äôs transparency around our terms of service , we plan to put the rubric on Github so people can see how it evolves over time. Many were involved in this effort. Thanks are due to Jesse Toth and Danilo Campos at Github, and Karla L. Monterroso of CODE2040, who reviewed early drafts. We were influenced in part by the writing of Camille Fournier , and inspired to release it in part by Clef‚Äôs handbook and Automattic‚Äôs legal documents . CODE2040 convened a workshop where we got to hear some really smart perspectives from industry leaders, which helped shape the rubric. And internally, thanks are due to the many Medium engineers who offered thoughtful critiques and suggestions, including Joy Chen , Jonathan Fuchs , Emma Zhou (having been hired using it!), and Kelly Ellis . Releasing this publicly is unusual and maybe unique. It‚Äôs also a little discomforting, but we believe it‚Äôs an important step that demonstrates our commitment to hiring objectively, based on the things that we think actually matter to job performance. We don‚Äôt claim to have all the answers, nor that this specific set of skills will be the ones that meet other organizations‚Äô needs, but we hope that by sharing the documents under an open license, others can build upon our work in ways that works for them. We hope it sparks a discussion within the wider tech community about hiring best practices and look forward to learning from our colleagues in the industry about areas where we can improve; we expect our process to evolve continually. Regardless, we‚Äôre interested to hear what people think. And if Medium sounds like a place you want to work, come and join us, we‚Äôre hiring ! Ex-gaijin, kangaroo-loving software simian from Merrie England, building @Mailchimp and @Pinian. Formerly @Medium and @StumbleUpon. 644 1 Thanks to Kelly Ellis and Dan Pupius . 644 644 1 Medium Engineering Interviewing Values Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2016-06-09"},
{"website": "Medium-Engineering", "title": "advice to our high school selves", "author": ["Jean Hsu"], "link": "https://medium.engineering/advice-to-our-high-school-selves-a181f2c3eeaf", "abstract": "Sign in Jean Hsu Apr 21, 2016 ¬∑ 2 min read Today, a few of us here at Medium hosted a Girls Who Code field trip for a group of high school girls ‚Äî they spent their afternoon touring the Medium office and then chatting with us about our work and lives. To conclude the field trip, the question came up: ‚ÄúWhat advice would you give your 15‚Äì17 year-old selves?‚Äù Here are some of our answers: Competition is an illusion. Much of our anxiety in high school (and college if you‚Äôre unlucky) is about how we are ‚Äúperforming‚Äù compared to our ‚Äúpeers,‚Äù and it can color all our interactions. In reality, we‚Äôre all running our own trails, in our own way. Once you realize that, understanding and helping other people, and letting yourself be understood and helped, becomes completely natural, and everyone can be better, with a lot less anxiety involved. ~ Joy Chen Do things that you actually want to do, rather than because you think you have to. I quit piano lessons, and it didn‚Äôt really matter in the long run. So you don‚Äôt have to do everything just because you think it will look good on your college app. ~ Eugenia Dellapenna Don‚Äôt be afraid to ask questions or admit when you don‚Äôt know something. If it‚Äôs in a group situation (like a CS class) it‚Äôs extremely likely that others are thinking the same question. And in the professional world there‚Äôs no stigma around admitting you don‚Äôt know something ~ Kelly Ellis What Kelly said. If you don‚Äôt know something, you can say something like ‚ÄúHey I‚Äôm not familiar with that. Do you have any pointers to resources about that?‚Äù As a 15 or 17 year old, I probably thought I would be judged or look bad if I didn‚Äôt know something. If you ask for help, it shows maturity and a willingness to learn. ~ Jean Hsu Building on Kelly‚Äôs and Jean‚Äôs, don‚Äôt not ask questions because you think someone will negatively judge you, because if they do then they‚Äôre an asshole and that‚Äôs their problem and not yours. And don‚Äôt let assholes get you down. ~ Stephanie Yeung Co-founder of coleadership.com , transforming engineers into leaders. Previously engineering at @Medium, Pulse, and Google. 56 1 Thanks to Eugenia Dellapenna , Stephanie Yeung , and Kelly Ellis . 56 56 1 Girls Who Code Women In Tech Events And Press Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2016-05-05"},
{"website": "Medium-Engineering", "title": "typography is impossible", "author": ["Marcin Wichary"], "link": "https://medium.engineering/typography-is-impossible-5872b0c7f891", "abstract": "Sign in Marcin Wichary Aug 24, 2016 ¬∑ 15 min read Y ou‚Äôre a front-end engineer, building boxes and putting text inside them. A lot of websites, and a lot of native apps, are basically that ‚Äî text flowing into boxes. It‚Äôs a testament to typography that hundreds of years since Gutenberg, letters and boxes keep reinventing themselves and finding new jobs to do, in materials and technologies that were once future‚Äôs future. You‚Äôre a front-end engineer‚Ä¶ but at thi s very moment, you‚Äôre also a typesetter. It‚Äôs good work. Satisfying work. (As of a few decades ago, you don‚Äôt even have to worry much about lead poisoning .) There‚Äôs something mathematically, geometrically comforting and peaceful about filling boxes. Computers are good at rectangles. This should be easy. But you‚Äôre about to discover, or perhaps already discovered, that this is no smooth sailing. Setting type can be tricky. Type lets you get close, but it never quite does what you want it to do. Let this be your guide, in four simple commandments. During the times of metal type, letters as well as whitespace were physical matter that you could only add to ‚Äî never subtract from: But even then, creative people figured out ways to make things overlap and cheat the restrictions imposed on them by rectangles made out of lead, via solutions that were, basically, hacks : In digital typography, few such restrictions apply. Pixels don‚Äôt have to compete for space the way atoms do, and the same pixel can be claimed and controlled by two or more letters. And so, we can encounter things like this: You can easily imagine the left example (set in a font named Stag ) as four rectangles ‚Äî one for each letter ‚Äî placed together side by side. However, in the word on the right, not only does y invade the space below t, but it actually sticks out farther than where text actually began! Sticking out is not unusual in typography, even if you don‚Äôt use flamboyant typefaces like Zapfino. Here are four examples from Medium today where cropping text precisely at its box‚Äôs edges would cut stuff off: The box is just a suggestion. You can‚Äôt assume everything will fit neatly in; fonts are likely to stick out any possible way (particularly left and right). You need to give text room to stick out. Don‚Äôt crop the box with text and, if you need to, leave padding on all the sides. (A rough suggestion would be to add horizontal padding that‚Äôs ‚Öì of the font size.) In HTML‚Ä¶ by default, browsers allow stuff to stick out, unless the container or one of its parents use overflow: hidden instead of visible. If for whatever reason it‚Äôs necessary to apply that restriction, it is important to add horizontal and vertical padding so that text is not clipped. In native iOS‚Ä¶ iOS crops horizontally by default, although it pads text elements via lineFragmentPadding . This value (5 points by default) should not be made too small, or padding should be achieved through other means. Also, beware of lineHeightMultiple ‚Äî if set to less than 1.0, it can crop tops of letters. On native Android‚Ä¶ I heard that clipChildren and clipToPadding might not work quite well, but you can trick TextView by using a shadow layer around the text with transparent colour radius of 1, and dx of ‚Äì60. Note: This might be outdated info. Please tell me if you know more! I bet you went through something like this at least once in your life. You go to Microsoft Word, choose a font size ‚Äî say, 50 pixels ‚Äî and then start with Helvetica: Mmmm‚Ä¶ Yes. It looks good . It‚Äôs the goddamn Helvetica. Period . But you‚Äôre not done exploring, right? So, you switch to another font, let‚Äôs say Clan, and suddenly things seem rather different: Sure, it‚Äôs a typeface with a different personality, but it also seems‚Ä¶ bigger. That couldn‚Äôt be, though ‚Äî you only changed the font, but didn ‚Äô t change its size. You double check. Correct. It‚Äôs still 50 pixels. So you switch between them to make sure: Definitely, Clan is bigger. How come? It turns out that when you choose font size, you actually only choose the size of the box the font lives within. What happens within that box is up to the type designer. (Well, within and sometimes without , if you remember Zapfino just above.) Here‚Äôs Helvetica and Clan at the same font size, one on top of the other. You can see that Clan feels slightly more‚Ä¶ comfortable within its box. So, yes: two fonts of the same size are likely to not actually be the same size. There are consequences of this beyond just font sizing. Since the font designer can do whatever they want within the box, some fonts will inevitably end up closer to top, or to bottom. You might have to take that into account when laying things out: Another consideration: Within each box, there will be some space both above and below text. So, spacing things consistently might be trickier. When you spread two images apart, you can rest assured 20 pixels will mean exactly 20 pixels. When it comes to text, those 20 pixels will be accompanied by extra vertical padding at the bottom and top of each text box ‚Äî and the text will feel like it‚Äôs further apart. In order for it to feel consistent with image spacing, you might have to pull it closer. (It‚Äôs a weird word, feel, isn‚Äôt it? Oh, believe you me, it will come back many times below.) But hey, at least you can rely on fonts being aligned horizontally, right? Right!? Look at the text below. It‚Äôs all set in the same font, and each line begins at the same horizontal position. However, you can see its starting point getting farther and farther away from the left edge: This is because each letter has some built-in padding on the left and right ‚Äî its own personal space it has for itself and no other letter. That personal space gets bigger as the letters get bigger, resulting in horizontal misalignment. The box is just a suggestion, yet again. Fonts are not only likely to sometimes stick out of the box ‚Äî they will even more likely never be aligned with any side of the said box. This will be more prominent as your type gets bigger. Font sizing works within the font, not necessarily across fonts. You can assume font size multiplied by two will result in letterforms twice the size. However, two fonts with identical font sizes might actually have very different dimensions. Horizontal and vertical spacing of text will be more tricky than images. If you need precise alignment, you will have to account for the horizontal and vertical whitespace that exist within each letter in a font. The shuffle mode of listening to music was once such a revelation that Steven Levy wrote a whole book about it . To me, one of the most interesting parts of the shuffle revolution was people complaining when their iPods played two or more songs by one artist, one right after another. ‚ÄúI just heard a Phil Collins song. Why am I getting another one? Did the shuffle break?‚Äù This is the same kind of a reasoning that has my Mom scoff when I tell her she should go for ‚Äú1 2 3 4 5 6 7‚Äù when betting in the national lottery. Apple could not fix that, but it addressed people‚Äôs complaints by adjusting the shuffle function: they made their sorting less random in order for it to feel more random. Typography works the same way. Type is aligned when it feels aligned, not when it actually is aligned. Here, the tops of the curved letters stick outside the line established by the straight letters, just so they all feel perfectly aligned: Or, the lowercase y has to go underneath T in order to feel as close as the uppercase Y, which is comparatively farther away: This goes deeper. The superscript 2 is no more a normal 2 made smaller, than a kitten would be a regular cat simply shrunk down: In order for the two digits to feel compatible at different sizes, they need to be physically different. Likewise, bold text is not just regular letterforms made na√Øvely thicker: The second line above ‚Äî the fake, gross, synthesized bold ‚Äî is one of the biggest crimes against typography one can commit. The same would be true for italics, or narrower/wider versions of fonts. They‚Äôre not simply slanted or stretched regular fonts; they are all new shapes, redrawn so that they feel, optically, like they‚Äôre slanted, stretched, or made fatter: This, so far, is the domain of the type designer: a person creating the font and painstakingly drawing its shapes. As a deputized typesetter , you can‚Äôt usually get inside the font and mess with its letterforms ‚Äî you have to trust the designer‚Äôs done a good job. There is, however, stuff you will have control over and responsibility for: values for font size, letter spacing, and line height. And within those, you‚Äôll find the same theme repeated. All of those numbers will have to change in order for type to feel the same. Here‚Äôs text in two font sizes: 50 and 500 pixels, with letter spacing adjusted so it feels roughly the same. For the smaller text, the letter spacing is ‚Äì30. For the bigger text, it is ‚Äì60: The kicker is: the letter spacing value already takes into consideration the font size. ‚Äì30 at a smaller font size is proportionally smaller than ‚Äì30 at a larger font size. If it needs to become ‚Äì60 to feel right, it means one thing: letter spacing gets tighter much faster than the font size gets bigger. If you use the same value for letter spacing for both font sizes, they will start feeling very, very different: It‚Äôs something of a theme. As fonts get bigger, letter spacing will need to get tighter, and line heights will need to get closer faster to feel right. As line lengths get longer, line height will have to get larger too, to compensate. Sometimes, you might have to adjust line height even if you just change font weight (for example from light to bold), and nothing else. Values should be reused with caution. You can‚Äôt usually copy/paste parameters for letter spacing or line height for one situation and use them elsewhere verbatim. This is true even for values in units that grow/shrink with the font size (for example em in CSS). Make sure you have proper fonts for all the flavours of type you need. If your site doesn‚Äôt serve bold or italic font files, or the glyphs for superscripts or small caps , your browser or operating system will create synthesized, fake ones instead. (If you do that, I hope you like your eternity spent in typographical hell. I know one thing: it will be justified. ) In native iOS‚Ä¶ Letter spacing and kerning are different things . For some reason, iOS calls the equivalent of letter spacing NSKernAttributeName . It‚Äôs maddening. Just something to be aware of. Did you ever wonder why, on a bigger screen, some text feels harder to read? Why this page, for example, doesn‚Äôt feel quite right? Text, left to its own devices, behaves like gas: it will expand to fill its container. Sure, it will sometimes stick out, and rarely align, but otherwise it will behave like a really, really fast typewriter ‚Äî it‚Äôll go from left to right, letter by letter, until it hits the other margin, then start again on the next line. This, sometimes, results in a disaster. If you imagine the text flowing into a container like a really fast typewriter, imagine an eye on the other side, reading the text, as its equivalent. No, eyes don‚Äôt move quite as precisely as a typewriter would , but they move nevertheless. And, contrary to typewriters, our eyes get tired. There is a point where a line becomes too long for comfortable reading. This is exactly what happened in the screenshot above. The lines stretched very long and, as a result, it became too tiring for our eyes to read comfortably. And when I said ‚Äúa point‚Äù above‚Ä¶ you should know, by now, that there will be no single number that I could give you because typography just doesn‚Äôt work this way. It will all depend on the font you choose, line height, etc. And yet, there is at least a range: we know that a line of 45‚Äì75 characters, with 65 being roughly optimal, is perfect for our eyes when it comes to western typography. The screenshot above seems to have about 130‚Äì140 characters per line, which is far too much, resulting in eye fatigue. The page you‚Äôre looking at right now is, instead, limited in width. Even on a huge screen it will never go above 70-something characters per line, despite seemingly wasted space on both its sides. You might say ‚Äúthis doesn‚Äôt matter any more, we‚Äôre all doing our reading on small screens, anyway.‚Äù But this is where we can get in trouble too, since the lines can also get too short for comfortable viewing. Here, a picture on the side of text might result in lines too narrow for comfort: And, if one of your words is rather long, the end effect could be simply embarrassing, since the word ‚Äî like incredibly below ‚Äî will just wait until there‚Äôs enough room on a line: It gets worse. Small screens or small boxes are also where ‚Äútype doesn‚Äôt like to be cropped‚Äù meets ‚Äútype doesn‚Äôt know any limits,‚Äù and the two edge cases intersect in a really insidious corner. As a typesetter, you should get to know other typesetters. Among them, one famous example is a German fellow, born in 1904. His typesetting contributions are less than clear, since they were overshadowed by his impossibly long name. Are you ready for it? Here we go: Hubert Blaine Wolfe¬≠schlegel¬≠stein¬≠hausen¬≠berger¬≠dorff, Sr. Psych! That‚Äôs not even close to Hubert‚Äôs full name. His given name was basically 26 first names (each for each letter of the alphabet), followed by an enormously long single-word surname. Here it goes, set in a smaller font because those pixels ain‚Äôt cheap: You can read more about Hubert B. Wolfe + 666, Sr. (not kidding) on his Wikipedia page , and among many anecdotes is one about a 1960‚Äôs IBM computer at John Hancock Mutual Life Insurance, which simply could not handle a name of that length ‚Äî Hubert‚Äôs policy was the only one that had to be done manually. More than half a century later, if you take Hubert‚Äôs name and plug it into a website, things might not go very smoothly either. Sure, absurdly-long names are not likely to happen to you, right? But imagine something joint together with a few slashes, or perhaps a naked URL, and the situation becomes a bit more real: It‚Äôs not hard to ask the word to break in the middle, but you have to remember to do it. Otherwise, words can just keep on going, and going, and going‚Ä¶ (In the above examples, they just go off screen. On a larger device, they might actually start overlapping other content!) Lines need maximum lengths. They should be relatively easy to calculate, and they don‚Äôt need to be very precise ‚Äî but make sure your text is not allowed to just stretch as far as the eye can‚Äôt see. Lines need minimum lengths, too. Small screens mean it‚Äôs easier to run out of room. If you have stuff on the side of text, or indentation, test extreme cases and put things on top of one another rather than side by side. Words need to be told to break. Otherwise, by default, they might just run over. (This is especially important when you create containers for others to fill out with text you‚Äôll have no control over.) In HTML‚Ä¶ you can manually insert soft hyphens , zero-width spaces , or <wbr> tags that will be inert ‚Äî except for when the word nears the right margin, allowed to break at this point. You can also use the CSS property word-break: break-all (although this will give you less control) or, if you‚Äôre okay with losing some text instead of wrapping it, text-overflow will come to the rescue. There‚Äôs also automatic hyphenation, but it‚Äôs not supported very well . (And, line clamping .) In native iOS‚Ä¶ Luckily, iOS behaves between when it comes to slashes and long words by default. Look up hyphenation . You can use e.g. zero-width spaces and soft hyphens in strings, but you have to escape them this way: \\u200B and \\u00AD. For labels, instead of text views, NSLineBreakMode can help. On native Android‚Ä¶ Lollipop introduced new hyphenation options: hyphenationFrequency and breakStrategy . Special characters can be inserted, escaped just like in iOS above. S o, there you have it. Welcome to the world of typesetting, where numbers cannot be trusted, rulers only pretend to align to things, and boundaries feel like those in post- Schengen Europe. (Too soon?) A lot of the above might seem arbitrary, but that‚Äôs typography for you, too: some of it is not things that are objectively better, just things we‚Äôve gotten used to over the last few centuries. But I hope after reading the four commandments above, some of the mysteries of typesetting will feel more under control. And, by all means, put ‚Äútypesetter‚Äù in your Twitter bio. Trust me. It‚Äôll feel really good. Even if your name happens to have fewer than 666 characters. Thanks to Nina Liong , Tyler Howarth , Nick Santos , and Bram Stein for reviewing this article. My other articles in practical typography: Space yourself ¬∑ Using system UI fonts in web design . And, if you want to dig even deeper, check out those links: Type doesn‚Äôt like to be cropped. Space yourself ¬∑ A photo essay of physical typesetting ¬∑ Hanging punctuation Type doesn‚Äôt like to be measured. Difference between kerning, letter spacing, and sidebearings ¬∑ On em, rem, and ch CSS units Type doesn‚Äôt like to stand still. On optical adjustments ¬∑ What is kerning ¬∑ How to choose the right line height ¬∑ Say no to faux bold ¬∑ Why distorting type is a crime Type doesn‚Äôt know any limits. Type measure ¬∑ Space yourself Designer/typographer ¬∑ Writing a book on the history of keyboards: https://aresluna.org/shift-happens 4.7K 54 Thanks to Bram Stein , Nick Santos , and Tyler Howarth . 4.7K 4.7K 54 Typography Design Front End Development Webclient Mobile Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2016-08-27"},
{"website": "Medium-Engineering", "title": "good debugging is putting yourself in your user s shoes", "author": ["Tyler Hedrick"], "link": "https://medium.engineering/good-debugging-is-putting-yourself-in-your-user-s-shoes-d638f0745a78", "abstract": "Sign in Tyler Hedrick Apr 8, 2016 ¬∑ 5 min read I woke up one morning to a notification on Slack saying ‚Äú@here iOS feedback:‚Äù with a link to an article by H. Nemesis Nyx . medium.com Oh shit. Not only is a bug like this embarrassing, it‚Äôs been affecting our users in an extremely negative way. At the time of writing there are 11 responses to that post, most of which chime in with a ‚Äúme too!‚Äù and ‚Äúso glad this isn‚Äôt only happening to me!‚Äù. I was devastated, to say t h e least. My number one priority as a developer is to provide users of the software I write a great experience. Having random words disappear from your Medium post is far from a great experience, but worse than that, it breaks the trust we work hard to build with our users. I responded to the author hoping others would see it, letting them know that fixing this bug was now my top priority. medium.com But where do I even begin? I hadn‚Äôt been able to reproduce this behavior myself, and even if I could, how would I track down such an obscure bug? I decided to put myself in the shoes of the author and type out their post word for word. You‚Äôll notice, the author of the open letter highlighted pieces of the article that were lost on publish. Perfect! The tone is passionate ‚Äî they likely wrote most of the words in one go, going back to make corrections later. They probably added styles to the paragraphs after most of the words in a given paragraph were written. For example, there‚Äôs a large section of block quotes in the middle: Every post. Every single one. When I publish, shows up with missing words when the finial post is shown to me. Single Post There are a couple of interesting things happening here. First, there‚Äôs a typo in the first sentence. My gut told me that the author attempted to fix that typo before publishing, but that fix didn‚Äôt show up in the final version. The second red flag was the incorrect grammar in the one word phrases. There should probably be an ‚ÄúEvery‚Äù before ‚ÄúSingle‚Äù and ‚ÄúPost‚Äù. Finally, there is another section of multiple pull quotes further down in the piece that have a bunch of missing words as well. This is the same block of paragraphs I was able to easily reproduce the bug with. I typed out the three paragraphs, changed each one to a pull quote, then went back to edit the first sentence to fix the typo. A few seconds later I saw the follow log statement in my Xcode console: Welp, that‚Äôs not good. The implementation of our editor saves your post every couple of seconds to make sure you don‚Äôt lose any data. To do this we have a timer set up to fire every 5‚Äì10 seconds which bundles up the current changes (deltas) and sends them to our servers. If the save method is ever called without any deltas to send, we log the above info message. Unfortunately, there was something to save: fixing the typo! If you‚Äôve ever written anything in C, you‚Äôre familiar with pointers. A pointer is just a reference to something that lives somewhere else. A pointer is like that little slip they give you when you check your coat at a party ‚Äî a small and portable object that uniquely identifies your item. But what happens if the coat check operator gives someone else a copy of your coat check slip? There are now 2 slips (pointers) that point to the same coat! In programming this situation is possible, and an easy mistake to make. Two people now lay claim to the same object, so what happens? In our case, we maintain two copies of the post data: the current version that is being rendered on the screen, and the version we last saved to the server. This way when we want to save the current version, we can easily find the differences between what we saved previously, and what is new to save. Each data source is a list of individual paragraphs ‚Äî two isolated and separate lists, or so we thought. To keep these lists in sync, we use one to update the other. Once the save is successful, we update the ‚Äúlast saved‚Äù list with what we just sent to the server. When we do this we give a pointer to the second data source that points to a new copy of the paragraph we are updating. However, in a couple of cases we were accidentally handing it a pointer to the original paragraph. It would be like handing someone else a copy of your coat check slip ‚Äî they now have direct access to your coat, just like this second data source had direct access to the first data source‚Äôs paragraph model. So, after we‚Äôve given the second data source direct access to the first data source‚Äôs paragraph, the user continues to type their post. The editor then tries to find differences that need to be saved, and asks for the two data sources to compare their paragraphs and give back deltas. When we get to the paragraph that both data sources share, it comes back saying ‚Äúnope, nothing new here‚Äù because it‚Äôs literally the same paragraph. It would be like asking someone ‚Äúwhat‚Äôs the difference between these two coats‚Äù while holding up a single coat. The fix is extremely simple: just give the second data source its own copy of the paragraph. In fact, I only had to change 3 lines of code. And then I did this: The moral of the story? Mutability is not your friend. Technical note: unfortunately it isn‚Äôt really possible for our editor models to be completely immutable. We update the underlying data model as the user types, and regenerating the entire model on every keystroke could cause the editor to slow down with larger data sets. Thanks to Eugenia , Michael , Madeline , and Marcin for helping me edit this post, Andrew for helping me track down this bug, and H. Nemesis Nyx and others for reporting it. iOS Software Engineer at Airbnb. Previously at Medium, Facebook. Music | Coffee | Code 118 4 Thanks to Eugenia Dellapenna , Brian Ellin ‚òïÔ∏è , Medium Engineering , Michael DiStefano , and Marcin Wichary . 118 118 4 iOS Broad City Mobile Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2016-05-05"},
{"website": "Medium-Engineering", "title": "engineering interviews refining our process", "author": ["Jamie Talbot"], "link": "https://medium.engineering/engineering-interviews-refining-our-process-52fbc9510e91", "abstract": "Sign in Jamie Talbot Jun 9, 2016 ¬∑ 4 min read We recently undertook a project to improve Medium‚Äôs engineering interview process. As part of that, I wrote this document to describe why we needed to improve on what we were already doing. It was originally published to Hatch, our internal version of Medium, on February 26, 2016, and is reproduced below without modification, except for link destinations. For more information about Medium‚Äôs practice of making internal documents public, see Hatching Inside Medium . While we are more thoughtful about interviewing than many companies, our process could nevertheless do with some refinements. Over the last few weeks, I‚Äôve been working with a number of people ‚Äî internally and externally ‚Äî to reconsider what it is we actually look for in engineering candidates, and how best to objectively screen for those qualities. Our current candidate scorecard and grading process suffers from a number of deficiencies, which we hope to resolve. The capabilities we ask for are poorly defined, and sometimes overlap. Nobody can really explain the difference between Critical reasoning and Strong analytical and problem solving skills . The capabilities are listed at different granularities ‚Äî CS Fundamentals is quite granular (though ambiguous), while Technical pass is a high level check mark. Cultural pass overlaps with the values section. It‚Äôs not clear which of these capabilities are absolutely necessary, and which are merely desired. There‚Äôs no high-level organisation to the capabilities ‚Äî we have separate sections for Skills and Qualifications without a clear explanation of how they differ. We would be hard-pressed to answer ‚Äî going only off the rubric ‚Äî what we actually look for in engineering candidates at a high-level. We also do not include some capabilities that we know we care about, e.g. Awareness and Empathy . We rely extensively on ‚Äúcalibration‚Äù ‚Äî which, let‚Äôs be honest, more often than not just means ‚Äúget comfortable with making a call‚Äù. Each interviewer has a different idea of what ‚ÄúStrong‚Äù means in Strong analytical and problem solving skills . Even if interviewers are internally consistent from candidate to candidate ‚Äî and, spoiler alert, we‚Äôre not ‚Äî there is a large difference between interviewers. Because we don‚Äôt specifically define how important these capabilities are, it follows that different interviewers have different opinions on which capabilities matter most. It is likely that they subconsciously value more highly the capabilities that they themselves exemplify. We provide no guidance to interviewers on the things that are unimportant. The tech industry has a habit of screening candidates on criteria that are uncorrelated (and in some cases negatively correlated) with job performance. By failing to be explicit about the things that we consider unimportant, we risk letting people make decisions based on them. Some capabilities that we looked for, like Confidence , are not universally positive, and under certain circumstances may even be a negative signal. Many great engineers at Medium appear outwardly to lack confidence. More broadly, Cultural pass is very ambiguous and invites subjectivity in a way that allows for unchecked bias. We recognised the need last year for an update to our Personality Traits section. The aims of the refreshed interview process are to: Be more objective and consistent in our assessment of candidates. Continue to hire great people who can help us build a platform for the whole world. Hire only those people who share our values ‚Äî regardless of their cultural background. Benefit from candidates who we think can thrive at Medium with a not-insurmountable amount of technical coaching. Understand, accept and work to mitigate our biases, and focus on reporting objective interview performance. And no, we are not ‚Äúlowering the bar‚Äù . In addition to this introductory piece, there are three living documents that are designed to help us achieve these outcomes. These have been designed in consultation with engineering leadership, frequent current interviewers at Medium, and external subject matter experts from companies brought together by CODE2040. What we screen for is an explicit statement of the things that we care about, grouped into three high-level areas that are easy to understand and communicate. What we don‚Äôt screen for lists a number of criteria, some of which we have previously screened on, that we do not consider critical to one‚Äôs performance as an engineer at Medium. The grading rubric is a pretty exhaustive enumeration of each desired category and a guide to what might indicate a Strong No , No , Mixed , Yes , or Strong Yes signal for each. At a high-level, there will be a few changes. Most notably among them: All categories for which a grade is recorded must be accompanied by at least one explanatory, objective piece of evidence. In general this means an observable fact that the candidate said or did. Candidates for whom we have previously said No on a technical basis may still be eligible, iff their technical deficiencies are sufficiently minor that they can be corrected with an amount of coaching that the current team can reasonably commit to, and the candidate is strong in learning and teaching, and there is strong values alignment. This is just the beginning of the process. In the coming weeks and months we will: Work with existing interviewers to help them understand and internalise the changes. Update the scorecard in Lever to reflect the new categories. Create a one-sheet to take into interviews to help the interviewer record observable facts. Assess the format of our interviews and determine whether they give us a strong enough signal. Devise a training plan with recruiting to onboard new interviewers. We may also publish these four documents on the Medium Eng blog to share our learnings with others in the industry, and demonstrate to prospective candidates that they can expect a thoughtful interview experience. Ex-gaijin, kangaroo-loving software simian from Merrie England, building @Mailchimp and @Pinian. Formerly @Medium and @StumbleUpon. 270 2 Thanks to Kelly Ellis . 270 270 2 Medium Engineering Interviewing Values Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2016-06-10"},
{"website": "Medium-Engineering", "title": "a guide to your technical interview at medium", "author": ["Jeff Lu"], "link": "https://medium.engineering/a-guide-to-your-technical-interview-at-medium-76d91942c737", "abstract": "Sign in Jeff Lu Mar 1, 2016 ¬∑ 4 min read H ere at Medium, we realize that being asked to solve an unfamiliar problem on a whiteboard, is not the same as coding in your favorite IDE while listening to your favorite tunes. The goal of our interview process is to predict how you‚Äôll perform once you join our team. Since interviewing ability has almost no correlation with employee effectiveness, we do our best to adjust our expectations. This post will be your study guide as we‚Äôll cover suggested reading material, our evaluation criteria, and finally some tips on interviewing. Please take some time to read through the following posts as they not only describe our engineering culture, but also how we value bringing together a team with different perspectives, life experiences, and educational backgrounds. More importantly, we‚Äôve publicized our engineering rubric so you can walk in on the day of your interview feeling like you‚Äôre ready to ace a midterm. medium.engineering medium.engineering medium.engineering Check out the Medium Engineering Blog for more We conduct several different types of interviews around coding, system design, career history, and employee values. Don‚Äôt worry, we don‚Äôt expect you to be good at everything. The whole point of the interview is to understand your boundaries ‚Äî areas in which you excel, as well as your limitations. Chances are if you‚Äôre amazing at one thing, you can be amazing at other things, right? The good news is that Medium is an environment that fosters a growth mindset, so you‚Äôll have many opportunities to develop your craft. Step 1: Exploratory. AKA the friendly ‚Äúget to know you over a cup of coffee‚Äù stage. This initial chat will cover highlights in your work experience, your aspirations, and a quick summary on Medium‚Äòs roadmap and the problems we‚Äôre solving. We want to make sure there‚Äôs mutual interest and values alignment before moving into technical screens. Step 2: Technical Interview. This is a one-hour interview with a Medium engineer where you‚Äôll be asked to complete a coding exercise. We emphasize coding ability in our process, so it‚Äôs important to show interviewers your ability to write clean, maintainable, extensible code. This step can be done in-person or remotely via collabedit/coderpad (we‚Äôll have a laptop for you for in-person interviews). Step 3: Onsite Interview. The final interview panel runs about 5 hours with an hour break for lunch. Coding x 2. Similar to the initial technical screen, you will be asked to complete two additional coding challenges. System design. We‚Äôll be asking you to design a system that performs a given task. The prompt will be open-ended, so remember to effectively communicate your familiarity with complex systems and your approach to design. Career history. A non-technical interview reviewing how you to got to where you are today. We want to hear about your biggest achievements, toughest challenges, high/low points, and anything else about who you are. Q&A. This is an unstructured Q&A with a member of the leadership team. Take advantage of this opportunity to get all of your questions answered about our engineering org. We understand the stressful conditions of a 60-minute technical interview, so we‚Äôd like your input on how we can most effectively assess your technical ability. If you‚Äôre not comfortable whiteboarding, or like to spend a few minutes brainstorming alone, please let your recruiter know and we‚Äôll do our best to accommodate. Here are some additional suggestions to help you prepare for your interview: Read through these tips on whiteboarding. Understand the problem. If any part of the requirements seem unclear, ask the interview for clarification. You don‚Äôt want to start off making the wrong assumptions. Plan ahead. Don‚Äôt jump straight into coding without thinking through the nature of the problem and a high-level structure/implementation. Break down the problem. For more complex problems, we look for the ability to provide simplified, well-factored solutions that break things down into something more manageable. Communicate your thought process. This will make it easier for the interviewer to provide guidance if you get stuck. You‚Äôre not here to answer CS trivia, but we do want you to have an understanding of what‚Äôs going on beneath the hood. Think about edge cases. Walk through your code to make sure it produces the right result. You should try to come up with a solution that handles most if not all edge cases. Hopefully you found this guide helpful. We‚Äôre always looking for ways we can improve our process, so please send us your thoughts. Thanks for taking the time to interview with us and good luck! Pokeymans Collector 354 2 Thanks to Dan Pupius . 354 354 2 Interview Recruiting Engineering Interview Guides Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2016-12-08"},
{"website": "Medium-Engineering", "title": "engineering interviews grading rubric", "author": ["Jamie Talbot"], "link": "https://medium.engineering/engineering-interviews-grading-rubric-8b409bec021f", "abstract": "Sign in Jamie Talbot Jun 9, 2016 ¬∑ 31 min read We recently undertook a project to improve Medium‚Äôs engineering interview process. As part of that, I wrote this document to describe how to assess the qualities we are seeking in engineering candidates. It was originally published to Hatch, our internal version of Medium, on February 26, 2016. For more information about Medium‚Äôs practice of making internal documents public, see Hatching Inside Medium . This is the actual rubric used by Medi u m to grade engineering candidates and has replaced the version on Hatch as the source of truth. If you apply for a job at Medium , these are the criteria on which you can expect to be judged. Preface: Refining our process Part 1: What we screen for Part 2: What we don‚Äôt screen for Part 3: Grading rubric This guide is up for continual improvement. Discussion on how to grade for certain categories is welcome, as are suggestions on improvements for clarity. However, the headline capabilities and component categories are unlikely to change unless there are exceptional circumstances or significant new learnings. We are trying to build an engineering organisation that is productive, effective and happy. We can only do that by hiring great people. Interviewing is one of the most important responsibilities you have an as engineer; your feedback on candidates will determine how the company evolves. A few points before you get started: As you are grading, remember this: we are biased. I‚Äôm biased too. That‚Äôs ok, as long as we stay vigilant about it, and then adjust. When I‚Äôm not thinking about it, I tend to give higher scores to people who speak with received pronunciation ‚Äî the kind of English accent you might associate with the Queen. I associate it with being smart (despite plenty of evidence to the contrary), possibly because I grew up watching BBC News where all the anchors sounded like this. Interviewing is subjective, but in your written evaluation, try to stick to observable facts. Editorialising on someone‚Äôs psyche or value system can be prejudicial, especially if what you write is interpreted by others without you being present to give more nuance. Bad : Lillian won‚Äôt admit when she doesn‚Äôt know something, probably because she‚Äôs Latina and I‚Äôve heard that‚Äôs characteristic of their culture. I don‚Äôt think she‚Äôll be able to admit when she‚Äôs wrong. Good : Lillian was very reluctant to describe her answer in detail, and talked in generalities instead of writing down the solution. If you have a really strong feeling and are convinced that you have to communicate it, make sure you separate the observable facts from your feelings, and communicate them first. Bad : Jackson is a misogynist. Better : Even though I was giving the interview, and Peter was just shadowing, every time I asked a question, Jackson gave the response to Peter. Jackson asked Peter clarifying questions, but not me. This frustrated me, and makes me think Jackson would have a problem working productively with a younger woman. We grade each category on a five point scale: Strong No , No , Mixed , Yes , and Strong Yes . We generally consider Mixed to be more No than Yes . It is the least useful rating you can give, so try to use it sparingly. It is not essential that you grade a candidate in every category of every section, so you should only grade those categories in which you can make a strong call, based on observable facts. However, if you are only able to confidently grade five or less categories, we should consider the interview format a failure, and think about why we aren‚Äôt able to get a strong signal from it. For each category that you provide a grade, you must provide a note that lists the observable facts that led you to choose that grade. Do not add a grade just to hit some minimum number of categories: if you are unsure about your performance as an interviewer, we can provide additional training. If the interview format does not help you get the signal you need, we can change it. You will be provided with a sheet that lists the qualities we are looking for, to help you remember what you should be judging the candidate on, and provide space for you to note what you see and hear. Qualities related to the candidate‚Äôs ability to effectively build software. Independently finding a creative solution is great. Failing to conceive of any solution is a red flag. Only demonstrating a na√Øve approach is a warning sign. Partial credit for being able to conceive of the solution, but not being able to follow through with it, especially for junior candidates. Do not make a call if you are not asking the candidate to solve a problem and they are not asked to describe a time where they solved a substantial problem. Strong No: The candidate is unable to conceive of any solution to the problem. The candidate is able to describe a basic, or na√Øve approach, but unable to implement it. No: The candidate is unable to arrive at a solution beyond the most basic, na√Øve approach, even with significant help and hints from the interviewer. The final solution does not account for edge cases. (If due to a lack of time, in the judgement of the interviewer, the candidate would not be able to address those edge cases.) Mixed: The candidate conceives of and implements a na√Øve solution independently, conceives of a better approach with minimal hints, and is able to complete it with help from the interviewer. The candidate dives in to a solution without giving the problem much thought, or asking questions. If a missing edge case is pointed out, they are only able to solve it with significant help. Yes: The candidate is able to outline a solution beyond the most na√Øve, independently, and implement it, covering the vast majority of cases. If one or two hints are required, the candidate understands their importance quickly, and moves on. The candidate asks questions to clarify the scope of the problem and states their assumptions. If an edge case is pointed out to the candidate, they are able to modify their solution independently. Strong Yes: The candidate clarifies the scope as a natural first step, is able to articulate multiple approaches and describe the pros and cons of each, makes a sensible decision based on the constraints of the interview format, and is able to fully implement the approach, without any real help from the interviewer. The candidate recognises edge cases and draws attention to them unprompted, then solves them. Make allowances at your discretion if this is a whiteboard interview, or if they are using tools on a provided computer that they don‚Äôt usually use. For coding tests, allow ‚Äî or instruct ‚Äî the candidate to use the language they are most familiar with. Do not make a call if you are not testing a candidate‚Äôs ability to produce code, or asking them to read or review code. Strong No: The candidate does not know basic language constructs like loops and conditionals. The candidate cannot invoke functions correctly. The candidate is unable to read provided code or describe in any sense what it does. No: The candidate is unable to translate their thoughts into code. Little knowledge of the language‚Äôs standard library is demonstrated. The candidate chooses nonsensical or non-descriptive variable names when writing code. The candidate is unable to describe the behaviour of any provided code with any precision. Mixed: The candidate is able to write basic code, but does not demonstrate strong familiarity with their chosen language‚Äôs properties or idioms. Candidate reimplements standard library functions, rather than using what is available. (Do not judge on this if you do not know their chosen language‚Äôs idioms or standard library.) Yes: The candidate codes fluently and naturally. The candidate chooses to use standard library functions and is able to describe their behaviour when asked. They may use placeholders to abstract away functionality then come back to fill them in. When reading code, the candidate is able to understand the general purpose of the code quickly. Strong Yes: The candidate codes without any significant pauses and writes idiomatic code by default. Thought is translated into code without any apparent difficulty. When reading code, and with a little effort, the candidate is able to understand its full behaviour and nuances, and point out more idiomatic approaches where appropriate. The specifics of this will vary by interview type. For Tech Lead Simulations, we might expect a good candidate to take control, break the problem down and assign them. For a coding interview, a good candidate will work independently, requesting little input except to clarify scope. Generally, we are looking for people who will be able to work with minimal guidance, and people who are able to own problems. Strong No: The candidate requires hand-holding and has to be led through every step of the interview. The candidate refuses to make any decisions without consent from the interviewer. No: The candidate requires lots of support to complete their task. Decisions are made reluctantly. Approval and validation are sought for each decision. The candidate is unable to describe a time where they led or instigated a project, or if they are more junior, is unable to describe a time when they solved something independently. Mixed: The candidate is able to work independently, but seeks approval regularly in a way that abdicates responsibility. The candidate demonstrates some ability to deliver a solution without much input from the interviewer. Yes: The candidate is confident owning their decisions and demonstrates a strong ability to work independently. If more junior, the candidate takes ownership of the problem, using the interviewer as a resource to make progress, if needed. Strong Yes: The candidate controls the cadence of the task-oriented part of the interview, asking for guidance or clarification only where appropriate. The candidate makes decisions without seeking approval, but describes the rationale to the interviewer. The specifics of this category will vary by role. For specialised roles like Recommendations Research Scientist, the expectation of algorithmic familiarity is likely to be higher, and we might, for example, have a reasonable expectation of the candidate knowing the na√Øve Bayesian or collaborative filtering. We would generally expect senior engineers to have a wider exposure to more special-purpose data structures than junior engineers. Some questions do not require the use of complex data structures. Do not arbitrarily force a discussion about them, unless there is a clear fit for the problem. To be clear: we are not judging candidates on whether they know terms like O(n) . We are judging them on whether they understand that there are trade-offs in building software, and that different algorithms and data structures have different trade-offs. Candidates who choose and implement appropriate data structures and algorithms without explaining their use may score well here, but more poorly on communication. Strong No: The candidate is unfamiliar with the most common data structures, like hash, set, or array. The candidate is completely unable to assess the relative merits of competing algorithm choices. No: The candidate has heard of common data structures, but cannot describe which ones are appropriate for the task at hand, or when they might be useful. The candidate cannot explain, for example, the difference between an O(n) solution and an O(n¬≤) solution (the behaviour, not the terms). Mixed: The candidate uses hashes, sets and the like appropriately, but cannot, for instance differentiate between a list, a queue, and an array. The candidate is aware that certain data structures are better for certain tasks, but has difficulty articulating why. Yes: The candidate understands time and space complexity (even if they don‚Äôt use those terms) and can describe the characteristics of common algorithms. The candidate can describe the tradeoffs inherent in different approaches, and can articulate why a specific data structure is appropriate. The candidate can competently implement a recursive algorithm (only if recursion makes sense for the task). Strong Yes: The candidate is able to pick an appropriate data structure or algorithm for a task, and has a strong understanding of their relative merits. The candidate‚Äôs knowledge goes beyond the basics, and there is a demonstrated familiarity with concepts like heaps, priority queues, tries, or more exotic constructs. The grading for this portion will depend on the type of interview and the seniority of the candidate. For more senior positions, we would expect sensible code composition as a minimum, and some evidence of larger-scale system design. For junior positions, sensible decomposition of code will typically suffice. Do not make a call if the task at hand is so simple that nobody would realistically do anything other than write a quick script. Strong No: The candidate writes all their code in one function, with no decomposition. The candidate does not see the value in separating out code in their solution, or if the task at hand does not warrant it, in principle. In a design question, the candidate fails to define any reasonable abstractions, or has no idea how to construct the system. No: The candidate does not seek to break out their code into reusable components, and doesn‚Äôt understand the value of doing so. The candidate is unable to describe the interaction of system components with any precision. The candidate does not demonstrate any understanding of separation of concerns. Mixed: The candidate adopts a reactive approach to code or system organisation, thinking only one step ahead at a time. Their finished output has the appearance of being bolted together, rather than being coherently designed. Abstractions exist, but are leaky, rigid or resistant to change. Yes: The candidate is able to structure their system in a way that separates concerns appropriately with components that interact through reasonable interfaces. In object-oriented code, the candidate demonstrates a good understanding of SOLID principles (even if they don‚Äôt know the specific terms). For simple code, functions are used appropriately to minimise complexity. Strong Yes: The candidate is able to break down a complex system into elegantly structured components, and thoroughly describe the interaction model, the interface and the behaviour. Abstractions are clear and clean, given the problem definition, and keep open the possibility of future needs without significant refactoring. Additional thought is given to complex and subtle interactions, like race conditions and idempotency. Giving up on a particular approach and finding an alternative is fine. Giving up on the entire task because it is too hard is not. This is unrelated to whether the candidate actually solves the problem. When grading on challenges in past positions, exercise your judgement as to whether any further effort was warranted on the candidate‚Äôs part ‚Äî staying in an abusive, hostile or dangerous environment is not a reasonable expectation of the candidate. Do not make a call if the candidate is able to provide a solution with little effort, and no questions are asked about previous challenges. Strong No: The candidate fails to complete the assigned task and is ambivalent about it. The candidate is unable, when asked, to describe a time when they persisted at something, or describes a time when they quit because something was too hard. (Excepting if, in the judgement of the interviewer, the project was unreasonably hard, or the situation was untenable.) Demonstrates no capacity for sticking with something in any prior position. No: The candidate shows no strong desire to finish the problem. When confronted with issues in their solution, the candidate shows no strong inclination to get to a fully working answer. Sees difficult times as barriers, rather than challenges. Mixed: The candidate professes a desire to finish a task, but shows signs of frustration when issues come up, and becomes negative about the situation. If describing a difficult prior position, the candidate failed to take any steps to make their situation better, did not explore alternatives, and instead moved on in relatively short order. Yes: The candidate demonstrates a desire to finish the assigned task, and if presented with issues is suitably motivated to fix them. The candidate describes a time when they persevered with a difficult situation and achieved a good outcome. The candidate describes prior challenges as growth opportunities. Strong Yes: The candidate is very determined to finish the task assigned and works hard to do so. If they finish, they are eager to describe next steps, additional work, or extensions. If the allotted time runs out, they express disappointment at not being able to finish, or suggest that they are going to work it out later. For exceptional performance, the candidate emails a solution after the fact (unprompted ‚Äî do not ask them to do this). The candidate demonstrated incredible staying power in a difficult previous situation, doggedly pursuing their goal beyond what would be expected of an average person. Qualities related to a candidate‚Äôs ability to improve themselves, and make Medium better. Curiosity does not have to be code- or industry-related! A demonstrated curiosity about, for example (and without limitation), their family genealogy, a foreign culture, cuisine, the mechanics of windmills, literary history, biomechanics etc. are all interesting. Consider as examples within Medium today: typography, the provenance of meat, travel-hacking, and Japanese, among many others. Strong No: The candidate demonstrates no interest in Medium, or in the world around them, and provides no evidence that they want to learn more. No: The candidate isn‚Äôt able to describe any self-directed learning. They accept every statement at face value, without digging in. They ask no questions. (Excepting if the candidate is tired from a long day of interviews and has previously asked questions of others.) Mixed: The candidate asks, or has asked, ‚Äúwhy?‚Äù once or twice, but isn‚Äôt particularly interested in the answers, and doesn‚Äôt go deeper. The questions the candidate asks are fairly standard, on topics like tech stack, or working hours, without really seeking any deep insight. The candidate has done a little self-directed learning on a topic that interests them. Yes: The candidate asks insightful questions about Medium. They ask follow-up questions to go deeper on topics that interest them. They describe times when they have done independent research, on any topic. The candidate describes needing to figure out why something was broken, and derives satisfaction from finding answers. The candidate has done research on the people interviewing them. Strong Yes: The candidate displays an insatiable appetite for learning, provides ample evidence of self-improvement and asking questions, and gets excited when they recognise an opportunity for learning. The candidate runs out of time asking questions, and still has more to ask. We want candidates who know themselves, who will respond well to feedback, and who are self-aware enough to know what their deficiencies are and seek to work with those who can support them. It will typically be hard to make a call on this in a purely technical interview. However, it is instructive to see how the candidate responds when bugs with their code are pointed out. An inability to recognise or accept a mistake can be problematic. Contrariwise, responding well to a bug with humour and good grace is a good sign. Strong No: The candidate demonstrates a significant lack of self-awareness and of introspection. The candidate fails to meaningfully identify any ways in which they could improve. The candidate uncritically gives themselves a 10/10 for performance at all their past positions. The candidate demonstrates no interest in receiving feedback. No: When asked to identify opportunities for improvement, the candidate gives false-modest answers like ‚Äúsometimes I work too hard.‚Äù They can‚Äôt identify their performance at a previous position relative to their peers. They don‚Äôt know how their manager would rate them, or why. They have rejected concrete feedback in the past, and were unable to see why it was offered. Mixed: The candidate recognises that they can improve, but speaks in vague terms that demonstrate a lack of significant thought on the matter. The candidate is ambivalent about receiving feedback. The candidate is unable to articulate a time when receiving feedback, or self-analysis, helped them become better. Yes: The candidate describes a time when they received critical feedback, and were able to integrate it to become better. They make reflective statements like ‚ÄúI was immature‚Äù, or ‚ÄúI wasn‚Äôt willing to compromise‚Äù, or ‚ÄúI‚Äôve learned that getting buy-in from others is important‚Äù. The candidate knows themselves, and has thought about how they can improve. The candidate made deliberate career choices in response to past experiences. Strong Yes: The candidate is able to critique their own past performance and identify a number of growth opportunities. They compare their past selves with their current selves unflinchingly, and identify areas where they have improved and the steps they took. The candidate is aware that they make mistakes and demonstrates a desire to learn from them. The candidate speaks objectively about their own shortcomings and describes strategies for mitigating them. They are eager to receive feedback, and demand it. Judging empathy in an interview can be difficult. Generally, we‚Äôre looking for people that understand there are multiple perspectives, are sensitive to other people, and can demonstrate the ability to imagine what someone else might be thinking or feeling. The more senior a candidate is and the more likely they are to lead others, the more important empathy is. You will generally not be able to make a call in a purely technical interview, if the candidate describes no interactions with others (colleagues, clients etc.). However, there may be some signs like empathy to future maintainers of code ‚Äî good variable naming, good documentation ‚Äî as long as the candidate describes the value of those things for that purpose. Strong No: The candidate is actively hostile about former colleagues and uses pejorative words, demonstrating a lack of care. The candidate describes people with whom they disagree as, for example, ‚Äústupid‚Äù. The candidate is incapable of putting themselves in another‚Äôs place. They are focussed on themselves. No: The candidate makes remarks that imply other people don‚Äôt matter, or is dismissive of alternative points of view without due consideration. When describing decisions that they don‚Äôt agree with, they are unable or unwilling to speak to any context or constraints the decision-maker faced. The candidate describes situations in terms like ‚Äúus vs them‚Äù, dismissing those with whom there are disagreements as ‚Äúother‚Äù. The candidate doesn‚Äôt understand why something upset someone. Mixed: The candidate demonstrates a limited ability to understand another‚Äôs point of view. The candidate understands that constraints on decision makers exist, but demonstrates little sympathy for people with whom they disagree. The candidate is not particularly worried about the unfair treatment of peers. Yes: The candidate declines the opportunity to blame others for a poor outcome, without providing nuance or mitigating circumstances. They demonstrate an intuitive grasp of the reasonable person principle (even if they don‚Äôt use the term). The candidate demonstrates that they recognise the impact of their actions on colleagues, and understands that their perspective is not the only valid one. The candidate describes good variable naming and code organisation as a service to colleagues. Strong Yes: The candidate does not judge someone‚Äôs actions without first understanding their perspective. The candidate shows a balanced assessment of challenges faced at previous roles, and can understand the perspectives of both reports, peers, and managers (as appropriate). The candidate can clearly articulate another‚Äôs point of view and describe their worldview. The candidate feels upset when people not within their peer group are treated unfairly. The candidate thinks about how their code will be used, who will look after it, and shows strong consideration for their colleagues in how they build software. Communication is very broad, and can cover presentation skills, verbal communication, an ability to explain new concepts clearly, written communication, slide decks, data visualisations, gesticulations with hands, listening, asking clarifying questions, and expectation-setting. Communication styles vary widely among candidates; you should focus on whether they are able to get their point across, and able to accurately interpret your questions. Some people are naturally less communicative than others when speaking to strangers, and especially in interviews. You should assess them on the entirety of their communicative ability, not just their ability to talk fast and off the cuff. It‚Äôs fine to coax more out of a person, and/or give them time to warm up. Whenever possible, ask open questions to give the candidate the opportunity to talk. You should be able to make a call on communication in every interview. Strong No: The candidate does not ask any questions, and doesn‚Äôt listen. They solve the wrong problem as a result. The candidate is incapable of describing a concept or topic even when they are intimately familiar with it (unless ‚Äî in truly exceptional cases ‚Äî the topic is so complicated that the interviewer lacks the context necessary to understand it). The candidate cannot clearly communicate their intentions or thought process, even after significant encouragement and prodding. No: The candidate‚Äôs intent is frequently unclear. When writing code, the interviewer frequently finds themselves in a position where they cannot in good faith say what the candidate is attempting to do, or why. The candidate cuts the interviewer off frequently. The candidate is reluctant to offer anything more than one or two word answers, or writes in fragments that don‚Äôt particularly make sense. The candidate needs a frequent re-framing of a problem to understand it. The cannot adequately explain why they chose the approach they took. Mixed: The candidate needs to say things multiple times to get their point across to a good faith listener. The candidate can communicate an idea at a high level, but lacks precision and nuance in the details. The candidate ‚Äúhandwaves‚Äù complex parts of code despite being prodded to expound. They are unable to describe a time where they convinced someone of something, or used language to influence something. Yes: When solving a problem, the candidate asks questions to clarify needs, and is able to describe an approach at a high-level. They describe how their code works, unprompted. They are able to communicate complex topics to a layperson. The candidate clearly imparts knowledge and concepts through appropriate means, including, but not limited to, diagrams, body movement, writing and speech. When explaining something, the candidate talks at a level appropriate to their audience. The candidate describes a time where their communication influenced a decision. Strong Yes: The candidate frequently checks understanding when explaining a complex concept, and if there is any misunderstanding, is able to unpack the problem and effectively communicate the necessary information. The candidate finds the precise word they want to convey the exact meaning they need (even if they takes a few seconds to do so). They are able to explain with great precision why they took the steps they did on a project. The candidate has put together cases that persuade a skeptical audience. If a candidate has worked exclusively in very small teams, much of this might be theoretical. In technical interviews, judge the candidate on their ability to use you for your knowledge, and willingness to ask for help. Pay attention to how they describe their role on previous teams, and whether they are comfortable sharing credit and accepting blame. Strong No: The candidate describes themselves as a loner, doing their best work alone. Demonstrates no understanding of the value of working within teams and cannot describe a time where working with others was beneficial. The candidate is suspicious, generally, of ‚Äúteamwork‚Äù as a concept. No: The candidate describes successes as ‚ÄúI‚Äù, but describes failures as ‚Äúwe‚Äù. The candidate does not like working with others. They do not make use of the interviewer when they are stuck and trying to solve a problem. The candidate fails to solicit input from teammates. Mixed: The candidate describes working with others, albeit with some reluctance. They demonstrate a limited capability to work on a problem with others. They ask some questions, though conversation on a problem falls short of a meaningful dialog. Yes: The candidate is happy working with others to achieve an outcome. The candidate employs a collaborative approach to problem solving, soliciting feedback, and integrating it into their solution. The candidate brings others with them. The candidate does not merely hand out tasks, and is not satisfied with merely receiving tasks to complete. Strong Yes: The candidate demonstrates repeated examples of working with others to achieve a desired outcome. They are eager to work with others. The candidate describes times where other people provided skills that they were lacking. Describes achievements as ‚Äúwe‚Äù as appropriate (though taking individual credit for their specific contribution is fine). ‚ÄãWhile everyone may be‚Äã (or at least, feel) unique, people from similar backgrounds with similar education and career paths tend to have similar worldviews‚Äã.‚Äã Current academic studies in this area suggests that diversity of background and point of view makes companies better . We recognize an inherent tension in this area ‚Äî that by weighing some demographic backgrounds more heavily, we may be disadvantaging others. ‚ÄãA candidate should not be penalised for the particular demographic that they belong to‚Äã, or don‚Äôt belong to.‚Äã ‚ÄãBut we recognise that those who are underrepresented at Medium‚Äã and in the tech sector more broadly,‚Äã can offer us points of view that we are currently missing. We should remember that while we are hiring individuals, we are building a team. Perspective is itself a broad topic ‚Äî it‚Äã ‚Äãcould‚Äã be of the world, of the company, of technology, of the product‚Äã, or something else entirely‚Äã. As a non-exhaustive example list, life experiences that may lead a person to have an underrepresented perspective may include gender, race, country of origin, languages spoken, military service, sexuality, age, socio-economic class, political preference, education, family makeup, or religion. It is intrusive and illegal to ask direct questions about most of these categories, so don‚Äôt. To the same point, asking indirect questions aimed at yielding this information are equally problematic. But, the underlying motivation ‚Äî to understand what point of view a candidate might bring to bear on our company our product ‚Äî is something you should pursue. To this end, open-ended questions may generate discussions on what a candidate may bring to Medium that isn‚Äôt in evidence on their resum√®. For example, questions like: ‚ÄúWhat are some of the important experiences that have shaped your view of the world and your work?‚Äù ‚ÄúDo you think there‚Äôs a perspective that our product is missing that could improve it?‚Äù ‚ÄúWhat are some things you think Medium can do better to broaden our appeal to new users?‚Äù Strong No: The candidate offers no new perspectives on the world, the product or the company. The candidate has no thoughts on how Medium can improve. The candidate appears not to have done any research on Medium at all. The candidate doesn‚Äôt recognise any of the dangers of groupthink. The candidate describes directly or indirectly homogeneity as the only way to achieve success. No: The candidate fails, when given the opportunity, to describe how they would improve the product, company or engineering systems. The candidate suggests that they prefer to work with people like themselves. The candidate demonstrates no interest in others‚Äô points of view. The candidate offers no new insight, and the interviewer learns nothing new in the interview, no matter how small. Mixed: The candidate has done a little research on Medium, but knows little more than that it‚Äôs a blogging platform, and that Ev is the founder. The candidate solves a problem in the same way that the vast majority of candidates do. Yes: The candidate is able to describe the needs of a demographic for which Medium does not yet adequately cater. The candidate is able to teach the interviewer something about people‚Äôs perspective of Medium, and recognises the value of diverse perspectives. The candidate is able to contextualise a problem or solution in a way that the interviewer hasn‚Äôt considered. The candidate teaches the interviewer something they didn‚Äôt know. The candidate adds something unique to the company that we don‚Äôt already have. Strong Yes: The candidate has extensively researched Medium and comes prepared with lots of ways the product could be improved. The candidate has strong ties to a community that is underserved by Medium, or with whom Medium currently has difficulty communicating. The candidate has ideas of how Medium could be made more useful or opened up to a new audience by serving a specific set of needs that haven‚Äôt been identified within the company. The candidate identifies an edge-case in a long-standing interview question, of which the interviewer was previously unaware, or solves the problem (correctly) in a way that hasn‚Äôt been seen before by the company. The candidate imparts substantial wisdom or something revelatory to the interviewer. Qualities that ensure the candidate is aligned with Medium. Trust is central to all we do. It allows us to distribute authority, work in parallel and treat each other with respect. Backchannels are particularly useful for understanding whether a candidate has previously built trust, but don‚Äôt rely on them in isolation because we will always lack the full context. Candidates who have undermined colleagues, or been economical with the truth in previous positions are unlikely to reveal that about themselves in an interview. Strong No: The candidate refuses to delegate work to others. The candidate is duplicitous, dishonest or disingenuous. The candidate has actively undermined colleagues. The candidate prefers to achieve results through fear. The candidate feels the need to check every piece of work and have a say in every decision, and is unable to temper that need. Nobody believes any deadlines that the candidate sets. No: The candidate doesn‚Äôt trust others to do their job, and demonstrates micro-managerial tendencies. The candidate has been on performance improvement plans at multiple previous companies for the same deficiency. The candidate has a history of missing deadlines or being late, and has taken no corrective action to improve this. People are unwilling to work with the candidate again. Mixed: The candidate has previously been unreliable, but has made a good faith effort to improve it. When describing a time when they failed at something, the candidate is unwilling to take responsibility for their part. The candidate has failed to update stakeholders on a number of occasions, without adequate justification. Yes: The candidate has earned trust from peers and leaders in previous positions. The candidate has been entrusted with delivering important projects, and has validated that trust. The candidate communicates effectively with stakeholders, hitting deadlines or giving good notice why they won‚Äôt be met. The candidate is honest and straightforward in their communication, and does not dissemble or sandbag. The candidate delegates effectively. Strong Yes: There are multiple references who state their unequivocal trust in the candidate. The candidate tells the truth, respectfully, even when it is hard, and is willing to speak truth to power. The candidate has delivered multiple projects on time and to budget, and been given ever more critical work throughout their career as a result. The candidate gives out problems, not solutions, and encourages and empowers subordinates to work autonomously, as appropriate. The candidate gives people the benefit of the doubt when they make a new mistake. We want people who relish a challenge. Do not make a call in a technical interview if the interview question is not sufficiently challenging. If making a call, consider how they reacted to a hard problem that they haven‚Äôt seen before. Strong No: The candidate has chosen positions that were easy, because they were easy (except if in the judgement of the interviewer they were deliberately taking a break after a stressful position). The candidate shies away from difficult work. No: The candidate has stayed in a non-challenging position for an extended period of time and demonstrated no desire to challenge themselves. The candidate is reluctant to attempt something at which they might fail. Mixed: The candidate has worked on some difficult projects, but prefers to follow, rather than lead. They have reluctantly worked on some challenging projects, but only at the insistence of others, and did not demonstrate an appetite for it. Yes: The candidate has willingly taken on tough challenges that involved some risk. The candidate has said yes to projects where they didn‚Äôt have a clear idea of how to achieve success, and achieved success anyway. The candidate has solved complex problems and developed innovative solutions. They relish challenges and often take on hard and unglamorous work because it is important and necessary. Strong Yes: The candidate has worked on incredibly difficult projects, inventing wholly new ways to solve problems, whether in code, process, or business model. The candidate is recognised by their industry peers as being innovative or a leader. The candidate has executed turnarounds on stalled or failing projects. The candidate has achieved success despite structural barriers to that success within society or a company. The candidate has a demonstrated history of leading the way for others to follow. Instigating change can come in many forms ‚Äî advocating for a new product, working to change the demographic makeup of a company, defining a new business model, pushing the company out of complacency. Engineers can typically instigate change by writing code, but organising meetings, getting decision makers interested in a problem, or writing op-eds or company memos can also count. Strong No: The candidate is satisfied with the status quo, and actively avoids or resists change. The candidate only changes when forced to by externalities. The candidate feels no urgency to improve process or solve problems. No: The candidate allows other people to lead on change, reluctantly going along with it only when necessary or expedient. The candidate is a passive observer, rather than an active participant. The candidate can solve a problem when they are given it, but don‚Äôt seek out opportunities to do so. Mixed: The candidate participates in change and happily goes along with it, but they are not responsible for it themselves. The candidate is flexible enough to deal with the effects of change in an organisation, but does not particularly take much initiative. The candidate is able to describe a rare case of them causing a change to occur. Yes: The candidate has taken initiative to solve problems and improve processes. The candidate can describe the issue, what they did to address it, who they involved, and the value of the change. The candidate volunteers to solve issues. The candidate has written or spoken extensively on a topic with the aim of influencing decision makers. Strong Yes: The candidate repeatedly drives change in their organisation, above and beyond what might be expected of someone in their role or seniority. They have caused large numbers of people to change in a meaningful way. They have helped influence the direction of a product by prototyping without seeking formal approval. Multiple product features exist because the candidate actively lobbied for and/or implemented them. The candidate sees driving change as a default behaviour, and does it unconsciously. Can the candidate make things or themselves better? In a technical interview, is the candidate satisfied with the brute force solution? Or do they look for a better approach without being asked? It‚Äôs ok if they ask for hints on how things can be better ‚Äî in this section we‚Äôre mostly concerned with ‚Äúare they satisfied?‚Äù. Ideally, they‚Äôll never be satisfied, given the constraints of the interview format, unless there is a ‚Äúperfect‚Äù answer and they find it. In a non-technical interview, does the candidate strive to improve themselves? Do they research things or learn new skills? Strong No: The candidate is satisfied with their current capabilities, and does not want to add additional skills. The candidate considers their learning ‚Äúdone‚Äù. No: The candidate does not take an active role in improving themselves. The candidate has not progressed in any meaningful way for a long time (relatively), and their career has plateaued. The candidate does not demonstrate the ability to learn from their mistakes. Mixed: The candidate has made a few half-hearted attempts to improve themselves, though not in any consistent way. Their career has been stop-start, with long periods that demonstrate no progress. Yes: The candidate demonstrates a strong desire to improve their craft. They deliberately work outside their comfort zone in order to broaden or deepen their skills. They are continually learning, whether through courses, reading material, practice or another method. The candidate has advanced steadily in their career. Strong Yes: The candidate is never satisfied with their competency or capabilities, and is constantly trying to improve. The candidate can describe multiple areas where they are aiming to get better, or skills they would like to deepen. The candidate has an exceptionally steep career trajectory, advancing quickly in seniority and experience through dedication to self-improvement. Does the candidate respect people‚Äôs time, and their own time? Can they effectively prioritise things so the most important work is done first? It does not matter, within reason, what time an engineer is at their desk or in the office. What matters is their ability to commit to a deadline and then hit it. In a coding interview, do they have the urgency necessary to get to the best solution they can in the limited time they have? For junior engineers, project work or internships with a deliverable are also valuable indicators. Strong No: The candidate has no sense of urgency and is content to bide time. They are content to do average work that does not satisfy them, so as to make rent (unless, at the interviewer‚Äôs discretion, there are extenuating life circumstances that require them to do so). The candidate has no demonstrated history of hitting a deadline. When leading projects, they have no concept of work-life balance for their subordinates. No: The candidate works hard, but is unproductive or inefficient. The candidate does not demonstrate any understanding of time-boxing, and has spent large amounts of time on futile endeavours (except if, in the judgement of the interviewer, they were trying something truly new and innovative). The candidate sees no value in deadlines as someone who is doing the implementing. If leading a project, the candidate cannot hit tight deadlines. The candidate is frequently late. Mixed: The candidate recognises the need for deadlines, but is content with setting or meeting conservative timelines that allow them to take their time. The candidate is sometimes late to meetings with no prior warning. When writing code, the candidate does not manage to finish the problem in the allotted time when, in the judgement of the interviewer, they could have if they had worked a little faster. Yes: The candidate demonstrates a healthy sense of urgency. They are able to prioritise competing needs effectively. The candidate is able to balance ideology with pragmatism, and is cognisant of time constraints. The candidate rejects timelines that are incredibly conservative as wasteful and unambitious. The candidate is always on time, or provides timely updates so as to avoid wasting others‚Äô time. They try to front-load their work, so as to have time to deal with unexpected consequences later. Strong Yes: The candidate has a strong bias to moving fast, shipping products and improving on them. The candidate is very respectful of other people‚Äôs time. They do not schedule needless meetings. They set aggressive but reasonable deadlines and then work hard to meet them. The candidate is constantly trying to find ways to be more efficient, and drives the organisation to do the same. Medium is not a family, even if many of us are very close. We don‚Äôt apply the airport test . But we do want a happy environment that people enjoy working in every day. The candidate doesn‚Äôt have to be a comedian, or extroverted, or the constant centre of attention, but they should enjoy their work, and demonstrate an ability to have fun. Your sense of fun and theirs doesn‚Äôt have to agree. Be careful not to conflate this with ‚Äúable to take a joke at their own expense‚Äù. That‚Äôs not expected of candidates. Likewise, the candidate is not expected to be good humoured about the structural inequalities in our industry or society . Candidates are not expected to be happy all the time. Much of the work we do is demanding and often frustrating. However, there should be some demonstrated joy in the craft, or examples of when they enjoyed their work. An excessively negative personality can be toxic to a small team and drain it of energy. Strong No: Makes jokes about marginalised groups, or laughs maliciously at others‚Äô misfortune. Sees work as a place to clock-in, do their eight hours, and clock out. Shows no interest in learning anything about their colleagues. Is excessively negative about the business and/or the product. No: The candidate can‚Äôt recall a time when they enjoyed themselves at work. The candidate is generally pessimistic and unable to describe many or any highlights of any previous roles. They appear to take no satisfaction in their work. Mixed: The candidate is unable to see the humour in anything they work on, and demonstrates no real love for it. While not pessimistic, they are not able to generate much enthusiasm for the things they‚Äôve worked on, or for Medium. Nothing really excites them. Yes: The candidate brings a sense of humour and joy to their work. The candidate is able to laugh at themselves (when they are the ones doing the joking) or some of the absurdity of the job. They are generally excited about their opportunities and are upbeat and positive. Strong Yes: The candidate derives immense pleasure from their work. They have an easy, affable nature that puts people at ease. The candidate is optimistic and tries to look on the positive side. For more introverted candidates, they are able to describe something they were very proud to have shipped that they enjoyed working on. You will be asked to give a final overall assessment of the candidate, Strong No , No , Yes , or Strong Yes . We can teach someone who is lacking in one or two technical categories, provided they have the right attitude. It is harder to change a person‚Äôs personality, or gain alignment with them on values. Below are general guidelines for how to think about each grade. There may be exceptions to this, at your discretion. Each case is unique, so exercise your best judgement. Although we are aiming to grow quickly, it is still true that a bad hire can have far-reaching and wide-ranging consequences. You should consider that your reputation as an interviewer is attached to your recommendation. Give an overall Strong No only if you think hiring the candidate would cause significant harm to Medium. A single overall Strong No from an interviewer is likely to result in rejection of the candidate in all but the most exceptional circumstances, even if other interviewers are in favour. Be judicious in your use of this grade. Give a No if you think the candidate isn‚Äôt right for Medium. Generally speaking, a Strong No in any of the personality or values categories will indicate at best an overall No, even if there are Strong Yes results for technical competencies . An overall No is also appropriate if the candidate has technical deficiencies that are too great to correct with reasonable on the job training. This will be typified by one or more Strong No results, or mostly No results in technical categories. Give a Yes if you think we should hire the candidate. Generally speaking, majority Yes and Strong Yes for personality and values categories may indicate an overall Yes , even if there are one or two technical No grades. An overall Strong Yes is a strong signal, and should be reserved for someone who you think we really need to have on our team. Be judicious in your use of this grade. Ex-gaijin, kangaroo-loving software simian from Merrie England, building @Mailchimp and @Pinian. Formerly @Medium and @StumbleUpon. 1.3K 16 Thanks to Tess Rinearson . 1.3K 1.3K 16 Medium Engineering Values Interviewing Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2018-03-14"},
{"website": "Medium-Engineering", "title": "if dr house did devops", "author": ["Dan Pupius"], "link": "https://medium.engineering/if-dr-house-did-devops-77322a7baf09", "abstract": "Sign in Dan Pupius Mar 17, 2016 ¬∑ 2 min read In the TV series House, a diagnostician and his team tackle medical mysteries. Every episode a patient presents with serious symptoms of unknown cause. The race is on to find a cure. At some point during the episode the team huddle around a whiteboard. Symptoms are written up. Hypotheses are shouted out. When they have a set of possible diagnoses ‚Äî the ones House hasn‚Äôt been able to shoot down ‚Äî they start a course of treatment for the most serious one. The treatment will either help, rule out the diagnosis, or as is most common in the show, uncover new information and new mysteries. This process is called Differential Diagnosis (DDx). Now, switch gears a bit, you‚Äôre a software engineer and you‚Äôre doing your on-call rotation. What can you learn from House? Modern software is complex. There are often multiple clients, multiple interacting services, and likely black-box 3rd party systems. When things go wrong it‚Äôs often not clear why. This is where DDx can be useful: Rule out simple, common explanations. Gather all the data; create a list of symptoms. List possible causes for the collection of symptoms. Prioritize the list of causes, most urgent at the top. Treat possible causes, or rule out through additional data. This likely sounds intuitive to experienced DevOps and SREs. It‚Äôs not uncommon for the root cause to be identified late on in an incident, or even afterwards during a postmortem. Essentially, through the act of treating symptoms, you find the cause. I like Differential Diagnosis as a framework to formalize the investigation process, to help make decisions in a stressful situation, and to train less-experienced engineers in incident response. Plus, it‚Äôs more fun to think you‚Äôre solving a mystery, rather than just responding to a snafu. Englishman in California. Father, engineer, photographer. Recovering adrenaline junky. Founder @ www.range.co . Previously: Medium, Google. 149 3 Thanks to Tessa MacDuff Pupius and Nathaniel Felsen . 149 149 3 DevOps Incident Response Infrastructure Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2016-05-05"},
{"website": "Medium-Engineering", "title": "too much rope", "author": ["Dan Pupius"], "link": "https://medium.engineering/too-much-rope-406af0a03d4e", "abstract": "Sign in Dan Pupius Jan 20, 2016 ¬∑ 8 min read This was original published as a chapter in O‚ÄôReilly‚Äôs ‚Äú Beautiful JavaScript ‚Äù, go buy a copy, all proceeds go to the EFF. Beauty is power and elegance, right action, form fitting function, intelligence, and reasonability. ‚Äî Kim Stanley Robinson, Red Mars JavaScript is a flexible language. In fact, this entire book is a testament to its expressiveness and dynamism. Within these pages you‚Äôll hear stories of how to bend the language to your will, how to use it to experiment and play, and suggestions for seemingly contradictory ways to write it. My job is to tell a more cautionary tale. I‚Äôm here to ask the q uestion: What does it mean to write JavaScript in a team? How do you maintain sanity with 5, 10, 100 people committing to the same codebase? How do you make sure new team members can orient themselves quickly? How do you keep things DRY without forcing broken abstractions? In 2005 I joined the Gmail team in sunny Mountain View, California. They were building what many considered at the time to be the pinnacle of web applications. The team was awesomely smart and talented, but across Google, JavaScript wasn‚Äôt considered a ‚Äúreal programming‚Äù language ‚Äî you engineered backends, you didn‚Äôt engineer web UIs ‚Äî and this mentality affected how they thought about the code. Furthermore, even though the language was 10 years old, JavaScript engines were still limited, they were designed for basic form validation not building applications. Gmail was starting to hit performance bottlenecks. To get around these limitations much of the application was implemented as global functions, anything requiring a dot-lookup was avoided, sparse arrays were used in place of templates, and string concatenation was a no-no. The team was writing first and foremost for the JavaScript engine, not themselves or other members of the team. This led to a codebase that was hard to follow, inconsistent, and sprawling. Instead of optimizing by hand, we transitioned to a world where code was written for humans and the machine did the optimizations. This wasn‚Äôt a new language mind you, it was important that the raw code be valid JavaScript, for ease of understanding, testing, and interoperability. Using the precursor to the Closure Compiler, we developed optimization passes that would collapse namespaces, optimize strings, inline functions, and remove dead code. This is work much better suited to a machine and allowed the raw code to be more readable and more maintainable. Lesson 1: Code for one another, use tools to perform mechanical optimizations. As the old adage goes, debugging is harder than writing code, so if you write the cleverest code you can, you‚Äôll never be clever enough to debug it. It can be fun to come up with obscure and arcane ways of solving problems, especially since JavaScript gives you so much flexibility. But save it for personal projects and JavaScript puzzlers. When working in a team you need to write code that everyone is going to understand. Some parts of the codebase may go unseen for months until a day comes when you need to debug a production issue. Or perhaps you have a new hire with little JavaScript experience. In these types of situation keeping code simple and easy to understand will be better for everyone. You don‚Äôt want to spend time decoding some bizarro, magical incantation at 2am in the morning while debugging production issues. Consider the following: And an alternative way of expressing the same behavior: Saying that the second snippet is better than the first may seem in conflict with the concept that ‚Äúsuccinctness = power‚Äù. But I believe there is a disconnect that stems from the common synonyms for succinct: compact, brevity, brief. I prefer terse as a synonym: using few words, devoid of superfluity, smoothly elegant The first snippet is more compact than the second snippet, but it is denser and actually includes more symbols. When reading the first snippet you have to know how coercion rules apply when using a numeric operator on a boolean, you have to know that methods can be invoked using subscript notation, and you have to notice that square brackets are used for both defining an array literal and method look up. The second snippet, while longer actually has less syntax for the reader to process. Furthermore it reads like english: ‚Äúif the element‚Äôs class list contains ‚Äòon‚Äô, then remove ‚Äòon‚Äô from the class list, otherwise add ‚Äòon‚Äô to the class list.‚Äù All that said, an even better solution would be to abstract this functionality and have the very simple, readable, and succinct: Lesson 2: Keep it simple; compactness != succinctness. When talking with ‚Äúproper programmers‚Äù they often complain about how terrible JavaScript is. I usually respond that JavaScript is misunderstood and that one of the main issues is that it gives you too much rope ‚Äî so inevitably you end off hanging yourself. There were certainly questionable design decisions in the language, and it is true that the early engines were quite terrible, but much of the problems that occur as JavaScript codebases scale can be solved with pretty standard computer science best practices. A lot of it comes down to code organization and encapsulation. Unfortunately, until we finally get ES6 there is no standard module system, no standard packaging mechanisms, and a prototypal inheritance model that confuses a lot of people and begets a million different class libraries. While JavaScript‚Äôs prototypal inheritance allows instance based inheritance, I generally suggest when working in a team that you simulate classical inheritance as much as possible, while still utilizing the prototype chain. In the above example, billy inherits from bob . What that means in practice is that billy.prototype = bob and non-matching property lookups on billy will delegate to bob . In other words, to begin with billy‚Äôs $100 is bob‚Äôs $100; billy isn‚Äôt a copy of bob . Then when billy get‚Äôs his own money it essentially overrides the property that was being inherited from bob . Deleting billy‚Äôs money doesn‚Äôt set it to undefined , instead bob‚Äôs money become‚Äôs billy‚Äôs again. This can be rather confusing to newcomers. In fact developers can go a long time without ever knowing precisely how prototypes work. So, if you use a model that simulates classical inheritance it increases the chance that people on your team will onboard quickly and allows them to be productive without necessarily needing to understand the details of the language. Both the Closure Library‚Äôs goog.inherits and Node.js‚Äôs util.inherits make it easy to write class-like structures while still relying on the prototype for wiring. This looks very similar to inheritance in other languages. Bank inherits from EventEmitter ; the super class‚Äôs constructor is called in the context of the new instance; util.inherits wires up the prototype chain just like we saw with bob and billy above; and then the property lookup for emit falls to the EventEmitter ‚Äúclass‚Äù. A suggested exercise for the reader is to create instances of a class without using the new keyword. Lesson 3: Just because you can, doesn‚Äôt mean you should. Lesson 4: Utilize familiar paradigms and patterns. The need for consistent style as codebases and teams grow is nothing unique to JavaScript. However, where many languages are opinionated about coding style, JavaScript is lenient and forgiving. This means its all the more important to define a set of rules which the team should stick to. Good style is subjective and can be difficult to define, but there are many cases where certain style choices are quantifiably better than others. In the cases where there isn‚Äôt a quantifiable difference, there is still value in making an arbitrary choice one way or the other. Style guides provide a common vocabulary so people can concentrate on what you‚Äôre saying instead of how you‚Äôre saying it. A good style guide should set out rules for code layout, indentation, whitespace, capitalization, naming, and comments. It is also good to create usage guides, that explain best practices and guidance on how to use common APIs. Importantly, these guides should explain why a rule exists; over time you will want to reevaluate the rules and should avoid them becoming cargo cults. Style guides should be enforced by a linter and if possible coupled with a formatter to remove the mechanical steps of adhering to the guide. You don‚Äôt want to waste cycles correcting style-nits in code reviews. The ultimate goal is to have all code look like it was written by the same person. Lesson 5: Consistency is king. When first working on Google Closure there was no simple utility for making XMLHttpRequests, everything was rolled up in large, application specific request utilities. So in my na√Øvet√© XhrLite was born. XhrLite became popular, no one wants to use a ‚Äúheavy‚Äù implementation, but its users kept finding features that were missing. Over time small patches were submitted, and XhrLite accumulated support for form encoded data, JSON decoding, XSSI handling, headers, and more, even fixes for obscure bugs in FF3.5 web workers. Needless to say the irony of XhrLite being a distinctly heavy behemoth was not lost, and eventually it was renamed XhrIo, though the API remained bloated and cumbersome. Small changes ‚Äî reasonable in isolation ‚Äî evolve into a system that no one would ever design if given a blank canvas. Evolutionary complexity is almost a force of nature in software development, but it has always seemed more pronounced with JavaScript. One of the strengths that helped spur JavaScript‚Äôs popularity is that you can get up and running quickly. Whether you‚Äôre creating a simple web app or a Node.js server, a minimal dev environment and a few lines of code yields something functional. This is great when you‚Äôre learning, or prototyping, but can lead to fragile foundations for a growing team. You start out with some simple HTML and CSS. Perhaps you add some event handlers using jQuery. You add some XHRs, maybe you even start to use pushState. Before long you have an actual Single-Page Application, something you never intended at first. Performance starts to suffer, there are weird race conditions, your code is littered with setTimeouts, there are hard to track down memory leaks‚Ä¶ you start wondering if a traditional web page would be better‚Ä¶ you have the duck-billed platypus of applications. Lesson 6: Lay good foundations. Be mindful of evolutionary complexity. JavaScript‚Äôs beauty is in its pervasiveness, its flexibility, and its accessibility. But beauty is also contextual. What started as a ‚Äúscripting language‚Äù is now used by hundred-plus person teams and forms the building blocks of billion dollar products. In such situations you can‚Äôt write code in the same way you would hacking up a one-person website. So‚Ä¶ Code for one another, use tools to perform mechanical optimizations. Keep it simple; compactness != succinctness. Just because you can, doesn‚Äôt mean you should. Utilize familiar paradigms and patterns. Consistency is king. Lay good foundations. Be mindful of evolutionary complexity. Englishman in California. Father, engineer, photographer. Recovering adrenaline junky. Founder @ www.range.co . Previously: Medium, Google. 124 2 124 124 2 JavaScript Coding Style Webclient Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2016-05-05"},
{"website": "Medium-Engineering", "title": "medium engineering job openings", "author": ["Medium Engineering"], "link": "https://medium.engineering/medium-engineering-job-openings-500e4a97e5e", "abstract": "Sign in Medium Engineering Feb 1, 2016 ¬∑ 1 min read We hire people with the expectation they may play many roles once they are here, but we source people for specific skills and interview them on their strengths. This list highlights the particular skill areas we are currently on the look out for. Last Updated: 28 November 2016 High Priority: Frontend Web Platform / Infrastructure Data Pipeline and Analytics Opportunistic: iOS Android Backend Engineer ‚Äî Node Test Infrastructure Publisher Solutions Engineer / Developer Advocate Analytics / Data Science Performance Czar Machine Learning and NLP Trust and Safety Internationalization Monetization While senior ICs and people with leadership experience are preferred, we‚Äôll consider candidates with a few years of experience, who are on a good career trajectory and embody CARE . We encourage candidates of all backgrounds, race, gender, and ethnicity to apply. Learn mo r e about who we are, what we‚Äôre looking for, and how to apply . We are the @Medium engineering team 83 3 Thanks to Jamie Talbot . 83 83 3 Jobs Media Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2016-11-30"},
{"website": "Medium-Engineering", "title": "the time we took the interns to pirate s cove", "author": ["Dan Pupius"], "link": "https://medium.engineering/the-time-we-took-the-interns-to-pirate-s-cove-76faea5c3ee3", "abstract": "Sign in Dan Pupius Aug 20, 2015 ¬∑ 3 min read This summer it‚Äôs been our pleasure to host three of the amazing fellows from Code2040's class of 2015. With less than a month left in their internships, the interns, the hosts, and I headed across the Golden Gate Bridge for a coastal hike from Muir Beach to Pirate‚Äôs Cove. Our little jaunt covered 5 miles and around 1500 feet of elevation. It was good to get into nature . We had a bunch of good conversations about everything from college football to neuroscience, and had fun scrambling round on rocks. Thanks to o u r interns Leilani , Bamidele , and Eduardo , and to the hosts Jamie , Grant , and Andrew , for a fun hike and a great summer. Englishman in California. Father, engineer, photographer. Recovering adrenaline junky. Founder @ www.range.co . Previously: Medium, Google. 69 69 69 Medium Code2040 Events And Press Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2016-05-05"},
{"website": "Medium-Engineering", "title": "the stack that helped medium drive 2 6 millennia of reading time", "author": ["Dan Pupius"], "link": "https://medium.engineering/the-stack-that-helped-medium-drive-2-6-millennia-of-reading-time-e56801f7c492", "abstract": "Sign in Dan Pupius Oct 23, 2015 ¬∑ 10 min read Medium is a network. It‚Äôs a place to share stories and ideas that matter ‚Äî it‚Äôs where you move thinking forward, and people have spent 1.4 billion minutes ‚Äî or 2.6 millennia ‚Äî reading on Medium. We get over 25 million unique readers every month and tens of thousands of posts published each week. But we want Medium to be a place where the measure of success isn‚Äôt views, but viewpoints. Where the quality of the idea matters, not the author‚Äôs qualifications. A place where conversation pushes ideas forward and words still matter. I lead t he engineering team. I was previously a Staff Software Engineer at Google, where I worked on Google+ and Gmail, and co-founded the Closure project. In past lives I‚Äôve raced snowboards, jumped out of planes, and lived in the jungle. I couldn‚Äôt be prouder of this team. It‚Äôs an awesome bunch of talented, curious, mindful individuals who come together to do great work. We operate in cross-functional, mission-driven teams, so while some people specialize, everyone should feel able to touch any part of the stack. We believe that exposure to different disciplines makes you a stronger engineer. I wrote about our other values here . The teams have a lot of flexibility in how they organize around their work, but as a company we set quarterly goals and encourage iterative sprints. We use GitHub for code reviews and bug tracking and Google Apps for email, docs, and spreadsheets. We‚Äôre heavy users of Slack ‚Äî and slack bots ‚Äî and many teams use Trello. We deployed to EC2 from the start. The main app servers were written in Node.js , and we migrated to DynamoDB for the public launch. There was a node server that we used for image processing, delegating to GraphicsMagick for the actual hard work. And another server acted as a SQS queue processor for background tasks. We used SES for email, S3 for static assets, CloudFront as CDN, and nginx as a reverse proxy. We used Datadog for monitoring and PagerDuty for alerting. The site used TinyMCE as a foundation for the editor. Before launch we were already using the Closure Compiler and some portions of the Closure Library , but Handlebars for templates. For a site as seemingly simple as Medium, it may be surprising how much complexity is behind the scenes. It‚Äôs just a blog, right? You could probably knock something out using Rails in a couple of days. :) Anyway, enough snark. Let‚Äôs start at the bottom. Production Environment We are on Amazon‚Äôs Virtual Private Cloud . We use Ansible for system management, which allows us to keep our configuration under source control and easily roll out changes in a controlled way. We have a service-oriented architecture, running about a dozen production services (depending on how you count them and some more micro than others). The primary choice as to whether to deploy a separate service is the specificity of the work it performs, how likely dependent changes are to be made across service boundaries, and the resource utilization characteristics. Our main app servers are still written in Node , which allows us to share code between server and client, something we use quite heavily with the editor and post transformations. Node has worked pretty well for us, but performance problems have emerged where we block the event loop. To alleviate this, we run multiple instances per machine and route expensive endpoints to specific instances, thus isolating them. We‚Äôve also hooked into the V8 runtime to get insights into what ticks are taking a long time; generally it‚Äôs due to object reification during JSON deserialization. We have several auxiliary services written in Go . We‚Äôve found Go very easy to build, package, and deploy. We like the type-safety without the verbosity and JVM tuning of Java . Personally, I‚Äôm a fan of using opinionated languages in a team environment; it improves consistency, reduces ambiguity, and ultimately gives you less rope to hang yourself. We now serve static assets using CloudFlare , though we send 5% of traffic to Fastly and 5% to CloudFront to keep their caches warm should we need to cut over in an emergency. Recently we turned up CloudFlare for application traffic as well ‚Äî primarily for DDOS protection but we‚Äôve been happy with the performance gains. We use a combination of Nginx and HAProxy as reverse proxies and load balancers, to satisfy the Venn Diagram of features we need. We still use Datadog for monitoring and PagerDuty for alerts, but we now heavily use ELK ( Elasticsearch , Logstash , Kibana ) for debugging production issues. Databases DynamoDB is still our primary datastore, but it hasn‚Äôt been completely smooth sailing. One of the perennial issues we‚Äôve hit is the hotkey issue during viral events or fanouts for million-follower users. We have a Redis cache cluster sitting in front of Dynamo, which mitigates these issues with reads. Optimizing for developer convenience and production stability have often seemed at odds, but we‚Äôre working to close the gap. We‚Äôre starting to use Amazon Aurora for some newer data, which allows more flexible querying and filtering than Dynamo. We use Neo4J to store relations between the entities that represent the Medium network, running a master with two replicas. People, posts, tags, and collections are nodes in the graphs. Edges are created on entity creation and when people perform actions such as follow, recommend, and highlight. We walk the graph to filter and recommend posts. Data Platform From early on we‚Äôve been very data hungry, investing in our analytics infrastructure to help us make business and product decisions. More recently we‚Äôre able to use the same data pipelines to feed back into production systems to power data-driven features such as Explore . We use Amazon Redshift as our data warehouse, providing the scalable storage and processing system our other tools build on. We continuously import our core data set (e.g. users, posts) from Dynamo into Redshift, and event logs (e.g. post viewed, post scrolled) from S3 to Redshift. Jobs are scheduled by Conduit, an internal tool that manages scheduling, data dependencies, and monitoring. We use an assertion-based scheduling model, where jobs will only be executed if their dependencies are satisfied (e.g. daily job that depends on an entire day of event logs). In production this has proved indispensable ‚Äî data producers are decoupled from their consumers, simplifying configuration, and the system is very predictable and debuggable. While SQL queries running in Redshift work well for us, we need to get data into and out of Redshift. We‚Äôve increasingly turned to Apache Spark for ETL because of its flexibility and ability to scale with our growth. Over time Spark will likely become the tool of choice for our data pipelines. We use Protocol Buffers for our schemas (and schema evolution rules) to keep all layers of the distributed system in sync, including mobile apps, web service, and data warehouse. Using custom options, we annotate our schemas with configuration details like table name and indexes, and validation constraints like max length for strings, or acceptable ranges for numbers. People need to remain in sync too so mobile and web app developers can all log the same way, and Product Scientists can interpret fields, in the same way. We help our people work with data by treating the schemas as the spec, rigorously documenting messages and fields and publishing generated documentation from the .proto files. Images Our image server is now written in Go and uses a waterfall strategy for serving processed images. The servers use groupcache , which provides a memcache alternative while helping to reduce duplicated work across the fleet. The in-memory cache is backed by a persistent S3 cache; then images are processed on demand. This gives our designers the flexibility to change image presentation and optimize for different platforms without having to do large batch jobs to generate resized images. While it‚Äôs now mainly used for resizing and cropping, earlier versions of the site allowed for color washes, blurring, and other image effects. Processing animated gifs has been a huge pain for reasons that should be another post. TextShots The fun TextShots feature is powered by a small Go server that interfaces with PhantomJS as a renderer process. I always imagined switching the rendering engine to use something like Pango, but in practice, the ability to lay out the image in HTML is way more flexible and convenient. And the frequency at which the feature is used means we can handle the throughput quite easily. Custom Domains We allow people to set up custom domains for their Medium publications. We wanted single sign-on and HTTPS everywhere, so it wasn‚Äôt super trivial to get working. We have a set of dedicated HAProxy servers that manage certs and route traffic to the main fleet of application servers. There is some manual work required when setting up a domain, but we‚Äôve automated large swathes of it through a custom integration with Namecheap. The cert provisioning and publication linking is handled by a dedicated service. Web Frontend On the web, we tend to want to stay close to the metal. We have our own Single Page Application framework that uses Closure as a standard library. We use Closure Templates for rendering on both the client and the server, and we use the Closure Compiler to minify the code and split it into modules. The editor is the most complex part of our web app, which Nick has written about. iOS Both our apps are native, making minimal use of web views. On iOS, we use a mixture of homegrown frameworks and built-in components. In our network layer, we use NSURLSession for making requests and Mantle for parsing JSON into models. We have a caching layer built on top of NSKeyedArchiver. We have a generic way to render items in a list with a common styling, which allows us to quickly build new lists with different types of content. The post view is built with a UICollectionView with a custom layout. We use shared components to render the full post and the post preview. Every commit is built and pushed to Medium employees, so that we can try out the app as quickly as possible. The cadence of our release to the appstore is beholden to the review cycle, but we try to keep pushing as fast as we can, even if there are only minimal updates. For tests, we use XCTest and OCMock. Android On Android, we stay current with the very latest editions of the SDK and support libraries. We don‚Äôt use any comprehensive frameworks, preferring instead to establish consistent patterns for repeated problems. We use guava for all the things missing from Java. But otherwise, we tend to use 3rd party tools that aim to solve more narrow problems . We define our API responses using protocol buffers and then generate the objects we use in the app. We use mockito and robolectric . We write high-level tests that spin up activities and poke around ‚Äî we create basic versions of these when we first add a screen or to prepare for refactoring. They grow as we reproduce bugs to shield against regression. We write low-level tests to exercise the particulars of a single class ‚Äî we create these as we build out new features and they help us reason about how our classes interact. Every commit is automatically pushed to the play store as an alpha build, which goes out to Medium staff right away. (This includes another flavor of the app, for our internal version of Medium ‚Äî Hatch ). Most Fridays we promote the latest alpha to our beta group and have them play with things over the weekend. Then, on Monday, we promote it from beta to production. Since the latest code is always ready for release, when we find a bad bug, we get the fix out to production immediately. When we‚Äôre worried about a new feature, we let the beta group play with things a little longer; when we‚Äôre excited, we release even more frequently. A|B Testing & Feature Flags All our clients use server-supplied feature flags, called variants , for A|B testing and guarding unfinished features. Misc There are a lot of other things on the fringe of the product that I haven‚Äôt mentioned above: Algolia has allowed us to iterate quickly on search-related functionality, SendGrid for inbound and outbound email, Urban Airship for notifications, SQS for queue processing, Bloomd for bloom filters, PubSubHubbub and Superfeedr for RSS, etc. etc. We embrace continuous integration and delivery, pushing on green as fast as possible. Jenkins manages all those processes. Historically we‚Äôve used Make for our build system, but we‚Äôre migrating to Pants for newer projects. We have a combination of unit tests and HTTP level functional tests . All commits have to pass tests before they can be merged. We worked with the team at Box to use Cluster Runner to distribute the tests and make this fast. There‚Äôs nice integration with GitHub . We deploy to a staging environment as quickly as we can ‚Äî currently about 15 minutes ‚Äî and successful builds are then used as candidates for production. The main app servers normally deploy around five times a day, but sometimes as many as 10 times. We do blue/green deploys. For production we send traffic to a canary instance, and the release process monitors error rates before proceeding with the deploy. Rollbacks are internal DNS flips. So much! There‚Äôs a lot to do to refine the core product and make the reading and writing better. We‚Äôre also starting to work on monetization features for authors and publishers. This is a green field project, and we‚Äôre approaching the problem space with open minds. We think the future needs new mechanisms for funding content, and we want to make sure our features incentivize quality content and value to the network. Generally we‚Äôre always interested in talking with mission-driven engineers who have experience working in the consumer space. We‚Äôre not prescriptive about what languages you know, since we think that good engineers can quickly learn new disciplines, but you should be curious, aware, resolute, and empathetic . That said, experience with iOS, Android, Node, or Go would give you a head start. We‚Äôre growing our Product Science team , so are looking for people with experience building data pipelines and large analytical systems. And I‚Äôm looking for engineering leaders to help scale the team. They should be interested in organizational theory, be willing to get their hands dirty, and be proponents of servant leadership. You can find out more about Medium Engineering here . Englishman in California. Father, engineer, photographer. Recovering adrenaline junky. Founder @ www.range.co . Previously: Medium, Google. 4.5K 69 Thanks to Nathaniel Felsen , Jamie Talbot , Nick Santos , Jon Crosby , Rudy Winnacker , Dan Benson , Jean Hsu , Jeff Lu , Daniel McCartney , and Kate Lee . 4.5K 4.5K 69 StackShare Engineering Events And Press Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2016-05-05"},
{"website": "Medium-Engineering", "title": "how medium detects hotspots in dynamodb using elasticsearch logstash and kibana", "author": ["Nathaniel Felsen"], "link": "https://medium.engineering/how-medium-detects-hotspots-in-dynamodb-using-elasticsearch-logstash-and-kibana-aaa3d6632cfd", "abstract": "Sign in Nathaniel Felsen Sep 8, 2015 ¬∑ 6 min read One of the most common issues you face when using DynamoDB, or any similar ‚ÄúBig Data‚Äù type database, is that it doesn‚Äôt access your data in a very uniform pattern. It‚Äôs a kind of issue commonly known as a hotspot or a hotkey . Let me try to help you understand what I mean. (By the way, I‚Äôm using DynamoDB here as an example, but this is applicable to virtually any distributed data store: Aerospike, Cassandra, Couchbase, you name it.) As your database grow s in size or is being accessed more and more often , you start hitting limits. The limit could be the number of objects you are able to keep in memory, or on disk. Or it could be that your application starts sending too many concurrent requests, and your database has to queue more and more requests. Scaling vertically ‚Äî adding more memory, more CPU ‚Äî has its limits, so all modern databases get around these problems by scaling horizontally: adding more servers. Let‚Äôs imagine that you have one database that can handle around 1,000 queries per seconds (QPS). If you manage to break up the data in two sets, and use two similar servers to store the same data, you can essentially get up to 2,000 QPS from your server ‚Äî as long as you access your data uniformly. Let‚Äôs imagine we‚Äôre storing people‚Äôs names in a database. Because we have a lot of people to store and we want to be able to access each of them really fast, we scale our database to 26 servers, one server per letter. We then break up the data by storing people‚Äôs information on those 26 servers using the first letter of the last name. Now you could potentially get to 26,000 QPS ‚Äî if the requests are made to all letters equally. However, if 99% of the requests are made for ‚ÄúJohn Doe‚Äù, you will mostly access the server containing the letter D, which means that your actual QPS will hardly be above 1,000, where we started. This is what a hotspot or hotkey is. In the world of Big Data, even though you usually talk to one endpoint, the same concepts apply. A DynamoDB table might be served by 20‚Äì30 different servers. But accessing the same keys over and over will create hotspots on a smaller subset, causing negative impact on overall performance. While hotspots are generally annoying to deal with, they are particularly hard in DynamoDB. DynamoDB is a managed service, which means you can‚Äôt do much when it comes to administrating it. In terms of capacity, you can only set a desired throughput for your read and write capacity. Let‚Äôs say you create a table and provision it with 100 write capacity unit (WCU). As long as your consumption stays below capacity you will be fine, but when you try to consume more than you provisioned the table for ‚Äî like 200 WCU ‚Äî DynamoDB will start returning throttling errors on some of your queries. What makes DynamoDB more challenging than competing technologies is that it takes the Read Capacity Unit (RCU) and Write Capacity Unit (WCU) values and divides them by the number of partitions your table has ‚Äî without ever exposing how many partitions your table has. This makes it very difficult to optimize the provisioned capacity units, and you‚Äôre forced to over-provision the entire table to satisfy the needs of your busiest partition. Take a look at this: Looking at the last 24 hours, it seemed that we had way enough capacity (the red line) to handle all the writes (blue line). But when we look at the Throttled Write Requests graph, on the right hand side here, we see that we had spikes at 150,000 concurrent request throttled. Why? Basically, if your table becomes too big, or if you need to be able to do a lot of concurrent requests, it gets partitioned automatically ( This document explains it in more detail .) The number of partitions isn‚Äôt exposed anywhere, but it directly impacts how you should set your read and write capacity units. In fact, the provisioned capacity is to be divided by the number of partitions. Looking back at the graph above, we set the Provisioned write Capacity to 1,400 ‚Äî but if the table is stored on 28 partitions, each partition only gets 50 WCU (1400/28). This makes the WCU per partition a lot closer to the average consumed capacity, and can be a possible reason why we are seeing a huge amount of throttled requests. So getting back to the concept of uniform access pattern, if you happen to access mostly a certain subset of records, and if they happen to be located on a small subset of a partition, your table will suddenly start throttling. The capacity you actually need has been divided quite substantially. It just goes downhill from here: DynamoDB doesn‚Äôt support the merging of partitions if you remove data or lower your RCU / WCU CloudTrail doesn‚Äôt have access logs. CloudWatch, until very recently , was only reporting every 5 minutes, now it‚Äôs down to 1 minute. Knowing that a lot of things are out of sight and out of our control, a team at Medium worked on a project to try to detect when we have a bad access pattern, and are accessing certain keys too often. To do that, we created our own access log for DynamoDB. Here‚Äôs an example of the output. That log file (db.log) is produced by each service that accesses DynamoDB. Those files get shipped to a pool of Logstash servers using LogstashForwarder . Logstash doesn‚Äôt really do much except sending the logs to ElasticSearch and then, in turn, we use Kibana4 to retrieve the data and make a nice visualization out of it. Here are two examples. Here, I‚Äôm looking at the mediumRequestTrace_2015_08 table. We can see that there is a very uniform access pattern in the bottom graph. Basically the top keys were all accessed twice. This is very much a best case scenario. Here we are looking a table called postChunk. The top key in the DynamoDB Hot keys graph spikes at 400, totally dwarfing every other key. This is definitely an issue and if DynamoDB starts alerting on throttling, chances are that it‚Äôs because of that key. That means increasing the RCU (we are doing too many query operations) will probably not help. As the trite quote from W. Edwards Deming says: ‚ÄúYou can‚Äôt improve what you don‚Äôt measure‚Äù. By going through this exercise, we‚Äôre now a lot more efficient at detecting issues in our data access pattern. This helps us detect bugs, and ‚Äî when we are being alerted to throttling issues ‚Äî we have more insight into knowing what to do next. If you can‚Äôt read *this*, it‚Äôs probably because of me‚Ä¶. 238 5 Thanks to Xiao Ma . 238 238 5 Elk Dynamodb Infrastructure Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2016-05-05"},
{"website": "Medium-Engineering", "title": "the journey", "author": ["Stephanie Yeung"], "link": "https://medium.engineering/the-journey-25043c59ca7f", "abstract": "Sign in Stephanie Yeung Jun 5, 2015 ¬∑ 5 min read This is a recap of my talk from February 2015 Engineering All-Hands Guilds at Medium are teams organized around specific domains ‚Äî they foster collaboration and craftmanship and spread knowledge about these areas. There are currently five engineering guilds at Medium: Web Client, iOS, Node Services, Data, and Server Performance. In the Web Client Guild, members hold one of three roles: Master craftsperson, journeyperson, or apprentice. Journeypeople are effective, contributing members in the domain, while those looking to grow their skills are apprentices. Mastercraftspeople mentor apprentices. Given that I w a s the first apprentice to graduate in the guild system, I wanted to share my thoughts on the process and make the path of growth transparent and obvious. (start of original presentation) ‚ÄúSometimes it‚Äôs the journey that teaches you a lot about your destination.‚Äù ‚Äî Drake (*source unverified) The journey for me could be defined by four stages: I. ‚ÄúLet me just double check everything I‚Äôm doing‚Ä¶‚Äù In this stage, I could be building something and have a general idea of how most things seem to work, but zero confidence in any of it. Every other line, I‚Äôd be doubting: Should I use a deferred here? Am I handling the event properly? What should I name this variable? I asked a bunch of questions in this stage, which was actually great because then I started to feel like‚Ä¶ II. ‚ÄúOK, I think I can build that.‚Äù Here, I‚Äôm chugging along, feeling a bit more confident about process, and my decisions around things like whether I should make something a component or service, how to organize code, etc. I think this would be a good stage for the casual web client coder to be in, where they‚Äôre able to build features relatively autonomously. But guild membership fosters more than just personal productivity, it also involves spreading knowledge and cultivating craftsmanship in our whole eng org. This, naturally, involves code reviews, wherein I initially felt‚Ä¶ III. ‚ÄúI can review that?‚Äù When the web client code review policy was first enforced, it gave me this whole new set of anxieties ‚Äî people trust me to review their code? What if I tell someone something and I‚Äôm wrong and it‚Äôs merged and the site blows up? But then I figured I really shouldn‚Äôt worry about any of that because everyone here is (a) a good engineer, and (b) a reasonable person ‚ò∫. Code reviews actually turned out to be one of the most valuable ways to grow, which is also why I wanted to call out this stage specifically. They provided new opportunities to learn, whether it was related to our style guidelines, or tactical bits like remembering to clean up references. For unfamiliar code, it allowed me the chance to ask clarifying questions in order to understand it more. Broadly, it allowed me to view processes from different perspectives and to understand others‚Äô thought processes. And then this funny thing started happening where I‚Äôd be reviewing something or asking some questions, and then I‚Äôd realize‚Ä¶ IV. ‚ÄúOMG, I have opinions!!!‚Äù There are definitely mini-stages of this as well (e.g. from ‚ÄúI‚Äôm commenting on something you said‚Äù ‚Üí ‚ÄúI have thought deeply about something and am going to take X action to address it‚Äù), and I‚Äôm probably somewhere in the beginning-middle. As it is now, I‚Äôve just been happy to find myself participating in more discussions in my initiative and in the guild. This stage is a culmination of all the previous stages, where I‚Äôm still double checking things and bouncing ideas around, building small and larger features, and reviewing more code ‚Äî but it now all works together. So, what was the process behind all of this? Though guilds vary across the different domains, each one applies a mentor/mentee model between a Master craftsperson and their apprentice. Along with his accoutabilities as a journeyperson, Anton also had the added responsibility of teaching young, grasshopper me, comprehensive web client skills. (And I had the accountability of learning and gaining aforementioned, comprehensive web client skills and knowledge.) These skills are codified in a document by Koop (Lead Link) on Hatch , aptly titled, The Journey , which covers concepts from vanilla JavaScript, to styles and templates, to Closure, to Medium specific knowledge, etc. I found this list quite helpful just in terms of providing a well defined and scoped curriculum. Otherwise, I feel like you could say, ‚Äúokay, learn everything there is to know about the front-end,‚Äù but there‚Äôs just so much to learn in general that it could never end. We should also keep in mind though that the list of concepts isn‚Äôt exhaustive nor strict. Some of the topics translated really well into initiative work, while others were harder to reconcile. Being in the guild was really opportune in terms of then setting myself up to be a front end resource for my initiative, taking on larger projects that could further my craft. But then, of course, there were concepts that were not applicable to goals of the initiative, where I couldn‚Äôt just say, ‚Äúwhy don‚Äôt I write X feature this way so I can learn about event propagation,‚Äù as they didn‚Äôt further the initiative‚Äôs objectives. In Discovery & Delivery, while working on the homepage redesign, I was able to think about how to build reusable components like a new sidebar, how to render things efficiently and responsively like the promos on various screen sizes, and how to consider performance when manipulating elements on the screen while we‚Äôre scrolling. For anything not covered by initiative work, having Anton as my Master Craftsperson was invaluable. We‚Äôd meet once a week to check in and just go over how things were going, if I had any questions or problems that had arisen over the week. We dedicated our last couple of meetings though just to go over the preset curriculum and cover all our bases ‚Äî I didn‚Äôt really get into any details about the event loop or things like profiling memory usage during my work on the homepage, so we spent a meeting just on those. After all of that, over the course of four & a half months, I scheduled a meeting with Koop. We first established whether I felt ready to become a Journeyperson, making sure Anton just wasn‚Äôt trying to get rid of me ‚ò∫. Then, we just walked through the list of skills in his document, spending longer on some (‚Äúso, talk to me about callbacks‚Äù), chatting briefly over others (‚Äúyeah, you‚Äôve used our LESS style guidelines‚Äù). AND THEN‚Ä¶ I found the entire process very rewarding, and the guild system a very practical example of ways we foster personal and engineering development at this company. Looking forward to the rest of this journey! currently @rangelabs. previously @medium @scsatcmu, @disney. 32 32 32 Values Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2016-04-05"},
{"website": "Medium-Engineering", "title": "the unluckiest paragraphs", "author": ["Nick Santos"], "link": "https://medium.engineering/the-unluckiest-paragraphs-751dd36d2d30", "abstract": "Sign in Nick Santos Dec 4, 2015 ¬∑ 7 min read Yes, this is the kind of story that starts by quoting the W3C‚Äôs CSS 2.1 Specification on how to apply style rules to web pages. 6.4 The cascade Style sheets may have three different origins: author, user, and user agent [the web browser]. [‚Ä¶] Style sheets from these three origins will overlap in scope, and they interact according to the cascade. The CSS cascade assigns a weight to each style rule. When several rules apply, the one with the greatest weight takes precedence. By default, rules in author style sheets have more weight than rules in user style sheets. Precedence is reversed, however, for ‚Äú!important‚Äù rules. All user and author rules have more weight than rules in the UA‚Äôs default style sheet. This text is a small-picture look at one of the grand underpinning ideas of the web. Every web page is a democracy of three parties: the author, the user, and the web browser. Each gets to contribute to the overall style of the page. And a set of laws decides how those contributions collaborate and merge, to get us to the web page you see on your screen. The pre c edence rules always remind me of Isaac Asimov‚Äôs ‚Äú I, Robot ,‚Äù where he lays out simple rules for how robots should behave, then tells stories of edge cases where the rules collide to cause problems. But Asimov‚Äôs an optimist. He believes that simple precedence rules can lead us to enlightenment, even though the road may be bumpy. It‚Äôs a comforting read for anyone that writes technical specs. This post is not about enlightenment. This post is about the problems. In early January, a user complained that they were not able to load the post ‚Äú Advertising Is Not For Geniuses .‚Äù On the author‚Äôs profile page, they would click on the post link, and get an error. Our engineers couldn‚Äôt reproduce the bug. One user support guy could. He made a screencast. This became our shining example of why screencasts are useful: one inconspicuous icon in the corner gave the bug away. That stop sign is an ad blocker. On most webpages, if you click a link, the browser automatically handles loading a new page. On Medium, we speed this up a bit with JavaScript. We send a request to ‚Äú https://medium.com/@ritasustelo/advertising-is-not-for-geniuses-5d1ffbc505ac?format=json ,‚Äù download the article text, and render it in your browser. The ad blocker believed we were requesting advertising to show, and blocked the request. The media has been paying more attention to ad blockers in the past few months. In August, Adobe and PageFair released a report showing a steady rise in users installing ad blockers. In September, Apple launched iOS9, which allowed ad blockers on iPhones. If you think of the separation of powers between author, user, and web browser as a weird sort of government, ad blockers are The Freedom Caucus . Also known as The ‚ÄúHell No‚Äù Caucus. The ad blockers are the hell-no backlash against a web plastered with too much advertising. If this is new to you, go read ‚Äú Welcome to the Block Party ,‚Äù which is a great summary of what‚Äôs going on. Most of the media coverage focuses on whether ad blocking is a good idea. That‚Äôs not the part I‚Äôm interested in here, because ‚Äî to be obnoxiously pedantic ‚Äî ad blockers do not ‚Äúblock ads.‚Äù They create a set of rules to try to classify ads, and implement a set of measures to block what they classified. There‚Äôs a big gap between what is classified by those rules, and what‚Äôs an ad. Some of that gap is philosophical. How do you define ‚Äúadvertising,‚Äù maaaaannnnnn üåø? Some is technical. Often the classification rules are laughably simple, like checking if the address has the word ‚Äúadvertising‚Äù in it. Sometimes they‚Äôre more complex. One of Medium‚Äôs main theses is that ‚Äúpage views‚Äù is a terrible metric. It incentivizes some of the worst parts of the web, like short articles split across multiple pages to increase ad impressions. Our data science team experiments with better metrics, like how much time people spend reading. To track these metrics, we send requests to the `/_/stat` route. Many ad blockers also double as privacy protection. Someone added `/_/stat` to the EasyPrivacy block list . We used `/_/stat` for other types of statistics, including: Are you experiencing errors? How slow is the page? Have you seen the onboarding dialogs yet? Counterintuitively, users with this ad blocker installed saw lots of redundant onboarding popups. When they sent us emails help, we found it difficult to diagnose their problems. It gets better, though! Not all ad blockers implemented the EasyPrivacy list consistently. Some matched only `/_/stat`. Others matched anything beginning with `/_/stat`, including `/_/static/icons.svg`. Many users saw their icons vanish. We wrote a post to assure people that, no, our icons are not clandestine payloads for advertising. After some conversations with the block list maintainers, and the EFF, we simply changed the URL. By this point, we‚Äôre used to random things on Medium disappearing due to ad blockers mis-classifying. But the best one came in a few weeks ago, when someone complained that a random paragraph in a post ‚Äú 6 step East European weight loss system ‚Äù was missing. To understand what happened, start with the Medium data model. All posts are represented as a list of paragraphs. We give each paragraph a unique name. The code to generate names is a one-liner: The oxFFFF is a hexadecimal number that translates to 65,535. This is a programmer in-joke. In ‚Äúnormal‚Äù math, numbers are written in base ten. You have ten digits, 0‚Äì9, and when you get to the tenth thing, you add a new position with a ‚Äò1‚Äô digit. Programmers sometimes use hexadecimal (base 16) numbers, which have 16 digits: 0‚Äì9, a, b, c, d, e, and f. The main advantage of this is that you can spell cool, instantly recognizable numbers like ‚Äúdeadbebad‚Äù or ‚Äúeatbeef.‚Äù ‚ÄúMath.round(Math.random() * 0xFFFF)‚Äù means ‚Äúpick a random number between 0 and 65,535.‚Äù Our longest posts are on the order of 1,000-ish paragraphs , so this seems reasonable. ‚Äú.toString(16)‚Äù means ‚Äúformat that number in hexadecimal.‚Äù Coincidentally, ‚Äúad‚Äù is a hexadecimal number. Can you guess what happened next? One of the ad blockers rolled out a rule that blocks anything with the ID ‚Äúad01‚Äù or ‚Äúad02.‚Äù Two out of every 65,536 paragraphs in Medium posts disappeared. The fix we added was simple, but unsettling. Way back at the top of this post, we talked about the rules of CSS precedence. They are not absolutely calibrated towards one party. They follow a set of weighting rules. There‚Äôs an old (slightly inaccurate) joke about it. Q: Who‚Äôs the most important person in CSS? A: The one with the most class. We can escalate by adding an extra ‚Äú.post-article‚Äù class to our selector. Some blocker could still roll out a yet more heavily-weighted rule to override our rule. We‚Äôre hoping they don‚Äôt. I feel frustrated by this dynamic. On the one hand, we have a three-party system that decides how web pages display: the author, the user, and the browser. Each party gets to add their own rules. But the author ‚Äî site owners ‚Äî get most of the blame when things go wrong. Power is distributed; accountability is not. On the other hand, I‚Äôm sympathetic to what the ad blockers are trying to accomplish. We don‚Äôt like the glut of ads and tracking on the web either. The tools that ad blockers have to fight back are blunt, and imperfect. Ad blockers will create collateral damage, and page authors are responsible for dealing with it. But here‚Äôs the catch: this dynamic is good for Medium. We have a user support team responding to these bug reports, and an engineering team fixing them. We can handle this damage. Random blogger Pat running their personal blog likely does not have the time or energy or expertise to handle this. A web ecosystem with ad blockers is more complicated for authors to run and maintain. A more complicated web favors big, centralized players and disfavors small, independent ones. But maybe a web of small independent players is impossible to save. Thanks to the many people who did the hard work of reporting, diagnosing, and fixing the bugs described in this post, most notably Koop , Greg , and one engineer who asked to remain anonymous (and who also suggested the title). Let us know about your favorite bugs on Medium by writing in to [email¬†protected] . Many of the ideas about CSS are from F A T ‚Äôs talk on the history of CSS and the cascade, which you can watch online . Software Engineer. Trying new things @tilt_dev. Formerly @Medium, @Google. Yay Brooklyn. 375 13 Thanks to Xiao Ma . 375 375 13 Ad Blocking CSS Webclient Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2016-05-05"},
{"website": "Medium-Engineering", "title": "medium android tools", "author": ["Daniel McCartney"], "link": "https://medium.engineering/medium-android-tools-f827bb96b8e4", "abstract": "Sign in Daniel McCartney Jun 24, 2015 ¬∑ 2 min read Our new Medium Android app is now released in the wild. We‚Äôre proud of it. But we owe a deep debt to the communities that fashioned the tools that made it possible: From all of us, thank you! source.android.com github.com github.com github.com github.com github.com github.com github.com github.com github.com github.com github.com github.com github.com github.com And here are some 3rd-party tools that also helped to make our app shine: github.com fabric.io developer.android.com Again, thank you! software dev, once lawyer, sometimes scholar - founder @scoutdotfm (ne @SubcastHQ). ex @Medium, @Grubhub, http://dmccartney.com 117 4 117 117 4 Android Open Source Mobile Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2016-05-05"},
{"website": "Medium-Engineering", "title": "five goofy things medium did that break accessibility", "author": ["Nick Santos"], "link": "https://medium.engineering/five-goofy-things-medium-did-that-break-accessibility-3bc804ae818d", "abstract": "Sign in Nick Santos Jun 29, 2015 ¬∑ 4 min read Medium Engineering recently had an accessibility fixit. We found some goofy things! But we‚Äôre trying to do better. We wanted to share some of what we found. 1 DON‚ÄôT: ‚ÄúIntercept‚Äù clicks by creating a transparent overlay over a control. This pattern made the home page completely unreadable on screenreaders. Every stream item had an overlay. The screenreader would try to read the overlay, instead of the content in the item. If you‚Äôre trying to ‚Äútrick‚Äù the browser into doing something non-standard on mouse click, please be mindful of how your trick will look to screenreaders. DO: W e have a web-client guild ! With office hours! If our engineers want guidance on how to support non-standard interactions on click, we ask them to come by and talk to us. With streams, we made the whole item into a link. 2 DON‚ÄôT: Use opacity: 0 to hide elements. Web browsers support many ways to hide elements ‚Äî display: none (‚Äúhide and set width/height to 0‚Äù), visibility: hidden (‚Äúhide but take up the same space‚Äù), and aria-hidden=true (‚Äúscreenreaders should ignore this‚Äù). Many of these are well-supported by modern screenreaders ( See Footnote 1 ). But using opacity: 0 to hide things is well-supported by no one. We used to do this for fade-in/fade-out animations. DO: Whenever you set opacity, also set visibility. We now have LESS mixins .m-fadeIn and .m-fadeOut that help do the fade-in/fade-out use case correctly. They look like this: 3 DON‚ÄôT: Create an <a> tag without an href We used to make anything clickable into an <a> tag, so that it would get all the CSS styles of a link. But screenreaders expect links to ‚Ä¶ link to things. DO: We now have two closure templates for this: a views.ui.links for stuff with hrefs, and a views.ui.buttons isLink for stuff without an href that looks like a link. Anton made an effort to simplify the API and make the two look the same even though they have different HTML structures. 4 DON‚ÄôT: Create a button or link without text. Many of our buttons and links use webfont-based icons. They‚Äôre pretty! But the screenreader doesn‚Äôt know what they are. DO: When using an icon or image, we have a template that requires a text description. The template will do its best to do the right thing, setting ‚Äútitle‚Äù and ‚Äúaria-label.‚Äù ( See Footnote 2 ) 5 DON‚ÄôT: Attach actions to SPAN or DIV tags to listen for user input. We have a framework to listen to actions whether they‚Äôre triggered by a click or a touchscreen or a keyboard. We add an HTML attribute data-action=‚Äúrecommend‚Äù, and the system automatically attaches handlers. But this API was so successful that engineers starting slapping data-action on anything, even random <span> tags. Screenreaders don‚Äôt know about data-action, and won‚Äôt know that this is clickable. DO: Use <button> tags for all clickable controls. We‚Äôve also made some other notable changes the past two weeks that help with accessibility. Headers and Footers ‚Äî Accessibility people are big fans of semantic markup like <header>, <footer>, and <nav>. Koop noticed that our post pages had become a ‚Äúsheer insanity‚Äù of nested containers. He cleaned things up to a much simpler <header><div role=‚Äúmain‚Äù><footer> that‚Äôs much easier to parse. role=‚Äúmenuitem‚Äù ‚Äî Most of our popovers are menus. We‚Äôre still trying to figure out the best template API for doing this well. We added some code to so that if the popover has buttons or links marked role=‚Äúmenuitem‚Äù, the up/down arrow keys will navigate through them. Footnote 1) Fun fact: how to hide elements in a screenreader-friendly way is surprisingly controversial. Some people say that display: none should be enough. Other people say that some versions of JAWS (the most popular screenreader) have a bug and the recommended workaround is to use visibility: hidden and display: none together. Other people say screenreaders can‚Äôt be trusted to interpret CSS, so we should abandon CSS and use DOM attributes for everything. O.o Footnote 2) Fun fact: how to add screenreader-friendly text is also controversial, also because of bugs. Some screenreaders won‚Äôt read ‚Äútitle‚Äù attributes (or only do if you opt-in). Others won‚Äôt read ‚Äúaria-label‚Äù attributes. Others recommend that you create a span with text-indent: -999999px to position the text offscreen. There are many blog posts on this. They mostly make me depressed about the state of accessibility tools. There are still many more things to fix! What do you hate most about Medium‚Äôs web accessibility? What anti-patterns do you wish people would stop doing? Let us know in a response or by emailing [email¬†protected] . Software Engineer. Trying new things @tilt_dev. Formerly @Medium, @Google. Yay Brooklyn. 289 9 Thanks to Kyle Hardgrave . 289 289 9 Accessibility Engineering Webclient Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2016-05-05"},
{"website": "Medium-Engineering", "title": "way we work", "author": ["Medium Engineering"], "link": "https://medium.engineering/way-we-work-ef431646ab17", "abstract": "Sign in Medium Engineering Jul 29, 2015 ¬∑ 7 min read This post is out of date. Read the latest here . This post is a follow-up from the event held at Medium on May 27, 2015. Daryl Koopersmith and Jean Hsu spoke about Holacracy, a system of tools Medium has used to create our organizational structure, and explored some of the challenges our engineering team may face as the needs of the team change with growth. Cathy Edwards gave insight from her experience working with different sized teams throughout her career. Below is a brief re-cap of the event and main points the panel discussed. Holacr a cy is a toolset for an organization and its employees. The roles in the organization are all defined, and each role has certain accountabilities and authority. This means that the people at the ‚Äútop‚Äù do not have all the authority ‚Äî it‚Äôs distributed even though it‚Äôs hierarchical. People can also hold multiple roles, and everyone has access to view the roles of any employee. To learn more about the system‚Äôs general principles, check out the Holacracy publication on Medium. Holacracy embraces and expects change, so Jean talked a bit about how our own structure has shifted to support Medium‚Äôs growing engineering organization. The team started off with a pretty basic structure with engineers working in small cross-functional teams ‚Äî engineers, designers, PMs, etc ‚Äî called product initiatives (represented in Holacracy as circles). As the team grew, there was a need for a more permanent, defined space for tracking engineering projects, more explicit support structures and room for engineers to discuss engineering-related concerns. To meet this need, the Engineering circle was proposed and created. Within that circle, there exists the Proto Engineer role, which all newly hired engineers fill, the Engineer role, and Tech Lead role. Each role has explicit accountabilities to detail what is expected of anyone filling that role. Most engineers have roles in both the core Engineering circle as well as a product circle. However, it‚Äôs possible that one engineer might hold many roles, more similar to the current state of Tech Ops‚Äî a circle within Engineering that has four engineers filling about a million roles. For a small circle that is responsible for a lot of important parts of the engineering team, they end up with a somewhat comical amount of roles ‚Äî and impressively execute each role well. Around the time the engineering team was ~20 people, it became clear that the lead engineer, Dan, wasn‚Äôt able to meet one-on-one with everyone regularly (more than once every few months). With people shifting in and out of roles and having various Leads in their product circles, it became clear the team needed a scaleable way for every engineer to have a longstanding relationship with someone to talk to about personal growth, career trajectory, and gnarly situations in day-to-day work. The team adopted the role of ‚ÄúGroup Lead,‚Äù which we consider the ‚Äúpeople side‚Äù of engineering management. This person is explicitly not your Tech Lead (who provide the ‚Äútechnical side‚Äù of engineering management) or Initiative Lead (our version of a PM), and is someone that an engineer meets with regularly one-on-one. The biggest difference to a traditional structure is that you don‚Äôt just occupy one role that takes you down a specific one-way path. People and roles are separate, so you can have a sort of a ‚Äúchoose-your-own-adventure‚Äù career. For example, Jean is on the engineering team at Medium, but she holds a variety of roles including Group Lead for 11 engineers, Lead of the Node Services Guild, and Engineer on the Publications Initiative. She also help set up the onboarding and interviewing training for the engineering circle, as well as some recruiting and outreach. Having these roles assigned to Jean explicitly is great for her because these responsibilities are important but are often overlooked or seen as detracting from an engineer‚Äôs work. Jean appreciates the explicit structure and doesn‚Äôt feel like she‚Äôs had to choose whether or not she wants to go down a 100% management track, which she thinks would have happened at a lot of other companies. She can pick and choose what she wants to focus on, and that can change even month to month. Sometimes she might want to focus on organizational leadership and a few months later, she‚Äôll want to work on or lead an infrastructure project to challenge herself technically. Koop, an engineer that contributes to the Writing and Reacting initiative and currently holds the Web Client Guild Lead role, spoke about the different roles he‚Äôs held during his time at Medium. Each person at Medium occupies a unique slice of the organization, which is reflected through their roles. Like most of our application engineers, when Koop joined Medium in March of 2013, he was given two roles: one as an Engineer, and another as a contributor to a product initiative. As the engineering team grew, the team sensed the need to have caretakers responsible for the core areas of our codebase. To fill this need, the engineering team introduced the role of Domain Expert at the end of 2013. Koop was one of the several engineers that stepped into the role, with a focus on maintaining Medium‚Äôs web framework. Over time, he‚Äôs held many other different roles in the engineering circle, while also holding his Engineering role throughout his tenure. Not everyone has to hold multiple roles. Some people have one or two roles and focus their efforts, while others are spread across more roles and accountabilities. At times, it can be difficult (or even impossible) to satisfy all of your accountabilities in a given moment. Additionally, everyone in the company has the authority to prioritize their work across roles. These priorities might change, so it‚Äôs always important to communicate what you‚Äôre focusing on to your coworkers. Every person has the power to propose changes to how we work. For example, at the end of 2014, engineering found that the Domain Expert role had become somewhat inaccurate. In reality, as the organization grew, a single person did not oversee an area of the codebase. Instead, a group of engineers ‚Äî Domain Experts and otherwise ‚Äî collaborated to maintain and improve areas within Medium‚Äôs codebase. In a meeting, Koop proposed to evolve the role of Domain Expert into several ‚ÄúGuilds‚Äù to reflect how the engineering team was functioning. We now have four guilds: Web Client, iOS, Node Services, and Data. Each guild is focused on improving their discipline, establishing best practices, and educating the rest of the team. Guilds prioritize their work by assessing the needs of the team. Some choose to focus on developer productivity, while others have focused on education and best practices. Our current engineering structure is the result of cumulative changes proposed by Medium‚Äôs engineers. Most organizational structures are rigid, and aren‚Äôt designed to change and grow. This can often lead to massive, disruptive reorganizations. Instead, Holacracy gives us the tools to continually refine. We‚Äôve tweaked and honed our organization to fit our needs, and will continue to do so as the company grows. We don‚Äôt have it all figured out. Holacracy gives us a set of tools to use to change our organization. We‚Äôre going to face more challenges as we grow. What does a comprehensive leveling system look like? How can we facilitate frequent, useful peer feedback? Most companies face these problems (regardless of whether they actually attempt to address them). We want to learn from their success and failures. We don‚Äôt want to reinvent the wheel. Jumping off on Koop‚Äôs point that we haven‚Äôt solved everything, we invited one of our engineering advisors, Cathy Edwards, to provide some insight from her experience working on and growing engineering teams. Cathy pointed out that it‚Äôs very trendy in the Valley at the moment to promote how little management your company has, or how you have a flat structure with no managers. She actually believes good management is critical to a company‚Äôs success. Good management helps minimize politics, ensures employee happiness and growth, and provides the right environment to maximize the productivity of the entire team. However, most people promoted to management positions are never told exactly what their jobs are, or trained, so they end up not delivering on this promise. One of the things Cathy appreciates about Holacracy is how it makes many of these management functions explicit, and makes it clear who is responsible for figuring them out. While certainly not perfect, organizations using Holacracy don‚Äôt have the single point of failure that hierarchical management structures have (as embodied by the famous Peter Principle ). Allowing the whole team to contribute to, and hold each other accountable for, making good decisions about company structure and process helps ensure that they work for everyone, and the earlier part of this post has been a great example of how this has worked at Medium. Medium launched the Way We Work series in May 2015 in order to better communicate how the engineering team at Medium works. With regular events, this series creates a space for a community of engineers and designers to come together to talk about topics covering both cultural and technical aspects of engineering teams. Interested in future events? Email [email¬†protected] to get on our events mailing list. We are the @Medium engineering team 105 1 Thanks to Dan Pupius . 105 105 1 Holacracy Management Events And Press Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2016-05-20"},
{"website": "Medium-Engineering", "title": "the browser that fixed the bug", "author": ["Anton"], "link": "https://medium.engineering/the-browser-that-fixed-the-bug-a4b7816c9880", "abstract": "Sign in Anton Jun 30, 2015 ¬∑ 1 min read ‚ÄúIt seems we‚Äôre back at square one.‚Äù This was the conclusion of my project to enable editing for Microsoft Internet Explorer 11 users. A week earlier we published a post explaining why Internet Explorer had to be a Tier 2 browser even though we really wanted to level it up. The problem was with the browser adding a grey border to any child of a content-editable element that was responsible for arranging and sizing its own contents. That meant many elements of our editor ‚Äî such as image grids or pull quotes ‚Äî were triggering that border on a regular basis. To work around the issue we would have to move all sizing to the outside of our content-editable element. That meant that every section would have to become its own content-editable and its own little editor. That would require us to almost completely re-architect and re-write the Medium editor. It seemed like we were back at square one. At the same time, in a different part of the west coast, our comrades at Microsoft were hard at work solving the exact same issue. Prompted by our blog post they were changing their content-editable implementation to match that of Chrome and Firefox. It was a breaking change for them and they probably had to move mountains but they did it . As of today, Edge , Microsoft‚Äôs latest browser, is officially a Tier 1 browser within Medium. I cannot be more excited. Trust & Security Engineering at Medium. For issues with your account, email [email¬†protected] . 60 1 Anton 60 60 1 Browsers Microsoft Webclient Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2016-05-05"},
{"website": "Medium-Engineering", "title": "perfectly suitable data models and apis are an illusion", "author": ["Xiao Ma"], "link": "https://medium.engineering/perfectly-suitable-data-models-and-apis-are-an-illusion-6219f1751b6b", "abstract": "Sign in Xiao Ma Jul 3, 2015 ¬∑ 3 min read Someone will say MongoDB or PostgreSQL or Riak or DB du jour is the best tool for the job, usually followed by some folksy platitude about how perfectly it suits a problem domain. My issue with this approach is that it ignores two realities of operational engineering: performance and knowledge. ‚Ä¶‚Ä¶ A good tool can be phenomenal but it won‚Äôt solve a problem for you. Patient, methodical software engineering, ultimately, is what solves the problem. On \"Will this solve my problem?\" thinking Dhanji Prasanna wrote a thought-provoking piece about choosing databases. He argues that simply considering whether a database perfectly suits a problem domain is not enough, one should also think about two realities of operational engineering: performance and knowledge . I couldn‚Äôt agree more with his thesis. But I‚Äôm also concerned at a deeper level: How do you determine if a database perfectly suits a problem domain in the first place? Usually we answer that q u estion from two perspectives: data models and APIs. Inspired by the ‚Äúdo one thing and do it extremely well‚Äù mentality, one may think that the more specifically a database‚Äôs data model and API fit a problem domain, the better a solution it is. In reality, this may not actually be true. Being overly optimistic about data models and APIs is dangerous, and it is largely related to the NoSQL phenomenon. Back in the world of relational databases, data stores try to stand out with better performance and reliability. There was not much to think about data models and APIs ‚Äî which are basically all SQL with small variations. You don‚Äôt look for a database to solve your specific problem; instead, you fit your specific problem to SQL. In the NoSQL world, things turned the other way around. We tend to invent one (or sometimes even many) databases for each unique type of data model and offer APIs that fit perfectly to that data model. Rich and flexible options create an over-optimistic illusion on how perfect a database could fit the requirement. It makes us overlook the real needs and the limitations of the solution, and often leads to premature adoption. Sometimes APIs create illusions too. What really matters are access patterns underneath the API. You can always wrap a not-so-perfect API to make it easier to use, but you can‚Äôt dramatically change the access patterns that a database supports. Let‚Äôs take graph databases as an example. Graph databases are invented to traverse graphs more efficiently than relational databases. They model data as nodes, edges (A.K.A. relations), and properties attached to nodes and edges. They also provide descriptive APIs for graph traversal. Does it mean that if you have graph-like data and traversal-like access patterns, you should use a graph database? Counter-intuitively, and as with many data modeling questions, the answer is: ‚Äúit depends.‚Äù Graph databases tackle certain problems really well, such as traversing through paths with many nodes or solving some of the graph algorithms. For example, the collaboration platform Mix by FiftyThree allows users to share their drawings and draw new things on top of others‚Äô. When they show a tree of drawings or replay the evolution of a given piece from its root, a graph database is a better option. If these relations are stored in RDS, it would require multiple sequential queries. But if your access patterns are mostly just traversal through two or three edges on a path, relational databases may perform just as well. For example, suggesting friends of friends to follow on a social network or fetching content that are recommended by friends. These problems basically map to joining two or three tables in relational databases, which modern relational databases are well optimized for. Even if you indeed have graph-like data and traversal-like access patterns, another important perspective that can‚Äôt be ignored is indexing . Indexing support is most NoSQL databases‚Äô weakness. Without proper indexing, even if the data is organized as graphs, you may not get expected performance benefits. For example, if you want to query relations by certain conditions, but the graph database does not index those relations, it essentially has to get all the relations and then filter them. That could be very slow if you have ‚Äúsuper nodes‚Äù with a large number of relations. To conclude, when you look for a database solution for a specific problem domain, the first thing should be to carefully examine the data model, access pattern and indexing requirements. Don‚Äôt get over-optimistic if there seem to be databases that are exactly designed to solve your problem. Chief Architect @Medium. Serving Engineers. Teaching Machines. The ultimate goal of tech is to help us live better. Built @PatternInsight PhD @IllinoisCS UCSD 94 Thanks to Jamie Talbot and Bobbie Johnson . 94 94 Database NoSQL Infrastructure Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2016-05-05"},
{"website": "Medium-Engineering", "title": "why passwords suck", "author": ["Jamie Talbot"], "link": "https://medium.engineering/why-passwords-suck-d1d1f38c1bb4", "abstract": "Sign in Jamie Talbot Jun 30, 2015 ¬∑ 4 min read We launched our passwordless login system on June 29, 2015. This was originally published to Hatch, our internal version of Medium, on April 1, 2015. I wrote it to illustrate to my colleagues why I didn‚Äôt consider passwords to be a good option for securing users when we implemented our login system. See Hatching Inside Medium for context on this publication. According to [my colleague], 50% of all support tickets at [large company] were related to passwords. When we implement native login, we should not use passwords. I‚Äôll stipulate up-front that s ome people use 1Password and generate a 50 character random password for each site, and never re-use passwords, and never copy-paste them anywhere for friends, and never write them down on a post-it note. Those people are probably safe with passwords. Are you one of those people? You should be one of these people. In the real world, people are not paranoid enough to do this. It is our job to provide a secure platform for our users. Passwords, as used by the general public, are insecure. We should design a system that has less opportunity for users to sabotage themselves. The value of cracking a password is very high. Passwords are long-lived, so once you have access you typically have access for a long time. Password based systems also often allow you to login without notifying the account owner, so misuse may go undetected for a long time. Here‚Äôs a scenario of how things might escalate, illustrated by two characters, Andy and Ev . Andy has a Medium account, and Ev is the evildoer who wants to access Andy‚Äôs account. All the actions of Andy are absolutely things that happen in the real world all the time . We start off with Medium allowing any password to be used. Andy chooses ‚Äúpassword‚Äù, or ‚Äú12345678‚Äù because it‚Äôs easy to remember . Ev just attempts to log in with the most popular passwords, and is successful, probably in under five minutes, without any special hardware or software. Engineering mitigation: we build ‚Äúmax password attempts‚Äù functionality, which annoys Andy who genuinely forgets his password sometimes, and causes stress to User Happiness. Engineering mitigation: we require some complexity in our passwords. One uppercase, one lowercase, one number, one punctuation etc., that is not in the dictionary. Andy chooses ‚ÄúM0nkey!‚Äù . (That‚Äôs a zero, not an ‚ÄúO‚Äù.) Ev does a modified dictionary attack with a botnet and probably logs in within a day or two, or else continually locks Andy out of his account by repeated failure. Engineering mitigation: we add ‚Äúdictionary-like‚Äù protection to prevent passwords like the above. Users hate it and complain to User Happiness. Engineering mitigation: we build a ‚Äúpassword-strength‚Äù meter to prevent passwords like the above. Users barely understand it, and are satisfied with a medium-strength password. Because Medium requires a gobbleydegook password, Andy writes his password down on a post-it. Ev walks by Andy‚Äôs desk, laughs maniacally , and logs in. Andy loses his post-it and is locked out of his account. Engineering mitigation: we add a ‚Äúforgot password‚Äù mechanism. Because Andy needs to log in from multiple places, he emails his password to himself. With a forgot password system, or users emailing themselves their own password, Medium can now only be as secure as the user‚Äôs email system. This is pretty much the upper limit for how secure we can make a password-only based system. Andy resets his password. He chooses the same one as for Slack, which also requires ‚Äúcomplicated‚Äù passwords. Ev hacks Slack , and with a little effort decrypts the encrypted password associated with Andy‚Äôs email address. Ev reuses that on Medium, and logs in. Some time passes. AMD releases a brand new GPU, which as a side-effect allows 1Password agilekeychains to be cracked . Everything is terrible and nothing is secure. Passwords are terrible. We can do all sorts of crappy mitigation schemes, which offer some convenience, but will require maintenance, and will be a user support headache. And ultimately, because our users are fallible, we have to offer the forgotten password mechanism, which puts an upper bar on how secure a user can ever be. Entering passwords is particularly terrible on mobile. It‚Äôs useful, and more secure ‚Äî the two factors are ‚Äúsomething you know‚Äù, and ‚Äúsomething you have‚Äù. However, many users won‚Äôt turn it on, plus if your ‚Äúsomething you have‚Äù ‚Äî typically a mobile device ‚Äî is compromised, a malicious user can in most cases reset the ‚Äúsomething you know‚Äù. Put simply, if someone steals your cellphone, they can probably do whatever they want, regardless of security measures we take. Therefore the ‚Äúsomething you know‚Äù part is kind of irrelevant. Ex-gaijin, kangaroo-loving software simian from Merrie England, building @Mailchimp and @Pinian. Formerly @Medium and @StumbleUpon. 113 6 Thanks to Dan Pupius and Sarah . ‚Ä¶e wanted to make our sign in process as secure and simple to use as possible, across all platforms. Passwords are neither secure nor simple. They‚Äôre hard to remember or easy to guess, everyone re-uses them (even though they know they should‚Ä¶ Jamie Talbot 113 113 6 Authentication Engineering Inside Medium Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2016-08-15"},
{"website": "Medium-Engineering", "title": "the helping mindset", "author": ["Xiao Ma"], "link": "https://medium.engineering/the-helping-mindset-9b0f08049ee2", "abstract": "Sign in Xiao Ma May 21, 2015 ¬∑ 2 min read One of a tech lead‚Äôs accountabilities is to help the team make technical decisions, but ‚Äúhelping‚Äù can be done in very different ways that lead to very different consequences. Let‚Äôs compare the two ways to help. Tech Lead : What‚Äôs up folks? Team Member : We are discussing how to do X, and ‚Ä¶ Tech Lead : Oh, that‚Äôs easy. I have done it before. I know exactly what you need to do ‚Äî A, B and C. I can actually help you with B. Team Member : Ok‚Ä¶ Thanks! The tech lead w alks away feeling proud, because they know about the solution, and satisfied, because they helped the team. Tech Lead : What‚Äôs up folks? Team Member : We are discussing how to do X. Tech Lead : Oh, interesting. What do you think we should do? Team Member : We have two options, but we can‚Äôt decide which one to use. Maybe you can help us? Tech Lead : Cool! Sure, I‚Äôm happy to help. Team Member : (describes the two approaches) Tech Lead : They‚Äôre both reasonable options. What are the risks that make you can‚Äôt decide which one to use? Team Member : (describes the concerns) Tech Lead : Yeah, that made the first option not work for corner cases. I like your second option more. It is simple and easy to implement. It doesn‚Äôt scale for the long run, but we can re-think about it once the scaling problem comes. Team Member : Yeah, that makes sense. What if the scaling problem comes earlier than we expect? Tech Lead : We could use the data store Y which has all the data as well. It would work but it requires much more work. Team Member : Oh, we didn‚Äôt even know we have that. Let‚Äôs go with option two then. Thanks! The team members walk away feeling proud of themselves, because the solution is their idea. They grow faster by actively thinking about the problem not just implementing the solution. They will be more likely to solve future problems independently. The intent of the tech lead in both scenarios is completely meritorious ‚Äî the desire to help others, but the results are very different. Trying to make every decision by yourself may seem to get things done a little quicker sometimes, but it doesn‚Äôt scale and it does more harm than good in the long run. The thing a tech leader needs to worry about the least is to prove whether they are qualified. Sharing knowledge and helping team members be able to make good technical decisions is more important than making technical decisions. Good tech leads trust team members, help and empower them. An old Chinese saying applies here: Êéà‰∫∫‰ª•È≠ö‰∏çÂ¶ÇÊéà‰∫∫‰ª•ÊºÅ . It means ‚Äúgiving a person fish is not as good as teaching a person how to fish‚Äù. Chief Architect @Medium. Serving Engineers. Teaching Machines. The ultimate goal of tech is to help us live better. Built @PatternInsight PhD @IllinoisCS UCSD 347 Thanks to Jean Hsu and Bobbie Johnson . 347 347 Values Stories from the team building Medium. About Help Legal Get the Medium app", "date": "2016-04-05"}
]