[
{"website": "Mallow-Tech", "title": "CSS – Inline, Internal and External Styling", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2015/12/css-inline-internal-and-external-styling/", "abstract": "C ascading S tyle S heets is mainly used for solving the problem of adding styles to HTML multiple times. There are three types of styles, Inline CSS The style attribute should be placed inside of any relevant tag and you can apply any CSS property. But you have to apply the styles individually to all the relevant tags, which makes it harder for re-use. Also, It’s impossible to use style pseudo-elements(hover, visited,active, etc.,) and classes with inline styles. <p style=“color: blue; border: 1px solid blue;” >This is a paragraph.</p> Internal CSS This can be used in a single document which has a unique style. You can define any style property in <style> tag in the head section. It has more advantages over inline styles, but still you have to use individual style tags in all pages. <head> <style> p { color: blue; border: 1px solid blue; } </style> </head> <body> <p>This is a paragraph</p> </body> External CSS : You can use any styles in a single separate file linked to any no. of pages. It is ideal choice for many web developers. Because it is highly re-usable, your CSS and HTML contents will be crystal clear as both are in separate files, It is also search engine friendly. – – – –  styles.css – – – – p { color: blue; border: 1px solid blue; } – – – –  index.html – – – – <head> <link href=“styles.css”> </head> <body> <p>This is a paragraph</p> </body> To know more about the advantages and disadvantages of the different CSS styles, visit the below URL: Inline vs Internal vs External – CSS – https://vineetgupta22.wordpress.com/2011/07/09/inline-vs-internal-vs-external-css/ Vadivel, Design Team Co-oridinator, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2015-12-18"},
{"website": "Mallow-Tech", "title": "Differences between A, CNAME, ALIAS and URL records", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/05/differences-between-a-cname-alias-and-url-records/", "abstract": "A CNAME, ALIAS and URL records are all possible solutions to point a host name (name hereafter) to your site. However, they have some small differences that affect how the client will reach your site. Before going further into the details, it’s important to know that A and CNAME records are standard DNS records, whilst ALIAS and URL records are custom DNS records provided by DNSimple’s DNS hosting. Both of them are translated internally into A records to ensure compatibility with the DNS protocol. A (Address) record (IPv4) This type of record allows associating a domain name or subdomain with an IP address (32-bit). Sample configuration for A record type IP Type Host Name 11.22.33.44 A example.com AAAA record (IPv6) The AAAA record is similar to the A record, but it allows you to point a domain to a IPv6 address (128-bit). This will configure in the same way as A record is configured. IP Type Host Name 1111:2222:3333:4444:5555 AAA example.com CNAME record This record specifies an alias of another domain name, canonical name. CNAME record will point your domain or subdomain to the IP address of the destination hostname. If the IP of the destination hostname changes, you won’t need to change your DNS records as the CNAME will have the same IP. Sample configuration IP Type Host Name 11.22.33.44 A example.com Host Type Name example.com CNAME mysite.com Please don’t set up CNAME for naked domain (@ hostname), since it may affect the operation of the domain’s MX records and, consequently, the email service. Thus, in most cases you will need to create CNAME record for WWW (or other subdomain) and URL redirect for @ that will point to http://www.yourdomain.tld/ NS record A NS record or name server record tells recursive name servers which name servers are authoritative for a zone.  Recursive name servers look at the NS records to work out who to ask next when resolving a name. This type of record allows you to delegate a subdomain of your domain to a name server, not associated with a domain itself. This is needed when your subdomain is hosted separately from a domain name. Name Type Host Name ns1.myhisting.com NS blog SRV record The SRV (Service) record is a Domain Name System (DNS) resource record that is used to identify computers that host specific services. SRV records allow you to define the location, i.e. the hostname and port number, of servers for specified services. Name Type Host Name Priority Port Weight _myservice._myprotocod SRV example.com 0 8080 5 Name should in the format of _service._protocol TXT record A TXT record is a type of DNS record that provides text information to sources outside your domain. The text can be either human or machine-readable and can be used for a variety of purposes. You can input any text for descriptive purposes. TXT records are often used to store SPF (Sender Policy Framework) records and to prevent people from receiving fake emails. Sometimes these records need to be set up for verification purposes, for example, some Google services require it. Name Type Text Type Text myname TXT mysite-verification=af4323-jkg7823-dfpq83h9c URL Redirect ( Unmasked Forwarding) URL Redirect is used to redirect a domain to another URL/domain name. When users type your domain in the URL bar, they are redirected to any specific web page, for example, http://maps.google.com/ or http://en.wikipedia.org/wiki/Main_Page . In this case, the destination URL is displayed for them in the address bar instead of yourdomain.tld . Host Name Type Redirect URL Forwarding Type example.com URL Redirect www.google.com unmasked URL Frame (Masked Forwarding) The URL Frame is similar to URL Redirect except that instead of redirecting the client to your web page, the web page is displayed in a frame. With this method the client’s browser will display your domain name (for example: www.yourdomain.tld ) while they are using your site and not the actual URL to your page. Host Name Type Redirect URL Forwarding Type example.com URL Redirect www.google.com masked It looks cool, but is have some cons: – It’s bad for SEO – Not all websites allow masking itself URL Redirect (301) URL Redirect (301) (sometimes known as Permanent Redirect) should be used when you wish to permanently redirect your domain to some specific URL/domain name. In this case search engines are notified of a permanent address change and the values of internal links are transferred to the new site. Host Name Type Redirect URL Forwarding Type example.com URL Redirect www.google.com Permanent(301) When should you use this – You’ve moved your site to a new domain – When you merge two websites into one and you want to redirect the user request of the outdated URL to the correct page MX record A mail exchanger record (MX record) is used to direct email to a particular mail server. Like a CNAME, MX entries must point to a host name and should not be pointed directly to an IP address. You also need to set priority for your MX record in Priority column. The lowest priority email server is the first destination for email. If the lowest priority email server is unavailable, mail will be sent to the higher priority email servers. IP Type Host Name 11.22.33.44 A example.com Host Name Type Name Priority example.com MX mx.mysite.com 10 MXE record MXE (Mail Easy) is used to forward mail to an IP address of a mail server. Using a mail record allows you to specify the address of your mail server. When you use a mail record, you must use an IP address in the address field. (Experts: Creating a mail record actually creates both the MX and the A record in DNS. Also, when using multiple mail servers, a preference value of 10 is used on all entries). IP Type 11.22.33.44 MXE Prakash & Surender, ROR Developers, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-05-30"},
{"website": "Mallow-Tech", "title": "From Eclipse to Android Studio for Android app development", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2015/12/from-eclipse-to-android-studio-why/", "abstract": "In this blog, we share our experience in moving towards the new Android Studio from the previous platform of Eclipse. At the outset, we used Eclipse to develop android apps. There was a downside while debugging and designing the layouts. To resolve this, we needed to restart Eclipse often. We faced an issue with emulators too. In Eclipse we need to integrate ADT tools manually whereas in Android studio it is integrated. We started using Android Studio IDE for Android application development now. The drawbacks in Eclipse has been overcome in Android Studio. We have listed below the optimal features of Android Studio which makes it better over Eclipse. Optimal features of Android Studio. – Android Studio provides Gradle-based (maven) build support. – Using Gradle which is one of the good features to have control over the build, create different application flavours, different signing configurations and so on. – Lint tools to catch performance, usability and version compatibility. – It provides support for building apps for Android wearables , Android TV. Android Auto and Google glass along with phones and tablets. – It has built-in support for google cloud platform, enabling integration with Google cloud messaging and app engine. – Easy customisation on project code refactoring and quick fixing. – Helps to improve the Performance like working with eclipse difficult to debugging and designing layouts. – Helps in performance analysis tools.(Rendering, battery, compute analysis tool). – Supports in build variants (Development and production APIs) and multiple APK generations. – Start projects using template code for patterns such as navigation drawer and view pages, and even import Google code samples from GitHub. – Rich layout and colour preview editor with support for theme editing. – Having Memory performance monitor to control the memory. – Dynamic Layout Preview enabling users to see and edit via drag&drop how their mobile app appears on multiple devices and across API versions. – Code Completion – the most important part is when the IDE tells me the member names of an object. In general, I found that the code completion is better on Android Studio than Eclipse, which seems to get a little confused at times and doesn’t always give accurate results. – It supports Android’s C/C++ NDK – Autocomplete feature: Compared with eclipse more user-friendly and auto-complete text edit. – Layout view – In the layout view, you have the option to view both the actual layout and the XML at the same time, while in Eclipse you must choose between the two tabs. – Changes in project structure and creating new files using templates. Jayamurugan, Android Team, Mallow Technologies . Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2015-12-11"},
{"website": "Mallow-Tech", "title": "An encounter with UXPin", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2015/12/an-encounter-with-uxpin/", "abstract": "UXPin is an online UX tool to convert your ideas into virtual forms of wireframes, mockup, prototype, etc., We had tried over dozen of wireframe tools, whether it is online or offline, but nothing comes close to UXPin experience in terms of usability and flexibility, which is important to convert your blank ideas into virtual forms. We had a short stint with UXPin 1.5 years back. At that time we wanted to make a prototype for our product which we dropped, due to resource concern. So we could use(subscribed) it only for couple of months and we didn’t have enough exposure on the tool. A couple of months back, we were informed by our business analysts team, that we’ve got a very good high profile project. After all the ideas and requirements of the project have been discussed, we decided to confirm the workflow of the project, to avoid the issues and mismatch during the development phase. To do so we required a wireframe tool. It is after an extensive search we decided to have another trial with UXPin. The other reason that we wanted to try UXPin is the collaboration feature which we have never tried before, because 4 to 5 of our team had to work simultaneously. I must say that the collaboration has helped a lot in this process. Since we used a different account than what we tried earlier, we had a trial period for 7 days which is considerably not enough time to try any product. Also we decided to try the pro features which includes presentation mode, Photoshop and Sketch imports, etc., The 7 days trial period was about to expire and we hadn’t completed that week’s tasks, as there were some changes in the requirement. So we had a discussion with the UXPin support team about the situation and even planned to subscribe the pro plan but without collaboration because their pricing structure is not suitable for us. The support team was gracious enough to extend our trial period to 30 days, plus adding 10 more days in the end, for another issue :). And thanks to them we ended up finishing the wireframe within those extended days. And the Client was very satisfied with the it. We had almost a month time to explore the tool and I must say that it has been a good experience. The one downside, is their pricing, it may be suitable for many clients but not to us. Because we don’t use the tool regularly, we use it only when it is required. Their pricing model is suitable for those who use it always. It would be good if they provide options to the users for moving projects from one account to another account and an option to start / stop the subscription when required. You have to contact the support team to do the mentioned process, who were really gracious in helping us. For those who want to convert their quick ideas into wireframes and prototypes, UXPin is the solution. The next time, I’ll write you my experiences and opinions about more design related topics like tools, work process, etc., Vadivel, Design Team , Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2015-12-11"},
{"website": "Mallow-Tech", "title": "3D Touch(Quick Actions) in iOS", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2015/12/3d-touchquick-actions-in-ios/", "abstract": "3D Touch is a simple and useful feature released in iOS 9. For now it is supported in iPhone 6s and 6s+. Also some of the iOS default apps like Calendar, Message, Photos, Safari etc., use this feature. The user can turn ON/OFF this feature through iOS default settings. 3D Touch ON/OFF: To ON/OFF the 3D Touch, open Settings then go to General > Accessibility > 3D Touch . Quick Actions Usage: Quick Actions let you do the things you do, most often faster and in fewer steps. For accessing the Quick Actions you have to force touch the app icon in home screen. It will pop up a menu with a list of shortcuts. By choosing any of the shortcuts, we can directly navigate to the corresponding screen in the app. What you can do with Quick Actions? 1. Shooting video, selfies and more Press the Camera icon on the Home screen, and you can immediately snap a selfie, shoot a video, or even go straight into a  camera mode, such as slo-mo. 2. Reading list, Bookmarks, Private Tab and much more Press the Safari icon on the Home Screen and you can choose any of the four options i)Show Reading List, ii)Show Book Marks iii) New Private Tab and iv) New Tab listed from Safari icon. By choosing the option “New Tab”, it directly navigate to the new tab page. How can a developer implement the Quick Actions feature in his own app? From Xcode 7 you can develop the Quick Actions feature for your own apps. You cannot test the Quick Actions feature directly in simulator. For that you have to do some tricks. I’ve explained this in detail below in the section “How to test Quick Actions?” Step 1: Create a new iOS application. Step 2: In the app info.plist add the key “UIApplicationShortcutItems” as NSArray. In the array you have to add a item as NSDictionary type. Step 3: In the NSDictionary we have to add 2 fields as mandatory field: i) UIApplicationShortcutItemType —> We have to specify the shortcut item type. By using this type we can handle our quick actions inside our app. ii) UIApplicationShortcutItemTitle —> This is the title of the option, listed in home screen icon. Step 4: Also we can specify some of the additional types in NSDictionary like UIApplicationShortcutItemSubtitle, UIApplicationShortcutItemIconType, UIApplicationShortcutItemIconFile and UIApplicationShortcutItemUserInfo. Each of the fields have some specific functions. For detailed implementation process of UIApplicationShortcutItems check out this link iPhoneOSKeys.html Refer the below image, on how to add UIApplicationShortcutItems in the app info.plist. Also I have attached a source code image for UIApplicationShortcutItems key. Note: We can also add the UIApplicationShortcutItems dynamically. You can refer this in IOS default Message app. First option is to create a new message and other three options are dynamically added. The other three options are the latest three message users. Testing Quick Actions: In simulator we cannot test this feature and as an individual developer, we cannot always buy the latest device for development process. In this situation we cannot debug/test the Quick Actions feature fully. For testing the Quick Actions in simulator, we have to do some tweaks. For tweaking the Quick Actions feature in simulator, download the “ SBShortcutMenuSimulator ” from Github. Follow the steps given in the Github page. In case it doesn’t work, then reset your simulator and try again. It will work as expected. Note: When testing the 3D touch in devices, make sure that the 3D touch option is enabled in iOS general settings. Yogesh, iOS Team Lead, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2015-12-11"},
{"website": "Mallow-Tech", "title": "The All New PHP7", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2015/12/the-all-new-php7/", "abstract": "The Language which Powers 80% of the web doubles its speed in performance “PHP 7 is a landmark achievement in the history of PHP and one of the most exciting moments in my career as a web developer. When the language that powers the majority of the web doubles in speed, it’s something to get excited about.” – Taylor Otwell, Laravel Founder PHP 7 is released with numerous improvements and copious features. In this blog I have given a gist of the newly added features. 1. Return type declarations We can now give return type declaration in PHP7 Illustration: <?php function sum($a, $b): float { return $a + $b; } // Note it returns a float var_dump(sum(1, 2)); ?> Output: float(3) 2. Null coalesce operator Null coalesce operator “??” is added which is similar to isset(). It returns the first operand if it exists and is not NULL otherwise it returns the second operand. One additional feature is that this operator can also used as a chain. Illustration: <?php $usertype = $_GET[‘usertype’] ?? ‘Member’; //equivalent to $usertype = isset($_GET[‘usertype’]) ? $_GET[‘usertype’] : ‘Member’; // chain $usertype = $_GET[‘usertype’] ?? $_POST[‘usertype’] ?? ‘Member’; ?> 3. Scalar type declarations The scalar type of declaration which can help us to use declare and use n number of variables during runtime.  It comes  in two flavours  coercive and strict Illustration: function sum(int …$ints) { return array_sum($ints); } var_dump(sum(8, ‘1’, 2.1)); Output: 11 4. Constant arrays We can define array constants now as below Illustration: <?php define(‘USERTYPE’, [ ‘Member’, ‘PortalAdmin’, ‘ChapterAdmin’ ]); echo USERTYPE[1]; ?> Output: PortalAdmin 5. Integer division PHP 7 has introduced new function intdiv() to perform integer division Illustration: <?php var_dump(intdiv(10, 3)); ?> Output: int(3) 6. Filtered PHP 7 has a also concentrated to provide better security when unserializing objects on untrusted data which prevents code injections. Now developers can whitelist classes. Illustration: <?php // converts all objects into incomplete classes $data = unserialize($foo, [“classes_allowed” => false]); // converts Class1 and Class2 as complete classes and all other as incomplete $data = unserialize($foo, [“classes_allowed” => [“Class1″, “Class2”]]); // Converts all objects into completed classes $data = unserialize($foo, [“classes_allowed” => true]); ?> Try this and get started with the new features, more flavours of PHP will be added in the next blog. Vijayanand, PHP Team Lead, Mallow Technologies Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2015-12-10"},
{"website": "Mallow-Tech", "title": "Envisaging my future with Mallow Tech", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2015/12/envisaging-my-future-with-mallow-tech-2/", "abstract": "Mallow Tech is worlds apart from my previous organisation. I am experiencing a change over here: say, Windows to Mac, Quarterly events, flexible hours, indoor games and much more. I stepped into this company with fear, anxiety and with full of doubts. Day-by-day I feel that I am coming out of it with the help of my peers. And, thereon I have given support for learning new things. I know how to use mobile apps, how to browse but I am not cognizant of how it works. But now, I feel that I am lucky for having the live opportunity to explore and gain knowledge on this. I am faced with exciting new challenges every day, and I am supported to overcome the barriers. So I am able to learn new things in different verticals. It is been a month now and now I realise i will have a flourishing career with Mallow tech when I give my best. Nancy, Junior Business Analyst, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2015-12-10"},
{"website": "Mallow-Tech", "title": "Believe in Yourself", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2015/12/believe-in-yourself/", "abstract": "In today’s world we roll fast and quick. We run all day- for the entire 24 hrs, the whole week, month and year. But is our run meaningful, with conscious?  No!!!!  To be exact, not at all times. Most of us feel energetic at good times and drained at bad times. We need to stimulate our energy and mind at all times. Just try to read your mind and listen to the words that it speaks. “Hear from many, Must is trust, Follow none & Believe in Yourself” . These words will make you feel that you own your life. I wish to share a story which inspires me a lot . Good or Bad starts from You There was a business executive who was deep in debt and could see no way out. Creditors were closing in on him. Suppliers were demanding payment. He sat on the park bench, head in hands, wondering if anything could save his company from bankruptcy. Suddenly an old man appeared before him. “I can see that something is troubling you,” he said. After listening to the executive’s woes, the old man said, “I believe I can help you.” He asked the man his name, wrote out a check, and pushed it into his hand saying, “Take this money. Meet me here exactly one year from today, and you can pay me back at that time.” Then he turned and disappeared as quickly as he had came. The business executive saw in his hand a check for $500,000 , signed by John D. Rockefeller , then one of the richest men in the world! “I can erase my money worries in an instant!” he realized. But instead, the executive decided to put the uncashed check in his safe. Just knowing it laying there, might give him the strength to work out a way to save his business, he thought. With renewed optimism, he negotiated better deals and extended terms of payment. He closed several big sales. Within few months, he was out of debt and making money once again. Exactly one year later, he returned to the park with the uncashed check. At the agreed-upon time, the old man appeared. But just as the executive was about to hand back the check and share his success story, a nurse came running up and grabbed the old man. “I’m so glad I caught him!” she cried. “I hope he hasn’t been bothering you. He’s always escaping from the rest home and telling people he’s John D. Rockefeller.” And she led the old man away by the arm. The astonished executive just stood there, stunned . All year long, he’d been wheeling and dealing, buying and selling, convinced he had half a million dollars behind him. Suddenly, he realised that it wasn’t the money, real or imagined, that had turned his life around. It was his newfound self-confidence that gave him the power to achieve anything he went after. Friends, I don’t wish to summarize the story but wish to shoot out some queries a) From where did the businessman get the energy? b) What made him progress? c) Where did the success comes from? d) Did the businessman really need money or just a spark to accelerate him ? Think Positive….. Live Happily….. Indhu, Business Analyst, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2015-12-25"},
{"website": "Mallow-Tech", "title": "Rails 5.0 – Review", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2015/12/rails-5-0-review/", "abstract": "WAIT IS OVER !!!! Lets Get into Action Rails was praised for being the easiest way to get Ruby on the web. It was the easiest option, and the best. Though plenty of other frameworks arrived, Rails is still the industry leading framework for Ruby developers. Rails 5 was announced on RailsConf past April. This was a major version of Ruby On Rails and there were number of new features and performance improvements that were included to this release. Rails 5.0 beta1 has been released and it is 790 scruffy-looking nerf herders contributed to this release  with over 7000 commits . Rails 5 works only with ruby 2.2.2 or better and reason is ruby 2.2 introduces a number of new features and performance enhancements that the Rails team wants to capitalize on and mainly to take advantage of new Incremental GC which will help to reduce memory consumption by our Rails applications. New stuffs added to Rails 5 1) Action Cable 2) Rails API 3) New Command Router 4) Attributes API 5) ApplicationRecord 6) ActiveRecord::Relation#or ActionCable: It’s a completely integrated solution that includes an EventMachine-powered connection loop, a thread-backed channels layer for server-side processing, and a JavaScript layer for client-side interaction. It’s incredibly easy to use, and makes designing live features like chat, notifications, and presence so much easier. The really lovely thing about Action Cable is that you get access to your entire Active Record and PORO domain model in your WebSockets work. We even added a brand-new ActionController::Renderer system that makes it trivial to render your templates outside of controllers, when you want to reuse server-side templates for WebSocket responses. In development, Action Cable runs in-process with the rest of your app. To do this, we’ve switched the default development server from Webrick to Puma. In production, you may well want to run Action Cable servers in their own processes. For more info: github-rails-actioncable API Mode: Rails is not only a great choice when you want to build a full-stack application that uses server-side rendering of HTML templates, but also a great companion for the new crop of client-side JavaScript or native applications that just needs the backend to speak JSON. We’ve made this even clearer now with the new –api mode. If you create a new Rails application using rails new backend –api, you’ll get a slimmed down skeleton and configuration that assumes you’ll be working with JSON, not HTML. There’s still more work to be done on this feature, but we’re off to a great start. By default, API mode just relies on #to_json calls on model classes. But you can either use Jbuilder, Active Model Serializers, or look at the new JSONAPI::Resources project for a more advanced solution. For more info: github-rails-pull Command Router: Though we have used both rails and rake commands, it is often difficult to remember which one to make use of and it definitely confusing for the beginners to understand when this needs to be used. For example, we start a console with rails console, but run migrations with rake db:migrate? That doesn’t make any sense. Starting in Rails 5, many of these old rake commands can be run with rails instead. For more info: github-rails-issues Attributes API: This new API adds functionality on top of ActiveRecord models, it made possible to override an attribute type to be a different type. Consider the case where we have a field in the database defined as decimal but in our app we only care for the integer part of the number. We can in our app just ignore the decimal part and format our number everywhere we need to use it to only display the integer part. With attribute API we can do this in an easy way: class Book < ActiveRecord::Base end book.quantity # => 12.0 class Book < ActiveRecord::Base attribute :quantity, :integer end book.quantity # => 12 Here we are overriding the automatically generated attribute from the database schema to be cast in our model as an integer instead the original decimal. For every interaction of our model with the database, the attribute will be treated as a decimal as it should be. We can even define our own custom types just by creating a class derived from ActiveRecord::Type::Value and implementing its contract to #cast, #serialize, and #deserialize values. Custom attributes will honor ActiveModel::Dirty to track changes in our models. Also, these new attributes can be virtual, so there is no need to be backed by a table column. ApplicationRecord: Just like ApplicationController, we’re getting an ApplicationRecord model superclass in Rails 5. Now you don’t have to monkeypatch ActiveRecord::Base to add functionality! For more info: github-rails-pull ActiveRecord::Relation#or: ActiveRecord::Relation is getting #or method, this will allow us to write queries with ActiveRecord DSL as follows: Book.where(‘status = 1’).or(Book.where(‘status = 3’)) # => SELECT * FROM books WHERE (status = 1) OR (status = 3) #or method accepts a second relation as a parameter that is combined with an or. #or can also accept a relation in a form of model scope. class Book < ActiveRecord::Base scope :new_coming, -> { where(status: 3) } end Book.where(‘status = 1’).or(Book.new_coming) # => SELECT * FROM books WHERE (status = 1) OR (status = 3) You should really checkout the CHANGELOGs, though. There’s just so much new and good stuff available in all the frameworks: Action Mailer CHANGELOG Action Pack CHANGELOG Action View CHANGELOG Active Model CHANGELOG Active Record CHANGELOG Active Support CHANGELOG Active Job CHANGELOG Railties CHANGELOG Hope the above informations were useful. Until next time….. Logesh, ROR Team Lead, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2015-12-25"},
{"website": "Mallow-Tech", "title": "Laravel 5.2 release at a glance", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2015/12/laravel-5-2-release-at-a-glance/", "abstract": "Even though we were planned to give a blog on “ The features of AWS in a Nutshell ”  as Laravel 5.2 got released my team decided to first give a clear view to readers on this that is the reason we have this blog. We will have a glance of some of the features which we need to know in Larval 5.2. Release 1. Array Validation In the previous version of Laravel, we need to loop through the array variables and do the validation like the below example Example : In view file which is common to 5.1 and 5.2 <input type=’text’ class=’form-control required’ name=’fields[1]’> <input type=’text’ class=’form-control required’ name=’fields[2]’> <input type=’text’ class=’form-control required’ name=’fields[3]’> Validation in Request upto Larvel 5.1 public function rules() { foreach ($this->request->get(‘fields’) as $key => $val) { $rules[‘fields.’ . $key] = ‘required|string’; } return $rules; } But now in Laravel 5.2, this has been simplified as below and it is much easier to as like other validations. Example : public function store(Request $request) { $this->validate($request->all(), [ ‘fields.*’ => ‘required|string’> ]); } 2. API Rate Limiting First let’s explain what is rate limiting – It allows to limit the number of requests that a given IP address can make to a route over a specified number of minutes. For example, to limit a route with only 30 requests per minute from a single IP address, it can be achieved by following Example : Route::get(‘/api/orders’, [‘middleware’ => ‘throttle:30,1’, function () { return Order::all(); }]); 3. Auth Scaffolding In previous versions, if we need to have view files for authentication purposes, we specifically need to include the package. But now in this latest version, we just have the files for views in front-end by simply executing the make:auth command. Example : php artisan make:auth 4. Appending output from scheduled tasks Previously, Laravel included a sendOutputTo option to write the current results of scheduled job. It overwrites every time the scheduler task runs. But now the result of the tasks can be appended to the same file by using ‘appendOutputTo ’. Example : $schedule->command(’emails:send’) ->hourly() ->appendOutputTo($filePath); 5. Implicit route model binding Implicit model binding is newly added feature in this version which is for binding a model to route. Example : Route::get(‘items/{item}’, function(Item $item) { return $item; }); Here, Item::findOrFail($item) will be executed by default and will return the result in $item variable. The item parameter will be automatically bind to Item model. In previous version, we need to do this model binding in RouteServiceProvider::boot method by manually as below. Example : Binding A Parameter To A Model public function boot(Router $router) { parent::boot($router); $router->model(‘item’, ‘AppItem’); } 6. Collections Wildcards If you want to pull out data while using a collection, it is now easy by passing a (*) as a wildcard. Example : $posts->pluck(‘events.*.title’); This will return all event’s title. 7. Global Scopes Eloquent Global Scopes: Global scopes will allow us to use some common type of constraints in all the eloquent queries as like soft delete concept. Now this feature becomes very simple than earlier. You just need to create the scope class in the scopes directory which is not available in Laravel by default. You can create this directory by your own inside the app directory. And add the apply method in this class as below. Here you are allowed to add your own  constraints. Example : <?php namespace AppScopes; use IlluminateDatabaseEloquentScope; use IlluminateDatabaseEloquentModel; use IlluminateDatabaseEloquentBuilder; class UserScope implements Scope { /** * Apply the scope to a given Eloquent query builder. * @param  IlluminateDatabase EloquentBuilder  $builder * @param  IlluminateDatabase EloquentModel  $model * @return void */ public function apply(Builder $builder, Model $model) { return $builder->where(’status’, ‘=‘, 1); } } You can easily apply this scope to your model by specifying the boot() method in your User model. protected static function boot() { parent::boot(); static::addGlobalScope(new UserScope); } Once you add this scope, you will be getting only the users whose status is 1 while you running User::all() query. 8. Middleware Groups In the previous version, we can have only individual middleware routes, whereas now, we can group many classes as a separate middleware groups and used in routes. Example : protected $middlewareGroups = [ ‘web’ => [ AppHttpMiddleware EncryptCookies::class, IlluminateCookieMiddleware AddQueuedCookiesToResponse::class, IlluminateSessionMiddleware StartSession::class, IlluminateViewMiddleware ShareErrorsFromSession::class, AppHttpMiddleware VerifyCsrfToken::class, ], ‘api’ => [ ‘throttle:60,1’, ], ]; As per the above example, we can have separate middleware groups for web and API usage. Example : protected $middlewareGroups = [ ‘web’ => […], ‘api’ => […], ‘admin’ => [ ‘web’, ‘auth’, ] ]; Like the above code, we are allowed to group the group into another group, like admin can have access to all the routes inside that. Hope this blog was useful.Until next time….. PHP Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2015-12-25"},
{"website": "Mallow-Tech", "title": "How to AirPrint from your iOS devices – An introduction", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2015/12/print-from-your-ios-device-through-an-airprint-enabled-printer/", "abstract": "Wireless is a term used to describe telecommunications in which electromagnetic waves (rather than some form of wire) carry the signal over part or all of the communication path. Some Common examples of wireless equipment which is in use today: Cellular phones and pagers – provide connectivity for portable and mobile applications, both personal and business Global Positioning System ( GPS ) – allows drivers of cars and trucks, captains of boats and ships, and pilots of aircraft to ascertain their location anywhere on earth Satellite television – allows viewers in almost any location to select from hundreds of channels Wireless LAN s or local area networks – provide flexibility and reliability for business computer users Wireless technology: Wireless technology is the process of sending information through invisible waves in the air. Information such as data, voice, and video are carried through the radio frequency of the electromagnetic spectrum. How Wireless Technology Changed Printing With wireless printing technology, you can send documents to your printer from across the room or the other side of the house. You don’t need a cable connection. If you have a computer that’s always connected to your printer, as well as a wireless router, you can simply share the printer to your wireless network. Wireless can be divided into: Fixed wireless Mobile wireless Portable wireless IR wireless Mobile wireless Different Methods for printing: AirPrint Email Print apps Google Cloud Print Among these methods, we are going to see in detail about AirPrint. Also, we will see in detail on how to print using AirPrint from your iOS devices. Print using Apple AirPrint AirPrint lets you print from your iOS devices. With this feature you can instruct to print from your iPhone, iPad, or iPod touch to an AirPrint-enabled printer. In order to use AirPrint, both your printer and iPhone must be connected to the same Wi-Fi network. With AirPrint setup, you can now print almost anything you see on your iOS device. Photos, maps, Web pages, and even content from third-party apps can be sent to your printer wirelessly. You can print from your iOS device to any AirPrint-enabled printer : 1. Open the app you want to print from. Find the print option by tapping the app’s share icon or settings icon. Click Print. For example, Open safari and select print option The below screen appears: After selecting the print option you will be able to see the screen which is shown below. 2. Choose an AirPrint-enabled printer. If your device is not connected to the AirPrint printer it will show error like this.  After connecting also if you don’t see your printer, make sure that: Your iOS device and your printer are both connected to the same Wi-Fi network and you’re within range. Your printer supports AirPrint . Select the number of copies you want to print by tapping the addition and subtraction arrows to the right of “Copy.” Tap Print. View or cancel your print job While printing, you can watch your print jobs or cancel them through the App Switcher. Just double-click the Home button and tap the printer icon. Did you find this blog useful? Let us know in the comments section. Happy Reading!! Mohanapriya, iOS Development Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2015-12-25"},
{"website": "Mallow-Tech", "title": "An Introduction to CloudKit in iOS Platform", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2015/12/cloudkit/", "abstract": "CloudKit , Apple’s new remote data storage service for apps based on iCloud, provides a low-cost option to store and share app data using user’s iCloud account as a back-end storage service. There are two parts to CloudKit: 1. A web dashboard to manage the record types along with any public data. 2. A set of APIs to transfer data between iCloud and the device. Why CloudKit? The answers are three: simplicity, trust, and cost. Simplicity : Unlike other backend solutions, CloudKit requires a little setup. Simply registering for the iOS Developer Program makes you eligible to use CloudKit – you don’t have to register for additional services or create new accounts.There’s no need to download additional libraries and configure them. CloudKit is imported like any other iOS framework. Trust : Another benefit to CloudKit is that users can trust the privacy and security of their data by trusting Apple, rather than app developers since CloudKit insulates the users’ data from you. Cost: Getting Started with CloudKit for free. CloudKit provides a generous amount of free public storage and data transfer to help you get started. Sign in to the CloudKit Dashboard to view your quota and project usage. CloudKit’s Free usage: CloudKit provides a generous amount of free public storage and data transfer to help you get started. 10 GB Asset storage 100 MB Database storage 2 GB Data transfer 40 Requests per seconds What is needed for CloudKit? Needed Xcode 6 or more installed in mac Membership in the Apple Developer Program Permission to create code signing and provisioning assets in Member Centre Steps to Start with CloudKit in Xcode project: Step 1 : Move to capabilities – switch on iCloud service Step 2 :  Asks for the apple id associated with developer account Step 3 :  When you select CloudKit, Xcode creates a default container ID based on the bundle ID. Because you can’t delete iCloud containers, verify that your bundle ID is correct in the General pane in Xcode before selecting CloudKit.Xcode has you covered in this area – via the Capabilities tab of your project settings file: Flicking the switch will enable iCloud for your app Note that the default settings just enable the iCloud Key-Value store and that you need to check the CloudKit checkbox to link against the correct framework and configure the entitlements appropriately Fundamental CloudKit Objects: There are 7 different fundamental objects in CloudKit. CKContainer : A container is like a sandbox. An application can only use the resources inside its container. The container is located at the very outer border and each application has one and only one separate container. CKDatabase : A database is a place that you put all your data. There are two different kinds of databases: private and public. The private database is where you store sensitive data, like user’s information. The public database is where you store shared data. CKRecord : A record is a piece of data inside your database. It is stored as a key-value pair. For now, you can save NSString, NSNumber,NSData, NSDate, CLLocation, CKReference, and CKAsset, as well as arrays of all the types listed above. CKRecordZone : Records are not stored scattered in a database, they are located in record zones. Every application has a default record zone, and you can also have your own custom record zones. CKRecordIdentifier : The unique label of a record, used for locating a particular record. CKReference : Reference is like the relationship in an RDBMS. In our check-in example, there may be many people checked in at the same place, so we’ll need to establish a reference between places and check-ins. CKAsset : Assets are resources, like binary files or bulk data. For example, a user’s picture should be stored as an asset. Container: The container is the top-level Storage object in the world of CloudKit, and by default, each app has its own, independent container. It is possible that two apps signed by the same developer share the same container – permitting sharing between iOS and OSX, as well as across multiple apps on the same platform. Container object coordinates all interactions between your app and the server. More apps by the same developer can share container Creating custom Container: 1. If “Use default container” is selected, select “Specify custom containers.” 2. Click the Add button (+) at the bottom of the table. 3. In the dialogue that appears, enter an identifier for the container you want to add. The format of Container ID : A container ID begins with iCloud. followed by a string in reverse DNS notation 4. Click OK. Xcode adds the new container ID to the Xcode project entitlements file and to Member Centre. Editing container names and viewing them : You can view all the container IDs for your team in the iCloud settings or Member Centre. In Member Centre, you can also add containers and edit the name of containers. To view container IDs in Member Centre 1. In Member Centre, select Certificates, Identifiers & Profiles . 2. Under Identifiers, select iCloud Containers. DataBases : Each container has exactly two databases: one public and one private . The public database is shared between all users of this container – everybody can access the data, and by default, everybody can write to it. The private database is, as you might expect, completely private to the current user. This means that only the logged-in user has access to this data – they can’t choose to share part of it, nor can the developer take a look at a user’s private database. This is an extremely powerful feature – offering top-notch privacy straight out of the box. The API is very clear about which database you are interacting with – all operations are performed on a database, and you use either the privateCloudDatabase or publicCloudDatabase properties on your CKContainer container object. Access CloudKit Dashboard Use CloudKit Dashboard to manage your CloudKit container schema and records. The schema describes the organization of records, fields, and relationships in a database.A record is an instance of a record type. In a relational database, a record type corresponds to a table and a record corresponds to a row in a table. To sign in to CloudKit Dashboard. 1.In the iCloud settings in the Capabilities pane, click CloudKit Dashboard. Alternatively, go to icloud.developer.apple.com/dashboard . 2.If necessary, enter your Apple ID credentials and click Sign In. All the containers for all the teams you belong to appear in the container pop-up menu in the upper-left corner of the window. To sign out, choose Sign Out from the account pop-up menu in the upper-right corner of the window. Creating and Saving Records in CloudKit Dashboard: – When you select Default Zone under Public Data, the record type should already be selected. – Create a new record either by clicking New Record or by clicking the plus button at the top. – Enter whatever you want for the record’s Description and Title fields. – Click Save in the bottom right to create the record. You’ll see that your record has been assigned a unique record ID, Created date, Modified date, Created By identifier, and Modified By identifier. – No matter what record type a record is based on, it will always have these five attributes. Enter iCloud Credentials Before Running Your App: In development, when you run your app through Xcode on a simulator or a device, you need to enter iCloud credentials to read records in the public database.In production, the default permissions allow non-authenticated users to read records in the public database but do not allow them to write records.Therefore, before you run your app and save records to the database, enter an iCloud account in Settings on iOS or System Preferences on a Mac. Also, enable iCloud Drive. Later, write the necessary error handling to present a dialogue to the user when iCloud credentials are needed to run your app in iOS Simulator, enter the iCloud credentials in iOS Simulator before you select the simulator and click the Run button in Xcode.You need to perform these steps for each iOS Simulator you select in the Scheme pop-up menu in Xcode. To enter iCloud credentials in iOS Simulator 1. Choose Xcode > Open Developer Tool > iOS Simulator 2. In iOS Simulator, choose Hardware > Home. 3. Launch the Settings app and click iCloud. 4. Enter an Apple ID and password. 5. Click Sign In.Wait while iOS verifies the iCloud account. 6. To enable iCloud Drive, click the iCloud Drive switch.If the switch doesn’t appear, iCloud Drive is already enabled. Search Records In the development and production environment, you can search for records that have string fields. To search for records 1.In the left column of CloudKit Dashboard , click Default Zone under Public Data or Private Data.Records appear in the second column. 2. In the second column, click the search icon.A search field appears. 3. Enter text in the search field.CloudKit Dashboard sorts the records by the field values. If the record type doesn’t have a searchable field, “doesn’t have a searchable field.” text appears below the search field. Sort Records In the development and production environment, you can sort records by field. To search for records 1. In the left column of CloudKit Dashboard , click Default Zone under Public Data or Private Data.Records appear in the second column. 2. From the “Sort by address” pop-up menu, select a field.CloudKit Dashboard sorts the records by the field values. 3. To change the order, from the “Sort by address” pop-up menu, select Ascending or Descending. Conclusion CloudKit is a nice addition to the backend service and causes that we may stop worrying about the backend side, if not for production solution, then at least for prototyping and testing ideas. It gives us the ability to track the changes, synchronising assets and syncing data with a small effort. It is also nice replacement for mBaaS services, if you don’t need a cross-platform feature and if you want to stick just with iOS/OSX or web. “Power is gained by Sharing knowledge, share your knowledge” – iOS Development Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2015-12-25"},
{"website": "Mallow-Tech", "title": "Using Gradle in Android development.", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2015/12/using-gradle-in-android-development/", "abstract": "Gradle is the official build system supported by Google for Android. It is written in Groovy programming language. The Gradle build system for Android supports resource shrinking at build time. This automatically removes resources that are unused from the packaged application.In addition to removing resources in your project that are not actually needed at runtime, this also removes resources from libraries you are depending on if they are not actually needed by your application. This can hugely reduce the size of your application. To enable resource shrinking, update your build file android { … buildTypes { release { minifyEnabled true shrinkResources true proguardFiles getDefaultProguardFile(‘proguard-android.txt’), ‘proguard-rules.pro’ } } } Providing different resources for the flavors In order to define a different behavior for a certain flavor, you need to create suitable folders for the defined flavors under app/src/. Flavor specific resources override the main resources, i.e., if you provide a different application icon in a flavor the Android build system picks up the flavor specific one if you are deploying or building your flavor. 1. The Gradle build system is designed to support complex scenarios in creating Android applications: ⁃ Multi-distribution: the same application must be customized for several clients or companies ⁃ Multi-apk: supporting the creation of multiple apk for different device types while reusing parts of the code 2. Gradle is an advanced build toolkit that manages dependencies and allows you to define custom build logic. ⁃ Android Studio uses a Gradle wrapper to fully integrate the Android plugin for Gradle. ⁃ The Android plugin for Gradle also runs independent of Android Studio. This means that you can build your Android apps from within Android Studio and from the command line on your machine or on machines where Android Studio is not installed (such as continuous integration servers). 3. Gradle is another build system that takes the best features from other build systems and combines them into one. ⁃ It is improved based off of their shortcomings. It is a JVM based build system, what that means is that you can write your own script in Java, which Android Studio makes use of. 4. One best thing about gradle is that it is a plugin based system. – This means if you have your own programming language and you want to automate the task of building some package (output like a JAR for Java) from sources then you can write a complete plugin in Java or Groovy, and distribute it to rest of world. 5. Integration with Android Studio – With Gradle, IDE integration isn’t an afterthought. Android Studio is deeply integrated with the new Gradle-based Android build system. 6. Simple, Declarative, Domain-specific Language – Gradle Inc. worked together with Google to create a simple, declarative DSL(Domain Specific Language) for Android builds. 7. A Single Build System – Gradle is the authoritative build across the IDE and the command-line. This means that the same build that powers Android Studio will power your command-line and continuous-integration builds. 8. Product Flavors, Build Variants, and Build Type – Many mobile applications have a free version and a paid version while other applications may ship seasonal variations. With Gradle product flavors are easy to manage with a few lines of code. Build types control application packaging and build configuration for different types of debug and release builds. 9. Android Signing Configuration – The Gradle Android DSL provides a very simple way to customize keystores and signing configuration across different build types. 10. Dependency Management – Gradle offers a flexible approach to dependency management that can reuse existing Maven repositories or reference local JARs. If you depend on libraries from Cntral or if you run your own local repositories, Gradle can adapt to any requirement. 11. Multi-project Support – Gradle supports multi-project builds from both the IDE and the command-line. With Gradle you can easily create builds that span multiple application and library projects. 12. Binary Bundles for Libaries (.aar) – Gradle supports the new .aar binary bundle format for library projects. 13. Full Incremental Builds – The new Gradle-based Android build system has been designed for developer efficiency. Gradle’s support for incremental tasks means you spend less time waiting and more time coding. 14. A Focus on Testing – The Gradle-based Android build system bring a new focus on testing. With Gradle you can run unit and integration tests without creating sub projects. Gradle supports several scenarios for integration testing on build servers. 15. Test Server API supports Hosted Testing – Integration with Jenkins-based build servers and services from AppThwack, TestDroid, and Manymo means that your build can support complex, massively-parallel integration testing scenarios. Advantages of Gradle: ⁃ Configure and intercept all build phases of your project with the use of plugins ⁃ Dependency management ⁃ Distribution management ⁃ SCM integration. ⁃ Well integrated with Continuous Integration environments such as Jenkins. ⁃ The possibility to write your build script with a functional programming language. ⁃ Possibility to write your own tasks in Groovy (tasks are based on task Ant model). ⁃ POM generation. ⁃ Reuse of all Maven repositories. ⁃ Integration with Ivy repositories. ⁃ Polyglot build system to integrate projects with different technologies and programming languages. ⁃ Create multiple APKs for your app with different features using the same project.(create several variants of an application) ⁃ Reuse code and resources. ⁃ Customise, configure, and extend the build process. ⁃ Customised integration with their own IDE Android Studio. ⁃ Single build tools to support multiple languages. Reference Links: 1. To support complex scenarios in Android applications: Stack overflow – What is gradle in android studio? 2. Advantages of Gradle: Quora – What are the advantages and disadvantages of gradle versus maven? 3. Features and Benefits: Gradle – The new gradle android build system. Until Next Time….. Android Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2015-12-25"},
{"website": "Mallow-Tech", "title": "How to create a Self-Signed SSL Certificate", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2015/12/self-signed-certificate-ssl/", "abstract": "What is SSL? SSL or Secure Sockets Layer is a standard technology behind establishing an encrypted connection between a web server (host) and a web browser (client). This connection between the two makes sure that all the data passed between them remain private and intrinsic. Any computer in between you and the server can see your credit card numbers, usernames and passwords, and other sensitive information if it is not encrypted with an SSL certificate. When an SSL certificate is used, the information becomes unreadable to everyone except for the server you are sending the information to. Why Self-Signed SSL? A Self-Signed certificate is similar to the certificate provided by CA(Certificate Authorities) except it being signed by yourself, but we are still using SSL, so we use encryption and we are defeating passive attackers: someone who wants to see our secrets will have to commit visibly to the effort, by mounting a fake server or a man in the middle attack. On the client side, you can use “direct trust”, i.e. specifically instructing your browser to trust the specific server’s certificate. The first connection to the server is vulnerable to a MitM(man in the middle attack), but afterward, you are protected. In many situations, SSL with a self-signed certificate is much better than no SSL at all. But definitely, “better” and “good” are not the same thing Let’s try creating a Sample SSL certificate. We can create SSL certificate through different approaches explained here. Approach 1: [########## courtesy : Digitalocean – How to create a SSL certificate on apache for ubuntu ##########] Let’s start off by creating a subdirectory to place the certificate files that we will be making: mkdir /ssl Now we have a location to place our key and certificate. We can create them both in a single step: OpenSSL req -x509 -nodes -days 365 -newkey rsa:2048 -keyout your_domain.key -out your_domain.crt In the above command openssl : This is the basic command line tool provided by OpenSSL to manage SSL req : This specifies a subcommand for X.509 certificate signing request (CSR) management. -x509 : This option specifies that we want to make a self-signed certificate file instead of generating a certificate request. -nodes : This option tells OpenSSL that we do not wish to secure our key file with a passphrase. -days 365 : This specifies the validity of our certificate -newkey rsa:2048 : The rsa:2048 tells OpenSSL to generate an RSA key that is 2048 bits long. -keyout : This parameter names the output file for the private key file that is being created. -out : This option names the output file for the certificate that we are generating. On running the command, we will be asked to provide the following details Country Name (2 letter code) [AU]: YOUR_COUNTRY_CODE State or Province Name (full name) [Some-State]: YOUR_STATE Locality Name (e.g., city) []: YOUR_CITY Organization Name (e.g., company) [Internet Widgits Pty Ltd] :YOUR_COMPANY Organizational Unit Name (e.g., section) []: YOUR_INDUSTRY_UNIT Common Name (e.g. server FQDN or YOUR name) []: YOUR_DOMAIN Email Address []: YOUR_EMAIL Upon failing the above details, it will generate a “key” file and “crt” file which is build based on the information you provided. You can upload the files to your server and restart it to apply the changes. If you hit your URL with “https”, you will get a warning that your browser cannot verify the identity of your server because it has not been signed by one of the certificate authorities that it trusts. As said earlier, we can use “direct trust”, i.e. specifically instructing your browser to trust the specific server’s certificate Approach 2: Now, let’s try the other approach. [########## courtesy : thegeekstuff.com – linux apache mod ssl generate key csr crt file ##########] Generate the “private key” by running the following command $ openssl genrsa -des3 -out server.com.key 1024 On executing the above command, we would be asked for passphrase as shown below Generating RSA private key, 1024 bit long modulus …….++++++ …………………………… ………………………………………. ……………………………. ………….++++++ e is 65537 (0x10001) Enter pass phrase for server.key: Verifying – Enter pass phrase for server.key: Remember the passphrase, that you give in the above step. Now it’s time to create our “CSR (Certificate Signing Request)” file by using the key file which we have generated in the previous step. $ openssl req -new -key server.key -out server.csr Enter pass phrase for server.key:<PASSWORD_OF_SECRET.KEY> You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields, there will be a default value, If you enter ‘.’, the field will be left blank. ——— Country Name (2 letter code) [AU]: YOUR_COUNTRY_CODE State or Province Name (full name) [Some-State]: YOUR_STATE Locality Name (e.g., city) []: YOUR_CITY Organization Name (e.g., company) [Internet Widgits Pty Ltd] :YOUR_COMPANY Organizational Unit Name (e.g., section) []: YOUR_INDUSTRY_UNIT Common Name (e.g. server FQDN or YOUR name) []: YOUR_DOMAIN Email Address []: YOUR_EMAIL Please enter the following ‘extra’ attributes to be sent with your certificate request A challenge password []:<NEW_PASSWORD> An optional company name []: Let’s cook the Self-Signed SSL certificate Now let’s create the sample certificate with 365 days validity. openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt Signature ok subject=/C=IN/ST=Tamil Nadu/L=Karur/O=Mallow/OU=IT/CN= *.mallow-tech.com/emailAddress=dev@mallow-tech.com Getting Private key Enter pass phrase for server.key:<PASSWORD_OF_SECRET.KEY> In this post, we have seen in detail about the ways to create a self-signed SSL certificate. Having a secure connection is essential for a business to sustain and avoid any threats. Having a self-signed SSL certificate will help in achieving the feat. Surender T, ROR Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2015-12-18"},
{"website": "Mallow-Tech", "title": "Installation of PHP 7.0(PHPNG) in Mac OS X", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2015/12/installation-of-php-7-0phpng-in-mac-os-x/", "abstract": "In the continuation of my preceding blog now I have shared about “How to install PHP 7.0”  which is also known as PHPNG indicating the “Next Generation” of PHP. This blog will help you to install PHP 7.0 in Mac OS X Step 1. Install Brew Install Brew so that you can install additional dependencies with the support of it. Open Terminal and in the prompt paste the below command ruby -e “$(curl -fsSL https://raw.githubusercontent.com/ Homebrew/install/master/install )” Step 2. Dependencies Install Use the following command to install dependencies brew install autoconf automake bison27 freetype gd gettext git mariadb mcrypt t1lib zlib Step 3. Building PHP 7.0  from source We need to clone the PHP-7.0.0 branch of the PHP source and compile it using the build script. git clone -b PHP-7.0.0 https://github.com/php/php-src.git cd php-src ./buildconf –force env YACC=`brew –prefix bison27`/bin/bison ./configure –prefix=”/usr/local/opt/phpng” –with-config-file-path=”/usr/local/etc/phpng” –enable-bcmath –enable-calendar –enable-exif –enable-ftp –enable-gd-native-ttf –enable-gd-jis-conv –enable-mbstring –enable-pcntl –enable-sysvmsg –enable-sysvsem –enable-sysvshm –enable-wddx –enable-zip –with-bz2 –with-curl –with-iconv –with-freetype-dir=`brew –prefix freetype` –with-gd –with-gettext=`brew –prefix gettext` –with-gmp –with-jpeg-dir=`brew –prefix gd` –with-mcrypt=`brew –prefix mcrypt` –with-mysqli=`brew –prefix`/bin/mysql_config –with-openssl –with-pdo-mysql=`brew –prefix mariadb` –with-png-dir=`brew –prefix gd` –with-zlib=`brew –prefix zlib` make -j`sysctl -n hw.logicalcpu_max` Step 4. Creating a package installer We can complete the installation by creating a package installer env INSTALL_ROOT=$PWD/phpng-pkg make install pkgbuild –root phpng-pkg –identifier net.php.phpng –version 7.0.0-dev –ownership recommended phpng-dev.pkg open phpng-dev.pkg Step 5. Use PHPNG By default MAC OS X will use the PHP binary located at /usr/bin/php which belongs to PHP 5.5. To make PHPNG take precedence we need to symlink to /usr/local/bin directory. After that You can make sure that you are having the correct version running by php –v. Hope you have learnt the new PHP 7.0 which has 100% increase in performance. In my next blog, “The features of AWS in a nutshell and how to reduce billing cost” which will make make a start up to use Cloud services without the fear of technology or expense. Vijayanand, PHP Team Lead, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2015-12-18"},
{"website": "Mallow-Tech", "title": "The best approach to handle images in Android apps.", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2015/12/the-best-approach-to-handle-images-in-android-apps/", "abstract": "We had faced many issue in handling images for android apps. Since android supports many low end devices we need to concentrate on memory management to avoid the out of memory exception in the app. When we decompressed the images, it took lot of memory which is allocated for the app. This leads the java garbage collector to run frequently, hence slows the apps performance. The problem is especially bad without improvements to the garbage collector made in Android 5.0. So we analysed and came back with few solutions and used external library to handle the issue for downloading the images from online and also to make round corner, circle and other shapes. To download the image we used “Universal Image Loader” which is a smart and powerful library that helps in loading, caching and displaying images in Android. This means, using this library you can download remote images and display on ImageView. Features of Universal Image Loader: • Asynchronous and multi-threaded image loading. This allows you to download multiple images Asynchronously. • Supports various configurations that helps to tune for your requirement. With this you can control memory, cache type, decoder, display image options, etc. • Possibility of image caching in memory and/or on device’s file system (or SD card) • Possibility to “listen” loading process. Allows various callback methods using which you will get to know the progress/state of your download request. It’s Free and Open Source Reference Link: for different image loaders Be lazy productive android Image loader useful links: Android Universal Image Loader – wiki – Useful – Info Shaping the Images in Android To reshape the images we use following external jar files to handle in android apps. RoundedImageView: It supports rounded corners and ovals/circles. It is a full superset of CircleImageView (which is actually just a subset based on this lib) with many more advanced features like support for ovals, rounded rectangles, ScaleTypes and TileModes. A fast ImageView (and Drawable) that supports rounded corners (and ovals or circles) based on the original example from Romain Guy. Ref Link: RoundedImageView Advantage: There are many ways to create rounded corners in android, but this is the fastest and best one because it: 1. Does not create a copy of the original bitmap 2. Does not use a clipPath which is not hardware accelerated and not anti-aliased. 3. Does not use setXfermode to clip the bitmap and draw twice to the canvas. 4. It has proper support for: a. Borders (with Colors and ColorStateLists) b. Ovals and Circles c. All ScaleTypes d. Borders are drawn at view edge, not bitmap edge e. Except on edges where the bitmap is smaller than the view f. Borders are not scaled up/down with the image (correct width and radius are maintained) g. Anti-aliasing h. Transparent backgrounds i. Hardware acceleration j. Support for LayerDrawables (including TransitionDrawables) k. TileModes for repeating drawables Dependencies which has to be added in grade file in Android Studio: dependencies { compile ‘com.makeramen:roundedimageview:2.2.1’ } Even we have many other support jar files like  “ siyamed/android-shape-imageview ”, “ MostafaGazar/CustomShapeImageView ” and “ pungrue26/SelectableRoundedImageView ” to handle the images in android app. I referred to the RoundedImageView, developed by Vince, in developing this new one, and I really appreciate him. This also helps you to solve your out of memory issue. Until next time….. Android Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2015-12-18"},
{"website": "Mallow-Tech", "title": "SwiftUI – Modern way of developing Apps for Apple platforms", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2021/03/swiftui-modern-way-of-developing-apps-for-apple-platforms/", "abstract": "Introduction SwiftUI is a modern declarative UI designing framework introduced by Apple at WWDC19 for developing applications for iOS, iPadOS, macOS, watchOS and tvOS. It’s not write once, run everywhere. It’s learn once, develop for any platform in the Apple ecosystem. Let’s see what are the advantages and tradeoffs of using SwiftUI and how the developer and product managers/product owners can make use of it. We mostly talk about iOS, but it applies to other platforms as well. Apple docs, SwiftUI is a modern way to declare user interfaces for any Apple platform. Create beautiful, dynamic apps faster than ever before. Development SwiftUI takes less development time and cost than the UIKit(traditional framework for developing iOS and iPadOS apps) due to its declarative nature and single point of implementation. With UIKit, we need to design UI components separately and need to connect them with code to proceed with business logic. There are too many areas to concentrate on UIKit which is time-consuming and error-prone, whereas in SwiftUI, designing the UI in code is the only option that is declarative, easy and fast. Simple login screen with it’s code As we are designing the UI and business logic in code, we can reuse the code more conveniently than UIKit, which again reduces the time. Since SwiftUI is very young, not all UI counterparts of UIKit are available in SwiftUI. As Apple has one or another way of backward compatibility, we can use UI components from UIKit in SwiftUI and vice versa, which makes SwiftUI more powerful. In UIKit we need to maintain the consistency between the business data and UI which is not easy in general. In SwiftUI, we will define how the UI should look when the state of our business data changes, then it’s SwiftUI’s responsibility to maintain the consistency between the data and UI. Live preview is very useful to get realtime updates in the UI as we update our code. No more building the whole app to see the surprise bugs in the new change. Instead, we can get it on live!! Live preview demo Can design any sort of complex UI and UX with ease in SwiftUI which might not be easy in UIKit. SwiftUI shines when the app supports multiple device sizes like the iPhone and iPad as it handles most of the heavy lifting for us. Assume a simple login screen that needs 4 – 6 hours of efforts in UIKit can be achieved with 60 – 70 % of efforts with more additional benefits in SwiftUI like accessibility support, dark mode, multiple screen sizes and orientation, etc… Achieving a complex animation in UIKit needs additional knowledge in CoreAnimation framework, which is not needed with SwiftUI. Implementing Animation in SwiftUI is more simple and efficient than UIKit, as SwiftUI takes care of everything for us from rendering to performance optimisation. Apple has added more UI components and improvements to SwiftUI in WWDC20. Apple has already started pushing SwiftUI to the mainstream by releasing a new framework that is completely written in SwiftUI. Eg, WidgetKit Providing supports for the latest OS and Swift versions will be simple than UIKit as we have everything in code and a single place to concentrate Testing Developer testing time will be very minimal due to the state-driven nature of the SwiftUI The bugs count due to developer mistake might get reduced as we no need to concentrate on multiple things when developing apps using SwiftUI Adapting UI to different screen sizes is not easy always and it needs development and QA testing time which can be reduced in SwiftUI Tradeoffs SwiftUI is available from iOS 13 and we need to go with UIKit if we need to give support for the older version of iOS. The good thing is that the majority of the iOS and iPadOS users are running on the latest OS(iOS14) which supports SwiftUI. Check the below image for more details, iOS and iPadOS usage Image courtesy: Apple We might face some unexpected issues at the framework level as SwiftUI is young and not matured like UIKit. Apple might change the existing APIs in new releases, as it is in continuous development. There is no backward compatibility for lower OS versions. Objective-C developers need to learn Swift language to use SwiftUI. We have started and kept exploring the SwiftUI from day 1 and worked on multiple internal projects and demo to understand the fundamentals of SwiftUI. We can expect more improvements and updates about SwiftUI in WWDC21. Product owners/managers can quickly convert their idea as a working app using SwiftUI. Watch this space for more updates about SwiftUI. Karthick Selvaraj, iOS Team , Mallow Technologies . Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2021-03-17"},
{"website": "Mallow-Tech", "title": "Scoped Storage in Android", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2021/03/scoped-storage-in-android/", "abstract": "In each version, Android improves many features and upgrades security to make user data safe. Like that, Android restructures the storage system for security purposes from Android Q. In this version, the scoped storage is newly introduced to access the storage system of the device. Before the scoped storage, we need to access the storage through read and write permission. But users don’t have knowledge regarding which data are handled and modified by the developer. This issue is solved by the scoped storage. In order to make changes to the data, the developer needs to get permission from the user to handle the data. This makes it pretty good, so that the user is able to share the data as per their convenience. Storage System The Android has two divisions in the storage system. They are private storage and shared storage. What is private storage? The private storage is the part of the storage given by the Android, it is a specific directory of the app which can be accessed only by the owner of the app. To handle this part, the developer doesn’t have to get permission from the user. i.e. Android/data/your package name. What is shared storage? The rest of the private storage is known as shared storage. The name itself indicates that it can be shared across the app in the device. Any application can get access to those data. Before Android Q, the developer needs to get user permission to read and write their data in the shared storage whereas in Android Q with scoped storage, the developer doesn’t have to get permission to write, read, and modify own data of our app. This sounds good. But the Android reconstructs the method of handling the storage also. Android introduces the media store API to handle the data in the shared storage and there are no changes in handling private storage, this part can be accessed by the common method which we needed before. Through the Scoped storage concept, Android improves the attributes i.e. the system knows which file is generated by which application and has better management over the files of the particular application. With these, the system allows users to access their data within an application without any permissions. From Android Q, the location of data cannot be directly accessed by the developer, if they need access, they need the permission of “ACCESS_MEDIA_LOCATION”. Media Store Collections The Media store API saves the data in the form of a database. For each collection, there is a separate table to store the data. The media store API is commonly classified into three collections. They are image, video and audio. From Android 10, they have added one more collection, which is called Download Collections. For images – MediaStore.Images table For Videos – MediaStore.Video table For Audio – MediaStore.Audio table For downloads – MediaStore.Downloads table Permission required to access the shared data in the devices In the media store API, to read the data in the device which is contributed by the app,  there is no need to get special permission from the user. To handle the data which is not contributed by the app, we need permission from the user to access data. We need to get read permission from the user to access the media file that was not contributed by our app. To modify and delete the data contributed by another app, we need permission from the user against those data. The non-media files are handled by the Storage Access Framework API. These features of getting permission against the data are introduced from Android Q only. On Android Q, we are unable to get permission to do bulk operation, while modifying and deleting data. In this version, in order to do bulk operation, we need to get permission against each item through an alert dialog. But later, in Android R, they have introduced a permission to perform bulk modify and delete the data. In Android R, they have added some additional features like favourite and trash. These features will not work below the Android version R. Favourite – In the name itself, we can understand that users can be allowed to select the data based on their importances and likes. By this feature, we can mark the data as favourite. The data can be favorited by all apps in the device and view in the favourite options. Trash – It is not like a delete operation. On moving the data to trash, it will be added to the recycle bin. The file will stay there for 30 days and if no further action is taken, the system will automatically delete it after that time. Accessing the data using Media Store API Fetch Media Files val projection = arrayOf(MediaStore.Images.Media._ID, MediaStore.Images.Media.DISPLAYNAME, MediaStore.Images.Media.DATE_TAKEN) val selection = \"${MediaStore.Images.Media.DATE_TAKEN} >= ?\" val selectionArgs = arrayOf dateToTimestamp(day = 24, month = 7, year = 2019).toString()) val sortOrder = \"${MediaStore.Images.Media.DATE_TAKEN} DESC” getApplication().contentResolver.query(                                            MediaStore.Images.Media.EXTERNAL_CONTENT_URI, projection, selection, selectionArgs, sortOrder)?.use { cursor -> imageList = addImagesFromCursor(cursor) } Projection – An array that contains all the information needed. It’s similar to the select clause of the database Selection – It’s similar to where clause in the database. It contains the condition based on which data should be retrieved. SelectionArgs – An array containing the values corresponding to the selection placeholder. SortOrder – The key used to sort the data based on column and order. Default order is ascending order. To switch to descending order, use DESC Keyword. query() – A method of ContentResolver that takes in all above as parameters as well as an additional Uri parameter that maps to the required table in the provider. In case, the required Uri is EXTERNAL_CONTENT_URI, Uri is always mandatory. Since you are requesting images from outside the app, it cannot be a nullable parameter while the rest of the parameters can be nullable. To save the data using Scoped storage Ex: save the image val values = ContentValues().apply { put(MediaStore.Images.Media.DISPLAY_NAME, name) put(MediaStore.Images.Media.MIME_TYPE, “image/jpeg\") put(MediaStore.Images.Media.RELATIVE_PATH, “Pictures/$bucketName/\") put(MediaStore.Images.Media.IS_PENDING, 1) } val collection = MediaStore.Images.Media.getContentUri(MediaStore.VOLUME_EXTERNAL_PRIMARY) val imageUri = context.contentResolver.insert(collection, values) context.contentResolver.openOutputStream(imageUri).use { out -> bmp.compress(Bitmap.CompressFormat.JPEG, 90, out) } values.clear() values.put(MediaStore.Images.Media.IS_PENDING, 0) context.contentResolver.update(imageUri, values, null, null) From Android Q, the new column field has been introduced in the media store to store the specified path of the file, that is MediaStore.Images.Media.RELATIVE_PATH. On using the Media store API, we can’t write the image directly to the folder. When you insert an item that is marked as pending intent (value 1), by default it will be hidden from other apps in the device. This can be used when you use long-running Download. Eg: Video Downloading from URL. Once the download is completed, set the pending intent to 0, to reveal it to other apps in the device value.put(MediaStore, Images.Media.IS_PENDING,0) resolver.update(item, null, null, null) To Delete Media file using media store API try { getApplication().contentResolver.delete( image.contentUri,\"${MediaStore.Images.Media._ID} = ?\", arrayOf(image.id.toString())  ) } catch (securityException: SecurityException) { if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.Q) { val recoverableSecurityException = securityException as? RecoverableSecurityException ?: throw securityException pendingDeleteImage = image _permissionNeededForDelete.postValue( recoverableSecurityException.userAction.actionIntent.intentSender ) } else { throw securityException } } In order to call contentResolver.delete(), it should be placed inside a try block because this method can throw a Security Exception at runtime. The method requires the Content Uri of the image you want to delete. In the ‘Where’ parameter, you should specify the column  based on which the file should be deleted. In the final parameter, you pass the value as an array to the placeholder in the ‘where’ clauses. From Android Q, it isn’t possible to delete or modify items from the media store directly. The developer needs to get permission for these actions. The correct approach is to catch Recoverable Security Exception, which contains an intentSender that can prompt a user to grant permission and if the user accepts the permission then the file can be deleted. Scoped storage Feature introduced After Android R: createWriteRequest – getting bulk access to modify the data createDeleteRequest – getting bulk access to delete the data Bulk Delete Data fun deleteMediaBulk(context: Context, media: List): IntentSender { val uris = media.map { it.uri } return MediaStore.createDeleteRequest(context.contentResolver,  uris).intentSender } This bulk operation is introduced to overcome the limitation of showing a dialogue for each data. Instead of calling the contentResolver.delete() , the developer can use Mediastore.createDeleteRequest which allows the user to grant access to delete all selected files with a single request. Thus, the scoped storage introduced by Android assures security of data in the shared space. Gowtham G M , Android Team , Mallow Technologies . Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2021-03-03"},
{"website": "Mallow-Tech", "title": "It’s Time to move on to Automation Testing", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2021/02/its-time-to-move-on-to-automation-testing/", "abstract": "Are you thinking about transitioning from manual to automated testing and would like to give it a try – If not completely, at least to have a minimum level of getting some insight into the method? If this is true then you are in the right way. You would have been tired of testing (it happens most of the time). There is also a chance of missing bugs at times which customers will find. This would have created dull time in your application. Hopefully it didn’t impact much. Regardless of the reason, would you like to enhance the test coverage at a scale – Test Automation can get you there. It’s certain that you know about Test Automation and also how the organisation is benefited with the properly automated tests – Faster, less-tedious testing Improved efﬁciency Better coverage Fewer bugs This in turn results in better customer experience. First, we will see the critical limitations of going with Automated Testing Manual testing will never fade Automation cannot automate everything There will always be a need for manual testers with awareness, responsiveness, and product understanding that cannot be automated or stuffed into an algorithm. Automated testing cannot work as same as manual testing in all cases. Possibly, it will complement and enhance it. There will ALWAYS be some testing activities, like Exploratory Testing, which can be handled only with human mind. The longer an organisation postpones the transition, the harder it’s to catch up with competitors. Automated testing is an important step to release the application faster with minimal bugs. This is often particularly true amid an age, when technology has exploded the variability of devices, browsers, and versions that customers use. Whether you’re a small team of developers as a Startup or a serious Organisation with devoted testing teams and budgets, the way to testing automation isn’t simple without any obstacles. Transforming a manual testing towards an automated one takes time and effort. How does one do this well? The way to shift from Manual to Automated Testing 1. Get Buy-In & Change Minds You clearly understand the importance of test automation and how it is good for the process and you don’t want to ignore it. On the other hand, you see that others are not convinced yet. To start out getting buy-in, you have to reframe your thinking and enter the perspectives of everyone involved — from management to practitioners. What does ROI(Return On Investment) appear as if to every of your stakeholders? Make it real. For management, the ROI are often best framed in terms of cost savings, product quality, and risk mitigation. What quantity of time are you able to save? How much better is that the coverage? Take a high priority page. What’s the value of downtime if a new feature release breaks something you didn’t even know you ought to have tested? For the daily practitioners, help them understand that the inconvenience is temporary, that they’re going to be ready to take the repetitive and boring tasks out of their day, and that having experience with test automation will only bring more career changes. Test automation means faster release rate which means more worth for customers. Those customers will face fewer confusion from bugs, human errors, or missed defects because automation testing also gives you good quality coverage across your development lifecycle. That coverage is increased, in part, by the very fact that automation helps you test in ways in which manual testing cannot, like performance testing, sophisticated scenarios, and API test automation. 2. Plan on What to Automate & Who Will do it Any new process comes with a learning curve. For the teams just starting with automation, there’s a broad range of things to wrap their minds around: from ﬁguring out which tests to automate to deciding who will do the automation. Does one have the resources and skills you need? Is there an existing testing team? Does one have the budget to rent an SDET to assist code changes? Or does one have to move further with an existing team of manual testers? All are important inquiries to answer. 3. Explore Frameworks The place to begin for choosing frameworks, of course, is narrowed down by what you’re testing. For mobile testing, there are Appium, Quantum, and others (like Espresso). For web testing, there are Selenium and others. In addition to the list, there is up-and-coming frameworks, like Cypress and Flutter. Each has its strengths and weaknesses. Selenium, for instance , is extremely ﬂexible and open sourced but also contains a reputation for being ﬂaky. Test maintenance is often a problem. A conflict for your team regarding frameworks is it will source major issues down the road so choose it wisely. 4. Pick Tools For those entering the world of test automation, getting the tooling right is important. There are many sorts of tools, from legacy and soon-to-be-obsolete record and playback tools all thanks to codeless test automation tools using AI to Strong testing tools that provide device labs and reporting. Just like frameworks, it’s important to select something that serves your purpose. Not only today, but within the near and distant future. Will the tool be around in ﬁve years? Are they releasing frequently? How about support? Ultimately, tooling must address your challenges, serve your strengths, and integrate together with your current and future needs. 5. Start Small, Fail Small, Learn Fast The ray of full-on test automation is bright. But don’t be blinded by planning too much on timely basis. Starting small may be a best practice for nearly any and each business initiative. It holds very true for test automation. Give yourself small goals. Automate a single test case (usually one that’s repetitive process). Compute kinks in your process, then bring that wisdom into more test cases. It’s easier to replicate and scale small successes than to separate exactly what broke amid the inﬁnite variables and dependencies. 6. Strive for Continuous Clarity The name of the automation game is collaboration. Manual testers got to be working closely with coders (or SDETs if you’ve got them) to make your automation efforts. There should be continuous clarity around what’s being tested, how, and what the results should be. Shift-left testing has become popular for a reason: It shortens the gap between development and testing. If done right, test automation achieves an equivalent end. But you would like fast feedback loops among everyone involved to deliver better automation. Keep talking throughout the method . If you’re not over-communicating, you’re under- communicating. 7. Start Automation Work Now, Next Quarter, Next Year Goals give us direction. In test automation, be upfront about what you’re planning to achieve. What does success appear as if within the short-term? Which may be as simple as automating a ﬁrst test case. Or executing X number of tests. By the top of the quarter, maybe that goal is tied more to ﬁnding more bugs or having fewer escaped defects. From there, how much faster are you able to be releasing? Because that’s really the goal, isn’t it? Bottom Line Test automation delivers beneﬁts across the organisation. But you’ll only experience them if you really start automating. So Let’s encourage Automation testing and enjoy the beneﬁts! Gayathri M, Testing Team , Mallow Technologies . Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2021-02-18"},
{"website": "Mallow-Tech", "title": "Form Validation by Custom Rules", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2021/02/form-validation-by-custom-rules/", "abstract": "Form data validation is based on the type of data you specify for each field when creating a form. Only a particular set of characters is required for each data form, and precise validation rules apply. To validate the incoming data of your application, Laravel offers many different approaches. The validation method available on all incoming HTTP requests is most widely used. Laravel offers a number of helpful validation rules; however, you may want to specify any of your own. Using rule objects is one way of registering custom validation rules. You can use the make:rule Artisan command to generate a new rule object. To generate a rule that verifies a surname string, let’s use this command. Php artisan make:rule Surname Once the rule is created, we are ready to define its behaviour. Two methods are included in the rule object: passes and message . The passes method receives the value and name of the attribute and should return true or false, depending on whether or not the value of the attribute is correct. The message method should return a validation error message to use when the validation fails: <?php namespace App\\Rules; use Illuminate\\Contracts\\Validation\\Rule; class Surname implements Rule { /** * Determine if the validation rule passes. * * @param string $attribute * @param mixed $value * @return bool */ public function passes($attribute, $value) { if ($value && preg_match('/^[\\pL\\s\\\\/.,`()-]+$/u', $value)) { return true; } return false; } /** * Get the validation error message. * * @return string */ public function message() { return 'Please enter a valid :attribute'; } } Once the rule has been established, you can apply it to a FormRequest by passing in the similar way: <?php namespace App\\Http\\Requests; use App\\Rules\\Surname; use Illuminate\\Foundation\\Http\\FormRequest; use Illuminate\\Http\\Exceptions\\HttpResponseException; class SurnameRequest extends FormRequest { /** * Determine if the user is authorized to make this request. * * @return bool */ public function authorize() { return true; } /** * Get the validation rules that apply to the request. * * @return array */ public function rules() { return [ ‘surname’=> ‘surname’, ]; } } Another way of defining custom rule is to declare it in AppServiceProvider using extend method in Validator Facade. The extend method has 3 parameters. They are rule name, closure to determine the functionality and the message to be displayed if validation fails. Validator::extend(‘surname’, function($attribute, $value, $parameters, $validator) { if ($value && preg_match('/^[\\pL\\s\\\\/.,`()-]+$/u', $value)) { return true; } return false; }, 'Please enter a valid :attribute'); Once the rule has been established, you can apply it to a FormRequest by passing in the similar way: <?php namespace App\\Http\\Requests; use App\\Rules\\Surname; use Illuminate\\Foundation\\Http\\FormRequest; use Illuminate\\Http\\Exceptions\\HttpResponseException; class SurnameRequest extends FormRequest { /** * Determine if the user is authorized to make this request. * * @return bool */ public function authorize() { return true; } /** * Get the validation rules that apply to the request. * * @return array */ public function rules() { return [ ‘surname’=> ‘surname’, ]; } } Form validation is therefore necessary to prevent malicious users from misusing the web form. Improper validation of type data is one of the main causes of security vulnerabilities. This exposes the website to attacks such as header injections, SQL injections, and cross-site scripting. Jayashree Vaishnavi Paramasivam , PHP Team , Mallow Technologies . Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2021-02-10"},
{"website": "Mallow-Tech", "title": "Strict Loading Associations on Rails 6.1", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2021/02/strict-loading-associations-on-rails-6-1/", "abstract": "Rails 6.1 was released on December 9, 2020 with great new features . In this blog post, we will see the overview of the feature “Strict Loading Association” – https://github.com/rails/rails/pull/37400 , https://github.com/rails/rails/pull/38541 , https://github.com/rails/rails/pull/39491 . How it works: With lazy loading approach, the data will be queried from the database when it is actually required. Consider a topic can be associated with many posts and if you want to list all topics and associated posts in the same page, Lazy loading will generate N number of queries to access the posts and 1 query to load the topics info. This will increase number of requests to the database and increases response time of the request. To avoid this performance issues, we are eager loading to associated data. Strict loading is introduced for developers to helps us caching possible N+1’s. When strict_loading mode is enabled and you are trying to lazy load the data, it will raise ActiveRecord::StrictLoadingViolationError exception. For example, Please consider the below models: class Topic < ApplicationRecord has_many :posts, dependent: :destroy end class Post < ApplicationRecord belongs_to :topic end Lets try strict_loading mode from rails console: topic.strict_loading! enables strict_loading mode on the topic object, When the posts association lazy loaded, rails by default raises an exception. 2.7.0 :001 > topic = Topic.first Topic Load (0.5ms)  SELECT \"topics\".* FROM \"topics\" ORDER BY \"topics\".\"id\" ASC LIMIT $1  [[\"LIMIT\", 1]] 2.7.0 :002 > 2.7.0 :003 > topic.strict_loading? => false 2.7.0 :004 > topic.strict_loading! => true 2.7.0 :005 > topic.strict_loading? => true 2.7.0 :006 > topic.posts Traceback (most recent call last): ActiveRecord::StrictLoadingViolationError (`Post` called on `Topic` is marked for strict_loading and cannot be lazily loaded.) Let’s try eager loading the posts association and check the outcome: 2.7.0 :001 > topic = Topic.first Topic Load (0.8ms)  SELECT \"topics\".* FROM \"topics\" ORDER BY \"topics\".\"id\" ASC LIMIT $1  [[\"LIMIT\", 1]] 2.7.0 :002 > 2.7.0 :003 > 2.7.0 :004 > topic = Topic.includes(:posts).first Topic Load (0.7ms)  SELECT \"topics\".* FROM \"topics\" ORDER BY \"topics\".\"id\" ASC LIMIT $1  [[\"LIMIT\", 1]] Post Load (5.2ms)  SELECT \"posts\".* FROM \"posts\" WHERE \"posts\".\"topic_id\" = $1  [[\"topic_id\", 14]] 2.7.0 :005 > topic.strict_loading! => true 2.7.0 :006 > topic.strict_loading? => true 2.7.0 :007 > topic.posts => #<ActiveRecord::Associations::CollectionProxy [#<Post id: 28, content: \"Test Post 1\", status: \"active\", topic_id: 14, created_at: \"2021-01-27 18:32:38.281310000 +0000\", updated_at: \"2021-01-27 18:32:38.281310000 +0000\">, #<Post id: 29, content: \"Test Post 2\", status: \"active\", topic_id: 14, created_at: \"2021-01-27 18:32:43.713495000 +0000\", updated_at: \"2021-01-27 18:32:43.713495000 +0000”>] It does return list of posts without any exceptions after eager loading. Possible ways of enabling strict_loading mode: 1. Enabling on per record basis: 2.7.0 :001 > topic = Topic.first Topic Load (0.5ms)  SELECT \"topics\".* FROM \"topics\" ORDER BY \"topics\".\"id\" ASC LIMIT $1  [[\"LIMIT\", 1]] 2.7.0 :002 > topic.strict_loading! => true 2.7.0 :003 > topic.strict_loading? => true 2.7.0 :001 > topic = Topic.strict_loading.first Topic Load (13.9ms)  SELECT \"topics\".* FROM \"topics\" ORDER BY \"topics\".\"id\" ASC LIMIT $1  [[\"LIMIT\", 1]] 2.7.0 :002 > topic.strict_loading? => true 2. Enabling for all the associations defined on specific model: Setting strict_loading_by_default to true inside the model will enable strict_loading mode for all the associations on the specific model. class Topic < ApplicationRecord self.strict_loading_by_default = true has_many :posts, dependent: :destroy end 2.7.0 :001 > topic = Topic.first Topic Load (1.9ms)  SELECT \"topics\".* FROM \"topics\" ORDER BY \"topics\".\"id\" ASC LIMIT $1  [[\"LIMIT\", 1]] 2.7.0 :002 > topic.strict_loading? => true 3. Enabling per association basis: Strict loading mode can be enabled on the association by passing the argument strict_loading: true while defining the association. class Topic < ApplicationRecord has_many :posts, dependent: :destroy, strict_loading: true end 2.7.0 :002 > topic = Topic.first Topic Load (8.8ms)  SELECT \"topics\".* FROM \"topics\" ORDER BY \"topics\".\"id\" ASC LIMIT $1  [[\"LIMIT\", 1]] 2.7.0 :003 > topic.posts ActiveRecord::StrictLoadingViolationError (`posts` called on `Topic` is marked for strict_loading and cannot be lazily loaded.) 4. Enabling on application wide: Strict loading mode can be enabled on application level using the configuration – strict_loading_by_default. The below will enable strict_loading mode for all the associations in all the models. Default value of this configuration is false . development.rb: config.active_record.strict_loading_by_default = true Disabling strict loading mode : You can also disable the strict loading mode using the above mentioned configuration by setting it to “false”, For example,  If the strict_loading_by_default is set to true on application.rb (or any environment related configuration) and if you want to disable the strict loading mode for the specific model, you can disable with the below query This will turn off strict loading for all the association defined on this model: class Topic < ApplicationRecord self.strict_loading_by_default = false has_many :posts, dependent: :destroy end Provisions for the actions to be done during the strict_loading mode violation : By default, an exception will be raised when an association is lazy loaded. Rails adds a configuration named action_on_strict_loading_violation. With the help of this configuration, we can also update the configuration to log the violations instead of raising exception. It accepts the values :raise and :log . It defaults to :log development.rb: config.active_record.action_on_strict_loading_violation = :log Thus we got a great new feature to alert us whenever there is a possible N+1. Hope this helps you with understanding the working behaviour of strict loading mode. Gomathi N , ROR Team , Mallow Technologies . Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2021-02-04"},
{"website": "Mallow-Tech", "title": "Diffable Datasource in Tableview and Collection view in iOS", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2021/01/diffable-datasource-in-tableview-and-collection-view-in-ios/", "abstract": "UITableView and UICollectionView are the fundamental parts of UIKit . Till iOS 12, we used Datasource to handle tableview and collection views. So, both these UI components have some issues related to UI updates. Example: If we missed to reload the tableview or collection view after updating datasource using local DB, App crashes with the warning message (as shown in the below image) in times. Above issue was one sample of the UI issues. Similarly, there are some other issues and difficulties occurs in tableview and collection view UIs. For resolving such difficulties, Apple has introduced Diffable datasource in iOS 13 at WWDC19. Diffable datasource has been used in terms of UITableViewDiffableDatasource and UICollectionViewDiffableDataSource . Before iOS 13, We were writing more steps to update UI in tableview and collection views. But, In Diffable datasource we have the direct method to update models without reloading table view or collection view. What is diffable datasource A diffable data source is an object, that is a specialized type of data source which works together with your tableview and collection view objects. It provides the behavior you need to manage updates to your table view’s and collection view’s data and UI in a simple, efficient way. It allows to use delegate methods in Tableview and Collection views. It is a replacement of a Datasource of tableView (UITableViewDatasource) and collectionView (UICollectionViewDatasource). This new diffable datasource allows to define a Datasource in terms of snapshot. The snapshot represents the current state of models. What is Snapshot It returns the representation of the current state of data in tableview or collection view. Diffable data sources uses snapshots to provide data for collection views and table views. Through a snapshot, you can set up the initial state of the data that displays in a view and later update that data.Table View/Collection View updates (append, insert, delete, move) will be done in the current snapshot of datasource. Following this, the updated snapshot will apply in datasource of tableviews and collection views. It will be automatically updated in UI without any manual reload of tableview or collection views. How to implement Diffable datasource 1. Create section models and item models to confirm the Hashable type. 2. A Diffable datasource is defined with the tableview object and cell provider. 3. Create a snapshot and append sections and items models in snapshot. Updated snapshot will be applied into Datasource. Implement Diffable Datasource in tableview 1.Create a new project in Xcode 2. Add a new view controller in main storyboard 3. Design a view controller with the tableview and create new tableview cell with .nib file name 4. Design a new table view cell with the first name and last name labels. Register TableviewCell to table view with reuse identifier 1. Create section models and item Models Create below Section model and item models. Hashable will handle the unique items in diffable datasource. So, Duplicated items will not be added in Diffable datasource and UI. Adding to this, Hashable confirmed model needs at least one unique propertyto handle the non-duplicated values. In the above image, ContactSection as section model and Contact as item model was used for contact list UI to show in tableview. Section model is defined as Enum cases and item model is confirmed as the Hashable customtype . So, Both will be handled uniquely. In Datasource , we don’t need to use Section model as mandatory to update models in tableview. But, We need Section Model as mandatory in diffable datasource to define and update models in tableview. 2. A Diffable datasource will define with the table view object and cell provider Let’s begin by declaring a diffable Datasource before defining a diffable Datasource. Declare a diffable Datasource with selection and item identifiers using above created models. In the above image, UITableViewDiffableDataSource will use diffable datasource for tableview. ContactSection is a selection identifier and Contact is an Item identifier for this diffable datasource. Next, we will define and assign diffable datasource into tableview’s datasource using below CreateContactDatasource method. This method need to be called from ViewDidLoad function in swift file. UITableViewDiffableDatasource will define with a tableview object and cell provider. Cell provider will provide the customised tableview cell to tableview within a closure. This closure have the tableview object, Indexpath and associated Item identifier (Row identifier as Contact ). These are the parameters used to handle tableview cell dequeue inside the Cell provider closure. We will dequeue the TableViewCell using the reuse identifier from tableview, customise the TableViewCell’s cell properties and return the cell within a Cell provider closure. Assign a defined diffable datasource to tableview’s datasource. Once we setup this diffable datasource in tableview, it will handle automatically when the items are updated in tableview. We don’t need to handle cellForRow method when we dequeue the cell for a tableview. It will be handled in diffable datasource definition part itself and also it is a declarative type definition. So, It is easily understandable for beginners also. Don’t need to handle noOfRows method for showing the number of rows to be shown in tableview. Diffable datasource will get the number of rows and sections from the appended items, sections and show in UI. 3. Create a snapshot, append sections and item models into snapshot In the below add Contact method, We will see about the Snapshot updation and updated snapshot will be added into diffable datasource. Create a new snapshot as NSDiffableSnapshot with Section and Item model. We need to use ContactSection as section model and Contact as item model in Snapshot too. Both diffable datasource and snapshot model custom types need to be same. By mistake, If we give different models then we will be getting error in code. Snapshot will be created as var type for updating the snapshot. Once an empty snapshot is created, first we need to append sections and the items will be appended into the sections. At least one section has to be added in the snapshot, otherwise we will be experiencing crashes in the app. Updated snapshot will be applied into a diffable datasource using .apply() method. It will be updated in tableview UI automatically. It is not required to reload tableview for every time we update diffable datasource. In the above code, we will append the favourite section as the first section and append the contact list in the favorite section. Snapshot apply method has Animation and handling completion. So, we can animate the UI updates in tableview while updating the diffable datasource. We can use completion handler to write required code once datasource is updated in tableview. We can call add contact method, where we need to add contact in our code. Till now we have seen the basic cell dequeue and initial datasource updation for the tableview. Now, we shall see about updation in already defined and updated datasource. For updating new items into diffable datasource, we can get the current snapshot of the datasource. After that we can add one item, item list, remove one item and remove item list and all possible updation in that snapshot. Once updated in snapshot, apply that snapshot into tableview’s datasource. The updated data source will be updated with animation because we have given animate as “True” in the data source apply method. Usually, If we need to remove one item from tableview, first we will get index of the model. After that we will remove that item from datasource and reload the tableview. Then only, Item will be removed from the tableview and will be updated in UI also. But, in diffable datasource, we can directly remove the item with only model using deleteItems() method from the current snapshot of datasource. Similarly, we can append, delete Items methods, snapshot insert items, move items, delete all items, and other methods for updating the data source. We can handle these all updates in a Diffable data source with the help of Snapshot. Implement Diffable Datasource in Collection view Let’s start implementation of diffable datasource in collection view. Add new view controller in a Main Storyboard and add a collection view in that view controller. Create a new Collection view cell with .nib file named as CollectionViewCell. Register collection view cell into collection view with reuse identifier. Customise collection view layout as per our requirement. 1. Create section models and items Models We can use same ContactSection as section model and Contact as item model for collection view also. Both are Unique custom type models. 2. A Diffable datasource will define with the collection view object and cell provider Declaration of collection view diffable datasource using UICollectionViewDiffableDatasource object with Section and item models as already used for tableview updates. Both Contactsection and Contact custom model types are unique model types. So, Declaration has been done for collection view datasource. In collection view, diffable datasource will be defined with collection view object and cell provider as same as tableview. Define a collection view cell provider with collection view object, Indexpath and Item model ( Contact as item model) within that closure. While using diffable datasource in collection view, we don’t need to define numberOfItemsInSection and cellForItemAt methods for a collection view. Diffable datasource will handle the dequeue cell and number of items in collection view automatically. 3. Create a snapshot and append sections and items models into snapshot Create an empty snapshot with section and item models as same in tableview’s snapshot creation and append items into that snapshot. We can call the above add contact method, when we need to contact in collection view and see about the UI updates. Append, remove, move items, insert items and other updates will be handled in collect view easily as same like table view with the help of Snapshot . Usage of Diffable datasource 1. Simple and direct methods to update UI in tableview and Collection view, more steps are reduced for update UI. 2. We can compare the new datasource and old datasource with the help of snapshot. 3. We can easily understand, because it was a declarative approach for define and updation. 4. We don’t need to reload tableview and collection views after updating datasource in tableview. It will handle insertion, deletion, reorders automatically in UI. 5. No need to define default methods of Datasource in Diffable DataSource implementation. Disadvantages of Diffable Datasource 1. We need minimum OS version as iOS 13 for using Diffable datasource in any screen. Because we can’t handle the datasource in version lower to iOS 13. 2. We can’t directly update the values in the particular item. We need to remove that item and replace with the updated item in the same place. 3. We need to add at least one section before adding any one item into tableview or collection view. If you are trying to add item without section, app will be crashed. Snapshot is the heart of Diffable datasource. Without Snapshot we can’t handle the diffable datasource and it is the easy, efficient way. Diffable datasource approach is reducing the developer’s complexities from the Datasource . We have seen only the basic things of diffable datasource that would be applied in tableview and collection views. For more updates about diffable datasource, we can check Apple Documentation. Completed Diffable datasource Xcode project will be in GitHub . Stay tuned for the next interesting blog..! Shanmugapriya S, iOS Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2021-01-20"},
{"website": "Mallow-Tech", "title": "Dart DevTools on Flutter", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2021/01/dart-devtools-on-flutter/", "abstract": "Introduction The Dart dev-tool is an option for debugging and analysis. The Flutter app runs in Dart Language. Now it runs only in the browser (like Chrome, Safari, or any other browser which you set as default), in the future, you can see the tool on the apps or separate screen on the editors (like Android studio, Vs-code, etc). By default, it runs in http://127.0.0.1 URL with a random port on the browser. How to get Dart DevTools There are multiple steps to get the Dart dev-tools into your system. First, check whether your system is compatible. You need a minimum of 8 GB RAM and a Minimum i3 processor. 1. Download the SDK of flutter from https://flutter.dev/docs/get-started/install. If you have flutter SDK already, then update the latest SDK by downloading with the same link or from Tools -> Flutter -> Flutter upgrades on the Android studio. You can install the flutter plugin, or else you can run the command flutter upgrade on terminal or CMD. 2. Install the flutter plugin on the android studio from https://plugins.jetbrains.com/plugin/9212-flutter by downloading it from a browser or you can directly install the plugin by the Android studio ->  Preference -> Plugins -> Market place (Tab) search Flutter. 3. Check if there is a browser on the machine, else, you will need a browser on your machine. How to Run Dart DevTools 1. In Android Studio you need to go to Tools -> Flutter -> Open Dart DevTools, as mentioned in the image. In case this option is not available, just upgrade your plugin and SDK to find the options. 2. Dart DevTools will be opened in the browser which will look just like the above image. (Disclaimer : The above image of Dart DevTools is taken on the Flutter version which is shown in the below image). 3. Run the flutter project on your device and you can find the URL of the Dart DevTools listener path in the First run, which you can find on the below image. 4. Paste the URL in Dart DevTools and Connect to a Running App with just the help of connect button. 5. Finally, you will enter into the Dart DevTools Dashboard Which has the option to debug the currently running app. Debug on Dart DevTools There are a list of options available for debugging the currently running app in this tool, where more options are available like tree structure of the widget, slow animation, etc. List of tab to debug on Flutter App 1. Flutter inspector 2. Timeline 3. Memory 4. Performance 5. Debugger 6. Network 7. Logging 8. App Size List of setting to Debug 1. Hot Reload 2. Hot Restart 3. Slow Animations 4. Debug Paint 5. Paint Baselines 6. Repaint Rainbow 7. Debug Banner Conclusion Dart DevTools is very useful for debugging the flutter app in many ways where no other tool is available to debug the flutter app as of now. Will meet you in the next interesting blog! Vignesh S, Android Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2021-01-13"},
{"website": "Mallow-Tech", "title": "Chrome Dev Tools – A Basic Overview", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2020/10/chrome-dev-tools-a-basic-overview/", "abstract": "Chrome DevTools is a set of web authoring and debugging tools which are built directly into the Google Chrome browser. It helps the developers in terms of providing deeper access into the web applications. Also it extends it’s support via editing website in realtime, diagnose problems quickly, performance measure and so on. Inspect elements The powerful tool which is hidden inside the browser is “Inspect elements”. It benefits in many ways and some of them are –  we can check the Page source code, Elements, Network request, Images and CSS  which forms it’s design, Fonts and Icons and Javascript code which is used for page animations. Also from the network tab, we can figure out the loading speed/time of the website, accurate colour of the text and the bandwidth used for download. For the application developers, it helps to preview the look and feel of the website in mobile browsers and for the marketing analysts to find out the “keywords” used in the header of other websites to identify which are all faster in the “google page speed test”. Search : Xcode It helps to search the specific content and HTML elements used in the web page. Elements We can see HTML, JavaScript and CSS that builds a website page. This is similar to viewing the source code of a website but the major difference is that we can edit the code and see the changes in real-time on the site which is currently opened. Emulations It helps to preview the web page in mobile browser. It has pre-set devices and the option to change resolution and aspect ratio. Network analysis reference We can record, stop and clear the response. Also, we can save the request response across different pages using “ preserve log” option and can take a screen shot with time details of the loading pages by clicking the checkbox of the “ screenshot” option. Changing loading behaviour 1. Emulate the first-time visitor by disabling the browser cache By Disabling the cache checkbox, we can emulate how a user experience on our website when they visit for the first time. DevTools disables the browser cache and gives the exact scenario of the user visiting the website for the first time. 2. Emulate them offline Some web pages are built as “progressive web apps” which can function offline with the help of service workers. To check those applications this option is more useful. 3. Emulate the speed of the network We can emulate the different connection speed like 2G and 3G by using this option. Also, we can custom the connection speed and check how our application responds to the different connection speed. We can also add “User-Agent” Example : different browsers in different platforms 2G – 114 kbit/s of download and 20 kbit/s of upload data rate 3G – 114 kbit/s of download and 20 kbit/s of upload data rate Filter request Using the filter option, we can filter the requests by properties such as domain or size of the request. Example: mime-type: image/gif – lists all the requests with gif image. mime-type: image/gif larger-than:1k – lists all the gif larger than 1kb. Note : Only AND operation is currently supported whereas no support is given for OR operation at the moment. List of supported properties are Domain – Displays all the domain names in the requests (.com) Response header – Shows the resources that contain all the specified HTTP response headers. DevTools populates the autocomplete dropdown with all the encountered response headers. Larger- than : It helps to filter the file by size. Priority : Allows to search the requests based on the priority – low/high/medium. Filter requests by type We can filter the requests based on the request type by clicking XHR, CSS, JS, Img, Media, Doc, Font, WS, Manifest and others buttons in network panel. We can also enable the multiple filter by pressing the + filter types in the panel. Filter requests by time Click/drag left or right on the Overview panel to display the requests that were active during that time frame. Sorting the requests by waterfall method We can sort the requests by Start Time : The request which was initiated first will be listed at the top. Response Time : The request which started downloading first will be listed at the top. End Time : The request which was finished first will be listed at the top. Total Duration : The request which has the shortest connection setup request and response will be listed at the top. Latency : The request with shortest waiting time for a response will be listed at the top. Analyse the response By default, The Request table displays the following columns: Name : Filename of the resource. Status : HTTP status code like 1** for continuing, 2** for success, 3** for redirection, 4** for client error, 5** for server error. Type : MIME type of the requested resource like Text, image, etc. Initiator : The following objects can initiate requests Parser : Chrome’s HTML parser Redirect : HTTP redirect Script : JavaScript function Others : Some other process, such as navigating to a page via entering the URL in the address bar or link. Size : The combined file size of response headers and body as delivered by the server. Time : The total duration time from the request start to the receipt of the final byte in the response. Waterfall : A visual breakdown of each request’s activity. Note: We can add or remove the different columns like web socket connections. Analyse the frames in web socket (conversations) When we click on the web socket URL under the name column and then click frames, it lists the data, length and time. Here the messages are colour coded, Outgoing text messages are light-green Incoming text messages are white WebSocket opcodes are light-yellow Errors are light-red Preview : It is mostly used to preview the images. Headers tab: It displays the response headers, query string parameters (view source and URL encoded) Time to take first byte Symptoms A request waiting for long time to receive the first byte from the server. Causes There might be slow connection between the client and server or the server takes time to respond. To determine whether connection or server is slow, host the server locally. If we still get a slow TTFB  when running in local server, then we can say that server is slow. Fix If the connection is slow, host your content on a CDN else change the hosting providers. If the server is slow, it is essential to optimize the database queries, implement the cache, or modify the server configuration. Note : Page response time should be less than 200ms (normally it will be 100 – 600 ms) and TTFB time to first byte should be less than 1 sec. Queuing : It means that the response is queued based on the priority. Stalled : Time taken by the request to wait before the request is sent . It might be due to the queueing time of some conditions for proxy navigation and web socket pages. Download content : If you notice lots of time spent in the Content Download phases, then improving server response or concatenating won’t help. The primary solution is to send fewer bytes. Dom content loaded : The time taken to load completely the initial HTML document , without waiting for css, images, and javascript to finish loading. A very different event load should be used only to detect the fully-loaded page. Ways to improve the speed and response 1. Order in which the elements are optimized : The elements with <head> section will load first and then the subsequent elements will get loaded in a logical way. 2. Minify and optimize the javascript codes : Line breaks, additional spaces, comments and increase the size of javascript files. 3. Asynchronous loading of Javascript : It will stop creation of DOM while javascript is executed. 4. Exclude the unused .JS libraries. 5. Using HTTPS protocol can minimize the load effect time. Generally Time for the First Byte: 200ms – 350ms DOM Content Loaded: 1000ms – 2000ms JS Load Event Fired: 900ms – 2200ms Total Download Size: 1MB – 2MB DNS Lookup: 10ms – 20ms HTTP Requests per page: 50 – 75 Tester can use dev tools for Emulate the mobile view Emulate for different network conditions Emulate the application in different browsers in different platforms Can check DOM content loaded time Can check the TTFB. To Check errors in console. Check the behaviour of web app by disabling cache. Hope you would have gained some knowledge on the basic fundamentals of Chrome Developer Tools. Stay tuned for the next blog on some interesting topic. Arunkumar, Testing Team , Mallow Technologies . Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2020-10-29"},
{"website": "Mallow-Tech", "title": "Kotlin Coroutines – The Asynchronous Programming", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2020/09/kotlin-coroutines-the-asynchronous-programming/", "abstract": "Since we started to develop the desktop, mobile or server-side applications, we often faced a problem in finding the solution to prevent our applications from blocking. We thought of avoiding the user’s wait time and the worst cause bottlenecks that would prevent an application from scaling. The word Asynchronous playing a vital role in modern programming, It can be used to increase the amount of work an app can perform in parallel and also allows us to run heavy tasks without UI freezing. When it comes to Android development, there are many mechanisms to perform asynchronous tasks including: Threading Callbacks Futures, Promises et al. Reactive Extensions Coroutines But it’s difficult to choose the most appropriate mechanism to implement because some have huge learning curve, while the others have tons of boilerplate code to implement and aren’t that concise. As of now, we are handling the multithreading by using Callbacks and blocking states because we don’t have any other simple way to do with thread-safe execution. Coroutines is a very efficient way and complete framework to manage concurrency more efficiently and simply. Coroutines were added to Kotlin in version 1.3 and its based on established concepts from other languages. In this blog, we shall understand Coroutines in a simplified way. What are Coroutines? We can start our learning with an analysis of the term itself, Coroutines = Co + Routines Every one of us is familiar with ordinary routines, also called as subroutines or procedures. But in Java and Kotlin they are known as methods or functions. These routines are the basic building blocks of every codebase. According to Wikipedia, a coroutine is a, “ sequence of program instructions, that performs a specific task, packaged as a Unit. This unit can then be used in programs wherever that particular task should be performed. ” Basically, Coroutines are lightweight threads, which is written over the top of the actual threading framework by taking advantage of cooperative nature to make it light and more powerful. It can be suspended and resumed in the mid of execution (i.e smart scheduling). Since the threads are managed by the OS, coroutines are managed by users as it can take advantage of the cooperation. Coroutines are available in many languages and Kotlin implemented with stack-less coroutines, which means they don’t have its own stack, so they are not mapping on the native thread. Trust me, after trying out Kotlin Coroutines, you’ll realize they aren’t just another tool. They’re a whole new way of thinking about asynchronicity. Kotlin Coroutines help you to write asynchronous code more naturally. That is, in a sequential style of programming, which is more humanly-understandable and readable. Here we go for implementation with a simple example. Before starting our implementation need to add these dependences in our Android project, implementation “org.jetbrains.kotlinx:kotlinx-coroutines-core:x.x.x\"\nimplementation “org.jetbrains.kotlinx:kotlinx-coroutines-android:x.x.x” We can take a common use-case of an Android application for below implementation, Fetch the list of fruits from server Show the fruits in the list UI fun getFruits(): List<Fruit>) {   \n\t// make network call   \n\t// return fruit list\n}  \nfun showFruits(fruits: List<Fruit>) {\n\t// show fruits in UI\n} \nfun getAndShowFruits() {\n\tval fruits = getFruits()\n\tshowFruits(fruits) \n} When we call getAndShowFruits function directly, it will throw the NetworkOnMainThreadException since the network is not allowed to perform on the main thread. To handle these cases, now we are using the callbacks. It will fetch the details in background thread and return the details in the main thread using callbacks. fun getAndShowFruits() {\n\tgetFruits { fruits ->\n\t\tshowFruits(fruits)\n\t}\n} For the same scenario we can use the coroutines as like this, suspend fun getFruits(): List<Fruit> {\n   return GlobalScope.async(Dispatchers.IO) {\n        // make network call\n        // return list of fruits\n      }.await()\n}\nfun showFruits(fruits: List<Fruit>) {\n        // show list of fruits\n}\nsuspend fun getAndShowFruits() {\n   val fruits = getFruits()\t\t// fetch on IO thread\n   showFruits(fruits)\t\t// back on UI thread\n} You see, many variables are looking new to us. Let’s have a look at what they are. Dispatcher: Dispatchers are used to help the coroutines in deciding the thread that the work has to be performed. It has three types majorly. Dispatchers.Default: It will perform CPU related works, such as sorting large lists, doing complex calculations and similar. A shared pool of threads on the JVM backs it. Dispatchers.IO : It will do networking or reading and writing from files. We can use it to perform any input and output works. Dispatchers.Main: It is the recommended dispatcher for performing UI-related events. For example, showing TextViews in an Activity, updating Views and so on. Suspend: Suspend is a function that could be started, paused and resumed. These functions are called from a coroutine or another suspend function only and it includes the keyword suspend . To use this function, we need to make our function as suspend too. If the suspending function has to suspend, it will simply pause its execution. By this way, you free up its current thread for other work. Once it’s done suspending, it will get the next free thread from the pool, to finish its work. As we told already, the getAndShowFruits function can be called from another suspend function or a coroutine only. Since we couldn’t make the onCreate function as suspend we need to call it from the coroutines like below: override fun onCreate(savedInstanceState: Bundle?) {\n     super.onCreate(savedInstanceState)\n     GlobalScope.launch(Dispatchers.Main) {\n         getAndShowFruits()\n     }\n} Which is same as, override fun onCreate(savedInstanceState: Bundle?) {\n     super.onCreate(savedInstanceState)\n     GlobalScope.launch(Dispatchers.Main) {\n         val fruits = getFruits()        // fetch on IO thread\n         showFruits(fruits)      // back on UI thread\n     }\n } showFruits will run on UI thread because we have used the Dispatchers.Main to launch it. There are two functions in Kotlin to start the coroutines which are as follows: launch{} async{} Launch vs Async: The basic and major difference is that launch{} does not return anything and the async{} will return the instance of Deferred<T>, which has an await() function that returns the result for coroutine. We have a function getFruitsAndSaveInDatabase like below: suspend fun getFruitsAndSaveInDatabase() {\n   \t// fetch fruits from network\n   \t// save fruits in database\n   \t// and do not return anything\n} Now, we can use the launch like below: GlobalScope.launch(Dispatchers.Main) {\n       getFruitsAndSaveInDatabase()    // do on IO thread\n} As the getFruitsAndSaveInDatabase does not return anything, we can use the launch to complete that task and then do something on Main Thread. We can use runBlocking{} instead of launch. It will run new coroutine and blocks the current thread interruptibly until it’s completion. Due to main thread blocking, we can’t use this in production. One best use of this function is JUnit testing, where the test method will wait for the coroutine to complete the run. runBlocking {\n\tdelay(3000)\n} Here you saw one more function delay() . It is the same as Thread.sleep() function to block the current thread. Since delay() is a suspending function, which results non-blocking suspension to allowing other Coroutines to execute. After the period of time delay (3000 milliseconds) finished, we will continue the execution of Coroutine from the point we left. It is equivalent to Thread.sleep(3000), since it is blocking call. The Coroutine is blocked for 3 seconds and only after the completion of the block, the other Coroutine will get the chance to run. But when we need the result back to continue, we need to use the async . We have a function which will return the Fruit details with the given input of Android API levels like below: suspend fun getFruitOneDetail(): Fruit {\n   \t// make a network call \n   \t// return fruit detail\n}\nsuspend fun getFruitTwoDetail(): Fruit {\n   \t// make a network call \n   \t// return fruit detail\n} Now, we can use the async like below: GlobalScope.launch(Dispatchers.Main) {\n     val fruitOne = async(Dispatchers.IO) {\n         getFruitOneDetail()     // get fruit one detail\n     }\n     val fruitTwo = async(Dispatchers.IO) { \n         getFruitTwoDetail()     // get fruit two detail\n     }\n     showDetails(fruitOne.await(), fruitTwo.await())       // back on UI thread\n } Here, it makes both the network call in parallel, await for the results, and then calls the showDetails function. Hope you have understood the difference between the launch function and the async function. There is something called withContext . suspend fun getFruits(): List<Fruit> {\n    return GlobalScope.async(Dispatchers.IO) {\n         // make network call\n         // return list of fruits\n    }.await()\n} withContext is another way of writing the async function instead of writing await(). suspend fun getFruits(): List<Fruit> {\n    return withContext(Dispatchers.IO) {\n         // make network call\n         // return list of fruits\n    }\n} But there are many more things that we should know about the withContext and the await . Now, let’s use withContext in our async example of getFruitOneDetail() and getFruitTwoDetail() in parallel. GlobalScope.launch(Dispatchers.Main) {\n        val fruitOne = withContext(Dispatchers.IO) {\n\t       getFruitOneDetail()\n        }\n        val fruitTwo = withContext(Dispatchers.IO) { \n\t       getFruitTwoDetail() \n        }\n        showDetails(fruitOne, fruitTwo) // back on UI thread\n} When we use withContext , it will run in series instead of parallel. That is a major difference. Scopes in Kotlin Coroutines: While implementing Kotlin coroutine in Android, we need to cancel the background task as soon as the activity / fragment is destroyed. For this, we need proper Scopes. Here, we will learn how to use scopes to handle these types of situations. Assuming that our activity is the scope, the background task should get cancelled as soon as the activity is destroyed. In the activity, we need to implement CoroutineScope. class MainActivity : AppCompatActivity(), CoroutineScope {\n\n        override val coroutineContext: CoroutineContext\n        get() = Dispatchers.Main + job\n\n        private lateinit var job: Job\n} In the onCreate and onDestroy function. override fun onCreate(savedInstanceState: Bundle?) {\n   \tsuper.onCreate(savedInstanceState)\n   \tjob = Job() \t// create the Job\n}\n\noverride fun onDestroy() {\n   \tjob.cancel()\t // cancel the Job\n   \tsuper.onDestroy()\n} Now, just use the launch like below: launch {\n        val fruitOne = async(Dispatchers.IO) {\n\t      getFruitOneDetail()\n        }\n        val fruitTwo = async(Dispatchers.IO) {\n\t      getFruitTwoDetail() \n        }\n        showDetails(fruitOne.await(), fruitTwo.await())\n} Once the activity is destroyed, the task also will get cancelled if it is running because we have defined the scope. When we need the global scope which is our application scope, we can use the GlobalScope as below: GlobalScope.launch(Dispatchers.Main) {\n        val fruitOne = async(Dispatchers.IO) { \n\t      getFruitOneDetail()\n        }\n        val fruitTwo = async(Dispatchers.IO) { \n\t      getFruitTwoDetail()\n        }\n} So, even after the activity gets destroyed, the getFruitDetail functions will continue running as we have used the GlobalScope . This is how the Scopes in Kotlin Coroutines are very useful. Conclusion: Now we have understood what exactly the Coroutines are. It does not replace threads, it’s more like a framework to manage threads. Like threads, coroutines also can run in parallel and wait for each other and then communicate. The biggest difference is that coroutines are very cheap or free so that we can create thousands of them, and pay very little in terms of performance. But the threads are expensive to start and keep around, where thousand threads can be serious challenge for a modern machine. And finally, you got to know how easy it is to switch between threads and return values asynchronously. We will see the exception handling in Coroutines in the upcoming blog. – Sasikumar K, Android Development Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2020-09-30"},
{"website": "Mallow-Tech", "title": "A short note on Property Delegation in Kotlin", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2020/07/short-note-on-property-delegation-in-kotlin/", "abstract": "Delegation is a design pattern that allows an object to delegate tasks to a helper instance. Kotlin provides the language level support for the delegation pattern by introducing a keyword by. The syntax is: val/var <property name>: <Type> by <expression> var name: String by DelegateClass() The expression after the keyword by , satisfies the convention for property delegates. Kotlin Standard Delegates Kotlin’s standard library provides several implementations of the delegated properties. Lazy lazy will be very useful when implementing read-only properties that perform that want to delay the initialization until it is accessed for the first time. The code in lambda executes only when we refer to this property. val lazyValue: String by lazy {\n    println(\"Initialization!\")\n    \"Hello\"\n}\n\nfun main() {\n    println(lazyValue)\n    println(lazyValue)\n} Output Initialization!\n Hello\n Hello As per the above output, the lambda passed to the lazy function was executed only once. Observable This delegate is useful for when an action must be done each time a property’s value changes. It takes two arguments: The initial value of the property and a callback that’s called after the property is assigned a new value. var observableValue: String by Delegates.observable(“Initial Value\") {\n        property, old, new ->\n        println(\"${property.name}: $old -> $new\")\n    }\n\nfun main() {\nobservableValue = “New Data\"\nobservableValue = “Another Data\"\n} Output observableValue: Initial Value -> New Data\nobservableValue: New Data -> Another Data NotNull We can use notNull delegate to prevent the usage of nullable type and refer to the field without safe call operator. It works similar to lateinit in that it will throw an IllegalStateException if a property is accessed before it is initialized. var name by notNull<String>()\n\nfun main() {\n    println(name) // java.lang.IllegalStateException: Property name should be initialized before get\n    name = “Abi”\n    println(name) // Abi\n} Writing Custom Delegate We can write our custom delegates, rather than using ones that already exist. This relies on writing a class that extends one of two interfaces that Kotlin provides. interface ReadOnlyProperty<in R, out T> {\n    operator fun getValue(thisRef: R, property: KProperty<*>): T\n}\ninterface ReadWriteProperty<in R, T> {\n    operator fun getValue(thisRef: R, property: KProperty<*>): T\n    operator fun setValue(thisRef: R, property: KProperty<*>, value: T)\n} For a read-only property (val), a delegate has to provide an operator function getValue() with the following parameters: thisRef – Reference of the property is in property – A reflection description of the property being delegated For a mutable property (var), a delegate has to additionally provide an operator function setValue() with the following parameters: thisRef – Reference of the property is in property – A reflection description of the property being delegated value – The new value of the property Let’s consider an example to get user details for which all the details should be trimmed. We can do this by using the custom setter, it will be called every time we assign a value to the property. var name: String\n    set(value) {\n        field = value.trim()\n    }\n\nfun main() {\n    name = “Jack     \"\n    println(name)\n} Output Jack Well, we have achieved this for user’s name property. If we want to trim the user’s address, city and state then we have to keep the custom setter for all the property as like below. var address: String\n    set(value) {\n        field = value.trim()\n    }\nvar city: String\n    set(value) {\n        field = value.trim()\n    }\nvar state: String\n    set(value) {\n        field = value.trim()\n    } There are lot of boilerplate code and we can solve this with Property Delegation. class TrimDelegate : ReadWriteProperty<Any, String> {\n    private var trimString = \"\"\n    override fun getValue(thisRef: Any, property: KProperty<*>) = trimString\n\noverride fun setValue(thisRef: Any, property: KProperty<*>, value: String) {\n        trimString = value.trim()\n    }\n} We have created our Trim Delegate class. We can use it for property whose value should be trimmed. var name by TrimDelegate()\nvar address by TrimDelegate()\nvar city by TrimDelegate()\nvar state by TrimDelegate() Kotlin Delegate properties help the developer to write reusable and clean code. Hope I have given you a basic idea on this and we shall connect in some other interesting blogs. – Prakash B, Android Development Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2020-07-30"},
{"website": "Mallow-Tech", "title": "ActiveStorage – Prevent existing file deletion on multiple file uploads in Rails 6", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2020/07/activestorage-prevent-existing-file-deletion-on-multiple-file-uploads-in-rails-6/", "abstract": "We have faced an issue with ActiveStorage in our project recently and when we looked into the source code, we found something interesting and wondered why it is not documented anywhere. Let’s get into the issue we have faced and see the solution. What the issue was? For example, Our app has the User model and a user can attach many images. # In User model we had something like the below, class User < ApplicationRecord\n  has_many_attached :images # for multiple file upload\nend # In the controller class UsersController < ApplicationController\n  def create\n    user = User.create!(user_params)\n    redirect_to user\n  end\n\n  def update\n    user = User.update!(user_params)\n    redirect_to user\n  end\n\n  private\n\n  def user_params\n    params.require(:user).permit(:name, :email, images: [])\n  end\nend In the form, <%= form.file_field :images, multiple: true %> Creating user object with attachments: There is no problem in the creation logic. All the attached images are inserted and mapped to the user. Updating user object with no existing images attached: As like create action, there is no issue here. All the attached images are inserted and mapped to the existing user. Updating user object with existing attached images: Say, the user was created with N images. When updating other attributes of the user, if the request receives images parameter as empty array , all the existing attachments of the user will be deleted. What we used to do with paperclip? But this is not the case when using paperclip with nested attributes. We used to specify  `_destroy` as true to delete an existing attachment. How to control the behaviour? Lets dive into the ActiveStorage’s source code (Setter method for the attachments) # active_storage/attached/model.rb def #{name}=(attachables)\n  if ActiveStorage.replace_on_assign_to_many\n    attachment_changes[\"#{name}\"] =\n      if Array(attachables).none?\n        ActiveStorage::Attached::Changes::DeleteMany.new(\"#{name}\", self)\n      else\n        ActiveStorage::Attached::Changes::CreateMany.new(\"#{name}\", self, attachables)\n      end\n  else\n     if Array(attachables).any?\n       attachment_changes[\"#{name}\"] =\n         ActiveStorage::Attached::Changes::CreateMany.new(\"#{name}\", self, #{name}.blobs + attachables)\n     end\n  end\nend The one thing noted from the source code is that there is a configuration available to make decision when the attachment is empty. replace_on_assign_to_many : This is a configuration available to “Optionally replace existing attachments instead of adding to them when assigning to a collection of attachments”. By default, this configuration is set as true . Here is the line from Rails source code(# rails/application/configuration.rb) active_storage.replace_on_assign_to_many = true So in the update request, all the attachments which are being sent in the request is attached and all the existing attachments are removed. How to make the existing images persisted when replace_on_assign_to_many = true? When sending signed ids in the update request, the existing images will be persisted even when the replace_on_assign_to_many value is configured as true . # By adding below code the signed ids are being sent in the attachment key for each existing images. So that the existing attachments with the attachment key won’t be removed. <% if user.images.each do |image| %>\n  <%= form.hidden_field :images, multiple: true, value: image.signed_id %>\n<% end %> If you want to remove any of the existing images, you can just remove the hidden field, so that the signed id of the particular image won’t be sent in the request and that image will be removed. Disabling purging existing images by default If you don’t want to remove the images when updating the record with new attachments, You can set the configuration replace_on_assign_to_many to false in any of the configuration file or in initializer. # Example configuration in config/application.rb config.active_storage.replace_on_assign_to_many = false By this configuration, ActiveStorage will merge the existing attachments and the new attachments always. Check the else part of the below source code, def #{name}=(attachables)\n  if ActiveStorage.replace_on_assign_to_many\n    attachment_changes[\"#{name}\"] =\n      if Array(attachables).none?\n        ActiveStorage::Attached::Changes::DeleteMany.new(\"#{name}\", self)\n      else\n        ActiveStorage::Attached::Changes::CreateMany.new(\"#{name}\", self, attachables)\n      end\n  else\n     if Array(attachables).any?\n       attachment_changes[\"#{name}\"] =\n         ActiveStorage::Attached::Changes::CreateMany.new(\"#{name}\", self, #{name}.blobs + attachables)\n     end\n  end\nend If you want to remove the existing images later, you can do this by using the purge or purge_later method available in ActiveStorage. You can also refer to the issue raised in Rails GitHub repository for more info. Note : This configuration is available only from Rails 6. Please check Rails 6 change logs for further info. Hope, the walkthrough would help you in handling similar issues. Lets connect in some other interesting blogs. – Aarthi K, ROR Development team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2020-07-15"},
{"website": "Mallow-Tech", "title": "Rails ActiveRecord Callbacks – PART 2", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2020/07/rails-activerecord-callbacks-part-2/", "abstract": "Welcome back! I hope, you have finished the first part of this blog post . If not, I recommend you to check it out here because you would get some basic learning about callbacks. In this blog, you will get an in-depth understanding on below callbacks, before_validation after_validation before_save around_save before_create around_create after_create before_update around_update after_update after_save before_destroy around_destroy after_destroy after_initialize after_find after_touch Transactional Callbacks (after_commit & after_rollback) Association Callbacks (before_add, after_add, before_remove, & after_remove) You may be familiar with these callbacks already but I hope, this blog will make you learn something new about these. before_validation : It’s called before Validations.validate method (which is part of the Base.save call). If this callback throws :abort , the process will be aborted and ActiveRecord::Base#save will return false and nothing will be appended to the errors object. after_validation : It’s called after Validations.validate method (which is part of the Base.save call). It will run even validation failed so please make sure before using it. ( Note : Better to use before_save instead of after_validation.) Common note for *_validation: The callbacks are before_validation & after_validation . Both will be triggered for the create, update, save, & valid? methods. ( Note : If you want to trigger this callback on specific method, you can use on option.) Note down the below cases when you are using the valid? methodwith on option, For on: :create , { new_record }.valid? – Callback will be performed. { persisted_record }.valid? – Callback won’t be performed. For example, class TestCallback < ApplicationRecord\n  after_validation :check_after_validation, on: :create\n\n  private\n  def check_after_validation\n    puts 'Inside after validations.'\n  end\nend >> new_record = TestCallback.new(name: 'Test')\n>> new_record.valid?\nInside after validations.\ntrue\n\n>> persisted_record = TestCallback.last\n>> persisted_record.valid?\ntrue For on: :update , { new_record }.valid? – Callback won’t be performed. { persisted_record }.valid? – Callback will be performed. For example, class TestCallback < ApplicationRecord\n  after_validation :check_after_validation, on: :update\n\n  private\n  def check_after_validation\n    puts 'Inside after validations.'\n  end\nend >> new_record = TestCallback.new(name: ‘Test')\n>> new_record.valid?\ntrue\n\n>> persisted_record = TestCallback.last\n>> persisted_record.valid?\nInside after validations.\ntrue before_save: It’s called before Base.save call. It ignores the on option silently so don’t use on option with before_save callback. ( Solution : You can use before_create or before_update instead of an on option. Below example is also a way to overcome this issue.) For example, before_save :change_callback_name, :if => :new_record? Common note for before_* callbacks: The callbacks are before_save , before_create , and before_update. The validation will be skipped if you did any attribute assignments within these callbacks. All the validations have passed before this callback so if you’re changing any attributes value within these callbacks, the validations won’t run for that. ( Solution : You can use before_validation instead of before_save for attribute assignments with validations) For example, class TestCallback < ApplicationRecord\n  validates_presence_of :name\n  before_save :change_callback_name\n\n  private\n  def change_callback_name\n    self.name = nil\n  end\nend >> TestCallback.create(name: 'Test')\n(0.4ms)  BEGIN\n#<TestCallback id: 18, name: nil, type: nil, created_at: \"2020-04-26 04:01:00\", updated_at: \"2020-04-26 04:01:00\">\n(3.1ms)  COMMIT The before_* callbacks are normally used to set some extra attributes after validations passed. Note the below points, The database validations won’t be skipped for the before_* callbacks. Don’t perform/enqueue any jobs in these callbacks because the changes won’t be reflected in the database at this point. The updated value should be available within the transaction/same thread . Common note for *_save callbacks: The callbacks are before_save , around_save , and after_save. These callbacks are triggered for create , update , & save methods. Common note for around_* callbacks: The callbacks are around_save , around_create , and around_update. These callbacks are invoked before the life cycle event. If you want to invoke the event itself, you yield to it and then continue execution. Here is an example for yield, For example, def test_yield\n  puts \"Before yield\"\n  yield\n  puts \"After yield\"\nend >> test_yield{ puts 'At yield' }\nBefore yield\nAt yield\nAfter yield You can use the around callbacks wherever you have both before and after callbacks in the same model for the same event . For example, class TestCallback < ApplicationRecord\n  before_save :set_callback_name\n  after_save :get_callback_name\n\n  private\n  def set_callback_name\n    puts 'set_callback_name'\n  end\n  def get_callback_name\n    puts 'get_callback_name'\n  end\nend class TestCallback < ApplicationRecord around_save :set_and_get_callback_name\n\n  private\n  def set_and_get_callback_name\n    puts 'set_callback_name'\n    yield\n    puts 'get_callback_name'\n  end\nend # As you can see here, the output is same for both >> TestCallback.create(name: ‘test callback')\n(0.7ms)  BEGIN\nset_callback_name\nINSERT INTO \"test_callbacks\" ……\nget_callback_name\n(40.0ms)  COMMIT around_save: Below is an example for around_save and the same example is applicable for other around_* callbacks. For example, class TestCallback < ApplicationRecord\n  around_save :check_around_save\n\n  private\n  def check_around_save\n    puts 'Inside around save - before yield.'\n    yield\n    puts 'Inside around save - after yield.'\n  end\nend >> TestCallback.create(name: 'Around save callback')\nInside around save - before yield.\n(0.4ms)  BEGIN\nTestCallback Create (44.7ms)  INSERT INTO ……\nInside around save - after yield.\n(46.8ms)  COMMIT If you don’t use yield in around_save callback, It will throw below exception, ActiveRecord::RecordNotSaved (Failed to save the record) If you have placed multiple yield within this callback, then the action/query will be performed for each yield . For example, class TestCallback < ApplicationRecord\n  around_save :check_around_save\n\n  private\n  def check_around_save\n    puts 'Inside around save - before yield.'\n    yield\n    yield\n    puts 'Inside around save - after yield.'\n  end\nend # As you can see here, an insert query has run on multiple times >> TestCallback.create(name: 'Around save callback')\nInside around save - before yield.\n(0.4ms)  BEGIN\nTestCallback Create (44.7ms)  INSERT INTO ……\nTestCallback Create (44.7ms)  INSERT INTO ……\nInside around save - after yield.\n(46.8ms)  COMMIT before_create: It’s called before Base.save on new objects that haven’t been saved yet. Common note for *_create callbacks: The callbacks are before_create , around_create , and after_create. These callbacks are triggered for create and save(for new record only) methods. around_create: If you don’t use yield in around_create callback, It won’t throw an ActiveRecord::RecordNotSaved exception. An exception would raise from the database, if you have placed multiple yield within this callback. after_create: It’s called after Base.save on new objects that haven’t been saved yet. if you have any create operation within this callback, then you are in recursion again so make a note of it. ( Solution : You have to manually skip the callbacks to fix this issue.) Common note for after_* callbacks: The callbacks are after_save , after_create , and after_update. These callbacks are still wrapped in the transaction around save. For example, If you invoke an external indexer within this callback, it won’t see the changes in the database. before_update: It’s called before Base.save on persisted/existing objects. Common note for *_update callbacks: The callbacks are before_update , around_update , and after_update. These callbacks are triggered for create and save(for persisted records only) methods. around_update: If you didn’t use yield in around_update callback, It won’t throw an ActiveRecord::RecordNotSaved exception. If you have placed the multiple yield within this callback, then the update query will be performed with same params. after_update: It’s called after Base.save on persisted/existing objects. if you have any update operation within this callback, then you are in recursion again so make a note of it. ( Solution : You can use update_columns or manually skip the callbacks.) after_save: It’s called after Base.save (regardless of whether it’s a create or update save). if you have any create / update operation in this callback, then you are in recursion again so make a note of it. before_destroy: It’s called before Base.destroy. If you want to destroy or nullify the associated records first, use the dependent: :destroy option on your associations. Sometimes we need the callbacks to execute in a specific order. For example , A before_destroy callback should be executed before the children records get destroyed by the dependent: :destroy . So you can achieve this by using prepend: true with before_destroy callback. Like below, For example, before_destroy :check_before_destroy, prepend: true If you used prepend: true, the before_destroy gets executed before the dependent: :destroy is called, and the data is still available. around_destroy: If you didn’t use yield in around_destroy callback, It will throw below exception, ActiveRecord::RecordNotSaved (Failed to save the record) The multiple delete query won’t run if you have placed multiple yield within this callback. after_destroy: It’s called after Base.destroy (and all the attributes have been frozen). As I mentioned earlier, If you have another destroy operation within this callback, then it will be an infinite loop. This scenario is applicable for all the callbacks. after_initialize: It will be called whenever an Active Record object is instantiated , either by directly using new or when a record is loaded from the database. For example, class TestCallback < ApplicationRecord\n  after_initialize :check_after_initialize\n\n  private\n  def check_after_initialize\n    puts 'Inside after initialize.'\n  end\nend >> TestCallback.new(name: 'after_initialize')\nInside after initialize.\n\n>> TestCallback.first\nTestCallback Load (1.4ms)  SELECT  \"test_callbacks\".* FROM \"test_callbacks\" ORDER BY \"test_callbacks\".\"id\" ASC LIMIT $1  [[\"LIMIT\", 1]]\nInside after initialize. It can be useful for avoiding the need to directly override your Active Record initialize method. after_find: It will be called whenever Active Record loads a record from the database. The after_find callback is performed before the after_initialize callback if both are defined. The after_initialize and after_find callbacks both have the before counterparts. after_touch: It will be called whenever an Active Record object is touched. It can be used along with belongs_to for updating the parent object’s updated_at whenever update the child object. Transactional Callbacks: Below are called as transactional callbacks, after_commit after_rollback It will be triggered whenever the database transaction is completed. – The after_commit will be trigged if the transaction is successfully committed. – The after_rollback will be trigged if the transaction is rollback. It’s very similar to the after save except but they don’t execute either database changes has been committed / rollback. We can use after_commit callback only on create , update , or delete action and below are aliases for those operations. after_create_commit after_update_commit after_destroy_commit You have to rescue it and handle it within the callback in order to allow other callbacks to run. The code executed within after_commit or after_rollback callbacks are not enclosed within a transaction. Note : If you’re using both after_create_commit and after_update_commit in the same model, it will only allow the last callback defined to take effect, and will override all other callbacks. ( Solution : Use after_save_commit with on option for create & update.) The after_commit callback triggered for last operation when you did multiple operations for the same instance with in the transaction. Look out the below examples for more understanding, For example, class TestCallback < ApplicationRecord\n  after_commit :check_after_commit\n\n  private\n  def check_after_commit\n    puts 'Inside after commit.'\n  end\nend Multiple operations for different instances, >> ActiveRecord::Base.transaction do\n   instance1 = TestCallback.first\n   instance1.update(name: ‘after_commit 1')\n   instance2 = TestCallback.last\n   instance2.update(name: 'after_commit 2')\n end\n\n>> BEGIN\n…….\nCOMMIT\nInside after commit. // Triggered for instance1.update(name: ‘after_commit 1')\nInside after commit. // Triggered for instance2.update(name: 'after_commit 2')\ntrue Multiple operations for the same instances, >> ActiveRecord::Base.transaction do\n   instance1 = TestCallback.first\n   instance1.update(name: ‘after_commit 1')\n   instance1 = TestCallback.last\n   instance1.update(name: 'after_commit 2')\n end\n\n>> BEGIN\n…….\nCOMMIT\nInside after commit. - // Triggered only for instance1.update(name: 'after_commit 2’).\ntrue Association Callbacks: The above mentioned callbacks won’t trigger when adding record to an association(collection) using shift left operator(<<) and when removing record form an association using delete method. For these actions, we can use association callbacks and perform operations during the callbacks. Below are the available association callbacks: before_add after_add before_remove after_remove before_remove and after_remove callbacks will execute before and after the delete methods. When we call delete method, It will invoke these callbacks by default. before_add and after_add callbacks will execute before and after added association with a record. If the before_add callback throws an exception, it cannot create the association with a record, the record simply won’t be added to the association collection. Similarly If the before_remove callback throws an exception, the record won’t be removed from the association collection. For example, has_many :associations, after_add: :check_after_add, after_remove: :check_after_remove\n\ndef check_after_add\n  puts 'Inside after add'\nend\n\ndef check_after_remove\n  puts 'Inside after remove'\nend Halting Execution: As you start registering new callbacks for your models, they will be queued for execution. This queue will include all your model’s validations, the registered callbacks, and the database operation to be executed. The whole callback chain is wrapped in a transaction. If any callback raises an exception, the execution chain gets halted and a ROLLBACK is issued. To intentionally stop a chain use throw :abort. If any callback returns false then callback chain is not halted. Hope, you learned something new about callbacks. We shall connect again with some other interesting blog. And we always welcome your feedbacks. Thanks for reading! – Rajesh Kanna R, ROR Development team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2020-07-08"},
{"website": "Mallow-Tech", "title": "View Binding on Android", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2020/07/view-binding-on-android/", "abstract": "View binding is a feature that allows you to write code more easily that communicate with views and replace findViewById with generated binding objects to simplify code, remove bugs, and avoid all the boilerplate of findViewById. View binding is available in Android Studio 3.6 Setup instructions:- 1. Enable view binding in a module, add the ViewBinding element to its build.gradle file (no libraries dependencies). As shown in the following example: android {\n    // Enable the view binding\n    viewBinding {\n        enabled = true\n    }\n} 2. Generates a binding object for each XML layout file present in that module. An instance of a binding class contains direct references to all views that have an Id in the corresponding layout as shown in the following example: (activity_login —> ActivityLoginBinding) 3. Complete support for both Java programming language and Kotlin Programming Language Use view binding in an Activity: To set up an instance of the binding class for use with an activity, perform following steps in the activity’s onCreate( ) method: 1. Call the static method of inflate( ) included in the generated view binding class, An instance of the binding class for the activity to use. 2. Get a reference to the root view by either calling the getRoot( ) method. 3. Pass the root view to setContentView ( ) to make it the active view on the screen. private lateinit var binding: ActivityLoginBinding\n\noverride fun onCreate(savedInstanceState: Bundle?) {\n    super.onCreate(savedInstanceState)\n    binding = ActivityLoginBinding.inflate(layoutInflater)\n    setContentView(binding.root)\n} You can use the instance of the binding class to refer the views: binding.username.afterTextChanged {\n    loginViewModel.loginDataChanged(\n        username.text.toString(),\n        password.text.toString()\n    )\n}\n\nbinding.password.apply {\n    afterTextChanged {\n        loginViewModel.loginDataChanged(\n            username.text.toString(),\n            password.text.toString()\n        )\n    }\n\nbinding.login.setOnClickListener {\n    loading.visibility = View.VISIBLE\n    loginViewModel.login(username.text.toString(), password.text.toString())\n} Use view binding in a Fragment: To set up an instance of the binding class for use with an fragment, perform following steps in the fragment onCreateView( ) method: 1. Call the static method of inflate( ) included in the generated view binding class, An instance of the binding class for the fragment to use. 2. Get a reference to the root view by either calling the getRoot( ) method. 3. Return the root view to onCreateView ( ) to make it the active view on the screen. private lateinit var binding: LoginFragmentBinding\n\noverride fun onCreateView(\n    inflater: LayoutInflater, container: ViewGroup?,\n    savedInstanceState: Bundle?\n): View? {\n\n    binding = LoginFragmentBinding.inflate(inflater, container, false)\n\n    return binding.root\n} You can use the instance of the binding class to refer the views: binding.username.afterTextChanged {\n    loginViewModel.loginDataChanged(\n        username.text.toString(),\n        password.text.toString()\n    )\n}\n\nbinding.password.apply {\n    afterTextChanged {\n        loginViewModel.loginDataChanged(\n            username.text.toString(),\n            password.text.toString()\n        )\n    }\n\nbinding.login.setOnClickListener {\n    loading.visibility = View.VISIBLE\n    loginViewModel.login(username.text.toString(), password.text.toString())\n} Differences from findViewById:- View binding has important advantages over using findViewById Null safety: View binding creates direct references to view’s, This mean that there’s no risk of a null pointer exception due to an invalid view ID. When a view is only present in some configurations of a layout file , the field containing its reference in the binding class is marked with @Nullable. Type safety: Each binding class have types matching the views they referred in the XML layout file. This means that there’s no risk of a class cast exception. Comparison with data binding:- View binding and data binding both will be generate binding classes that can use to refer views directly. View binding is intended to handle simple use cases and provides the following advantage over data binding: Faster compilation: View binding requires no annotation processing, so compile times are faster. Ease of use: View binding doesn’t require specially-tagged XML layout files, so faster to adopt in your application. Once enable view binding in a module, it applies to all of that module’s layouts automatically generate. Conclusion:- View binding solved some previous issues like : To avoid the N ull pointer exception ( due to an invalid view id) To avoid Class casting exception (due to miss match in different types of views) Improving the speed and performance of our application development. – Manikandan K, Android Development Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2020-07-01"},
{"website": "Mallow-Tech", "title": "Apple WWDC 2020 : Announcements on iOS 14", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2020/06/apple-wwdc-2020-announcements-on-ios-14/", "abstract": "Finally, the Apple WWDC 2020 event has commenced and we have got exciting announcements on several new features and improvements along with iOS 14 release. Here is an overview on the highlights of the first day event. Home Screen: We can easily group our Apps by using a new feature called App library. In the App Library, apps are organised by using the App category. A search field in the App library makes the search easy to find the apps. Also, we can hide the unused pages/screens from the Home screen. On-device intelligence will show suggestions for quick access to the app along with recently accessed apps or app clips. Home Screen Widgets: Widgets on iOS 14 became more informative, data-rich, interactive, and easy of use. Earlier, the widget could be added only on Today’s screen, but now we can add the widget in both Today’s screen and Home screen. On-device intelligence helps to show the right widget at the right time. We can resize the widget in three different sizes based on our needs and can drag the widget to the required place. We can even group the widgets based on our needs. iOS will show the right widget at the right time which is called a smart stack. We can swipe/scroll the widgets in the stack at any time. Widget Picture in Picture: We can watch the video even when doing other activities like taking notes and chatting with friends by using Picture in Picture. We can drag the picture in picture video to any part of the screen. We can pinch the video to zoom in or zoom out and also swipe and hide the video to access the full screen of the app, at the same time, the audio will still be playing. Picture in Picture Some significant updates have been released for the existing features mentioned below, Siri Messages Car Play App Store Siri: Earlier, Siri would show the results in full-screen mode, and it has improved a lot in iOS 14 for better user experiences. Opening an app, via Siri is smooth and fast. For other kinds of stuff like taking notes, sending messages it displays like a popover view, and it is easy for us to use without blocking the main content we are already working with. Now, Siri supports sending an audio recorded message in the messages app. Also, some additional languages are added in translation. Siri Messages: Now we can pin the conversations for easy access. New memojis with greater looks and age options are added. In the group messages, it’s never been easier to continue the conversations because of some new messages. Now, we have inline replies where we can reply for a specific message as like in Slack. Messages Maps: Many great features were added in the Map for the past few years. Now, the map is rebuilt from the ground-up. The new map gets roll out by this year across the US with new detailed features, navigation, roads, paths, and more. The map is now built with more accurate information on places. Apple partners with brand companies to give some proper guide for the places. We can save this guide for the later use and the guide will be updated whenever pieces of information are updated. The cycling path is also introduced, now we can choose the best path for cycling. Users can also filter the path to avoid stairs. EV routing is introduced where users can choose the EV route when traveling in an electric car. Maps Car Play: New features that are added to CarPlay with iOS 14 release are Parking, EV charger, and Quick food. Instead of a physical car key, a digitalised car key is introduced. Now we can start/unlock our car by using iPhone. The first car supported for this key is the 2020 BMW 5 series. It uses NFC to unlock the car. We can also share our key to our friends with some restrictions like driving speed, etc. This feature is also available on iOS 13. Expecting this feature to be available in all cars soon 🙂 Car Play App Store: Sometimes we might not have an app installed in our device when needed for quick one time access, so we have to download the app for single time purpose and delete after use. To solve this problem, Apple has introduced a feature called App clips. App clips are lightweight and fast to do things quickly. It is mainly designed to speed up the user experience. We can have an option to download the full app from the App clips sheet right after the user is done with their need. We can open the App clips using NFC tags or scanning QR codes. The standard way to inform the user that the App clip is available for the app is using a dedicatedly designed App Clip Code. App Clip In the blog, we have just seen an overview of the new features released in iOS 14, and in our upcoming blogs, we can see the technical and development part of each item. – iOS Development team, Mallow technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2020-06-24"},
{"website": "Mallow-Tech", "title": "Parallel Programming in Swift using OperationQueue", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2020/06/parallel-programming-in-swift/", "abstract": "In a developer’s life it’s a common task to write a program and ask system to perform it. Understanding how the system performs a task helps us utilise its full potential. In this blog, initially we are going to see how a hardware performs a task. Later we will discuss about OperationQueue – a programming model which automatically scales based on available hardware resource. History Earlier days developers used thread to execute a task. Thread is low level tool and it doesn’t scale as the number of core increases. It’s challenging to create multiple threads and keeping them synchronised efficiently. In order to resolve it, instead of creating threads manually, let us assign our task in a queue and asks the system to perform it. By letting the system to manage threads, our app gains maximum scalability with simpler and efficient programming model. GCD and OperationQueue are such models which creates a way for our program to take advantage of multiple cores which handles dynamically changing system conditions. Today we are going to see a brief about OperationQueue before that let’s see how a single and multiple core system executes a task. Concurrency It refers to dealing lot of things at once. Let’s understand it by an example: In a day today life apart from developing, we have lots of task to perform like read/reply mail, followup a task, read blog, plan meetings etc., But if you see its really complex to perform all those tasks at a time. All we can do is, we will switch between different tasks based on resources[time, priorities, our energy]. Following the same way in a single core environment multiple tasks will execute concurrently at a time by switching the context. Parallelism It refers to doing lots of things at once. As per the previous example, if we have multiple persons to perform each task, we can execute all at a time without interrupting others. So in multi core environment multiple thread will execute tasks via parallelism. Concurrency vs Parallelism Parallelism needs hardware with multicore processing units whereas Concurrency don’t need it. Concurrency requires 2 task to exist whereas Parallelism don’t need it. Parallelism assigns each task for a core to execute whereas Concurrency execute all tasks by switching tasks at a same time. Credits: https://joearms.github.io/published/2013-04-05-concurrent-and-parallel-programming.html What’s OperationQueue? OperationQueue is a high level abstraction of GCD. It’s a queue that regulate the execution of a task. In OperationQueue when we add tasks to execute, unlike a queue it won’t execute task in FIFO order. It executes tasks based on the priorities and readiness of a task to execute. In an operation queue, we could add a task as a block or as an Operation object. – Execute a task as a block in the OperationQueue let operationQueue = OperationQueue()\n\nlet block = { () in\n    print(\"Execute a block task\")\n}\noperationQueue.addOperation(block) What’s Operation? Another better way to execute a task is using Operation. It’s an abstract class which represent a single unit work to be executed. It provides us much flexibility to write code in an object orientated way. We can use Operations either by subclassing it or by using system defined subclasses [InvocationOperation or BlockOperation]. It has more benefits like executing based on priorities, adding dependencies and cancelling operations – Executing a task using a block operation let blockOperation = BlockOperation {\n    print(\"Execute a task using BlockOperation\")\n}\noperationQueue.addOperation(blockOperation) – Executing a custom operation class UploadOperation: Operation {\n\n    let data: Data\n    var serverURL: URL!\n\n    init(uploadData: Data) {\n        data = uploadData\n    }\n\n    override func main() {\n        guard !isCancelled else { return }\n\n        // Upload a media to aws server and get the url\n        print(\"Execute a task using a Custom Operation\")\n    }\n\n}\n\nlet customOperation = UploadOperation(uploadData: Data()) – Operation has the potential to add dependency between operations. The object oriented syntax helps us to pass objects around the operations. class MapOperation: Operation {\n\n    override func main() {\n        guard !isCancelled, let uploadOperation = dependencies.first as? UploadOperation else { return }\n        print(uploadOperation.serverURL ?? \"Some server url\")\n        // Map the uploaded url to an api\n    }\n\n}\n\nlet mapOperation = MapOperation()\nmapOperation.addDependency(customOperation)\n\noperationQueue.addOperations([mapOperation, customOperation], waitUntilFinished: true) So by the above example, we can use Operation to execute a task in object oriented way which provides flexibility to add dependencies. Conclusion In addition, operation has added advantages like cancelling a task, KVO/KVC and QueuePriority. In my next blog, we can see the cancelling operations, concurrent, synchronous vs asynchronous operations and their states. Srikanth T, iOS Development team, Mallow technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2020-06-17"},
{"website": "Mallow-Tech", "title": "Policy violation on Google Play", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2020/06/policy-violation-on-google-play/", "abstract": "Having troubles in releasing your ingenious app in Google’s playstore? Yeah, we know how your travel goes until you push your good work into the store. Even the seasoned developers feel frustrating when their apps are pushed out of the store even before having a round in the market. This may happen due to few types of policy review outcomes by Google when you try to release an app into the store and they are, Rejection When you update an app or submit a new one, rejections can occur. It is common when your APK has spam meta data information or repeated keywords. This is one of the point behind rejections. Removal Your already updated/live APK might be removed in some corner cases including any previous versions, if there are any violations for the Google’s ever updated policies. It can happen when the info of answers given during the app creation mismatches with the contents of the app. Suspension This happens incase of any further serious violations of the Google policies. For example, the suspension occurs when your app contains any malware(who knows, but Google does) or inappropriate informations. It can result in removal of all your app versions, ratings ad reviews, which can also lead to suspension of your app bundle, so you can never try to use it again. Termination As said, when there are multiple outcomes from Google policies and violations towards your account, then you will be terminated from releasing an app in Google play again with your account. So be cautious in sorting out the policies of Google before you release your award winner into the store. Google’s Policy Categories Below are Google’s policy categories, based on which your app is judged before releasing it in the store. This can also help you to maintain a good reputation of your console’s account when followed diligently, 1) Restricted Content: Child Endangerment Inappropriate Content Financial Services Gambling Illegal Activities User Generated Content Unapproved Substances 2) Impersonation and Intellectual Property 3) Privacy, Security, and Deception User Data Permissions Device and Network Abuse Malicious Behaviour Deceptive Behaviour Misrepresentation 4) Monetisation and Ads Payments Subscriptions and Cancellations Ads Ad Network Certification 5) Store Listing and Promotion App Promotion Metadata User Ratings, Reviews, and Installs Content Ratings 6) Spam and Minimum Functionality 7) Other Programs Android Instant Apps 8) Families Designing Apps for Children and Families Ads and Monetization 9) Enforcement Policy Coverage Enforcement Process Managing and Reporting Policy Violations 10) Updates and Other Resources. For more details on the policies, please visit the Developer Policy Center Hope you will be ready to release your masterpiece into the Google playstore without any policy violations now. -Indirajith M. Android Development team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2020-06-10"},
{"website": "Mallow-Tech", "title": "Supporting dark mode in iOS 13", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2020/05/supporting-dark-mode-in-ios-13/", "abstract": "Apple has introduced a new feature in iOS 13.0 called dark mode.When dark mode is enabled the apps that are build with iOS 13 will support dark mode. Dark mode is applicable for all UI related components. Requirements: Xcode 11 or later Xcode 11 is required to support the dark mode in our app, which contains all api for supporting . iOS 13 device iOS 13 or later is needed to support the dark mode. For lower OS version, the application will display in light mode. Thinks to be considered while implementing dark mode provided by apple: • Focus on your content Dark Mode focuses on the content areas of your interface, allowing that content to stand out while the surrounding UI recedes into the background. • Test your design in both light and dark appearances See how your interface looks in both appearances and adjust your designs as needed to accommodate each one. Designs that work well in one appearance might not work in the other. • Ensure that your content remains legible When you adjust the contrast and transparency accessibility settings, ensure that your content remains comfortably legible in Dark Mode . Adopting color: Apple has introduced system color to support the dark mode automatically. We can also use custom color. view.backgroundColor = UIColor.systemBackground If we use cgcolor it will not change automatically because they are not part of UIKit. So apple has provided a method called resolveColor according to trait collection of our application. let resolvedColor = UIColor.label.resolvedColor(with: traitCollection)\nlayer.borderColor = resolvedColor.cgColor Supporting custom color: let color = UIColor(named: “Color\") Overriding Dark Mode: In specific viewcontroller:You can override the user interface style per view controller and set it to light or dark using the following code: class ViewController: UIViewController {\n    override func viewDidLoad() {\n        super.viewDidLoad()\n        overrideUserInterfaceStyle = .dark\n    }\n} In specific view: You can do the same for a single UIView instance: let view = UIView()\nview.overrideUserInterfaceStyle = .dark Creating extension for color: We can create your own UIColor extension to support both light and dark mode by checking the user interface style and return the specific color according to the interface style. extension UIColor {\n    public static var primaryColor: UIColor {\n        return UIColor  { (traitCollection) -> UIColor in\n            if traitCollection.userInterfaceStyle == .dark {\n                return UIColor.red\n            } else {\n                return UIColor.blue\n            }\n      }\n    }\n} Supporting image’s: Select the image, in the Attribute inspector, go to the Appearance and select Any, Dark. You will see the empty box to upload images for the dark mode. System icon: In iOS 13 we can use 1500 icons designed by apple, with variety of size and weights. The system icons are vector based they can be used in various sizes without any loss in quality. let personFill = UIImage(systemName: \"person.fill\") Test dark mode: We can test the dark mode in simulator in Xcode 11, by using Environment Override option available in debug view in Xcode. There is a section called Interface style, which provides options to switch to dark mode or light mode. In that, select dark mode to switch our app to dark mode. Disabling dark mode: If there is no need for our app to support dark, Apple has provide way to disable dark mode for your app by adding a key-value pair in info.plist <key>UIUserInterfaceStyle</key>\n<string>Light</string> In this blog, I have shared my experience on Dark mode support. Hope you know how to make your app support dark mode now. It may take some time to make your app support dark mode, but it will make users love your app! Kavinkumar V. iOS Development Team , Mallow Technologies . Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2020-05-18"},
{"website": "Mallow-Tech", "title": "Testsigma – Automation tool", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2020/03/testsigma-automation-tool/", "abstract": "Testsigma helps you to create simple English scripts for automating the application. It ensures the tests are completely automated along with the development and ready to run through the continuous integration pipeline. Testsigma has inbuilt integrations with the Bug tracking tools, Collaboration tools, ALM tools, CI tools, and also with tools like Slack, JIRA, GitHub, Jenkins, BrowserStack, Sauce Labs and more. Why we opt Testsigma ? Testsigma is the complete package to test web and mobile applications. Testsigma is easy to reuse and maintain. It allows many users like Manual testers, SMEs, developers to write automated tests using simple English. Coding knowledge is not needed for using Testsigma tool. Created test suites can be distributed over the multiple browsers and mobile devices. Execution time is reduced 10 times comparing to the parallel execution across the browsers done by other tools. If any changes are done in the feature of the application, Testsigma suggests to change the feature in all the affected areas and related test suites to be executed. Easy to maintain the automated tests and faster executions. Installation of Testsigma No initial set up needed for the Testsigma tool. Basic working of Testsigma Follow the below steps to get started with the Testsigma tool Create a Project To create a new project in Testsigma, Click on the + tab in the left sidebar, then click on New project. Enter all the required details and click on create button. Now, the new project has been created. Create UI identifiers We are creating UI identifiers to find the elements in the application to be tested. We can create UI identifiers either by using path or using chrome extension plugins which can be installed immediately. Create new UI identifier for which the elements needs to be used in the test cases. Identify the element by using path or check the enable to capture in the chrome extension checkbox. By clicking on the checkbox, the user will be navigated to the application in the next tab and user needs to click on the required element to fetch the path automatically. Create a Test Case and add some Test Steps To create a test case, Enter the application URL and start adding the test steps. Whatever the actions needs to be done in the application while testing are supposed to be added as test steps. While entering the test steps itself shows many suggestions for the users to pick up the test step and UI identifiers. Group Test Cases for creating Test Suite and Test Plans To create a Test suite, Click on the Test suite tab from the sidebar and click on create button. Enter all the details and click on the hyperlink to choose the test cases. Select the test cases that needs to group it as a suite to execute tests. Run Test Case / Perform a Dry Run on the Test Case To perform a dry on the test case/test suite, just click on the Run button from the Test case window and enter all the necessary details in the Create Run window. After initiating the dry run, user will be taken to the Test case results page where passed and failed test steps are shown. If test steps are failed, user can edit the test steps or UI identifiers to pass the test case/test suite. View Run Results Executed test results can be viewed and initiate re-run from the Run results window. Passed/Failed/Aborted tests will be shown with all the details here. Passed and failed percentage will be shown in the graph. Screenshots of the pages where the tests are failed are also shown. Hope you all got some information on the Testsigma tool and how to use it for the automation tests. Start automating ! – Mathubhala Logesh, Testing team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2020-03-11"},
{"website": "Mallow-Tech", "title": "Rails ActiveRecord Callbacks – PART 1", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2020/02/rails-activerecord-callbacks-part-1/", "abstract": "Introduction Active Record Callbacks are very effective and quite useful in Ruby on Rails. Equally, they can be the allusive and invisible sources of bugs. In this blog, we will be looking at the basics of ActiveRecord Callbacks. What is a callback? It is a method that get called at certain moment of an object’s life cycle. What is an object life cycle? When we do a normal operation in the rails application, objects may be created , updated , and destroyed . These life cycle actions are called as object life cycle. An Active Record provides hooks (called callbacks) into this object life cycle so that you can control your application and its data. What does the callbacks do? Callback is basically just a way to trigger logic before, after or around a change to the object’s state. This allows you to execute any arbitrary code automatically whenever any event occurs. By using the callbacks, We can write the code that will run whenever an Active Record Object is Initialising, Loading, Validating, Saving, Creating, Updating, and Deleting from the database. Callbacks Registration To use the available callbacks, you need to register them as callbacks. So There are two different ways in callbacks registration, First, you can define a method to be called, class TestCallback < ApplicationRecord\n  # before_validation is one of the macro-style class method\n  before_validation :check_before_validation\n\n  private\n  # We registered the below ordinary method as callback by using macro-style class method\n  def check_before_validation\n    puts 'Inside before validations.'\n  end\nend Second, you can use the macro style . It also receive a block and use this style if the code inside the block is so short and that fits in a single line . class TestCallback < ApplicationRecord\n  # The before_validation(macro-style class method) is registered as a block.\n  before_validation do\n    puts 'Inside before validations.'\n  end\nend We can also be register the callbacks to fire on certain life cycle events . For example, below code will register the callback method check_before_validation to run only on creating a new record. class TestCallback < ApplicationRecord\n  # The below callback is only fire on \"create\" life cycle event\n  before_validation :check_before_validation, on: :create\n\n  private\n  def check_before_validation\n    puts 'Inside before validations.'\n  end\nend It is a good practice to declare the callback methods as protected or private . If kept public, It can be called from outside of the model and violate the principle of object encapsulation. See https://www.rubyguides.com/2018/10/method-visibility/ to learn more about method visibility. Available Callbacks & Order of Operations Below are the list of all available Active Record Callbacks listed in the order in which they will get executed during the respective object life cycle. Creating an Object before_validation after_validation before_save around_save before_create around_create after_create after_save after_create_commit after_commit/after_rollback Updating an Object before_validation after_validation before_save around_save before_update around_update after_update after_save after_update_commit after_commit/after_rollback Destroying an Object before_destroy around_destroy after_destroy after_destroy_commit after_commit/after_rollback Finding an Object after_find after_initialize Initializing an Object after_initialize Touching an Object after_touch Triggering Callbacks The following ActiveRecord methods trigger callbacks to run, Creating a Record save save! save(validate: false) create create! Updating a Record save save! save(validate: false) update_attribute update update! toggle! Destroying Record destroy destroy! destroy_all Finding Record all first find find_by find_by_* find_by_*! find_by_sql last new Intializing Record new Validating Record valid? Touching Record touch Note before_validation & after_validation can be skipped with object.save(validate: false). The after_initialize callback is triggered every time a new object is initialized. Skipping Callbacks The following ActiveRecord methods will skip any callbacks defined in the model from running. decrement! decrement_counter delete delete_all increment! increment_counter update_column update_columns update_all update_counters These methods should be used with caution, bypassing them without understanding the potential implications may lead to invalid data. We will see in more detail about all the available callbacks in the upcoming blog. -Rajesh Kanna R, ROR Team, Mallow technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2020-02-20"},
{"website": "Mallow-Tech", "title": "On device text recognition in iOS using vision", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2020/02/on-device-text-recognition-in-ios-using-vision/", "abstract": "Apple made lot of improvements in vision framework in iOS 13 which was introduced in iOS 11. One of the improvement is on device text recognition . Before this release, you need to use VNDetectRectangleRequest to detect characters in an image and should run CoreML model to extract the meaningful text from detected characters. You should take care of all optimisation, error correction and everything from recognised text. From iOS 13, you need not do all these stuffs to extract the text from an image. Vision will take care of everything from extracting to optimising the performance, with little inputs from your end. The main advantage of vision text recognition is the text extraction and processing, that are done on device. The images(or user sensitive data) won’t leave user device, which will reduce the risk of data theft or misuse.  The on device text recognition speed is considerably fast when compared to cloud based process using services like Google vision or AWS Textract . Vision have two types of recognition levels that can be chosen to recognise text from an image. They are Fast and Accurate . Each have their own pros and cons. Fast: It works based on character detection for real time processing of text and it’s optimised for it As this doesn’t run any heavy CoreML models to process images and text, it takes less time to complete the process The result accuracy will be less, as its purely character based detection and uses NLP only for corrections in detected texts Uses less memory, since it doesn’t need to run large neural networks(NN) Apple recommended this for live capturing and processing, like live translators You can prefer this, when there is another heavy process on progress like rendering an AR scene in foreground Accurate: It works based on neural networks(NN) to detect meaningful text from an image It is purely meant for async processing, which is not necessary to provide results in real time As it requires running an NN, it takes more time than fast accuracy level The results are more accurate even when you have different font styles and sizes in an image, rotated image and misaligned texts Apple recommended this when images are already available in photo gallery and need high accuracy You need to choose the accuracy level based on the requirement. If you need high accuracy and committed to meaningful results, go with Accurate accuracy level. If there is any memory constraints in device as your primary feature is consuming it, need results fast for real time action, go with fast accuracy level. Just to start with VNRecogniseTextRequest, Check the code snipped below. Code Snippet: func process(image: UIImage) {\n        guard let imageData = image.pngData() else { return }\n        let requestHandler = VNImageRequestHandler(data: imageData, options: [:])\n        let request = VNRecognizeTextRequest { (request, error) in\n            guard let observations = request.results as? [VNRecognizedTextObservation] else { return }\n            self.recognisedTexts = \"\"\n            self.recognisedTexts?.append(\"Recognised texts:\\n\\n\")\n            for observation in observations {\n                let candtidates = observation.topCandidates(1)\n                for candidate in candtidates {\n                    self.recognisedTexts?.append(\"\\(candidate.string)(\\(candidate.confidence))\\n\")\n                    self.populateLabel()\n                }\n            }\n            DispatchQueue.main.asyncAfter(deadline: .now() + .milliseconds(1)) {\n                self.activityIndicator?.stopAnimating()\n            }\n        }\n        \n        // Showing progress of text recognition from the given image.\n        request.progressHandler = { (request, completed, error) in\n            DispatchQueue.main.async {\n                self.hideScannedImage()\n                self.recognisedTexts = \"\"\n                self.resultLabel.text = \"Recognising..\\((Int(completed * 100)))%\"\n            }\n        }\n        request.recognitionLevel = .accurate // Using accurate recognition level to process static scanned images\n        request.usesLanguageCorrection = true\n        request.minimumTextHeight = 0.1 // Minimum image height is the fraction of the image height. I want to process texts which are at least 10% of image height, remaining texts will be ignored.\n        \n        self.activityIndicator?.isHidden = false\n        self.activityIndicator?.startAnimating()\n        DispatchQueue.global(qos: .userInteractive).async {\n            try? requestHandler.perform([request])\n        }\n    } Points to consider: Whenever possible, crop the image and process only the part / section of image needed. So that processing time and memory footprint will get reduce. You can turn on and off language correction. You are not supposed to use this when you deal with numeric characters. Use this when dealing with non numeric characters, like alphabets. Use your domain knowledge to eliminate common errors. Say if you recognise phone number, you should add validation in recognised phone number string to cross check it accuracy and to not show false value to user. As image quality plays major role in text recognition, use document camera controller to scan the document. Document camera controller is best companion for text recognition. Pass domain specific custom words to help language correction to get better results. Set minimum text height to increase performance. All texts which are less than the minimumTextHeight will be ignored, so that processing time will be reduced. If you have heavy running process like rendering AR scene in foreground, ask text recognition to run only in CPU, to free up GPU. Use progressHandler to show progress to the user for better experience. Cancel on-going text recognition, which you can use to provide cancel button to the user to stop long running recognition process. That’s all for today. Please checkout Lakshmi Vaults app in iOS 13.0+ devices, if you want to check use cases of on device text recognition in action. Complete code is hosted here . Karthick S. iOS Development Team , Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2020-02-13"},
{"website": "Mallow-Tech", "title": "Postman Environment Setup For Laravel API", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2020/02/postman-environment-setup-for-laravel-api/", "abstract": "Postman is a forum for API development (Application Programming Interface), the forum can be used to develop the API during the development process and also to test it with development teammates. The following information will provide the basic steps for setting up environment for API development. Workplace and Collection : Workplace is the first step in the process. For the development process, we will create multiple workplace. We can use collection in workplace, because in the development stage we’ll build more than one API request(s). We can record all the API requests by using the collection and group them to a folder structure. You may build the workplace for personal use or for team development. We can create the new workspace from the top bar of the postman as well as from the left sidebar in the new collection layout. Create new workspace from the top bar Environment In Postman : The next configuration in the postman tool is Environment. For the requests, the postman environment uses multiple key and value pairs.The key(s) can be used as variables for the environment. We can create the variables as local or global. The variable(s) are also trackable and modifiable. We can access variables throughout postman. The environment setup provides option to create many environments with various variables. It has local and global variable support. The local scope variables will work within the selected environment. But the global scope variables will work outside the environment. Setting Up Environment Variable With Laravel API : Here we will have a look at the setup of the environment variable and the laravel framework will be used for the example purpose. The laravel framework based on php facilitates the developers for Web and API development process. The laravel’s intent in the development of the API has the file “api.php” (under the routes folder). We can use the environment option (we can see it in the right side of the top bar in the postman) to create the API process variable. Use Environment Option We may use this option in the development process for the repeated use of values. Both variables can be controlled and modified if need occurs. For example we must authenticate the users by validating their authentication before accessing our project data through the APIs. Every time we don’t ask for credentials from the user to verify them. We’re just giving them one token to access our API and the data here in the environment. We can store the authenticated token and use that variable for all the requests. Access and Modify Variables : Use the double curly brace (“{ } “) to enclose the element. Use” { { url } } “(url key with double curly brace) to retrieve the url name. The variables can be accessed in header, body and so on of requests. Use Double Curly brace I Use Double Curly brace II For example, (Request body in the JSON format) {\n    “name”: {{name}}\n} Every time we don’t change environment variable values. We can also alter the values from the answers to requests. It will affect the actual key value to the environment. This option is available in the “Test” option using the scripts. Alter the values For example, (Test Script) var jsonData = JSON.parse(responseBody);\npostman.setEnvironmentVariable(\"token\", jsonData.token); We’ve seen the local and global scope environment variables already. We have two methods to modify them from the script and they are setEnvironmentVariable() & setGlobalVariable(). Benefits Of Environment Variables : When we start to use the collection and environment of postman, with development, testing, and production data it is easy to test the same set of APIs. For this easy option, we can set up separate environment with the single collection as well. It will reduce the time for the developer to test multiple values with the API collection that has been developed. Hope you would have got an idea on the steps to set up environment for API development. We shall look into some other interesting topics in the upcoming blogs. -Ramadurai M, PHP Team, Mallow technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2020-02-06"},
{"website": "Mallow-Tech", "title": "WorkManager – Schedule background tasks in Android", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2020/01/workmanager-schedule-background-tasks-in-android/", "abstract": "In Android development, to schedule a work we are using job scheduler and other background processing types. Now we can use work manager to run the background processes. WorkManager is one of the Android Architecture Components and  part of Android jetpack ,a new and preferable approach to take on how to build modern Android application. Adding WorkManager dependency: To use the work manager, we have to add the below code snippet to build.gradle file and we must add the Google Maven Repository to your project. dependencies {\ndef work_version = “2.2.0”\n// (Java only)\nimplementation “android.work:work-runtime:$work_version”\n// (Kotlin + coroutines)\nimplementation “android.work:work-runtime-ktx:$work_version”\n} Cases for using WorkManager: i) Should the task be completed now? Should the task be completed now even the application is killed? For example, in a notes taking application the data needs to be synced with server once user completes and this must be done even if the application is killed. ii) Should the task be completed later? Should the task be completed later even after the application killed? In both of the above cases, we can go with work manager. It will ensure to complete the task. Implementation: We need to create a custom class for work manager to define our work.Here the UploadWorker class overrides the worker class and doWork() does the job. class UploadWorker(appContext: Context, workerParams: WorkerParameters) \n                            : Worker(appContext, workerParams) {\n                 override fun doWork(): Result {\n                     try {\n                             // Get the input\n                             val imageUriInput = inputData.getString(Constants.KEY_IMAGE_URI)\n                             // Do the work\n                             val response = upload(imageUriInput)\n                             // Create the output of the work\n                             val imageResponse = response.body()\n                             val imgLink = imageResponse.data.link\n                             // workDataOf (part of KTX) converts a list of pairs to a [Data] object.\n                             val outputData = workDataOf(Constants.KEY_IMAGE_URI to imgLink)\n                             return Result.success(outputData)\n                     } catch (e: Exception) {\n                     return Result.failure()\n                     }\n             }\n                fun upload(imageUri: String): Response {\n                     // Webservice request code here; note this would need to be run\n                     // synchronously for reasons explained below.\n                 }\n         } The input and outputs passes as Data class. In data object, we can pass the limited size of data. This is set by MAX_DATA_BYTES .If the data exists we can use database or something else to pass data. In WorkManager we can return the result in two ways – Result.success() and Result.failure(). There is also an option for Result.retry() option to retry your work on later time. Creating WorkRequest: There are two kinds of works that can be called to make a work request. We can use OneTimeWorkRequest and  PeriodicWorkRequest. // workDataOf converts a list of pairs to a [Data] object.\n        val imageData = workDataOf(Constants.KEY_IMAGE_URI to imageUriString)\n        val uploadWorkRequest = OneTimeWorkRequestBuilder<UploadWorker>()\n              .setInputData(imageData)\n                .build() We can also add the constraints for work request, for example this work should start when the device has network connection. val constraints = Constraints.Builder()\n                .setRequiredNetworkType(NetworkType.CONNECTED)\n                .build() There are some other constraints are available to use with work request. val constraints = Constraints.Builder()\n                .setRequiredNetworkType(NetworkType.CONNECTED)\n                .setRequiresCharging(true)\n                .setRequiresBatteryNotLow(true)\n                .setRequiresDeviceIdle(true)\n                .build() After adding the constraints we can enqueue our work. WorkManager.getInstance().enqueue(uploadWorkRequest) Chain our work: If multiple works has to be finished one by one, we can chain the tasks in work manager. WorkManager.getInstance(myContext) \n            // Candidates to run in parallel\n            .beginWith(Arrays.asList(filter1, filter2, filter3))\n            // Dependent work (only runs after all previous work in chain)\n            .then(compress)\n            .then(upload)\n            // Don't forget to enqueue()\n            .enqueue();\n Sequence and parallel Chaining work status: When multiple works are chained together and enqueued in OneTimeWorkRequest, and any one of the work has failed then all works will be marked as FAILED. Also if any parent work request is cancelled, then the child work requests will also be marked as cancelled. Types of chaining: Sequencial chaining: Its a simple chaining, when one worker completes the work then next worker starts the work. First worker’s output may be passed as input for second worker. Parallel chaining: In this type of chaining we can run some parallel task.When this parallel task completes its execution, then the next one starts execution. Multiple parallel chaining: WorkManager gives us the ability to execute multiple chains parallel with the use of WorkContinuation class. Observing work status: After enqueuing work, we can observe the status of work. This work status is available in WorkInfo class. We can retrieve the work info by work request id. WorkManager.getInstance(myContext).getWorkInfoByIdLiveData(uploadWorkRequest.id)\n                .observe(lifecycleOwner, Observer { workInfo ->\n            if (workInfo != null &amp;&amp; workInfo.state == WorkInfo.State.SUCCEEDED) {\n                displayMessage(\"Work finished!\")\n            }\n        }) Cancelling WorkRequest: If  any work isn’t needed anymore we can cancel it by its id. WorkManager.cancelWorkById( workRequest.id ) Conclusion: In this blog, we have seen how to implement the WorkManager and different cases in it. WorkManager is now in stable release and available in Android jetpack components. – Selvaraj V, Android Team, Mallow technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2020-01-24"},
{"website": "Mallow-Tech", "title": "Evolution of Software testing – Automation", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2020/01/evolution-of-software-testing-automation/", "abstract": "In this blog, let me walk you through the Automation testing process and why it is replacing manual testing day by day, so that you will get some idea on the process. Automation testing It uses special software tools to control the execution of tests and later compares the actual test results with predicted or expected results. Doing so reduces manual effort yet not compromising with the quality. Automation tool mimics those same steps by using scripting or a programming language like Javascript, Perl, Python, Ruby, VBScript, Unix Shell script, Tcl, etc. Automation testing mainly used to perform repeated testing like Regression. Automation can be more effective than manual testing in quality, code coverage, easy bug fixing, etc. Why we go for automation testing? The main reason why people go for Automation testing is to save time. Initially, it will take time to prepare the framework and scripting but once the framework is done, automation is a fast process. It is 70% faster than manual testing. Tester does not need to spend their full time in testing the whole module. Instead, they can run the automated test scripts and can see some other project work. Human makes mistakes, but the system will not. We tend to make mistakes when we do the same testing repeatedly and it can be avoided by using the automation testing. One can increase the depth and scope of tests by performing automated software testing and can help improve software quality. Incase the texts are lengthy, they are often avoided during manual testing whereas here can be run unattended. Another additional feature is that we can run them on multiple computers that use different configurations. Executing thousands of different complex test cases can be done by test automation, during every test run providing coverage that is impossible with manual tests. Sometimes, humans will miss the bug but the system will throw the error so that we can fix the bug. That’s the reason, companies are preferring automation testers and they are getting more pay than manual/functional testers. Difference between automation and manual testing Automation uses tools and languages to perform testing whereas Manual testing uses manual efforts Automation testing takes lesser time than manual testing Comparatively, Automation Test case coverage is higher than the manual test cases Some automation tools are payable and some are open source. Initial investment for manual testing is comparatively lower than the automation testing and its tools Initial stages the testing is done by manual and once the app is stable and then automation is done. UI testing is done by manual and functionality, load and performance is done by automation. Tools for automation testing Below are the tools used for the automation process: 1) Ranorex 2) TestComplete 3) LEAPWORK 4) Katalon Studio 5) Selenium 8) LambdaTest 9) CrossBrowserTesting 10) Testimony 11) Appium 12) Micro Focus UFT 13) Test Studio 14) Testsigma Testsigma is an automation tool for which tester does not need knowledge on the programming languages since it uses only the normal English language in the commands. It is a paid tool that supports Web, iOS & Android Apps and API automated testing. I hope you all got some information on the automation testing and its process. Will catch you all in my next blog which is about Testsigma tool 🙂 Start automating ! -Mathubhala Logesh, Testing Team, Mallow technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2020-01-09"},
{"website": "Mallow-Tech", "title": "Understanding Bundler & Gemfile in Ruby on Rails", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2019/12/understanding-bundler-gemfile-in-ruby-rails/", "abstract": "Bundler is a dependency management tool available as a gem. You can install it through RubyGems which comes built-in from Ruby 1.9 with gem install bundler. Bundler will read the Gemfile for the list of gems need to be installed, fetches metadata from the source provided, resolves the dependencies of each gem, installs them and requires them while booting. Without bundler, we need to handle the installation and manage the dependencies manually. Gemfile: Gemfile is a ruby file. You can specify the gem dependencies of the project in Gemfile. During the gem installation and while auto requiring the gems, bundler will search for the Gemfile under the directory mentioned by the environment variable BUNDLE_GEMFILE or at the root of the project directory. Bundler provides a utility called bundle init which creates a simple Gemfile on the current working directory with default source as RubyGems. By default a new rails application ships with Gemfile along with the default gems. Gemfile.lock: When you run bundle install (Or simply bundle) , bundler will install the gems listed on Gemfile along with their dependencies (Includes the dependencies of dependencies). Bundler will create a file called Gemfile.lock with the list of the gems installed along with versions of the installed gems. Next time when you run bundle install, bundler will read the Gemfile.lock and install the exact same versions of the gems listed on Gemfile.lock. This makes sure that the application runs with the same version of the gems in all the environments. Whenever you install a new gem or remove a gem or updating a gem, the Gemfile.lock will get updated. Be sure to commit the Gemfile.lock to the version control to avoid breaking your app. Groups: A gem can be declared under more than one group. Bundler will consider the gems as default group if no gem group specified. On the below Gemfile, gem rails isn’t specified under any group, bundler will consider this gem in default group. Gemfile group :development do     \n   gem 'spring' \nend \n\ngem 'rails', '5.2.3' 1. By default, bundler will install the gems listed in all the groups. You can override it by passing the option without . It accepts the list of groups to exclude from the installation. Please note that bundler will only skip the installation of the gems. It will still download the gems to exactly resolve the dependencies of the gems listed in the Gemfile. For example, bundle install –without test will exclude installing the gems from the test group. It will create a file called config under the directory root of the app/.bundle to remember the option. The next time when you bundle install without the without option, bundler will still remember the option from the config file. .bundle/config ---\n BUNDLE_WITHOUT: \"test\" 2. Most Rails applications contain few gems which are used only for development and testing. Source code of these gems doesn’t needs to be loaded on the production environment. With bundler, you can auto require gems from the specific groups. Versioning gems: When you specify a gem without version on the Gemfile, Bundler will try to install the gems with the latest version based on its dependencies. RubyGems suggests a versioning convention for the Gems as follows: Patch – 0.0.X – Includes bug fixes, All the features worked on v0.0.1 will also work on v0.0.2 Minor – 0.X.0 – Includes additional features, All the features worked on v0.1.0 will also work on v0.2.0 Major – X.0.0 – Includes breaking changes, Some of the features worked on v1.0.0 may break on version v2.0.0 You can specify the version of the gem that needs to be installed on the Gemfile. For example gem ‘ factory_bot_rails ‘ , ‘ >= 4.0 ‘ – Specifies any of the gems greater than or equal to version 4.0 can be installed. You can also provide a pessimistic version using ‘~>’ . Bundler will increment the last digit of the specified version to identify the range of versions applicable for installation. For example gem ‘ rails ‘ , ‘ ~> 4.2.0 ‘ allows installation of rails gem with version ‘ >= 4.2.0 ‘ and ‘ < 4.3.x ‘ . How does bundler auto require the gems? We need to require a dependency in another file in order to use the code inside it. Ruby provides a commonly used method called require which allows us to execute the code from another file. The require method allows the file to be executed only once. It works with the help of global variables $LOAD_PATH (simply $:) and $LOADED_FEATURES . Consider a file called test.rb with the following: test.rb: p 'Hello World' When you launch irb and require the above file, ruby will execute the code inside it and returns true. If you require the same file again, code inside the file will never get executed and require method will return false. Ruby keeps track the absolute path of the required files in the global variable called $LOADED_FEATURES . With the help of $LOADED_FEATURES, ruby ensures the file is required only once at any point. D061:TestApp gomathi$ irb\n 2.6.0 :001 > require '/Users/gomathi/Documents/Projects/Project/TestApp/test'\n \"Hello World\"\n  => true \n 2.6.0 :002 > $LOADED_FEATURES\n  => […, \"/Users/gomathi/Documents/Projects/Project/TestApp/test.rb\"] \n 2.6.0 :003 > require '/Users/gomathi/Documents/Projects/Project/TestApp/test'\n  => false $LOAD_PATH is an array which contains the path to the directories. When you require a file with an absolute path, it will look for the file on the given path, execute the code inside it. If the name passed to the require method is not an absolute path, then it searches for the given file name by iterating through the list of directories on $LOAD_PATH. If it doesn’t find any, then LoadError will be raised. 2.6.0 :001 > require 'test'\n Traceback (most recent call last):\n LoadError (cannot load such file -- test)\n 2.6.0 :002 > $LOAD_PATH << '/Users/gomathi/Documents/Projects/Project/TestApp/'  => […, \"/Users/gomathi/Documents/Projects/Project/TestApp/\"] \n 2.6.0 :003 > require 'test'\n \"Hello World\"\n  => true Bundler uses the same process for requiring the gems. During the initialisation process of Rails app bundler loads boot.rb and application.rb. boot.rb require 'bundler/setup' application.rb Bundler.require(:default, Rails.env) require ‘bundler/setup’ adds the paths provided on require_paths option of the gemspec(which defaults to lib directory) of gems listed in the Gemfile to $LOAD_PATH. Hence the gem files can be required without the need for specifying the absolute path of each file . The next step Bundler.require accepts an array of groups for auto requiring. It then requires the gems along with their dependencies on the specified groups using ruby’s built-in require method. It eliminates the need for manually requiring the gems. What does require: false do? gem ‘rubocop’, require: false The require: false after the gem name instructs bundler to not to auto require the gem. Please note that the bundler will still add the gem to $LOAD_PATH. You can manually require the gem whenever required using require ‘gem_name’ . Hope you would have got an idea on Bundler & Gemfile in Ruby & Rails and we shall see some other interesting concepts in the future blogs. – Gomathi N, ROR Development Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2019-12-25"},
{"website": "Mallow-Tech", "title": "An Introduction for Dependency Injection in Swift", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2019/12/10796/", "abstract": "Dependency injection is a technique wherein one object will supply the dependencies of another object. To be more detail, dependency is an object that can be used, like a service and an injection defines, passing a dependency to a dependent object (a client/service) that would use it. Dependency Injection is mainly used with the intention of writing a code that is loosely coupled, thus, making it easier to test. When we use dependency injection in our code, we are essentially giving an object its instance variables. Here is a very basic example, that distinguishes default methodology and injection properties, In this example, we are defining a UIViewController class that declares a property, named requestManager, which is of type RequestManager? (Optional type) import UIKit\n\nclass ViewController: UIViewController {\n\n    var requestManager: RequestManager?\n\n} We can initialise the value of the requestManager property using the following, Without Dependency Injection This means to populate the ViewController class with the instantiation of the RequestManager instance. In this way, the view controller is in charge of creating the RequestManager instance. import UIKit\n\nclass ViewController: UIViewController {\n\n    var requestManager: RequestManager? = RequestManager()\n\n} This means, the ViewController class not only knows about the behaviour of the RequestManager class but also knows about its instantiation. With Dependency Injection Using dependency injection, we can inject the RequestManager instance into the ViewController instance. All though the end result may appear identical, it isn’t. By injecting the request manager instance object, the view controller doesn’t know how to instantiate the request manager. // Initialize View Controller\nlet viewController = ViewController()\n\n// Configure View Controller\nviewController.requestManager = RequestManager() Many developers mainly ignore the second option (with dependency injection) because it’s cumbersome and unnecessarily complex. But if we consider the benefits, then dependency injection becomes more appealing. Main benefits of this approach includes, 1. Loose coupling : It mainly makes the components less coupled and more reusable in different contexts coupling of objects especially in case of protocols. 2. Improve Testability : Unit testing is much easier while using dependency injection. It allows developers to replace an object’s dependencies with mock objects, which makes isolating behaviour and setting up unit tests easier and less complicated. 3. Improves Transparency : The responsibilities and requirements of a class or structure become more clear and transparent. By injecting a manager into a view controller, it is clear that the view controller depends on the request manager, providing better encapsulation. There are few types of dependency injection approaches particular to the usages like, property injection, constructor injection etc. We will deal with its types and mocking practices in the next blog. – Poorvitha Y, iOS Development Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2019-12-19"},
{"website": "Mallow-Tech", "title": "Jetpack Compose – The new way of UI design in Android", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2019/12/jetpack-compose-the-new-way-of-ui-design-in-android/", "abstract": "In android development, while designing the UIs we were using Linear layout, Relative layout and so on. Then, we have started with Constraint Layouts to design Complex UIs without nested layouts. And now it’s time to design the UIs on the next level. In Google IO ’19, Jetpack Compose was launched by Google to create a declarative UI. Basically, declarative UI means to create UI with a specific set of UI elements and to structure it in some way. So, you will not create or edit the XML layouts anymore. Instead of layouts, we will use Jetpack compose functions with UI as its elements. In this blog, we will come up with some basic elements from Jetpack compose. Implementation: To try Jetpack compose, you should use Android Studio 4.0 canary build. While creating the new project, need to select the “Empty compose activity” from the Project template. 1. Adding Jetpack compose toolkit dependencies implementation 'androidx.ui:ui-text:0.1.0-dev02'\nimplementation 'androidx.core:core-ktx:1.1.0'\nimplementation 'androidx.ui:ui-layout:0.1.0-dev02'\nimplementation 'androidx.ui:ui-material:0.1.0-dev02'\nimplementation 'androidx.ui:ui-tooling:0.1.0-dev02' 2. In Activity file We can write the design in setContent. Being new to Compose, let’s start with ‘Hello world’. override fun onCreate(savedInstanceState: Bundle?) {\n    super.onCreate(savedInstanceState)\n    setContent {\n\t//Write your design here\n\tText(text = \"Hello World!\", style = TextStyle(color = Color.Black, fontSize = Sp(16f)))\n     }\n} 3. Composable function Jetpack Compose is made up of composable functions. These functions will help you to design your UI programmatically by describing its shape and data dependencies. To write the composable function we need to use @Composable annotation as shown below. @Composable\nfun writeText(inputText: String) {\n    Text(text = \"Hello $inputText!\", style = TextStyle(color = Color.Black, fontSize = Sp(16f)))\n} Then, call this ‘writeText()’ function from ‘setContent{}’. Composable functions can be called only from another Composable function. 4. Function preview Instead of downloading the app in an Android device or emulator, you can easily preview your Composable function in Android Studio by adding @Preview annotation. The main limitation is that the Composable function should not take any parameters. So, you need to create one function named ‘previewWriteText()’ with @Preview annotation which calls ‘write text()’. @Preview\n@Composable\nfun previewWriteText() {\n    writeText(\"World\")\n} 5. Using layouts When it comes to Android app UI designing, you are not going to use one or two elements. You need to use many different elements to get an attractive design. If we need to design the UI with more elements, then will go with Linear layout, Relative layout or Constraint layouts to get the perfect design. To achieve the same in Jetpack compose we have to use some specific containers. For example, Column() is the one of the container. Column {\n\t    //Write your design here\n} As the name of the function describes, this will align the elements in the vertical order. Here we have an example with three Text() widget with some values in vertical order. @Composable\nfun showText() {\n     Column {\n\t   Text(\"Text Header\")\n\t   Text(\"Text Subject one\")\n\t   Text(\"Text subject two\")\n     }\n} As you might expect, you can use the Row() function to align the same widgets horizontally. Conclusion: In this blog, we have seen some basic elements from the Jetpack compose, which will help you step into this. However the Jetpack Compose is in Developer preview now, we may expect minor changes when it comes to a stable release. To read more about it try https://developer.android.com/jetpack/compose . -Sasikumar K, Android Team, Mallow technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2019-12-11"},
{"website": "Mallow-Tech", "title": "Updates to Location Permissions in iOS 13", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2019/11/updates-to-location-permissions-in-ios-13/", "abstract": "Back in June, Apple announced several major changes for location permissions in iOS 13 which was released in September. These changes are useful to end-users, that provides them a greater control and transparency on how apps are using their location Location service When the app needs to access your Location Services information for the first time, you’ll get a notification asking for permission. These are the options you can choose : Tap the ‘Allow’ option to let the app use Location Services information as needed. Tap the ‘Don’t Allow’ option, to prevent access. Tap the ‘Ask Next Time’ option, to choose Always While Using App, Allow Once, or Don’t Allow. Wi-Fi and Bluetooth might be considered by iOS, to determine your location. In the iPhone and iPad (Wi-Fi + Cellular) models, GPS and cellular locations are present. Uses Apple uses location service for the following stuff that helps us in our daily life and makes it simple, they are : Maps (directions) Camera (place ) Weather Four significant changes have been done in the recent version and they are: ‘Always Allow’ User-Flow (it has been updated) ‘Allow Once’ Permission Location Permission Map Bluetooth Permissions Always Allow : By choosing this “always allow” option we grant the app ‘background‘ location access, and the location is automatically accessed without the user’s permission. Allow once : This option allows the app one-time permission to use their location, ie whenever you open the app it gives access for that particular session. Location permission map : For apps that have granted the Always Allow location permissions, iOS 13 will periodically display a “map prompt”. The location points collected by the app, are displayed by the “map prompt”. In testing, they have identified that this prompt will be triggered after 3 consecutive days of background location use, and will continue to appear periodically with continued use. Background location use : If you give an app the permission to access your precise location, while it’s in use, the app then asks another prompt to know where you are at all times. In these cases, you will get a second prompt for permission to access the location even when you are not using the application. There are two options below, Keep Only While Using : This option gives the app, permission to access the exact location, but only when the app is running. Change to Always Allow : This gives the app permission to access your accurate location always. Bluetooth permission : iOS 13 will now show a specific permission prompt when an app attempts to access any Bluetooth service. Apps created for iOS 12, now running on 13, will trigger a generic version of the Bluetooth prompt To avoid unnecessary Bluetooth permission prompts, initiate and access Bluetooth iOS services only if and when your app needs them. I hope you might have got an idea on the updates made on the location permissions in iOS 13. Let us see some more interesting topics in the future blogs. -Karthick N, iOS Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2019-11-20"},
{"website": "Mallow-Tech", "title": "AWS CloudWatch Custom Metrics for Beanstalk Environment", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2019/11/aws-cloudwatch-custom-metrics-for-beanstalk-environment/", "abstract": "Amazon CloudWatch is a monitoring and observability service for AWS resources. Using CloudWatch you can collect monitoring and operational data in the form of logs, metrics and events. Also CloudWatch alarms can beset and used to send notification when a metric crosses a specific limit. CloudWatch metrics : CloudWatch metrics gives the users’ visibility into the resource utilisation, application performance and operational health. These can help you make sure that you can resolve technical issues and streamline processes and that the application runs smoothly. The following concepts are important for your understanding on CloudWatch metrics: Namespaces is a container for CloudWatch metrics. Metrics in different namespaces are isolated from each other so that metrics from different applications are not accidentally aggregated for computing statistics. Metrics represents a time ordered set of data points that are published to CloudWatch. It can be thought of as a variable that we need to monitor and the data points are the values of the variable over time. Metrics exist only in the region they are created. Dimensions is a name or a value pair that uniquely identifies a metric. You can assign a maximum of 10 dimensions to a metric. Dimensions help you design a structure for your statistics plan. Statistics are metric data aggregation over time specified by the user. Aggregation are made using the namespace, metric name, dimensions and the data point unit of measure within the time period you specify. Percentiles as the name suggests, the percentile indicates the relative standing of a value in a dataset. It helps you get a better understanding of the distribution of your metric data. Percentiles are used to detect anomalies. Alarms are used to initiate actions on your behalf. An alarm monitors a metric over a specified interval of time, and performs the assigned actions based on the value of the metric relative to a threshold over time. Why we need custom metrics? The default metric collection includes CPU Utilisation, Network Traffic and Disk Read/Writes. It does not include metrics to monitor Disk Space and Memory Usage. Hence, we are in the need of custom metrics if we want to monitor the Memory (RAM) usage and Disk space, of our instances. In order to implement the cloud watch custom metrics in your existing Beanstalk Environment, please follow the following steps, Prerequisites:- Elastic Beanstalk Environment with an application running on it. You should have a IAM user with full Administrator Access. Steps to implement custom metrics 1. In IAM console choose roles and select aws-elasticbeanstalk-ec2-role and click Attach policy , search for AWS managed policy named “CloudWatchAgentServerPolicy” and attach with this role. 2. Add the file “cloudwatch.config” in your codebase under “.ebextension” folder. So the file structure will be look like (/ .ebextension / cloudwatch.config) . If you don’t have “.ebextension” folder go ahead and create it, in the root of your application source code. 3. Add the following contents in your folder packages:\n  yum:\n    perl-DateTime: []\n    perl-Sys-Syslog: []\n    perl-LWP-Protocol-https: []\n    perl-Switch: []\n    perl-URI: []\n    perl-Bundle-LWP: []\n\nsources: \n  /opt/cloudwatch: https://aws-cloudwatch.s3.amazonaws.com/downloads/CloudWatchMonitoringScripts-1.2.1.zip\n  \ncontainer_commands:\n  01-setupcron:\n    command: |\n      echo '*/5 * * * * root perl /opt/cloudwatch/aws-scripts-mon/mon-put-instance-data.pl `{\"Fn::GetOptionSetting\" : { \"OptionName\" : \"CloudWatchMetrics\", \"DefaultValue\" : “—    mem-     util --disk-space-util --disk-path=/\" }}` >> /var/log/cwpump.log 2>&amp;1' > /etc/\t   cron.d/cwpump\n  02-changeperm:\n    command: chmod 644 /etc/cron.d/cwpump\n  03-changeperm:\n    command: chmod u+x /opt/cloudwatch/aws-scripts-mon/mon-put-instance-data.pl\n\noption_settings:\n  \"aws:autoscaling:launchconfiguration\" :\n    IamInstanceProfile : \"aws-elasticbeanstalk-ec2-role\"\n  \"aws:elasticbeanstalk:customoption\" :\n    CloudWatchMetrics : \"--mem-util --mem-used --mem-avail --disk-space-util --disk-space-\t  used --disk-space-avail --disk-path=/ --auto-scaling\" 4. Deploy the code to your environment. Thats it, now you have configured memory and disk space metrics for your environment. This script will continuously put the custom metrics to cloud watch every five minutes. The Custom Metrics can be viewed under Cloudwatch -> Metrics -> Linux System InstanceId section will give you the Memory utilisation metrics (RAM) for each individual instances in your environment. AutoScalingGroupName section will give you the Average Memory utilisation metrics (RAM) for your environment. Filesystem section will give you the Disk utilisation metrics for each individual instances in your environment. AutoScalingGroupName Filesystem section will give you the Average Disk utilisation for your environment. Creating Dashboard You can create your own dashboards for the above metrics by following the steps in the below Open the CloudWatch console In the navigation pane, choose Dashboards and then Create dashboard. Select the widget type you want and click Configure . Under Custom Namespaces choose Linux System and click AutoScalingGroupName and select the memory used checkbox and click Create widget . Click save dashboard . Similarly we can create as many custom dashboards we want. In the upcoming blogs we will see more about the CloudWatch events and rules to trigger some operation, when these metrics reaches a certain threshold value. https://github.com/mounick-mallow/AWS-CloudWatch -Mounick Raj T, DevOps Team, Mallow Technologies. Reference https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/mon-scripts.html Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2019-11-06"},
{"website": "Mallow-Tech", "title": "JSON Serialization in Rails – PART 2", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2019/10/json-serialization-in-rails-part-2/", "abstract": "In the previous blog post we learned some basics about JSON Serialization: how it works and how Active model serializer works. So far, we’ve been discussing mostly basic concepts with examples. Let’s see the other serializer Fast JSON API in detail in this blog. JSON API serialization is often one of the slowest parts of many well implemented Rails APIs. With use cases like infinite scroll on complex models and bulk update on index pages, you could observe degraded performance on our Rails APIs. With this being the case, the Fast JSON API has been built with their own object serialization library. Active Model Serializer (AMS) is designed to serialize JSON in several different formats, not just JSON:API and also handle lists that are not homogenous whereas on the other hand the Fast JSON API always use JSON:API for our APIs and almost always serialize a homogenous list of objects Fast JSON API is not a replacement for AMS. AMS is a great gem, and it does many things and is very flexible. It can still be used for non JSON:API serialization and deserialization. Fast JSONAPI is aimed at providing all the major functionality that Active Model Serializer (AMS) provides, along with more focus on speed and performance as mentioned in the previous post by meeting a benchmark requirement of being 25 times faster than AMS. When a model has one or more relationships, AMS begins to slow down. And on including related resources along with the primary resource, AMS slows down further. With Fast JSONAPI, it is mentioned that performance gain is significant when the number of serialized records increases. As far as the features are concerned, it provides all the major functionalities that AMS provides 1) Declaration syntax similar to Active Model Serializer 2) Support for belongs_to, has_many and has_one 3) Support for compound documents (included) 4) Optimized serialization of compound documents 5) Caching Syntax: class MovieSerializer\n  include FastJsonapi::ObjectSerializer\n  set_type :movie  # optional\n  cache_options enabled: true, cache_length: 12.hours\n  attributes :name, :year\n  has_many :actors\n  belongs_to :owner, record_type: :user\n  belongs_to :movie_type\nend Object Serialization Return a hash hash = MovieSerializer.new(movie).serializable_hash Return Serialized JSON json_string = MovieSerializer.new(movie).serialized_json Serialized Output {\n  \"data\": {\n    \"id\": \"3\",\n    \"type\": \"movie\",\n    \"attributes\": {\n      \"name\": \"test movie\",\n      \"year\": null\n    },\n    \"relationships\": {\n      \"actors\": {\n        \"data\": [\n          {\n            \"id\": \"1\",\n            \"type\": \"actor\"\n          },\n          {\n            \"id\": \"2\",\n            \"type\": \"actor\"\n          }\n        ]\n      },\n      \"owner\": {\n        \"data\": {\n          \"id\": \"3\",\n          \"type\": \"user\"\n        }\n      }\n    }\n  }\n} The block syntax can also be used to override the property on the object: class MovieSerializer\n  include FastJsonapi::ObjectSerializer\n\n  attribute :name do |object|\n    \"#{object.name} Part 2\"\n  end\nend So, Fast JSON API feels like better solution to use with Ruby on Rails. The response standard is great and saves time. Another reason why I prefer using Fast JSON API over AMS is that AMS’s latest update has been about three years ago. – Logesh M, ROR Team Lead, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2019-10-31"},
{"website": "Mallow-Tech", "title": "A Note on Agile Methodology", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2019/10/a-note-on-agile-methodology/", "abstract": "In the modern IT world, most of the well-known IT companies like IBM, Microsoft and AT&T use the AGILE process. Without doubt all must heard the term “AGILE” in the IT sector. What is AGILE? Agile is the iterative and time boxed approach to develop a high quality software, which builds the software incrementally from the beginning. It breaks down the project into the user functionality, said to be as “User stories”. It consists of the continuous production and deployment of the working software in the iterations of two to three weeks time period. So it moves on with each iteration, until all the iterations completed to build the final software (that contains all the features updated in each iteration), that satisfies the customer requirements. Each and every step of development is monitored continuously. It consists of self-organizing cross-functional teams with good collaborative and face to face interaction to share the ideas and updates of the project to improve the quality and efficiency of the project. Agile uses the adaptive approach for development of softwares. In a feature-driven development, the team needs to adapt to the changing product requirements dynamically. It helps in the rapidly changing environment, like the new features can be added as quickly as possible. What is Scrum? Scrum is a framework in the Agile methodology, to manage the project in an efficient and quick way. Basically, the Scrum consists of highly collaborative self-organizing cross-functional team with Scrum master – who acts as a coach or facilitator for the agile development team Product owners – who represents the business or user community Scrum team – contains the developers and testers Scrum is achieving the collaboration by making the daily Scrum meets, i.e. the daily standup called Scrum. The scrum meets will be held for roughly 15 minutes, where each team member discusses on the below What was done yesterday? What will be done today? Any issues faced by the team members and the updates that to be delivered in the scrum meeting. The development of the product consists of product backlogs, sprint backlogs and the user stories. Product backlogs: Product backlog is said to be a list of entire tasks, like the features and functionalities that has to be done within the system. The software should have a product backlog that contains a very large feature set. Multiple teams will work to give a efficient and high quality software to satisfy the client’s expectations. User Story: A user story is the functionality based requirement is shared from the client’s end. Sprint backlogs: The Sprint backlog is a subset of product backlog items that are selected for the sprint and planned for delivering the product incrementally. Sprint backlogs are forecasted by the development team to get functionality that should be in the next increment. The sprint backlog is a plan with enough details, the change in progress can be understood in the daily scrum. The development team can modify the sprint backlog throughout the scrum. Principles of Agile: Satisfying the customer requirements through the early and continuous delivery of valuable and high quality software. Adapting & accepting the changing requirements of the project. Completing the big projects quickly by breaking down it into smaller tasks. Making a daily meet with the project team and business owners for collaboration and sharing ideas. With the preference, the software is delivered continuously at two to three weeks time scale. By measuring the amount of the work completed, required motivation and support can be given to complete the project efficiently on time. The team members stay connected and active through daily face to face interactions and with the tools. Regular and continuous attention on the excellence in the technical and design of the project. The self-organizing cross-functional teams emerges the best architectural, requirements and design of the project. Merits of AGILE: The product quality is very high. The satisfaction of the customer is tremendous. ROI is faster because of the features that are delivered incrementally. Elimination of project risks. The detection of error, defects and fixing it is faster. The adaptation for the change and it’s response is faster. The deployment of the product is continuous and highly efficient. Share ideas with the team and can implement faster. Get the feedback faster for making the product better. Demerits of AGILE: The decisions are taken only by the senior programmers during the development process. There is a lack of importance on necessary documentation. Requires an experienced agile coach and it requires an expert to take important decisions on implementations. Agile is not suitable for the projects with the fixed scope, fixed budget and fixed time for which the projects all are pre-defined. If the project manager is not clear in the required outcome, the project would easily jump out of the track. In Agile, the testing can be performed concurrently with development. It satisfies the customer by the continuous deployment of the high quality software. The scrum is an implementation in agile methodologies that focuses on delivering the high business value.  Leadership plays a vital role in Agile. -Sudharsan, Testing Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2019-10-17"},
{"website": "Mallow-Tech", "title": "What’s new in iOS 13", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2019/10/whats-new-in-ios13/", "abstract": "iOS 13 introduces a huge collection of improvements for developers in frameworks, APIs, features, and designs. Let’s see few of the important improvements here. Improvements in Design: 1) Dark Mode: In iOS 13, we have got a system-wide dark mode. Here are two options, as per the client’s requirement we can support our app in light mode or dark mode or both with the help of Xcode 11. It is a useful feature specially at night when bright hues will be a nightmare. It may also save battery life on the OLED-equipped iPhones, from the iPhone X onwards. This did not come from the mouths of Apple, but we know that OLED will initiate ‘turn off’ pixels when they are into black. 2) SF symbols and Icons iOS 13 added new icons and symbols to make our apps more appealing. Symbol images use the SVG format to implement vector-based shapes that scale without losing their sharpness. They also support many traits typically associated with text, such as weight and baseline alignment. 3) SwiftUI Xcode 11 has brought a new way of designing the user interface known as SwiftUI. For a long time, we’ve had to choose between seeing our UI in a storyboard or having a more maintainable option with programmatic UI. Even though storyboards and XIBs have given us what we needed, not everyone is fond of them. SwiftUI is a replacement of storyboard and Xib’s, there is a new way of declarative UI structure that defines how our layouts look and work. Once the UI preview is updated, it automatically generates new Swift code and when the Swift code is changed the UI preview is updated. Even-though it uses controls from UIKit and Appkit frameworks, there are features to be aware of before you dive headfirst into SwiftUI. First, it’s Swift only, we can’t use SwiftUI from Objective-C and we don’t rely on actions and outlets in swift UI .There we use both storyboard and swift UI. Improvements in Features: 1) Multi-window support: In iOS 13, multiple windows are supported. Here they have handled a lot of new APIs like UIWindowScene, UIScene. With the help of this feature, we can chat on one screen and watch videos on the nearby screen. And we can create multiple UI instances on the same app. With this, we can switch between different screens on the application at the same time. Through the app switcher, we can see the different scene snapshots, so can decide to switch over on the particular screen. From a developer perspective, we have to be aware of the new scene delegate life cycle methods. Those delegate methods help to do some works on the particular scene state but the app delegate will define the application state i.e launching and terminating. 2) QuickPath Keyboard: iOS 13 has Apple’s default QuickType keyboard that is the swipe-to-type functionality, a common way of sliding across the keyboard which automatically forms words. We’ve used this in prior iOS keyboard extensions like Google’s G board and SwiftKey. You can use the QuickType and QuickPath methods of typing interchangeably, and so far supported languages include English, Simplified Chinese, Spanish, German, French, Italian, and Portuguese. 3) Silence Unknown calls: Nuisance spam calls drive us crazy every day, and iOS 13 wants to fix the issue with the help of Siri, which scans your Contacts, Mail, and Messages to check if you’ve contacted the caller previously.Silence Unknown Calls sounds fairly smart if you’re not expecting business numbers calling you for work. Those who call you and aren’t on your personal ‘VIP list’ will go straight to voicemail. 4) Photo editing tool: Photo editing tools get advanced: Photos now can be edited in 15 different ways. It’s more robust to the point where we’re opening Adobe Lightroom less. Videos also can be edited, and photos can be edited without damaging the Live Photo properties. 5) Facetime Correction: We know that thing in a FaceTime calling when you are looking at the screen, the eye contact will be on the downside of another side. Apple fixed this issue in iOS 13 with the help of AI to move the direction of gaze. And then it supports iPhone 10 and later mobiles 6) Connect to wifi and Bluetooth from the control centre: This is huge – and we’ve been asking for it for several years. You can now select Wi‑Fi networks and Bluetooth accessories right from Control Centre. Android has been always a step ahead, it has always managed to connect to new Wi-Fi networks or Bluetooth earbuds without moving away from your current app and dive into five Settings submenus. Apple is finally coming around in iOS 13. 7) Face ID: Unlocking your phone with our face is wider, so looking at the phone on the desk will open your iPhone up without needing to lift the handset. It helps to unlock the handset very quickly. 8) Contextual menus: Developers are aware of contextual menus feature, it will help to provide people access to additional functionality related to onscreen items without cluttering the interface. It supports only in  devices with iOS 13. Improvements in Privacy: 1) Sign in with Apple id: Signing in with Apple is made easy for users to sign in to apps and websites using the Apple ID. One doesn’t have to fill out forms, verify email addresses, and choose new passwords, they can just Sign in with Apple to set up an account and start using the app. A two-factor authentication are used for superior security for all the accounts, and users’ activity will not be tracked in the app or website. 2) Location permission: Apple improves the tracking transparency in location permission alert. In iOS12 we can provide permission ‘Always allow’ as an option to track the user’s current location always. Now they have changed the option to allow once. When the application is tracking the location in the background ,then it will show another prompt with ‘always allow’ option. Apple is also making it more transparent by checking how often an app accesses your location. A map is created, including the locations the app has checked in the background by giving a periodic alert and asks if you want to keep the apps settings how they are. 3) Bluetooth permission: In iOS 13 they provide Bluetooth access permission when the app opens in the first time itself. If we denied the request the Bluetooth functionality will not be working in the application. Hope, my points would have given you a glimpse on the important improvements of iOS 13 and if you look for deeper knowledge in these topics please refer to the WWDC videos 2019 keynote Kannan A, iOS Team , Mallow Technologies . Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2019-10-09"},
{"website": "Mallow-Tech", "title": "Monitor the Application Performance with Retrace", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2019/09/monitor-the-application-performance-with-retrace/", "abstract": "What is retrace? Retrace is a tool for monitoring the Application Performance (Application Performance Monitoring tool – APM). It combines several tools in one by performing code level server monitoring, performance profiling, centralised application logging, application monitoring, error tracking, and more. Retrace is an affordable alternative to expensive products like New Relic, AppDynamics, Dynatrace, and others. Features: – App Performance Management APM solutions collect a lot of data about the performance of our applications. Only Retrace combines all of this data into an easy to understand App Score. Retrace allows you to monitor your user satisfaction. By using the industry-standard apdex scoring, Retrace can identify which requests are fast, sluggish, too slow, or failed. Satisfaction scoring enables you to monitor your application’s performance readily in real-time. Deployment monitoring from Retrace makes it simple to see if your application’s output has altered as a result of deployment. And recognise rapidly if performance or error rates have changed from deployment to deployment. And also finds the slowest part of the application (like SQL query, Redis or even specific HTTP web service down or slow). Retrace track your top SQL queries rapidly depending on the number of executions or their percentage of total time. It defines each SQL query you perform, providing you very thorough reporting. – Code Profiling Retrace monitors only your code’s main techniques and is secure for use in production. In this APM, all standard application frameworks and dependencies are automatically supported. It also gathers detailed snapshots of what is being done by your code and how long it takes. Retrace tracks each of your code’s SQL queries. This includes how long they take as well as other key details. Most applications leverage multiple external web services. Retrace will monitor usage and efficiency wherever HTTP requests are made by your code. Almost all kinds of HTTP demands are endorsed automatically. It can be very complex to profile and understand the efficiency of async software. Retrace promotes contemporary models of async design for. NET and Java. Dozens of common frameworks are supported out of the box with no code changes. – Error Tracking The powerful code profiling of Retrace can even track errors that you don’t log. Identify large spikes in errors quickly before affecting all of your customers. Notify yourself when a fresh form of mistake is found in your app. Identify new mistakes that occur immediately after a fresh deployment. Monitor error rates to guarantee the smooth running of your application. Some errors occur all the time and are fundamentally noise. They may be mistakes you may not be able to solve in your software, or they may be random SQL timeouts or similar mistakes. You can ignore certain mistakes with Retrace. If you need to see them, they are still being tracked, but they are being suppressed from normal reporting so they don’t skew your reporting. Retrace gathers a lot of background information about what happens when you throw an error. For error reporting reasons, this information can be very helpful. – Centralised Logging Access all your application logs in all apps and servers from a single location. Get the complete error context that appears in your records. Logging objects and searchable characteristics make our logging smarter. For your log messages and filtering on any captured areas, full-text searching is accessible. For stuff like app name, environment, server name, log type, and log level, several fast filters are readily available. All you need to do is placed a # in your records, and Retrace will be responsible for tagging. – App & Server Metrics Easily create custom dashboards to track what’s important. Retrace can easily monitor applications that scale up and down. Retrace’s powerful combination of APM, error tracking, log management, and application metrics creates an unparalleled ability to monitor your applications. Retrace tracks each of your Windows & Linux servers automatically. You can even configure your server’s monitoring templates. From this blog, you would have known the features and significance of retrace. We shall see its integration with Laravel in our future blogs. -Poovarasu PHP Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2019-09-25"},
{"website": "Mallow-Tech", "title": "Interesting features of Android Q", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2019/09/interesting-features-of-android-q/", "abstract": "Google released Android 10(Android Q), a major release of the Android Mobile operating system, on Sep 3, 2019. Google has added many new features to its latest Mobile Operating System Android Q or Android 10. Android 10 has major enhancements in user experience, privacy and security. The main note is Google abandons the convention of naming the Android versions with a  dessert name from Android 10. Android 10 new features: 1. Foldable Phone Support Android 10 system, building on robust multi-window support and extends multitasking across application windows and provides screen continuity to maintain your application state as the device folds or unfolds.  Android 10 added the number of improvements in OnResume and OnPause to Support multi-resume and notify the application when it had focused. 2. Dark Mode Android 10 adds a system-wide dark theme ideal for low light and helps save battery. Users can activate a new system-wide dark theme by going to Settings or turning on Battery Saver. This changes the device UI to dark and enables the dark theme of apps that support it. In the Android 10 operating system ,Power Mode will get Dark Mode feature. 3. Gesture Navigation The gesture navigation feature of Android 10 will help users to access Google Assistant by simply swiping the screen from any corner. 4. Sharing Shortcut Earlier, the sharing functionality was too lazy, when the user taps on the share button, the user has to wait for few seconds while the share sheet is loading. In Android 10, the share sheets will load instantly via Sharing shortcuts. App developers can add their shortcuts to the system shortcut manager so that the system is aware of the share shortcuts. 5. Privacy and Permissions Android 10 system, central focused on Privacy and stronger protections in the platform to new features designed with privacy in mind.  Android 10 includes extensive changes to protect the privacy and give users more control, with improved system UI, stricter permissions, and restrictions. See the Privacy and permissions. 6. Device Location Android 10 system, users will get more control when they get a location. This will make the app work, only when it is running or in the background all the time. The user can ever allow the app to view the location. 7. Emergency Shortcut Android 10 system also includes a new Emergency Button, which can be accessed from Power Menu. Through this, the user will be able to call Emergency calls in a short time. 8. Smart Reply in notifications Android 10 also includes a on-device ML to suggest contextual actions in notifications, such as smart replies for messages or opening a map for an address in the notification. The application can take advantage of this feature right away, without the need to do anything. The system provided smart replies and actions are inserted directly into notifications by default. 9. Screenshot Notch Android 10 Operating System Mobile answer, will remove your screenshot and your notch will also be there. Well, it was needed, but it has support in the new operating system of Android 10. 10. Scope Storage This will give you more control over access to Shared files. Will also be handy to the users to control the access of the app to photos, video, and audio collection through new runtime permissions. Android 10 has currently rolled out to Google Pixel phones and the exciting news is that others will get the new version soon. The striking feature is, with every new release Google packs some new stuff in its already awesome operating system. Though various new features are introduced, Android still manages to keep it user friendly. Users who got the new stuff, Enjoy!. Manikandan K, Android Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2019-09-18"},
{"website": "Mallow-Tech", "title": "What’s New in Swift 5", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2019/09/whats-new-in-swift-5/", "abstract": "Swift 5 is the major evolution for all Apple developers. In Swift 5, they have introduced many standard library and compiler updates. In this blog we will cover some of the important proposals accepted in Swift Evolution. ABI Stability One of the most important part of Swift 5 is the ABI stability. It enables binary compatibility to our application and library compiled with different version of Swift. Function isMultiple(of:) Swift 5 implemented a new function isMultiple(of:) for integers, to check if a given number is a multiple of another number. let isMultipleOfTwo = 4.isMultiple(of: 2) Raw String Swift 5 also adds raw strings. We can add # at the beginning and end of the string, so we can use backslashes and quote marks without any issue. Since we don’t need to escape backslashes in raw strings, in regex we can use only half the number of backslashes. let backSlashString = #\"\" Without Backslash\"\"#\nlet multilineInterpolation = #\"\"\"\nMultiline string with\n\\#(backSlashString)\n\"\"\"# Function compactMapValues() Swift 5 introduced a new function for effectively mapping and filtering dictionary values called compactMapValues(_:) let data = [\"a\": \"1\", \"b\": \"three\", \"c\": \"///4///\"]\nlet resultValues: [String: Int] = data.compactMapValues { str in Int(str) } // [\"a\": 1] Result Type Swift community added an entirely new type called Result in Swift. This type has two cases .success associated with any value and .failure associated with Error protocol. public enum Result<Success, Failure: Error> {\n    case success(Success), failure(Failure)\n}\n\nenum NetworkError: Error {\n    case noResponse\n    case noNetwork\n}\n\nstruct User: Decodable {\n    let id: Int\n    let name: String\n\n    enum CodingKeys: String, CodingKey {\n        case id\n        case name = \"first_name\"\n    }\n}\n\nfunc getUser(from urlString: URL, completionHandler: @escaping (Result<User, NetworkError>) -> Void)  {\n    Alamofire.request(url, method: .get, parameters: nil, encoding: JSONEncoding.default, headers: [:]).validate().responseJSON(completionHandler: { (response) in\n        switch response.result {\n        case .success:\n            let jsonDecoder = JSONDecoder()\n            let data = response.data\n            do {\n                let list: [User] = try jsonDecoder.decode([User].self, from: data)\n                completionHandler(.success(list))\n            } catch {\n                completionHandler(.failure(NetworkError.noResponse))\n            }\n        case .failure(let error):\n            completionHandler(.failure(NetworkError.noResponse))\n        }\n    })\n} Future Enum case In Swift 5.0, a new @unknown keyword can be added to the default switch case. The @unknown keyword will trigger a warning, if we use non-exhaustive switch statement. switch CLLocationManager.authorizationStatus() {\ncase .authorizedWhenInUse, .authorizedAlways, .denied, .restricted:\n    break\n@unknown default:\n    break\n} Flatten Optionals In Swift 5 flattens ‘try?’ gives us the same behaviour as ‘as?’ and optional chaining. Thereby it eliminates nested optionals. struct NewUser {\n    var id: Int?\n    init?(id: Int) throws {\n        if id < 1 {\n            return nil\n        }\n        self.id = id\n    }\n}\n\nvar newUserId = try? NewUser(id: 1)?.id // Swift 4.2 newUserId?? : Swift 5 newUserId? Conclusion In this blog, we have learnt about important updates in Swift standard library, which will be helpful in developer productivity. You can view the entire list of updates here . Please check here to view recent proposals . It will be great to contribute in Swift Evolution which is open for all. Srikanth Thangavel iOS Team , Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2019-09-11"},
{"website": "Mallow-Tech", "title": "Save Time with Worktree in GIT", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2019/08/save-time-with-worktree-in-git/", "abstract": "Imagine working on a new feature on a branch and this feature is going to scoop too much time for completion. While working on the new feature, the tools, IDE, etc, unexpectedly a critical issue comes up in the production code where a quick patch is needed. Back to master and then to a new patch branch might result in shutting the application down, turning the tools off, probably closing the workspace in the IDE and stashing the uncommitted changes. This method of switching will be costly when repeated frequently. Instead of stashing or committing a code, one can create sub branches without interrupting the work. What is worktree? Worktree handles multiple working trees attached to the same repository. A git repository can support multiple working trees, allowing you to check out more than one branch at a time, eventually saves a lot of time. Use of Worktree? For example, When I’m working on a branch called feature and some high-urgency bug in master is reported or build needed from current production branch for testing, I usually stash away whatever I’m working on and create a new branch. When I’m done, I can continue working. This is a very simple model, I’ve been working like that for years. But now Instead of stashing or committing the code with the help of work tree we can create multiple sub branches and switch between branches without interrupting our work on the new feature. How to create Worktree? The following are some simple and quick commands to get you started: Create a new working tree at <path> and checkout <branch> in the new working tree: git worktree add <path> <branch> Using “git worktree add”  a new working tree is added with the repository. The resultant Worktree is called a linked working tree and the source Worktree is called main working tree prepared by git init or git clone. A repository contains one main working tree and either none or more linked working trees. To remove a linked working tree use “git worktree remove”. Prune working trees after deleting their files with: git Worktree prune Now that a new and a better solution to all the stashing and committing issues has been found, all one has to do is make use of the Worktree and save a lump of time. Indirajith M, Android Team , Mallow Technologies . Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2019-08-28"},
{"website": "Mallow-Tech", "title": "Scriptless Test Automation", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2019/08/scriptless-test-automation/", "abstract": "Automation Testing is the use of a separate software to control the execution of test scripts and compare the Predicted outcomes with the Actual outcomes. Test Automation can automate repetitive but necessary task in a formalised testing and also it may be critical for continuous testing and delivery of the software. This will give a complete overview about the script less test automation framework.There are various levels of automation testing to know before getting deep into the script less automation, the levels are: Scripting / Coding Scriptless Advanced Automation using Artificial Intelligence Scripting / Coding The name itself indicates that this requires the Program or a Set of codes to automate the test or process to verify whether the functionality is working as per the requirement. For example: If you are planning to do Unit testing for a particular functionality or a class you must need to create a Code or a script to test. There is no other way to automate your unit test without coding or script. In general, automation tools requires the testers to create some code or a script for providing test input and execution of automated test result, In such a way the Automation Tools are categorised in levels. Scriptless Scriptless test means it enables the tester to automate the test scenarios and test cases without worrying about the coding, It helps to achieve faster result and reduces the time to understand the code and logics. Advanced Automation using Artificial Intelligence This is the highest level of automation and this can be achieved by Creating the test scripts from the test scenarios or test case documents Auto – correcting the changes based on the new changes in the application or software for the effective regression testing Auto – generation of the Test scripts based on the user action and use case scenarios when the application under test – this is the advanced version of Traditional Record and Playback feature Auto validation of the result / Output by the automated script based on Machine Learning without the user inputs on what needs to be validated and test analytics There are various kinds of Script-less Automation Tools available, Some of the tools are listed below. Test Craft AccelQ Ranorex Studio Carnia GoogleEarlGrey mabl TestCafe Studio Leapwork TestArchitect Benefits of the Scriptless automation tools: Testers does not require any mandatory programming or scripting skills Apart from the testers (who are the primary consumers of Scriptless automation), the framework usage can be extended to the Product owners (in the Agile world), and Business Analysts as well for setting up and executing the User Acceptance Tests (UAT). Quicker development of automated tests that perfectly fit into the Agile Process Offers flexibility for both native and advanced users. Less ‘test’ related errors as the underlying Scriptless framework would have been tested thoroughly. This, in turn, reduces the time spent on debugging and fixing test related issues. Easier maintenance of the overall automation suite. We hope this article would have given you a short idea about the script less automation and its benefits. The future of Software Testing will be more effective with the Automated Tools. Manikandan S, Testing team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2019-08-21"},
{"website": "Mallow-Tech", "title": "Introduction of androidX ViewPager2", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2019/08/introduction-of-androidx-viewpager2/", "abstract": "The lesser the text, the better the experience. But delivering the content is equally important. Why dump all the words in one page when you can split it into pages and acme them with a swipe? View pager supports this and ensures to deliver more content by separating them into pages. The previous version of Android, supported only left to right and right to left swipes. Now androidX supports viewpager2 which lists the below additional features. Android Viewpager2 Beta version was launched by Google on August 7, 2019. You can find detailed information about the release here . New concepts: The additional features introduced in Android ViewPager2 are listed below Right to Left layout support Vertical orientation support A better PageChangeListener API changes : Android ViewPager2 has been updated with some improvements, such as RecylerView.Adapter replaces PagerAdapter FragementStateAdapter replaces FragementStatePagerAdapter RegisterOnPageChangeCallback replaces addPageChangeListener ViewPager2 is included for AndroidX, if this has to be used in your project then the project must be migrated to AndroidX and minSdkVersion should be 14 or higher. For example, Gradle Dependency: Add the following dependency to your app build.gradle. dependencies { \n\n    implementation 'androidx.viewpager2:viewpager2:1.0.0-beta03'\n} Setup ViewPager2: Adding android viewPager2 widget to your XML file activity_main.xml <?xml version=\"1.0\" encoding=\"utf-8\"?>\n<androidx.constraintlayout.widget.ConstraintLayout\n        xmlns:android=\"http://schemas.android.com/apk/res/android\"\n        xmlns:tools=\"http://schemas.android.com/tools\"\n        xmlns:app=\"http://schemas.android.com/apk/res-auto\"\n        android:layout_width=\"match_parent\"\n        android:background=\"@color/colorPrimaryDark\"\n        android:layout_height=\"match_parent\"\n        tools:context=\".MainActivity\">\n\n    <androidx.viewpager2.widget.ViewPager2\n            android:id=\"@+id/view_pager\"\n            android:layout_width=\"wrap_content\"\n            android:layout_height=\"wrap_content\"\n            app:layout_constraintBottom_toBottomOf=\"parent\"\n            app:layout_constraintLeft_toLeftOf=\"parent\"\n            app:layout_constraintRight_toRightOf=\"parent\"\n            app:layout_constraintTop_toTopOf=\"parent\"/>\n\n</androidx.constraintlayout.widget.ConstraintLayout> Lets create layouts on viewpager2: We need to create the adapter for viewPager2. This is the best part of RecylerView.Adapter and the sample code follows class CountryPagerAdapter(private val countryStrings: Array<String>) : RecyclerView.Adapter<CountryViewHolder>() {\n    override fun onCreateViewHolder(parent: ViewGroup, viewType: Int): CountryViewHolder {\n        return CountryViewHolder(\n            LayoutInflater.from(parent.context).inflate(\n                R.layout.country_list_item,\n                parent,\n                false\n            )\n        )\n    }\n\n    override fun onBindViewHolder(holder: CountryViewHolder, position: Int) {\n        holder.countryName.text = countryStrings[position]\n    }\n\n    override fun getItemCount() = countryStrings.size\n}\n\n\nRecyclerView.ViewHolder\n\nclass CountryViewHolder(view: View) : RecyclerView.ViewHolder(view) {\n\n    val countryName: TextView = view.findViewById(R.id.country_name)\n} To create adapter for Viewpager2, an instance of RecylerView adapter has to be created viewPager.adapter = CountryPagerAdapter(Country.countryStrings) We can set the orientation for vertical scrolling viewPager.orientation = ViewPager2.ORIENTATION_VERTICAL You can find the sample application here for reference. From this blog, we got to know the benefits of preferring viewpager2. As days go by, the android version we are using will soon be outdated and updating ourselves to the changing trend is much more important to keep us in the track. We shall see the further updates in the future blogs. – Manikandan K, Android Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2019-08-14"},
{"website": "Mallow-Tech", "title": "JSON Serialization in Rails – PART 1", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2019/08/json-serialization-in-rails-part-1/", "abstract": "What is JSON? JSON (JavaScript Object Notation) is a format that can be used to store or exchange data. It is easy to read by humans and easy to parse by machines, which is why a lot of APIs use JSON. What does the term Serialization refer to? Serialization in Rails programming is a reference to formatting the JSON output of an API so that each record is unique and carries with it the desired data. There have been a few attempts at standardizing Rails JSON output, with corresponding Ruby gems to do the job. The most common were called “Active Model” serializers. ActiveModelSerializer: ActiveModelSerializers brings convention over configuration to your JSON generation. ActiveModelSerializers works through two components: serializers and adapters. Serializers describe which attributes and relationships should be serialized. Adapters describe how attributes and relationships should be serialized. ActiveModel::Serializer provides a way of creating custom JSON by representing each resource as a class that inherits from ActiveModel::Serializer. With that in mind, it gives us a better way of testing compared to other methods. Add the following gem to your Gemfile: gem 'active_model_serializers', '0.9.3' Then install it using bundle: bundle install You can generate a serializer as follows: rails g serializer post The above generator will create a serializer in app/serializers/post_serializer.rb with the following content: # app/serializers/post_serializer.rb\nclass PostSerializer < ActiveModel::Serializer\nend It is very easy to create complex JSON responses using ActiveModel::Serializer, but it’s strongly discouraged. The following examples use basic constraints that you can follow. It should serve the goal of simple and maintainable serializers. # app/serializers/post_serializer.rb\nclass PostSerializer < ActiveModel::Serializer\n  attributes :title, :description\n  has_many :comments\nend It is possible to automatically include all attributes of a model, but it will introduce the risk of accidentally sending sensitive data to the client. It also floods the client with unnecessary data. This is strongly discouraged unless the model has a small attribute set and they rarely change. In that case, the serializer below serves the purpose of a simple serializer example that includes all attributes automatically # app/serializers/post_serializer.rb\nclass PostSerializer < ActiveModel::Serializer\n  attributes *Post.column_names\nend Response of the API looked like before the serializer: {\n  \"id\": 1,\n  \"title\": 'Test 123',\n  \"description\": 'Test',\n  \"created_at\": '2019-08-08 02:36:37.199806',\n  \"updated_at\": '2019-08-08 02:36:37.199806'\n},\n{\n  \"id\": 2,\n  \"title\": 'Test 124',\n  \"description\": 'Test',\n  \"created_at\": '2019-08-08 02:36:37.199806',\n  \"updated_at\": '2019-08-08 02:36:37.199806'\n},\n{\n  \"id\": 3,\n  \"title\": 'Test 125',\n  \"description\": 'Test',\n  \"created_at\": '2019-08-08 02:36:37.199806',\n  \"updated_at\": '2019-08-08 02:36:37.199806'\n} After implementing the serializer, the API response looked like this: {\n  \"id\": 1,\n  \"title\": 'Test 123',\n  \"description\": 'Test',\n  \"created_at\": '2019-08-08 02:36:37.199806',\n  \"updated_at\": '2019-08-08 02:36:37.199806',\n  \"comments\": [\n    {\n      \"id\": 6,\n      \"post_id\": 1,\n      \"content\": 'Test comment'\n    }\n  ]\n} The larger your responses get, you will experience the serialization bottleneck that Rails has long suffered from, partially due to ActiveModel::Serializers. ActiveModelSerializer  is a large library supporting multiple specs, not just JSON API, so it supports many things but not specifically built for high performing API. Performance is critical to us and to solve this we could use Fast JSON API by Netflix https://github.com/Netflix/fast_jsonapi The Netflix JSON serializer is simply called “Fast JSON API.” It presents data in accordance with the new JSON 1.0 standard. But it’s also, well, FAST. According to its own GitHub post “serialization time is at least 25 times faster than Active Model serializers on up to current benchmarks of 1000 records”. Using the serializer isn’t hard at all. It really involves just three things: installing/including the gem, creating a serializer, then calling that serializer in the appropriate controller action. You even get access to automatic generation of serializers via “rails generate” commands. It’s all pretty solid, actually! To get going just go to https://github.com/Netflix/fast_jsonapi and follow the very simple instructions. We will look into Netflix Fast JSON API in next part describing in more detail. – Logesh M, ROR Team Lead, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2019-08-07"},
{"website": "Mallow-Tech", "title": "LARAVEL TELESCOPE – A Debugging Tool", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2019/07/laravel-telescope-a-debugging-tool/", "abstract": "Debugging is a multi-step process that involves in the identification of bugs and errors which can be handled by using debugging tools. The use of debugging tools helps us in identifying various bugs in our application. Laravel Telescope is an open source debugging assistant for the Laravel framework written by Taylor Otwell. Laravel Telescope is free on Github and it can be pulled into your project application as a dependency using the composer. It can also be installed for local development by using the dev flag. Once installed, it can be accessed by visiting the route /telescope of the application which opens up an interactive user interface to monitor various aspects of your project. Basically telescope comprises of a series of watchers that constantly ‘watch’ every request. TOP FEATURES OF LARAVEL TELESCOPE: Telescope provides monitoring capabilities for monitoring the requests that come into your application including commands, scheduled commands, jobs, exceptions, logs, dumps, queries, models, events, mails, notifications and cache activities. Telescope consists of a primary configuration file that allows the developer to configure based on his needs at the config/telescope.php. This file allows us to customize the watcher options. One of the major features of telescope is data pruning. When data pruning is activated, the records will get cleared so that the database doesn’t  accumulate with the data, once in 24 hours. By scheduling the command in Laravel, we can customize the time interval at which it should run. You can also modify the number of queries that are being allowed at a time. The default Telescope_limit is 100. You can configure it based on your needs. The Laravel TelescopeServiceProvider allows us to filter the data monitored by the telescope by filter callback that is registered in the service provider. By default, telescope monitors and stores all the data and it can be customized based on the needs. Telescope watchers gather application data when a request or console command is executed. You may customize the list of watchers that you would like to enable within your config/telescope.php configuration file. There are several watchers that can be added as per our use cases. The Telescope watchers collect the application data when any request or activity is executed in your application. In the config/telescope.php configuration file, you can explicitly specify the list of watchers that you want to enable and the activity is monitored and stored based on the watchers you specify. The Cache watcher records all the cache hits and deletes. You can see the cache key, its own expiration time and time regarding its creation. Redis watcher is also similar to the Cache watcher.  It records all the time taken, and request initiated time in Redis. The command watcher records all the commands that are being run in the application and their exit codes including all the arguments along with options of the command. The dump watcher records and displays your variable dumps in Telescope. In Laravel, when you use dump() method you will get the data on the dump screen in the Telescope. When the dump screen is initiated on the Telescope all the dumps in the application gets directed to the telescope and it doesn’t affect the running of the application on the browser. But once the dump screen is closed, all of a sudden all the dump contents get displayed on the actual browser. The event watcher enables you to monitor all the events that has been triggered by your application. You can see all the events that are broadcasted with a tag on it. It also stores all the data regarding the event occurrence. The mail watcher shows all the e-mails sent, it’s timing, recipients and the status whether it is queued or sent. We can see the entire mail along with its content and it can also be downloaded as an .eml file and can be opened. The query watcher records the SQL queries that have been executed throughout the application. It also shows the nature and speed of the query and differentiates it based on various aspects like response time There are a lot more watchers that are supported in telescope and they serve their purpose accordingly. Authorization can be enabled in Telescope where you can add a list of emails in the Telescope service provider thereby providing them access on production. Telescope can be run on both local and in production environment. If used in production environment, it is best to move the telescope in a separate database for easier handling. Telescope also has built-in authorization and tools for protecting private data. You can also ensure private data doesn’t get logged on production. So from this post we have seen the various features of Laravel Telescope. It is both development friendly and production friendly. Thus the use of Laravel Telescope will make it easier for the process of monitoring and debugging. Ajit T., PHP Team, Mallow technologies Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2019-07-24"},
{"website": "Mallow-Tech", "title": "Why End-to-End Solutions ?", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2019/07/why-end-to-end-solutions/", "abstract": "Software development is a vast area, where none can limit themselves to one domain. To create an application, choosing the correct software solution might be a nightmare and appointing different development companies for each module is a hard task. Clarifying the requirement to each group of developers and receiving the expected output might add to the burden. And as a client, Partnering up with the right and trustworthy developer is the crucial element for the idea to move forward. What if there was a way to sort all of the above ? Then won’t it be the most sought after option? One such way is the end-to-end solution . What does end-to-end solution mean? The very common meaning of end-to-end solution is that, a company takes up a service for a client completely from the beginning of the project till the end which includes installation, integration, setup and support of the software. Adding to this, the client will be provided with all the hardware requirements and consultations regarding the service whenever needed. To sum it up, one organisation will provide overall service for a project thereby easing the client to deal with the same organisation for all the services. Benefits of end-to-end solutions Increased efficiency: The increased productivity generated by end-to-end solution is the reason for this to be the most preferred option. The whole system is integrated by a single organisation, reducing the use of a middle man and related consequences. The overall process is streamlined and operates in a flow, as the organisation decides the priority of tasks thereby increasing the efficiency and performance. Cost cutting solution: This is an apparent reason and is also the main selling factor. For instance, when a Client uses different organisations for a single project, managing all the software would require additional man power which eventually increases the cost of the project . If a single organisation takes care of the whole process then the hassle is reduced, work is streamlined and the expense is lowered. Ease of learning: When a system throughout is handled by a single organisation, developers can learn quickly and upgrade for advancements along the process. If different companies take up individual tasks, the learning factor will be interrogative and advancements will be detained. Faster solutions to problems: An organisation providing end-to-end solution, will have complete knowledge of the project. Hence all the solutions are preplanned and issues are avoided. Incase any problem arises, it will be tackled within thereby minimising disruption. The overall process is speeded up, increasing the efficiency. Maintains pace in a changing environment: Generally end-to-end solutions are provided by organisations that offer a complete system .Thus they maintain their pace even if they are in a constantly changing environment i.e. changing requirements and demands. Inspite of those changes, the outcome meets expectation which adds to the good factor of end-to-end solutions Transparent process: This is one feature that multiple companies working for a single client cannot give.Whatever be the data, it is shared across the organisation crossing all the needed levels. The beneficial factor is that the areas that need improvement are identified easily and are improved. All the developers and the client will have an idea of what is going on in the project . Businesses are in search of the best end-to-end solutions and here we provide it with the best quality. Sowndarya Rasappan, Business Analyst – Intern, Mallow Technologies Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2019-07-17"},
{"website": "Mallow-Tech", "title": "A BRIEF INTRODUCTION TO KOTLIN SCOPE FUNCTIONS", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2019/07/a-brief-introduction-to-kotlin-scope-functions/", "abstract": "Earlier we have given a brief overview on Kotlin and now we follow up with one of the interesting topics in Kotlin i.e Scope functions. Scope functions help us in the process of simplifying the logics used in the block. The Kotlin standard library contains several functions and purpose of each is to execute a block of code within the given context. The Scope function is also similar to other functions with the difference that it takes on an object with a lambda expression which forms a temporary scope and we can access the object without its name. The Scope functions are of five types as 1) let 2) with 3) run 4) apply 5) also There are mainly two difference between each scope function. They are : 1) The way to refer the context of the object 2) The return value Context object : Each scope function uses one of the two ways to access the context object : this & it . this is called lambda receiver & it is called lambda argument. We will see in more detailed way about its usage in the below examples. Return value : 1) apply & also return the context object. 2) let , run & with return the lambda result. Let’s now dive deep into the scope function types & its usage let The context object is available as an argument ( it ). The return value is the lambda result. The let function is used to execute block of code, access its parameter using it and returns the value which is present in the last line (optional). The let function can also be used as an alternative for if block using safe call operator (?.) as below. Example : fun main() {\r\n    val str: String? = \"Hello\"   \r\n\tval length = str?.let { \r\n    \tprintln(\"$it World\")        \r\n\t    it.length // Returns the length\r\n\t}\r\n    println(length)\r\n} Output : Hello World\r\n5 with with is a non-extension function. The context object is passed as an argument and it is available as a receiver ( this ) . The return value is the lambda result. It is similar to let with the difference that this is used as context object instead of it . Example : fun main() {\r\n    val numbers = mutableListOf(\"apple\", \"orange\", \"grapes\")\r\n    with(numbers) {\r\n        println(\"$this\")\r\n        println(\"${this.size}\")\r\n    }\r\n} Output : [apple, orange, grapes]\r\n3 run The context object is available as a receiver ( this ). The return value is the lambda result. The run scope function is useful when our lambda contains both the object initialisation and the computation of the return value. Example : fun main() {\r\n    val text: String? = “Hello World”\r\n    val len = text?.run {\r\n        println(“Get length of $this\")\r\n        length //`this` can be omitted\r\n    } \r\n    println(\"Length of $text is $len\")\r\n} Output : Get length of Hello World\r\nLength of Hello World is 11 apply The context object is available as receiver ( this ). The return value is the object itself. The apply block is mainly used when we don’t worry about returning a value and instead mainly operate on members of the receiver object. We can use apply for the simplification of the complex chains of blocks. Example : data class Student(var name: String, var age: Int = 0, var city: String = \"\")\r\nfun main() {\r\n    val student = Student(\"Alex\").apply {\r\n        age = 20\r\n        city = \"Chennai\"        \r\n    }\r\n    println(student)\r\n} Output : Student(name=Alex, age=20, city=Chennai) also The context object is available as an argument ( it ) . The return value is the object itself. The also block is used mainly for printing, logging & having reference of the passed object. It is not used for altering the object. Example : fun main() {\r\n    val planets = mutableListOf(\"Mercury\", \"Venus\", \"Earth\")\r\nplanets\r\n    .also { println(\"The planets so far: $it\") }\r\n    .add(\"Mars\")\r\n} Output : The planets so far: [Mercury, Venus, Earth] Thus we have seen in detail about the Kotlin Scope functions. In order to make it clearer you can see the below image which simplifies each scope function usage & how to use. – Bringe Raj, Android Development Team , Mallow Technologies. REFERENCE : https://kotlinlang.org/docs/reference/scope-functions.html https://proandroiddev.com/kotlin-standard-functions-just-another-guide-8c639181ceb1 https://en.proft.me/2018/11/7/scoping-functions-kotlin/ Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2019-07-10"},
{"website": "Mallow-Tech", "title": "Android’s WebView – Safe Browsing Support", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2019/03/androids-webview-safe-browsing-support/", "abstract": "Google has announced that it enabled Safe Browsing support for the Android WebView component, a stripped-down browser that comes with all Android versions. So, Google Play Protect brings Safe Browsing to WebView by default in April 2018 with the release of WebView 66. Google has launched the Safe Browsing, a decade ago. The Safe Browsing API is a blacklist of malicious content that hosts the malware, phishing pages, or other deceptive sites. This was added when API was integrated with Chrome, which indeed is becoming a staple feature of Google’s main browser. What’s webview in android? We can render web pages as a part of the application using webview. WebView comes with all features as that of a desktop browser like managing history, cookies and a lot more. Using webview you can build apps that even integrate HTML5 games inside the application. Safe Browsing added to WebView 66 Previously, Google added support for Safe Browsing to work inside WebView. The feature was added in Android Oreo (8.0) but was not turned on by default, as developers specifically had to enable it in each app where they used WebView component. But now, Google said that with the release of WebView 66, the Safe Browsing service would be turned on by default in all WebView-capable apps. Nate Fischer , a Google Software Engineer, said that “Developers of Android apps using WebView no longer have to make any changes to benefit from this protection” – Indirajith M, Android Team , Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2019-03-15"},
{"website": "Mallow-Tech", "title": "Android App Bundle – A Brief Introduction", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2019/02/android-app-bundle-a-brief-introduction/", "abstract": "What is Android App Bundle? Android App Bundle is a new app publishing format in playstore. It is an improved way to package your app. It includes all your app’s compiled code and resources, but defers APK generation and signing to Google Play.  The Android App Bundle lets you more easily deliver a great practice in a smaller size of the app, allowing for the HUGE difference of devices. No refactoring of code is required for a minor app. Advantages of Android App Bundle? Android App Bundle has enormous advantages. In today’s blog, we will see in detail about some of the most important advantages which make it unique and compelling to opt in. Dynamic Delivery No more Multi APKs Reduced APK size Dynamic Feature Module Although it’s clear from the names we’ll go through each of them in detail. Dynamic Delivery In simple terms, Dynamic delivery means to install the modules in the application as per the user’s needs. It uses your app bundle to generate and serve more optimized APKs according to each user’s device configuration so that they download only the code and resources which will execute. For say, we don’t need other language strings if by default English is set as your preferred language. The below gif explains everything about Dynamic Delivery featured by Android App Bundle. No more Multi APKs Previously, we used to build multiple APKs and manage different versions and the process was so messy and NOT Efficient. Now, with the Android App Bundle(aab), you build one artifact that includes all of your app’s resources, compiled code, and native libraries for your app. You no longer need to build, sign, upload, and handle version codes for multiple APKs. Dynamic Feature Module The DFM contains features and assets that match the user’s device configurations on the first download of the app. In case if we use the Play Core Library (PCL), the application can later request to download the left-out or denied modules as dynamic feature APKs. For example, the video calling feature and camera filters on the specified application can be downloaded later on demand. Likely, on request, these features or modules can be downloaded as a dynamic feature APKs by using the Play Core Library. For say, the CAMERA APP which indeed contains Filters will be ignored on the very first download of the app. Initially, only the camera module will be installed, but if the user requires some filters then those modules will be downloaded as Dynamic Feature APKs. Reduced APK Size Google Play uses the Split APK mechanism, which can break up a large app into simple units or discrete packages that are installed on a user’s device as and when required. On average, apps published with app bundles are 20% smaller in size. The below images depicts the app bundle’s usage effect on app size. This blog we have explained you the basic idea of Android App Bundles. We will see the in-depth functionality of every module in our future blogs. – Indrajith M, Android Development Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2019-02-14"},
{"website": "Mallow-Tech", "title": "How to upload files from an Android app to aws s3", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2019/01/how-to-upload-files-from-an-android-app-to-aws-s3/", "abstract": "In this blog, we will see about how to upload the files from android app to aws s3. We need to implement the feature that stores the files (like user profile image, user documents etc., into the server. We can simply store the files into the aws s3 bucket rather than to our own server. Here the step by step process to integrate the aws s3 bucket and upload the files. 1. Include the aws dependencies to the app level build.gradle implementation 'com.amazonaws:aws-android-sdk-core:2.6.+'\r\nimplementation 'com.amazonaws:aws-android-sdk-cognito:2.2.+'\r\nimplementation 'com.amazonaws:aws-android-sdk-s3:2.6.+'\r\nimplementation 'com.amazonaws:aws-android-sdk-ddb:2.2.+' 2. Import the following files import com.amazonaws.auth.BasicSessionCredentials;\r\nimport com.amazonaws.mobileconnectors.s3.transferutility.TransferListener;\r\nimport com.amazonaws.mobileconnectors.s3.transferutility.TransferObserver;\r\nimport com.amazonaws.mobileconnectors.s3.transferutility.TransferState;\r\nimport com.amazonaws.mobileconnectors.s3.transferutility.TransferUtility;\r\nimport com.amazonaws.regions.Region;\r\nimport com.amazonaws.regions.Regions;\r\nimport com.amazonaws.services.s3.AmazonS3;\r\nimport com.amazonaws.services.s3.AmazonS3Client;\r\nimport com.amazonaws.services.s3.model.CannedAccessControlList; 3. Code to upload the files a) Create the amazon s3 client: AmazonS3 s3Client = new AmazonS3Client(new BasicSessionCredentials(awsAccessKey, awsSecretKey, sessionToken)); b)Set the region for s3Client : s3Client.setRegion(Region.getRegion(Regions.US_WEST_2)); c ) Create the TransferUtility to upload the file : TransferUtility transferUtility = new TransferUtility(s3Client, context); d ) Upload the file : TransferObserver transferObserver = transferUtility.upload(bucketName, pathToStore, file, CannedAccessControlList.PublicRead); (Note : If you want the file url read by public, include CannedAccessControlList.PublicRead value.) e ) To know whether the file is uploaded successfully or not : Include the TransferObserver to listen the file upload status.\r\n\r\ntransferObserver.setTransferListener(new TransferListener() {\r\n\r\n    @Override\r\n\r\n    public void onStateChanged(int id, TransferState state) {\r\n\r\n//Implement the code for handle the file status changed.\r\n\r\n   }\r\n\r\n    @Override\r\n\r\n    public void onProgressChanged(int id, long bytesCurrent, long bytesTotal) {\r\n\r\n        //Implement the code to handle the file uploaded progress.\r\n\r\n    }\r\n\r\n    @Override\r\n\r\n    public void onError(int id, Exception exception) {\r\n\r\n//Implement the code to handle the file upload error.\r\n\r\n  }\r\n\r\n}); You can access the file by the URL: https://s3-cn-north-1.amazonaws.com/bucketName/pathToStore . Conclusion: we have seen about the complete solution for upload the files into AWS S3 securely and efficiently. It is the easy service to store the file and retrieve anywhere from the web. – Sivavishnu R, Android Team, Mallow Technologies . Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2019-01-31"},
{"website": "Mallow-Tech", "title": "Android Architecture Component – Data Binding Library", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2019/01/android-architecture-component-data-binding-library/", "abstract": "I welcome everyone to the series of Android Architecture Components. Last time we have seen about Room library , ViewModel and LiveData . Now we are going to see about one more interesting library called Data Binding Library which is also present in the Android Architecture Components. Data Binding Library is used to bind UI components in your layout to data sources in the app using a declarative format rather than programmatically. Traditionally we developers are using findViewById() to bind layout views in XML with data programmatically. There are some popular data injection libraries like Butterknife which is used to bind data with a view. Following is the sample snippet of Butterknife: @BindView(R.id.user) EditText username; As developers, we are still facing difficulties in implementing proper data injection libraries due to some or more specific cases. Hence google themselves provide an optimum solution for proper data binding & reducing number of boilerplate codes compared to all. Implementation: It is always good to have a sample demo application in order to understand the concept better. 1. First, enable the data binding library in your project module (app module). android {\r\n    ....\r\n    dataBinding {\r\n        enabled = true\r\n    }\r\n} 2. Wrap your XML code around layout tag and include the data tag with the respective variable tag to bind the UI components as below: <?xml version=\"1.0\" encoding=\"utf-8\"?>\r\n<layout xmlns:android=\"http://schemas.android.com/apk/res/android\"\r\n    xmlns:app=\"http://schemas.android.com/apk/res-auto\">\r\n\r\n    <data>\r\n\r\n        <variable\r\n            name=\"user\"\r\n            type=\"com.example.databind.User\" />\r\n    </data>\r\n\r\n    <RelativeLayout\r\n        android:layout_width=\"match_parent\"\r\n        android:layout_height=\"wrap_content\">\r\n\r\n<TextView\r\n            android:id=\"@+id/tv_id \"\r\n            android:layout_width=\"match_parent\"\r\n            android:layout_height=\"wrap_content\"\r\n            android:text=\"@{String.valueOf(user.id)}\" />\r\n\r\n\r\n        <TextView\r\n            android:id=\"@+id/tv_user_name \"\r\n            android:layout_width=\"match_parent\"\r\n            android:layout_height=\"wrap_content\"\r\n\r\n    android:layout_below=\"@id/tv_user_name \"     \r\n            android:text=\"@{user.username}\"/>\r\n\r\n    </RelativeLayout>\r\n</layout> 3. Create a POJO class called User.java import com.example.databind;\r\n\r\npublic class User{\r\n\r\nprivate Integer id;\r\n\r\nprivate String username;\r\n\r\npublic User(Integer id, String username){\r\n\r\nthis.id = id;\r\n\r\nthis.username = username;\r\n\r\n}\r\n\r\n// getter and setter method\r\n\r\n} 4. Then in your respective activity class add the following data binding code public class MainActivity extends AppCompatActvitiy{\r\n\r\n@Override\r\n\r\nprotected void onCreate(Bundle savedInstanceState){\r\n\r\nsuper.onCreate(savedInstanceState);\r\n\r\nActivityMainBinding dataBinding = DataBindingUtil.setContentView(this, R.layout.activity_main);\r\n\r\nUser user = new User(1, “Arjun”);\r\n\r\ndataBinding.setUser(user); // this will update the view\r\n\r\n}\r\n\r\n} Conclusion: Thus data binding library has proved to be a better, stable and easy to write (reduces the number of lines compared to other libraries). – Bringe Raj S B, Android Team, Mallow Technologies . Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2019-01-29"},
{"website": "Mallow-Tech", "title": "5 Advanced features in Google Maps you should know", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2019/01/5-advanced-features-in-google-maps-you-should-know/", "abstract": "Google has introduced 5 advanced features in Google maps. These features enhance the way Google maps can be used and proves to be useful to the user in many ways. The following are the features that were introduced, Material Design concept Explore For you Lists Your Matches Now we are going to see these features in brief. Material Design in Google maps : Nowadays, the material design is all over google apps. It provides UI with more colourful and attractive design. Google has improved it Search at the top of the Android home screen with rounded corner and shadows. In google maps, the material design is applied to tabs, texts, button and so on. Animation and effects are added to it. Explore – Local guides list Explore provides refreshed feeds experience and it is very useful for us to find cafes, takeaways and restaurants in a very quick time. We can explore the places no matters wherever you are in the world. It helps us to plan a trip or explore new places around. Explore also show you top events, shopping places, activities going around your area. You can apply filters and find activities that fit your mood. For you – Notable spots For you, the tab will let you know everything happening in your place you care about. Your place may be near home, work or even city. By following your neighbours allows you to see new places that match your taste. For you tab is only available in US, UK, Canada, Australia and Japan. Your matches – Dumplings Based on your recent history, likes and rating it will find the relevant places for you. Location history is important for this feature, you must turn it on. Instead of reading all reviews, you can quickly choose from your matches. You can improve it by giving a rating, likes and visiting places. Lists You can add the places to the lists. List types : Favourites Want to go Starred places. Lists provide options to share the list of places and location with your friends, family and so on. Once the saved button is clicked, it will ask you to save the place in one of the above lists. Then you can share it. Conclusion We have seen in detail about the new features introduced in Google Maps by Google. This helps us in utilizing the application in a much better manner and make the most out of it. In future, we will see in detail about various applications. – Prakash B, Android Team, Mallow Technologies . Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2019-01-23"},
{"website": "Mallow-Tech", "title": "Apple October Event – A Brief Overview", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/10/apple-october-mac-event-a-brief-overview/", "abstract": "Apple’s much-awaited final hardware event for the year 2018 was scheduled at New York on October 30th. This event concentrated on Mac devices and a new iPad. This event turned out to be a great event with the announcements of the following products. MacBook Air Mac Mini iPad Pro Apple Pencil Let us see in detail about these products and its features. MacBook Air: After a long wait, MacBook Air users are going to get Retina Display. Along with Retina Display, now the device has Touch ID, modern keyboard and force trackpad. The new MacBook Air will be available in three colours namely Silver, Space Grey and Gold finish. This version of MacBook has become thinner, lighter and enhanced with Apple T2 security chip. The force trackpad is 20% larger than before and will allow more gestures and haptic feedback. Now you can upgrade the memory up to 16GB RAM and storage up to 1.5TB SSD. Check more about the new MacBook Air at the Product page of Apple . Mac Mini: Mac Mini is probably the most awaited product for a very long time from the Mac users. Coming after a long gap of 4 years, the new Mac Mini is all beefed up with eighth generation Quad Core and 6 Core processors, faster DDR4 memory up to 64GB and all-flash storage up to 2TB. This new device speeded up to give 5X system performance and achieves the frequency of 4.6GHZ clock speed with the help of turbo boost. With the 6 core processors, it runs Xcode 2.2X faster and Webkit Compile 3.4X faster. Along with all these, Mac Mini comes with 2 USB-A ports, 4 USB-C/ Thunderbolt ports, and an ethernet port. These upgrades can very well prove to be one of the best upgrades by Apple. To know more about the new Mac Mini, click the Mac Mini Page. iPad Pro: The final big product from the announcement is iPad Pro. The new iPad Pro will be available in two screen sizes of 11″ and 12.9″. It has an edge to edge liquid Retina display like the new iPhone XR. The new iPad Pro has no home button and can be unlocked by Face ID. It has been told that the Face ID will work perfectly in both Portrait and Landscape mode. iPad Pro is powered by the A12X Bionic chip for faster performance which allowed new photoshop and project AR by Adobe to run seamlessly without any compromise in performance.  Apple has updated human interface guidelines for giving your app support to latest iPad pro. For complete details refer to this link . Developers can look into this link for optimising your app for iPad Pro. This new revamped iPad Pro might well replace a lot of Notebooks. Check in the iPad Pro page to know more about the product. Apple Pencil: This is the best companion for new iPad Pro. Apple completely redesigned Apple Pencil 2 which magnetically attaches to iPad Pro to pair and charge wirelessly. You can double tap in Apple Pencil to change tool/options in apps and it’s customisable. For example, you can double tap to switch between brushes or switch to eraser in notes apps in iPad Pro. Click in the link to know more about Apple Pencil. Other Key takeaways: Apart from the above-mentioned product announcements, Apple emphasised on its go green approach with their products. Both the MacBook Air and Mac Mini metal body is made with 100% recycled Aluminum. They have developed an alloy on Aluminum to achieve this. Another important announcement is increasing the sessions of Today at Apple events to reach more people. – Karthick S, iOS Development Team , Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-10-31"},
{"website": "Mallow-Tech", "title": "Unit Testing for Mapping JSON – A Brief Introduction", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/10/unit-testing-for-mapping-json-a-brief-introduction/", "abstract": "JSON (JavaScript Object Notation) is a lightweight data-interchange format which is built on name/value pairs or ordered list of values. In recent times, Almost all apps use JSON in one way or another including the configurations, over the network etc. Since we often use JSON to such a heavy extent, it becomes more intense to deal with the errors, especially in the core data models. It’s therefore important that we have solid tests in network place to make sure its error free. Unit Testing: In iOS, usually, test cases are written to just verify the single unit or module of our app. Though these tests are valuable to iterate on separate parts of our app, and it eliminates rework to write the entire test suite, we face a lot of challenges when it comes to JSON mapping. Consider the following user model in our code: struct User {\r\n\r\n    let name: String\r\n\r\n    let age: Int\r\n\r\n}\r\n\r\nWhich requires the below JSON structure:\r\n\r\n{\r\n\r\n    \"name\": “Mark”,\r\n\r\n    \"age\": 30\r\n\r\n} To test that our User model could be initialised with above JSON, we first bundle the JSON in our test target, then load it in a test case, and finally verify that a User instance was successfully created. class UserTests: XCTestCase {\r\n\r\n    func testJSONMapping() throws {\r\n\r\n        let bundle = Bundle(for: type(of: self))\r\n\r\n        guard let url = bundle.url(forResource: \"User\", withExtension: \"json\") else {\r\n\r\n            XCTFail(\"Missing file: User.json\")\r\n\r\n            return\r\n\r\n        }\r\n\r\n        let json = try Data(contentsOf: url)\r\n\r\n        let user: User = try unbox(data: json)\r\n\r\n        XCTAssertEqual(user.name, “Mark”)\r\n\r\n        XCTAssertEqual(user.age, 30)\r\n\r\n    }\r\n\r\n} These tests serve to an extent but the problem arises when the JSON that backend sends changes in any way. That ideally should not happen and we must ensure to use proper versioning and integration tests so that a new version of the backend never breaks any users. The problem in above code occurs since we have bundled a static JSON file in our tests, which will indeed break then once we start requesting real data from the backend. End-to-end Tests: In this situations, we bring in end-to-end tests which are really valuable. Its perspective is to extend code coverage with the tests that cover our entire stack vertically. In the JSON tests, we need to test the data that is received from the backend system, which ought to get mapped into a model. Typically, we use UI Testing to perform end-to-end testing, but those are very expensive to run. We don’t necessarily require to run through all the UI components in order to test JSON mapping. Like in most programming situations, being able to maintain a single source makes things simpler and less error prone. So we could base our client-side JSON mapping tests on real data from the backend and have a single, auto-updating) source. For auto-downloading the script in real time we have several services. Here goes one such example with marathon(https://github.com/JohnSundell/Marathon) which is a tool that enables you to easily write and run scripts using Swift. //Download JSON\r\n\r\nlet query = \"language:swift\"\r\n\r\nlet url = URL(string: “https://git.com”) //Required url\r\n\r\nlet json = try Data(contentsOf: url)\r\n\r\n// Write JSON file\r\n\r\nlet resourceFolder = try Folder.current.subfolder(atPath: \"Tests/Resources\")\r\n\r\ntry resourceFolder.createFile(named: \"User.json\", contents: json)\r\n\r\n// Save a new version of .lastRun\r\n\r\nlet lastRunFile = try scriptsFolder.createFile(named: \".lastRun\")\r\n\r\ntry lastRunFile.write(string: String(Int(currentTimestamp))) To get the script run, every time the tests are initiated, add a new Run Script phase to the test target in the Xcode’s project navigator, preferably right after Target Dependencies. Call it as ”Download JSON” and add the below content: marathon run Scripts/DownloadJSON Now on running the tests a TestResources folder with a Git.json file will be created the root folder of the project. Add the file into Xcode -> test target and we have our auto-updating JSON file. The following could help writing a test in Xcode, struct GitFile {\r\n\r\n    let id: Int\r\n\r\n    let value: String\r\n\r\n}\r\n\r\nextension GitFile: Unboxable {\r\n\r\n    init(unboxer: Unboxer) throws {\r\n\r\n        id = try unboxer.unbox(key: \"id\")\r\n\r\n        value = try unboxer.unbox(key: “value\")\r\n\r\n    }\r\n\r\n} Finally, execute the test that verifies that the downloaded JSON file is indeed compatible with the model, class RepositoryTests: XCTestCase {\r\n\r\n    func testJSONMapping() throws {\r\n\r\n        let bundle = Bundle(for: type(of: self))\r\n\r\n        guard let url = bundle.url(forResource: \"Git\", withExtension: \"json\") else {\r\n\r\n            XCTFail(\"Missing file: Git.json”)\r\n\r\n            return\r\n\r\n        }\r\n\r\n        let json = try Data(contentsOf: url)\r\n\r\n        let repositories: [Repository] = try unbox(data: json, atKeyPath: \"items\")\r\n\r\n        XCTAssertFalse(repositories.isEmpty)\r\n\r\n    }\r\n\r\n} And now we have an end-to-end test, that runs fast, auto-updates and makes sure that our JSON mapping code will always work against real data from the backend. – Poorvitha Y, iOS Development Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-10-25"},
{"website": "Mallow-Tech", "title": "Fabric crash tracking based on environment in iOS", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/10/fabric-crash-tracking-based-on-environment-in-ios/", "abstract": "Fabric Crashlytics is a crash reporting tool that helps us track crashes in our app. But while you are working on a project with different environments, say (debug and release)  how would you track the crashes based on a particular environment. One way to track this is by differentiating between the build numbers. But what if we have the same version and build numbers for both debug and release builds. You can achieve this by creating a separate app under separate organisation for debugging and release builds in Fabric. You can create two organisations, one for development and one for release. Then,  add your app in both the organization. Now when you get crash for a release build, you would receive the crash in the app under the release organisation. But here comes the problem, there would be separate API key and Secret Key for both the organisations. You have to configure the keys based on the environment in Xcode. Xcode’s custom user-defined setting can be used to solve this problem. Go to your project’s build settings. Choose the “+” button to add a user-defined setting as shown below. Add your fabric API key and secret key based on your environment as shown in the image. Go to your build phases tab, and add the run script as follows. Project/SubModules/Fabric/Fabric.framework/run ${FABRIC_API_KEY} ${FABRIC_SECRET_KEY} Go to your info.plist file and add the value of API key as “${FABRIC_API_KEY}” so that it takes the value dynamically based on the environment we are running. Conclusion: Now when you run the app, the crash would be logged separately based on the environment we are running. Rajtharan G, iOS App Development Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-10-03"},
{"website": "Mallow-Tech", "title": "Apple Special event – September, 2018 wrap up", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/09/apple-special-event-2018-wrap-up/", "abstract": "Apple today at Apple Special Event. September 12, 2018 , announced its next set of the line-up of Apple watch and iPhone devices. Let’s check out what Apple has done new this time as ever. When it comes to Apple’s events, what Apple is going to announce just not in terms of its devices list, But what it could do more with it , Yes I am one such fellow who wonders what Apple is going to breakthrough in terms of usage of technology, If you are one among us this blog is mainly for you. I will cover up the breakthrough that Apple has done and follow up with rest of the announcements. Here let’s begin, Here are the new devices announced by Apple at the special event , Apple Watch Series 4 iPhone XS iPhone XS Max and iPhone XR Let us check out whats new in each new devices, Apple Watch Series 4 : An upcoming complete health monitor compact device. Yes, It will be soon a complete health monitor device. As wondered what Apple could do with this compact device when it announced the Apple watch at first glance it made it revolutionary on each and every new release of it. And in this release, it even surprised me with the new features, ECG( ElectroCardioGram ): Yes, with new electrical sensors added in the watch now you can record ECG with just a hold on watch crown. Low heart rate monitor: Alerts when your heart rate gets low. Atrial Fibrillation: Alert Irregular heart rhythm, also tracks in the background. Detects fall: Detects real-world motion patterns like fall, trip & slip and It calls automatic if no reaction for 1 minute after fall detection. Technical details of the watch, 30% larger display 44MM than series 3 watch 40MM. Now it can accommodate up to 8 complications in the watch face and can be customized like having Contacts, Health apps, Different time zones at the shortcuts in the watch face. Digital crown now has haptic feedback, with it now you can not just know but can even feel when you scroll down the contents of the watch. Speaker is 50% louder. And mic has been moved away from the speaker to opposite side to reduce the echo. Radio waves can pass in front and sideways which lets more connected to the carrier. Integrated with the S4 chipset with Dual-core 64-bit processor which makes this device 2x times faster than its predecessors. iPhone XS, iPhone XS Max & iPhone XR : The biggest iPhone ever. Apple has announced 3 new models and one among them iPhoneXS Max is the biggest screen of iPhone kind ever released. iPhone doesn’t seem to have many upgrades compared to its predecessor except few new upgrades as below so will coverup it in short, A12 Bionic chip: Mainly helpful for real-time machine learning Dual sim support : e-sim support with tied up carriers & only in China they are providing dual physical sim support. Super retina display in iPhone XS & iPhone XS Max. Liquid Retina display in iPhone XR. Split view in iPhone XS Max. Wider stereo sound Rest of the specifications of iPhone is detailed in following image gallery. Summary : Though there are not many features introduced as expected in iPhone devices, new features introduced in Apple Watch Series 4 has made it useful in this event. And in iPhone, the bigger display looks good and the addition of A12 bionic chip looks promising on the performance. Looking forward to a bigger and better set of announcements on next WWDC event. – Bharath R, iOS Development Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-09-13"},
{"website": "Mallow-Tech", "title": "ANDROID ARCHITECTURE COMPONENT – LIVEDATA", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/09/android-architecture-component-livedata/", "abstract": "INTRODUCTION: Once again I welcome everyone to the series of Android Architecture Components. Last time we have seen about View Model and Room library . Now, we will be continuing with LiveData component, LiveData is an observable data holder class. Unlike other observable components, it is life cycle aware, meaning that it behaves according to the app lifecycle components (activity, fragment or service). One of the advantages is that there will be no memory leak issue while updating the app components and there will be always quick updated results. WORKING & BENEFITS: LiveData is achieved by adding the lifecycle owner (i.e Activity and Fragment) as an observer to the data update. Following are some of the benefits : – UI will always be up to date (UI showing most recent data), as activity and fragment will always be notified whenever there is a data change. – As everything falls under lifecycle, registered for observing will only occur when the lifecycle owner is STARTED or RESUMED. So, that there will be no memory leaks or null pointer exceptions. SAMPLE IMPLEMENTATION OF LIVE DATA: Let’s understand with sample implementation: 1. First, add the necessary dependency: implementation \"android.arch.lifecycle:extensions:1.1.1\"\r\nannotationProcessor \"android.arch.lifecycle:compiler:1.1.1\" Above two dependencies should be added in order to use to live data effectively, first one to add its implementation code and the second one to add its annotation related dependencies. 2. Consider we have a list of students to observe: public class Students extends ViewModel {\r\n\r\n    \r\n\r\n    private MutableLiveData<List<Student>> studentLiveData = new MutableLiveData<>();\r\n\r\n    \r\n\r\n    public Students() {\r\n         setStudentListRefreshCallback(newStudentList -> {\r\n             studentLiveData.postValue(newStudentList);\r\n         });\r\n     }\r\n \r\n     public LiveData<List<Student>> getStudentList() {\r\n         return studentLiveData;\r\n     }\r\n } Here the list of students is liable to change so it is wrapped around the MutableLiveData. MutableLiveData is a subclass of LiveData that exposes the setValue and postValue methods so you can dispatch a value to any active observers. Whenever there are some changes in the list of students (maybe changes occurring in DB or from API calls) it will be intimated, it is done with help of live data. We can either use postValue() or getValue(). The postValue() method behaves in an asynchronous manner and getValue() in a synchronous manner. 3. Getting the updated values in Activity/Fragment: public class StudentActivity extends AppCompatActivity {\r\n     \r\n\r\n     @Override\r\n     protected void onCreate(Bundle savedInstanceState) {\r\n         super.onCreate(savedInstanceState);\r\n         setContentView(R.layout.activity_main);\r\n        // initialising the view model\r\n         Students studentsViewModel = ViewModelProviders.of(this).get(Students.class);\r\n        // getting the updates and updating the list\r\n         studentsViewModel. getStudentList ().observe(this, this::showStudents); \r\n\r\n    }\r\n} In above code we can see that observer() methods takes the first parameter as lifecyclerOwner (here activity) and the second one changes performed in the list which will be updated in the UI using showStudents() method. CONCLUSION: Thus livedata and ViewModel combined makes the life of Android developers easy by focusing on our core logic and not worrying about the data changes which occur in our local DB or through API call. Featured Image courtesy: Thetechnocafe.com – Bringe Raj B, Android Development Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-09-04"},
{"website": "Mallow-Tech", "title": "Things to be considered while implementing a Search/Auto completion feature", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/08/things-to-be-considered-while-implementing-a-search-auto-completion-feature/", "abstract": "You might have seen search feature in many famous apps starting from social media apps like Facebook, Twitter, Instagram to e-commerce apps Amazon and Flipkart. Mostly the famous app uses the search feature for universal searching of contents. In Facebook you can search people, pages, post, places, etc.. In Amazon and Flipkart, you can search for different products in the different category. Search allows your app user to reach your/their content very fast and with ease. If you are planning to implement this kind of search(Auto-completion way) feature in your app, you have to consider some basics points to improve the responsiveness of your search. Mostly we will be talking from mobile app side(Some points may be applicable for web app also) and a little bit on the server side as well. Mobile app side: You should decide searchable column in the database for your search operation. It could be a username, address, email ID, Country, or any project-specific fields/values. 🤔 Based on the search column you need to configure input providing ways. If you are about to search only using alphabets you need to configure alphabet/default keyboard properly. You should not accept numbers or any special characters. ⌨️ Before starting the search operation you need to format and validate search text accordingly. You should not hit API if the user adds unwanted special characters, space in search text. You should remove unwanted spaces, new lines at the starting and ending of the search text before hitting API. You should not hit API if the user is typing very fast. You need to have a time delay(say X seconds) between previous searched text and current searched text. iOS: One way of achieving this using configuring performSelector() with a delay of X seconds and whenever user types you need to cancel previously configured perform selector and configuring a new one. This code will go to your viewController. // Cancel previously scheduled perform selector\r\nNSObject.cancelPreviousPerformRequests(withTarget: self, selector: #selector(handle(searchText:)), object: previouslySearchedText)\r\n\r\n// Schedule perform selector with latest search text\r\nperform(#selector(handle(searchText:)), with: previouslySearchedText, afterDelay: kMinimumTypingInterval) You need to cancel in-progress search API request(if any) before hitting API for current search text. Before hitting API you can do a local search in the array which you got in previous request to speed up search text highlighting process(Refer next point). When user search using search option you can highlight search text in results list if needed. Refer below image for search option in Amazon. If search text is cleared in the search field, you need to reset all local details like searched details array, locally filtered array, search text, in progress API request, etc… If previously searched text and new search text are same, you no need to hit API. Local search and server search should happen in a case-insensitive manner for alphabets. When searching against any column you need to analyse and handle special characters like $^*() , these type of special characters may cause an issue when highlighting search text in response. The user may search contents using emojis in iOS. You need to handle this as well. 👽 If needed, you can add loading indicator at search bar without blocking the main UI. This should be handled in the worst case after optimising the API properly. Server side: You need to analyse and form a JSON response structure as flat as possible rather than nested . 1. Flat JSON: (Simple and response time will be less) {\r\n\t“key_1”: “value”,\r\n\t“key_2”: “value”,\r\n\t“key_3”: “value”,\r\n\t“key_4”: “value”\r\n} 2. Nested JSON: (Complex and may take large response time than flat JSON) {\t\t\r\n\t“key_1”: “value”,\r\n\t“key_2”: {\r\n\t\t“key_1”: “value”,\r\n\t\t“key_2”: “value”,\r\n\t\t“key_3”: {\r\n\t\t\t“key_1”: “value”,\r\n\t\t\t“key_2”: “value”,\r\n\t\t\t“key_3”: “value”,\r\n\t\t\t“key_4”: {\r\n\t\t\t\t“key_1”: “value”,\r\n\t\t\t\t“key_2”: “value”,\r\n\t\t\t\t“key_3”: {\r\n\t\t\t\t\t“key_1”: “value”,\r\n\t\t\t\t\t“key_2”: “value”,\r\n\t\t\t\t\t“key_3”: “value”,\r\n\t\t\t\t\t“key_4”: “value”\r\n\t\t\t\t},\r\n\t\t\t\t“key_4”: “value”\r\n\t\t\t}\r\n\t\t},\r\n\t\t“key_4”: “value”\r\n\t},\r\n\t“key_3”: “value”,\r\n\t“key_4”: “value”\r\n} You need to have a minimum number of queries for fastening the search operation. API should not return entire matching records details in response JSON. Instead, you can return the record ID and other needed details like record name(Ask a question yourself like, do App need this actually before adding any column value in response?) to App. The app needs to hit another API to get the complete details about that particular record using its ID. You may need to use Postgres ILIKE query for this search operation based on the project requirement. You need to add indexing for a particular field you are about to search for to reduce the query time/execution time. You need to analyse and handle special characters like & in search text. If you have only & in search text then the query may not perform. You need to limit response counts in API. E.g If user types a letter “a” you should not return all records which have “a” in searchable field. The user just started to type so you can return only latest 20 or 30 records(Depends on project requirements) in response. While deciding this limit you need to analyse project requirement clearly and need to configure this limit based on it. You need to give high priority for the record which exactly matched a searchable field with search text. Next priority will go to records which matched the pattern in the searchable field. You can sort response based on this priority order. E.g Lets assume user searching another user by using his/her full name, Search text = John , response = [ John (Exact match), John Appleseed(pattern match)]. Try to avoid showing loading indicator in your app when implementing this feature, because your user will expect search response as soon as possible. Instead of showing loading indicator try to optimise your API and query performance to speed up the search process. These are the basic points you may need to consider before implementing search/auto-completion feature in your app. If we missed any important point or scenario, please mention it in the comment box. P.S: Featured Image courtesy – Appcelerator.com – Karthick S, iOS Development Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-08-29"},
{"website": "Mallow-Tech", "title": "Ways to improve App performance in Android", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/08/ways-to-improve-app-performance-in-android/", "abstract": "App performance plays a major role in making an application successful. An application might have much more features than its competitors but if it lags in performance then the features won’t help to increase the userbase. In this blog, we will see about improving the performance of an Android application. String vs StringBuffer vs StringBuilder: String: The string is the most used class Java programming language. It is immutable. When we create a new string with double quotes, Initially it looks for the same value in the memory pool. If the memory pool has any string with the same value, the new string is stored in that reference. Otherwise, it creates a new object in the memory pool. But if we create a new string with a new keyword, it explicitly creates a new object in heap memory. If we manipulate the string, it creates the new memory for each manipulation due to its immutable character. If we use + operator in a loop for string append, it creates the new object for each append operation. So it consumes a lot of memory. Hence, String is not the best choice for large concatenation operations. StringBuffer and StringBuilder are two other best ways for large concatenation operations because both are mutable. We will see about both of them in detail. StringBuffer & StringBuilder: Both StringBuffer and StringBuilder are mutable. String manipulation is done without creating any new unwanted objects. The only difference between them is, StringBuffer is “thread safe” because it is synchronised while StringBuilder is not. Due to this StringBuffer is much slower than StringBuilder. We must avoid the String when we need more string manipulation. When we use non-multi threaded case, StringBuilder is the best choice as per memory and speed. If we want a multi-threaded operation to access the String, the best choice is StringBuffer. For loop performance: Program: List<Integer> list = new ArrayList<>();\r\n\r\nlong startTime;\r\n\r\nlong endTime;\r\n\r\nfor (int i = 0; i < 100000; i++) {\r\n\r\n    list.add(i);\r\n\r\n}\r\n\r\n//Type 1\r\n\r\nstartTime = Calendar.getInstance().getTimeInMillis();\r\n\r\nfor (Integer i : list) ;\r\n\r\nendTime = Calendar.getInstance().getTimeInMillis();\r\n\r\nLog.d(\"tag\",\"for loop performance :\"+\" For each loop : \" + (endTime - startTime) + “ ms\");\r\n\r\n//Type 2\r\n\r\nstartTime = Calendar.getInstance().getTimeInMillis();\r\n\r\nfor (int j = 0; j < list.size(); j++) ;\r\n\r\nendTime = Calendar.getInstance().getTimeInMillis();\r\n\r\nLog.d(\"tag\",\"for loop performance :\"+\" Using collection.size() in condition check : \" + (endTime - startTime) + \" ms\");\r\n\r\n//Type 3\r\n\r\nstartTime = Calendar.getInstance().getTimeInMillis();\r\n\r\nint size = list.size();\r\n\r\nfor (int j = 0; j < size ;j++);\r\n\r\nendTime = Calendar.getInstance().getTimeInMillis();\r\n\r\nLog.d( \"tag\",\"for loop performance :\"+\" Assign collection.size() in separate variable : \"+(endTime - startTime) + \" ms\");\r\n\r\n//Type 4\r\n\r\nstartTime = Calendar.getInstance().getTimeInMillis();\r\n\r\nfor (int j = list.size(); j > size ;j--);\r\n\r\nendTime = Calendar.getInstance().getTimeInMillis();\r\n\r\nLog.d(\"tag\",\"for loop performance :\"+ \"Assign collection.size() as initialization : \"+(endTime - startTime) + \" ms\"); Output: for loop performance: For each loop: 12 ms for loop performance : Using collection.size() in condition check : 3 ms for loop performance : Assign collection.size() in separate variable : 1 ms for loop performance :Assign collection.size() as initialization : 0 ms Analysis: – Type 1 is slow because the iterator is internally created in for each loop. – In Type 2 size() method is called in every iteration. So it also takes a lot of time to execute. – Type 3 & Type 4 is almost the same. Both are fetching the size initially. But Type 4 don’t have an extra memory. Type 3 have additional memory to save the size. If we no need to consider the order of the list, type 4 is the best choice. Otherwise, type 3 is the best choice. Save the Instance State: The current state of the activities should be saved to avoid recalculation when the application is opened again. The data loaded by your activities or the result of any long-running operation should be saved when the onSaveInstanceState event is raised and restored when the onRestoreInstanceState event is raised. Since the state is saved with a serializable bundle object, the easiest way to manage state is to have a serializable state object containing all the information needed to restore the activity so only this object needs to be saved. The information entered by the user in View controls is already saved automatically by the Android SDK and does not need to be kept in the state. Remember, the activity state may be lost when the user leaves your application or rotates the screen, not only when the user navigates to another activity. Slow Rendering: Android is trying to refresh the activities for every 16 ms. Hence the app has to do all the logic to update the screen in 16 ms. If the app can’t complete the logic in 16 ms, Android OS tries to draw a new picture but it won’t be ready. As a result, it won’t refreshing anything. So the animation will not be smooth. Optimise Layout Hierarchies: Using the basic layout structures leads to the most efficient layouts. However, each widget and layout you add to your application requires initialisation, layout, and drawing. For example, using nested instances of LinearLayout can lead to an excessively deep view hierarchy. Furthermore, nesting several instances of LinearLayout that use the layout weight parameter can be especially expensive as each child needs to be measured twice. This is particularly important when the layout is inflated repeatedly, such as when used in a ListView or GridView . We have seen in detail about few methods with which the performance of the application can be improved. This gives you a good idea about how the small things act as a major game changer in terms of performance. – Sivavishnu R, Android Development Team, Mallow Technologies . Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-08-17"},
{"website": "Mallow-Tech", "title": "Best practices to pass Context and their Memory Leak possibilities", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/08/best-practices-to-pass-context-and-their-memory-leak-possibilities/", "abstract": "Definition of Context : Context represents environment data. It provides access to things such as databases. Different methods by which you can get context: getApplicationContext() getContext() getBaseContext() or this (when in the activity class) O kay, now lets see the difference between getContext(), this, getBaseContext(), and getApplicationContext(). Different types of Context: UI Context: In truth, only the ContextThemeWrapper is UI Context which aids Context + Your theme. Activity extends ContextThemeWrapper. This is the reason that, when you inflate any XML, those views are themed. If you inflate your layout with Non-UI context, your layout will not be themed. Go further, try it. When you use Activity as a placeholder for Context, you are assured to be using UI Context. If you use the getContext method from the Fragment, you are indirectly using Activity (if you attached Fragment via fragment manager in the activity). But view.getContext() is not guaranteed to be UI Context. If View was instantiated using Layout Inflater and passed UI Context, you get UI Context back. But if it was instantiated by not passing UI Context, you get the other context back. Examples: Activity – Instance of your activity (this) Fragment – getContext() in Fragment View – getContext() in View (if View was constructed using UI-Context) Non-UI Context: Anything except the UI Context is a Non-UI Context. Technically, anything which is not ContextThemeWrapper is Non-UI Context. Non-UI Context is allowed to do more or less everything UI-Context can do (bad design spotted). But as we pointed out above, you will lose theming. Examples: Application instance as the context. Activity – getApplicationContext() in Activity. Broadcast Receiver – Context received in the broadcast receiver. Service – Instance of your service (this) & getApplicationContext() in Service Context – getApplicationContext() in Context instance. Lastly, We have reduced it a little bit by putting Context in two buckets. UI Context is Context (+) Theming, and technically any class which is a subclass of a ContextThemeWrapper comes in this bucket. Memory Leak or Crash: Yes, it’s a worst case scenario when you use context in the wrong place. If you are new to the Android app development world, let me share some knowledge. Memory leaks are inversely proportional to your experience. Every Android developer has leaked memory. There is no shame in doing so. Shame is when you repeat the mistake again and leak it the same way. If you leak memory a different way every time, best wishes you are growing. Better yet, get the application context to avoid memory leaks. Summary Do you need to access UI related stuff? Use UI-Context. Inflating Views and showing dialogue are the two use cases I can think of. Otherwise, use Non-UI Context. Make sure you do not pass short-living context to long-living objects. – Indrajith M, Android Development Team, Mallow Technologies . P.S: Image courtesy – nimbledroid.com Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-08-01"},
{"website": "Mallow-Tech", "title": "How to debug memory issues using Allocations in Swift", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/07/how-to-debug-memory-issues-using-allocations-in-swift/", "abstract": "In this blog we gonna see about Debugging Memory issue in Swift. Before we deep dive into the concept we should learn some basic things. Value Types Vs Reference Types Value Types : Each instance keep a unique copy of its own data. Usually in Swift struct, enum or tuple falls into value types. Reference Types : Many instance share a single copy of the data. In swift we have class which is reference type. The above is a raw definition of value and reference types. The concept here is value types are stored in stack memory whereas reference types are stored in heap memory. Stack uses static memory allocation on the other hand heap uses dynamic memory allocation. Stack which is faster than heap usually get deallocated when it goes out of the scope (i.e normally out of the function or a class). But heap won’t deallocates automatically which is responsible for memory leaks.   In swift we have a clean technology called Automatic Reference Counting which will deallocates the reference types automatically on our behalf. But we need to consider relationships between each instance we create. ARC Mechanism ARC works with simple mechanism, it will keep track of each reference type instance we create. If we create a reference for any instance, ARC will increment the reference count for that instance as 1. It tracks that instance and increments its reference count for each references we create. But If we assign weak or unowned to the reference of any instance we create ARC won’t increment reference count for that instance.   When a reference count for a instance becomes zero, ARC will deallocate the instance, if the instance is no longer needed. Now we will see a simple example for retain cycle and will debug to break the retain cycle. Project Details Here we are having a sample project with two View Controllers FirstFloor and SecondFloor. In FirstFloor we are having a button to go SecondFloor and a label to display a message that we pass from SecondFloor. In SecondFloor we are having a text view to type message and a button to send the message to FirstFloor. Here we are having a delegate method in SecondFloor to pass message to FirstFloor. protocol SecondFloorDelegate {\r\n   func shareMessageToFirstFloor(message: String)\r\n} When a button is pressed in FirstFloor we will navigate to SecondFloor. Here you could see for the FirstFloor instance, we have created a reference and assigned to SecondFloor’s delegate method. So, reference count for FirstFloor is 1. @IBAction func goToSecondFloor(_ sender: UIButton) {\r\n   let reference = self\r\n   secondFloorVC = UIStoryboard(name: \"Main\", bundle: nibBundle).instantiateViewController(withIdentifier: \"SecondFloorVC\") as! SecondFloor\r\n   secondFloorVC.secondFloorDelegate = reference\r\n   self.present(secondFloorVC, animated: true, completion: nil)\r\n} After typing message, we are sending message to FirstFloor. Then we are dismissing from SecondFloor. @IBAction func sendMessageToFirstFloor(_ sender: UIButton) {\r\n   if let delegate = secondFloorDelegate {\r\n      delegate.shareMessageToFirstFloor(message: messageToFirstFloorTextView.text)\r\n   }\r\n   self.dismiss(animated: true, completion: nil)\r\n} Here ARC won’t deallocate SecondFloor instance. Because we have created a strong retain cycle between FirstFloor and SecondFloor. var secondFloorVC: SecondFloor! @IBAction func goToSecondFloor(_ sender: UIButton) {\r\n   let reference = self\r\n   secondFloorVC = UIStoryboard(name: \"Main\", bundle: nibBundle).instantiateViewController(withIdentifier: \"SecondFloorVC\") as! SecondFloor\r\n   secondFloorVC.secondFloorDelegate = reference\r\n   self.present(secondFloorVC, animated: true, completion: nil)\r\n} So we need to break the retain cycle to deallocate SecondFloor Instance. So we will see how to debug and break the retain cycle. Debugging Memory issue Usually in debug navigator you will be able to see references. Now I kept a break point in FirstFloor inside goToSecondFloor IBAction method. Here you will able to see value types by displaying values and reference type with its memory address. Also you could see both the reference variable’s memory address and self’s memory address are same. Now we are going to see how to debug memory issue. Click on the Debug Memory Graph option in the Debug Tab bar. Now you will be able to see the references we are maintaining in our project. Here we could able to see AppDelegate method which is Singleton and with one SecondFloor instance which was not deallocated. If you click on the SecondFloor reference you will be able to see the retain cycle in the graphical representation. Here we are having a strong retain cycle between FirstFloor and SecondFloor. So we need to break that retain cycle. There is also another way to Debug Memory issue. For that first you need to clean the project folder(cmd + shift + k) and profile your project(cmd + I). Xcode has a inbuilt developer tool called Instruments. In that we are having Allocations to track virtual memory and heaps. Choose Allocations, In top left corner of Allocations tool choose your device and project you profiled and click on the record button. Instruments will start recording, you can perform the screen navigation in your device/simulator and stop recording.   In Allocations, you will have different option to see the result like Statistics, Call Trees etc. Here I am choosing Statistics option to see the result. Now I am selecting Statistics option to debug. Here you will able to see the number of columns and rows of the recorded result. The third column Persistent Bytes represent total number of bytes currently used by our application. Persistent column represent number of references currently maintaining in our project. Transient column represents Number of references totally created by our project. Now I am searching for SecondFloor’s reference by typing Floor in the bottom left search bar in Allocations. Now you will able to see filtered results. Currently we have one FirstFloor and SecondFloor instance persisting. You could also able to see three Transient instances of SecondFloor. Because I have totally visited four time SecondFloor Screen, three instances which will be no longer needed so ARC automatically deallocated it. One instance of SecondFloor which will never be deallocated. You can also debug using call trees, for that choose main thread and you can debug using their hierarchy. Choose a method that taking higher bytes if you click on it you will able to see source code of that method. Now you switch to statistics mode you will able to see the instance. Solving Memory Issue var secondFloorDelegate: SecondFloorDelegate! We have created a strong reference cycle between FirstFloor and SecondFloor. We know that ARC won’t increment reference count for weak or unowned reference. So we are making SecondFloor instance as weak. weak var secondFloorVC: SecondFloor! By making secondFloorVC instance as weak we could be able to break the reference Cycle. Now we have seen how to debug a basic memory issue using Allocations in detail. In our next blog we will see in detail about some of the most common memory issue mistakes faced in the project. – Srikanth T, iOS Development Team, Mallow Technologies . Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-07-27"},
{"website": "Mallow-Tech", "title": "UI Testing for Mobile Applications – A Brief overview", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/07/ui-testing-for-mobile-applications-a-brief-overview/", "abstract": "Nowadays the there is a huge market for mobiles and mobile application testing became more important and exciting day by day. You can’t just leave it by testing only functionality of the mobile application. Testing has gone to the next level by field testing, UI testing, battery life testing, network testing etc…. and UI testing is one of the most important testing to be done. When the user downloads mobile application from Play store/App store, first thing that attracts the most is its UI and design. How to decide the UI of the application: Mobile apps are divided by different category and how much % these apps holds in the market. Categories Percentage in market Games 24.43% Business 10.07 Education 8.82 Lifestyle 8.61 Entertainment 6.31% Utilises 4.95% Travel 3.98% Book 2.99% Health and fitness 2.97% food and drink 2.83% In above chart, the Games has the majority of 24.43% of market share followed by Business and Education apps. Life style and travel apps are commercial app which has to be done complete UI testing. Business apps are only used by particular set of peoples, so compete UI testing is not necessary. For gaming apps the UI is the main strength and biggest contributor, so UI should be concentrated more on testing to gain more success. Important things to be done on Mobile testing: 1. Screen resolution: Following are some of the common screen resolutions that are considered while creating test beds: 640 × 480 800 × 600 1024 × 768 1280 × 800 1366 × 768 1400 × 900 1680 × 1050 The mobile apps must be tested in the following resolutions. 2. Different UI elements: The UI elements like headings, buttons, images, icons, feilds., text areas, check boxes etc.. should be same all over the app and it should be verified in all resolutions and mostly used mobile brands(Samsung, Moto, Redmi) to ensure whether its looking similar with any issues. 3. Multi-touch or Single touch: If the app is supporting multi touch features like shrink, Zoom, Pinch etc.. should be tested by preparing lots of test cases to ensure whether its meets users satisfaction. 4. Color and Theme Scheme of the Device: Each and every application have their unique colors and Theme which should be consistence all over the app and it should be testing in different mobile models. Real Devices or Emulators: What to Choose for UI Testing? Whether to test on a real device or emulator or both? There’s no firm answer to this because the choice depends on what you want to test. For testing the functionality, performance, network response, field test etc., you should always prefer a real device. But for things like UI you should choose emulators along with some real devices. Pros: The pros of using emulators for UI testing are, 1) It is not practically possible to collect the devices of all resolutions and that would also cost an enormous amount of money. But emulators cost nothing. 2) With an emulator, you can create all screen resolution and OS combinations. 3) If you have only one set of real devices but the QA team is of more than 1 person, then it is not possible that all QAs can test for the same test bed in parallel. With an emulator, every QA can create the same combination on their machine and test in parallel. 4) Testing on an emulator is less time consuming and is faster when compared to a real device. 5) Common bugs related to the UI like alignment etc can be easily caught on emulators. Cons: Cons include the following points. 1) Gestures can’t be tested on emulators. Only one gesture can be emulated at a time. 2) Physical inputs of GPS, dropping or weak network etc also can’t be tested. 3) There is no way that you can create an emulator for Sony, LG, Nexus, etc phones. 4) It is not possible to create a real environment with a low battery or low memory etc., on the emulator. These are the few things to concentrate on UI testing and see you all in some other interesting topic on my next blog. – Kumaresh T, Testing Team, Mallow Technologies. P.S: Image courtesy – Nimbl3 Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-07-24"},
{"website": "Mallow-Tech", "title": "React and React Native – A brief introduction", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/07/react-native-a-brief-introduction/", "abstract": "React is a framework and used for data-driven web interfaces. React is created by Facebook. React provides a component driven architecture which uses a declarative syntax and is easily extensible. What is the difference between React and React Native? React was created for web user interfaces. “Learn Once, Write Anywhere” is the mantra behind React. The set of principles given in React such as the virtual dom, stateful components, layout engine, and many others to the iOS and Android platforms. The benefit of React and React Native is learning once and writing anywhere. If you understand how to build a React Native app for Android, you understand how to build a React Native app for iOS. React Native provides a virtual DOM representation that renders native controls. React Native takes native platform components like sliders, labels, tab bars, switches, and wrap them in React component counterparts. React uses web components as building blocks whereas React Native uses native components. If you already know React, still you need to learn React-Native stuff like the native components. To understand the basic structure of a React Native app. We need to learn some of the React concepts like JSX, state, components, and props. React Native uses the same design as React, letting you compose a rich mobile UI from declarative components. It lets you build mobile apps using only JavaScript. Why do we need to go for React-Native? React Native is built around a rich ecosystem. This is made possible with the help of fellow developers’s willingness. It is well documented and has plenty of plugins available for ease of use. It also has plenty of packages for easy usage. Last but not the least it is Javascript. Build native mobile apps: import React, { Component } from 'react';\r\n\r\nimport { Text, View } from 'react-native';\r\n\r\nclass Sample extends Component {\r\n\r\n  render() {\r\n\r\n    return (\r\n\r\n      <View>\r\n\r\n        <Text>\r\n\r\n          Hi, Basic app using React-Native framework.\r\n\r\n        </Text>\r\n\r\n        <Text>\r\n\r\n          In React-Native, we will use native components like 'View' and 'Text',\r\n\r\n          Where in React we use web components like 'div' and 'span'.\r\n\r\n        </Text>\r\n\r\n      </View>\r\n\r\n    );\r\n\r\n  }\r\n\r\n} A React Native helps us build the real mobile app. You build a real mobile app that is the same as from an app built using Objective-C or Java. React Native uses the same fundamental UI building blocks as regular iOS and Android apps. We just put those building blocks together using JavaScript and React. import React, { Component } from 'react';\r\n\r\nimport { Image, ScrollView, Text } from 'react-native';\r\n\r\nclass ScrollingImageWithText extends Component {\r\n\r\n  render() {\r\n\r\n    return (\r\n\r\n      <ScrollView>\r\n\r\n        <Image\r\n\r\n          source={{uri: 'https://i.chzbgr.com/full/7345954048/h7E2C65F9/'}}\r\n\r\n          style={{width: 320, height:180}}\r\n\r\n        />\r\n\r\n        <Text>\r\n\r\n          On iOS, it uses native UIScrollView.\r\n\r\n          On Android, it uses a native ScrollView.\r\n\r\n          On iOS, native UIImageView.\r\n\r\n          On Android, native ImageView.\r\n\r\n        </Text>\r\n\r\n      </ScrollView>\r\n\r\n    );\r\n\r\n  }\r\n\r\n} React Native lets us build our app faster. Instead of building and recompiling the app, we can instantly reload our app. We can even run new code while retaining your application state. Optimise with Native code: If we need to optimize a few aspects of our application, it is also easy to build part of our app in React Native, and part of your app using the native code directly. Facebook app works the same. import React, { Component } from 'react';\r\n\r\nimport { Text, View } from 'react-native';\r\n\r\nimport { TheGreatestComponentInTheWorld } from './your-native-code';\r\n\r\nclass SomethingFast extends Component {\r\n\r\n  render() {\r\n\r\n    return (\r\n\r\n      <View>\r\n\r\n        <TheGreatestComponentInTheWorld />\r\n\r\n        <Text>\r\n\r\n          We could use native Objective-C, Java, or Swift - the product development process is the      same.\r\n\r\n        </Text>\r\n\r\n      </View>\r\n\r\n    );\r\n\r\n  }\r\n\r\n} Conclusion: In this post we have seen a brief introduction about React and React Native. We have seen some of the reasons to use the new developing technology and ways to optimise the app development process through them. In an another post we will see in detail about some upcoming technologies. – Prakash B, Android Development Team, Mallow Technologies. P.S: Cover image courtesy – Codefluegel.com Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-07-20"},
{"website": "Mallow-Tech", "title": "What’s new in Xcode 10", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/07/whats-new-in-xcode-10/", "abstract": "Xcode is a complete developer tool set which can be used to create apps for Apple TV, Apple Watch, iPad, iPhone, and Mac environment. The development environment of Xcode bundles, Instruments for analysis, Simulator, and several OS frameworks. Apple new release, Xcode 10 beta includes the beta SDKs for iOS 12, watchOS 5, tvOS 12, and macOS Mojave including Swift 4.2. The following are some of the prominent features in Xcode 10. 1. XCODEBUILD The upcoming Xcode 10 launch includes the various command line tools which could be used to achieve tasks through scripts. – Parallel Tests Xcode 10 supports running tests in parallel, which reduces the time it takes to run tests. It’s possible to run the XCTest from the command line using the Xcode build tool. The following are some scripts for enabling parallel testing, – maximum-concurrent-test-device-destinations : depicts maximum number of device destinations to test on concurrently – maximum-concurrent-test-simulator-destinations : the maximum number of simulator destinations to test on parallel – parallel-testing-enabled : indicates the per-target setting in the scheme – parallel-testing-worker-count : exact number of test runners that will be spawned during parallel testing – maximum-parallel-testing-workers : maximum number of test runners that will be spawned during parallel testing. Sample code : $ xcodebuild -project Xcode10-Demo.xcodeproj/ -scheme Xcode10-Demo 'platform=iOS Simulator,OS=12.0, name=iPhone X' clean build test CODE_SIGN_IDENTITY=\"\" CODE_SIGNING_REQUIRED=NO -parallel-testing-worker-count 4 The above command will start the execution concurrently in 4 clones of the iPhone X simulator. – Upload App to App Store It’s possible to upload an iOS app to App Store from the xcode build tool with Xcode 10 release. With the following command $ xcodebuild -exportArchive -archivePath <xcarchivepath> [-exportPath <destinationpath>] -exportOptionsPlist <plistpath> Along with executing the above command, We need to pass the ExportOptions.plist file which will contains the key destination. Xcode should be configured with membership details to connect to Apple developer portal. 2. Code Snippets We can create custom code snippets in Xcode 10 and increase the reusability of the code. This is accessible from Xcode Editor menu — -> Create Code Snippet. We can include snippets for other languages as well. e.g Ruby, YAML etc along shortcut key for the snippets. 3. Multi-Line Editing Xcode10 include support for multi-line editing witch is depicted in below image. We can select multiple instances by holding CTRL+SHIFT and select required the spots. 4. Source Control Enhancements In past WWDC, Apple has already announced tight integration with Github. Apple has now integrated more source control systems like Gitlab and BitBucket. Xcode developers will be able to resolve merge conflicts from the highlights in code. There is a extra interesting feature that allows the users to create ssh keys from Xcode and upload to the remote source control. Developers can perform actions like discard changes, pull changes, rebase change straight from Xcode. 5. Dark Mode Apple’s upcoming macOS Mojave, has a new dark interface which indeed brings dark mode to Xcode 10 environment. You can switch it on from Xcode System Preferences. Xcode 10 provides support with powerful tools for creating one’s own dark apps for macOS. 6. Asset Catalog The asset catalog supports varying image and color by Light, Dark, and High Contrast appearances on the upcoming macOS 10.14 and above. 7. Build System The new build system in Xcode 10 improves the reliability and the build performance. This system detects the project configuration problems which is neglected by the legacy build system. Developers can switch to the legacy build system in Xcode 10 by selecting system setting in File > Project/Workspace Settings sheet. The above are some of the few high-level features of Xcode 10 in action those were announced at the WWDC 2018. As we progress through the WWDC session, we will cover the details of each topic in the later blog posts. – Poorvitha Y, iOS Development Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-07-13"},
{"website": "Mallow-Tech", "title": "Android Architecture Component – VIEWMODEL", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/07/android-architecture-component-viewmodel/", "abstract": "INTRODUCTION : First we need to understand what is meant by android architecture components ? It is nothing but a collection of libraries that helps you in designing a robust, testable, and maintainable apps. It was released by google in google I/O 2017. Now in 1.0 stable version. Following are the key components of Android Architecture and we are going to see about ViewModel in specific : ViewModel Room LiveData Paging DataBinding Lifecycles Navigation and WorkerManager VIEWModel : One of the major headaches for android developer is that they need the fetch data from database (or) call API and present it UI components without delay. Another major problem is that to sustain data (or) fetch data again for orientation changes. For example, let’s assume you have some Activity. Probably you’ll also have some class to store and provide data for UI (like Presenter known from MVP or ViewModel from MVVM). What happens when you rotate the screen? your activity gets recreated probably you need to do fetch data from database (or) make API call again and pass data to the UI components again. There is also possibility of memory leaks of not handling the view holder properly as it may sustain more than the activity. For this google provided alternative solution using the architecture component – ViewModel. ViewModel stores your data and it is lifecycle aware. ViewModel does the following for you : ViewModel will be automatically created by factory methods so you don’t worry about creating or destroying it and as simply as its lifecycle will be handled. Whenever screen gets rotated no need to worry about fetching data again it will be handled automatically and provides the data to the UI components. ViewModel Vs onSaveInstanceState() : Both ViewModel and onSaveInstanceState() are different and both can be used in our application. ViewModel is used situations in where we need to store data for UI components and does not survive when app gets killed. onSaveInstanceState() survive even after app gets killed. So why can’t we use onSaveInstanceState() in all situations? It is not possible because onSaveInstanceState() cannot contain more data and needs to be Parcelable to store and retrieve data. Both satisfy their own purposes. Sample Implementation of ViewModel : Let’s understand the ViewModel with sample implementation as below : First need to add the dependency : implementation \"android.arch.lifecycle:extensions:1.0.0\"\r\nannotationProcessor \"android.arch.lifecycle:compiler:1.0.0\" Create a sample UserViewModel, it must be extending the ViewModel class public class UsersViewModel extends ViewModel {\r\n\r\n     private List<User> userList;\r\n \r\n     public List<User> getUserList() {\r\n        if (userList == null) {\r\n             usersList = loadUsers();\r\n         }\r\n         return userList;\r\n     }\r\n \r\n     private List<User> loadUsers() {\r\n         // do something to load users\r\n     }\r\n } Now we are able to get our userViewModel class in our activity public class UsersActivity extends AppCompatActivity { \r\n\r\n     @Override\r\n     protected void onCreate(final Bundle savedInstanceState) {\r\n         super.onCreate(savedInstanceState);\r\n         setContentView(R.layout.activity_main);\r\n \r\n         UsersViewModel usersViewModel =\r\n             ViewModelProviders.of(this).get(UsersViewModel.class);\r\n \r\n         showUsers(usersViewModel.getUserList());\r\n     }\r\n } That’s it so simple to use ViewModel and it saves lots of our time. CONCLUSION : That’s it so simple to use ViewModel and it saves lots of our time. Already we have seen about Room a component of android architecture . Hope we will see more important architecture components in the upcoming blogs. – Bringe Raj S B, Android Development Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-07-06"},
{"website": "Mallow-Tech", "title": "What’s new in Swift 4.2 – A brief introduction", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/07/whats-new-in-swift-4-2-a-brief-introduction/", "abstract": "Apple has released Swift 4.2 which seems to be a preliminary step for the launch of Swift 5 next year. We will now see some of the improvement in Swift 4.2 which may come in handy in our projects. Random number: Before Swift 4.2: let randomNumber = arc4random_uniform(50) The above code generates a random number from 1 to 50 of UInt32 type. In Swift 4.2: let randomNumber = Int.random(in: 1..<50) Here the above code generates number from 1 to 50 of Int type. The above method applies for similar data types like Float, Double, CGFloat, etc. In case if you were to generate a random bool, you can do easily with Bool.random(). One more addition to the above is we can also generate a random from an array like Let cars = [“Ford”, “Toyota”, “Volkswagen”, “Benz”]\r\n\r\nprint(cars.randomElement()) // Will print any one from above cars array. Shuffling: Shuffling property might come in handy in places where you generate a permutation randomly somewhere like card games. var cards = [“Jack”, “king”, “Queen”]\r\n\r\ncards.shuffle() // Will reorder the array elements in place\r\n\r\nor let cards = cards.shuffled() // Will assign the reordered array back to cards variable Improvements in Sequence naming: Before Swift 4.2: let array = [“apple”, “mango”, “orange”]\r\n\r\nif let appleFruit = array.index(where: { $0  == “apple”) }), {\r\n     print(“Found apple“)\r\n}  else {\r\n     print(“No apples found”)\r\n} The above code takes the index of first element in array which is equal to “apple” In swift 4.2 if let firstFruit = array.firstIndex(where: { $0  == “apple”) }), {\r\n     print(“Found apple“)  \r\n} else {\r\n     print(“No apples found”)\r\n} The index(where:) becomes firstIndex(where:) for proper naming conventions and avoiding confusions. Enum’s new all cases: Often we come across a scenario where need a collection of all the available enum types. Before swift 4.1: enum Cars: String {\r\n\r\ncase Ford = “Ford”\r\n\r\ncase Benz = “Benz”\r\n\r\ncase Audi = “Audi”\r\n\r\nstatic let allValues = [Ford, Benz, Audi]\r\n\r\n} Say for example if we need to print the list of all the cars, then we have to add an additional variable called allCars which is an array of all the available types. In Swift 4.2: We have an new allCases property by default which lists all the available enums, so that we don’t have to manually add a property for it. However, we must add CaseIterable to the declaration for the allCases property to be available. We can call the property like enum Cars: CaseIterable {\r\n\r\ncase Ford = “Ford”\r\n\r\ncase Benz = “Benz”\r\n\r\ncase Audi = “Audi”\r\n\r\n}\r\n\r\nfor car in Cars.allCases {\r\n\r\nprint(car) // Will print “Ford”, “Benz”, “Audi”\r\n\r\n} #warning and #compiler directives Often we use something called //TODO:- which would remind developer to do some task at a later point of time  or a //FIXME: – which is an error or issue that the developer has to fix it. But the problem with above is that, there is a high chance of developer neglecting the above changes. To trigger a warning for every “TODO” or “FIXME” tags, you might have to add a build script in XCode which is something like: TAGS=\"TODO:|FIXME:\"\r\n\r\nfind \"${SRCROOT}\" ( -name \".h\" -or -name \".m\" -or -name \".swift\" -type f) -print0 | xargs -0 egrep --with-filename --line-number --only-matching \"($TAGS).\\$\" | perl -p -e \"s/($TAGS)/ warning: \\$1/\" From Swift 4.2: They have added new compiler directives that help us mark issues in our code. #warning: This is useful reminder about some tasks that the developer has to look on later. func example() {\r\n\r\n/* — */\r\n#warning(\"This method needs to be improved \")\r\n\r\n} #error: This is useful when you cannot proceed without FIXING some issues. Like  providing an api key when you ship a library func credentials() {\r\n\r\nlet username = “”\r\nler password = “”\r\n\r\nif username.isEmpty || password.isEmpty {\r\n#error(“User name and password is mandatory”)\r\n}\r\n\r\n/* — */\r\n\r\n} Conclusion Swift 4.2 improves upon many Swift 4.1 features which makes developer’s life easier and also paves the way for Swift 5. It was great working with Swift 4.2 and looking forward from Swift 5 which will be released early next year. – Rajtharan G, iOS Development Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-07-03"},
{"website": "Mallow-Tech", "title": "Flutter – A Brief Introduction", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/06/flutter-android-a-brief-introduction/", "abstract": "Flutter is a mobile development SDK and an open source project currently in beta. It is developed by Google. It helps you build fast, beautiful and cross platform mobile application. It uses a new language called Dart . What is Dart? Dart is a programming language influenced by Java and JavaScript. Advantage One of the biggest advantages of Flutter is Reactive views and Widgets. Flutter provides Reactive views without need for the javascript bridge. It improves the performance significantly. Everything is Widget Flutter in React Native ? Flutter has used Modern Reactive Framework. Flutter has improved hot reload, easy styling, simple navigation, use of widgets and easy firebase integration. Development in Flutter is comparatively faster. Many features of Flutter are inspired by React Native. Key Features Hot Reload: Flutter’s version of hot reload really ease the effort and makes the development process enjoyable. It is already present in React Native. Smart widgets: If a single widgets has an error in processing, only that widgets and its child will get affected. All other widget will render just fine. In place of affected widgets, the error message is displaced. Everything is a widget: In Flutter, Everything is a widget nested inside the another widget. It comes with beautiful, customisable widgets and we can control the behaviour of each widget and also styling becomes easy. Flutter can run both IOS stimulators and Android emulators simultaneously by using the command “ flutter run -d all ” .This command will run the app in all your open emulators without any visible performance lag. Need to be Improved The app just stops and wont show any error message if there is an conflict with firebase dependencies in android. Flutter is still in alpha, You need to be very careful before upgrading. In future some things might change. Basic animation mentioned in document of flutter works fine. Could not find many resources for adding custom animation. Takeaways We can build our entire app UI by using widgets. Widgets tree will be very useful to track each component of you app. I believe Flutter is going to be major platform for mobile app development. – Saravanakumar B, Android Development Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-06-27"},
{"website": "Mallow-Tech", "title": "Testing Estimation Techniques – A brief introduction", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/06/testing-estimation-techniques-a-brief-introduction/", "abstract": "Estimation techniques are common for both development and testing. In this process we can estimate the testing activities. Nowadays, several organisations are providing independent verification and validation process to their client. Project estimation for a testing team requires experience on various projects and STLC process. This considers the following factors, Team Skills Bug cycles Resource availability System environment Downtime Domain Knowledge The following testing estimation techniques are used, a) PERT software testing estimation technique b) UCP Method c) WBS d) Wide-band Delphi Technique e) Functional point/ Testing point analysis f) Percentage distribution g) Experience -based testing estimation technique PERT software testing estimation technique: This technique is based on statistical methods, which each main task is broken in to various subtasks. and 3 types of estimations are done in each subtasks. The estimations are followed by the below formula. Test Estimate = (O + (4 × M) + E)/6 O = Optimistic Estimate. M = Most likely Estimate. E = Pessimistic estimate. Standard Deviation (SD) = (E − O)/6 UCP Method: UCP stands for Use-Case Point method. UCP Method is based on the use cases where we calculate the unadjusted actor weights and unadjusted use case weights to determine the software testing estimation. Work Breakdown Structure Step 1 − WBS is created by breaking test projects in to small pieces. Step 2 − Sub modules are divided by the modules. Step 3 – Submodules are divided in to further functionalities. Step 4 −Functionalities are divided in to further sub functionalities. Step 5 −All the test requirement should be reviewed. Step 6 − Number of tasks should be figure for each team. Step 7 −Each task effort should be estimated. Step 8 − Each task duration should be estimated. Wideband Delphi Technique: In this method, a team is created with 3-7 members and WBS is distributed to a team for re-estimating the tasks. The final estimate result is based on the team consensus. This method relies more on experience rather than statistical. Functional point/ Testing point analysis: FPS is nothing but the functionality of the software application from the user’s perspective and to estimate the size of the software project. Percentage distribution: PD is the technique in which the each and every phases of SDLC are assigned effort %. Experienced based Testing Estimation Technique: This technique is based on the experience with previous projects, in which metrics are collected and documented from previous similar projects and take inputs from experts who know the application and use metrics you have collected to the testing effort. These are some of the Testing estimation techniques.  We hope the above information is useful and see you in next time with some new content. – Kumaresh T, Testing Team, Mallow Technologies. P.S: Image source – 360logica.com Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-06-21"},
{"website": "Mallow-Tech", "title": "Introduction to Kotlin – Language for Android Application development", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/06/introduction-to-kotlin-language-for-android-application-development/", "abstract": "Introduction: Kotlin is a modern programming language and in future, it might replace the Java language for Android development. In this blog, we will see in detail about its features and its unparalleled attributes. We will see some of the important reasons for Kotlin becoming the official language for Android app development. Kotlin was developed by JetBrains, the developers behind Android Studio IDE. Kotlin community is constantly growing and everyone is discussing it. In this post, we will see how it is different from Java and see in detail about the language per se. Language overview: The latest version of Kotlin is 1.2.41. Kotlin is a statically typed programming language. It means that the type of variable is considered at compile time instead of runtime. The basic examples of other statically typed programming languages other than Kotlin are C, C++, C#, Java, Scala, JADE, Ada, and Pascal. Areas where Kotlin language can be used: Kotlin can be utilized for various types of web and mobile app development such as Client-side web, Server-side web, Android app, Mobile app, Client-side with JavaScript, and Data Science. Java and kotlin: Kotlin works with Java at the same time. It means that you can add the Kotlin code to the existing project even if it is based on Java language. Due to Kotlin’s are bi-directional use, android application developers were able to call into Java language from Kotlin or vice-versa. Which is why kotlin is quite different from other languages. JetBrains has started working on Kotlin, A statically typed programming language, which runs on a ( JVM ) Java virtual machine. JetBrains has done a remarkable job by fusing the Kotlin programming language in the IDE (Android Studio) that is based on the IntelliJ platform. Google has announced that it is making Kotlin a first-class language for writing or to android application developing. We’ve prepared five reasons on why Kotlin has become the official programming language for android application development. Reasons why Kotlin has become the official programming language for Android Application Development: 100 % of Interoperable with Java. Kotlin is Safe Performance It is Concise Great Support for Integrated Development Environment(IDEs) and Tools. 100 % of Interoperable with Java: The main reason why Kotlin has become the first-class language in Android is that it runs smoothly on JVM (Java Virtual Machine). JetBrains developed Kotlin as a JVM programming language, making it 100% interoperable with Java programming language. Android developers can use a lot of Java libraries whilst writing code for Android application in Kotlin. Android developers can generate Java code from Kotlin code using the converters provided by JetBrains. Kotlin is Safe: Android developer biggest pains for while writing the java code in null pointer exception. It is hard to imagine that server developers have suffered from the NullPointerException while writing the codes. Most common drawbacks in many programming languages. Including Java is that accessing a member of a NULL reference will result in a NULL reference exception. Performance: When it comes to the speed, Kotlin does not outperform Java. but, the programming language, Kotlin increases the execution speed of lambda functions by supporting inline functions. It’s has a compact runtime library that adds few methods as compared to Java at runtime. It is Concise: The class written in Kotlin is more concise and compact as compared to class written in Java programming language. It means that less coding is required in Kotlin as an official programming language. Kotlin has reduced the boilerplate codes as compared to Java. So that the code, which is written in Kotlin is quite compact. Saves development time, fewer bugs, and eventually reduce costs. It’s main reasons behind the kotlin popularity in a short span of time. Great Support for Integrated Development Environment(IDEs) and Tools: Android developers can take advantage of robust IDEs. as the IDE has full tooling support from Android Studio. It’s designed with complete tooling support for Kotlin. The developers can write code for the Android application in Kotlin more efficiently and with the development tools provided by Kotlin team. Android extensions to eradicate the findViewById() function using Kotlin. The android extension is computer extension, which allows Android application developers to get rid of findViewById() calls in the code, and to replace with the synthetic computer-generated properties. Android extensions enable programmers to the replace the findViewById() function with the synthetic compiler-generated properties. They use libraries such as Anko (Kotlin Library) in order to fasten the process of android application development. All these components help android application developers to keep the application code more readable and clean. Conclusion: Kotlin has become quickly popular among developers in a short span of time, and become the official language for android application development. – Manikandan K, Android Development Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-06-15"},
{"website": "Mallow-Tech", "title": "WWDC 2018 – A Wrap up", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/06/wwdc-2018-a-wrap-up/", "abstract": "WWDC 2018 is all about big software updates across all Apple platforms. Let’s have a small wrap up of key takeaways from yesterday’s event. Here we go, let’s get started with iOS. iOS 12: As we guessed, the next iOS Version is iOS 12. The iOS 11 has been adopted by 85% of users in just 7 weeks which is fast adoption than Andriod’s 6% adoption of a new OS. In iOS 12, we can work even faster than iOS 11. It is 70% faster swipe to the camera, 50% faster keyboard display and up to 2X times app launching speed on a heavy workload. 🚀 iOS 12 supports all the devices which are supporting iOS 11. This is the first OS which has all device base support for a new OS released by Apple. There are lots of improvements in the photos app. We can share the photos with friends and people who are in the photos. There is a new section called “ on this day” for reminding our memories of a day. They have improved the search option, we can search photos by the object in it and places where we took the photos. Tongue detection – Apple has introduced a new technology called tongue detection in Animoji. Memoji – Unlike Animoji, ok some selected emojis, we can create our own avatar in iMessage. That’s called as Memoji. There are a lot and lots of customisation options are available while creating your new Memoji. Group FaceTime – This a big update for FaceTime users. We can have group FaceTime up to 32 members. Participants can join or leave group FaceTime at any time. We can use Memoji in FaceTime. We can many features like auto zooming/focusing of a participant who is speaking currently in the group to give importance to the content. Notification – In iOS 12, we can have grouped notification based on app and we can have control over notification setting in notification centre itself. Just like Do not disturb while driving, we have Do not disturb in bedtime. Do not disturb end time “for 1 hour”, “Until this evening”, etc.. in iOS 12. Screen time – This new app will be useful for many social media apps addicted users. We can set a time limit for each app per day, this is will notify us before the expiry time of using that app for a day. Once you crossed the expiry time they will add a cover screen above that corresponding app to stop using that app with dismiss button. So no worries you can continue to use it ✌️ .  We can get a weekly summary of app usage in a device. Completely Redesigned stock apps with Apple news embedded in it for reading business and stock news in parallel. Shortcuts app – A brand new app which is kinda like Workflow app which Apple acquired long back. But it will do more task than workflow app. Siri shortcuts – We can customise our phrases to open any third party app. We have updated version of Core ML. They call it as Core ML 2. ARKit 2 Now it has sharing user experience in AR. Apple introductory new file format called USDZ which allows easy sharing of AR content. Measure app – We can measure all objects in 3D by using brand new measure app powered by ARKit. WatchOS 5: Activity competition and awards. – We can share our workout with others and start a new competition. On completion of a competition, you will be awarded for your work. New workout type – yoga and hiking No longer need to say hey Siri to activate Siri. Just raise your wrist to activate Siri. The podcast is now available in watch OS. WebKit – We can load interactive web content in watch OS using WebKit. tvOS 12: iTunes has a large collection of 4K movies. Dolby Atmos support is now available. Live sports and news. Charter spectrum partnership coming later this year. Support for third-party remotes is available. Will show aerial screen savers locations, can swipe between locations. Stunning Earth aerial screen saver filmed by ISS. Zero sign on – Last year we had Single sing on for accessing all content in single sign-on. But now it’s Zero. No sign on is required access all your contents. MacOS Mojave: Dark mode including many default apps(Xcode support as well) Dynamic desktop – Desktop subtly change throughout the day. Morning it will shine like morning view in real time, the brighter in afternoon time, less bright in the evening time and dark in the night time. Gallery view in finder for a better view of files, videos, images, sheets, etc.. Continuity camera – You can prompt iPhone to snap a photo from its camera and you can use in your Mac within a second. Improvements in quick look – We can have markup options in quick look of a file, video trimming option for video files, etc.. Stack desktop – Just for cleaning your huge dirty desktop in single click as a group of files based on added time, kind, etc.. This is called as stack desktop. We can do more customisation in files stack. Great security update against social fingerprints in safari. Create ML app – We can train our ML model without being an ML expert in a faster way. Apps – We have following iOS famous apps in new Mac OS. Voice memo, News, Stocks and home app. Completely redesigned Mac App Store just what they did in iOS App Store in last year. This is the wrap up about the event. In our future blogs, we will see some of the features in detail. – Karthick S, iOS Development Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-06-05"},
{"website": "Mallow-Tech", "title": "Facial Recognition in iOS with AWS Rekognition – II", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/05/facial-recognition-in-ios-with-aws-rekognition-ii/", "abstract": "In our previous blog, we have seen a brief introduction of AWS Rekognition service and its advantages . As I stated before we are about to identify your app’s user based on the picture. For this, you need two things for identifying your app user using their picture, The current picture of the user. Old picture of the user to compare with the current picture. In this part of this series, we will see how to create a new face collection in AWS Rekognition and how to add users face in it. Let’s get started, Where to save the old picture and how? When a new user signs up to your app, you can ask them to upload the valid image as their profile picture. If they upload a valid image, you can save their image to face collection in AWS Rekognition. Face collection? What it is? Face collection: This is the place where AWS Rekognition will maintain all your user’s face data as mathematical value. When you try to search a user by using their current photo, AWS Rekognition will extract feature vectors(Mathematical value) from the currently uploaded image and will check whether the same kind of feature vectors are available in face collection. You will get a response based on the result of the searching process. Let’s see how we can create face collection in AWS Rekognition from your iOS app using AWS Rekognition SDK. Before start creating your face collection you have to setup few things, Integrate AWS Rekognition SDK using cocoapods or by doing the manual integration. Create a new pool ID in AWS. For complete procedure refer to this link. AWS setup: Before starting anything in AWS Rekognition we need to do following setup in AppDelgate. You can add this logic in didFinishLaunch(…) method import AWSCore\r\nimport AWSRekognition\r\n\r\n// AWS Configuration\r\nlet credentialsProvider = AWSCognitoCredentialsProvider(regionType:.EUWest1, identityPoolId: “Your identity pool ID”)\r\nlet configuration = AWSServiceConfiguration(region: “Your region”, credentialsProvider:credentialsProvider)\r\nAWSServiceManager.default().defaultServiceConfiguration = configuration 1. Creating new face collection: The below code help you to create new face collection in AWS Rekognition. import AWSRekognition\r\n\r\nlet colRequest = AWSRekognitionCreateCollectionRequest() // 1\r\ncolRequest?.collectionId = “configure_your_face_collection_id_here”  // 2\r\nAWSRekognition.default().createCollection(colRequest!) { (response, error) in  // 3\r\n    if error == nil {\r\n        // face collection is successfully created.\r\n    } else {\r\n        // Request Failed\r\n        print(error)\r\n    }\r\n} Description: 1. We need to create new AWSRekognitionCreateCollectionRequest to create new face collection in AWS Rekognition . 2. Configure your face collection ID for your new face collection. In future, we need to use this face collection id to search, indexing operation, etc… 3. Start creating new face collection by calling .createCollection with AWSRekognitionCreateCollectionRequest. 2. Saving user’s picture in face collection: You have successfully created face collection in AWS Rekognition. Next thing is you have to save your user’s face in it. The below code will help you to save your user’s face in your face collection. import AWSRekognition\r\nlet indexReq = AWSRekognitionIndexFacesRequest() // 1\r\nindexReq?.collectionId = \"configure_your_face_collection_id_here\"  // 2\r\nindexReq?.externalImageId = “configure_your_user_id” // 3\r\n\r\nlet image = AWSRekognitionImage() // 4\r\nimage?.bytes = imageData // 5\r\n\r\nindexReq?.image = image // 6\r\nAWSRekognition.default().indexFaces(indexReq!) { (response, error) in\r\n    if error == nil {\r\n        print(\"Error occured\")\r\n    }\r\n} Description: 1. For saving a face in the face collection we need to use . indexFaces method in AWS Rekognition SDK using AWSRekognitionIndexFacesRequest. 2. Configure your face collection ID which you configured in Creating new face collection process. 3. Configure the external image ID of the image which you are uploading. You can configure a unique value of your user as external Image ID. Say for example User ID. 4. Create a new AWSRekognitionImage instance 5. Assign your input image data as bytes of AWSRekognitionImage. 6. Assign your AWSRekognitionImage instance as an image value of indexReq. 7. Hit .indexFace function in AWS Rekognition SDK. In this post, we have seen how to create face collection and adding a face to it. In this process, we have many issues, if your user uploads any celebrity image, the object image, etc. it will accept. But when you search it by using user’s current image you will get nothing. For this, we need to add many validations to make sure your user is uploading their original image. In next blog, we will see how to identify your user using user’s current picture and how to add validation while uploading face to face collection. – Karthick S, iOS Development Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-05-23"},
{"website": "Mallow-Tech", "title": "iOS updates from WWDC 2018 – Siri Shortcuts", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/06/ios-updates-from-wwdc-2018-siri-shortcuts/", "abstract": "We saw the key takeaways from WWDC 2018 in one our previous post. In this post we will see in detail about the Shortcuts feature. The main idea behind launching shortcuts is to give the apps a new way to communicate with Siri. Basically, Siri Shortcuts lets you automate some of the common tasks you perform every day with your apps. This can be done in one step, like ordering a cup of coffee, or multi-step processes that involves several different apps. One simple example Apple used on WWDC presentation was accessing hotel reservation information from the Kayak app. Instead of having to launch the Kayak app and search for the needed information, you can use the new “add to Siri” functionality. Once added to Siri, you just record a shortcut — the phrase you want to use with Siri to trigger the action (in the Kayak example, it was “travel plans”). Once enabled, using that phrase with Siri will bring up the information directly from Kayak without launching the app. A Shortcuts app There will be a dedicated Shortcuts app for iOS users.The app might look quite similar to the workflow app. This app will use a simple drag and drop UI, so you can create very specific shortcuts. For example, you could set up a shortcut for your daily routine activities like sending a text message, playing your music just by telling Siri “I’m going home.”  Also if you are cricket fan and you want to see the scores everyday at a particular time, you can add short with phrase like “It’s play time” which will bring you the latest scores of live matches without having to launch the app. People will also be able to use the new app on the iPhone , iPad , HomePod or Apple Watch , through Apple’s new iOS 12 Suggestions: Like Shortcuts, Siri Suggestions automates common activities you do inside a app without actually having to launch the app. The assistant will suggest the action right on your lock screen based on your prior activities. For example, if you always open a particular app every morning, or put your phone on Do Not Disturb mode while driving, iOS 12 will be able to send you suggestion involving these activities so that you can add a shortcut. So whether you use the Shortcuts app or just rely on Siri’s new Suggestions feature, Apple’s assistant should be making your life quite easier from iOS 12. We will see in detail about the other features that were announced in the upcoming posts. – Bharath R, iOS Development Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-06-13"},
{"website": "Mallow-Tech", "title": "Various Types of Testing – A Brief Introduction", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/05/various-types-of-testing-a-brief-introduction/", "abstract": "In general, Testing is in order to check or evaluating the software which is created by the developer is working as per the customer requirement specification is called testing, If the Tester noticed any deviation in the functioning of the software which is created by the developer is called Issue or Bug or Defect. This unexpected behaviour of the software is also called as Error. Manual Testing Testing the software which is created by the developer is working as per the customer requirement specification by without using any Automation Tools, there are various kinds of testing methods available in Manual Testing yet, Manual testing plays an important role in the Software testing even for a company which has automated most of its task successfully. In this post, we will discuss in brief about various Testing types: Types of Testing ⁃ White Box Testing (WBT) ⁃ Black Box Testing (BBT) ⁃ Functional Testing (FT) ⁃ Integration Testing (IT) ⁃ System Testing (ST) ⁃ Acceptance Testing (AT) ⁃ User Acceptance Testing (UAT) ⁃ Unit Testing ⁃ Performance Testing ⁃ Usability Testing ⁃ Soak Testing ⁃ Adhoc Testing ⁃ Smoke Testing ⁃ Sanity Testing ⁃ Regression Testing ⁃ Retesting ⁃ Alpha Testing ⁃ Beta Testing ⁃ Internationalisation Testing ⁃ Localisation Testing ⁃ Statement Coverage ⁃ Condition Testing ⁃ Stress Testing ⁃ Mutation Testing White Box Testing -Testing is done by the developer, they can do the testing in the source code of the application which is created is working properly or not. Black Box Testing -Testing is done on the application which is created by the developer is working properly or not is called black box testing, its done by the testing team or tester. Functional Testing -Checking for the each and individual component of the software is working properly or not is called functional testing. Eg.login button. Integration Testing -Checking for the communication happens from one module to another module in the software is called Integration testing. Eg.Login page to Welcome page System Testing -Checking the software with different environments and its also testing it End to End. Eg.Login page to Logout page Acceptance Testing -Checking whether the software created satisfies the customer requirements without any issue or not. This testing is done on by the tester within the company. User Acceptance Testing -Once the software is created by the company, the customer can do the testing in particular software in their place with their environment and specification. In order to ensure that the software satisfies their requirements and works as per their expectations. Unit Testing -Unit testing, a testing technique using which individual modules are tested to determine if there are any issues with the developer himself. The main aim is to isolate each unit of the system to identify, analyse and fix the defects. Reduce Defects in newly developed features in the existing application and it’s often done by the programmer. Performance Testing -Checking the Time taken for a particular application to respond and perform well under the expected workload is called performance testing. Usability Testing -Checking the user-friendly nature of the application or software, flexibility in handling controls and ability of the system to meet its objectives. Soak Testing -Applying a certain load over a particular period of time and test that how far the application is able to handle it perfectly. Adhoc Testing -Adhoc Testing means testing is done without any proper planning and documentation, ad-hoc testing is the least formal test method. Smoke Testing -Testing that the given build by the developer in the testable format and also to ensure that the most important function of the software is working properly as per the requirement. Sanity Testing -Testing done when we do not have enough time to test is called sanity testing and it is also called surface-level testing to verify the most important functions and commands available in the product is works fine. Regression Testing -Re executing all the test case which is created in the module wise structure is called regression testing and also ensures that the newly added feature does not affect the existing functionality of the application. Retesting -Executing the failed test cases(i.e.)The issue which we have reported to the developer team is once got fixed we will do re-execute the failed test-cases and check the issue got fixed and its work as per the requirements is called Retesting. Alpha Testing -Testing the software which is created by the developer by setting the user environment within the company and do the testing by testing team and also calling the customer to the company, its also called as user acceptance testing. Beta Testing -Testing is done on with the application by installing and checking whether it satisfies the customer requirements without any deviation in the requirement is called beta testing. Internationalisation Testing -Developing and Testing the internationalised software and its able to adapt for different countries with different languages is called internationalised software, we do testing in the internationalised software is called internationalisation testing. Localisation Testing -Adopting an internationalised software to the specific region and specific country is called localisation, testing that software is called localisation testing. Statement Coverage -Checking each and every line of the statement if it is working properly or not is called statement coverage. Condition Testing -Checking the true or false conditions if it is working properly is called condition testing. Stress Testing -Applying a load over than the desired load and checking how far the application able to handle is called stress testing. Mutation Testing -We purposely change the source code of the application which is created by the developer and do WBT. If the WBT get passed then the application which is created is totally wrong if the WBT gets failed the application which is created is 100% perfect, this kind of testing is called mutation testing. In this blog, we have seen about the Testing types and hence it could be useful and I will be with another new topic in my next blog. Manikandan S, Testing team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-05-16"},
{"website": "Mallow-Tech", "title": "Key Takeaways from Google I/O 2018", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/05/key-takeaways-from-google-io-2018/", "abstract": "Google conducted it’s annual Google I/O conference at Mountain view. It started on May 8th and on the first day was exciting and they announced some very interesting projects and updates. We will see some of the important snippets of their announcements in below. Before looking into the key takeaways, here are few wow moments it’s going to be …. So hereafter you don’t need to write… Smart Compose is there !!! you don’t need to speak … Google Assistant is there!!! You have to talk to devices … Smart Displays are there !!! Robot revolution has started!! Keynotes: AI & Healthcare AI can help predict cardiovascular risk, and detect it non-invasively. Pichai says AI will field trials to diagnose diabetic retinopathy in developing countries. Machine Learning & Morse Code This helps someone with a disability who requires a Morse code device to communicate. Google says these devices can now be powered by the company’s algorithmic keyboard, Gboard. Smart compose predictions Therefore Google will launch this feature to all Gmail users this month. You will have someone completing your sentences, hence a lot more emailing than ever before. Google photos You will now be able to make your kid look cuter in pictures, make the colours pop, recreate old pictures. If you have a friend’s photo Google photos will suggest one hit share to them. AI will be seamlessly integrated with photos to cherish all your memories. The future of Voice call! Google Assistant will now make phone calls on your behalf. If you are looking to book an appointment for a restaurant, Google Assitant will make that for you in a seamless conversation and then gives you a confirmation notification. App remainders for breaks! Apps like YouTube will soon have reminders for breaks. There’s a dashboard that will show your phone usage and tell you to stop. You can monitor and manage your daily usage of your mobile applications. Revamped Google News New Google News will give you key 5 stories right at the top when you open the app. The app will feature big headlines, local news, YT videos, and more. AI intimidating to developers AI expertise is hard to come by, and it’s intimidating to developers. So Google is launching a new set of AI APIs called ML Kit. ML kit will open a lot of avenues to explore for the developers. Enhanced Google Lens Starting next week, Google Lens will be integrated right into the camera app of Google Pixel devices, LG G7, and other Android phones. New features for Lens now includes smart text selection which will help the phone camera understand words. Google Lens is using image and object recognition to identify stuff in photos: landmarks, food, etc. Street View will now call out locations with on-screen overlays. Waymo Waymo uses simulation to train its self-driving cars, and the systems have driven more than 5 billion miles in a simulation. Waymo is running a constant simulation with 25k cars in it. Google’s these announcements are really groundbreaking in terms of AI growth. Let’s have to wait and see how it will change the way market is working and it very well has the potential to disrupt the market. – Indrajith, Android Development Team, Mallow Technologies . Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-05-09"},
{"website": "Mallow-Tech", "title": "8 Factors for an iOS developer to know apart from Swift, Objective-C and Xcode", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/05/8-factors-for-an-ios-developer-to-know-apart-from-swift-objective-c-and-xcode/", "abstract": "Becoming an iOS developer is a dream for many programming enthusiasts. What makes a developer better than others is the quality and efficiency of the code. Below are the steps one has to know to become a better developer. WWDC Conference: WWDC is Apple’s Worldwide Developers Conference. In WWDC, Apple releases its new OS for iPhone/iPad and Mac. They will have a 1-week session. All the session videos will be published on their site and the developers can easily gain insights through those. As a developer, it is essential to have updates from this conference to update one to the current trend. This year WWDC is on June 4th . Apart from the WWDC some of the other conferences to follow can be seen here . Learn through Tutorials: Apart from Apple documentation learning from tutorials gives an edge in learning and understanding the concepts. A huge number of tutorials are available for implementing various features in iOS. By learning through tutorials you can try out new features and explore the concepts. Some of the tutorials I follow are RayWenderLich , Stanford Video Course , Appcoda . Here you can get a number of tutorials. Keeping up with Weekly blogs: Reading weekly blogs to understand the trend and progress of the contemporaries is important. It helps you in being relevant in this dynamic field. iOS Dev Weekly , Swift Weekly are some of the blogs which give you some better insights regarding iOS developments. Here you can get a number of blogs to follow. Well versed with App Store guidelines: Before beginning any application it is essential to be well versed with the App Store guidelines . App store guidelines are stringent than of Android Play store guidelines and perfecting an application that meets the standard guidelines of App Store is much more important and that makes an app get a way to reach the major audiences. Before beginning any project, you have to check if any of the features is violating the App store guidelines or not. This saves a lot of time and helps in avoiding last minute changes. Before any app comes to AppStore there is an AppStore review process in the process they will check whether the App has met the guidelines properly. App Distribution process: Once an application is developed before uploading the app in Appstore it will be given to testers for testing purposes. One should be aware of the App distribution methods to do this process correctly. App distribution in Android platform is simple, as we can generate APK of the file and share it with all we want. But in the case of iOS, it’s pretty complicated. In iOS, we need to create an App-Id, certificate and profiles for distributing our Apps. You can follow the link to create the App-Id, certificate and profile process. Apple provides a service called Testflight to send the beta version across of the testing users. Some of the services I am using are TestFairy , Instabug , AppBox , Diawi , Fastlane . The service to be used can be decided based on the particular needs and constraints. Analytics: Analytics is the key to understanding the success of an application and plays a major role in driving the application towards success. There is a huge number of applications available to check the app analytics ranging from Google, MixPanel and iTunesConnect. Making use of it properly and exploring it to the fullest makes you a complete iOS developer. Some of the services which I use are InApptics , Mixpanel and Google Analytics . You can get more insights regarding the Analytics tools from this medium blog . Crash Reports: One of the most important thing after completing the development of an application is looking for the App crashes. App crashes play a major role is user engagement and success of an application. You should track the crashes in the app regularly so that to fix it in the next update. If the frequency of the application crash increases then highly likely for the person to not use the app more than ever. Some of the prominent crash services used are Google Analytics ., Crashlytics. You can get the crash report from iTunesConnect also. Optimal usage of Libraries: You might be well versed in handling few things in iOS but it might take time. Instead, you can use the third party libraries to finish the work in no time. With the help of libraries, you don’t have to handle all the scenarios by yourself. You can also contribute to the libraries which will be of a great help to the community. From these libraries, you can learn a new way of coding, approaches and understanding of other’s code. Some of the famous third party libraries are Awesome , Alamofire , Alamofire Image , IQKeyboardManager , Moya , DZNEmptyDataSet and MGSwipeTableCell . Here you can get best libraries to be used. Conclusion: In this blog, we have seen 8 must known factors for an iOS developer to excel in creating an application in iOS platform successfully. – Yogesh M, iOS Development Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-05-02"},
{"website": "Mallow-Tech", "title": "An Introduction to Test Driven Development", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/05/an-introduction-to-test-driven-development/", "abstract": "Test-driven Development also called as test-driven design, is a method of implementing software programming that interfaces unit testing, programming and refactoring on the source code. Testing is an essential aspect of providing quality applications. Manual testing is tested only in limited ways. Making tests in depth is only achieved by writing automated test code.TDD consistently produces well-structured, resilient and easy to make changes to as business requirements. PHPUnit which is used to write automated test code is a programmer-oriented testing framework for PHP. Thus the importance of testing and its implementation and usage of PHPUnit is explained below. Testing: Testing means revealing capabilities by putting them under strain; challenging. Testing is required to point out the bugs and defects that were made during development. In general, such tests had been written using Unit Test framework. In best practices testing is carried out via TDD(Test Driven Development). Test Driven Development: The process involved in TDD is simply said to be RGR (Red Green Refactor pattern). Red for the failed test case. Green for making test case work by adding code. Refactor for restructuring existing code. The flow of Test Driven Development : The developer writes the automated test case for the desired new function. Then produce the minimum amount of code to pass the test. Refractor the produced code. (Process of restructuring existing code without changing its external behaviour) Factors considered for writing testing code, Valid inputs Invalid inputs Errors, exceptions, and events Boundary conditions Everything that might break PHPUnit: Testing in PHP is carried out with Unit Testing provided by PHPUnit. • It is a programmer-oriented testing framework for PHP. • It belongs to the family of XUnit test libraries. • It is created by Sebastian Bergmann. Running an automated unit test is much faster than manual testing. The name itself describes that Unit-Testing. A Unit is the smallest part of an application, it might be a set of code or function or class. Testing those units provides the term called Unit Testing. Whenever you make changes to the code, just run those set of tests and watch if anything fails. If everything passes, then it’s assured that you haven’t broken any functionality of your application. A simple example is mentioned below PHPUnit generates output as All we know that testing helps bug fixing and verifying the proper execution of code. But how we know that all our codes are tested by the given set of unit tests. Here comes the tool called Code Coverage. Code Coverage – PHPUnit: Testing improves the quality and predictability of an application. But adding more test cases doesn’t mean that the application code has better quality. Sometimes you may end up with situations like testing the same code over and over again while missing an important piece of code entirely. Code Coverage report helps the developer to make a quick analysis of codes which are covered and uncovered by Unit Testing. Metrics for Code Coverage, • Line Coverage checks whether each executable line was executed. • Function and Method Coverage checks whether each function or method was covered. * PHPUnit Code coverage considers a function or method is covered only when all of its lines are executed. • Class and Trait Coverage checks whether each method of a class or trait was covered. * PHPUnit Code coverage considers a class or trait is covered only when all of its methods are executed. • Other coverages are Opcode Coverage, Branch Coverage and Path Coverage. But these coverages are not supported by PHPUnit Code coverage. For additional Reference: https://phpunit.de/manual/current/en/code-coverage-analysis.html Conclusion: Thus the apps built with TDD tends to have less duplication, fewer edge cases and a better overall architecture. There is no better way to save money and time while making sure that you have a codebase that is easy to maintain, extend and resistant to change. Will catch you soon with a detailed explanation for RGR pattern in next blog. – Kumaravel K, PHP Development team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-05-08"},
{"website": "Mallow-Tech", "title": "An Introduction to Room Persistence Library in Android Development", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/04/an-introduction-to-room-persistence-library/", "abstract": "It is not a very difficult task for Android developers to store raw data into a database for internal storage. But still they wish to have an efficient library to overcome boilerplate codes and compile-time verification for queries, here comes the relief Google announced Room Library in Google Developer meet 2017. The Room is a persistence library, part of the Android Architecture Components . It makes it easier to work with SQLiteDatabase objects in your app, decreasing the amount of boilerplate code and verifying SQL queries at compile time. There are three major components in Room: Entity: represents data for a single table row, constructed using an annotated java data object. Each entity is persisted into its own table. DAO: (Data Access Object) defines the method that accesses the database, using annotation to bind SQL to each method. Database: is a holder class that uses annotation to define the list of entities and database version. This class content defines the list of DAOs. Annotations in Room Persistence Library Annotations Purpose @Entity Creates an SQLite table in the database using a data model class. @Dao Create a Data Access Object in the database using an interface class. @Database A class with this annotation will create an abstraction for the Data Access Object. @PrimaryKey A variable with this annotation will set a primary key for the table. @Insert Inserts parameters into the table. @Update Updates parameters of an existing table. @Delete Deletes parameters of an existing table. @Query Running SQL query method within the table @Ignore Ignores the parameter form the Room database Let’s look at a sample implementation: 1. Add these dependencies in module build.gradle // Room (use 1.1.0-beta3 for latest beta)\r\nimplementation \"android.arch.persistence.room:runtime:1.0.0\"\r\nannotationProcessor \"android.arch.persistence.room:compiler:1.0.0\" 2 . Add the Google Maven repository Android Studio projects aren’t configured to access this repository by default. To add it to your project, open the build.gradle file for your project (not the ones for your app or module) and add the google() repository as shown below: allprojects {\r\n    repositories {\r\n        jcenter()\r\n        google()\r\n    }\r\n} 3. Defining the Table The class is annotated with @Entity to mark as a table. To make field primary key, you need to annotate a field with @PrimaryKey and property autoGenerate which assign automatic IDs. The room will create a user table with defined attributes. @Entity(tableName = \"user\")\r\npublic class User {\r\n\r\n    @PrimaryKey(autoGenerate = true)\r\n    private int uid;\r\n\r\n    @ColumnInfo(name = \"first_name\")\r\n    private String firstName;\r\n\r\n    @ColumnInfo(name = \"last_name\")\r\n    private String lastName;\r\n\r\n    @ColumnInfo(name = \"age\")\r\n    private int age;\r\n\r\n//...getters and setters\r\n} 4. Creating the Data Access Object (DAO) This class is annotated with @Dao annotation. @Dao\r\npublic interface UserDao {\r\n\r\n    @Query(\"SELECT * FROM user\")\r\n    List<User> getAll();\r\n\r\n    @Query(\"SELECT * FROM user where first_name LIKE  :firstName AND last_name LIKE :lastName\")\r\n    User findByName(String firstName, String lastName);\r\n\r\n    @Query(\"SELECT COUNT(*) from user\")\r\n    int countUsers();\r\n\r\n    @Insert\r\n    void insertAll(User... users);\r\n\r\n    @Delete\r\n    void delete(User user);\r\n} 5. Database Creation Create a database holder called AppDatabase extends RoomDatabase, we will define a list of entities and database version. The class is annotated with @Database annotation. It is good practice to use singleton approach for the database, so you need to create a static method which will return an instance of AppDatabase. @Database(entities = {User.class}, version = 1)\r\n\r\npublic abstract class AppDatabase extends RoomDatabase{\r\n\r\npublic abstract UserDao userDao();\r\n\r\n} 6. One to Many Relation @ForeignKey is used to one to many relationships. Consider each user having many pets, it can be achieved using following example. onDelete = CASCADE is used delete the rows when that user has been deleted from the User table. @Entity(foreignKeys = @ForeignKey(entity = User.class,\r\n                                  parentColumns = \"id\",\r\n                                  childColumns = \"userId\",\r\n                                  onDelete = CASCADE))\r\npublic class Repo {\r\n    @PrimaryKey public final int id;\r\n    public final String name;\r\n    public final int userId;\r\n\r\n    public Repo(final int id, String name, final int userId) {\r\n        this.id = id;\r\n        this.name = name;\r\n        this.userId = userId;\r\n    }\r\n} @Embedded is used for having nested fields in the table. For example, user having address can be related using @Embedded. @Entity\r\npublic class User {\r\n    @PrimaryKey public final int id;\r\n\r\n@ColumnInfo(name = \"full_name\")\r\n    public final String name;\r\n\r\n@Embedded\r\n    public final Address address;\r\n\r\n    public User(int id, String name, Address address) {\r\n        this.id = id;\r\n        this.login = login;\r\n        this.address = address;\r\n    }\r\n} Conclusion: Android developers now feel very easy and convenient to handle raw data and make queries with Room Persistent Library. – Bringe Raj, Android Development Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-04-27"},
{"website": "Mallow-Tech", "title": "An Introduction to UI TESTING in iOS", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/04/an-introduction-to-ui-testing-in-ios/", "abstract": "UI testing is a process of testing how the software interface interacts with a user. It involves checking the ease of access, intuitiveness in navigating, compatibility with all the devices and crashes. It is important to have UI testing at an earlier stage of development to sort out issues at its roots. As time progresses the product becomes more complex and so even a minor issue will take longer and a complex process to sort out and restricts the user from using freely. UI testing can be done in two ways namely Manual and Automated. MANUAL TESTING In Manual testing, the tester will perform the operations by checking how the application behaves. He checks whether the product conforms to the client requirement. This approach has its own advantages and disadvantages. Higher time consumption, the effort needed and quality of the tester defines the success and efficiency of the process. AUTOMATED TESTING In Automated testing, the UI is tested with the help of a code. We can automate the repetitive tasks with the help of a code. By this, we can make testing after Refactoring easier.  In Xcode, XCTest framework and Accessibility tool are integrated which can be used for UI Testing. UI testing works by finding UI object using queries, creates events and sending to objects. We can compare the objects state and properties with the expected state. It is based 3 classes namely XUIApplication , XUIElement and XUIElementQuery . Below we are going to see a sample project for UI testing. SETTING THINGS We can set up UI test while creating a project by clicking Include Unit Tests checkbox or otherwise using File > New > Target and selecting iOS UI Testing Bundle. SET UP PROJECT In our project, we are having a nameTextField, showClueButton and travelToSpaceButtton. Initially, travelToSpaceButtton is hidden and showClueButton is not enabled. @IBOutlet weak var travelToSpaceButton: UIButton!\r\n    @IBOutlet weak var showClueButton: UIButton!\r\n    @IBOutlet weak var nameTextField: UITextField!\r\n    \r\n    // MARK: - View life cycle method\r\n    \r\n    override func viewDidLoad() {\r\n        super.viewDidLoad()\r\n        travelToSpaceButton.isHidden = true\r\n        showClueButton.isEnabled = false\r\n    }\r\n    \r\n    // MARK: - IBAction methods\r\n    \r\n    @IBAction func showClue(_ sender: UIButton) {\r\n        travelToSpaceButton.isHidden = false\r\n        sender.isHidden = true\r\n    }\r\n    \r\n    @IBAction func travelToSpace(_ sender: UIButton) {\r\n        performSegue(withIdentifier: \"ShowSpaceViewController\", sender: nil)\r\n    } TESTING FLOW We are enabling showClueButton when a user enters text using text field delegate method. Once the user taps showClueButton we are making travelToSpaceButtton visible. When the user taps the travelToSpaceButtton we are navigating to next Space Journey screen. The user clicks the start button in the navigation bar to get back to Start screen. // MARK: - Text field delegate method\r\n    \r\n    func textField(_ textField: UITextField, shouldChangeCharactersIn range: NSRange, replacementString string: String) -> Bool {\r\n        if let name = textField.text, name.count > 0 {\r\n            showClueButton.isEnabled = true\r\n        } else {\r\n            showClueButton.isEnabled = false\r\n        }\r\n        return true\r\n    } WRITING THE FIRST UI TEST After setting up a test target we will have a testing template with setUp and tearDown methods. SetUp method gets called before every test cases get started and tearDown method gets called after every test gets completed. Testing methods should start with prefix “test”. XCUIApplication returns the proxy for the application that we set as a target in our project. XCUIElement is the objects encapsulated with information used in UI. XCUIElementQuery is used to query the XCUIElement in the interface. Using XCUIApplication we can access our app then by using XCUIElement we can create events and send to objects so that we can compare the expected output using XCTAssert class. var app: XCUIApplication!\r\n    var nameTextField: XCUIElement!\r\n    var buttons: XCUIElementQuery!\r\n    var showClueButton: XCUIElement!\r\n    var travelToSpaceButton: XCUIElement!\r\n    \r\n    override func setUp() {\r\n        super.setUp()\r\n        // In UI tests it is usually best to stop immediately when a failure occurs.\r\n        continueAfterFailure = false\r\n        \r\n        // Setting up the orientaion\r\n        XCUIDevice.shared.orientation = .faceUp\r\n        \r\n        app = XCUIApplication()\r\n        nameTextField = app.textFields[\"name\"]\r\n        buttons = app.buttons\r\n        showClueButton = buttons[\"Show Clue\"]\r\n        travelToSpaceButton = buttons[\"Travel To Space\"]\r\n        \r\n        // UI tests must launch the application that they test. Doing this in setup will make sure it happens for each test method.\r\n        app.launch()\r\n    }\r\n    \r\n    override func tearDown() {\r\n        nameTextField = nil\r\n        buttons = nil\r\n        showClueButton = nil\r\n        travelToSpaceButton = nil\r\n        app = nil\r\n        super.tearDown()\r\n    }\r\n    \r\n    // Testing UI by writing tests\r\n    func testSucessSpaceJourney() {\r\n        // We can test button state using XCTAssert\r\n        XCTAssert(nameTextField.identifier == \"name\")\r\n        XCTAssertEqual(showClueButton.isEnabled, false)\r\n        \r\n        // After tapping key board appears to type in text field\r\n        nameTextField.tap()\r\n        nameTextField.typeText(\"Mallow Tech\")\r\n        \r\n        // Tap show clue button to make travelToSpaceButton visible\r\n        showClueButton.tap()\r\n        XCTAssert(travelToSpaceButton.isHittable == true)\r\n        \r\n        // Tap travelToSpaceButton to navigate to Space Journey screen\r\n        travelToSpaceButton.tap()\r\n        \r\n        let labelText: String = \"Wecome To Space\"\r\n        XCTAssertEqual(app.staticTexts[\"Wecome To Space\"].label, labelText)\r\n        app.navigationBars[\"Space Journey\"].buttons[\"Start\"].tap()\r\n    } WRITING UI TEST USING UI RECORDING Keep the cursor inside a test method of the test target. Click on the start record option in the debug tab bar. Perform actions in the app which will get recorded. Once actions get recorded we can add assert for expected output in the test code written by XCode. // Testing UI using UI recording\r\n    func testUIRecording() {\r\n        XCUIDevice.shared.orientation = .faceUp\r\n        let app = XCUIApplication()\r\n        let nameTextField = app.textFields[\"name\"]\r\n        \r\n        // We can test button state using XCTAssert\r\n        XCTAssertEqual(app.buttons[\"Show Clue\"].isEnabled, false)\r\n\r\n        // After tapping key board appears to type in text field\r\n        nameTextField.tap()\r\n        nameTextField.typeText(\"mallow\")\r\n        \r\n        // Tap show clue button to make travelToSpaceButton visible\r\n        app.buttons[\"Show Clue\"].tap()\r\n        XCTAssert(app.buttons[\"Travel To Space\"].isHittable == true)\r\n        \r\n        app.buttons[\"Travel To Space\"].tap()\r\n        app.navigationBars[\"Space Journey\"].buttons[\"Start\"].tap()\r\n    } SUCCESS AND FAILURE TESTS In testing, we should write the tests in user’s perspective. We are enabling the showClueButton once nameTextfield got text. Here we are going to write a successful test case that tests the showClueButton’s state. func testShowClueButtonSucessState() {\r\n        // After tapping key board appears to type in text field\r\n        nameTextField.tap()\r\n        nameTextField.typeText(\"Mallow Tech\")\r\n        \r\n        // showClueButton is enabled once we have text in the text field\r\n        XCTAssertEqual(showClueButton.isEnabled, true)\r\n    } We are navigating to space journey screen when a user taps travelToSpaceButton. For testing failure case, we are testing with the start screen navigation bar after we reached the Space Journey screen. Use Cmd + U for running test. func testFailureSpaceJourney() {\r\n        // After tapping key board appears to type in text field\r\n        nameTextField.tap()\r\n        nameTextField.typeText(\"Mallow Tech\")\r\n        showClueButton.tap()\r\n        travelToSpaceButton.tap()\r\n        \r\n        // Currently we are in Space Journey screen\r\n        XCTAssert(app.navigationBars[\"Start\"].exists)\r\n    } CONCLUSION In this post, we have seen the UI testing methods. With a sample project, we saw in detail about Automated testing. In a future blog, we will see about Unit Testing. Srikanth T, iOS Development Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-04-12"},
{"website": "Mallow-Tech", "title": "Apple’s Field Trip iPad event – A Roundup", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/03/apples-field-trip-ipad-event-a-roundup/", "abstract": "Apple has made its major push in the education market. During its keynote in Chicago at the event, the company revealed its plans with a bevy of new apps, APIs and other software tools. Apple announced its cheapest iPad ever. Apple has pitched it specifically for students. 9.7-inch iPad with Apple Pencil support Apple’s 9.7-inch iPad was upgraded with Apple Pencil support. It also comes with a cheaper price tag for some. It costs $299 for schools buying in bulk or $309 if you qualify for special education pricing . The new model includes a speedy A10 Fusion processor along with its 2048-by-1536-resolution display. It includes an 8-megapixel camera on the back, Touch ID, GPS, compass and gyroscope. Apple promises up to 10 hours of battery life. That should be enough for continuous use throughout the school day. Apple Pencil alternative Apple gave a little bit of stage time to Logitech’s Crayon . It’s a cheaper alternative to the Apple Pencil — and built specifically for schools. The sturdy, $49 Logitech stylus is aimed squarely at the educational market. Free iCloud storage upgrade The 5GB iCloud account storage has been upgraded to 200GB for free. However, it is only applied to students. If you’re not a student and you had a 5GB iCloud account, it’s not being upgraded to 200GB for free . The upgrade announced today only applies to students. iWork Smart Annotations are coming to Apple’s iWork suite of iOS apps later this year. With the upcoming versions, along with the Pages, Numbers and Keynote will allow iPad owners draw directly on reports with the Smart Annotations features. It’s a great update for students and regular users alike. Classroom for Mac The teaching assistant app, in the iOS version, helps teachers guide the students through lessons, automate with their progress, and let keep them on track. The all-new Schoolwork app Teachers and students are getting some much-needed help from Apple in the form of the new Schoolwork app . It’s basically a command centre for education. Schoolwork let us assign specific activities within the app, and students will be taken there automatically. The app can also check students’ progress, making it easy to see if they have done their work and helping teachers tailor classes to the needs of individuals. Guider’s can use Schoolwork to give handouts, assignments and apps to their students. They can also use the app to send class reminders about field trips or group work updates. ClassKit API framework To make it easier for developers to create apps that play well with Schoolwork, Apple created a new API called ClassKi t . It does most of the heavy lifting works of integrating with the Schoolwork’s best features so that developers can concentrate on making the best apps on the education platforms. AR apps with Swift Playgrounds Teaching kids to be great Swift coders is high up on Apple’s list of priorities. Augmented reality is one of Apple’s other big priorities, so it’s merging the two with some new lessons in Swift Playgrounds that teach kids how to build AR apps. – Poorvitha Y, iOS Development Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-03-29"},
{"website": "Mallow-Tech", "title": "Facial Recognition in iOS  with AWS Rekognition – I", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/03/facial-recognition-in-ios-with-aws-rekognition-i/", "abstract": "Last year Apple released a new Framework for Machine learning, which is called as CoreML . We can build intelligent apps with the help of CoreML. For this, we need the CoreML model to do an intelligent process, which is like a heart of the machine learning process in your app. Apple providing only a few hands-on models to integrate machine learning inside your app. You can also get some useful models from this website . By using these limited pre-built model you can achieve things using machine learning in your app. We need something better to achieve big things like Facial recognition. Okay, let’s come to our topic. How to do Facial recognition on iOS? When talking about facial recognition using machine learning first we need an efficient highly trained model to analyse your input data(image) and to process it. You have to work hard to train your model for better performance and efficiency. Developing and training a model for better performance is a tedious and tiring process. So instead of creating a new model from scratch, it is better to go with a pre-built model with better efficiency, performance and with a continuous learning capability. AWS Rekognition service is one of the best options for doing visual analysis of images and videos. Introduction to AWS Rekognition service: AWS Rekognition is Deep learning-based visual analysis service for analysing, search and verify millions of images and videos. It makes very easier to add image and video analysis to your app. You just provide the image or video which you need to analyse, they will do all heavy lifting process to analyse your data and return all possible response from the content they analysed. AWS Rekognition can be easily integrated to the other AWS services like AWS S3 and AWS Lambda. So you can develop a scalable and reliable visual analysis application. Uses of AWS Rekognition service: Searchable image and video libraries Face based user verification Sentiment and demographic analysis Facial recognition Unsafe content detection Celebrity detection Text detection Common benefits of using AWS Rekognition service: Integrate powerful image and video recognition into your apps Deep learning-based image and video analysis Scalable image analysis Integrate with other AWS services Low cost The main motto of this series of blogs is to identify(modern way of login) your app’s user by using their picture instead of using a traditional username and password login. So I don’t want to explain each and everything about AWS Rekognition service. If you are interested, feel free to check out below links for more details. AWS Rekognition service docs Link. AWS Rekognition service console Link. Key points about AWS Rekognition service: (Mostly we will discuss Image analysis using AWS Rekognition service) In AWS Rekognition you can search a user by using their live photo. For this, you need to create faces collection and add faces of all users whenever new user signed up your app. You can analyse following basic things in image analysis like person face in the input image is male or female, happy or sad, with a beard or without a beard, etc… AWS providing iOS and Android SDK for Rekognition service. As of now, this service is available only in the following regions EU (Ireland) US East (N. Virginia) US East (Ohio) US West (Oregon) You can send input image in API or you can send AWS S3 image reference to AWS Rekognition service. Your input image to AWS Rekognition should be in .png or .jpg file format. If you have many faces in the input image, Rekognition will detect large 100 faces in the input image. You can set the similarity threshold in compare/search face action. Means for every face search action, they will give the confidence value of the face to be matched with some similar face. We can say like give success response to us only if the confidence value is greater than some value.(Example greater than 99%) AWS Rekognition will not save the actual image in face collection, instead, it will analyse the input image first and extract the feature vectors from the face. It will save only the feature vectors in the collection. Misusing of users faces is not possible since it going to be mathematical values. You can index the user’s face and you can find the user based on this index. You can delete the faces from collections using Face ID if needed. This will be useful when your user changing profile picture or deleting the account. Since Machine learning is all about the prediction of things, you can’t completely rely on it. To make sure your prediction is correct you need to add validation to your app when user setting profile image, it should not be celebrity image, it should not be some object image like flower, car, bike, etc.., it should have person face in image, the calculated age of face in image should approximately match with the DOB if you got it from user, etc. AWS Rekognition has two types of API. In our case, we need storage based APIs Storage-based APIs — For image analysis, we have following operations (Index faces, list faces, search faces by image, search faces and delete faces) Non-Storage based APIs — For image analysis, we have following operations (Detect labels, Detect faces, Compare faces, detect moderation labels, Recognise celebrities, detect text) In next blog, we will start to integrate AWS Rekognition service with the iOS app to identify your user using AWS Rekognition iOS SDK. – Karthick S, iOS Development Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-03-23"},
{"website": "Mallow-Tech", "title": "MQTT Protocol for IoT – A Brief introduction", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/03/mqtt-protocol-for-iot-a-brief-introduction/", "abstract": "What is IoT and Why IoT: IoT is a network of physical devices like home appliances, sensors, etc which can be connected and used to exchange data with each other. Basically, it’s a giant network of connected devices – all of which collect and share data about the way they are used and about the environment around them.This can be anything like smart microwaves which can automate cooking, self-driving cars, etc. It enables devices/objects (thing) to observe, identify and understand a situation without human help and perform a task based on the situation. Some of its advantages include more data, tracking, time and money. We have seen in detail about the IoT in one of our blogs . What is Thing: A ‘thing’ is a term commonly used which refers to a physical device connected to the internet. It can be a mobile device connected to the internet. Now we will see in detail about the MQTT protocol which is a lightweight protocol used to facilitate IoT in a device. MQTT – Protocol for IoT: MQTT (Message Queue Telemetry Transport) protocol complements the necessities of IoT. It is a lightweight protocol designed for publish/subscribe messaging transport. It requires very low bandwidth and has less battery consumption. It can be used in small sensors, home automation devices, etc. Facebook also uses this protocol. https://www.facebook.com/notes/facebook-engineering/building-facebook-messenger/10150259350998920 It is high-level architecture with 2 main parts – (broker and a client) Broker: A broker does the important job with capabilities for both subscribing and publishing. Its primary function is to queue the received messages from the publisher and transmit the messages received to the subscriber client accordingly. Client: MQTT client does very simplified tasks as most of the major handling is done by the broker. They can be run on almost any operating System ranging from Mac, Windows to mobile OS like Android and iOS. The publisher client publishes messages using a TOPIC and QOS. Similarly, a subscriber client subscribes to messages with a TOPIC and QOS. Topic: Every transmission over the network relies on a particular topic. It is nothing but a path where you can publish/subscribe messages. For e.g.: Consider an app connected using MQTT sending current location of the user to the topic like “AppName/Location”. If a client is subscribed to the same topic as said above, they can continuously track the user’s location. If you want to track user app’s battery status apart from tracking the location, then the topic can be configured something like “AppName/UserID/Location”  for location tracking and “AppName/UserID/BatteryStatus” where userID mentions the corresponding user. There are two wild card operators “+” and “#” involved here. “+”  is used where the client receives all arbitrary messages up to one hierarchy while “#” allows messages to be received from all below hierarchy levels. Eg:-  When a client is subscribing to topic like “AppName/+/BatteryStatus”, it will receive battery status from all user. And subscribing to “AppName/userID/#”, it will receive all messages like battery status and location of that corresponding userID. QOS: It stands for Quality of Service. There are basically three types. QoS – 0: This does not guarantee if a message has been delivered successfully. It is like “fire and forget” type. QoS – 1: This guarantees the message will be delivered at least once. But can be sent more than once. QoS – 2: This guarantees that the message is sent only once. The higher the QoS, the higher it consumes bandwidth to process the transmission. Conclusion: Thus we have seen in detail in about the principles of MQTT protocol for IoT. In the future blogs, we will see how the process is done in detail with a sample program for a better understanding. – Rajtharan G, iOS Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-03-15"},
{"website": "Mallow-Tech", "title": "How to redirect to third party app’s App store product page", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/03/how-to-redirect-to-third-party-apps-app-store-product-page/", "abstract": "In many cases of working with an app, we may have a need to access a third-party application from your app. But what if the app which you required is not installed on user’s device? In this case, you can show one message to the user or you can navigate the user to App store to download it. If you simply navigate them to App store user have to search the app which you need and install. There is a chance to user install a different app than you need. To resolve these type of conflicts we can directly take the user to App store product page of the app which you need. Rather than making it more tedious we will see how we can redirect the visitor to the specific app’s product page. We will explain you in detail with an example of redirecting to a Google maps product page in the App Store. 1.The first step is to check whether the particular app is installed on the phone or not. In this case, it is Google Maps. The below defines the app to be checked. To check the same add this code in info.plist. If you want to check other apps like Facebook or Twitter, kindly read their documentation how to check whether it installed or not. The following details are got from Google maps docs. <key>LSApplicationQueriesSchemes</key>\r\n <array>\r\n <string>comgooglemaps-x-callback</string>\r\n <string>comgooglemaps</string>\r\n </array> 2.The second step will check if the google maps app is installed or not. The following code will check for the same. /**Check whether Google map app installed in device or not*/\r\n   func isGoogleMapsInstalled() -> Bool {\r\n       if let url = URL(string: \"comgooglemaps://\") {\r\n           return UIApplication.shared.canOpenURL(url)\r\n       }\r\n       return false\r\n   } 3.In the case of the app not being installed on your user’s device, you will give a redirect link to the particular product page. For that, you need to get the specific app’s product page. This can be done by the following steps. ->Visit https://linkmaker.itunes.apple.com . ->In the search bar, type the name of the app to be downloaded. And select Media Type as iOS apps. ->Now you will get the list of apps and chose the right one. ->In the app link page, you will see the direct link to the app. In this case the direct link to the Google Maps app. Copy the link. 4.Opening google maps product page from your app func openGoogleMapsProductPage() {\r\n       if let url = URL(string: \"https://itunes.apple.com/us/app/google-maps-gps-navigation/id585027354?mt=8\") {\r\n          if UIApplication.shared.canOpenURL(url) {\r\n               UIApplication.shared.open(url, options: [:], completionHandler: nil)\r\n               return\r\n           }\r\n       }\r\n} This is how the code has to be written for redirecting to any app’s product page in the App Store. As we mentioned the complete code for redirecting to download the Google maps app page is given below. Complete code: /**Navigate the user to Google maps with source and destination address*/\r\nfunc navigateToGoogleMaps(address: String?) {\r\n       if let address = address {\r\n           if isGoogleMapsInstalled() { // Check whether google maps installed in iPad\r\n               // Google maps is installed in user device, take proper action.\r\n           } else { // Google maps is not installed in device.\r\nself.openGoogleMapsProductPage()\r\n           }\r\n       }\r\n   }\r\n\r\n\r\n// Check google maps is installed in users device or not.\r\nfunc isGoogleMapsInstalled() -> Bool {\r\n       if let url = URL(string: \"comgooglemaps://\") {\r\n           return UIApplication.shared.canOpenURL(url)\r\n       }\r\n       return false\r\n   }\r\n\r\n\r\n\r\n// Navigate user to google maps product page in App Store\r\n\r\nfunc openGoogleMapsProductPage() {\r\n    let googleMapsPageLink = \"https://itunes.apple.com/us/app/google-maps-gps-navigation/id585027354?mt=8\" // Link got from link maker website.\r\n       if let url = URL(string: googleMapsPageLink) {\r\n           if UIApplication.shared.canOpenURL(url) {\r\n               UIApplication.shared.open(url, options: [:], completionHandler: nil)\r\n               return\r\n           }\r\n       }\r\n   } In this post, we have seen how to redirect you to the product page of a third party app’s product page in App store. This eases up the process of installing a third party app on your phone when necessary. We have seen the process for it for iOS development. – Karthick S, iOS Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-03-13"},
{"website": "Mallow-Tech", "title": "A Guide for making Energy Efficient Apps – II", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/03/a-guide-for-making-energy-efficient-apps-ii/", "abstract": "In our previous blog of Guide for making Energy efficient apps , we saw the areas which have to be concentrated to make an app energy efficient. We saw in detail about the Energy basics and possible energy hacks. In this blog, we will see in detail about some of the energy debugging tools and summary of making it energy efficient. Energy debugging tools: We can check the energy usage of our apps and also can able to debug what amount of energy each and individual process is consuming in our app. This can be done using various tools that are provided with XCode by default, let’s see how can we debug the energy usage of our apps and how that will be helpful for creating energy efficient apps. Ways to check the energy impact: i.) Debug Navigator. ii.) Instruments. i.) Debug Navigator: By default, you can easily check the energy impact of an app in the device by looking into the “Debug Navigator” in the XCode shown in the following image, For this to happen you need to run the project. “Debug Navigator” will give you an overview of following details, – Average energy impact, – Average component utilization, – Energy impact on each and every second(live reading) – Other shortcut links to check, Time profile, Network profile, Location profile,… Here it will just show you how much energy consumption is being made by the app, and you can also see what service is consuming the energy, but there is a limitation in this debug navigator that you cannot know what specific part/line of the code is the reason for the impact. For analysing deeper on this you can make use of the latter option(Instruments). But you can make use of this option, unlike Instruments where this can be useful even when you develop the app itself, whereas the latter can be used after the development process. Keep an eye on the energy needle and try to keep is away from Hight energy impact area. ii.) Instruments: What is “Instruments”: “Instruments is a powerful and flexible performance-analysis and testing tool that’s part of the Xcode toolset. It’s designed to help you profile your OS X and iOS apps, processes, and devices in order to better understand and optimize their behaviour and performance. Incorporating Instruments into your workflow from the beginning of the app development process can save you time later by helping you find issues early in the development cycle.” – Apple On Instruments, you have an option called “Energy Diagnostics” which is used for monitoring and analysing the energy consumption details of your app. It also includes the energy consumed by app functionalities, network actions, display usage and so on as shown in the image below. Whenever you test the app, have an eye on the Energy debugging gauge, so that you will be able to get any Energy leak issue upfront as soon the new changes had been made in the app. If in case you find any abnormal energy usage you can use the instruments link provided in the energy efficiency gauge in Xcode where it will directly take you to the Instruments to the specific debugging option. A sample energy diagnostics report is shown in the image below, Few important scenarios Points to be considered during energy efficiency testing process are, 1. Launch and idle: In some cases we may launch the app and user may not perform any action yet but still, unwanted usage may happen, consider those cases. 2. Background: Test this scenario by making the app go background when energy debugging is in the process, check whether any unwanted process is happening which results in energy consumption. Try to avoid unwanted background processes as much as possible unless it required for your app’s functionality. 3. Application specific: There are few other cases that need to be considered based on the type of application that you are developing, like in case you are developing a cab tracking app and your app needs to continuously fetch cab’s current location and update on the app. In those cases, consider whether the location service is used only when the cab update information is shown or location is fetching even when we are on that particular screen. And other cases like getting direction, navigation,… Use the location accuracy based on the need like, because the more the accuracy the more energy consumption happens. Try to use less accurate if you don’t need precise accuracy. Pro-Tip* Use the “Energy” logging feature given in the iOS when you test or giving your app to your testing team. It will record the energy usage details. Also, you can make use of the above report by importing the same to Instruments. For more information on h ow to test using Instruments and using the Energy logging in iOS device check out the following link. https://developer.apple.com/library/content/documentation/Performance/Conceptual/EnergyGuide-iOS/MonitorEnergyWithInstruments.html#//apple_ref/doc/uid/TP40015243-CH33-SW1 Summary: Energy efficiency is so important in a mobile app, keep in mind that the more an app consumes energy from user’s device the possibility of removing your app from the device is high. Keep tracking of “Energy gauges” as a part of your regular app development lifecycle itself for greater improvements to your app and keep tracking of the energy impact as well. Here are some of the important things we discussed in this blog, keep in mind these points whenever you develop an app, – Use NSURLSession Background Session – Minimise use of continuous location and choose accuracy efficiently – Avoid timers – Use energy gauges Also, check out the following WWDC session for further details on working with App energy efficiency, https://developer.apple.com/videos/play/wwdc2017/238/ – Bharath R, iOS development team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-03-01"},
{"website": "Mallow-Tech", "title": "Factors to be considered post launching an App", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/02/factors-to-be-considered-post-launching-an-app/", "abstract": "Plan to have a well-deserved break after your app launch? Resist it. The early days after your app launch play a crucial role in ensuring an outstanding chance against some fierce competition. Last week we saw the factors to be considered before launching an app. If you want your app to have a successful shot, read out the following factors to know what you should do immediately after your app launch. Focus on User Engagement Paid user acquisition will be effective for initial downloads but not for customer retention. So, in that case, you can go for the best paid channel which can be combined with other marketing strategies. Engage the customers continually by identifying the channel where they can spend much time. Be active on those channels, say social media, for example, ask questions, clear their queries and thank them for their contribution. Users like when they are identified in the crowd. Word of mouth is a powerful tool which tends to positive returns when individualised customer support is offered. Optimization of UI UI doesn’t mean the design alone; also the experience the app offers to its users with its function. You have the most beautifully designed app in the market, but if the functionality of the app is sub-par, you are screwed. It is true in the opposite case too. So your app needs to be top-rated to compete in the expanding market. The following things need to be taken care to optimize the UI, Adjust the colour scheme and interface to create a more engaging and intuitive app Make the app interaction as simple as possible Integration between the app and other relative channels Improve the workflow for a more streamlined experience Address the Feedback Getting feedback from beta testers before launching the app is very important. Likewise closely monitoring feedback from the early adopters, once the app is launched, helps us to know the pits and peaks of the functionality. Where are people facing difficulty? Are they using any other different features than the expected one? In addition to addressing the issues, it also helps to prioritize updates and optimizations. Users feel happy on seeing the updates and rectifications made based on their feedback. Optimize the frequency of Push Notifications Push notification is a great communication channel to remind the existence of your app to the users and making them to launch again. Customers like to be engaged, not to be spammed. So plan your push notifications carefully in a way not to irritate them and let them turn it off easily if they want. Also, keep different time zones in mind while sending a push notification. Updates, Marketing and Churn Apart from seeing marketing, updates and churn as separate entities, these three can be collaborated to achieve customer retention on a big scale. Customers feel bored if the update is simply of “bug fixes”. The update description space itself acts as a good marketing channel that conveys what is the new feature to offer, as well as the issues that are fixed. This can be a great strategy to get back users who haven’t opened your app in a while. Identifying where the users start churning, gives an insight into the ‘why’. By filling the gaps, churn rate can be reduced to a maximum level. It’s crucial to ensure that customers have a positive experience with your app and the best way to achieve it is Communication. Reach out, engage them, and make them feel valued. Conclusion You may think that the heavy lifting of development ends in a single moment of app launch; it’s not. But the reality is long series of action has to be carried out to place the app at the top. As the number of apps in the market skyrocket, the challenges for app marketers continue to grow. So continue to engage your customers, collect data, test, and innovate. – Marketing Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-02-28"},
{"website": "Mallow-Tech", "title": "Factors to be considered before launching an app", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/02/factors-to-be-considered-before-launching-an-app/", "abstract": "The on-going progress of mobile technology, access to high-speed Internet and integration of cutting-edge technologies has resulted into an all-new and enticing atmosphere in the mobile world. Not only individuals are employing mobile apps day-to-night for their leisure, brands are also investing in mobile app development to entice their target users and do a profitable business. As a result, the market is flooding with apps and competition is rising exponentially. 1.Market Research: The market is usually comprised of key players, such as target audience and competitors. Target Audience Researching the target customers can give you some great insights into what they actually value in an app. Also, the pattern of buying varies with each individual. some keep on trying newer mobile apps on a regular basis (1-2 every week), others install new applications at a high rate at the beginning of the month and stay away from the app store for the rest of the month. Competitors It is important to know where our app stands in the competition. For this, it is crucial to understand and analyse the features, price, categories and keywords of the competitors. This gives an idea of building our value proposition better than others and to include the missed features. Along with this, participating in the online communities and discussion is a great way to conduct market research. 2.Social media: Social media helps to expand the web presence. The first step is to identify the social networks most popular with your target audience. Once you know where your market is, start posting or sharing content related to your soon-to-be-launched app. App promo video captures the essence of your app in a one-minute pitch and takes the marketing to the next level by bringing your messaging to life. So they can be embedded into your social posts, landing page, and even your app store product page to boost conversion by up to 80%. The ideal promo video is usually of 30 seconds to 3 minutes in length, clearly states your key benefit, and shows either your app in action or a mock-up of your future app. 3.Feedback loop: Beta testing is the first opportunity to get some unbiased first-hand feedback from the target audience. The goal of a beta test is to work out last-minute issues in the weeks leading up to its anticipated launch. An open channel of communication between developers and beta testers is established. This channel will allow them to relay any bugs they experience and communicate whatever questions, suggestions, and comments they have for your app. For best results, the feedback loop should be built into the app itself, not requiring testers to leave the app to open their email or give you a call. TestFlight can be a great platform for organizing beta testing. The number of beta testers you need depends on a number of factors, such as your goals and length of the test, how much you are willing to spend on it, and your target market. 4.Marketing plan Planning the marketing activities for an app is one of the important areas of app development, which is most neglected. Here is the list of activities that your marketing plan should include: Find out the USP – Know what makes your app unique among the crowd. App Store Optimization – Following things should be optimized in the App store. App Name – You can choose to name your app based on common search terms or use a branded name that you can copyright. A lot of app developers optimize their app names by using a combination of branded and common search terms to enhance discoverability. Keywords – The keywords will help your app get discovered by users. Every app gets 100 characters in the keywords section so it’s important to experiment with your keywords to find out what is working for your app. Description – The App Store displays only 2-3 lines of text. Users need to tap on “more” in order to continue reading the description. Hence, it’s important that your app clearly convey the key message in the first 2-3 lines. Blog on your website – Blogs and newsletters highlighting the features of the application can be published on the website. Create a promotional channel list – Find the best channels for promoting your app. Promotional deadlines – Create a timeline for all the activities to be carried out. This will ensure that you are prepared when your app releases. 5.Release Date Timing matters a lot to ensure higher app success. Launching your app at the right time will fill your pockets with money. While on the flip side, your app might struggle if it enters the market at the wrong time – even when your app idea was superb, the development team was adept and marketing team was passionate. According to Fetch – one of the reputed app marketing agencies globally, the best month to launch your application is December and February. This is the time when marketing buys cost goes high, which increases the chances of app success. While on the other side, August is the cheapest month of the year to enter the mobile market. However, the outcome is not satisfying since the app installs are slower in this period. Similarly, a San Francisco-based app optimization company revealed that weekends are the best time to launch new apps and features. This is the time when users are looking for a break from their daily life and would like to try something new. Conclusion Mobile app development is a profitable yet expensive task. A single mistake could cost you a loss of millions. So keep the above factors into your consideration while launching your application. To be beneficial, promote your app well, and also remain updated with the app store policies. – Marketing Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-02-23"},
{"website": "Mallow-Tech", "title": "An hour with Apple experts at App Accelerator Centre, Bangalore", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/01/an-hour-with-apple-experts-at-app-accelerator-centre-bangalore/", "abstract": "In my previous blog, I was talking about basic things about apple app accelerator centre in Bangalore . Today, I would like to share my one to one discussion experience with Apple experts. By the end of December 2017, Apple had published time slots for one to one meeting for the month of January. Within an hour, all the time slots were booked and I have been added to the waiting list for the slot of 12pm – 1pm, Jan 22, 2018. We received an email from Apple that my time slot has been confirmed for an appointment which I have booked for. Before discussion: In one to one meeting, we can discuss only one app. So we decided to take an App on Digital Security , which is in the development phase to discuss. Why App on Digital Security ? The reason is, integrated technologies like Beacon and ARC Controllers (Microcontroller) have been used along with fully customised UI. They asked us to bring the product owner (Key decision maker), lead developer and lead designer to make use of this discussion effectively. Since App on Digital Security app client is in the US, we decided to represent our iOS Team lead to play product owner role and lead designer was already present. After finalising the roles we sent a confirmation mail to Apple. Along with the attendee’s list, I have sent a brief description of App on Digital Security and the technologies to be discussed in the meeting. This will give them some idea of the discussion. So we ensured that high priority has been given to the important topics. We prioritised the topics in the following order (from high to low) Beacon and Core location framework Custom UI Encryption and decryption best practices in iOS Performance improvements Machine learning using CoreML How we prepared: Since this was our first meet with Apple team, we are not clear with ideas of how to proceed to make use of this one hour effectively; so we prioritised the questions in each technology/topics. Best practices: Prioritise your topics and questions properly. Your question should not be too strange. Read Apple documentation properly before asking doubts & best practices in any framework/topics. Choose a question from topic/feature which is idea phase, because if you choose questions from the feature which you have already implemented, they will give only feedback on your work. But if you bring an idea of a feature before implementing they will guide you to achieve it in an efficient way. In discussion: We reached the Apple accelerator centre by 11am itself. The receptionist followed some procedures to enrol our names. After the registration process, we are asked to wait in the developer area and had coffee too. As the people who booked the slot before we were not present, our appointment commenced a bit earlier at 11:40 am. Three experts from Apple team were present for the discussion. Two of them are technical experts while one is a UI/UX expert. Along with 3 from the team of Mallow Tech, 6 of us are ready for the discussion. The discussion went as follows. Overview of the app: I explained the concept of the app, core functionality, technologies we integrated, how we implemented, target users, and so on. Live demo: After explaining the project details to the Apple team, they asked us to show the demo of the app. We can’t give a demo for each and every functionality of the app, so we demonstrated only the core features. But we almost covered all features orally. From demo they asked many doubts, so we discussed those points in detail. Feedbacks/Suggestions: As I said before, bringing the project when it is in idea phase will be good for this one to one meeting. Since we have almost implemented core functionalities, they have said some points as feedback, alternate suggestions, mandatory improvements and they suggested some new technologies to integrate with App on Digital Security . We got many comments in UI/UX part since it’s a fully customised UI. QAs: Finally we discussed the questions what we have prepared. It was easy for us to discuss since we properly prioritised the topics and questions. General discussions: After completing all of the prepared questions, we had an open discussion. We asked some common questions such as Build time issue in XCode and development machine. Then we explained a bit about our organisation and also we showcased some of our other apps too. This general discussion was also important and we wanted to make use of this opportunity efficiently. Best practices: Try to explain your project in detail within a short span of time. This will be very helpful for further discussion. Give high priority to the core functionality of an app in a live demo. Before the demo, make sure you are giving a demo with actual data, not with the data you used for testing. This will help them to understand the usage of the app in real time which is important. You need to connect your iPhone/iPad with AppleTV via screen mirroring. So make sure your mobile have enough charge. Turn off notification for remaining apps, if possible. This avoids distraction and savs a lot of time. As I said before, read the documentation before asking a question to them in any topic, because Apple documentation is the perfect place to learn their technologies. This helps to reduce some unwanted questions and saves time. Try to have a key decision maker of your app along. It may be your project’s client or project manager. This will help to take on time decision for some queries and to make use of this discussion effectively (Apple highly recommends this). Take your MacBook with you, if you have. If you want to show data in some backend service, keep it ready. Say for example if I do some action from the App on Digital Security app, it will reflect in Zoho CRM. We have opened all references pages/website in Safari. Have a coordination with your teammates like, who will take notes while discussing, showing demo, explaining the project and overall leading head. Try to reach the centre before 1-hour, since we reached earlier we gained 20 additional minutes to discuss with them. So these are the small opportunities to use. We have travelled from Tamil Nadu to Bangalore(around 640 km, up and down) for this 1-hour meeting, so we don’t want to waste a single minute. After discussion: After completing the discussion with us, they started preparing for their next session with another batch. Unlike our early arrival, we didn’t depart soon from the centre. As the team said us to be comfortable we took the word of it and comfortably exploring the centre to the fullest. As there was a 6-hour journey ahead we charged our Mobiles and Macbooks at the centre. Their smile and patience throughout made us respect them more and more. We also asked them regarding the pre-booking of time slots for future discussions. By that, we can visit for 3-4 time slots continuously. This trip gave us a lot to learn professionally and technically. It is all about how you make the most out of the available space. – Karthick S, iOS Development Team, Mallow Technologies Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-01-25"},
{"website": "Mallow-Tech", "title": "Apple app accelerator centre in Bangalore – An Overview", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/01/apple-app-accelerator-centre-in-bangalore-an-overview/", "abstract": "A few months back Apple has commenced their app accelerator centre in Bangalore, India. India has one of the most vibrant and exciting iOS developers’ communities, with tens of thousands of developers. The app accelerator will help you fast-track your apps so you can become part of this thriving app economy. I along with my teammates visited the app acceleration centre. Sharing my one to one meeting experience with Apple experts was my first idea, but without telling about Apple app accelerator centre it won’t be meaningful to talk about one to one meeting experience. So I thought of writing this blog first. The following processes are taken place at the App acceleration centre. 1. Session 2. One to one meeting 3. Lab We will see in detail about each of these processes. Session: In the session, they will deal with new Technologies what they have released in new OS. So that developers can adapt to that technologies as soon as they release it publicly. They also cover some common and important topics which are not new. Developers can get to know best practices in implementing old technologies and knowledge about new technologies Some of the Topics are, 1. What’s new in Swift 4? 2. CoreML and ARKit. 3. Common pitfalls in UI/UX designs. One to one meeting: In the session, we can learn about new technologies and best practice in existing technologies. But what if you want to get a comment about your app before submitting your app for app store review? That’s where you can make use of one to one meeting. One to one meeting is a one-hour pre-booked time slot for discussing with Apple experts. In this one hour, you can take any of your live apps, under development app or even app which is in idea phase(Correct phase to bring it to them). Due to time and efficiency constraints, one app per appointment is permitted where you can clear your doubts and get suggestions in both technical and UI/UX wise. Lab: Session awards you with technical ideas/ stuff, what if you get stuck while integrating that new technology into your new product or existing one. That’s why they are going to the hands-on lab, where we can take our development kit to the accelerator centre in Bangalore, and implement the new feature under the guidance of Apple experts. This will have a crucial impact in reducing the development time and efforts when trying new technologies. FAQ: 1. Do we need to pay them? No. We don’t need to pay for any of their services(Session, one to one meeting and lab) 2. Do I need Apple ID to book services in Apple app accelerator centre? Yes. 3. How can I register for a session? You can register for a session on their website . They will publish events calendar for some time. You need to keep an eye on their page to get an appointment for a session. 4. How can I register for one to one meeting? They are doing this service for every month. You can expect event calendar for next month at the end of current month. i.e  You may expect event calendar for March in February end. 5. How can I register for the lab? You need to contact them in person via email to get their time for lab. 6. Is it worth to attend a session? Its based on how you are using it. You are open to ask any questions to them. 7. Is it worth to attend one to one meeting? Yes. In my opinion, one to one meeting is much better than sessions. Because you can learn new technologies from their documents itself, so it’s not necessary to attend that session unless it’s a completely new and complex technology to implement it. But in one to one you can get valuable feedback about your app in person. 8. Is it worth to attend labs? Yes. If you want to implement new technologies with minimum time and effort you can make use of it. 9. Where is it located? RMZ Galleria Residences, 14th floor, SH 9, Ambedkar Colony, Yelahanka, Bengaluru, Karnataka 560065. 10. What are the modes of taking notes? Except live streaming and recording, you can choose your convenient way of taking notes. 11. What are the services you have attended in apple app accelerator centre? I have attended 5 sessions and 1 one to one meeting. 12. Last but not least. Shall I take selfies 🤳🏼from inside their centre? Yes. Apple wants us to feel comfortable, they are not restricting to take selfies and walk to all places inside the centre. They have cool infrastructure places for sessions, one to one discussion and hands-on lab. The office which is located on the 14th floor of the building also has a nice garden. These are the basic things you need to know about Apple app accelerator centre in Bangalore. In my next blog, I will share my one to one meeting experience with Apple experts. – Karthick S, iOS Development Team, Mallow technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-01-23"},
{"website": "Mallow-Tech", "title": "7 important metrics to measure the User Engagement in Mobile-apps", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/01/7-important-metrics-to-measure-the-user-engagement-in-mobile-apps/", "abstract": "Building apps and looking to leverage the mobile platform to get more users for your business is good but the success of app would be determined by the user engagement and activity of the app. Following are the metrics to be considered to understand the user behaviour and to engage them accordingly. No. of Downloads: The number of installs is the most important metric for the app to be successful, hence it should be large. It is essential to provide protection and security against threats and spams to attract a huge customer base. Advertising channel and source of app install are much important to track. No. of Active Users: Trace out the number of active users who have engaged with the application apart from downloading helps to build better engagement with the users, analysing their specific behaviour and segmenting them. The numbers can be seen by Daily, Weekly or Monthly. Retention Rate: The percentage of users that return to your app in last 30 days defines retention of the app. It’s better to retain rather than to acquire since costs are high. The retention metric is important to have clear insight into the actual performance of the application, evaluate the user lifetime and design the strategies accordingly. Session Length: Session length is the time spent by the user in the app. More engagement would mean longer session durations. Developers can identify those customers who spend a lot of time on the app just to improve the experience for less-engaged users. Screenflow: This analysis will help to get insights into users activities on any particular screen. By looking at this navigation patterns, it will be easy to sense of drop off screens and problem areas, thereby recreating the in-app marketing campaigns to get back dropped users and implement redesigns to create clearer funnels. Custom & Break-even metrics: Custom metrics are all about drawing reports from analytical tools which allows app developers to seek out the paying user in an app segregate them into groups and analyze them separately to satisfy their specific requirements. Break-even metrics deals with revenue generation, which will be measured based on the user lifetime value defining the ROI in marketing and advertising. Cohort Analysis: Cohort analysis is all about grouping users into segments and analyzing the metrics of those groups and purpose is to tell which channel works best. Cohorts are based on traffic source, country, and device. Conclusion As a servicing company, it is crucial to maintain the user engagement to ensure the long-term success and satisfying visibility in the app stores . – Marketing Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-01-12"},
{"website": "Mallow-Tech", "title": "5 ways to boost your mobile app’s performance", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/01/5-ways-to-boost-your-mobile-apps-performance/", "abstract": "Mobile apps made its presence in all areas right from education to shopping. As a result, the expectations of the users have been raised, making them impatient towards any problematic app. If the app fails to satisfy the user expectations of quick load, the user tends to uninstall the app or switch to an alternative. Factors including network strength, app complexity, app design, app testing and peak usage affect the performance of an app. In this post, we will examine the ways to overcome those poor performance issues and thereby enhancing its performance. Load Data as Needed: A mobile app requires a large amount of data to be loaded for proper functioning. But, the users are not ready to wait for long to view the parts of the app. Fetching whole data instead of the needed amount will be ineffective. In such a situation, Splitting up the assemblies will help accomplish this. If possible, the data can be pre-load/pre-fetch, so that when the data is needed, the user doesn’t have to wait. Offline mode: Network connections might drop while using the app during travelling situations. In such situations, it is crucial delivering an impressive service since users are not bounded to the same place. An offline app mode can be offered where their data remains saved for a while even when the connection is lost. When the network connection drops while the user is in the middle of completing an action, an option of “save the data for later” can be made so they can resume the activity once the connection has been re-established. Features – Less is more: Users prefer a faster and functional app over the one which has a lot of features but is slow. To entice the users, it is not required to offer a large number of features in the app. If the app’s performance is getting compromised when including multiple features, it is better to have a few crucial ones. Frequent software updates: New releases receive more attention from developers and the user community. The recent updates will be more compatible and higher-performing than older releases. Also, the components are chosen based on their reputation for stability and performance. We can take advantage of tuning optimizations, bug fixes, and security alerts when stayed on top of software updates. So choosing the latest and high-quality components (software/tools) boosts the app performance effectively. Clean coding and Right monitoring tools: Using the latest crash monitoring and profiling tools is also an essential method to improve the speed of your web app or mobile app on a long-run. The mobile app development companies can use different tools to track and improve their app’s performance, like Neumob Accelerator , Xcode and TraceView . Clean coding makes the app flow easy and smooth, which ultimately improves the app speed and performance. To ensure that the app runs perfectly, the following aspects are considered, Minimizing power consumption. Avoiding irrelevant resource consumption Optimizing security requirements and permissions Conclusion: Mobile app performance directly affects user retention rate, ratings, number of downloads, conversions, and ultimately, revenue. Creating a high-quality app that meets or exceeds user performance expectations will make the users to use it over and over again, elevating their perception of your brand and strengthening the relationship they have with it. – Marketing Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-01-10"},
{"website": "Mallow-Tech", "title": "Factors to be considered for a Wearable app development", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/01/factors-to-be-considered-for-a-wearable-app-development/", "abstract": "The wearable devices have brought a significant digital transition around the world. The wearables are portable gadgets that can be carried all over the place thus, much of the success depends upon the experience of the users and how does the application works. The purpose of the wearable application should be clearly defined. The idea on which your app is based should be imagined with right ease of use and assets to achieve success in highly competitive modern automation world. It’s necessary to examine what elements should be taken into consideration while building up the applications for the wearable gadgets. Ease of access Designing UX for a wearable device is very challenging; it should be composed with a great measure of deliberation since the screen size is small. The design should be kept as simple as possible to permit users with ease of access. Though some difficulties are involved while designing the UX, it offers a faster assess when it comes to interaction and is easier to handle as compared to mobile apps. Pairing with companion device The companion device (smartphones) would communicate with the wearable device via Bluetooth most of the time, therefore the proximity of both devices matters. This in-turn helps in implementing the animations and the users do not have to wait long for exchanging the data. There should be a mechanism to ensure data back up and transfer if the companion device gets out of range. Energy efficiency Ensure that the app is as light as possible to allow for adequate use since the small hardware requires a small battery with low energy capacity. Developers should design and develop the app considering the user aspect of wearable devices with a battery that lasts for weeks/months. This involves avoiding battery consuming features running in the background, switching off the screen when not in use, and using the platform provided optimization methods. Timely Upgrade As wearable applications and devices are somewhat new in the marketplace, the resources available for wearable app development can be limited. Check frequently for errors and glitches and should consider user’s reviews seriously. Users would want to upgrade their existing app so as to continue usage of the same. If the functionality becomes obsolete, consumers are likely to uninstall the application affecting customer satisfaction. Variety of Segments In recent days, wearable devices have penetrated various market segments such as healthcare, lifestyle, wellness, industrial, financing (wearable pay), police, military, etc. While innovation is rapid in this area, there is a need to develop applications very quickly so that the market can be captured. Conclusion The wearable gadgets make the app developers invest resources as well time to achieve their desire. The User Experience and in addition the functionality of the application should constantly top the priority list. This is one of the significant reasons why the greatest manufacturers including Apple, Google, Samsung, and others are investing a lot of resources to grow best in the class wearables. – Marketing Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-01-05"},
{"website": "Mallow-Tech", "title": "7 MOBILE APP TRENDS THAT WILL REIGN 2018", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2018/01/7-mobile-app-trends-that-will-reign-2018/", "abstract": "Mobile apps are gaining substantial position in every business practices. Technologies for mobile app development are emerging over years whereas it is mandatory for the app development companies to have the latest technology to create competitive edge thereby gaining the market position. In this post, we will look out the technologies which made its identity in 2017 and seem to rule the upcoming years. ARTIFICIAL INTELLIGENCE: The new availability and advancement of AI and machine learning are causing a revolutionary shift in the way that developers, businesses, and users think about intelligent interactions within mobile applications. Combining AI technology with built-in features makes apps more relevant and personalized which is more valuable than the last. Amazon and eBay have already implemented AI in their apps and proved the potential success of it. CLOUD & LOCATION BASED TECHNOLOGIES: Cloud technology covers a vast area in the mobile app sector with its growing demand. Data accessibility has become quicker and easier without impacting your internal phone memory. Thus mobile app developers are designing more cloud driven mobile applications in recent days, also to ensure the safety and security of the sensitive data of the company. Along with Dropbox and Google Drive, some-other mobile apps are going to be cloud driven in the near future. Location-based mobile app development is increasingly being adopted by small and medium businesses (SMBs) world over. They reach out to potential customers in close proximity and provide them with immediate access to product or service information, price comparisons, reviews, product alternatives, and several additional mobile commerce options, thereby increasing the likelihood of an immediate sale. IOT & WEARABLES: Wearables form a part of the Internet of Things. Using wifi or Bluetooth, the wearables like health band, apple watch , glasses can be connected to the smartphones and any sort of data can be transferred between the devices. SECURITY & DIGITAL PAYMENT: One of the prime factors, the users consider while downloading an app is security. It is an essential feature of the app because it helps in securing the private and confidential data which makes the developers develop apps that have in-built security, which obviously is a huge bonus point to convince the customers. We all know that the world is moving towards a cashless economy and so the importance of payment gateway apps/ digital wallets such as PayPal or Paytm has hiked a lot. Within the approaching years, more and more people are going to get associated with online payment methods because it is fast, safe and easy. AR & VR: Both AR and VR will be offering its services to a diverse set of industries. While AR is focusing more on healthcare, retail, real estate and others, VR will be more helpful in gaming and events. Augmented Reality has already proved to be a key player in the mobile app industry. But within the coming years, its primary focus will remain on improving the all-day battery life and to also make the connectivity better. Although Virtual Reality is receiving a positive response in the market, still it will take some time to gain the ground. CHATBOTS: Today customers want a quick reply to their queries and Chatbots is an answer to that context. Implementing Chatbots provide better UI and UX which helps to boost business. At the same time, the customer executive will also get an idea of what type of common queries are pouring in from most of the users and will look to address the issue better. HYBRID APPS: In the upcoming year, business firms will be preferring hybrid apps as it is flexible and suits the business needs more than the native. It can help in creating platforms for businesses of all sizes. Moreover, it is easy to access and hybrid apps are cost wise friendlier too. The hybrid apps are quite effective in enhancing the user experience, which in turn generates more traffic to the app. Besides it also accelerates the speed of app loading and is also easier to develop because they are based on cross-platform apps. You can maintain them without much hassle and the apps can run offline as well. Along with these, the Progressive Web apps are in the game too. CONCLUSION: These are the top mobile app trends that will ruin in the upcoming years, to ensure that the company is adapting all these trends or new innovations in their app development strategies to have a competitive advantage. Though it tends to face more challenges by the developers, they should remain updated to compete in the market. – Marketing Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2018-01-03"},
{"website": "Mallow-Tech", "title": "7 factors to be taken care of before creating an E-Commerce app", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/12/7-factors-to-be-taken-care-of-before-creating-an-e-commerce-app/", "abstract": "Electronic Commerce (or E-commerce)apps enable the transactions to be done over the electronic medium such as the Internet. The app should primarily highlight the objectives of the business such as lead generation, gain market position, profit growth, customer base, etc. which varies according to the type of business undertaken. Some commonly used E-commerce apps such as Amazon, Walmart, Paytm, Starbucks and Uber plays a vital role in driving the marketing efforts to next level. In this post, we will see in detail about the 7 factors to be taken care of before creating an E-Commerce application. Image courtesy : axon-labs.com 1. UI Design: The interface design holds the responsibility of grabbing the attention and raising the curiosity of the users. The contents should be precise and uncluttered so that users can have quick go-through. Some visuals, graphics and videos can be imparted to have a better understanding of the app features thereby increasing the conversion rate. 2. User Engagement: It is important to engage with the customers/users constantly. Push notifications provide the users with timely information such as promotions and offers. The message should be appropriate and relevant that it should not annoy the users. Additionally, facilities like Chabot’s, feedback, review (star ratings, comments and likes) systems are essential. It will not only enhance the user engagement but also communicates the fact that you are listening to their views and opinions. 3. User-friendly: The users are not ready to spend much time in figuring out a way to use the application, rather make it simple and intuitive. The sign-up process should be easy and convenient. In case of many activities involved, users will be distracted and do not show any interest to complete the process. Quick reach to payment gateway is made. If not the users will not use the app further. Also, an added advantage in quick reach to payment gateway avoids the user from getting distracted from making the purchase. 4. Consistent menus: For easy access, the menu list is made in a way that it can be accessed from any page. To simplify the process, filters and categories are enabled and features like add to cart/wishlist provide additional support. 5. Speed: All the users are not with high-speed networks like 4G. So the speed of the app should be in a way that it can be accessed by anyone at anywhere and anytime. Lighter the app, long is the usage. 6. Analytical tools: Tools like Google Analytics can be used to monitor the activities of users such as how frequent they are, what they actually want, time spent, which features are not utilised, etc. Analysing the user’s behaviour helps to enhance the features of the app as well as to grow the business. 7. Security and Trust: Though it involves additional investments like time and money, efforts should be taken to secure and safeguard the details of the users (personal as well as bank details). Return policy and cash-back schemes help to build trust and confidence in the customer’s minds. These are the factors that play a crucial role in designing an e-commerce application. These are not the luxury factors but rather the bare essentials necessary to keep the app running and reaching a greater audience. In the upcoming weeks, we come up with some ideas to implement to optimise each and every factor. – Marketing Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-12-26"},
{"website": "Mallow-Tech", "title": "Ways to detect the Memory Leaks in Swift", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/12/ways-to-detect-the-memory-leaks-in-swift/", "abstract": "Managing memory and avoiding leaks is a crucial part of any programming language. Memory leaks happen certain memory is allocated to set of objects but deallocation is never initiated. Hence the system can never reclaim the allocated memory which eventually means it will run out of available memory for an app. Swift uses Automatic Reference Counting ( ARC) for memory management. However, there are situations in which retain cycles occur(holding a strong reference to an object which indeed is a reference to other). Retention cycles in Delegates Delegates enable loosely coupled relationship between objects but delegates are been referenced strongly.Consider the following case, Class ViewController {</span>\r\n\r\n<span style=\"font-weight: 400;\">     var delegate: delegateName?</span>\r\n\r\n<span style=\"font-weight: 400;\">} The above code will likely cause retain cycle, as the owner of a ViewController instance will probably also be its delegate – causing both of the objects to strongly reference each other. To solve the retain cycle we need to Introduce weak var. Class ViewController {</span>\r\n\r\n<span style=\"font-weight: 400;\">     var weak delegate: delegateName?</span>\r\n\r\n<span style=\"font-weight: 400;\">} We only need to use weak if the delegate is a class. Swift structs and enums are value types(not reference types), so they don’t make strong reference cycles. Note:- There is no weak let. When we use weak, the property should be optional and mutable in order to set it as nil or assign a value to the delegate property. Retention Cycle in Closures Similar to the delegates, closure types also account to retain cycles. manager.add { self in</span>\r\n\r\n<span style=\"font-weight: 400;\">         print(“\\(self.value) in Closure”)</span>\r\n\r\n<span style=\"font-weight: 400;\">} In above case, the closure block contains a reference to the property which causes leaks. Any code in a closure that refers to self. is a potential memory leak.This can be solved by adding [unowned self] or [weak self]. Identifying memory leaks The Xcode memory graph debugger helps to find and fix to retain cycles and leaked memory. When activated, it pauses app execution, and displays objects currently on the heap, along with their relationships and what references are keeping them alive. To activate graph debugger, Opt in to stack logging integration via the Xcode scheme editor. Note that we only enable logging of ‘Live Allocations’. This has a lower overhead than ‘All Allocations’ when debugging, and is all we need to identify retain cycles and leaks. Perform the actions that are suspected to cause retain cycles. Finally, enter the memory graph debugging mode by selecting its debug bar button. The memory graph debugger pauses app execution and displays the following: On the left, the debug navigator displays the app’s heap contents . Selecting an instance from the debug navigator shows the instances references in the centre pane . Selecting an instance in the centre reference pane displays general object memory information and the allocation backtrace in the right-hand inspector pane . Leaks are displayed in the debug navigator. In this blog, we have seen the common mistakes causing retain cycles and ways to detect leaks in an app. In upcoming blogs, we will learn more about debugging tools and approaches to avoid the retain cycles. – Poorvitha Y, iOS Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-12-22"},
{"website": "Mallow-Tech", "title": "TESTING CHALLENGES WITH BEACON APPLICATIONS", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/12/testing-challenges-with-beacon-applications/", "abstract": "Estimote Beacons: The applications build with beacon is used widely nowadays which offers a wide variety of opportunities, but there are more challenges when it comes to the testing team. Beacons are small, low of the cost, easily portable and pieces operated by a battery which can be easily attached to a wall. which uses Bluetooth connections to transmit data regularly. The beacon can be detected on any mobile devices which supports Bluetooth low energy and can detect other beacons nearby. Low energy emitted by Bluetooth is used by beacons to broadcast signals which are gathered up by a compatible applications/OS. Transmit data over short distances by a network technology is known as Bluetooth low energy. The Devices physical location can be looked up over the internet or by triggering an action on the device such as a push notification. Signals are transmitted as data packets with Bluetooth which all the devices are in range at an interval ranging from 10 ms to 10 seconds.This interval also impacts the battery life of the beacon. Shorter intervals result in the quicker discovery of devices but it means shorter battery life. Image Courtesy; rambus.com To test the beacon application, we followed the following steps: 1. Installed the App on multiple iOS/Android devices. 2. Logged in to the App on all the devices with different user IDs. 3. Placed beacons in different rooms (1 beacon per room) at 4 rooms of one geolocation and 2 rooms of another geolocation. 4. With iOS OR Android device move to a room. 5. Verified that the count of the attendee in that room is increased by 1. 6. Moved out of that room. 7. Verified that the count of the attendee in that room is decreased by 1. 8. Moved into one room with both iOS and Android device. 9. Verified that the count of the attendee in that room is increased by 2. 10. Moved out of that room. 11. Verified that the count of the attendee in that room is decreased by 2. 12. A user with different User Id enters different rooms at different Geo-Locations. 13. Verified that the count of the attendee in each room is increased by 1. Challenges in Testing: Testing a beacon based application Well, testing a beacon based application is not as straightforward as testing any other application. There were many obstacles which we faced while testing this application. Below I have jotted down a few of those: 1. The range of Beacons: Important features of Beacons is Ranging; Beacons generate the signals are responsible for searching any compatible devices in range. This is an issue faced often that the detection of devices are not consistent and sometimes even when the iOS/Android device was in a range of the beacon it was not detected by the beacon. It happened many times that the range was changed from ‘Near’ to ‘Far’ even when the beacon and mobile devices were placed closed to each other. 2. Battery Drainage : Battery drainage was another issue that we faced during testing. When the application was running on the devices, the battery drainage varied from 14%-19%. However, the drainage problem in Android was slightly lower as compared to iOS devices. 3. Internet connectivity : This is another challenge that we faced. If the internet is disconnected for a fraction of a second, then the application will not respond and the record of the person will not be updated. Once the internet connection is reestablished, then the application will start running again and then only it will send the information to the server to reflect the user count. 4. Placement of Beacon : Well, placement of the beacon is very important in testing any app which is based on beacon technology. Because even If the beacon range is good and there is some obstacle between the beacon and the mobile device, then the detection of the mobile device can be a problem. We saw this frequently during our testing. 5. Multiple Geo-Location verifications: it was quite a challenge to test the application at other geolocations, as the entire team was in one geolocation, and for this, we requested our stakeholders to install the app on their mobile devices and use the same from other geolocation simultaneously. Prerequisites Like other applications, our application also has certain prerequisites as follows: 1. Location services should always be up and running. 2. Internet connectivity should be on always. 3. Bluetooth should always be On on the mobile device. 4. The app should be running on mobile device. QA Best practices 1. To overcome the beacon ranging issue, the QA team, in coordination with the dev team, started the ranging as soon as monitoring started and the method to stop ranging was set not to be called ever. 2. The app should be run in the background to reduce battery drainage, and more the beacon ranging time is set in settings, lesser will be the battery drainage. 3. Internet connectivity issue can be overcome by a high-speed regular internet connection, which can cover the mobile device in an entire company’s location. 4. Beacons should be fixed on the wall or roof of the rooms so that there will be no obstacles between them and mobile devices. 5. We can use the Android SDK to send mock GPS information to a real device, For multiple geolocation testing. The Android SDK theoretically allows us to do so. Thus we have seen about how to test and challenges faced during beacon testing, At Mallow technologies, we have successfully implemented the applications with the help of beacons and faced and overcame the challenges while testing. – Kumaresh T, Testing Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-12-19"},
{"website": "Mallow-Tech", "title": "5 Factors to be taken care of before creating a medical application", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/12/5-factors-to-be-taken-care-of-before-creating-a-medical-application/", "abstract": "Healthcare is one of the crucial areas where the application development is booming. Developing a health monitoring application elevates the standard of everyone’s day to day habits. Various applications have helped in achieving a healthier life and optimising the process in this area. In order to develop a health-specific app, one has to see that the following five factors are taken care. Scalability Localisation Readability Efficiency Design 1.Scalability: A medical application must never subject to trade-off when it comes to its scalability. It is the capability of a system, network, or process to handle a growing amount of work, or its potential to be enlarged to the corresponding growth. An analogous meaning is implied when the word is used in Economic terms, where an application feeds to its own growth bragging out its possibilities to work under swivel situations.When important updates are to hit, it should oblige to the extent of its use. 2.Localisation: A medical application with built-in alerts should possess the power to work to a greater extent when updates regarding the geographical area, geo-fencing, POIs are brought in. Every moment counts when it comes to medicine and health. Localisation is ultimately essential to a medical app. By this process, it makes it easy for each and every user to efficiently utilise it. 3.Readability: The data output in all the medical applications has to be easily readable and inferable to the user.  Since it adds to a point of medical sciences, there are imminent outcomes regarding the use and the readability of an application. Consider a simple example of measuring blood sugar level, when the sugar level crosses the acceptable limit, the warning and notifications have to be sent. By this, even a person who has no knowledge on the same would be able to decipher something is off. The important part of the application is communication. Also, the UI must not be convoluted. Making a UI which is easy to use and intuitive will stand as a differentiating point for the application. 4.Efficiency: The efficiency of a medical application should be at brinks when it comes to alerts. Its programmatic infrastructure should be elegant and should use the far best minimal battery power and that adds an extra point to its market class. The utilities and accuracy of notifications should be near perfect. As the things at stake are high in this. Efficiency stands as a must needed a feature to sustain in the market. 5.Design: The design and its UI approach should be of a coherent nature that brings true vibrant tint when a user interacts with it. Also, the layers of every element within the application should possess an all-around artistic approach. The texts should be visible and must flaunt a user-friendly touch to get the most out of the application from within. Thus we have seen some of the most important factors that have to be covered before building a medical application or application for health care . At Mallow Technologies, we were able to build some great applications which help the life of various people. You can anytime contact us for creating a Healthcare application. – Divakar Karunanithi, Business Analyst Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-12-15"},
{"website": "Mallow-Tech", "title": "Designing factors for iPhone X and UI Changes in iOS 11", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/12/designing-factors-for-iphone-x-and-ui-changes-in-ios-11/", "abstract": "In iOS, we have the topLayoutGuide and bottomLayoutGuide as properties of UIViewController. These properties are used to create constraints that allow us to keep the content away from UIKit bars like the status bar, navigation or tab bar. These layout guides are deprecated in iOS 11 and it is replaced by a safe area layout guide. Apple told us in WWDC 2017 Session 412 that Storyboards using safe areas are backwards compatible. This allows the developers to use safe area layout guide starting from iOS 9.  There may be a situation where the developers need to handle constraints in code. In that case, you can use view’s safeAreaInsets property to get the values of the safe area. But remember to use the view’s safe area inset property in the viewDidLayoutSubviews method because we get the correct values only after the view has been completely initialized. For eg:- When I tried to print the values of safeAreaInset in viewDidLoad method, I got the values as UIEdgeInsets(0, 0, 0, 0).  Again I tried to print the same in viewDidLayoutSubViews method, I got the value as UIEdgeInsets(0, 140, 0, 30), where 140 is the top inset and 30 is the bottom inset in an iPhone X in portrait mode. iOS 11 Changes Large tiles One of the important change is the new large titles in navigation bars. The title gets smaller when you scroll down, in a fashion similar to iOS 10 style where it sits neatly inside the navigation bar itself . If you scroll up, you’ll see the new large title gets a bit larger.This property can be set using navigationController?.navigationBar.prefersLargeTitles = true You have the option to control which view controllers should have large titles and which should have small. Apple prefers to use the large tiles only on the first view controller in the navigation stack similar to the setting app. But by default, if you set the preferred large tiles to true, the subsequent view controller in the navigation stack would have the larger tiles. This can be controlled using the property navigationItem.largeTitleDisplayMode = .never Search controllers inside the navigation Previously you needed to create your UISearchController then add it to your view manually, and most often it is set as their table header view. With iOS 11 you can move it up into the navigation bar, and even have it fixed in place if you want. You can attach search controllers to the navigation bar to have them participate in this shrinking effect similar to the default settings app. If you prefer you can have your search bar to remain static even during scrolling similar to the default Files app. These are handled as follows navigationItem.searchController = UISearchController(searchResultsController: nil) navigationItem.hidesSearchBarWhenScrolling = false Deferred gestures Before iOS 11 the way you tell the system not to grab gestures at the bottom and top edge of the screen are to hide the status bar. Apple has changed the way they handle gestures at the screen edges in iOS 11. From now,  deferring the system gestures has no dependency on the status bar. They have introduced a method which we can override and inform the system to handle deferred gestures. For eg:- we can use the below method to inform the system to defer the gestures on all edges of the screen. override func preferredScreenEdgesDeferringSystemGestures() -> UIRectEdge { return .all } New leading and trailing swipe gestures One of the new APIs in iOS 11 allows the addition of swipe actions on UITableView rows via the new UISwipeActionsConfiguration class and associated UITableViewDelegate methods. For eg:- look at the below method func tableView(_ tableView: UITableView, leadingSwipeActionsConfigurationForRowAt indexPath: IndexPath) -&gt; UISwipeActionsConfiguration? {\r\n</span><span style=\"font-weight: 400;\">  </span>       let read = UIContextualAction(style: .normal, title: \"Mark as read\") { action, view, completionHandler in\r\nprint(\"Marking as read!\")\r\ncompletionHandler(true)\r\n}\r\nread.backgroundColor = UIColor.orange\r\nread.image = UIImage(“read_image”)\r\nlet unread = UIContextualAction(style: .normal, title: \"Mark as unread\") { action, view, completionHandler in\r\nprint(\"Marking as unread!\")\r\ncompletionHandler(true)\r\n}\r\nunread.backgroundColor = UIColor.purple\r\n\r\nlet config = UISwipeActionsConfiguration(actions: [read, unread])\r\nconfig.performsFirstActionWithFullSwipe = false\r\nreturn config\r\n<span style=\"font-weight: 400;\">} In the above method, we have created two swipeable actions read and unRead. There is an option to set the title and background colour as expected. You also have the option to set an image, but in the latter case, the title will not be displayed. Similarly, we have trailing swipe gesture method to handle swipe from the right of table view cell. func tableView(_ tableView: UITableView, trailingSwipeActionsConfigurationForRowAt indexPath: IndexPath) -&gt; UISwipeActionsConfiguration? {\r\n</span><span style=\"font-weight: 400;\">      let delete = UIContextualAction(style: .destructive, title: \"Delete\") { action, view, completionHandler in\r\n</span>           print(\"Deleting!\")\r\ncompletionHandler(true)\r\n<span style=\"font-weight: 400;\">}</span><span style=\"font-weight: 400;\">\r\n</span>      let config = UISwipeActionsConfiguration(actions: [delete])\r\n<span style=\"font-weight: 400;\">      config.performsFirstActionWithFullSwipe = true\r\n</span><span style=\"font-weight: 400;\">      return config\r\n</span>} We can specify the UIContextualAction’s style as normal or destructive. In the latter case, on its action, the cell would be deleted by the system itself. So you have to make sure you call the completion handler after the data has been successfully deleted from the data source. You also have the option to configure full swipe using config.performsFirstActionWithFullSwipe property as shown in above method. Thus in this post, we have seen the points to consider before designing for iPhone X. Along with it, we have seen the major changes that were introduced in iOS 11 with some sample codes. – Rajtharan G, iOS Team, Mallow Technologies Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-12-08"},
{"website": "Mallow-Tech", "title": "Native Apps, Hybrid Apps, and Web Apps – A Comparison", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/11/native-apps-hybrid-apps-and-web-apps-a-comparison/", "abstract": "Native applications, web applications and hybrid apps are the three different applications that are ruling the software application development industry. Each has its own pros and cons and are defining the future of the industry . It is essential for anyone who wants to develop an application to know exclusively about all the three. By knowing about it, one can easily choose which of these will suit their requirements. Native Application: A Native application is developed for a particular platform or device (such as Apple, Android, Windows Phone and BlackBerry). They can take the full advantage of all the features available on mobile devices such as GPS, camera, address book, etc. A native app can be installed directly on a mobile device or it can be installed from a public or private app store. iPhone and Android app are the most used platforms. iPhone apps are written in Objective-C or Swift while Android apps are written in Java. Pros of Native Apps * Aspect Ratios – One size fits most of the Aspect rations. Apps may behave differently depending on the device you are using. If you are on phone or tablet then it will be portrait or landscape respectively. * IDE – Android provides Android studio and iOS provides XCode. These tools provide everything from design to testing. With these tools, we can track the performance of the app, analyse and trace, etc. * Usability – Native app makes more efficient on that platform, we can expect specific functionality as well as design patterns like zoom and multi-touch. Also, back button location varies according to the devices. Cons of Native Apps Native apps are costlier to develop and maintain compared to a hybrid app, separate developers are required to create both Android and iOS apps individually. A codebase has to be managed for every platform launched. Approval in the app stores takes too long and is not guaranteed too. Hybrid Application: A hybrid app has the elements of both web and native applications. A hybrid app is a mobile app that uses the web view to run the web application within the native app. The hybrid apps are distributed through the app stores just like a native app. A hybrid app is built using the HTML 5 and Javascript, it is easier and faster to develop than a native app and also require less maintenance. Hybrid apps completely depend on the speed of the user’s browser. There are seven popular cross-platform app development tools are available, they are, Xamarin, NativeScript, Appcelerator, Kony, Sencha Touch, PhoneGap, React Native. Pros of Hybrid Application * Scaling – Hybrid apps are quite easy to scale and develop compared to native and web apps. Hybrid apps are cross-platform and developers can reuse the code for multiple platforms. * Availability – Hybrid apps are available for different platforms. (eg. Play Store for Android, App Store for iOS, etc.) * Offline Support – Saved date offline, reducing the app response time by access the data in offline mode and in low network bandwidth. * Cost-effective – Single code base across multiple platforms. This reduces the development time and cost and there is no need to develop individually for different platforms. * Uniformity – Single code base across multiple platforms helps in maintaining the branding and user experience(UX). With a single update, we can fix the app for different platforms. Cons of Hybrid Applications Hybrid apps are lower performance than the native app. Takes a lot of time and work to make app works faster and efficiently on different platforms. Web Application Web apps are not an application, they are websites written in web code so it feels like an app on mobile devices. With web apps, we can’t access native APIs and distribute through app stores. A web app is one of the best for a product that requires minimal native gestures and also doesn’t require feature from the mobile device like push notification. A web app is the most inexpensive option. Progressive web apps is another updated technology in which the app acts similar to a native app but can be accessed through the web browser on your mobile. Web apps have become really popular when HTML5 came around and people realised that they can obtain native-like functionality in the browser. Today, as more sites use HTML5, the distinction between web apps and regular web pages has become blurry. Pros of Web Apps A single operating system used when developing web apps. Their development is cost-effective. Ease of Access. The user can access them anywhere and anytime they need. Web apps are more secure as compared to the simple websites. The user can easily customise the web apps. Cons of Web Apps Size is too large. Low performance compared to the native apps. Thus we have seen the Pros and Cons of all types of apps. Choosing a method to create an application depends upon the need of the particular application, time and monetary constraints. By knowing the pros and cons of all these methods helps you to choose the method to best suit you. – Prakash Android Team Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-11-29"},
{"website": "Mallow-Tech", "title": "A Guide for making Energy Efficient Apps – I", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/11/a-guide-for-making-energy-efficient-apps-i/", "abstract": "The screenshot below is something much more familiar to any iPhone user. The screen shows the battery consumption by the applications running on the phone. Any developer’s dream is to top the list of Trending Apps, top list apps but definitely not this. As a user, it is obvious that you would delete the application which consumes a huge portion of the charge. High energy consumption by any application discourages the user from using that app anymore. This leads to a reduction in the userbase and ultimately results in the failure of the application. In order to avoid this, we need to make the application energy efficient. Let us see the ways to make an application more efficient in this blog. We will see this under 4 subtopics, 1.Energy basics 2.Possible energy efficient hacks 3.Energy debugging tools 4.Summary 1.Energy Basics: Before getting into the ways of saving energy it is essential for us to know what is meant by energy in this context. Having a basic understanding of energy will let us work efficiently. Energy equals power times time, i.e. E=P*t. So the longer the time the app consumes power the quicker the battery gets drained. Let’s see how energy is handled in iOS devices. You can see the following image, which represents a typical energy usage chart of an app of an iOS device. The chart drawn in the graph represents the energy usage of an app and some terms had been added which are, Idle: The state when the device is idle. Active: The state when the user is actually using the app. Overhead: The amount of power that’s needed to bring the device hardware up to be able to do the app’s work and also to put it back to sleep. To continue further on this topic it would be better to split the energy usage into two as represented in the image above, 1.Dynamic cost 2.Fixed cost Dynamic cost : Represents the energy usage that the app’s activity is going to consume. Fixed cost : Its the overhead cost which is must/required to make the app’s activity to happen. This very blog is going to revolve around there above two main things and let us see how to we can efficiently handle these two to make the energy consumption of the app as efficient as possible. 2.Possible energy efficient hacks: Everything you do in the device will consume some energy for it to happen. And the following four things plays the major role in it, they are, 1.Processing : Some best practices we can make use to reduce the impact of CPU processing utilization are as follows, a.Background processing: Avoid unwanted background actions, i.e., If in case you are performing a background action, for example, fetching new detail in the background, and at the same time the user closes/goes to the home screen or to another app, that particular data is useless and the unwanted background process is happening. For similar cases, we can cancel the request whenever the user is not actively using the app in scenarios like app goes background. By doing this you can avoid usage of unwanted background processing. b.Call completion handler: If your method or any delegate methods has a completion handler make sure you call that completion handler as soon as your work gets done because until you call the completion handler there would be some precious CPU utilization is being consumed. And by calling the completion handlers you are allowing your device to let sleep, else until the completion handler gets called the device is not permitted to get to a sleep state. The following picture can represent the difference with and without calling the completion handler. Without calling completion handler 2.Networking: a. Avoid timers as much as possible, Instead, you can make use of i. Notifications : Perform certain actions when you receive notification. You can make us of notification like in case your app is a news app and you want the news feed to refresh automatically when some urgent news content is published, in such situation you can post a notification and on receiving that notification you can make use of it making the refresh news feed call which you want. ii. User interaction : Here, it’s not always there will be a need for timer based update/action. In most of the case we might not have needed it, and in such cases, you can perform the action only when the user think they need it. Like in the above example if the user wants to see whether any updated news is available you can make use of a pull to refresh action or a refresh button to make the refresh call. So by making this small tweaks, you can avoid unwanted usage of energy by eliminating timer usage. b.NSURLSession default session There are several properties available in NSURLSession which you can make use of to accomplish energy efficiency, i.WaitsForConnectivity: A Boolean value that indicates whether the session should wait for connectivity to become available, or fail immediately. By making use of this property you can avoid unwanted network calls till the network connection is active for making network calls. ii.Cache: You can enable and configure cache for NSURLSession which could be used for avoiding re-download of contents which is already downloaded. You can perform the above operations as follows, </span>\r\n\r\n<span style=\"font-weight: 400;\">// Setup NSURLSession default session</span>\r\n\r\n<span style=\"font-weight: 400;\">let config = URLSessionConfiguration.default      </span>\r\n\r\n<span style=\"font-weight: 400;\">// Making use of waitsForConnectivity property</span>\r\n\r\n<span style=\"font-weight: 400;\">        config.waitsForConnectivity = true</span>\r\n\r\n<span style=\"font-weight: 400;\">      </span><span style=\"font-weight: 400;\">// Making use of Cache</span>\r\n\r\n<span style=\"font-weight: 400;\">        let cacheDirectoryURL = FileManager.default.urls(for: .cachesDirectory, in: .userDomainMask).first</span>\r\n\r\n<span style=\"font-weight: 400;\">       </span><span style=\"font-weight: 400;\">let cacheURL = try cacheDirectoryURL?.appendingPathComponent(\"MyCache\")</span>\r\n\r\n<span style=\"font-weight: 400;\">        </span><span style=\"font-weight: 400;\">var diskPath = cacheURL?.path</span>\r\n\r\n<span style=\"font-weight: 400;\">        </span><span style=\"font-weight: 400;\">let cache = URLCache.init(memoryCapacity: 12345, diskCapacity: 123456789, diskPath: diskPath)</span>\r\n\r\n<span style=\"font-weight: 400;\">        </span><span style=\"font-weight: 400;\">config.urlCache = cache</span>\r\n\r\n<span style=\"font-weight: 400;\">        config.requestCachePolicy = .useProtocolCachePolicy</span> Minimize retries: You can reduce the number of retry attempts you are making for making a network call in case of failure. Set timeouts : You can explicitly specify timeout for the network calls, by default the system would perform retry Batch network calls : If you think a network call is not necessarily to be called then and there, you can combine that network call when performing other network calls. Background session : As stated in the batch network calls when you think some network calls are not needed to be done as soon as you perform it, you can hand it over to the System. Yes, you heard it right, iOS provides you with such an opportunity where you can handle your task to the system using NSURLSession background session. Thus we have seen the first two points. In the next post, we will see in detail about the energy debugging tools and summary of how to go about it. – Bharath R, iOS Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-11-27"},
{"website": "Mallow-Tech", "title": "5 Things to consider before developing an educational App", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/11/5-things-to-consider-before-developing-an-educational-app/", "abstract": "The education sector is one of the fastest growing sectors in the digital age. As the digital devices are available to all age groups, it is a very good mode to increase the engagement through that. Digitising the education sector has given very good results in terms of the student interaction and piqued the interests of the students. Various apps such as Byju’s, Khan Academy are creating wonders. This in a way is a paradigm shift in the education sector. As digitising education sector is on the rise, it is high time to develop an application to assist the learning. Before developing an application for any sector you need to understand your core users. In this blog, we will see the five most important things that have to be taken into consideration before developing an app for the education sector. Intuitive UI/UX: The application should definitely have an intuitive user interface. This is a primary necessity as the main aim of the app is making the user curious to learn and explore without anyone’s help. The UI has to be designed in such a way that the student can explore and find what they want intuitively. Ease of Access: Ease of access is the key ingredient in making an application successful. Consider an app containing multiple ways to solve a problem, finding and exploring each way should be available at ease. If it takes some time to explore or the app is designed in such a way that the access is different then it definitely won’t engage the users for a long time. Ease of access keeps your app on the Top Of the Mind for solving that particular problem. Technological Updation: The very idea of digitisation is making full use of the technology in assisting the learning process. When new technologies and features come up, you need to upgrade and utilise that feature to give more value to the user. It just might even turn as your differentiating factor. Gamification: Gamification is the ultimate strategy to increase the user engagement. Here the key is not a surface level gamification of the application but rather it has to be a part of core build. Gamification as a gimmick will result is negative engagement. A proper gamification will recognise the user and pique their curiosity to learn and adds value to them. There are a lot of tools available to gamify to your application. Synchronise to share: In any application, today sharing must be easy. Adding social share plugins or synchronising your achievements if gamified to share online acts as a great motivator. Along with that if you need to send particular info or assignment then facilities of sharing the same in multiple channels had to be added. The above-mentioned points are some of the most critical points to be considered to make an app successful in the education sector. We at Mallow Technologies have created an application to find one stop solution for all the physics, chemistry and mathematical formula named FormulaMAX. You can download the app from Google Playstore and Appstore . If you have an idea to develop an application for the education sector, you can very well contact us. We help you in transforming your dream into reality. – Marketing Team , Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-11-23"},
{"website": "Mallow-Tech", "title": "6 things not to do before deployment", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/11/6-things-not-to-do-before-deployment/", "abstract": "Deployment of an application is a crucial and critical stage. The deployed application should be perfect and that decides the fate and future of the company and their business. Today in this post we will see some of the most important precautionary points that have to be taken care before deployment of an application. 1. Do not accept last-minute changes: For any business constant updating of features is very much important to sustain in the market. All the companies will try to give as many features within a short span to gain the advantage. When the client comes up with last-minute features to be added you shouldn’t just comply and add it just before deployment. Sometimes, the developers tend to not add any test cases and add test cases for the last minute features. This eventually affects the overall quality of the product and sometimes it might even jeopardise the app on the whole. Every feature has to go through the process to make the final product perfect and stable. 2. Do not skip the checklist: When you comply with the last minute changes, you tend to skip the checklist. This is a big red flag when deployment is concerned. Never ever skip the checklist. Your peer might have identified some problems and have updated the checklist, by not checking it, you might potentially ruin the user experience. 3. Do not deploy without testing: Sometimes you might be satisfied with the development team’s testing. No, that is not testing of the product. Any feature shouldn’t go live without the approval of the testing team. Testing team will see for every possible glitch and ensure that the feature works perfectly. Every feature must go through the cycle of processes that are designed by the team before. Any shortcuts will not help for the betterment of the product. 4. Do not make any change without a proper Analysis: Any changes made in the app has to be analysed well before implementation. Without analysis of the feature and making any change might harm the entire application. It will be tough to rework once the mistake is done. Another big issue of the changes without analysis that you don’t know how it affects the other features. Hence, any changes in the application have to be done with proper research and analysis. 5. Do not implement any changes in Live program: Any changes or addition has to be done and tested at the development environment. After perfecting the features and testing at various levels only you can make the feature live. Directly making the changes in the live application is very dangerous as any wrong or crash at the live application will totally affects the usage and the customer acquisition just moves from tough to impossible. 6. Do not keep migration and account creation as a last task: Database migration is one of the most important tasks. Keeping it as the last task before deployment is a big no. You should definitely have migrated the database soon enough. Generating API key, creating third party accounts are some of the important tasks which has to be done at the early stage of development. It has to be perfectly ready before deployment, by changing it at the last moment it may even hinder the basic functionality of the application. Thus we have seen in detail about the six important don’ts before deployment.  This might give you a definitive idea to make your application successfully deployed. A well-developed application is considered successful only if it is deployed perfectly. – Yogesh M, iOS Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-11-14"},
{"website": "Mallow-Tech", "title": "How to use ARKit using SceneKit", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/11/how-to-use-arkit-using-scenekit/", "abstract": "This is the continuation of the previous blog about ARKit introduction . Today we can see how we can implement ARKit by simply placing the default object in the real world using SceneKit . To implement ARKit we need some basic knowledge in one of the following technologies. Each technology is different in their own ways. The technologies are, Scenekit SpriteKit Metal SceneKit: It is used to render 3D scenes in our app or game. We can easily add physical simulation, animations, effects. SceneKit combines high-performance rendering engine with descriptive API to render a 3D scene. Unlike Metal and OpenGL which requires a detailed algorithm to render the scenes in view, SceneKit only requires the description of our scene like lighting, the position of a scene, etc… Following are the Important classes In SceneKit which May come into picture when we implementing ARKit SCNScene : – Its like view hierarchy like camera node, light node, etc… SCNView : – A view for displaying 3D SceneKit content. SCNNode : – A Structured element of the scene graph to represent the position and transform in 3D space. NOTE: Today we are going to use SceneKit for our demo since we want to place 3D contents in the real world. SpriteKit: It is used to create the 2D scenes for games which support only 2 Dimensional views. You can learn more about SpriteKit in Apple docs . Metal: It is used to create advanced 3D graphics using GPU. Metal encompasses Metal frameworks, metalKit, Metal shading language and Metal standard library. It is advanced than SceneKit and SpriteKit, but it requires GPU programming knowledge. You can learn more about Metal on their documentation page . Small brush up about ARKit: ARKit uses device camera and motion sensor to analyse the real world scenes and to render virtual objects in it. ARKit is Available on iPhone and iPad which has an A9 processor and above. We need high computation and processing power to analyse the real world scenes and to do lot more maths to render our virtual objects. That’s why Apple sets minimum required processing capability as A9. To make your app available in app store only for devices which contain A9 and above use UIRequiredDeviceCapabilities in info.plist. If AR is a secondary feature of your app we can check AR capability using isSupported in ARConfiguration class. Important classes in ARKit: ARWorldTrackingConfiguration – This world tracking configuration uses device rear camera, motion data to find orientation and position and to find a flat surface. AROrientationTrakingConfiguration – This orientation tracking configuration uses only device rear camera and tracks only the orientation of the device. ARSCNView – Gives 3D AR experience using SceneKit. ARSKView – Gives 2D AR experience using SpriteKit. ARHittestResult – Contains info about real-world surface using device camera view. This info is more than enough to create a simple ARKit demo. Assumptions: You have latest Xcode installed on your iMac or MacBook You have iPhone or iPad with A9 and above processor. You are familiar with basic Project setup in Xcode. Okay AR developer, let’s start, Open Xcode and create new Project in Xcode. To implement AR related things we can simply use Augmented Reality app template. We can use any other template to create AR demo. The reason we are using Augmented Reality app template is that it will reduce our time by setting up basic things for this demo. Name your Project as you want. Choose your development team. Make sure SceneKit technology is selected in content technology. Hit next and create. As soon as Project created just run your app on your iPhone or iPad you can see Apple’s default example for AR. Now open your viewController.swift file, Now you are going to add a ball(Sphere geometry) in the real-world scene at where user tapped. In SceneKit, we have many default shapes/objects like Sphere, Cone, Cylinder, etc., Now we are going to use a sphere to get a ball-like structure. We need to get the point where the user taps on the screen to place our ball where the user taps. For that, we are going to use user touch began method from UIResponder class. So in the following method just below didReceiveMemoryWarning() method. </span><span style=\"font-weight: 400;\">override func touchesBegan(_ touches: Set&lt;UITouch&gt;, with event: UIEvent?) { </span>\r\n\r\n<span style=\"font-weight: 400;\">        let touch = touches.first. // 1 </span>\r\n\r\n<span style=\"font-weight: 400;\">        let results = sceneView.hitTest((touch?.location(in: sceneView))!, types: .featurePoint) // 2 </span>\r\n\r\n<span style=\"font-weight: 400;\">       guard let firstresult = results.first else { return } // 3 </span>\r\n\r\n<span style=\"font-weight: 400;\">        let transform = firstresult.worldTransform // 4 </span>\r\n\r\n<span style=\"font-weight: 400;\">        let matrix = SCNMatrix4(transform) // 5 </span>\r\n\r\n<span style=\"font-weight: 400;\">        let position = SCNVector3(matrix.m41, matrix.m42, matrix.m43) // 6 </span>\r\n\r\n<span style=\"font-weight: 400;\">        sceneView.scene.rootNode.addChildNode(createNode(at: position)) // 7 </span>\r\n\r\n<span style=\"font-weight: 400;\">} What’s happening in the above method, We are getting the first touch from the set of touches. Here we are trying to get the real world details from the point where the user taps on the screen. The “result” is an array of ARHittestResult. We are getting the first hitTest result for more accuracy. We are getting world scene details as a numeric value. The value will be type of matrix_float4x4 Convert matrix_float4x4(kind of float value) into real 4 x 4 matrix using SCNMatrix4. Calculating the position where the user taps from the x, y and z coordinate values from the matrix which we formed on above step. These elements, m41, m42 and m43 will have real-time coordinates data. That’s why we are using those elements. We are creating a new node(Creating new ball) and adding it to sceneview’s root node. Don’t worry about createNode(at: ) method, we are going to create it now. Add a new method to create a new ball to place at given position. The method will be something like below. </span><span style=\"font-weight: 400;\">func createNode(at position: SCNVector3) -&gt; SCNNode { </span>\r\n\r\n<span style=\"font-weight: 400;\">        let geometry = SCNSphere(radius: 0.15) // 1 </span>\r\n\r\n<span style=\"font-weight: 400;\">        let matrial = SCNMaterial() // 2 </span>\r\n\r\n<span style=\"font-weight: 400;\">    </span> <span style=\"font-weight: 400;\">matrial.diffuse.contents = UIImage(named: \"art.scnassets/football.jpg”) // 3 </span>\r\n\r\n<span style=\"font-weight: 400;\">    </span> <span style=\"font-weight: 400;\">geometry.firstMaterial = matrial // 4 </span>\r\n\r\n<span style=\"font-weight: 400;\">        let node = SCNNode(geometry: geometry) // 5 </span>\r\n\r\n<span style=\"font-weight: 400;\">    </span> <span style=\"font-weight: 400;\">node.position = position // 6 </span>\r\n\r\n<span style=\"font-weight: 400;\">        return node // 7 </span>\r\n\r\n<span style=\"font-weight: 400;\"> } What’s happening in the above method, We are creating a new sphere with a radius of 0.15 metre. If we create a sphere we won’t get balls like the look and feel. Simply we will get white round shape. So we need to do some extra stuff to make our sphere look like a ball. So to create that look and feel we have a class called SCNMaterial. Here we are just initialising it. Here we are giving ball image to your material as diffuse content. Here the contents are the type of Any so we can give whatever we want like UIColor, String, etc… So download any ball image from the internet and place it inside art.scnassets and give proper image name while initialising UIImage. Assigning create material to your sphere. We can give an array of material using .materials property in the sphere, here we are giving only one material, so we are assigning material to spheres by using its firstMaterial property. Creating a new node using our sphere geometry. Here node is like UIView. Providing the node position in real world. Here is position is the point where the user taps. Just returning the node what we created. Now go to viewDidLoad(:-) method and comment or delete following lines, we are going to have our own object so we don’t need these lines anymore, // Create a new scene\r\n\r\n<span style=\"font-weight: 400;\">        let scene = SCNScene(named: \"art.scnassets/ship.scn\")! </span>\r\n\r\n<span style=\"font-weight: 400;\">        // Set the scene to the view </span>\r\n\r\n<span style=\"font-weight: 400;\">        sceneView.scene = scene What’s in viewWillAppear() override func viewWillAppear(_ animated: Bool) {\r\n\r\n<span style=\"font-weight: 400;\">        super.viewWillAppear(animated) </span>\r\n\r\n<span style=\"font-weight: 400;\">     </span>\r\n\r\n<span style=\"font-weight: 400;\">       // Create a session configuration </span>\r\n\r\n<span style=\"font-weight: 400;\">        let configuration = ARWorldTrackingConfiguration() // 1 </span>\r\n\r\n&nbsp;\r\n\r\n<span style=\"font-weight: 400;\">        // Run the view's session </span>\r\n\r\n<span style=\"font-weight: 400;\">        sceneView.session.run(configuration) // 2 </span>\r\n\r\n<span style=\"font-weight: 400;\">} Just creating new session configuration to start analysing your real-world scenes using the device camera. Start running the session configuration, after this only we will get data about the real-world scene. What’s in viewWillDisappear() override func viewWillDisappear(_ animated: Bool) {\r\n\r\n<span style=\"font-weight: 400;\">        super.viewWillDisappear(animated) </span>\r\n\r\n<span style=\"font-weight: 400;\">       </span>\r\n\r\n<span style=\"font-weight: 400;\">        // Pause the view's session </span>\r\n\r\n<span style=\"font-weight: 400;\">        sceneView.session.pause() // 1 </span>\r\n\r\n<span style=\"font-weight: 400;\">} </span> No need to analyse our real-world scenes whenever this view disappears. So just pausing the running session. How to test? You have done everything from your side remaining will be handled by ARKit, just Run your app. Wait for some time to run your session configuration and then taps anywhere on the screen, you can see your ball in the real world where you have tapped. In the next blog, we will see how to place a custom object in the real-world using ARKit. – Karthick Selvaraj, iOS Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-11-09"},
{"website": "Mallow-Tech", "title": "Tez – A new force in the digital payment game", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/11/tez-a-new-force-in-the-digital-payment-game/", "abstract": "In the growing era of digitisation and mobile payment, Google has entered the Indian market with the app called TEZ. This app is designed specifically to suit the Indian markets. Although players like PayTM and PhonePe is trying to capture the digital payment through their wallet services, Tez is not a wallet service per se. Tez links the bank accounts of the customer to mobile account and the payments are done. This is similar to that of the Apple Pay. Google uses Audio QR technology to make the payment. The phone number is used to set the account. Then the UPI access has to be provided from the bank and once it is done then it automatically links with the google account. This is a highly secure mode of transfer and lot simpler way of money transfer. As it draws the money from the bank account directly, you don’t have to load the money in the wallet. This makes this app unique. Some of the key points of TEZ are given below. Direct payment: As mentioned above Tez uses direct payment from the bank accounts and hence less complex and time-consuming than the other wallet payments. Cash Mode for nearby transactions: With Tez, you can share money with a nearby person without sharing any private details such as phone number or bank account. This will serve as a huge advantage for the small and big vendors. This in a way is a perfect way to go digital in terms of payment. Image source: Androidauthority.com Tez Shield: It provides 24/7 data security by detect Fraud, prevents hacking and verifies the identity of the user. Image courtesy: Gadgets.ndtv.com Tez for Business: Tez for Business is a program for large and small enterprises to connect with consumers inside the Tez app to make payments, share redeemable offers, products and updates. Localisation: Tez is localised to the Indian markets with the inclusion of various Indian languages such as Hindi, Bengali, Gujarati, Marathi, Tamil and Telugu. Thus we have seen the entry of the Google’s Tez by force and it is nearly conquering the market with its flashy offers. This is the first step to bring a huge change in the future of digital payments. This may also pave way for many businesses to integrate their payment with this and also a lot of similar technologically advanced payment services might arise. – Sivavishnu R, Android Team, Mallow Technologies Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-11-07"},
{"website": "Mallow-Tech", "title": "How to choose your Brand Colour?", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/11/how-to-choose-your-brand-colour/", "abstract": "Creating and establishing a Brand is an important step for any business in the long run. A Brand’s identity is registered in the consumer’s mind based on their design and usage of colours. In this blog, we are going to see in detail about the usage of the colours for your Brand. Choosing a colour for any brand cannot be made at random. The brand identity or logo creation can be done with three major types namely Mono colour, Two colour and Full colour. Mono colour is the usage of single dominant colour. Mono colour design – 51% Two colour design – 30% Multi colour design – 19% Facebook and Twitter are good examples of mono colour design. Flipkart and FedEx stand as an example of Two colour design. Some of the great examples of multicolour designs are Google, Microsoft etc., To choose the perfect colour it is important to understand the psychology of the colours. Here we explain briefly about the characters associated with the colours and the brands using it. Blue: Blue is one of the majorly used colour in branding. The blue colour is associated with trust, conservative nature, dependable, honesty, calm, secure and cool. The brands which use blue tries to convey these message with their tone. Facebook, Dell, Ford and Samsung is a good example. Black: Black is the second most used colour in the branding. Black is normally associated with sophistication, luxury, formal, stylish, elegant, authoritative and expensive or premium quality. Blackberry, Mercedes Benz, Audi are few examples which perfectly blends the colour to give the feel you wish to imbibe among the customers. Red: Red is the colour which most often combines well with white or black to give the required feel. It is often associated with boldness, passionate, strong, attention-grabbing, love, excitement, action and aggression. KFC, Coca-Cola, Netflix, Virgin are some of the brands that use red as their dominant colour. You can associate the characteristics of these brands with the red colour. Yellow: Yellow is a unique colour which has to be handled carefully. Often used as a caution or warning colour it indeed grabs the attention totally. Yellow is often bordered or aligned with another dark colour to give a perfect contract appearance which gives perfect attention that’s required. Often the aligning or bordering colour would be black which goes well with yellow. It is associated with logical, optimistic, progressive, playful and creative aspects. Nikon, Mc Donalds, Snapchat, IMDB are some of the examples. Orange: Orange is a colour which is often associated with happy, energetic, sociable, friendly, affordable, enthusiastic aspects. Fanta, Mirinda, HTML, VLC Media player are some of the brands that use Orange as their predominant colour. Green: Green is associated nature, wealth, fresh, life, harmony, environment, growth. Some of the brands that use this colour to perfectly synchronise their ideology and feel are the Animal planet, recycle, Subway, Tropicana etc., These brands have to communicate the above aspects to position themselves. Purple: Purple is one of the most expensive colour to produce. It is often seen as elite colours due to the sophistication of the colour. Some of the aspects that are associated with purple are royalty, mystery, pomp, ceremony, creative, unique and majestic. This colour is more often catches the eyeballs of the kids and hence Cadbury, Taco Bell and Yahoo use it as their dominant colour. Multicolour: Multicolour is often unique and associated with fun, easy going, childlike, multidisciplinary characteristics.  Some of the well-known brands that make use of this pattern is Google, Microsoft, eBay etc., Thus we have seen in detail about the colours to choose and the brands that capitalised on the colours. In the next blog post, we will see in detail about the designs to be used. – Satheesh Kumar, Design Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-11-03"},
{"website": "Mallow-Tech", "title": "Simple example of Drag and Drop feature in iOS 11", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/10/simple-example-of-drag-and-drop-feature-in-ios-11/", "abstract": "We saw in brief about the Drag and Drop feature introduced by Apple during their WWDC a few months back. Today, we will have a deeper look on the feature through a sample code. We will see how to implement the Drag and Drop feature in View and Table View. Create a new project and add 2 options View and TableView. When the user selects Custom View option, navigate to CustomViewController and design the UI like given below. In this screen, we are going to do a drag from one imageView to another imageView and from one textView text to another textView. First, enable the user interaction for imageView. Then, we need to set a Drag interaction for ImageView with the DragInteraction delegate. In the delegate only we are going to specify the DragItems which we are going to drag. </span></p>\r\n<p class=\"p2\"><span class=\"s1\">        dragImageView.isUserInteractionEnabled = true</span></p>\r\n<p class=\"p2\"><span class=\"s1\">        dropImageView.isUserInteractionEnabled = true</span></p>\r\n<p class=\"p2\"><span class=\"s1\">        dragImageView.addInteraction(UIDragInteraction(delegate: self))</span></p>\r\n<p class=\"p2\"><span class=\"s1\">        dragTextView.addInteraction(UIDragInteraction(delegate: self)) Once an object is ready for drag, the below delegate method will be called. </span>\r\n\r\nfunc dragInteraction(_ interaction: UIDragInteraction, itemsForBeginning session: UIDragSession) -&gt; [UIDragItem]<span class=\"s1\"> We are going to drag the imageview and textview to be dragged so the code implementation will be as follows. </span>\r\n\r\nfunc dragInteraction(_ interaction: UIDragInteraction, itemsForBeginning session: UIDragSession) -&gt; [UIDragItem] {\r\nif let textValue = interaction.view as? UITextView {\r\nlet provider = NSItemProvider(object: textValue.text! as NSString)\r\nlet item = UIDragItem(itemProvider: provider)\r\nreturn [item]\r\n} else if let imageView = interaction.view as? UIImageView {\r\nguard let image = imageView.image else { return [] }\r\nlet provider = NSItemProvider(object: image)\r\nlet item = UIDragItem(itemProvider: provider)\r\nreturn [item]\r\n}\r\nreturn []\r\n}<span class=\"s1\"> Spring Loaded: This is to recognise the action for a button when we hover the dragging item above the button. Once you drag the image and hover the button it will unhide dropping area. Like below </span></p>\r\n<p class=\"p2\"><span class=\"s1\">        dropOffButton.isSpringLoaded = true Drop interaction: W e need to set a Drop interaction for ImageView with the DropInteraction delegate. In the delegate only we are going to handle the Dropping operations. Once the dragging operation is started, the below drop interaction delegate method will be called. </span>\r\n\r\nfunc dropInteraction(_ interaction: UIDropInteraction, sessionDidUpdate session: UIDropSession) -&gt; UIDropProposal<span class=\"s1\"> To check whether the image or text can be dropped in the particular frame the below code is used. </span>\r\n\r\nfunc dropInteraction(_ interaction: UIDropInteraction, sessionDidUpdate session: UIDropSession) -&gt; UIDropProposal {\r\nlet location = session.location(in: self.view)\r\nlet dropOperation: UIDropOperation?\r\nif session.canLoadObjects(ofClass: String.self) {\r\nif dropTextView.frame.contains(location) {\r\ndropOperation = .copy\r\n} else if dropImageView.frame.contains(location) {\r\ndropOperation = .forbidden\r\n} else {\r\ndropOperation = .cancel\r\n}\r\n} else if session.canLoadObjects(ofClass: UIImage.self) {\r\nif dropTextView.frame.contains(location) {\r\ndropOperation = .forbidden\r\n} else if dropImageView.frame.contains(location) {\r\ndropOperation = .copy\r\n} else {\r\ndropOperation = .cancel\r\n}\r\n} else {\r\ndropOperation = .cancel\r\n}\r\n\r\nreturn UIDropProposal(operation: dropOperation!)\r\n}<span class=\"s1\"> To perform a drop operation, we need to implement the code below. </span></p>\r\nfunc dropInteraction(_ interaction: UIDropInteraction, performDrop session: UIDropSession) {\r\nif session.canLoadObjects(ofClass: String.self) {\r\nsession.loadObjects(ofClass: String.self) { (items) in\r\nif let values = items as? [String] {\r\nself.dropTextView.text = values.last\r\n}\r\n}\r\n} else if session.canLoadObjects(ofClass: UIImage.self) {\r\nsession.loadObjects(ofClass: UIImage.self) { (items) in\r\nif let images = items as? [UIImage] {\r\nself.dropImageView.image = images.last\r\n}\r\n}\r\n}<span class=\"s1\"> Second, we are going to look about the TablView Drag and Drop. TableView Drag and Drop: In table view we are having DataSource and Delegate method like now we have DragInteraction and DropInteraction delegate method. In Table view the drag and drop are mainly based on the index path. First, we need to set a drag and drop delegate. </span>\r\n\r\ntableView.dragDelegate = self\r\ntableView.dropDelegate = self<span class=\"s1\"> Similar to the method we did in custom view, we need to specify the drag item in the drag delegate. This is done by the below method. </span>\r\n\r\nfunc tableView(_ tableView: UITableView, itemsForBeginning session: UIDragSession, at indexPath: IndexPath) -&gt; [UIDragItem]<span class=\"s1\"> To drag a row, the following code is followed. </span>\r\n\r\nfunc tableView(_ tableView: UITableView, itemsForBeginning session: UIDragSession, at indexPath: IndexPath) -&gt; [UIDragItem] {\r\nlet string = stringArray[indexPath.row]\r\nlet itemProvider = NSItemProvider(object: string as NSString)\r\nreturn [UIDragItem(itemProvider: itemProvider)]\r\n}<span class=\"s1\"> Once the dragging action is begin the screen looks like this. For drop, we need to check whether the table view can handle the dropping object or not. This will be done by the following code. </span>\r\n\r\nfunc tableView(_ tableView: UITableView, canHandle session: UIDropSession) -&gt; Bool {\r\nreturn session.canLoadObjects(ofClass: NSString.self)\r\n}<span class=\"s1\"> Once the above condition is satisfied, then the below delegate method is called. In this delegate method we are going to handle the copy or move operation to the table view. </span>\r\n\r\nfunc tableView(_ tableView: UITableView, dropSessionDidUpdate session: UIDropSession, withDestinationIndexPath destinationIndexPath: IndexPath?) -&gt; UITableViewDropProposal {\r\nreturn UITableViewDropProposal(operation: .copy, intent: .automatic)\r\n}<span class=\"s1\"> Once the object is ready for dropping then the below delegate method will be called. </span>\r\n\r\nfunc tableView(_ tableView: UITableView, performDropWith coordinator: UITableViewDropCoordinator)<span class=\"s1\"> To handle the dropping operation for Text, the code will be as below. </span>\r\n\r\nfunc tableView(_ tableView: UITableView, performDropWith coordinator: UITableViewDropCoordinator) {\r\nlet destinationPath: IndexPath\r\n\r\nif let indexPath = coordinator.destinationIndexPath {\r\ndestinationPath = indexPath\r\n} else {\r\nlet section = tableView.numberOfSections - 1\r\nlet row = tableView.numberOfRows(inSection: section)\r\ndestinationPath = IndexPath(row: row, section: section)\r\n}\r\n\r\ncoordinator.session.loadObjects(ofClass: NSString.self) { (items) in\r\nif let values = items as? [String] {\r\nvar indexPathArray = [IndexPath]()\r\nfor (index, item) in values.enumerated() {\r\nlet indexPath = IndexPath(row: destinationPath.row + index, section: destinationPath.section)\r\nself.stringArray.insert(item, at: indexPath.row)\r\nindexPathArray.append(indexPath)\r\n}\r\n\r\ntableView.insertRows(at: indexPathArray, with: .automatic)\r\n}\r\n}\r\n}<span class=\"s1\"> We have seen the simple operation of drag and drop in this blog. In our upcoming blog we will see how we can incorporate animations and custom interactions in Drag and Drop. You can find the full source code of this sample program in the github . – Yogesh M, iOS Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-10-26"},
{"website": "Mallow-Tech", "title": "Importance of Tacit Knowledge for Business Analysts", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/10/importance-of-tacit-knowledge-for-business-analysts/", "abstract": "Knowledge Management is the key to being a successful Business Analyst. While talking about knowledge management, people generally work with explicit knowledge which can be transferred easily from one individual to other with proper understanding, also can be easily documented and studied. Though explicit knowledge is important, it is vital to possess and predict Tacit Knowledge for being a successful Business Analyst. Tacit knowledge cannot be documented or transferred or taught easily from one individual to another, it includes attitude, beliefs, capabilities and expertise possessed by an individual. Being a Business Analyst understanding the untold requirements of clients by analysing their tacit knowledge will ensure the development of software to meet the client’s expectations. Though Business Analysts focus on eliciting, analysing, documenting, verifying and validating the requirements from an explicit knowledge base, there will be some inarticulate requirements which should be identified by understanding their tacit knowledge base for delivering the customisable product to the client. Eliciting the requirements of clients, both explicit and tacit knowledge base can be done by applying some basic skills and techniques as follows: Maintaining good rapport and teamwork – this helps in having a close collaboration and communication with the client so that we can understand their needs. Also, the rapport among the team (developers, testers, client and BA) provides a platform to discuss and understand others view. Close observation of stakeholders – this helps to predict their workflow and suggest for alternatives if any. Probing scenario based questions – this is an ingenious way to understand one’s perceptions from their response. Methods like “Five Why’s” helps to find the roots by extracting requirements from client’s tacit knowledge base. As more projects are moving nowadays to the agile environment, where there is minimal documentation, the need for understanding client’s tacit knowledge is very important to save the efforts of the developers and to deliver the product with utmost satisfaction of customers. It is important for all the organisations to have an understanding about Tacit Knowledgebase of all its employees for better utilisation of their skills and knowledge effectively for the growth and development of the organisation. – Kalaivani Sathish, Business Analyst Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-10-17"},
{"website": "Mallow-Tech", "title": "Key takeaways from Google’s pixel 2 launch event", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/10/key-takeaways-from-googles-pixel-2-launch-event/", "abstract": "Google launched Google Pixel 2 and Pixel 2 XL on October 4th, 2017. In this event, they also launched few other interesting products along with the Pixel phones. Let us see in detail about those products in this blog. Google Pixel Buds: Google introduces the first pair of headphones with built-in Assistant. The headphones will be tethered together by a wire but connect to your phone via Bluetooth. The buds are circular and feature an adjustable loop that will help them stay in your ear. Google assures up to five hours of listening time on a single charge with another 24 hours of battery life waiting in the included charging case’s 620 mAh battery. You can access Google’s Assistant via along press on the touch-sensitive right earbud. You can also tap for play/pause and swipe for volume control. The Real-Time Translation is also listed in features of Pixel Buds. Using Google Translate and machine learning, the Pixel buds will translate conversations in real time. At the launch, 40 languages will be support for the Real-Time translation but it looks like this will be a Pixel only feature for the time being. The Google buds will currently work with Android version Marshmallow and above or iOS 10 and above. Google Clips: Google Clips uses Machine learning technology to automatically sense interesting which needs to capture and will also start recording it as video to save your best moments. Clips can upload pictures or video footage to Google Photos automatically, and don’t need internet. From here you can share your favourite moments and even use Google Photos to create memorable movies and albums. You don’t need an internet connection for Clips, either. All it needs is your phone, and you’re ready to roll. Google Clips can mount to a variety of objects using its built-in hardware, so you’ll be able to get footage of things you normally wouldn’t have access to. Put it in a crib, a jacket, or even a skateboard. The choice is yours. Clips can get about 3 hours of recording in before you have to charge it in again, so you shouldn’t have to worry about it. If you prefer to grab photos instead of video, just save a frame from one of the clips it snagged. Google is trying to make Clips extremely versatile, and it seems like it should be an extremely interesting product for those who love to share short moments in their life. Google Pixel 2 grabs DxOMark best smartphone camera crown: Samsung had tied for DxOMark’s best camera title, Google has just announced on stage that the Pixel 2 has now taken the crown with a score of 98,. The Google Pixel 2 trumps both Samsung Galaxy Note8 the and the iPhone 8, which just received a score of 94. With a 1/2.6-inch 12MP sensor and a f/1.8 aperture, the Pixel camera is extremely hard to beat. The new Pixel camera has Google’s electronic image stabilization paired with optical image stabilization technology, so it should be able to stabilize even the shakiest of images and video. And provides unlimited full-size upload to Google Photos, you’ll be able to keep all the photos and videos you shoot without losing any quality. The main features that gave the Pixel 2 this score were the wide dynamic range in all lighting conditions, strong flash performance, a high level of detail preservation, and pleasing foreground and background blur for portraits. On the video side, DxO says that the camera had fast and accurate autofocus, good noise reduction and detail preservation, very good stabilization, and decent white balance. The Google Pixel 2 received a score 99 for photos and 96 for videos, that equated to that overall score – 98. Pixel 2 to include a preview of Google Lens, along with AR stickers: In the past, Google officially announced its new project Google Lens. It is a new app that would let users take pictures and get information about the subject of those images via Google Assistant. Today, the company confirmed that its new Pixel 2 and Pixel 2 XL smartphones will be the first to have a preview version of Google Lens. Google showed off how Lens will work on a few demos. You can be able to add animated AR stickers to pictures and videos. Some of them will be based on properties such as the Saturday Night Live, NBA, and Netflix’s Stranger Things. In the demo, we saw an AR sticker based on that show’s main monster, the Demogorgon, as if it was on stage. Google announces new Daydream View (2017): Google has revealed its new Daydream View VR headset. To justify, the new headset will have a wider, more “immersive,” field of view than its predecessor, presumably to accommodate the recent trend of bezel-less smartphones, and will also include a dedicated slot to house its controller. It arrives with a removable, over-the-top head strap, which could go some way to making the headset feel more secure (this was sorely missing from the original Daydream View). As for its dimensions, it measures 6.6 x 4.6 x 3.9 inches and weighs 9.2 ounces. The current devices that support the headset are given below, but others are likely to be added in the coming months: Pixel 2 Pixel Galaxy S8/S8 Plus Galaxy Note 8 Axon 7 Mate 9 Pro Moto Z Moto Z2 ZenFone AR Thus we saw in detail about the products launched by Google. In the next blog, we will see in detail about the Google Pixel 2 and Pixel 2 XL phone and its features. – Pangaj, Android Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-10-06"},
{"website": "Mallow-Tech", "title": "An introduction to Apple’S AirPlay 2", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/10/an-introduction-to-apples-airplay-2/", "abstract": "AirPlay AirPlay was initially build to stream audio, video and photos to Apple TV on a wireless basis.  AirPlay was predominantly used to stream audio from iTunes to AirPort Express, which was built on Apple’s ‘AirTunes’ software from 2004. AirPlay replaced Apple’s previous technology called AirTunes, which only allowed the streaming of music, but not the other kinds of data that AirPlay supports. Though innovation focused on wireless transitions, it was difficult to get a product set up. Those early products also didn’t have the most stable connection, and music would often drop out. To enhance stability, Updates to AirPlay was made and the main focus of the update is on streaming music from your iOS device to more than one product. What is AirPlay 2? Apple’s AirPlay 2 is the latest version of the AirPlay protocol introduced in iOS 11 which lets you send audio to multiple AirPlay speakers at a single stroke, from anywhere in iOS. It assembles a multi-room audio system from any compatible speakers, and control it from iOS’s AirPlay controls or inside third-party apps. There’s also a new MusicKit API which engulfed developers to integrate with the full Apple Music service. AirPlay 2 will offer the ability to stream music wirelessly to, and between, compatible speakers on the same wifi network. This is through the Control Centre on iOS devices, an Apple TV box, or iTunes. AirPlay 2 Features The main features introduced in AirPlay 2 includes, Speakers in Home app Multi-room audio and Shared playlists . Initially, for starters, AirPlay 2 will add support for controlling of speakers via the Home app, which means users will be able to select through which speakers audio is played, along with the volume controls of the individual, for all of those speakers regardless of their location within the home. Another adding innovation with AirPlay 2, is the ability for multiple users to add songs to one playlist. This “Shared Up Next” feature is available for Apple Music and extends support for third-party apps as well since Apple is providing AirPlay 2 audio API for third-party developers. Apple products that Support AirPlay 2 Any Apple device that supports iOS 11 will also get AirPlay 2: iPhone iPhone X iPhone 8 Plus iPhone 8 iPhone 7 Plus iPhone 7 iPhone 6S Plus iPhone 6S iPhone 6 Plus iPhone 6 iPhone SE iPhone 5S iPad 12.9in iPad Pro (first generation) 12.9in iPad Pro (second generation) 9.7in iPad Pro 10.5in iPad Pro iPad (fifth generation) iPad Air 2 iPad Air iPad mini 4 iPad mini 3 iPad mini 2 iPod touch iPod touch (6th generation) Apple TV Apple TV 4th Gen MacBook and MacBook Pro MacBook: Late 2009 or later iMac/iMac Pro: Late 2009 or later MacBook Air: 2010 or later MacBook Pro: 2010 or later Mac mini: 2010 or later Mac Pro: 2010 or later AirPlay 2 with HomePods AirPlay 2 will work in harmony with Apple’s own HomePod smart home speaker. Apple Music plays on the HomePod via the cloud, but any other audio if needs to be sent, it has to come over AirPlay 2, from a device running iOS 11, macOS 10.13, or tvOS 11. It is not just Apple’s speaker which is compatible with AirPlay 2, rather illustrious list of hi-fi companies have pledged their support for this innovation. The companies signed up include: Bang & Olufsen Beats Bluesound Bose Bowers & Wilkins Definitive Technologies Denon Devialet Dynaudio Libratone Marantz McIntosh Naim Sonos – from 2018 Polk Apple AirPlay 2 in HomeKit AirPlay 2 extends support to HomeKit, which allows HomeKit to communicate to speakers automatically. If you happen to own an Apple TV connected to a speaker setup, it can also act as the central hub to stream music. Sharing audio using macOS AirPlay 2 extends its support to mac OS 10.13 as well. It ensures the transfer of music or podcasts to multiple speakers from your Mac. Apple AirPlay 2 with Apple TV Once upgraded to tvOS 11, Apple TV can send audio to speakers around the wide range, rather than just coming from nearby iPhone or iPad. Furthermore, devices like sound bar or speakers, that are connected to the Apple TV would automatically become a de facto AirPlay 2 speaker. – Poorvitha, iOS Development Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-10-05"},
{"website": "Mallow-Tech", "title": "Important Android O Features that developers must Consider", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/10/important-android-o-features-that-developers-must-consider/", "abstract": "Finally, the Android O has been fully baked and rolled out for Google Devices. Google, at the launching ceremony, told that other handsets will also get the new Android O update by the end of this year. Android Oreo is a comprehensive version of Android as there has ever been and it is stable, functional and feature-rich. There are more than tons of Android O features such as integrated instant apps, instant boc time, auto fill, picture-in-picture, Google play protect and more. This makes it as the most powerful Android OS till date. Now, we are going to see the new Android O features that will make huge impact on the android app development process and will also contribute in making the app smooth and efficient New Autofill FrameWork With the new autofill framework, there will be a reduction in app developer’s time consumption. This feature will manage the app’s password with the Android operating system so that the users can access them easily and just like we do with a thirty-party keyboard. It is hard to type all information such as email ids, username, password and address over and over again across the different apps. But now, this feature in Android O makes it easier by allowing the operating system to auto-fill the user information. Developers can register their app as an auto-fill provider with the system to seamlessly log the user in. It saves the android developer’s time, effort and the developer can also develop the app more efficiently. Splash Screen API There are multiple ways to develop a splash screen in Android OS. And the most common among all approaches is in which, a drawable, a custom theme, and a SplashActivity is used. Now in the new Android Oreo, Google has standardised the entire process by letting the developers take advantage of this new API. In the Android Oreo, Google has made the process of developing a splash screen easier task. The new Splash screen API allows the developers to set a drawable resource or images as an app loading screen. This API will also make it easy for them to set a splash screen in between activities of your android app. Background Limits An Android app running in the background consumes the smartphone’s RAM. This results in inefficient user experience, especially when the user is running a high resource consuming app like streaming a high-quality video or playing a high-definition game. To improve the user experience and app performance, Google has imposed limitations on background functional activities of the app. Before the new Android Oreo, developers were able to develop an Android app that listens to a range of system broadcasts. And whenever these broadcasts receive or occur, applications wake-up and impact on the system performance. However, in Android Oreo, this is not going to happen. Now the developers have to use specific receivers and job scheduler to ensure that app running in the background wake up effectively to do its task. Besides this, Android O also knows which apps are running background services and are not connected to what user doing on the device. For example, for the News Feeds there is no need to refresh its feed in the background stage. Notifications Android Oreo brings three major changes in Notifications. 1)  There are extra actions for notification shade. 2)  There are new notification dots. 3)  Android Oreo adds notification channels, which is a unified system to help the users to manage their notifications. The notification shade has a number of performance improvements, visual changes, and practical. On the visual side, the media controls have been given a new colour tweak. Before Android Oreo, the media controls in the notification shade displayed the album cover image. With Android Oreo, the background of media control will change its colour according to the album artwork. However, besides these general changes, notification has always been the most important feature for app developers as well as marketers. In the new notifications feature, the user can see channels as categories. These channels are planned to represent different categories of notification that an app can send. For example, A Hotel/restaurant app can have different types of notifications such as promotions as well as important updates of a booking. Here, the developer can make the promotions in the hotel app as a promotion channel, and hotel booking related notifications as an update channel. Apart from this, developers can also enable users to set a timeout on notifications or snooze them so that they can take a look at it later. – Saravanakumar B, Android Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-10-03"},
{"website": "Mallow-Tech", "title": "What’s new in iPhone X – A features overview", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/09/whats-new-in-iphone-x-a-features-overview/", "abstract": "The all-new iPhone X enables new user experiences from unlocking your phone with the new Face ID to playing AR games and sharing Animoji in messages. In this post we will see in detail about various features of iPhone X. Design: – It has an all screen display that follows the curve of the device to rounded corners. – Apple claims that all glass (front and back) feature is the most durable glass ever in any smartphone. Super Retina Display: – The HDR (High Dynamic Range) display supports Dolby vision and HDR10 which include True Tone which means it can dynamically white balance the display to match the surrounding environment for a more natural viewing experience. – iOS 11 is redesigned to take the full advantage of the super retina display and it replaces the home button. Users can now simply swipe up from the bottom to go home from anywhere. Face ID, a new System to Unlock: – Apple claims to have revolutionised authentication system with the new iPhone X, by using True Depth Camera system made up of dot projector, infrared camera and flood illuminator. – These features are powered by the A11 Bionic chip, which maps and recognises a face. – Apple’s Face ID projects more than 30,000 invisible IR dots. The IR image and dot pattern are pushed through neural networks to create a mathematical model of your face and send the data to the secure enclave to confirm a match while adapting to physical changes in appearance over time. – Regarding its security, it is protected by the secure enclave to keep data secure, while all the processing is done on-device and not in the cloud to protect user privacy. – Face ID only unlocks iPhone X when customers look at it and are designed to prevent spoofing by photos or masks. Augmented Reality Experiences: – The cameras on iPhone X is customised for AR experiences. With ARKit, iOS developers can take advantage of the TrueDepth camera and rear cameras to create games and apps which offers immersive and fluidic experiences that go far beyond the screen. – The new camera also delivers better video stabilisation, 4K video up to 60fps and 1080p slo-mo up to 240fps. The Apple-designed video encoder provides real-time image and motion analysis for optimal quality video. Animoji – a dynamic form of Emojis: – The TrueDepth camera brings emoji to life in a way that Apple calls it “Animoji”. Working with A11 Bionic, the TrueDepth camera captures and analyses various facial muscle movements, then animates those expressions in a dozen different Animoji characters, including a panda, unicorn and more A11 Bionic chip: – Apple introduced the new A11 Bionic chip which features a six-core CPU design with two performance cores that are claimed to be 25% faster than previous models of iPhone. And four efficiency core that is claimed to be 70% faster than previous A10 Fusion chip. – Apple also noted that the new A11 Bionic neural engine has a dual-core design and performs up to 600 billion operations per second for processing. This is designed specifically for machine learning algorithms and enables Face ID, Animoji and other features. Wireless Charging: – The glass back design enables a wireless charging solution. Apple gave a sneak peek of AirPower, an Apple-designed wireless charging accessory coming in 2018, which offers an active charging area that will allow iPhone 8, iPhone 8 Plus or iPhone X customers to simultaneously charge up to three devices, including Apple Watch Series 3 and a new optional wireless charging case for AirPods. What new for developers – Length of the screen is increased by 20% so the aspect ratio has to be changed. – Have to avoid explicitly placing interactive controls like a call for action buttons at the very bottom or any corner of the screen. – Since people will use swipe gesture at the bottom edge to access the home screen, these gestures may cancel custom actions implemented in these areas. – Also, controls placed in the far corners of the screen would be difficult for the user to reach in. – Don’t attempt to hide the device’s rounded corners, sensor housing (the notch) by placing the black bar in top or bottom of the screen. Thus we have seen an overview of the features of the all-new iPhone X. Also, we have seen a brief not the points to ponder by the developers due to the changes introduced. We will see you in another interesting topic in upcoming weeks. PS: Image credits – Appleinsider.com, expertreviews.co.uk – Rajtharan G, iOS Team , Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-09-21"},
{"website": "Mallow-Tech", "title": "Apple’s September 2017 special event Round up", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/09/apples-september-2017-special-event-round-up/", "abstract": "Yesterday Apple has announced their brand new products in all platforms and this is the first-ever event at the Steve Jobs Theatre. They gave 5 big updates in this event, Watch series 3 Now you have apple watch series 3 with built in cellular. Watch series 3 has built in micro SIM and display has built in antenna to use cellular in Apple Watch series. You can stay connected to your families and friends with watch series 3 without iPhone near to you. You can listen to 40 million songs from iTunes right on your wrist. Watch series 3 runs on watchOS 4, which have a lot of updates and features in it. Now it will work 70% faster than previous watch series. The heart of the watch series 3 is redesigned W2 chip with Dual core. Like the previous series, watch series 3 too is swim proof. It can stand up to 18 hours of battery life. It costs from 329$. Last year Apple Watch ranked number two for worlds best watch, but no more, because now it is moved to number one. Please have look at below video, “https://www.apple.com/apple-watch-series-3/ ” Apple TV 4K The new Apple TV will support 4K contents, Apple TV 4K lets you watch movies and shows in the amazing 4K HDR quality. Offers great content from apps like Netflix, Hulu, and ESPN. And streams live sports and news. It runs on A10X fusion chip with 64-bit architecture. A10X is 2X time CPU and 4X times GPU performance than the previous version of Apple TV. With this A10X fusion chip, we can enjoy richer, more interactive games and apps. Apple TV now supports live sports to get live scores of sports event and we have much more in new Apple TV 4K. Please have look at below video, “ https://www.apple.com/apple-tv-4k/ “ iPhone 8 and 8+ This year apple comes up with all new glass design in its new iPhone 8 and 8+, with an improved camera than iPhone 7 and 7+. iPhone 8 & 8+ have the most advanced chip in the smart phone called A11 Bionic. A11 Bionic is a 64-bit architecture, 6 core processor with 4.3 Billion transistors in it.  The brand new A11 Bionic has 4 efficiency cores for providing 70 % faster performance than A10 chip and it has 2 performance core to give up to 25% faster performance than A10 chip. iPhone 8 also has a redesigned 3 Core GPU which is up to 30% faster than A10 fusion chip. The brand new iPhone 8 & 8+ gives greater way for Augmented Reality(AR), the developers can make use of A11 Bionic with ARKit to develop greater AR apps. The glass formed design in front and back allows iPhone 8 & 8+ to charge wirelessly. It has Retina HD display with TrueTone, which gives you a wide color gamut and 3D Touch. With TrueTone technology, its display automatically adjusts white balance based on light around you. The portrait mode photo got new improvements in new iPhone 8+. Apple introduces Portrait lighting in camera app to create dramatic studio lighting effects in Portrait mode. iPhone 8 and 8+ available in 64 and 256GB variant and it has new space gray, silver and gold finishes. iPhone 8 costs from 699$ and iPhone 8+ cost from 799$. AirPower Apple has given a sneak peek into its new way of charging wirelessly named AirPower . This is capable of charging iPhone, Apple Watch, EarPods and its case at the same time. We can expect AirPower in next year. These are the great products apple have released in yesterday’s event, surely these products will take you to the next generation of Smart Phone, Smart Watch, and Smart TV experiences. Hey, wait… Did I miss something? Yes, it’s the….Brand new…wait before we get started I suggest you take look at this video. “ https://www.apple.com/iphone-x/ ” iPhone X(Pronounced iPhone 10). This brand new beast has the edge to edge 5.8 inch super Retina display. The display employs new techniques and technology to precisely follow the curves of the design, all the way to the elegantly rounded corners. iPhone X have first OLED screen that rises to the standards of iPhone, with accurate, stunning colors, true blacks, high brightness, and a 1,000,000 to 1 contrast ratio. Instead of pressing the home button, you have to swipe up to get the home of your iPhone. FaceID – It has TrueDepth camera to provide you a new way of unlocking your iPhone X called Face ID . We know that there is no perfect system, the possibilities of cracking a Touch ID is 1 in 50,000 attempts, but for Face ID it is 1 in 1,000,000(1 Million)attempts. The TrueDepth camera projects and analyzes more than 30,000 invisible dots to create a precise depth map of your face. Say bye bye to Touch ID and home button in iPhone X. Animoji – Apple moved to next step of emoji is called as Animoji. The TrueDepth camera analyzes more than 50 different muscle movements to mirror your expressions in 12 Animoji. Reveal your inner panda, pig, or robot(Haha). Camera – With portrait lighting and Dual OIS (Optical image stabilization) the photography in iPhone X is brilliant than ever. Neural engine – A11 Bionic chip has build in a neural network which is called as a Neural engine. It has the capability of performing up to 600 billion operations per second, Face ID will make use of it to unlock your iPhone as faster as possible. Rate – Like always it’s never going to be a cheaper one. New iPhone X will cost from $999. These are the small sneak peak about the new products that apple have released in yesterday event. We can See what’s news in iOS 11, tvOS 11 and watchOS 4 in future blogs. – Karthick S iOS Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-09-13"},
{"website": "Mallow-Tech", "title": "Importance of Manual Testing in Mobile Devices", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/09/importance-of-manual-testing-in-mobile-devices/", "abstract": "Manual is not a very favorite term for many in the Software Industry. Yet, Manual testing plays an important role in software testing even for a company which has automated most of its tasks successfully. In this post, we will discuss the importance of manual testing and how to perform it on mobile. Manual Tests on Mobile And why? Automated tests can enhance the most the required software for testing, but manual testing is mainly used by QA teams to fill the gaps, check the quality and ensure whether the final products behave well as per the end user actually use an application. In Mobile testing, manual testing often answers questions like: Whether all the design elements are arranged properly in a comfortable way? Whether it is easy to touch the elements with one finger? Whether it is easy to use all the option by one hand of the user? By doing manual testing with real users, you can easily identify and measure the functionality and user interaction of the mobile application. And can easily make a note on the challenges faced while testing each application. To Perform Manual Testing on Mobile Devices Effectively: To perform manual tests, initially, the tests should be organized and standardized. These tests can be then repeated in any of the devices without any changes in the flow. And it is easy to reproduce the bugs and errors again whenever necessary. Organizing test will save time and it will improve the quality of the product. Without organizing the test, you will find something wrong and will miss out major bugs and time will also be wasted. Test Plan: Planning before doing any thing is a must. Planning makes the activity much more efficient. The first step before the test is to prepare a test plan, which helps you in many situations when you are stuck. And it also consumes much more time. Test: After preparing the test plan, run the plan and you have to test everything in the plan. Then make a note on the steps you have followed to avoid confusion of when to test it again. Try to reproduce the errors when it occurs and also try to find the root cause of each and every error. Log the Errors: Logging the error is much more important than testing. The error should be logged with a proper tool and which should be easily understood by the developers and bug fixers so that this can be easily reproduced. Error logging also helps to maintain the error history and makes it easy to test them again and again. Repeat the Testing: You have to repeat the testing every time when the code is changed or any improvement is done in the app and recorded the testing and assure whether the error rate is reduced compared with the previous phase of testing. Test in Various Devices and software: You have to test the same application and test plan in various devices because UI might differ across devices. Also, you have to test it with various software versions because there are differences in screen size and resolutions. These responsive testing can be done only through manual testing. In Automation we unable to cover all the functionalities and features and all the types of testing. It’s wise to test it in manual testing mode. Accessibility and usability testing can be done only through manual testing. Kindly follow above steps to improve the standard of manual testing for mobile application and stay focused while testing to become a good manual tester. Thus, we have seen how to do and improve the mobile manual testing in this blog. – Kumaresan T, Testing Team , Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-09-12"},
{"website": "Mallow-Tech", "title": "Commonly used communication patterns in iOS", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/09/commonly-used-communication-patterns-in-ios/", "abstract": "In this blog, we are going to see in detail about the commonly used Communication patterns in iOS. Communication patterns play a major role in the application development. It is essential to know the best practices and the appropriate time to use each pattern. We will see how each pattern works in detail. Communication patterns in iOS: The three communication patterns which are going to see here are, Delegation Notification Closures/Blocks For those who are new to the term communication patterns, here is a short explanation about them which will give you an understanding of what those are. Delegate: A delegate is an object that acts on behalf of, or in coordination with, another object when that object encounters an event in a program. -Apple Notification: A notification is a message sent to one or more observing objects to inform them of an event in a program. -Apple Closures/Blocks: Closures are self-contained blocks of functionality that can be passed around and used in your code -Apple I hope you would have got some idea what each one is if not no problem we will discuss about each one below, in brief, to better understand how each one works. How each one works: Delegate: Apart from the definition given above, Delegate is most commonly used pattern in most of the Apple frameworks for example like table view, collection view,.. and so on. It helps in notifying about certain events which have been occurred or completed or called. In order to implement complete delegation pattern, we must have two main things namely Sender & Recipient /s Sender: A sender is the one who declares what are all the delegate methods it supports. ie., we can add one or many methods as delegate methods. Recipient /s: Recipients are the one who confirms to those senders, and as the result of confirmation to those senders the recipient will have to support/add all or some(in case if the delegate methods are optionally declared by the sender) those delegate methods in their class. Here to make this delegation works the sender has to notify the recipients using its delegate object whenever the dedicated action has been completed or started or what so ever the state when we want the delegate methods to be performed on the recipients. Once the sender calls the delegate methods using the delegate, the recipients (one or many) who have currently assigned themselves as the delegate will be called and the recipient can perform their action as per their need. Few important points regarding delegates: Can make use of two-way communication. But mostly we tend to use one-way communication. We can pass objects(also custom objects) using delegates in the form or arguments to the delegate methods. Delegates produce tight coupling between objects, i.e, the delegating object has a direct reference to its delegate. So It’s easy to trace and identify the flow & control of delegate usage within the app. Notification: Notification communication pattern follows the broadcast model. This way is also used in most of the Apple framework. In order to implement notification, we again have the following components involved, Sender & Receiver(Observer). Here, The notification communication works with the help of NSNotificationCenter which is a singleton, all the notification is processed throughout this central mechanism. Before explaining further, to make it, even more, easier for understanding, think how an “FM Radio” works. I will explain the above items with the help of FM Radio. Sender: Think sender as the FM Station, the work of an FM Station is to host or broadcast the program in a certain frequency. Likewise here the sender object will send/post a notification to the NSNotificationCenter which is like the FM Station who’s work is to broadcast the incoming notification. Recipient: Think recipients as the subscribers are the listeners of the radio channel(to a specific frequency, likewise wherever we need to be notified of an event in those recipient class we have to add observers for those particular notification type. This will be registered in the NSNotificationCenter as well. So whenever a sender posts a notification, the recipient will observer will be called and we can perform our actions accordingly as per the need. Few important points regarding Notifications: By default, notifications are delivered synchronously, but we can also post notification asynchronously using NSNotificationQueue. It’s acts as one way communication only. Cannot able to pass custom objects using notification, instead, we could add the required object inside the user info object that comes along with the notification object. Notifications produce loose coupling between objects, i.e, the sender doesn’t know what are all the receivers are listening to it. Closure: Closures / Blocks is an alternative to the delegation, It generally consists of small sets of code combined together and it can also be passed as arguments between methods. Closures takes multiple forms and each one handles data as follows, Global functions: It has a name and doesn’t capture any values. Nested functions: It has a name and capture values. Closure expressions: Its unnamed with lightweight syntax and capture values from surrounding context. As of now you don’t need to worry about their types or what capturing values ( Capturing Values ) means since doesn’t interfere with how it works here. Closures are functions with no function names and a function keyword. It is mostly recommended to use because of its simplicity of its syntax. The most used cases of blocks are, Completion blocks: When you have a time-consuming task and you want to be notified when that particular task gets completed. Higher order functions : We can use closures as input parameters for higher order functions like filtering, etc,. One advantage of using closure is that we don’t need to handle memory management, the os will take care of itself. Best practice, when to use Delegate & Notification: There is no right or wrong answer on where to use each one of the above ways, this option depends based on your need, here I as far my experience I will share you on what cases you shall choose what kind of option to go with, Delegate: In situations when you want the receiver class to perform all the actions mandatorily. If one object needs to talk/communicate with another. I.e., If you want strong coupling/reference between the sender and receiver and so it’s easier for debugging compared to Notification. If you don’t want any fraction of time delay on passing the data you can go with delegate since sometimes there is a fraction(very minute) of time delay on using Notification. Notification: When you want to notify any class(multiple receivers) when certain actions occur on any part of the application. If you are about to use multiple listeners without the need of strong coupling/reference between each other. When you don’t want to expose any details to the receiver, notification is preferable. When you don’t care who are the receivers are. My personal suggestion to use notification lesser as possible, it’s not that using notification is wrong, it’s not better suited for debugging purpose. Closure: For simple functions which have lesser lines of code. If a delegate has only one function & it has only small sets of codes as in the above point we can choose to use Closure over/instead of Delegate. When you need to perform any task and want the result at any time based on the result computed or fetched like network calls. In this post, we have seen the commonly used communication patterns namely Delegate, notification and closure in detail. We also saw how the process works and appropriate time of usage. This will give you an insight into these patterns. Bharath R, iOS development Team, Mallow Technologies . Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-09-07"},
{"website": "Mallow-Tech", "title": "How to deploy a WordPress website with amazon RDS Database to Elastic Beanstalk", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/09/how-to-deploy-a-wordpress-website-with-amazon-rds-database-to-elastic-beanstalk/", "abstract": "Deploying a WordPress website with Amazon RDS Database to elastic beanstalk involves the following step. Let us see in detail about the steps to configure and deploy the same. Downloading WordPress Launching a DB instance in Amazon RDS Launching an Elastic Beanstalk environment Configuring the security groups and Environment properties Installing the WordPress Configuring the auto-scaling property Download WordPress: Download the latest version of WordPress from https://wordpress.org/ into your local machine for installing the WordPress to the Elastic Beanstalk environment. Download the configuration files in the following repository: https://github.com/awslabs/eb-php-wordpress/releases/download/v1.0/eb-php-wordpress-v1.zip. Configure your default VPC and subnet IDs from the Amazon VPC console. Launching the DB instance in Amazon RDS: Separate DB instance is required for the WordPress storage. Choose the type of DB instance accordingly ( e.g: MySQL). While launching the DB instance make sure that the cost of DB instance is affordable according to your project. This instance is not monitored by the Elastic Beanstalk. Configure the DB instance and launch. Multi-AZ deployment will increase your cost but it also increases the availability. Your estimated monthly cost is displayed on the left side of the page. Launching an Elastic Beanstalk environment: Choose the PHP as the platform and upload the downloaded WordPress code in zip format. Configure the Elastic Beanstalk and launch. Environment creation takes about 5 minutes. Launching an environment creates the following resources: EC2 instance Instance security group Load balancer Load balancer security group Auto Scaling group Amazon S3 bucket Amazon CloudWatch alarms AWS CloudFormation stack Domain name Configuring the security groups and Environment properties: For EC2 security groups, type a comma after the name of the auto-generated security group followed by the name of the RDS DB instance’s security group. Configure environment properties for the Launched RDS DB instance: RDS_HOSTNAME – The hostname of the DB instance. Amazon RDS console label – Endpoint is the hostname. RDS_PORT – The port on which the DB instance accepts connections. The default value varies between DB engines. Amazon RDS console label – Port RDS_DB_NAME – The database name, ebdb. Amazon RDS console label – DB Name RDS_USERNAME – The user name that you configured for your database. Amazon RDS console label – Username RDS_PASSWORD – The password that you configured for your database. Install the WordPress: Open Elastic Beanstalk console and Choose the environment URL to open your site in a browser. If you succeeded, you will be redirected to a WordPress installation wizard, which looks like above image because the site has not been configured yet. Choose the language and continue the installation where you have to register and install WordPress. Configuring the auto-scaling property: In the scaling section of Elastic Beanstalk console, configure the minimum instance and maximum instance count. If the load is increased load balancer will automatically balance the load based on the configuration in the scaling section. Conclusion: We saw in detail about to how to configure a WordPress website with Amazon RDS database to Elastic Beanstalk. This will help you in configuring the site by yourself. Aravind Rajesh Kanna, Front End Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-09-01"},
{"website": "Mallow-Tech", "title": "Introduction to drag and drop in iOS 11", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/08/introduction-to-drag-and-drop-in-ios-11/", "abstract": "What is Drag and Drop? In WWDC 2017 apple has released new API for graphically move/copy data from one place to another which is called as Drag and Drop. Goals: Apple have following things as goals of drag and drop to provide great user experience when user moving/copying data using drag and drop, • Responsiveness • Security • Great multi-touch experience Responsiveness: The entire operation will be performed asynchronously and based on demand from destination app. Since the entire process is performing asynchronously the main block won’t get the block, a user can continue to do interact with the app. Security: There won’t be any security risk at when we are dealing with confidential data, OS will handle everything from the security point of view. Source app can restrict dragged data like it only visible to other apps which are developed by same developer or all apps in the system. Great multi-touch experience: Apple fully utilized their multi touch feature in drag and drop, a user can do multi-touch to select multiple data once they picked up the first one. The interface for drag and drop is very live and it will give great visual feedback when the user activates drag action and drop action. When dragging the data from one app to another user can hover destination app icon to navigate into it and they can navigate to the place where they want to drop their data. In addition to this user can change the drag action between their fingers and even between their hands for easy use. Concepts: • From iOS 11 we can drag and drop the contents from on screen location to another using the continuous gesture. We can use drag and drop between different screens in the same app and between apps too. • In iPad, we can use the full functionality of drag and drop feature in iOS 11. In iPhone, we can use only within apps. • The app where the drag initiating is called as source app . • The app where the drop action takes place is called destination app . • In iPhone the single app play as both source and destination app role, in which drag and drop action perform. • The complete action from start to finish action is called drag activity . • The system manages an object with the items dragging is called as drag session . • When the drag action is performing between the apps, the source and destination apps will work as usual until its time came to act for drag and drop action. The user interaction also enabled for both source and destination apps. So a user can invoke drag and drop activity, return to home screen, open the second app in split view and the user can initiate another drag and drop action. • Unlike macOS, iOS can drag and drop multiple contents in a single drag and drop action. For this user have to select multiple contents from single drag from source app and the destination app can handle multiple contents from single drop action. Drag and drop use the power of multi touch to drag and drop the multiple contents. • Spring loading: With spring loading, you can use drag and drop feature to open the destination app and navigation a to place where you want to place the dragged contents. • Text view and text field offers default drag and drop functionality. The collection view and table view offers view specific methods and property for handling drag and drop in it. • Text view also offers apis for handling custom view drag and drop action. • The beauty of dragging and dropping between apps in iOS is we don’t need to do code signing, configure entitlements and info.plist. The system will handle everything for us from security aspects. • We need to register Uniform type identifiers(UTI)  in our app for accepting different content types for dropping action and providing different documents from source app, just like importing contents to our app. • The app which allows for drag action should implement UIDragInteractionDelegate methods and the app which allowing for drop action should implement UIDropInteractionDelegate methods. • The drag and drop can be integrated throughout the iOS and it can be used in following places Home screen, Dock, Reminders, Calendar, Message, Spotlight, Files, Safari, Contacts, iBooks, News, Notes, Photos, Maps, Keynotes, Pages and Numbers • The below image will explain the roadmap of the drag and drop api. API Roadmap These are some of the basic things about drag and drop features in iOS 11. We can see more details about drag and drop in our future posts. – Karthick S, iOS Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-08-24"},
{"website": "Mallow-Tech", "title": "6 Things to consider before Deploying your web or mobile app", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/08/6-things-to-consider-before-deploying-your-web-or-mobile-app/", "abstract": "In this post, we are going to see 6 points to be tested and taken care before deploying a mobile or web application. These points decide the success or failure of the app in a way. 1.Reality check: Checking how UI looks at the Developer’s environment differs from that of the user’s environment. Checking how the UI looks at various lights has to be checked. If it’s a web application then the developer might have been using Mac and they have to ensure it gives perfect experience for the Windows system too. Checking the application by putting oneself in the user’s shoes gives a different perspective and the final product will be more relatable and comfortable to the user. Are the features perfectly helping the target users? Satisfying the target users is the primary task of an application. 2.UX with regard to the usage: If you are creating an enterprise app or app to increase the productivity then you should be sure of keeping the controls restricted to the keyboards. They should be able to change the categories and to navigate over columns with keyboard itself. Using a mouse to select and move will reduce the efficiency of the user and results in the failure of digitisation. 3.Device Check: If you are designing an application for iOS then you need to be specific about the form factors and the devices in which it will be used. Ensure that the app gives the same experience in all devices. This becomes tough for Android as there are huge number of devices. To make it better for the users ensure that you comply the standards set for each platforms and customise in a way that it never fails to give the perfect User Experience. 4.Third Party dependency: Third party dependency is fine as far as you are in control. Third party services for limiting API request can be done. But you have to ensure that the traffic fluctuation regularly and the crash and bugs has be to fixed regularly. If these are perfected, when it hits the market you get better results. 5.Update Frequently: It is good to update each feature by giving some time for the user to experience. Only then you can understand how the user reacts to a particular feature and get feedbacks of the same. Crash, bug and error monitoring has to be done frequently before the updates. 6.Analyse similar apps: If you are working on an e-commerce app, then analyse the top e-commerce apps and check the issues they are facing from the user point of view. Incorporate the changes in your app and make it a holistic product. These are the six factors which can avoid your product from failing in the market. – Yogesh M, iOS Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-08-10"},
{"website": "Mallow-Tech", "title": "Google Glass – A Game changer in Enterprise mobile apps?", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/08/google-glass-a-game-changer-in-enterprise-mobile-apps/", "abstract": "Recently Google has announced that its highly ridiculed Google Glass will be back soon and it is ready for the Industry. After facing huge criticisms for privacy concerns and a higher price tag made Google stop the product. After two years of dormancy, the Google Glasses will now be available in the market as an enterprise edition. Initially planned as a consumer product, Google Glass was released in the year 2015. Google Glass is basically a framed glasses in which the lens are replaced by the Head up display. It has a touch pad on the side which helps you control the device. The Glass allows you to take pictures and record 720p videos. Many third party apps such as twitter, facebook apart from the Google apps were available to access in the product. Another big advantage of the product was the voice controlled commands. As exciting this may sound, there were a lot of hitches and privacy concern crept up which led to the dormancy of the product. Also as many felt that this product had more enterprise usage than that of the consumer usage. After stopping the product at 2015, Google glass underwent a major experimentation. With insights and partnerships from the industries, Google glass was perfected for the Enterprise. Below is the video of Google Glass being used in Boeing. With customising the glass for enterprise has enriched the usage of the product and also have opened up the possibilities for Enterprise App development on Glass OS platform. Glass OS is an Android OS optimised for the Google Glass. As we have already mentioned the Augmented Reality as the future of mobile application development. At Mallow Technologies we have extensively worked with geo-location based apps. Working with Glass OS to make a customised application for an industry will be the new challenge to all app development companies. For that, the companies who have the domain authority regarding a particular industry or technology will dominate the future. – Saravanakumar B, Android Team, Mallow Technologies . Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-08-03"},
{"website": "Mallow-Tech", "title": "What’s new in iOS 11 Location Technologies", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/07/whats-new-in-ios-11-location-technologies/", "abstract": "Accessing location is an important feature in many of the applications. The developer has to decide the way of accessing the location. The ways to access location has been changed in the recent iOS 11 updates. Let us see in detail about the ways of accessing the location before and after the update. iOS 10 and before Two ways of accessing location: 1. “While Using” access 2. “Always” access 1. “While using” access “While using” access is used by the developers to access location information when the app is currently active and in the foreground. There may be a case where the app needs to track location when the app is in the background, but still the “While using” access would be sufficient. In this case, a blue bar is indicated below the status bar that your location is being tracked by the app. NSLocationWhenInUseUsageDescription key is used in Info.plist file for describing why the app needs access to the location. In location permission setting, there will be options “Never” and “Always” 2. “Always” access “Always” access is used by the developers for apps that need to track your location even when your app is not active. API’s like significant change API which notifies when the user moves to a specific distance and region monitoring API that notifies when the user moves or leaves a specific position. NSLocationAlwaysUsageDescription key is used in Info.plist file for describing why the app needs always access. In location permission setting, there will be “Never”, “While using the app” and “Always” From iOS 11: There is no major change for those apps that use the above said “While using” access. According to Apple, 21% of the Apps use “Always” access. These apps have to consider the changes made to work perfectly. When developing apps for iOS 11, you should provide NSLocationWhenInUseUsageDescription irrespective of the type of permission you ask. If you are in need of “Always” access, then you should provide additionally NSLocationAlwaysandWhenInUseUsageDescription key in info.plist. So from now, the description should contain what features would be available in respective modes to the user. Note: – However, the “ NSLocationAlwaysUsageDescription ” is needed for supporting backwards compatibility for iOS 10 and below versions. Three ways of accessing location: 1. “While Using” access 2. “Always” access 3. “While Using” access first and then “Always” access 1. “While Using” access It would work the same way as before. 2. “Always” access Now in this case, previously the user would be prompted with either “Allow” or “Don’t allow”. But from iOS 11, you will see “Allow”, “Don’t allow” and “Only while using the App”. 3. “While Using” access first and then “Always” access This is the recommended approach from Apple for iOS 11 apps. It is also called as “two phased” approach. When you first ask for “While using”, it will prompt with “Allow” and “Don’t allow”. Most users would give this a thumbs up and you can use this permission for giving the user a basic user experience. After a while, when you feel “Always” access is mandatory, then you can now ask for “Always” permission. But now the prompt would contain “Always allow” and “Only While using the app”. Note that this prompt does not have “Don’t Allow” option as the permission has been already given in the first step itself. The blue bar of location status Before iOS11, you would get blue bar below the status bar indicating that the app currently using your location.  But this would be shown for apps that have “When in use” access in the background. From iOS 11, this bar would be shown irrespective of what type of permission you get from the user when the location is tracked from the background using precise tracking API. However, it will not be shown for apps that use less precision API like significant change or region monitoring API. So, it is recommended that you call location API only needed and decrease the frequency of calling precise tracking API as much as possible. The tracking Arrow Before iOS 11, the tracking arrow that appears on the top right of home screen would be filled or hollow based on which location service is being used. But Apple felt that it was unfair. Because consider two apps, the first app which tracks location continuously would be shown by a solid filled arrow. And another app which uses significant change API would also result in solid arrow even though it has been called the API only a few times compared to the previous case. From iOS 11, when app request location, there would be a hollow arrow. Then when the app actually receives location data, the arrow gets filled for few seconds, which on trial is approximately 10 seconds. In this way, many apps may display solid arrow very often. Thus, we have seen the different ways of accessing the location in iOS 10 and iOS 11. The changes brought in the iOS 11 helps in making the app experience better. – Rajtharan G, iOS Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-07-27"},
{"website": "Mallow-Tech", "title": "How to avoid Cross site request forgery (CSRF) attack?", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/07/how-to-avoid-cross-site-request-forgery-csrf-attack/", "abstract": "What is CSRF? CSRF stands for C ross Site Request Forgery . It’s also known as session riding or XSRF. It is a process of hacking the data from a site through another site without the user’s knowledge. CSRF will be used to perform actions of the attackers using the session of the website which is used by the victim. Normally when the user is logged into the website, a session will be created. Let us consider that user wants to log in into his banking application and parallelly he is also using the attacker’s website named xyz.com. So when the user is logged in, the attacker will send some auto submitting forms to the target site. Let us see in detail with an example. Currently, the user is in attackers site named xyz.com/csrf.html and there is a hidden auto submitting a form in the page which will submit the request to the banking website. &lt;html&gt;\r\n</span><span class=\"s1\">&lt;body onload=“document.frames[0].submit()”&gt;\r\n</span><span class=\"s1\"><span class=\"Apple-converted-space\">    </span>&lt;form action = “<a href=\"http://sssbank.com/action.html\"><span class=\"s2\"><b>http://sssbank.com/action.html</b></span></a>\" method=“post”&gt;\r\n</span>&lt;input name1=“send_money” value=“10000”&gt;\r\n&lt;input name2=“A/c number” value=“01333243242432345465”&gt;\r\n<span class=\"s1\">&lt;/form&gt;\r\n</span><span class=\"s1\">&lt;/body&gt;\r\n</span><span class=\"s1\">&lt;/html&gt;</span></p>\r\n<p class=\"p1\"> The attacker will hide this form in the iframe as &lt;iframe width=“0” height=“0” style=“visibility:hidden;” src=“<a href=\"http://xyz.com/csrf.html\"><span class=\"s2\">http://xyz.com/csrf.html</span></a>\"&gt; So now he can put this iframe in any of his websites and on loading the page which contains this iframe will make us to auto submit the form to the banking application and the action will be successful if the user is logged into the banking application. Phishing: The easiest way to exploit CSRF from a technical point of view is to have complete control over the CSRF site. Then convince your victim to visit the site. Phishing is done for both large-scale and targeted attacks. For targeted attacks, phishing is even more effective. Intranet and administrative systems are excellent CSRF targets, and an attacker can tailor his or her phishing emails for those targets. For example, if attacking an intranet, phishers can send an email purporting to be from a corporate training partner or insurance provider. If attacking a blog, phishers can email the maintainer of a cool site. If attacking a helpdesk system, phishers can email support about a problem with the site. The victim needn’t perform any actions on the CSRF site—merely visiting the site is enough. How to Protect Our Websites from CSRF Attack: We can’t protect our websites from the CSRF attack by adding the confirmation screens for the sensitive actions. Attackers can bypass the confirmation screens, the better way to avoid it is to add another type of validation like sending the OTP’s etc., For changing the password the user should be asked to enter his/her current password so that the attacker cannot change the password by merely submitting the form that contains the new password. Generating Nonce: The Nonce is a unique token which will be generated before submitting the form and the nonce will be validated after submitting the form. Many web development languages have the support to generate the nonce. For example, rails will automatically avoid CSRF by generating the authorization token for every form. Using CAPTCHAs: Another way to avoid CSRF is by asking the user to enter the randomly generated CAPTCHA so that the attacker cannot know the CAPTCHA generated and he will end up with a failure. Using Token Based Authentication: Instead of using the sessions for authorization the web developer can use the token based authentication where the tokens will be verified on each and every request. e.g.: JWT(JSON Web Tokens) How users can protect themselves from CSRF Attack 1. Logging Out whenever not needed: CSRF requires the user to be logged in to perform the attack. So by logging out from the website whenever it’s not required will secure you from the CSRF attack. 2. Changing Default Passwords: Most Attackers will perform the CSRF attack using the default password provided by the websites. The default passwords will remain same for all the users until the user changes it. 3. Using different Browsers: Most CSRF targets require the victim to have an active session on the website in order for the attack to work. One way users can protect themselves from CSRF attacks is to use one browser for browsing sensitive, trusted sites and another for general browsing. For instance, a corporate user might use Microsoft Internet Explorer to browse his/her corporate intranet, and Firefox to browse the Internet. Conclusion Cross-site request forgery is a subtle attack technique that can be extremely toxic. In some cases (such as attacks against a user management system that allow an attacker to create administrative users), it can lead to the complete compromise of a web-based system. So it is essential for the developers to develop their website and applications keeping it in mind. We at Mallow Technologies, keep these security measures in mind before creating a web application. – Sairam Reddy, ROR Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-07-25"},
{"website": "Mallow-Tech", "title": "A glimpse of Rich Communication Services and Android Messages", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/07/a-glimpse-of-rich-communication-services-and-android-messages/", "abstract": "The communication and messaging service market is expanding rapidly. According to a research conducted by Business Intelligence, the SMS mode is declining day by day and the market is swooned by applications like WhatsApp, Messenger, hike etc., The below image shows the revenues made by the wireless carriers on SMS and RCS. Business Insider Research survey The applications such as WhatsApp, snap chat, messenger and so on are not only seen just as a messaging services app but rather a social networking on its own. These apps in a way nearly killed the SMS services of the phone. Apple has already addressed this issue by introducing the iMessage app which serves as the default message app in the iPhones. Android, on the other hand, juggled a lot of various other apps and failed to capture that. At present bringing in RCS which is expanded as Rich Communication Services is the only way to revive the carrier dependent communication. Before delving deeper into it, let us see in detail about what is RCS. RCS is basically an enriched format of SMS and MMS. This supports sending text, images, videos to groups or individual through your Mobile Carrier. This type of messaging helps you in sending enriched texts, can see if the texts are delivered and viewed and so on. Google has announced recently that it has released an app called Android Messages. Android had the messenger app as the default SMS/ messages app which is now reinvented and rebranded as Android Messages. The Android Messages app will be RCS updated in the near future. Android is making it as a default app for the future devices and as it is available in play store also for old devices to install. This assures that the app will get constant updates from Google. This is the third messaging app for the mobile phones from Google. Allo and Hangouts are the other two apps. In the announcement, Google gave the example of airlines that could send a passenger a text to provide a full check-in experience, complete with the boarding pass, visual flight updates and terminal maps on demand. Also, the features like image sharing, location and map sharing come at ease. Also the messaging in groups will also be enriched and customised. Initial partners for RCS Android Messages include Virgin Trains, Walgreens, Amber Alert Europe, Baskin-Robbins, BlaBlaCar and FICO. Gamestop, Philips, Subway, Time Inc., and Uber are among the others. One big issue in here is some of the mobile devices yet to support this technology. Samsung and Apple are few among them. This update might help in bringing back the revenue through communication and messaging to the carriers which were taken away by the third party messaging apps. The release date of the RCS update to the Android Messages app is yet to be announced. Let us wait for the update to see the changes in the industry. – Saravana Kumar B, Android Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-07-20"},
{"website": "Mallow-Tech", "title": "7 Things not to do in an Internship", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/07/7-things-not-to-do-in-an-internship/", "abstract": "An internship is basically an opportunity given to the students to get exposed to the industry. Through an internship, one can apply the knowledge gained in Academia into practical situations. This will give them a proper insight about the industry and application of academic knowledge. The internship can be as full time or part time, any time of the year including over the summer and during the semester. It’s an excellent way to try out a certain career and offer students a hands-on opportunity to work in their desired field that makes them stronger candidates for jobs after graduation. Since the internship plays a vital role in deciding our career path, it is important for us to know “What not to do” during the internship rather than “What to do” things. 7 Things not to do in an Internship: 1. Never Ignore the organisational culture: Learning new skills is important but at the same time, it’s essential to observe the practices followed in the office like working hours, dress code and correspondence of employees. The interns should comply with the work habits that the employer values. 2. Never be incomplete and never miss a deadline Completing the work within the stipulated time is one of the crucial factors is defining your professionalism. That gives you the transformation from a student to a professional. At the same time, what is worst is submitting an incomplete work. If you can’t perfect the assignment within the stipulated time then inform prior rather than submitting your incomplete work. This gives you a very bad impression about your ability. 3. Ask many questions, but not too many An intern’s duty is to learn about the job, gain experience and learn new skills. In order to achieve that it is essential to ask necessary questions. Asking questions also showcase your interest in learning. But think well before asking any question to the person concerned. Think twice if it can be solved on your own or need an expert’s guidance. Ask only if it is absolutely necessary and use those opportunities cleverly. 4. Never be late Keeping up your time should be consistent throughout. Arriving late to the office gives an image that you might not be interested in the job. An internship is an opportunity to showcase your interest in particular field or industry. So it is absolutely essential to be on time for meetings, arriving at the office and so on. Also, it is a quality that is essential in any profession. 5. Never Share Official matters Don’t even think of sharing any information that is related to the organisation in any social media. Taking the official information for granted is not a professional practice. If there is any need to share any information then you need to get prior permission from the authorities before sharing. 6. Never show boredom and tiredness Nobody prefers a person who is disinterested and bored of their job. Not all of the tasks you perform will be equally interesting. Some of the works given to you might not fall in your comfort zone, and some work might take more time. You shouldn’t get bored and disinterested in performing the same rather you should see what can you learn from that task. This shows your enthusiasm towards the work. 7. Never Lose contact Never lose contact once the internship is over. This helps in future in one way or another. You can get a job or you can get a reference to some other from here, you never know. But ensure that your contact is not irritating and hindering them. These form the seven most important what not to do during your as an intern in any organisation. If you are interested in an internship at Mallow Technologies, you can apply for the internship through our contact page. – Harini G K, Marketing Intern, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-07-18"},
{"website": "Mallow-Tech", "title": "Autofill password feature in iOS 11", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/07/autofill-password-feature-in-ios-11/", "abstract": "Problem: We often tend to forget our passwords and so we use some 3rd party password manager to remember. Some time in the process of securing various accounts we tend to keep the password hard as possible with a complex combination which we forget sometimes or make mistake in entering. This may also be a reason for using these apps. History: Apple has already addressed this issue in its Safari web browser which automatically fills the password if we had saved one before for any specific sites. This helps the user not to worry about the password or to maintain it somewhere. Apple itself saves it in user’s iCloud account and using which the user can make use of those passwords wherever or whichever device(iPhone, iPad or Mac) their iCloud is configured with. Solution: Now Apple has brought a similar feature to the third party apps. Apple has introduced password autofill feature from iOS 11 for third party apps also which is somewhat similar to the same feature which already exists in the Safari browser. With this feature now the user can just choose a password and it automatically fills the username and password in its respective places without making the user type it. How to use: 1. Select the field where they want to enter the credentials 2. Select the “Key” icon from the keyboard quicktype bar which lists all the credentials stored in the iCloud account. Or if configured correctly directly choose associated website linked credentials. 3. During the selection process in the above step, the user will be prompted with either Touch ID or Passcode for security reasons. 4. And once chosen any credentials it will automatically be filled in the respective places and the user just needs to select the button to log in. Note* 1. For this feature to work, there must be some credentials available in their “Accounts & Passwords”. 2. You the credentials can be added in two ways, a.) Log into a particular website in Safari and save the password when asked. b.) Add credentials in Settings -> Accounts & Passwords option. How to implement: Before we dive into the implementation process let’s see in how many ways this could be done. 1. Apple automatically enables this features for few apps using some complex Heuristics. Where we no need to handle anything for those apps and it will work by default. 2. Manually configuration. We will cover about the 2nd point which will be useful for developers who wants to implement this feature in their apps. For which we consider creating an application with a login screen which has two text fields(username & password) and one button for login action. Note* 1. It is better to do the manual configuration for the app rather than expecting the heuristics do the work. Steps involved: 1. Make sure to show the quicktype bar appear with key icon in it by doing the following a. Set “textContent” property for your UITextField / UITextView whichever you are using in your case either through storyboard as follows • Choose the Text Field in our case. • Select Attribute inspector. In which change the “content type” property to “username” for username text field and set “password” for password text field. b. You can set the content type in the code as follows. usernameTextField.textContentType = .username passwordTextField.textContentType = .password Just by making the above change the quicktype bar with the key icon will be displayed and from where you can select the key and choose credentials from the list shown. 2. If you want to make the suggestion more specific for example if you are maintaining a site called “ example.com ” and you want to suggest the password belonging to that specific site then this step is for you. For giving particular suggestion in the quicktype bar we have to perform the following steps, In our Xcode project: a. Turn on “Associated Domains” from Project Settings -> Capabilities. b. Add your website URL by clicking the + icon in the following format. For example, you domain name is “ example.com ” then your associated domain name should be prefixed with “webcredentials:” in the following format webcredientials: example.com In our website: Yes, we also need to perform few steps in the associated website also. This process is for security purpose in order to make sure that website is owned by us and for other security reasons. Note* 1. It’s mandatory that the associated site must be “HTTPS”(SSL) site else this won’t work. a. create a file named “apple-app-site-association” and paste the following set of codes which is the standard format used for this purpose. And place the following file in a folder named “.well-known” and place it the folder in your website root directory. Also, make sure when this file is accessed it should return us the JSON response exactly as follows and not by encoded with any other characters. { “webcredentials” : { “apps” : [“1ABCDEFGHIJ.com.example.TestApp”] } } In the above code snippet, “1ABCDEFGHIJ” is your team ID. “com.example.TestApp” is your app bundle ID. After uploading the above file in its place. If we call the following link it should show the above JSON content. link: https://example.com/.web-known/apple-app-site-association . Now if you run your app the quicktype bar will show us a suggested credentials related to our site. So now we just need to select the suggestion to perform the authentication process(Touch ID or Passcode) and the credentials will be auto filled. Conclusion: Autofill password feature reduces user’s work and which in turn reduces the scale of abandoning the app. It’s better to include this feature which will be very much useful for the users to overcome the problem I have stated in the first section of this blog and for user convenience. – Bharath R, iOS Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-07-13"},
{"website": "Mallow-Tech", "title": "Android Pay – A small introduction", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/07/android-pay-a-small-introduction/", "abstract": "Introduction: Google has unveiled Android Pay in its recent update. Android Pay is basically an upgraded and sophisticated version of Google wallet. As I mentioned Android Pay is a mobile wallet application which helps you to store your credit cards, debit cards, loyalty cards and so on. This application is yet to be introduced worldwide, as of now it is active only in few countries which include England and USA. This app is available in the Google Play store and can it be downloaded in the countries which allow Android Pay. Convenience: One of the primary ideas behind the development and reinvention of Google Wallet to Android pay is to make it more convenient to the users and the merchants. The user can add a debit or credit card within the app. If the user had cards associated with their Google accounts then it can connect in few steps to your Android Pay account. Adding a new card can also be done by taking a snap of the card. This is the easiest way to add a card to the system. Once the cards are added then just by tapping you can pay to any stores you want to pay. To pay at any contactless terminal open the Android Pay app and tap the button. It can also be seamlessly integrated with Android Watches. Safety & Security: When they first unveiled Android Pay, it was said that the user will be able to pay for the products by just simply unlocking the phone. Another feature here is for under £30 the user can pay without even unlocking the phone. For these type of purchases, you need to authenticate the purchase. Authentication is nothing but a tap and bingo, the transaction is done. You don’t even have to open the app, the virtual swipe does the job. Once the transaction is done, you will receive the confirmation details on your phone. Offers: When you pay at some selected retailers, your locality points and so on the offers will be auto updated during the checkout. Being a company heavily relying on advertisements integrating the brands, stores and localities to the product help in personalising the offers to the users to a greater extent. So there is a high chance for you to receive specialised offers for Android Pay. This may also increase the proximity marketing and loyalty programs to a greater extent. Google Playstore: Synchronising the app store apps with buy with Android pay for the apps and built-in payment within the app for further purchases will make it easier for the user to buy products through mobile. Apps like Chipotle, Domino’s, Dunkin Donuts in the US. Apps like Deliver, JD Sports, Zara in the UK have already implemented it. Chrome Extension: Google has announced that it might enable Android Pay through chrome to make the business easier for the companies/stores which don’t have apps. This opens the possibility for various stores and eases the process of payment for web based apps. Google is yet to announce the release date for this update though. As we have seen a lot about the Google Pay app, we need to wait until it is released worldwide to experience the new wave of payment. If this can provide success then your mobile phone will be your new credit card. – Saravanakumar B, Android Developer Trainee, Mallow Technologies Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-07-11"},
{"website": "Mallow-Tech", "title": "How to stay relevant in today’s App market", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/07/how-to-stay-relevant-in-todays-app-market/", "abstract": "Developing an application for your business is a must in today’s scenario. But not all of the businesses which have developed applications are not performing well in the industry. It is important that your application must be relevant to the ever dynamic trends of the app markets. In order to stay at the top consistently, a business has to take care of the following factors. Let us see in detail about the factor to be taken care off. 1. Update Constantly: App updates forms the most important factor for the app to be on the top. If your app is not updated properly then it in a way implied that it is not monitored regularly. If your app has recent updates then you can see a spike in the downloads and the usage. Also, it gives an opinion to the user that the business is constantly working towards the perfection of the app. Frequent updates also keep the app secure and bug-free. This, in turn, helps the user to have a seamless experience. 2. Customise to the platform: The app has to be customised based on the platform. You cannot create a common app for various platforms. The app has to have the unique feature of the platform to ease the users of the application. The majorly used platforms such as iOS and Android has their own standards and rules to be followed. Following the norms of each platform plays a major role in the app to be placed in the respective app stores and visibility. So, customising the application to each platform is an important factor to be considered. 3. Personalise the application: Personalising the application is one of the most important factors needed to communicate to the client that they are significant to your business. Personalising the contents makes them feel special. Personalisation has been reduced from the delight factor to the must have factor to sustain the app market. With the help of analytics, gamification and various other technological excellence you need to personalise the app to sustain in the top spot. 4. Embrace the technology: App market reach is the result of technological advancement. To sustain in a market driven by the technology it is essential to embrace the technology. Any features in the application have to be updated to suit the recently released technology. This will not only add as an extended feature but can also serve as a product differentiator. Incorporating technologies like Augmented Reality and other latest technologies will serve the purpose of staying on the top or if yours is a new product it will accelerate you towards the top. 5. Listen to your customer: The ultimate victory of any business is the big thumbs up from the customer. If your customer hates it then you can never taste the victory at any point. Constantly listen to your customers, fix the bug reported by them, convey them the changes you made. Communicate them about the changes, ensure that they are aware that you are listening to them. Each of their reviews and comments matters a lot, never take them for granted. Take their comments seriously, add a bit of a personal touch to them. Then you can definitely stay on the top or climb the stairs swiftly. These are the five factors that play a major role for an app to stay relevant in the market. A business organisation has to ensure that these factors are incorporated and followed to avoid failure in the app market. – Marketing Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-07-06"},
{"website": "Mallow-Tech", "title": "Configuring a product page of an App in iOS 11", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/06/configuring-a-product-page-of-an-app-in-ios-11/", "abstract": "Creating a great app is just the beginning in iOS Platform, it has to travel a mile to get placed in the app store. Your app has to pass the Apple review to get uploaded in the App store. You need to provide metadata in iTunes Connect to configure the product page of your app in App store. In iOS 11 Apple completely redesigned the iOS App Store to showcase your work with additional app previews, localisation and new text fields. We can use these redesigned features to increase user attention and the number of downloads of your app. Each and every element is important in your app’s product page, which has the power to boost the number of downloads. Let’s see each element one by one, App name: This is first most important element in your product page. This is the display name of your app. It should simple to spell, unique and it should not be greater than 30 characters. This name will appear on each device and each version of your app like Apple TV, iOS and iPad in the app store. Subtitle: This will be present in a place just below your app name, you can use this for mentioning an important feature of your app or typical use of your app. You can change the subtitle when releasing a new version of the app. It also should not exceed 30 characters. Icon: We can use this element mainly to gain the user attention and this will used as a symbol to convey the quality and purpose of your app. You can have a simple and more meaningful icon. To know more about human interface guidelines for app icon design, refer following link https://developer.apple.com/ios/human-interface-guidelines/overview/design-principles App preview: App preview is a small video which will demonstrate the app features, functionality and UI with its flow. This will give an overview of your app’s important features. The maximum limit of the app preview video is 30 sec. Apple recommends using the footage which is taken in an actual device to get the feel of your app. We can upload up to 3 app preview videos in any order from iOS 11, this will help us to provide video for localisation which your app supports. In your product page, app preview will be placed at first followed by description and screenshots. In iOS 11 the app preview video will play automatically when it makes visible to the user in the screen without audio. If the user wants to see the preview with audio they can click the app preview and play it on a big screen. In iOS 10.3 and below, the first preview only will be shown to the user. So prioritise the order of your app preview accordingly. Screenshots: Apart from app preview videos, you can post your app’s screenshot to explain more about your app. Make your screenshots clear and informative to your user, since the screenshots will be placed first if you fail to provide the app preview video. You can post up to 5 screenshots on the product page. Description: Here you can give a complete description of your app. Just start with significant features of your app to get the user attention. You have to release a new version if you want to update your app’s description, so be careful when giving the description of your app. Promotional text: If you want to update some short news about your app frequently without releasing a new version, then this element will perfectly suit you. The promotional text appears on the top of the description text and it is limited to 170 characters. For example, you can give a text about upcoming features in next version, greeting texts, limited time sales, etc.. in your app. Keywords: Keywords will help the user to find your app when they are trying to search it. So use simple and relevant keywords words to your app. The keywords are limited to 100 characters and each keyword will be separated by a comma(,). To accommodate your keywords within the limit we can follow apple’s suggestion to provide keywords, Don’t use plurals of words that you’ve already included in the singular form since the maximum limit is 100 characters. Don’t use the name of category or name of the app. Don’t duplicate keywords. The improper keywords may lead to rejecting your app in review process, the followings are the don’ts when providing metadata for keyword, Unauthorised use of trademarked terms, celebrity names, and other protected words and phrases Terms that are not relevant to the app Competitor app names Irrelevant, inappropriate, offensive, or objectionable terms In-app purchase: Users can view and start an in-app purchase from your product page. Subscriptions and in-app purchases are shown on separate sections on your product page, and you can showcase up to 20 total items across both. Each item has its own display name, promotional image, and description. In-app purchases can also appear in search results and be featured on the Today, Games, and Apps tabs. Your app must support the new SKPaymentTransactionObserver method to make in-app purchases available on the App Store. You can list in-app purchases in any order on your product page to help drive awareness for a specific content. If the users don’t have your app installed on their device when they make an in-app purchase, they will be prompted to download or purchase the app to complete the transaction. What’s new: In what’s new section you can add a short note about the new features and updates in the new version of your app. This will play a major role when you are releasing updated version of your app, to increase user adaptability of the new version of your app. Rating and Review: You can respond to your customer’s review by pointing directly to their feedback or review using iTunes connect. If you reply to their review, it will be notified to the user and he/she can edit their review at any time, the point is, user’s latest review will be shown on the product page. The ratings of the app will be shown for all the version in of your app, so if you want you can reset the rating of your app at when releasing a new version. NOTE: Apple recommends to reset ratings at when you are releasing major feature in the updated version, otherwise it will affect users attention to download your app. Categories: You can select up to two categories for your app. The first(Primary) Category is very important since your app will be sorted under primary category order when the user searches by category and filter based on category while searching for an app. The primary category also decides whether your app should appear in apps tab or games tab in the App store in iOS 11. These are the elements available in your app store product page. Apple completely redesigned the app store in iOS 11, some of the elements available only in iOS 11, so you don’t need to provide two metadata for iOS 11 and its earlier version. You need to provide only one metadata, rest will be handled by the App store. – Karthick S, Junior iOS Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-06-29"},
{"website": "Mallow-Tech", "title": "Internship at Mallow Technologies – Experience of an Intern", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/06/internship-at-mallow-technologies-experience-of-an-intern/", "abstract": "I am sharing my experiences as a Marketing Intern at Mallow Technologies through this post. As Part of my MBA curriculum, I have to go for a one-month summer internship that holds 2 credits in my upcoming semester. As the season started we are flooded with companies with varied profiles ranging from HR, Finance, Production and Sales. Being particular about pursuing a career in Digital Marketing, I was waiting for the right profile. On one fine day, our placement officer flashed us with the Digital Marketing Intern opportunity at Mallow Technologies Private Limited, Karur. I applied for the company without having any presumption about the location. Along with four other college mates, we had a skype interview which leads to my selection for the position of Marketing Intern at Mallow Technologies , A Mobile and web application development company. I was asked to report on May 10, 2017, at their Campus at Karur. HR of the organisation received me and after completing all the formalities I had a short meeting with the Marketing Executive. We discussed the expectations from either side and he clearly gave a picture on the roles and responsibilities. This leads me to imagine the bigger picture during my tenure more precisely. The culture in the company can be compared to many of the startups nurturing in the Tier I cities. HR introduced me to all the employees and made me comfortable to the new space. This made me feel significant and able to understand that how they value each of the employees, this also helped me in eliminating the feel of an odd man out in the workplace. The task for the internship started off with the Market Research of the competitors of Mallow Technologies. My task was to identify the competitors, analyse their content and create a content strategy based on the analysis. It was tough for me to barge in and start the process. My teammate helped me profoundly in achieving the same. I thought he would assign me the tasks and expect an outcome outright. But he let me experiment with the methods and guided me in approaching the problem. This lead me to discover many things and able to differentiate the good and bad contents all by myself. He made me find answers to all of the questions by myself. This helped me in gaining a foothold in the Digital Marketing. With this help, I was able to properly carry my internship and complete the task within the stipulated time. I created a sample marketing plan for the company for their future reference, and also I was given a chance to contribute to blogs and case study creation. At the end, I have gained a lot through this internship. I have learnt different ways to conduct a market research, how to create content and attract readers and above all developed a habit of reading. Mallow Technologies has helped me in envisioning my future in the area of Digital Marketing in a perfect manner. Looking back, If I overlooked this opportunity considering the location, I might have missed a lot of domain knowledge, real-life business scenario, exposure towards current trends in app development and a lot of great people. – Chandrasekaran S.S, Marketing Intern, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-06-27"},
{"website": "Mallow-Tech", "title": "What’s new with Android O : Features preview", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/06/whats-new-with-android-o-features-preview/", "abstract": "The Nougat age is almost over. Google has officially unveiled its new OS version named Android O for smartphones and tablets. Google has added a lot of new features for user and developers in Android O. Android O is under testing stage. The final API is expected to launch on mid of June 2017. The final release of Android O most likely in late of August or early September. According to Android O Developers, the upcoming Android O will have better battery life and performance improvement. As per the updates from Google, these are the additional features added in Android O. 1) Notification: In Android O, developers have mainly focused on user experience. In the Notification, they have included few more options like a reply, archive, snooze. The option changes based on the applications. Android O introduces a variety of new features in the notification. Notification channel: Android O introduces notification channels to provide an unified system to help the user manage notification. It helps the user to setup most of the setting associated with notifications using a consistent system UI. For example: in the chat application, the user can add a conversation to notification channel. All conversation in a notification channel behaves the same. The characteristic of the notification channel Importance Sound Lights Vibration Show on Lock screen override do not disturb Notification Badges: Google Android introducing the functionality to display notification badges on app icon in few supported launchers. Notification badges reflect the presence of notifications associated with an app, which the user has not yet dismissed or acted on. Notification badges show notification counts associated with notification channel in an app. Notification badges are also known as notification dots. The user should long-press on the app icon to view the notification in notification badges. The notification count will automatically reflex the change according to the user action. Snoozing: user can snooze the notification to reappear at a later time. By updating a change in snooze notification does not cause it to reappear. These are some features in the notification that provides the user to set notification background, messaging style and notification timeout. 2) Picture-in-Picture mode: in Android O, the screen can be launched in PIP mode. It is a framework for video app. PIP is a special type of multi-window, it helps to navigate elsewhere while watching the video. PIP mode lets apps run a video in the pinned window while we can perform another activity in the background. 3)Autofill Framework: In the previous version of Android, we felt account creation, login and card transaction takes time and is prone to errors. To solve this, Android O introduces Forms such as login and credit card forms. It makes easier with the autofill framework. In Android O, it remembers our user name and even a password in some case, to quickly and easily to enter the app on your devices. 4) Adaptive Icon: This feature allows the user to create “adaptive icon”. It makes the icon to change their shape according to the theme of the user. 5) Autosizing TextView: Android O provides the facility for the developers to set a text to expand or contract automatically based on the textView. It makes much easier to optimise the text size for different screens. 6) Smart Text Selection: In the previous os version, we can only have cut/copy/paste option by selecting a text. In Android O, highlighting or selecting a text includes the additional features tap to dial if it’s a phone number, tap to navigate if it’s an address and tap to mail if it’s an email. Other than this, highlighting is more intelligent itself, it automatically selects phrases or a full address when we tap. 7) Screenshots: In Android O, there are lot options added in Screenshot. We can edit, share, crop after taking the screenshots. It helps in cropping specific portions. 8) Vitals: Android O will have many features under the banner vitals, including the security tools, OS optimisations and tools that supports the developers in the betterment of the device usage. Ex: for developer tool – Play dashboard console. With this, help developer can view the analytics results of their app running on other devices. There’s plenty of other features too, but we won’t see it in effect. Android O supports a developer to improve the fonts style and weights. Still, there are chances to introduce new features. Only after the launch of Android O, we can explore it fully. – Saravanakumar.B Android Developer Trainee, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-06-22"},
{"website": "Mallow-Tech", "title": "How to test the battery app usage of Mobile", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/06/how-to-test-the-battery-app-usage-of-mobile/", "abstract": "In this blog, we will see how to measure and test the mobile app battery usage. Nowadays battery life is a bigger headache for mobile users and everybody wants to extend their phone’s battery life. users expect better battery life more than camera, processor and storage. For example, the Nokia 3310 phone only had a battery capacity of 900 mAh, In comparison, the Apple iPhone 7 has a 1960 mAh lithium-ion battery and the Samsung Galaxy S7 Edge has an even bigger 3600 mAh battery. But even with such big batteries, phones can only last for a maximum of a couple of days. And more often than not, our phones need to be charged everyday or even a few times a day. There’s an interesting race going on right now. From one side, mobile chipsets are becoming more energy efficient. But on the other hand, apps are becoming more demanding in terms of processing power and we see a growing trend not only in the amount of data used by mobile devices but in the speed of connections as well. As bigger batteries pose bigger threats of an explosion, software developers should be working really hard to conserve as much power as possible in their apps. And we can help with that! How can you measure battery usage? 1. There is a simple way to analyse and measure battery usage on mobile devices. go for device settings, and tap battery, it displays the battery usage of the each and every app that you have installed. 2. Another method is to install freely available apps in the store(eg, Battery Doctor) that measure and save the battery usage. 3. Another way to measure the battery usage to attaching the phone to a special measuring device or equipment that can read and measure the battery in the real time. Image Courtesy: HubSpot blog How an application consume more battery? Check with yourself with these questions. Whether your app handles large amounts of data(Example: Export/import large amount of file such as photo/documents/video.? Whether your app handle live streaming? Whether your app use a large amount of mobile data? Whether your applications check for location frequently? Whether your app sync between user and server? Whether your app send analytic data from your app to 3rd party(Example: Google Analytics) Whether app runs a more background data? How to Perform Battery Testing? Battery testing is something you’ll need to do in a methodical way. While every application is different, we’ve come up with an example of a mobile app testing workflow. Set your app up for test(get ready to download/export/stream,, etc) Note your current battery stats (overall percentage, the percentage used by your app currently, etc). How to test a mobile app battery usage? Start the test Note down the current battery stats and keep a log of this data for comparison purpose. Repeat the testing for any features/functions that could be more problematic Repeat this testing with varying levels of overall battery(low/full/half) Check whether your app’s other feature are working properly(Example, checking by turn off/on the location services) When it comes down to testing your app’s battery usage, using different angles of attack is the best approach. Each of these monitoring services we mentioned will help you get a better fix on what you need to improve upon, and with mobile apps, it’s all about efficiency. At the end of this testing, we would be happy and helps improve our battery life of ur mobile phones, which would be useful to many customers. We will come up with another important topic related to testing in the upcoming weeks. – Kumaresan T Test Engineer, Mallow Technologies Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-06-20"},
{"website": "Mallow-Tech", "title": "Machine Learning in iOS", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/06/machine-learning-in-ios/", "abstract": "This post deals completely with how Apple has allowed its developers to integrate Machine Learning into their apps, be it iOS, watchOS, macOS, or tvOS. Apple has introduced a few frameworks namely – Vision, NLP, and CoreML. Apple intends its developers to use these frameworks for Integrating Machine Learning with less consideration on the working of the frameworks. Apple also indicates that the developers need not necessarily be masters of Machine Learning to integrate it. Rather, the user experience which the developers try to achieve using the app needs to concentrate more. Basically, machine learning is used to make machines, in our case apps, acquire the facility to perform activities at real time without being programmed but using their own “brains”. It consists of making the machine learn and then use the learned properties and behaviours in real time. What does it mean for apps? It brings in a variety of uses and new features for the apps – starting from predicting the next word in the keyboard to analysing a real-time video and the objects present in it. This was shown in the WWDC session on Machine Learning. For a few more examples – In Photos – People recognition, scene recognition In keyboard – next word prediction, smart responses In Apple Watch also, these can be applied – smart response, handwriting prediction Image recognition in real time Creating new contents The process of making a machine learn involves 2 steps – Training, and Inference. Training involves – learning the algorithm, note the possible behaviours and make a collection of all the behaviours in one entity. In the case of Machine Learning in iOS – Apple has introduced the concept of Model – MLModel. A model is the collection of all the behaviours, properties, features, and whatever you think of, into a single entity. Models play the pivotal role here. Machine Learning in iOS cannot be without the Models. Model can be thought of as the result of training a machine, or set of code. Model consists of all the functions that can be used in the next step – Inference. Inference involves – passing an object as an input to the model and getting the result – this result is to be used in our apps in the way want it to be. This process of training and inference is more of an empirical form, i.e, observation and inference rather than theoretical representation. As already said, Apple insists its developers to concentrate more on inference, than on training because constructing models can be a huge task and there are a lot of teams contributing to generate models. Possibly, we can get the models of the type we want. If we don’t get it, then we can make our models. As described in the session videos – Machine Learning is followed in a layered approach – the top layer is the App where the user experiences the machine learning concept The app accesses the Vision, NLP, GamePlayKit frameworks which form the second layer – domain specific frameworks. Vision is used for processing image, video, audio – like face detection, tracking objects, etc. NLP relies more on text processing, identifying languages, etc. Most of the basic machine learning features can be accessed using these domain specific frameworks. Although, there are certain features which do not fall in both the categories – these are achieved using the third layer – CoreML. This is also a new framework added by Apple, which is the base machine learning framework involving both deep and standard learning processes. It takes input in the form of numbers, text, image, etc and can be used for captioning an image, describing a live video, etc. These three frameworks work by taking in the input, processing the input using the available models and producing the result. Where Vision and NLP use the models provided by Apple, CoreML uses any model. All these frameworks are built on top of Accelerate and MPS frameworks, which form the fourth and final layer. These can be used for math operations, and also to create custom models. As Apple insisted, we need not concentrate on them. Rather, the previous frameworks will do most of the work. Speaking of Models, there are a variety of types – predicting text, Sentiment analysis, music tagging, handwriting recognition, style transfer, scene classification, translation, etc. The MLModel supports tree ensembles, Feed forward neural networks, recurrent neural networks, generalised linear models, vector machines, convolutional neural networks. Where do we get the models? Apple has provided 4 models in their site – https://developer.apple.com/machine-learning/ and more are to come. To create our own custom models, Apple has introduced CoreML Tools. It is a python package. Takes models and converts them to MLModels It has got 3 layers – Convertors, Core ML bindings & Converter Library, and Core ML specification Converters – convert models from other formats to the one in the form which CoreML accepts Core ML bindings – get the prediction and the results from Python package for the models Converter Library – this is a high-level API used in building converters Core ML specification – writing new models on our own. Now, enough of this theory. Let’s get started on how to achieve a basic machine learning feature in the app. Our aim here is to provide an image and get a description of the image using the model provided by Apple – Inceptionv3 Achieving machine learning is super-simple and involves just 2 steps: Include the model you want and add it to the app’s target. Code You may consider creating a new model as a step prior to including it in the app. When the model is dropped in the Xcode project, Xcode detects it as an MLModel once we add it to our app’s target. And then, we can start coding!! We are trying to use the Inceptionv3.mlmodel which is available in the above website. Once the model is included in the app and added as target, it looks like: The app contains an imageView, a label describing the image, and a button to choose an image. What we aim is achieved by the following code: let model = Inceptionv3()\r\n</span>if let prediction = try? model.prediction(image: image as) {//Make sure the image is in CVPixelBufferFormat\r\n<span style=\"font-weight: 400;\"> descriptionLabel.text = prediction.classLabel\r\n</span><span style=\"font-weight: 400;\">} else {\r\n</span>   descriptionLabel.text = \"Oops. Error in processing!!\"\r\n<span style=\"font-weight: 400;\">}</span> If you think it takes a hard time to convert UIImage to CVPixelBuffer and then doing the above step, we have another approach . First, we need to import the required frameworks: import CoreML import Vision Then the following needs to be done: Get the model from VNCoreMLModel Create request by providing the obtained model In the completion of the request, using the response, obtain the results in the form [VNClassificationObservation] The first of this result array gives the top result – which has identifier – description, and confidence – probability of the description matching the image <span style=\"font-weight: 400;\">if let model = try? VNCoreMLModel(for: Inceptionv3().model) {    //Get the model\r\n</span>   let request = VNCoreMLRequest(model: model) { [weak self] response, error in  //Create a request using the model\r\nif let results = response.results as? [VNClassificationObservation], let topResult = results.first { //Using the response, get the result\r\nDispatchQueue.main.async { [weak self] in\r\nself?.descriptionLabel.text = \"\\(Int(topResult.confidence * 100))% it's \\(topResult.identifier)” //Update the label\r\n<span style=\"font-weight: 400;\">}\r\n</span>   }\r\n}\r\n<span style=\"font-weight: 400;\">//The following is to perform the request</span>\r\n\r\n<span style=\"font-weight: 400;\">    let handler = VNImageRequestHandler(ciImage: CIImage(image: imageView.image!)!)</span>\r\n\r\n<span style=\"font-weight: 400;\">    DispatchQueue.global(qos: .userInteractive).async {</span>\r\n\r\n<span style=\"font-weight: 400;\">   </span> <span style=\"font-weight: 400;\"> do {</span>\r\n\r\n<span style=\"font-weight: 400;\">   </span> <span style=\"font-weight: 400;\"> try handler.perform([request])</span>\r\n\r\n<span style=\"font-weight: 400;\">   </span> <span style=\"font-weight: 400;\"> } catch {</span>\r\n\r\n<span style=\"font-weight: 400;\">   </span> <span style=\"font-weight: 400;\"> print(error)</span>\r\n\r\n<span style=\"font-weight: 400;\">   </span> <span style=\"font-weight: 400;\"> }</span>\r\n\r\n<span style=\"font-weight: 400;\">   </span> <span style=\"font-weight: 400;\"> }</span>\r\n\r\n<span style=\"font-weight: 400;\">   }</span> And then, run! On giving a few of the default images present in the simulator and a few other common images – we get the following output. Have a look at it and enjoy! You can also develop the sample project from here – Sriram K, Junior iOS Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-06-15"},
{"website": "Mallow-Tech", "title": "Introduction to Core ML and ARKit in iOS 11", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/06/introduction-to-core-ml-and-arkit-in-ios-11/", "abstract": "Last week Apple have released two big frameworks as part of WWDC 2017 to take the iPhone and iPad users to next level. They are called core ML and Augmented reality. A developer can make use of core ML framework to develop intelligent apps and augmented reality framework to develop augmented reality experience in real world. Let’s see small introduction about each framework, Core ML: Now you can build more intelligent apps with the power of Core ML which is recently released by Apple at WWDC 2017. With the new foundational machine learning framework which is used in following apple’s default apps camera, Siri and Quicktype, we can build high-performance intelligence apps with just a few lines of code. We can easily integrate trained machine learning models to our app. Trained model is the result of applying a machine learning algorithm to a set of training data. The model makes predictions based on new input data. Core ML allows you to integrate wide variety machine learning model in your app, which also supports some standards models like tree ensembles, SVM’s and generalised linear models. It is built on top of low-level technologies like METAL and ACCELERATE frameworks. Core ML uses the power of CPU and GPU to provide the high performance in data processing and analyse. All the analyses of your data will happen only in device. So the data won’t leave your computing device, it ensures the security of our data. Where to use core ML in your app? We can easily integrate ML in your app for following features Face tracking Landmarks Rectangle detection Face detection Text detection Barcode detection Object tracking and Image registration The natural language processing api in foundation framework in uses machine learning to deeply understand the text using following, Language identification Tokenization Lemmatization Part of speech Named entity recognition Core ML also supports Vision framework(Debuted in iOS 11) – For image analysis Foundation framework – For Natural language processing GamePlayKit framework – For evaluating learned trees The below image will clearly explain how core ML builds and works in your app Core ML layer structure Core ML working These are the basic intro about machine learning framework. ARKit:[Augmented reality] ARKit is a framework which uses your device camera and motion sensor to create the augmented reality experience in your app or game. ARKit adds the 2D or 3D view in your real world views, which is taken by using a device camera. AR combines device motion tracking, camera scene capture, advanced scene processing and display conveniences to simplify the process of building AR experience. AR will run on the device which has A9 and above chips set. The following steps involved to build AR experience in real world, Tracking – Matching real world and visual-inertial odometry The ARKit uses the visual-inertial odometry (VIO) method to create the correspondence between the real world and virtual spaces. This method uses data from the motion sensor and computer vision analysis of a scene from device camera. ARKit analyses the features in the scene using data gathered from different video frames and it combines this scene data with motion sensor data to provide the high precision information about device’s position and motion . Scene understanding – Plane detection, Hit testing and light estimation Plane Detection – We can detect the plane surface in our scene by enabling “planeDetection” setting in our ARSessionConfiguration. As the result of plane detection, we can get the position and size of the detected plane in our scene. We can use this to place our virtual content in the real world scene. Hit testing – Using this we can find the real world surface corresponding to the point the camera image. Light estimation – Lighting of the scene we are tracking also plays a major role in AR. So scene with low light and a blank wall will reduce the tracking quality. Rendering – Easy integration, ARView and Custom rendering After completing tracking and scene understanding we can place virtual elements in real world scene using ARKit. The following image will explain how AR actually works, These are the small intro about the apple’s new ARKit. We will see about ARKit in detail with a hands-on demo in future blog post. – Karthick Selvaraj, Junior iOS Developer, Mallow Technologies Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-06-13"},
{"website": "Mallow-Tech", "title": "iOS 11 updates in the Settings app", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/06/ios-11-updates-in-the-settings-app/", "abstract": "With the release of iOS 11, Apple has done quite a few changes in the Settings app. We shall go through the most common changes and additions in the Settings app. Before that, it is necessary to mention that the appearance of Navigation Bar has changed. The title is bigger than usual and more towards the left, probably aligned naturally. And upon scroll, the big title becomes small(the actual size of the navigation title – in previous versions), it is set in the middle, and the animation is quite good. And this change is not a feature present in Settings app alone, but it can be used by anyone. More importantly, developers need not spend time in this animation since apple has it by default. In deeper levels of hierarchy – the appearance was found to be mixed: Control Centre had the new one, but other screens like General Settings had the old one. In the “Notifications” settings – there is an option to choose whether the notification preview should be shown or not. This is to help some users who wish to see the details of the notification in the notification centre itself. So, while implementing push notifications, it is to be kept in mind that the preview is optional. This can be changed for the apps specifically also. So, users can avoid seeing the preview for some apps and let other apps show the notification previews. Now, the messages can be synced to iCloud and accessed from any other device. Syncing can be enabled or disabled depending on how the user prefers. There is an option in FaceTime to enable capturing live photo during video call. This is an improvement done in the FaceTime app and users can enable/disable it. Other videos also can have this feature to pick a particular moment without any disturbance in the image. Photos and Camera settings were under the same roof in the previous releases, but they have been separated in this release. One main reason would be to differentiate them both since there are many settings when they are clubbed together. The respective features have been retained, with the addition of enabling/disabling QR Code scanning for camera. And in photos, if there is low space in app,  f ull resolution photos are automatically replaced with optimized versions and corresponding full resolution versions are stored in iCloud. Although, this relies entirely with the user – to enable it or not. There is an option for the text to be highlighted during speech. In Safari settings, there is a new option – Try to avoid cross-site tracking. More about this is expected to be told in the WWDC sessions to come. There are two changes in Control centre settings – Access on Lock Screen, Access within Apps – have been removed, and by default they are enabled. They can be disabled in the App settings for every app.  The second is a major change where we can customize the elements to be present in Control centre as in Android Mobiles. We can choose the basic accessories like torch, timer, calculator, camera, alarm notes, etc. In the iTunes and App Store settings, we can switch off the app-rating and review manually for all the apps. This stops the apps from asking the user regarding the rating and review. There is a new option – Offload unused apps – which uninstalls the apps that are not used for quite some time. But their data is stored and kept. There is a new setting added to the list – Accounts and Passwords. Here the passwords for specific apps are stored and can be viewed and changed. Also, personal accounts can be managed like Gmail, Yahoo, iCloud, etc. There are a few changes in the Accessibility part of General Settings – In Display Accommodations, inverting the colors was present already but enabling it would invert them to dark theme which might affect some of the apps. But now, there is an option – Smart Invert which reverses colour, except for images and apps containing dark themes. As always one can choose the older one – Classic Invert. The second significant difference would be in accessing Siri – now we can access Siri by type – by enabling Type to Siri option. Apple has also changed the names and locations of some of the settings. Under ‘Do not disturb’, the term ‘Manual’ is replaced with ‘Do not disturb’ which looks more apt. Storage and iCloud Usage is changed to iPhone Storage. Also, the UI for the storage details has changed and now looks more appealing graphically rather than just a few numbers denoting the statistics. Siri is now Siri & search. With this change, there is the introduction of suggestions and lookup for searches using Siri. This can be handled specifically for each of the apps. Also, the emergency SOS is moved to main settings screen. Finally, there is a major change in the Settings app – the social account apps like Facebook, Twitter, Flickr, Vimeo have been removed from the Settings app. If the user wishes to sign in via any of these social accounts, he would be redirected to Safari and login from there. This probably might come as a drawback for many apps. Although, Apple has introduced another feature – Password Autofill in apps, to enable the app to pre-fill the user’s password. This might fill the void created by the removal of social account apps, at least to some extent. These are the features that are changed in the settings app with the iOS 11. In the upcoming weeks, we will see in detail about the other changes that might be significant to the users and the developers with the release of new iOS 11. – Sriram K iOS Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-06-08"},
{"website": "Mallow-Tech", "title": "5 Must know feature updates from iOS 11", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/06/5-must-know-feature-updates-from-ios-11/", "abstract": "Apple has announced the release of the new iOS 11. In this post, we are going to see in detail about the 6 new features to be noted in the new release. The features are as follows. 1. Control Centre : iOS 11 lets you customize the redesigned Control Centre so you can change the settings for the things you do most. In order to customize, go the settings – select Control Centre. There in more controls tab, you have various options which include alarm, do not disturb, low power mode, screen recording etc., You can use 3D Touch in Control Centre to unlock even more commands, in case of the phones without 3D Touch, the Long press would do the job. 2. The all-new App Store: The App Store has been redesigned from the ground up to help you discover new apps and games you can’t live without. You’ll see daily stories by experts, a dedicated Games tab, lists for all kinds of apps, and much more. It’s the biggest thing to come to the App Store since apps. 3. Do Not Disturb: When you’re driving, just drive. iPhone can now sense when you’re driving and prevent you from being distracted by calls, text messages, and notifications until later. People trying to reach you can automatically be notified that you’re driving. 4. Automatic Setup: Get off to a quick start. Just hold your new iPhone or iPad near an iOS device or Mac you already own, and many of your personal settings, preferences, and iCloud Keychain passwords are quickly and securely imported. Or in technical terms, easy peasy. 5. Screenshot: Take the screenshot and it will preview in the bottom of the home screen. Tap them to open and edit it accordingly. Screenshots are taken for sharing momentary instances and adding this editing feature along will definitely a welcome move. You don’t have to go to photos folder to select edit and share the screenshot pictures. Also, the new iOS 11 will be supported for the following devices. In future blogs, we will see in detail about the other important features of iOS 11 and the important snippets from WWDC 2017. – Arasuvel T, iOS Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-06-06"},
{"website": "Mallow-Tech", "title": "5 Qualities of a Good mobile App developer", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/06/5-qualities-of-a-good-mobile-app-developer/", "abstract": "App development has surging like anything in today’s scenario. Developers are facing high time demand and are also available in abundance. In what way we can differentiate a good developer from a normal developer is the qualities they possess and the process they follow. In this post, we try to give a detailed account of 5 qualities of a good mobile app developer. Compliance with the standards: If a new project is to be developed then the developer should maintain the coding standards corresponding to the platform like Syntax declaration, design pattern etc., If it is the case of an existing project then the developer should comply with the already written programs. Existing code with defects should be commented and new logics should be added on top of it. Before any syntax or function, a comment should be added for the better understanding of the code flow. Versioning should be taken care promptly, beginning of the code should have the versioning details . This helps for a new coder to understand the requirement in a better way. Thought process: Before proceeding to code it very important to decide how you are going to proceed it. As per normal flow , drawing a flow diagram then proceeding with the pseudocode then the functions involved and its flow. A rough code in notepad helps you to get advanced things. While start coding always is in the shoes of the user and put your logics. A virtual reality of your logics in your mind helps. Stand outside the box and look into the box for the better understanding of logic. App store compatibility and update Be online, be updated always. Check your platform updates either it is AppStore or Playstore gets details about the updates a week before. If any changes in OS inform the client about the change prior. Client communication Always have a constant touch and feedback from your client starting from the problem detection phase, collect all the required details and be informed about the approach we carryout. It is always a wise thought to have client idea in mind while proceeding. Every time you give a new working code to client separate it into a different project so that the client will have a clear differentiation from the live one. Before sending beta version to try to get the details 3 days or 1 week before . Testing standards Any app is accepted only if it is sealed with TESTED OK by the testers. This crucial phase should be handled with care. The test case should be created for the algorithm and every logic and that should be tested. A clear documentation should be maintained which acts as a reference manual for the developers to maintain few scenarios somewhere to check the same in future apps. Whether the device supports Multilanguage or not, as a tester , it’s the responsibility of the tester to check that application in other languages as well. Concentrating on the scope More than the features, few things should be taken care as well like battery consumption, Memory check, the Internet or bandwidth check because your app is going to work on so many types of devices on a same Operating system. The performance will rate your application anywhere. Keep in mind your new changes, how it is going to affect the old users. Start your work from that perspective and fulfill the client requirements. Be proactive – before your client logs defect during their testing, check the issue and start working on it. Always put yourself in the user’s shoes and code or test the app. Thus we have seen in detail about the 5 important qualities that a developer has to possess. This differentiates a good developer from a normal developer. Any person who wishes to be an excellent developer has to ensure that these steps are followed. – Yogesh M, iOS Team Lead, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-06-01"},
{"website": "Mallow-Tech", "title": "How to integrate HipChat Room With Laravel Application", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/05/how-to-integrate-hipchat-room-with-laravel-application/", "abstract": "Debugging is a process of an identifying a problem or the source of a problem then either correcting that problem or defining a way for work on it. It is the part of the software development life cycling. We can easily identify our application problems with the help of debugging. The debugging is involving in the process of locating an errors. We can track the application process on the input, output, database transactions, logic of the code etc. Log We can use the Log to debug our application. Log is an option to record the application errors, the database transaction, application process and errors in the application. We can use the Log to validate the application’s process or behaviour. If we are using the Log, then we can track the status, problems etc., from the application. Laravel’s Logging When we are starting a Laravel project, the error and exception handling is already configured in the application. It is monitoring the errors from the application and if any then all are logged and rendered back to the user. The default rendering method is returning the exception back to the browser as a HTTP response. Here the laravel is using Monolog library to handling the logs. The log files are stored in the storage/logs directory. Laravel is allowing us to save the logs as a single or multiple files. The Log example looks like this, use Illuminate\\Support\\Facades\\Log; Log::info(‘Showing user profile name: Laravel‘); Monolog is a php library to record the triggered errors and desired logs from our application. Monolog has a stack of handlers. We can use one or more handlers based on our need. Example handlers are HipchatHandler, MailHandler, SlackHandler etc. The monolog is giving a different type of levels to record a log message. They are, * debug * info * notice * warning * error * critical * alert * emergency So, please ensure about what type of log’s level is used by our application. Laravel’s Errors & Logging is explaining more over the how to configure and maintain the monolog log files in the application. Error Log Notifications Laravel is providing the log file to debug the application. But, the developer needs to spend his/her precious time on reading this log file(s) and identifying the error(s). Think about it, If the developer getting the notification about the application error at the time of log entry based on the log level then the developer can easily resolve the error based on the severity. We are mentioned at early the monolog is having the various configuration handlers. From that handlers, we are going to use the Hipchat Handler to get the notification of an error from our application. The purpose of this configuration, we can easily improve our application quality, the logic of the code and can develop the skill in our coding style or programming language. We will see about below coming points for how to send a notification to the HipChat room from the laravel application. Create HipChat Room First of all, we need a hipchat room for the laravel application. Here we will see about the steps to create a room. Step 1:- Open the hipchat account and launch the web app or download any given app from that page based on the our system/mobile. We have a option to ‘create a room’ and enter the further details. For example, the room name, it will look like, Ex:- hipchat-testing Step 2:- Clicking the integration option from the room or web page of hipchat. Now, we can see the integrations page with a option to “select a room” while clicking this it will be list the created rooms name (Note:- If we are an admin person for that room(s).). Now we can select (any one or) the required room from that list. For Example using the “hipchat-testing”. Now, we can choose “Build your own integration” then need to give a name for our integration in the next page. Ex:- hipchat-app Step3:- On next screen, we can get the URL for our hipchat room. It will look like this, https://COMPANY_NAME.hipchat.com/v2/room/ROOM_ID/notification?auth_token=AUTH_TOKEN Configure The Room With Laravel Application We have a two type of process to connect the room with the laravel application. Process 1:- We can configure the hipchat room from the application bootstrap/app.php file. Laravel is documented about the custom monolog configuration . $app-&gt;configureMonologUsing(function ($monolog) {\r\n</span><span class=\"s1\"><span class=\"Apple-converted-space\">   </span>$monolog-&gt;pushHandler(...);\r\n</span><span class=\"s1\">});\r\n</span><span class=\"s1\">return $app; This will notify the errors for the configured hipchat room. In this process, we have a disadvantage of can not create as usual log files. Process 2:- We have an another process of configuration to get as usual log files and hipchat room notification also. Please make the changes in the above code and locate it in the boot method of AppServiceProvider.php. use Illuminate\\Support\\Facades\\Log; </p>\r\n<p class=\"p3\"><span class=\"s1\">Log::getMonoLog()-&gt;pushHandler(new \\Monolog\\Handler\\HipChatHandler(</span></p>\r\n<p class=\"p3\"><span class=\"s1\"><span class=\"Apple-converted-space\">                </span>’AUTH_TOKEN’, ‘ROOM_ID', ‘hipchat-app’, true, \\Monolog\\Logger::CRITICAL, true, true, ‘text', 'COMPANY_NAME'.hipchat.com, 'v2'</span></p>\r\n<p class=\"p3\"><span class=\"s1\">)); Conclusion So in this post, we have seen in detail about how to configure the hipchat room for log entries from laravel application. The advantage of this configuration is, we can easily debug our application via the notification of hipchat room. I hope this blog is helpful for you while trying to debug your laravel application. – Ramadurai M, Junior Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-05-25"},
{"website": "Mallow-Tech", "title": "How to create a template in Android Studio", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/05/how-to-create-a-template-in-android-studio/", "abstract": "Templates: Templates are prewritten modules that can be used for repeated use. You can create code templates with the help of Android design studio to get elements that follow the Android design & development standards. This makes the process of Android app development easy. In this post, we are going to see the step by step process of creating a template with the help of Android Studio. For creating new templates: In the Android studio. Right click on the source code folder and select “New”, then select “Edit File Templates”. Then you will see a window like in the picture below: Here you can see some predefined templates but we don’t need this so click on “+” icon in the top left corner. After this action, your screen should look like this. In the field called “Name:” enter a name for your template. The name should be “ViewPagerTemplate”. Now we are ready for some fancy template coding in the big area below template name. For defining some custom variable, write ${VARIABLE NAME}. Entry for the variable name will be displayed during class creation, also here are some predefined ones: ${PACKAGE_NAME}, ${NAME}, etc. Example 1. In this example we will use only predefine variables. ViewPagerAdapter template code is shown below: </p>\r\n<p class=\"p3\"><span class=\"s1\"><i>package ${PACKAGE_NAME};\r\n</i></span><span class=\"s1\"><i>import android.support.v4.app.Fragment;\r\n</i></span><span class=\"s1\"><i>import android.support.v4.app.FragmentManager;\r\n</i></span><span class=\"s1\"><i>import android.support.v4.app.FragmentStatePagerAdapter;\r\n</i></span><span class=\"s1\"><i>import java.util.ArrayList;\r\n</i></span><span class=\"s1\"><i>public class ${NAME} extends FragmentStatePagerAdapter {\r\n</i></span><span class=\"s1\"><i>private ArrayList fragmentArrayList = new ArrayList();\r\n</i></span><span class=\"s1\"><i>public ${NAME}(FragmentManager fm, ArrayList fragmentArrayList) {\r\n</i></span><span class=\"s1\"><i>super(fm);\r\n</i></span><span class=\"s1\"><i>this.fragmentArrayList = fragmentArrayList;\r\n</i></span><span class=\"s1\"><i>}\r\n</i></span><span class=\"s1\"><i>@Override\r\n</i></span><span class=\"s1\"><i>public Fragment getItem(int position) {\r\n</i></span><span class=\"s1\"><i>return fragmentArrayList.get(position);\r\n</i></span><span class=\"s1\"><i>}\r\n</i></span><span class=\"s1\"><i>@Override\r\n</i></span><span class=\"s1\"><i>public int getCount() {\r\n</i></span><span class=\"s1\"><i>return fragmentArrayList.size();\r\n</i></span><span class=\"s1\"><i>}\r\n</i></span><span class=\"s1\"><i>} Example 2. In second example shown below, we will be using singleton class and predefined variables. </p>\r\n<p class=\"p3\"><span class=\"s1\"><i>#if (${PACKAGE_NAME} &amp;&amp; ${PACKAGE_NAME} != \"\")package ${PACKAGE_NAME};#end\r\n</i></span><span class=\"s1\"><i>#parse(\"File Header.java\")\r\n</i></span><span class=\"s1\"><i>public class ${NAME}{\r\n</i></span><span class=\"s1\"><i>private static ${NAME} ourInstance = new ${NAME}()\r\n</i></span><span class=\"s1\"><i>public static ${NAME} getInstance()\r\n</i></span><span class=\"s1\"><i>return ourInstance;\r\n</i></span><span class=\"s1\"><i><span class=\"Apple-converted-space\">    </span>}\r\n</i></span><span class=\"s1\"><i><span class=\"Apple-converted-space\">    </span>private ${NAME}() {\r\n</i></span><span class=\"s1\"><i><span class=\"Apple-converted-space\">   </span>}\r\n</i></span><span class=\"s1\"><i>}</i></span></p>\r\n<p class=\"p3\"> How to use Templates : First select the package where you want to generate your template code. Then choose “New” and select a template. After selecting a template, you have one more than step – writing variable entries. Conclusion: We have seen in detail about the creating a template in Android studio. Creating a template helps in reducing the development process considerably and also eases the coders to create extensive projects. – MANIKANDAN K, Android application developer, Mallow technologies private limited. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-05-23"},
{"website": "Mallow-Tech", "title": "On Demand Resources – Apple’s answer to storage problems", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/05/on-demand-resources-apples-answer-to-storage-problems/", "abstract": "In our previous post, we saw about the technologies by Google to manage the storage problem faced in the mobile. They have developed Progressive Web Apps and Android instant apps to save a lot of internal storage. On Demand Resources is a technology developed by iOS to manage the app efficiently. In this post, we are going to see the On Demand Resources in detail. On demand resources was introduced in iOS 9 for efficiently managing the size of an app. The main purpose of this feature is to reduce the initial app download size so that developers can separate resources from their main application bundle so that resources are hosted in Apple app store and can be downloaded when needed. Resources can be images, sounds, data, scripts but no executable content. Eg: In a game, level 1 and level 2 might be sufficient for the developer to run the app. And once level 1 is finished, he might request for level 3 and it will be downloaded in the background. And also developer can delete the resources and free up the spaces that are not needed like if a user reaches level 10, then he might free up the spaces for resources used by the previous levels of the game. This feature also supports tvOS. Features: -> Dynamically downloads the content only when needed. -> Reduces the app size. -> Resources are Safely hosted in Apple server. -> Efficient managing of memory in device (removes the resources when not needed) -> Max. application size of total resources can be up to 20 GB. -> Users will a have a better experience of the UI rich contents. Three categories of on demand resources – Initial install tag : Downloading the resources along with the app. The app size in app store include these resources. – Prefetch tag order : Downloading the resources immediately after install. A simple example would be a “tutorial” related resources which might be needed after install. – Download on demand : Downloading the content only when the resource is needed. Managing On demand resources:- -> Tagging: Resources are downloaded from the server based on tag name which is strings. Each resource is identified by its tag name. We can assign resources to tags. For e.g.: – We can assign tags “tutorial” to an image that displays basic app instructions. We can also apply one or multiple tags to a resource. -> Developer request for the resources using tags. It also includes progress reporting of the downloading process, handling errors. -> Developers can also set preservation priority and loading priority for the downloading. When preservation priority is set high, OS will most likely not delete the resource. When loading priority is high, it will be downloaded fast but might affect other app performance. Best practices: We can assign resources up to 512MB for a single tag, but the Apple recommended size is 64 MB. This will be useful in scenarios where if the internal memory gets low and the OS decides to purge resources associated with a tag. Eg: – If OS needs 64MB space to be cleared and if the tag size is 128 MB, then it will delete the 128MB completely. In this case, extra 64MB of content is deleted unnecessarily. So assigning the tag size efficiently increases the app performance. Conclusion: On demand resources in iOS 9 and tvOS will help reduce the app size and give a better user experience. A small app with limited resources would not see much benefit, but a large app with many resources (like a game) would easily benefit from loading resources on demand i.e when needed. – Rajtharan G, iOS junior developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-05-18"},
{"website": "Mallow-Tech", "title": "Progressive Web Apps – The future of mobile apps ?", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/05/progressive-web-apps-the-future-of-mobile-apps/", "abstract": "We saw about Google’s Instant apps in one of our previous posts. Instant apps is not the only solution to the storage space problem. Another technology which holds the future is Progressive Web Apps. Both of these are developed by Google and has the huge potential to change the market of applications. Instant apps & Progressive Web Apps: You can see in detail about the Google’s instant apps in our blog post . The biggest disadvantage of Instant apps is that it relies on the platform. It is developed by Google for the Android OS. A similar concept developed by iOS has its own issues and hence it cannot be the universal solution. Progressive Web Applications, on the other hand, is a browser based application. Here the application viewed through browser gives the feel and navigation of a native app. As of now, this technology is supported for chrome and Microsoft’s browsers. In future if it is supported for Safari then a common app developed would do the wonder. Although a lot of hybrid app development is trending, progressive web apps are holistic and solve the biggest problem of storage space. That’s not the only issue it will help in solving but also attaining the native app experience through web browsers. Also, it helps in marketing the apps easily. Marketing: Developing a PWA helps to streamline the marketing activities and direct it towards the web as it is search engine discoverable. Also, repeated use of an app in the browser helps in bookmarking the app and you can see it on the home page. The user can go to the browser and launch the most frequently used apps through the browser. It is easy and also the cached memory is low. Scope & Future The biggest challenge in this technology is attaining the native app like experience. If you can get the native app experience then it indeed cannot succeed as a replacement to the apps. The success of the technology relies heavily on the customization available in the future and support for other browsers. The future will be decided based on the user experience more than anything. – Marketing Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-05-17"},
{"website": "Mallow-Tech", "title": "Banking Apps – Digitizing the Banking process", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/05/banking-apps-digitizing-the-banking-process/", "abstract": "Introduction: In this post, we are going to check in detail about the banking mobile apps and its future & scope. A Banking mobile app is an application which helps you in performing the banking operations through your mobile. Some of the major activities include that of the fund transfer between the accounts, paying bills, monitor the transactional history and so on. Banking applications are becoming so popular for a lot of reasons. The primary reason being it saves a considerable amount of time one needs to travel and complete the work in the bank. Along with this the scope of the application is not just restricted to the activities mentioned in the before paragraph but rather it also gives way to the mutual fund investments, portfolio management and so on. Digitizing the sector: Mobile banking to be precise is pretty much an advanced version of online banking. Online banking needs a laptop all the time and it is nearly impossible to carry a laptop all time and hence at that instance, a mobile app comes in handy. Many banks have understood the importance of having a mobile app for the banking processes. It not only reduces the human effort and save time but also paves way for a completely digitized process. Digitizing the banking operations has the following advantages such as ease of access, time-saving, time efficiency and so on. This gives an edge to the customer to interact with the banks. By this process, the banks are doing a big favor to the customers and themselves. Customers will use the online banking services more than the offline services, which considerably reduces the clutter. Also for the banks, increased usage of their services gives them a boost. Scope & Safety: At present, about 292 million people are smartphone users. It is expected to increase to about 340 million by the end of 2017. Also, the emphasize given to Digital India is another boost for the banking sector to push their limits on the mobile and other applications. As mentioned above the app can’t be restricted only to the fund transfers but can also serve as a one-stop solution for maintaining all the portfolios, banking and finance activities. We at Mallow Technologies have helped Karur Vysya Bank , one of the leading Bank in south India to get into the Appsphere. We have also developed an app called Noverdraft. Noverdraft was specifically designed for the US-based Severus Holdings. This aims at automating the integrating the loan processes. For any bank to develop an app by outsourcing it is essential to see that the team can handle such projects and their performance in this particular domain. You can check our blog the factors to consider before outsourcing a project to know more on this. – Marketing Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-05-11"},
{"website": "Mallow-Tech", "title": "6 Factors to be considered before creating a landing page", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/05/6-factors-to-be-considered-before-creating-a-landing-page/", "abstract": "Landing page plays a major role for the all the web and mobile apps. A landing page is a page dedicated to complete an action required from the visitor. The action can be making a purchase, signing up for the site or newsletter and so on. The landing page has to serve its purpose and the success of a landing page can be measured by the converts. In order to create a better landing page, you need to concentrate on the factors explained below. By concentrating on this you can easily reach the goals. Be clear on the Goal: You need to be clear with the ultimate goal of the landing page. Consider that the goal is to get more signups for the newsletter then it must be conveyed clearly. If the goal is not clear then it is nearly impossible to communicate the same to the users. Add a Call to Action: Adding a powerful call to action button will push the visitor to opt for the same. If your aim is to collect the emails for newsletter subscription then having a striking Sign up button helps in acquiring the user. Highlight the necessary elements: Once the goal is clear then the final call to action has to be highlighted. If a user is scrolling through the page it shouldn’t be difficult for the user to find the final call to action. Also, the heading of the landing page should convey the message pretty clear rather than be giving mixed messages. Design visually stunning elements: The landing page should possess the visual aesthetic that is necessary for a particular product. Visually aesthetic pages garner more attention and the usage of contrasting colours push the users to check out more. Also, usage of images and product videos give more reach than of the texts. Garnering the attention of the visitor is quite high with images and videos. Make it reliable: Adding a testimony or Quote from a user or an existing customer adds more reliability to the site and product. It provides a social proof in a way to the product. The acceptance of a product is spread by the testimony given by the existing users. Test repeatedly: Testing is an important phase before launching the landing page. Testing the page with various tools helps in optimizing the page. You can either opt for a split testing or multivariate testing but, it is essential to keep on testing. The necessary for the keeping it up to date is to provide the users the best experience. By following the above-mentioned steps one can get a perfect landing page. As mentioned in the final point you need to keep it updated to stay active among the user base. – Marketing Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-05-09"},
{"website": "Mallow-Tech", "title": "Swift Source Compatibility – An introduction", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/05/swift-source-compatibility-an-introduction/", "abstract": "Swift Source Compatibility: Swift source compatibility is a community based platform where, the developers can add their projects. The primary aim is to check the compatibility of the project with the new swift releases. As soon as a new version of Swift is out, the projects added in Swift Source Compatibility build against latest version of swift. This is achieved by swift continuous integration which is a part of Swift Source compatibility. This will allow the swift compiler developers to understand the compatibility impact their changes have on real-world swift projects. Test Suite: A new Swift source compatibility test suite as part of the effort to maintain source compatibility in future Swift releases. The source compatibility test suite is community driven, meaning open source project owners can submit their projects for inclusion in the suite. Instructions for adding open source projects to the test suite can be found in the Swift Source Compatibility section on Swift.org. Advantages: Developers can now use Swift’s pull request testing system to test their changes against the source compatibility test suite, helping catch source compatibility regressions before they are merged. The goal is to have a strong source compatibility test suite containing thousands of projects Acceptance Criteria: To be accepted into the Swift source compatibility test suite, a project must: Target Linux, macOS, or iOS/tvOS/watchOS device Be an Xcode or Swift Package Manager project (Carthage and CocoaPods are currently unsupported but are being explored to be supported in the future) Support building on either Linux or macOS Be contained in a publicly accessible git repository Maintain a project branch that builds against Swift 3.0 compatibility mode and passes any unit tests Have maintainers who will commit to resolve issues in a timely manner Be compatible with the latest GM/Beta versions of Xcode and swiftpm Add value not already included in the suite Be licensed with one of the following permissive licenses: -> BSD -> MIT -> Apache License, version 2.0 -> Eclipse Public License -> Mozilla Public License (MPL) 1.1 -> MPL 2.0 -> CDDL Note: Linux compatibility testing in continuous integration is not available yet, but Linux projects are being accepted now. We have seen how Swift Source Compatibility community helps in keeping your project live. This is a huge help to majority of the projects to be up to date. You can view the current list of projects added in the library by the following this link . In the next blog we can see about how to create a project, maintaining a project and giving pull requests. – Arasuvel T, iOS develeoper, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-05-04"},
{"website": "Mallow-Tech", "title": "5 Ways to increase the trust factor of your online business", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/05/5-ways-to-increase-the-trust-factor-of-your-online-business/", "abstract": "If you are a new business in the online sphere then building trust is an important factor. Earning a customer to do business in the online space relies heavily on the trust factor. In order to build a high trust factor, you need to concentrate on the following factors. The 5 important factors that plays a major role in building the trust are as follows. Full disclosure: Full disclosure is the first and foremost important factor. Consider yourself to an e-commerce company and you have advertised as free delivery for all items. When the customer checks out he/she sees some delivery charges, this makes them furious and there is a huge chance for them to sign out from the cart and not return after. This kind of surprises upsets the customer and hence a full disclosure is essential which gives them a picture that the company is what they said they are. It gives a clear message to the customers. Site Encryption: Site encryption looks like a small thing but it definitely has a huge impact in terms of trust. If you are e-commerce site or a service provider and involve payments then site encryption is a must. Configuring the website with SSL certification gives that extra layer the customer needs to keep their data safe. Process Transparency: The whole process has to be transparent. If you are an ecommerce site then the shipping updates and the logistic update has to be accurate. If the property is damaged in the case of an ecommerce site then returning has to be easy. If any glitches happened during the service it has to be addressed and ensured that the customer gets uninterrupted service and a complimentary service to make them delighted. Sustainable Value Proposition: The value proposition offered by the company should be consistent and sustainable. And this has to be conveyed to the customers. Conveying this makes the customer trust you with long time products and subscription. If the value proposition is just a clickbait and not a sustainable one then the longevity of the customer retention will be low. Higher customer retention increases the trust factor. Social Activity: The activity in the social networks play a major role in building the brand image and the trust factor. For any new business social networks serves as a way to communicate. Answering the queries, solving the issues and replying faster with a personal touch increases the brand value along with the trust score. This is one of the touch points where the customer is directly interacting with the brand and hence handling it with ample care makes the brand successful. Thus we have seen the 5 most important factors that has to be taken care for increasing the trust factor of an online business among the customers. By following this an online business can improve their trust factor considerably. – Marketing Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-05-02"},
{"website": "Mallow-Tech", "title": "5 Things to consider before creating your restaurant app – II", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/04/5-things-to-consider-before-creating-your-restaurant-app-ii/", "abstract": "In our previous pos t, we saw in detail about the factors that have to be considered for building an app for your restaurant in user’s perspective. In this post, we are going to see in detail about the 5 factors from the backend/ management perspective. The five factors that should be considered are as follows., Functions: The functionality of the app has to be laid clear before proceeding with the app creation. The functions and features that the app has to be understood thoroughly. This helps clearly to develop the application in a manner it is touted to be. If the basic functionality is not clear then the app might not be able to take the expected final shape nor gives the expected result. Also, the functions should be listed out along the priority of each function. End user features: First of all, things that have to be considered by the admin side is the end user. If a restaurant is building a POS app it has to be sure about the customer expectations and booking. Whether the booking is integrated with the app or not and if not how to sync the bookings matters. The ease of options given to the customer should be ease to the employee’s side too. Technical needs: The most important aspect in helping the management through a POS app is inventory management. By giving permissions to the app in monitoring the inventory and orders it can keep track of the inventory and cushion capacity. The admin team can either be intimated about the stock or the app itself can be made to re-order if the inventory falls below the minimum capacity. This helps in reducing the service failure and meet the surging demands. Similarly, the other technical needs have to be catered so that the app improves the efficiency. Scaling: Scaling up the app is another feature that has to be taken care. If the app is going to be used at one facility or it is going to be at a combined facility has to be noted. If a company is planning to switch for a franchise or centrally controlled facility then the expansion plays a major role. Scope & Budget: The scope of the app should say whether the app is restricted in certain aspects or is it digitizing the entire restaurant. At the latter case, the budget plays a major role in deciding the app development. When the ballpark estimate exceeds the budget then the company has to sort out the prioritized functions and aspects and go on with the application. The final product should be in line with the scope of the organization. These are factors to be noted on the admin side before developing a restaurant application. Both the end users and the admin side factors have to considered before developing an application to cater the needs of both end user and employees. – Marketing Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-04-27"},
{"website": "Mallow-Tech", "title": "5 ways to optimize the performance of the testing team", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/04/5-ways-to-optimize-the-performance-of-the-testing-team/", "abstract": "In this blog, we can see how to increase the performance and potential of the testing team. The QA team has lots project to be tested at the same time with limited resources. To tackle this scenario testing team’s potential and performance should be increased. There are many ways to optimize the performance of the testing team and we can see 5 common ways to optimize the performance of the testing team. 1. Plan and Communicate Clearly Ensure that the testing team has a better understanding of all the information about the project and the testing plan. planning is the important task which will not only make the process smoother but will help in identifying the process flow for testing for more efficient. If there are any changes it should be immediately communicated to the testing team. and each and every app upgrade that requires additional testing cycles should be planned in advance to reduce the time consumption and work delay. The test plan should consist of size of an update or feature, when the update is bigger there will more work for QA team 2 . Involve Testers in Creating the Test Plan The testers should be involved in each and every requirement gathering phase to improve the testing process. By this, the testers can know the requirements clearly and this helps in creating a test plan. This could be a better opportunity for providing the testing team with ideas and suggestions which can lead to new test scenarios. 3. Promote a Collaborative Environment Bugs should be found and reported immediately and it should also be fixed by developers as soon as possible to reduce the time consumption for bug fixing. Check whether there is smooth communication between testing team and development team. There should be collaborative work environment to reduce the risk of insufficient bug fixing and also reduce the process delay. You can also track the time taken for bug fixing, which helps you in planning the release. You can also use the data to reduce the number of defects from one build another build. 4. Provide Opportunities for Learning There are many new opportunities which can be encouraged. Allow your QA team to participate in training workshops and seminars to increase the quality of testing. The more knowledge gained by the testers about the software application they are testing, the more new and useful ideas will be raised. This will result in perfecting the process. 5. Use effective communication tools To increase the efficiency of the testing team, a new proper system with an efficient tool for documentation should be provided to track the bugs more easily. The bugs should be tracked periodically to understand the effectiveness of the testing plans and also the priority and severity of the bugs can be tracked. With the above tips, the efficiency and potential of the testing team can be increased and quality of the products can be reached to the new heights. In this blog, you have learned how to increase the performance and potential of the testing team, and I will be with another new topic in my next blog. – Kumaresan T, Test Engineer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-04-25"},
{"website": "Mallow-Tech", "title": "New features in TestFlight 1.5", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/04/new-features-updated-in-testflight/", "abstract": "For those who are new to TestFlight, there won’t be even better time to start using it, You don’t have to worry about the product much since it is integrated with Apple. Regarding the new features, everything is fine and the most interesting feature for me as a developer is the availability of multiple builds, It really useful in many scenarios like time consumption, comparison testing and so on. Key features added/updated in TestFlight: What is TestFlight? Multiple Build Support Enhanced Groups Improved Tester Management Additional information Notes What is TestFlight? TestFlight is an Apple product using which you can able to test your app(iOS, WatchOS and tvOS) by inviting users before you release them in App Store. This can use used for collecting feedback about your app and make is even better. Key points about TestFlight are, You Just need Testers/Users email id for adding them as a tester. It’s free of cost. Multiple Build Support Now TestFlight lets you distribute and test multiple builds at the same time. So testers can choose from a number of builds to test from. So tester can choose any build from the list of builds available. If you select any app in the TestFlight app, you will be shown Install option for installing the latest version and there is an option called “Previous Builds” in which other builds will be listed, using which you can able to install any build as you like. Enhanced Groups Groups have been changed in iTunes connect. Now you can create groups of TestFlight users as you like. And you can send/assign separate/multiple builds for individual groups and it will be available for testing for those individual group members. By default, Apple has added all of your existing external testers to the group “External Testers”, which you can edit at any time. If you have created groups previously, And If you want to create groups similar to the previously created groups, the Admin users can able to download/export existing groups and import them to TestFlight groups. For more information on managing testers and use, groups check out the link more about testflight groups . Creating Group: You can create TestFlight groups as flows Choose your app in iTunesConnect -> TestFlight -> Click New Group(+) You can edit group name anytime later as you want. You can create multiple groups as needed. Add Testers in the group: Testers can be added to the group in multiple ways as follows, Add New Testers : Here Email address(Mandatory), FirstName & LastName (Optional) Add Existing Testers Import from CSV Sending build for groups: You can able to assign single/multiple builds for individual groups. You can send build to a group as follows, Choose your app in iTunesConnect -> TestFlight -> Choose the group -> Builds -> Click Add Build(+) List of builds will be displayed and will be asked to “Select a Build to Test”. Choose the build which you like to send for the group and click Next. Then you will be asked to enter “Testing Information” where you need to enter the what you want the users to test in this build. This information will be available to testers in all groups to which it’s shared. Then you choose “Submit for Review”. The build will undergo for “Beta App Review” and will be notified to the users/testers once the review process is completed. You can also choose another build for the same group. Then all the builds added for that group will be available to that group testers. Stopping testing a build: You can able to stop a build from testing either for a tester or group as you needed using the following steps. Choose your app in iTunesConnect -> TestFlight -> iOS(under BUILDS) -> Choose a build -> Testers You can remove a particular group or tester as you needed from here. Or you can choose “Expire Build” to make the build expire for all the testers. Improved Tester Management Now the testers can continue testing a build even when the app goes live on the AppStore. iTunes connect users can access all the active builds of the app. By which user can able to compare and test any builds as they want. It’s easy now for resending invitations to testers whose invitation is yet to accept. Additional information The number of days for a TestFlight build to expire has been extended to 90 days, Previously it was 60 days. Notes You can add 25 Internal testers per app. You can add 2000 External testers per app. If there is no builds available for testing then that particular app won’t be listed/shown in the TestFlight app. Conclusion: In this blog post, we saw what are the new features in Testflight. Everything has little cons in it like the “Beta App Review” process for sending builds to Groups in this case. But its much needed since those builds are for external testing. You can start using the TestFlight and let us know what you feel about the new version. Image Courtesy: Apple Videos: https://itunespartner.apple.com/en/apps/videos#testflight-beta-testing – Bharath R, iOS Developer, Mallow Technologies Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-04-20"},
{"website": "Mallow-Tech", "title": "5 Things to consider before creating your restaurant app", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/04/5-things-to-consider-before-creating-your-restaurant-app/", "abstract": "Restaurant business is one of the most crucial business and digitization of the same acts as a value proposition. One can create an app to make it convenient for the users to order and get the food. Before developing an app for your restaurant you need to keep in mind about these points which will help you crafting the app. These points will provide the need to perfect the app and give the customer a higher value proposition. Easy ordering and engagement: One of the primary reason to opt-in for an mobile application is that it gives the user flexibility and customisation of ordering the menu. By designing a proper UI and giving an excellent user experience you can easily capture the users. By improving the engagement towards the app you can easily tap the users to try your dishes. Payment Integration: Integrating payment is one of the most important you need to concentrate on before creating an app. The location of your restaurant plays a major role in the payment integration mode. The majorly used service available to your customers has to be integrated, the payment mode should make it easier rather than tedious. In the app named bubbleology , we have integrated the Braintree payment gateway. The company which is based in UK is spread across Europe and America needed a single payment integration which supports payment in all countries. Braintree payment gateway was chosen based on their requirement. Strype, PayPal are some other payment gateways which can be of use based on the needs. Customer Retention: Acquiring a new customer costs more than that of anything else. So the app should be catering the need of customer retention. Preparing a loyalty program to delight the repeat customers is the most important task. The value proposition should be higher for the repeat purchase and features should be added to increase the engagement rate. Extensive Marketing: When you decide to go for an app, it should completely utilise the features and data available to customise the marketing of the product. You can personalise the offers based on the data collected from the customer. For example, for a registered user you can spend a special offer notification on special occasion such as Birthdays, anniversary days and so on. This kind of gives the personal touch which makes the consumer to visit your restaurant again. Location based offers can be rolled out with the help of push notifications that can trigger the instant buyers. Excelling in Location based push notification should be handled effectively. If you are planning to outsource your app building then you should be keen on the company which excels in building the similar kind of apps. We in mallow technologies have worked extensively with the apps which uses the geo location to send notification and information. Referral and Social Sharing: You should remember the fact that in the age of social media, word of mouth and social shares plays a major role. Providing referral points makes a repeated customer a brand ambassador. The app should contain the feature that lets the user share the refer an offer to others easily. Social sharing and posting reviews of your restaurants should be made easy so that it helps you widen your reach. At the same time you should be careful not to over do the same. If you are asking for rating then it should be done in a decent interval, if not the customer gets irritated and it leads to deteriorating ratings. Thus by keeping these 5 factors in mind you can create an app which can actually help you in growing your business exponentially. These factors emphasise on the user’s perspective. In coming weeks we will see the factors that has to be taken care from the backend’s perspective to create an app for a restaurant. We at Mallow technologies have helped Bubbleology to completely digitise their product and have also worked on a Interactive Restaurant app which also serve as a POS. This can be your value proposition and differentiator. – Marketing Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-04-18"},
{"website": "Mallow-Tech", "title": "Advantages and implementation of FlexboxLayout in Android", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/04/advantages-and-implementation-of-flexboxlayout-in-android/", "abstract": "Flexbox Layout is same as CSS Flexible Layout module in android. Flexbox can be judge as advance form on LinearLayout, both layout are aligned sequentially. The difference is that, Flexbox has feature of wrapping. For using FlexboxLayout in your app, you need to add gradle dependency in you app gradle file: dependencies {\r\n\r\n…\r\n\r\n…\r\n\r\ncompile 'com.google.android:flexbox:0.1.3'\r\n\r\n} Let us see in detail about the cases where Flexbox is useful: 1. In Flexbox when you arrange items in horizontal manner with attribute (flexWrap=”Wrap”). If there is not enough space left in current line, then It take to the new line. 2.To achieve this, You need to set multiple layout design for various screen aspects (like layout-600dp, layout-720dp, layout-1020dp). But by using Flexbox, you can reduce the number of layouts design. You can use this Flexbox layout instead of linearlayout as below. &lt;com .google.android.flexbox.flexboxlayout\r\nandroid:layout_width=\"match_parent\"\r\nandroid:layout_height=\"wrap_content\"\r\napp:flexwrap=\"wrap\"&gt; By this child aligned to new line instead of overflowing its parent. 3. Can also pad space in between them when you have space at the end, but can’t able to load a new item. Then attribute (layout_flexgrow=”1″), will make the line between items with equal space. &lt;android .support.design.widget.TextInputLayout\r\nandroid:layout_width=\"100dp\"\r\nandroid:layout_height=\"wrap_content\"\r\napp:layout_flexgrow=\"1\"&gt; 4. Flexbox with RecyclerView , A latest version of Alpha version, the Flexbox extends RecyclerView.LayoutManager, we can use the scrollable container in much more memory-efficient way. Real world examples for RecyclerView with Flexbox are, GooglePhotos and NewStand, where there will be lots of cards and need to be handle various width of items. FlexboxLayoutManager layoutManager = new FlexboxLayoutManager();\r\n\r\nlayoutManager.setFlexWrap(FlexWrap.WRAP);\r\n\r\nvoid bindTo(Drawable drawable) {\r\n\r\nmImageView.setImageDrawable(drawable);\r\n\r\nViewGroup.LayoutParams lp = mImageView.getLayoutParams();\r\n\r\nif (lp instanceof FlexboxLayoutManager.LayoutParams) {\r\n\r\nFlexboxLayoutManager.LayoutParams flexboxLp =\r\n\r\n(FlexboxLayoutManager.LayoutParams) mImageView.getLayoutParams();\r\n\r\nflexboxLp.setFlexGrow(1.0f);\r\n\r\n}\r\n\r\n//Your own code\r\n\r\n} 5. FlexDirection The direction of its children is controlled by FlexDirection. – row, row_reverse, column and column_reverse i. row : Its children will aligned in LTR direction (Left to Right). ii. row_reverse : Its children will aligned in RTL direction (Right to Left). iii. column : Its children will aligned one below another starting from Top of the layout. iv. column_reverse : Its children will aligned one above another starting from Bottom of the layout. 6. JustifyContent Child items are positioned along the main axis is controlled by justifyContent similar to flexDirection, But flexDirection controls the “order of the child items” whereas JustifyContent controls the “relative positioning”. – flex_start, flex_end, center, space_between and space_around i. flex_start : Start its child from a new line when its wrap in LTR direction. ii. flex_end : Start its child from a new line when its wrap in RTL direction. iii. center : Start its child from a new line when its wrap from its center. iv. space_between : will provide equal space in between its child. v. space_around : will provide equal space in between its child including padding in first and last child in a row. 7. AlignItems AlignItems controls the positioning and sizing of items along the cross axis. The possible values are stretch, flex_start, flex_end, center, and baseline. 8. AlignContent There is a thin line of difference in between AlignItems and AlignContent. AlignItems controls how items are positioned within their own line, Whereas AlignContent controls the line itself. Similar to TableRow within TableLayout, Using “alignContent” is similar to applying layout attributes to TableRow, whereas “alignItems” is similar to applying layout attributes to the child views representing the individual cells in table. The possible values are stretch, flex_start, flex_end, center, space_between, and space_around. In this blog, you have seen pros of FlexboxLayout which overcomes the cons of LinearLayout. In our next blog we can see how to implement FlexboxLayout in RecyclerView. For reference : https://github.com/Manikandan92/flexboxLayout – Pangaj JG Android Developer, Mallow Technologies Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-04-13"},
{"website": "Mallow-Tech", "title": "5 factors for Appreneurs to market their apps", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/04/5-factors-for-appreneurs-to-market-their-apps/", "abstract": "In the increasing world of Appreneurs, it is very important to set the basic rules of marketing an app right. Today we are going to see in detail about the 5 important factors that has to be set right before planning the marketing strategy for your app. The five important factors are as follows. ASO and Mobile SEO Right Metrics User Engagement & Retention Feedback Choice to the user ASO and Mobile SEO: First and foremost factor that has to be taken care of is the ASO or App Store optimisation. In order to reach the right target market it is essential to use the perfect keywords and description. The words and description space has to be utilised properly so that the app should be easily discoverable while searching. Thus it is given prime focus before marketing an app. Right Metrics: The second important factor is setting the right metrics. Any marketing effort is inefficient if it can’t measure the effectiveness of the same. The measure should rightly represent the business and reach. If the metrics fails to show the scenario of the app then there is no use in measuring them. The relevance and the time spent in measuring plays a huge role. These metrics shows the efforts of the marketing activities and gives a platform and direction to work further. User Engagement & Retention: App installations are no more a viable metric nor a way to judge an app. The user engagement attracted by the app defines the success of an application. Retention of the application is another factor that has to be taken care in marketing the application. The marketing activity should not only concentrate of the app installs but rather it should also keep in mind about the user engagement and retention. Feedback: Another important factor to be remembered for marketing the application is feedback. Honest feedback from the customers has to be taken seriously. By listening to the users and responding them aptly increases the goodwill of the application among the users. Although it looks just like a technique to increase the brand image, it is also the basis for improving the product. The product optimised based on the feedback will be received well from the audience. User’s choice: An user appreciates if he was present with a choice to make any decision. Actions such as push notifications and seeking review for the products are necessary but the user should be given a choice to mute it too. If the push notification and asking for a review or rating is frequent it will annoy the user. The frequency should be maintained proper and if possible some value addition has to be given to the user for ratings and reviews. This engages the user in giving a proper rating. Thus we have seen the 5 important factors to be considered while marketing an application. By taking care of these factors the success of an application in the market can be ensured. – Marketing Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-04-11"},
{"website": "Mallow-Tech", "title": "How to add in app rating to your app in iOS 10.3", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/04/how-to-add-in-app-rating-to-your-app-in-ios-10-3/", "abstract": "Prior to iOS 10.3 we need to navigate the user to app store for getting rating/review of our app. By this getting a review/rating from an user is less and it also makes the user annoyed and reduces the engagement of the app. When the user is redirected to the app store there is a high chance for them to quit the app and browse further.  But in iOS 10.3 onwards no need to navigate the user to App Store to get the rating/review. Apple have added new api called SKStoreReviewController in StoreKit framework to get the in-app rating/review. Let’s get dive in detail. Keep in mind: In development mode the rating/review feature will work until showing view to get the rating for testing UI and user experience. But the actually process of updating user rating/review in App Store will not happen, because you didn’t uploaded your app in App Store yet. This rating/review feature will not have any effect to the app which is distributed via test flight. We need to call one single method to show the view for getting rating/review, the remaining work will be handled by OS itself. In addition, we can automatically open the review page of your app in app store, you can simply append the query parameter action=write-review to your product URL, in app configuration place from your app. This link will directly take the user to review page in App Store. Do’s and Dont’s: Before implementing the in-app review/rating, apple have suggesting simple do’s and dont’s. The view showing for getting the in app rating/review screen is fully governed by App Store policy of our app. So there may be a chance to not display the review/rating screen. So it would be better if we follow following Do’s and Dont’s. Do’s: We need to find the perfect place to get rating/review from user. The way you are asking the rating/review for your app should not affect user experience. Dont’s: We should not asking rating/review from user in response of user action(For example: button action, switch action, etc.) We should not ask rating/review when the user opens the app. We should not ask user to rating/review your app frequently. Things need before coding: Xcode 8.3 iPhone Device with iOS 10.3 and above(10.3.1 is also released)(We can test rating in iOS 10.3 simulator, but for testing review we need device) Let’s start coding: Create single view application in Xcode 8.3 Name your project with appropriate name. Here i’m giving my project name as “RateMeHere”. Here we are simply going to present the rating screen from viewDidAppear method. (For better user experience choose the best place to ask rating, again this is only for demo so i’m doing it from viewDidAppear method of my ViewController.swift class.) Open your ViewController.swift file. Import StoreKit framework in that class Add viewDidAppear method in ViewController class,. Add following line in viewDidAppear method. SKStoreReviewController.requestReview() Our final code will look like this import UIKit\r\nimport StoreKit\r\nclass ViewController: UIViewController {\r\noverride func viewDidAppear(_ animated: Bool) {\r\nsuper.viewDidAppear(animated)\r\nSKStoreReviewController.requestReview() // Requesting alert view for getting rating from the user.\r\n}\r\n} Just build and run your project you will see the alert for asking rating for your app. Let’s implement logic to take user directly to App Store review page of our app. As per apple says they will handle the things to get rating and review from user. If we want we can do it as additional to take user directly to review page of our app in App Store. To automatically open the review page of our app in App store, we need to append action=write-review query parameter with our product url. Lets add one button in storyboard and give constraint to make it as centre in screen. Have a look into below image for reference. Create action for button from storyboard to your ViewController.swift class. Enter following logics inside the action method to open app’s review page directly. Note : Change with your product url instead of <Your product url> in below code. Then append query parameter at the end of your url to open review page directly. See below code. @IBAction func reviewMeButtonPressed(_ sender: Any) {\r\nif let url = URL(string: \"&lt;Your product url&gt;?action=write-review\") {\r\nUIApplication.shared.open(url, options: [:], completionHandler: { (status) in\r\nif status {\r\nprint(\"Success\")\r\n} else {\r\nprint(\"Failed\")\r\n}\r\n})\r\n}\r\n} Run your app in device The app rating screen will present when viewDidAppear calls. The review page will open once you click your button, which we added a minute back. In this post we have seen the advantages of in app review feature and how to add that in iOS 10.3. In the upcoming posts we will see the other features that has been introduced in 10.3. Karthick S, Junior iOS Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-04-06"},
{"website": "Mallow-Tech", "title": "Importance of User Engagement in Google play rankings", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/04/importance-of-user-engagement-in-google-play-rankings/", "abstract": "Recently in the Game developer conference , Google announced that they are tweaking the algorithm for games discovery. User engagement will now be an integral part of the rating of the app for discovery. Previously only the star ratings given by the users and downloads had the major role. These metrics can easily be manipulated and bought and hence it lead many wonderful apps being hidden. Changes: Google’s move to bring in user engagement as a metric to rate the apps among the top is one of the best move in the recent times. They haven’t mentioned the same for other apps but it is evident that they bring in the same with all other categories as this will increase the reliability of the app. Also they have now planned to introduce flexible promotions to increase the exposure of the app. We hope that these changes soon might come to other categories. The key point to be noted in here is that Google is changing itself from the traditional metrics and giving importance to the metrics that matters. So if you are looking to build an app you must think in the way Google ranks. You need to satisfy the users and their ease and value offered plays a huge role. We have already discussed about the ways to increase the user engagement in an app. Significance: This move will bring in lot of changes among the top rated apps and relevant apps will get more attention. To make use of this, the app developers or the entrepreneurs should think in a way to make the app more relevant to the users rather than thinking on the click bait. The idea development has to have a strong root to make it successful. This change will help the original ideas flourish among the identical apps. Marketing Task: As far as the task of a marketeer is concerned the unique point of the app has to be communicated to bring the user to user base. It is then in the hand of the technical team who designed the app to convert as a successful venture. On the surface it looks like the job of the marketing team might be irrelevant but deep down it has shifted the work load from finished stage to market research. This is a crucial move to attain a value added app. As concluding note, we have seen clearly that the developers play the crucial role in the success of an App Venture. So if you are outsourcing your app development make sure that the developers keeps this algorithm in mind. You can check our post on the things to keep in mind before developing an app . This will give you an insight about the way we work. We have developed numerous apps in varied domains. – Marketing Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-04-04"},
{"website": "Mallow-Tech", "title": "3 Key factors defining the future of Mobile Apps", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/03/3-key-factors-defining-the-future-of-mobile-apps/", "abstract": "According to the statistical report by statista.com among the 462.1 million internet uses nearly 442.7 million uses internet via mobile phones. This shows clearly the need to optimise the usage to suit the mobile users. Also among the mobile users, it is seen that 90% of the time spent is in the apps. This has pushed the mobile browsing bit back due to availability of apps for all uses. Here are some interesting info regarding app usage statistics as in the year 2015_ Men in average spend 3 hours 45 minutes per month in mobile web and 29 hours 32 minutes per month in apps. Women in average spend 3 hours 46 minutes per month in mobile web and 30 hours 58 minutes per month in apps. Today, mobile devices available for both Android and iOS come with massive inbuilt storage which allows the user to install more apps in the devices. Earlier, most utilities like booking movie tickets, news updates and general search were done through traditional browsing and activities were accessed through web pages. But currently the scenario is changing, the number of apps available in App store/Play store is gradually increasing in a good phase and people are slowly migrating to apps from webpages. The preference is increasing as the apps are just a touch away. Hence, there is a shift in usage pattern of users. It is observed that mobile users are more inclined to apps rather than web pages. Necessity for Business Apps: A business has to create an app so that it optimises the usage the mobile users and helps in creating a brand value. In the year 2016, the number of smartphone devices shipped globally was 1,959 Million. This proves the necessity to create apps for the business and increase the reach of the product. A mobile app plays an important role for a business: Serves as a direct marketing channel Provides value to customers Builds brand and recognition Understands the customer’s need Improves the engagement with customers Builds/Boosts customer loyalty It will become a basic necessity for a business to create an app in order to band together with their customers and build the brand value. In order to survive in the competitive market, an app can play a major role for a business in future. In order to make the App experience better and help in making the business run, 3 key factors are considered. These three factors play a huge role in defining the contribution of App to the business. They are App Analytics Cloud Enabling Digital Assistance App Analytics: Analytics helps in understanding the real status of the application. One cannot judge the performance of the application based on the downloads alone. Majority of the apps are not even used more than 90 days and are uninstalled sooner. It doesn’t affect the download count too and hence the right metrics are needed to understand the performance. When you have the data you can focus more on what the users need and remove the unwanted features which are not used by an individual. In the future, businesses will have their hands on behavioural data like never before. This will help businesses to analyse and improve the mobile app experience to become more interactive. Enable cloud: Google is already coming out with this idea called Instant apps. Instant apps make the mobile app available to the customer without downloading it. The app is streamed to the user like a web page content. This streamed content still functions like the traditional mobile apps. This cloud-enabled service will be a hybrid between standalone “app” and traditional “website” as a form of content experience into Instant apps . Digital assistance on mobile apps Digital assistants seem to have a greater scope of development in the future course of time. Digital assistance will change the way a user use a search engine to a more of an assistant based search in future. Presently, digital assistant apps like Siri and Ok google are in the nascent stage of development. These apps are popular and getting much smarter every year. Apps like Allo, which is integrated with Google’s digital assistant is a good example for the digital assistance apps that are available now. This is the hot area of development in the present trend. Based on the trend it is clear that digital assistance will become a dominant one in the market. The biggest strength in integrating Digital Assistant gives a personal touch to the user thus giving an edge over the competitor. – Business Analyst Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-03-30"},
{"website": "Mallow-Tech", "title": "How to Send Push notifications using Laravel and AWS SNS", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/03/how-to-send-push-notifications-using-laravel-and-aws-sns/", "abstract": "Push notification is the process of delivering information from the back end application to end user’s mobile device without any request from the end user. We can send the push notifications from Laravel application using AWS SNS service easily. AWS SNS (Simple Notification Service) is a flexible, fully managed push notification service provided by Amazon web services. Using this, we can send messages to individuals or large numbers of recipients. Amazon SNS makes it simple and cost effective to send push notifications to mobile device users, email recipients or even send messages to other distributed services. In this blog, we will see about sending push notifications to android devices with FCM (Firebase Cloud Messaging). FCM is a cross-platform messaging solution that allows us to send messages for both Android and Apple devices. Implementation Step 1 : Firstly, we need to create an project in Firebase and get the Legacy server key for Cloud messaging. Step 2 : Then create an application in AWS SNS with GCM platform. It will create an ARN for your application. Then add the this ARN in your .env file ANDROID_APPLICATION_ARN=arn:aws:sns:us-east-1:9273842649560:app/GCM/Test-Application Step 3 : In laravel, We need to use the following package, https://github.com/aws/aws-sdk-php-laravel This makes the developers to access Amazon Web Services in Laravel code. And Add your AWS credentials in aws.php config file. Step 4 : Then we need to get the device tokens with the corresponding platform (Android) from User App. Here, we have got the device token and generated the end point ARN for our Mobile using the Android application arn and stored in the database. Step 5 : Finally, we can send Push notifications using the already generated end point ARN. We can also pass the the custom data through push notifications. It is more efficient if you send notifications using queues. More about queues, refer this link https://laravel.com/docs/5.4/queues So in this post we have seen in detail about how to send a push notification to Android Devices using laravel, FCM and SNS. In future posts we will see some other feature that can be integrated with Laravel and AWS so work in perfect manner. Anandhan S, Junior Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-03-28"},
{"website": "Mallow-Tech", "title": "iOS and watchOS – A comparison for beginners", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/03/ios-and-watchos-a-comparison-for-beginners/", "abstract": "It has been almost 22 months since the introduction of watchOS and there are a lot of useful watch apps in the AppStore. The development for watch has been considerably increasing, especially health apps. While learning watchOS, I started noticing certain similarities and differences between iOS and watchOS and wanted to present them here. First, I would start with the way watch apps are organised. They are built as extensions to iOS apps. Unlike iOS, there are two bundles: Watch app and WatchKit extension bundles. An interesting fact here is: separate targets are to be created for each of the bundles and it becomes harder when we realise that we need to have separate bundle IDs and profiles too. Thanks to the Automatic Signing in the latest releases of Xcode(8.0,*), we need not spend much during the development phase. AppDelegate : iOS :: ExtensionDelegate : watchOS: The ExtensionDelegate(not necessary to have the same name, you can have your own name, but make sure it extends WKExtensionDelegate protocol) does the work for the watch similar to what AppDelegate does for the iPhone/iPad. It has got similar functionality in: applicationDidFinishLaunching applicationDidBecomeActive or applicationWillResignActive applicationWillEnterForeGround or applicationDidEnterBackGround Image Courtesy: developer.apple.com LifeCycle The watch app can be supposed to be at different states like Active, Inactive, Background, Suspended similar to iOS. If the app goes to background, the time taken for it to get suspended is very less when compared to iOS. Performance: Unlike the iOS app, it is not considered wise to build long running apps since watch apps interact with the user for just a short duration. Also, background tasks are to be avoided. Once the app goes to background, it gets suspended sooner. For a larger variety of apps, Apple watch apps are considered to have sufficient information and not the entire iOS app. Communication: To share data with the companion iPhone app, there are two ways possible: NSUserDefaults – we can store data in shared user defaults. Shared Coredata But in order establish communication between the watch app and the iOS companion app, Apple had introduced a framework called WatchConnectivity. Using this framework, we can send data to and from watch app and iOS app. DataBase: Watch has now got its own DB. Earlier, the data was shared between the iPhone and watch. But now, in addition to sharing, we can also create a local DB for watch and iPhone separately. This makes persistence easier from the watch. Controllers: The job of a viewController in iOS is to manage the views and provide data to them from the models. The same is done by interfaceControllers in watchOS, but instead of “views”, they are termed “interfaces” and the controllers need to extend WKInterfaceController. It has got 3 important methods which are overridden for proper usage: init awakeWithContext – to load data – (analogous to viewDidLoad of iOS) willActivate – to do last minute updates – (analogous to viewWillAppear of iOS) Interfaces vs Views: There is no UIView in WatchKit. This introduces a lot of difficulties if we want to use a customized UI. Instead, we have been provided with WKInterfaceObject which is similar to UIView but with a lot of restrictions. One main disadvantage is that: “We cannot assign user-defined subclasses for interfaces created in the storyboard.” As another negative, “We cannot set constraints between elements in the storyboard”. The elements are adjusted automatically depending on the orientation we specify. They are adjusted either horizontally or vertically. Instead of UIViews, we can also have groups(WKInterfaceGroup, a subclass of WKInterfaceObject) which provide the same functionalities as views. But the constraint restriction is also present here. So the major difference is regarding the layout system. Also, when we try to align an element using left, top, right, bottom, centre, the system chooses a position on its own relative to the surrounding elements. To set up a custom UI, groups play an important role. We can have multiple groups in different combinations, one inside the other and along with the top, left, right and bottom constraints to make the UI we want. There are few other drawbacks like: there is no background image for the buttons. But buttons can be considered as a single object or a grouped one. In case of a grouped button, we can have at most 1 element as a child. These might seem a bit harsh on Apple from the developers’ point of view. But one thing we need to keep in mind is that Watch is a tiny device and whatever we show on it should be short, simple, but complete. That is one of the reasons why Apple has not let the developers take advantage of the SDK to make the watch so much customized. Or else, the basic purpose of the development of watch apps – Fast and Simple Interface – gets ruined. Apple watches have a force touch capability like 3D touch for iPhones of latest models. A menu appears on the screen and the user is asked to choose one action to perform. This can be done inside the app as well. An important concept present in Apple Watches is the Complication. It displays the details of the app on the watch face. A watch face is what a user sees when he opens or activates the watch. There is an option to keep the complications updated regularly. For example, a weather app might show, the current weather at the location where the watch is present or the next remainder along with the timing, etc. A close similarity with iOS can be found in the Today widgets. Complications are not the same as Today widgets, but their purpose is the same. Sriram K, Junior Developer iOS Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-03-23"},
{"website": "Mallow-Tech", "title": "Getting started with RxJava on Android app development", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/03/getting-started-with-rxjava-on-android-app-development/", "abstract": "RxJava is basically a library that helps the programmers to work on the asynchronous applications. In this post we will be seeing about Reactive programming and how it can be implemented with the help of RxJava. First of all let us see what is reactive programming. Reactive programming is a method of programming where you define a source and a consumer. The source and receiver is then connected through. The source generates data required and then the consumer needs the data to process, this is when RxJava comes into the picture. Once the consumer and the source are connected then the library will take care of pushing the data and henceforth. 1) Observable – source 2) Subscriber – consumer 3) Subscribe – connect Below we will see in detail about the source, consumer and the connect using subscribe. Observable and subscriber class: Observable is a stream abstraction in RxJava. Observable class emits a stream of data or events. Subscriber class on the other hand acts upon the emitted items. Observable is to emit one or more items, and then completed successfully or with an error. Observable can have multiple subscribers, and each item emitted by the observable, the item will be sent to the Subscriber.onNext() method to be handled. Once Observable finished emitting items, is call the Subscriber.onCompleted() method, else call the error the observable will call the Subscriber.onError() method. Observable integerObservable = Observable.create(new Observable.OnSubscribe() { @Override public void call(Subscriber subscriber) { subscriber.onNext(1); subscriber.onNext(2); subscriber.onNext(3); subscriber.onCompleted(); } }); Observable has emits the integers 1, 2, and 3 and then completes. Now we need to create a subscriber so we can act upon the stream of emissions. Subscriber integerSubscriber = new Subscriber() { @Override public void onCompleted() { Log.d(“Subscriber”, “onCompleted: ” + true); } @Override public void onError(Throwable e) { } @Override public void onNext(Integer value) { Log.d(“Subscriber”, “onNext: ” + value); } }; Subscriber will simply print out any items emitted and notify us upon completion. Once you have an Observable and a Subscriber you can connect them with the Observable.subscribe() method. integerObservable.subscribe(integerSubscriber); // Outputs: // onNext: 1 // onNext: 2 // onNext: 3 // Complete! Observable code can be simplified by using the Observable.just() method to create an observable to emit only the values defined, and changing our subscriber to an anonymous inner class, we get the following. Observable.just(1, 2 ,3).subscribe(new Subscriber() { @Override public void onCompleted() { Log.d(“Just”,”Completed”); } @Override public void onError(Throwable e) {} @Override public void onNext(Integer value) { Log.d(“Just”,”onNext: ” + value); } }); Operators: Creating a subscribing to Observable is simple enough, and may not seem overly useful, but that is just the beginning of what is possible with RxJava Observable can have its output transformed by what is called an Operator. Multiple Operators can be chained onto Observable. Observable.just(1, 2, 3, 4, 5, 6, 7, 8) // add more numbers .filter(new Func1() { @Override public Boolean call(Integer value) { return value % 2 == 1; } }) .subscribe(new Subscriber() { @Override public void onCompleted() { System.out.println(“Complete!”); } @Override public void onError(Throwable e) { } @Override public void onNext(Integer value) { System.out.println(“onNext: ” + value); } }); // Outputs: // onNext: 1 // onNext: 3 // onNext: 5 / onNext: 7 // Complete! In filter() operator defines a function that will take in our emitted Integer values, and return true for all odd number, else false for even number. the event number return false from our filter() function are not emitted to the subscriber. Thus we have seen a sample program of how to define a source and consumer with observable and subscriber class and how to to connect them with the help of Subscribe function. This post will give you a clear idea about the way of incorporating reactive programming with the help of RxJava on Android platform. Manikandan, Android Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-03-21"},
{"website": "Mallow-Tech", "title": "Design and Architectural Patterns in Android – An Introduction", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/03/design-patterns-in-android-an-introduction/", "abstract": "A design pattern can be defined as a general repeatable solution to a commonly occurring problem in software design. It won’t be the exact solution whereas it would just give a template to solve a solution. Why design patterns? •They give the developer a selection of tried and tested solutions to work with •They are language neutral and so can be applied to any language that supports object-orientation •They aid communication by the very fact that they are well documented and can be researched if that is not the case. •They have a proven track record as they are already widely used and thus reduce the technical risk to the project •They are highly flexible and can be used in practically any type of application or domain Types of Design Patterns: Creational Patterns These design patterns provide a way to create objects while hiding the creation logic, rather than instantiating objects directly using the new operator. This gives the program more flexibility in deciding which objects need to be created for a given use case. Structural Patterns These design patterns concern class and object composition. The concept of inheritance is used to compose interfaces and define ways to compose objects to obtain new functionalities. Behavioural Patterns These design patterns are specifically concerned with communication between objects. Two main reasons for many codes to be in such bad shape is, 1. Continuous changes in UI. 2. Lack of an architecture that supported the flexibility that we needed. Architectural patterns are used to overcome these problems. Architectural Patterns in Android: The three most commonly used Architectural Patterns in Android are MVC(Model View Control) MVP(Model View Presenter) MVVM(Model View View Model) Model: The Model represents a set of classes that describe the business logic i.e. business model as well as data access operations i.e. data model. It also defines business rules for data means how the data can be changed and manipulated. View: The View represents the UI components like CSS, jQuery, HTML etc. It is only responsible for displaying the data that is received from the controller as the result. This also transforms the model(s) into UI. MVC(Model View Control): The Controller is responsible to process incoming requests. It receives input from users via the View, then processes the user’s data with the help of Model and passing the results back to the View. Typically, it acts as the coordinator between the View and the Model. The Architecture of MVC is given below. MVP(Model View Presenter): The Presenter is responsible for handling all UI events on behalf of the view. This receive input from users via the View, then process the user’s data with the help of Model and passing the results back to the View. Unlike view and controller, view and presenter are completely decoupled from each other’s and communicate to each others by an interface. The architecture of MVP is shown below. MVVM(Model View View Model): The View Model is responsible for exposing methods, commands, and other properties that help to maintain the state of the view, manipulate the model as the result of actions on the view, and trigger events in the view itself. Simply any change that takes place within the model will be automatically updated in the view itself. The Architecture of MVVM is shown below. Thus we have seen about design patterns in details and in specific saw about the design patterns used in Android. Next week we will come up with another interesting topic to explore. – Raasesh R, Android Junior Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-03-16"},
{"website": "Mallow-Tech", "title": "5 hurdles in software testing to be taken care of", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/03/5-hurdles-in-software-testing-to-be-taken-care-of/", "abstract": "Testing is an important phase before launching of the product. Testers face many drawbacks during this phase that might delay the release and reduces the efficiency considerably. Perfecting the product is done in this phase and apart from the regular difficulties, there are a lot of traps present. In this post, we are going to see in detail about the five of the most important hurdles in software testing. The direction of testing: This is one of the most common hurdles a tester will have to face. When a product is entering a testing phase there will be numerous opportunities and possibilities to approach the product. Especially if the product and technology involved are complex, then its direction is lost. This totally sabotages the process at its entirety. As the deadlines approach the process stumbles at many places. To deal with this issue, you need to look at the existing bugs and segregate them based on the criticality. Having a conversation with the project managers and getting their opinion on the critical factors helps a lot in designing your direction of the testing. Analyse the review documents, user manuals and guidebooks and get an idea about the information available to the end user. Tester has to think at the point of end users. Priority of the issue: You might have a checklist to approach the bugs and defects but you might just miss the obvious. Situations like these can be very embarrassing not only because you missed something that is so basic and so obvious but also because it happened when you were actually busy religiously following the test cases to find things just like these. In order cross this hurdle you need to prioritise the issue. And rather than following the test cases and test matrix as it is, ask yourselves which test case is important? Explore the things which are not covered in that test case. Check if it covers the critical functionality. Also, check if an alternative is available. This pretty much clears this hurdle. Deviation from Goal: Sometimes the team might be explaining about a feature and way it has to work, but you might not exactly get what they convey. This might cause a deviation from your testing goal. There is a high chance that if you missed the exact path of the feature you might test the same in a different way and the result might not be pleasing to the users. To overcome this hurdle all you need to do is just question the developers. Try to understand the core benefit of the feature. If you can understand the core benefit then you can approach the feature in a better way. Dilemma Bug: Dilemma Bug is nothing but you come across an issue but you aren’t sure that if it is a bug or not. What happens most of the times is the bugs you leave as nothing to worry will be seen a hurdle by the users. Overcoming this hurdle is simpler than many others, trust your instinct. If something is fishy then obviously it will present itself in front you. All you need is to observe the same. Reporting such bugs is far better than ignoring on some assumptions and later proves to be a major bug. Mental Block: This is one of the most common hurdles for any tester. There comes a situation where you don’t have a clue on what to test or how to approach the same. This condition of mind block stops your ability to find new bugs and defects. You will be redundant for a while. This is just a temporary stage though. This hurdle can be easily taken care. All you need to do is opt-in for a pair testing. Pair testing is nothing but two testers combine to perform the operation. By this, you don’t have to worry about the block as you will have another person to take care of pushing the envelope. Also stressing on thinking out of the box works perfectly at this. Also, you can change the approach of testing which gives you the push needed to move from the block. The above mentioned are the most frequently faced hurdles by the testers. As mentioned these hurdles have to be taken care of to make the product bug free. By following the precautions explained the process of the tester can be made easy and efficient. Kumaresan T, Testing Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-03-14"},
{"website": "Mallow-Tech", "title": "7 factors to increase the user engagement for your App", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/03/7-factors-to-increase-the-user-engagement-for-your-app/", "abstract": "Success or a failure of an app depends entirely on the user engagement of the particular app. In this post we are going to see in detail about the 7 factors that plays a major role in increasing the user engagement for your application. By concentrating on these factors you can easily improve the engagement of the user significantly. Core value proposition While developing an app, it is not advisable to bombard all the features at the same time. By doing so you might not know the user’s priority for each feature. Understand the core problem you need to solve and give the proper feature right. Then you can add other features on the go. This is because you should know the priority of the users. If you satisfy their most prioritised problem the chances are high for an user to use your app. Target audience You should be very much aware about your target audience. With the help of Analytics you will be able to see the demographics of the users and based on that you need to ensure that the app is serving the mindset and purpose of the particular target group. Knowing the sensibilities and preference of the target audience is so much important and the app has to be modified according to their needs. Another important thing is you need to ensure that the reach is high among your target group and also note response from the target group. Design Design or UX/UI forms the major factor in engaging the users. The colours, interaction and navigation plays a major role in engaging the user to use the app. If it hurts the eye or difficult to navigate and not smooth then user is put off and might not come back to use the app. The navigation has to be intuitive and simple. For example if you are creating a e-commerce app then the buy button has to near the right thumb in that way it makes it easier to click. This gives a huge advantage in converting the purchase of impulse buyers. Also any features for the user to get noted has to be intuitive and explicit. Keeping it hard to find makes the user reluctant to use again. Localisation Localisation gives a better feel to the target niche audiences. Localisation gives a personal connect to the users. If given an option between two equally good apps, the user always prefers the app with personal connect. Especially if you are targeting Russia, France and scandinavian countries presenting them the option of local language will give you an edge over the other apps. Push notification & Platform Optimisation Push notifications is one of the key factor that increases user engagement tremendously. Also with the use of proximity marketing you can give a push notification with special offers on particular place where the chances are high to agree. Also another major feature is using the features available in the platform to the fullest. For example, latest iOS introduced Siri with few changes and  integrating it with your app gives an edge over the other apps. If a new keyboard is released your app has to integrate features of it. Feedback Feedback is an important factor you need to concentrate to make the app user friendly. Its the users who have to convey the direction and the needs of the app. Also don’t frequently ask for user reviews for the app. It might just annoy the user from using the app on its entirety. Feedbacks has to be detailed rather than yes or no, these detailed feedbacks give more inputs than any other factor. Another important thing is that you need to be perfect and proper in responding to the feedbacks. You should convey the user that you take feedbacks very seriously. Analytics Analytics forms the backbone of any web or mobile application today. Metrics to be measured plays a major role in your Analytics. You need to concentrate on which metric to be measured. These metrics used in Analytics guides you in further direction of your app. You should note the screen in which maximum drop occurs and the reason behind the drop so to rectify it. Noting the frequently used feature can be given a shortcut for easy access. You should carefully analyse the data and make changes in the application. Updates Updates help you in keeping the app relevant among the ever dynamic environment. The updates had to be frequent, not once in a blue moon. It should add some value to the users rather than namesake updates. Also updates are the best possible way to give small changes that the users might like. This is a chance for you to delight to the users. Introducing exciting features that may not be the core priority can be done in this phase. Providing such updates and making the operation better makes the user engaged to the app. These above mentioned steps should be followed systematically for each app you have developed. If you follow these steps regularly, then the user engagement will increase considerably. This is a general systematic procedure to make your app substantial for the user. – Yogesh M, iOS Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-03-09"},
{"website": "Mallow-Tech", "title": "How to Configure & Install WordPress in AWS Instance", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/03/how-to-configure-install-wordpress-in-aws-instance/", "abstract": "Today there is surge in the hosting service providers and a large number of companies are providing shared hosting services. Majority of the small business websites opt in for the shared hosting services. In this there will be a monthly premium to be paid and you will get a predefined set of features. But if you need some advanced options and thinking of scaling, optimising and using your website for advanced features then Amazon’s Cloud is an option worth considering. One of the significant feature of the service is that it is easy to upgrade. Creation of a server machine won’t even take a lot of time. Also the biggest advantage in Amazon cloud is that you can instantly upgrade the servers to handle the jump in traffic any time. Balancing the surging load is not a complex task in here. If your site traffic is increasing tremendously then you need to upgrade your shared hosting services or move on to the specialised hosting services. It costs you a fortune. Amazon on the other hand gives you a great deal in designing a server architecture to match your needs. The beauty in it is you can do that on your own rather than hiring a network operations team in the most efficient way possible. This is the way most of the facebook developers have built their servers. Now the thing with WordPress is that it restricts some of the operations. So if you ever had a thought of rebuilding or rejuvenating your site with PHP or MySQL, you can do it by yourself. You don;t have to ask your web hosting company. You can install the software of your choice, just as you do in your own server. So, Be it WordPress or any other CMS, Amazon is the perfect choice for the site based on the traffic it receives. Also it depends on the value you give in configuring your server to meet your needs. Let us see in detail about creating an Amazon Wen services account and how to install WordPress in it. Step 1 – Create an Amazon Web Services Account Before starting to use Amazon’s cloud for your web hosting, you need to create an account with Amazon Web Services (AWS). Go to aws.amazon.com and click Sign Up Now button. If you have already used Amazon.com, you can use your existing e-mail and password to login to AWS. If not you can also create a new account by choosing “I am a new user.” At this stage, you have to give them your credentials such as contact info and credit card number for billing purposes of the services. Everything apart from creating an account costs you in this. The payment is on a hourly basis for the running server. But the actual price varies as it is a bit more complex than just calculating the running server. So you need to be careful in your price calculations before leaving the servers unattended to avoid the bills that bites your pocket. Building the WordPress setup shouldn’t take much time. We will stop everything when we’re finished, so the price for completing the tutorial will be nearly zero Dollars. Step 2 – Launch Your First Server Machine Setting up the server consists of two parts: Application server is hosted on Amazon’s Elastic Computing Cloud (EC2), running Apache and PHP, with WordPress installed on it. MySQL database hosted on Amazon’s Relational Database Service (RDS). There is another cheaper option is to manually install the MySQL server on the machine with Apache and PHP. This method is bit difficult than the previous one but saves you a few dollars. We will see the Relational Database Service as it eases your work. Also in this way you don’t have to worry about the backups, database maintenance as Amazon will take care of that. Also Amazon will take care of the additional security too. Let us start by creating the first application server instance. Click on the EC2 tab in the AWS Management Console. As this will be your first time using the EC2 service, you will need to separately sign up. Click on the “Sign Up For Amazon EC2″ button as shown below Amazon will verify your identity by placing a call to your phone for security purpose. This process is automated: you type a code from the web page into your phone and, once the system has verified that the codes match, you will be then redirected to the next page. When you are done with the sign up process, return to the Management Console and the EC2 tab. Click on the Launch Instance button in the page as shown below. A popup with a list of Amazon Machine Images (AMIs) opens. (AMI’s are basically the snapshots running computers) Most consist of an operating system and a few utilities, but you can also create AMIs with as much complexity as you wish for — even containing your full application, ready to be started on a virtual machine with just a click. In here we will pick the most basic option: “Basic 32-bit Amazon Linux AMI 1.0.” Click on “Select” next to the AMI and you are ready to go. After selecting the AMI, our next step is to decide what kind of hardware we will use to run it. Depending on whether you picked a 32-bit or a 64-bit AMI, you will see a different list, the 32-bit AMIs offering the cheaper options. For testing purposes, we don’t need much of a memory or processing power, so we will start with a Micro instance. Select the instance type and click “Continue.” In the next screen, the defaults do just fine. Click “Continue.” If you have many machines performing different roles, there is a good chance to mixup the machines. Hence naming the machines will help is tracking the work. In this particular case naming is not too important, as we will run only one EC2 instance, but it is better to name it for future reference. Enter your desired name and click “Continue.” Next, you will be asked to create a key pair file for securely connecting to the machine. This key replaces a password when connecting to the machine with SSH. Name your key pair file, and click on “Create & Download your Key Pair.” Copy the key pair file to a safe location (A good place, if you are on a Unix system such as Mac OSX or Linux, is ~/.ssh). After copying the file, change its permissions to 400: chmod 400 wordpress_demo.pem If you are using Windows, you probably use PuTTY for SSH. PuTTY uses its own key format (ppk), so you will need to convert the key to that format by using the Puttygen tool available at the PuTTY download page. After you’ve created the key pair, you will still be asked to configure the firewall for your new machine. By default, no one is allowed to connect to the machine — every port is closed. Let’s open ports 22 (SSH) and80 (HTTP), so that we can configure the machines over SSH and access the blog from the browser. Select the type of connection from the drop down list at the bottom of the popup and click on “Add Rule.” When you are done with the setup, click “Continue.” Review the configuration and if everything is fine then click “Launch” button. Now the server machine is launching! Close the popup in order to return to the dashboard. At first, you’ll notice that the instance’s status is set to “pending,” and within a couple of minutes it switches itself to “running.” This means the server is up and running — you can start of the operations now. When the machine is running, it can be accessed through the defined ports in the firewall configuration. Let’s use SSH to connect to the machine and finish its setup by installing Apache, PHP, the MySQL extension to PHP, and finally WordPress. Step 3 – Install Required Server Software In this we will see the steps to install the required server software. Firstly right click on the particular name of the machine and select connect from the drop down list. A popup will open with an SSH Command. Highlight the command, and copy it to a console if you are using a Mac or a Unix machine. The command will be similar to the following: ssh -i wordpress_demo.pem root@ec2-….compute-1.amazonaws.com If you saved your pem key to ~/.ssh, update the path in the command. Also, you need to change root into ec2-user — Amazon hasn’t yet updated the command to match its new AMI setups that don’t allow connecting with the root user. If you are on Windows, or prefer to use a more graphical SSH application, simply copy the name of the machine and open it in your SSH application of choice. Remember to use the user name ec2-user and the related key pair file (wordpress_demo.pem). Once logged in, you can use the virtual machine just as you would use any Linux machine. To install software, we will use an easy to use installer called Yum. First, to install the Apache web server, type the following command: sudo yum install httpd The installer asks you to confirm the package to install and possibly some other steps as well. Reply with “Y” to every question, and, in no time at all, you will have Apache installed. Next up, PHP: sudo yum install php And the same for the MySQL extensions: sudo yum install php-mysql this marks that the setup is done and we are ready to test Apache. Start it with this command (you can later replace “start” with “stop” or “restart” depending on what you want the web server to do): sudo /etc/init.d/httpd start The web server is up, and you can test it by copying the URL of the machine to your browser: Step 4 – Create the Database Machine: Before installing WordPress, we need a database. Setting up a database using RDS is simple process. In your AWS console, switch to RDS tab. As you have never used this particular service before, you will be asked by AWS to enable it. This time, the process is much faster and simpler than when you enabled EC2. Click on “Sign Up For Amazon RDS” to get started. Follow the process through and, when you are finished, head back to the RDS tab in the AWS console. The screen you will see looks a lot like the EC2 console we used in the previous step. Click “Launch DB Instance.” In the popup that opens, you can choose the properties for the database server to start, such as the server instance and storage space to allocate. Let’s pick the smallest values as they are more than enough for our simple test. Pick a name for you database server and the root user on it. I used “wordpress-db” as the database server name and “root” / “rootpass” as master login. Not the most secure of options, mind you, but this machine is not intended to last for long, so it’s okay in this instance. After setting up the database server information, you will be asked to define a default database to be created on the server. We will call it “wordpress” to follow the WordPress conventions. The rest of the settings on this screen can be left untouched. On the next screen, you can define settings for database backups. For now, leave the values to their defaults and click “Continue.” After verifying the settings, click “Launch DB Instance.” Creating a database instance takes quite a bit longer than creating the EC2 instance, but after about five minutes of waiting, you should see the database instance as “available” on the instances tab. Click on the instance to see more data about it, then copy the “endpoint” value. This is the URL of the database server that we will use in the WordPress setup. There is one more step before we can move on to installing WordPress: we need to configure the firewall for this database so that the application server can access it. Still on the RDS tab in the AWS console, click on “DB Security Groups.” You will see that there are no authorizations yet: To give our application server access to the database, we need to authorize its security group to this database security group. Select “EC2 Instance” from the drop down list below “No Authorizations” and enter the name of the security group (“wordpress_app_server“) and your Amazon Account ID to the two text fields that appear next to the drop down list. The account ID is hidden quite deep in the AWS settings: you’ll find it by first clicking the “Account” link at the top of the page, and then the “Security Credentials” link on the page that opens. After you’ve entered the required information and clicked “Add,” you will see the security group as authorized. We are ready to install WordPress. Step 5 – Install WordPress: If you are not connected to the application server anymore, open an SSH connection to it again. We’ll start by downloading WordPress on the machine. By default, Apache is configured to look for HTML files from/var/www/html/, so let’s download WordPress to that directory. view plaincopy to clipboardprint? cd /var/www/html To make things easier in the future, we will change ec2-user to be the owner of that directory: sudo chown ec2-user . You can download WordPress to your own computer and upload it from there using SCP, but I find it easier to download it directly to the Amazon machine using wget: view plaincopy to clipboardprint? wget http://wordpress.org/latest.zip This way, the WordPress package goes straight to its final location and all you need to do is to unzip it: unzip latest.zip We are about ready to start configuring the blog. As our last step in the command line, change permissions of the wordpress directory that was just created so that the installation script can create the wp-config.php file: chmod o+w wordpress Now, open the WordPress URL in your browser (The URL of the EC2 instance followed by /wordpress). Click on “Create a Configuration File” and then on the next page “Let’s go!” You will end up on a page for entering the database settings. Enter the database name, user name and password, and the URL of the RDS instance. Then click “Submit.” ( image 27) You are almost set. Configure the rest of the blog details to finish the installation and enjoy your newly created blog. You have successfully installed WordPress in the cloud! Step 6  – Stop Everything As I mentioned at the beginning of this tutorial, AWS billing is based on the hours of usage, so to make sure you are not billed for time that you are not really using, make sure to stop everything once you are done testing. First, stop the EC2 instance by selecting it from the admin, right clicking on it and choosing “Stop.” If you later decide to start the machine again, all you need is to click on “Start” in the same drop down list and the machine will resume from where you left it. Stopping the database is just as easy, with the exception that you can’t resume the database again. That’s not so nice, but luckily you have the choice to save a snapshot of the data while stopping the database. You can later use this data to recreate the database setup whenever you need it again. On the RDS tab, right click on your database instance and select “Delete.” Verify that everything is stopped and log out of the AWS console. Your blog is gone, just as fast as it started. – R. Rajesh Networking Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-03-07"},
{"website": "Mallow-Tech", "title": "5 factors to consider before outsourcing your app development", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/03/5-factors-to-consider-before-outsourcing-your-app-development/", "abstract": "There is always a dilemma whether to outsource the app development or develop in house. Outsourcing an app development gives you numerous advantages. If you have a complex app to be developed , lot of domain expertise needed. Going to a outsourcing partner is wise choice in situation like this. Before choosing your outsourcing partner you should consider these following factors . Let us see those 5 factors to be considered in detail below. Expertise of the developers: You are primarily opting for the outsourcing option so that the app has to be built by the experts. The development team should be well versed with technology and platform in which the app to be developed . The versatility in handling the complex problems have to be studied in a detailed manner. You should explore their portfolio to understand their spectrum of their work. Reputation of the organisation: Another big factor to be considered is the reliability of the organisation. Their reputation in quality, business and professionalism matters the most. So you might wonder what does it have to do with the product, it basically has everything to do with the product. You are trusting your business model and operation with the company, hence they have to earn the trust . So another big question is how to find that? You cannot just randomly rely based on the reviews alone. Having a talk with them gives you a better idea. Quality of the product: Developing a quality product relies on the domain expertise. If the team has no prior experience in particular domain then check the versatility of other apps . If they have proven their versatility in developing complex apps then they can trusted . Check the quality of the apps they have developed for others. Communication of the team: Communication not talks about the language expertise of the team but it speaks about the understanding your core idea . The team might be well versed with the language but if they can’t grasp and visualise your idea then the final outcome might not be as expected . It is very important that the communication is clear. There shouldn’t be a gap between the expectation and result. You need to check if the teams can visualise your ideas . You can check that by wireframes creation. Cost efficiency: This is one of the important factor to be considered before choosing an outsourcing partner . Opting for a low cost developer is entirely different from partnering with a cost efficient development team . Some firms offer a very low per hour cost but ends up costing you more than you might have spent with a better developer . Also the method of development plays a major role in this. It is advised to opt in for a waterfall method at the initial phase so that you can understand the working methodologies of the company. Once you get enough trust on the development team, then you can move to Agile method of development. These are the 5 most important factors to be considered before choosing an outsourcing partner for your app development . – Marketing Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-03-02"},
{"website": "Mallow-Tech", "title": "Introduction to AWS and its services – III", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/02/introduction-to-aws-and-its-services-iii/", "abstract": "You can check out the first and second part of the posts discussing the IAM, Lambda, CloudFormation and API Gateway . In this post we will see in detail about the S3, Aside and DynamoDB. What is S3? S3 expanded as  “Simple Storage Service” and helps you in storing the data in Amazon cloud. This data can be anything ranging from photos, codes, zipped music archives and so on. AWS ensures that the infrastructure is administrated so that you can always access your files hassle free. Furthermore you have “infinite” storage available. This means that you don’t have to think about the size before designing your infrastructure. From then on its just uploading the data. Permission management, revisions and many more can also be implemented in S3. You can define who can access what at every time. You don’t even have to worry about accidental removing of some data. You can restore it easily (although you have to enable it when creating your bucket). Apart from the web console you can use standardised protocols to upload and access your S3 data. Buckets: Buckets helps you in organising your files. Just create a bucket (e.g. „photos“) and upload everything related there. Permissions, Revisions and other settings can be defined on a bucket level. So you can e.g. share your photos online while keeping your uploaded code files (in your „code“ bucket) as a secret. How Serverless uses S3: Up until v0.4 Serverless uses S3 as a storage for your project related code (such as e.g. Lambda functions). Upon project creation Serverless creates an S3 bucket for your project where everything related is uploaded. The bucket also functions as a backup. This way you can still access your Lambdas even if your development machine burns down to ashes. Serverless has removed the S3 bucket dependency in v0.5 (Recently the maximum storage space for Lambda functions was increased. Hence there is no need for a separate S3 bucket which stores all the versioned Lambdas). But you could still use S3 buckets to e.g. host your fronted which talks to your Serverless backend. What is DynamoDB? DynamoDB is basically a NoSQL database service with nearly infinite scalability and flexibility. NoSQL means that you don’t have to specify a schema which declares what kind of data you store (like you would do when you use a relational database). You simply have to create a table which should hold your data and store the data. With DynamoDB you can store key-value or document based data inside those tables. The concept of NoSQL data stores is relatively new compared to old, relational based database technologies. Recently more and more data was generated that needs to be stored and analysed in a flexible and easy was. NoSQL databases try to target those needs. DynamoDB related databases are e.g. CouchDB or MongoDB How Serverless uses DynamoDB: DynamoDB is not used per default in Serverless. However you should definitely consider DynamoDB for your database operations as it nicely integrates into the whole AWS system. Aside: Regions Amazon web services can be deployed to various regions. They are split up geographically. You should choose a region near to you or your users to keep response time low as possible and your app performance snappy. Furthermore regions makes it possible to create a redundant and fault tolerant application infrastructure. It’s no problem if a datacenter in Oregon is on fire if you have another deployment in Ireland. Serverless makes it easy to deploy your Lambdas into multiple regions Which makes it possible to spread the app across the globe. This concludes the three part series explaining the services of AWS and how it can be of a greater use to the business around the globe. – R. Rajesh Networking Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-02-28"},
{"website": "Mallow-Tech", "title": "Introduction to AWS and its services – II", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/02/introduction-to-aws-and-its-services-ii/", "abstract": "In our previous post we saw some of the fundamentals of AWS and an introduction on IAM and Lambda . In this post we will see more about Lambda, CloudFormation and API Gateway. Advantages of Lambda: The best thing about Lambda is that you don’t have to manage the servers or the infrastructure to run your code smoothly. Amazon will take care of every other issues. It essentially means that you don’t have to think about issues such as security updates for your OS, scalability, availability. It doesn’t matter if you have n number of users who hit your function. No slow responses or downtime due to overwhelming customer engagement. Also, you only pay for the time your functionality runs. This reduces the costs of your application considerably greater. They analyzed one production ready app (16000 requests / day @ 200ms avg. response time) and calculated how much it would cost when hosting it with EC2 in contrast to lambda.The results are astounding: Two EC2 instances $2.97 / day Lambda $0.05 / day This difference pretty huge, and imagine the amount earned if implemented in a large scale. Different runtimes Lambda supports different runtimes as well. As of now, Node.js, Python and Java are supported. This means that you can develop different parts of your application with different programming languages. Maybe your user management is better realized with Python while your other team works on a Node.js / JavaScript implementation of your users status updates. No problem! All can be done perfectly without much of a confusion. What is CloudFormation? Back in the starting days of AWS you would login to your AWS account and configure everything manually. You’ll have to create the necessary resources like S3 buckets, policies and users / roles and then orchestrate them to make it functional. The problem with this approach is that nothing is (obviously) automated. You can’t share and recreate an infrastructure from scratch without spending a huge amount of time configuring everything. CloudFormation was developed by Amazon to overcome these limitations. How does it look like? Here’s a simple example: { “Version”: “2012-10-17”, “Statement”: { “Effect”: “Allow”, “Action”: “s3:ListBucket”, “Resource”: “arn:aws:s3:::example_bucket” } } The CloudFormation templates are defined with the help of JSON. This makes it quite easy, accessible and understandable if you have experiences with JSON. It also makes it very easy to interact with the templates in your favourite programming language. If you have no experience with JSON you can make use of the AWS CloudFormation designer to design your templates in your browser. The designer generates the JSON which you can then use for further processing. Note: The usage of CloudFormation is free, but you’ll have to pay for the resources you’ll define in your template. What is API Gateway? API Gateway is another great service available through AWS. Nearly everyone who has developed an application has to face the task to defining an API. Now the bigger question is what is an API in the firsthand? An API (application programming interface) is a service you’ll develop so that other users / applications can access certain data of your application. Imagine that you have developed the next social network and you want to enable other developers to use the data of your network to build cool new applications around them. You can expose the content with different markup languages (the most famous ones are XML or JSON). Now the question is How does API Gateway helps you in this. As soon as you have started to develop your API you might have encountered hurdles. What about versioning? Should it be RESTful? How do I implement a RESTful API? How do I handle different stages (development, testing, production)? These are the innumerous questions that ponders at this stage. API Gateway is Amazons answer to target those pain points. It makes it easy to version APIs, monitor events (like usage of a certain API method), scale the API independently, roll out APIs for different stages and create RESTful services. How Serverless uses the API Gateway The Serverless framework uses API Gateway to help you setup routes to your Lambda functions. You can e.g. perform a GET request and fetch all related data which is then available in your related Lambda function. The API Gateway is the trigger which causes your Lambda function to run. In the upcoming posts we will see in detail about the S3 and DynamoDB. – R. Rajesh Networking Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-02-23"},
{"website": "Mallow-Tech", "title": "Introduction to AWS and its services – I", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/02/introduction-to-aws-and-its-services-i/", "abstract": "In this blog post series we’ll take a closer look at Amazon web services (AWS) and all their  services in detail. We’ll start with an overview what Amazon web services (AWS) is and what you’ll get if you use them. Amazon Web Services (AWS) is a collection of cloud based web services you can use for a monthly fee. It was invented when Amazon faced scaling issues with their retail website in the early 2000s and opened up to the public crowd in 2006. Today AWS is one of the largest cloud providers and powers a huge amount of the internet (e.g. Netflix, Airbnb, Pinterest or Slack). Here are some case studies if you’re interested how AWS helps companies scale their business. The available services range from servers (EC2), to storage (S3) up to devices you can use to test your applications (Device Farm). If you want an overview what’s available you should check out their product page which lists and structures every available service. Don’t get too confused about the overwhelming number of services you can rent. Understand AWS as a service provider where you have access to different services you need while developing a modern application. Sounds interesting but you don’t want to spent a bunch of money monthly to play around and get used to their services? Amazon has you covered. There’s a very attractive starter plan available which allows you to play around with their services for free. I’d recommend that you’ll sign up for the free account so you can use the full potential of the framework and see the power of modern, applications. What is IAM? In this blog post series we’ll take a closer look at Amazon web services (AWS) and all their related services in detail. Today we will be looking at IAM (Identity and Access Management). What is it? How does it work? And how does the framework use it? IAM stands for “Identitiy and Access Management” and makes it possible to control access to your AWS services and resources. IAM has different methods to control the access to AWS services. Users Create users if you want to grant other users access to your AWS account without sharing your login credentials. Groups Groups make it easy to manage access for multiple users.You could e.g. create a “servers” group with permissions to spin up EC2 instances and add multiple users to this group. This way the users in this group can create EC2 instances. Changes to permissions in this group affects all users who belong to that group. Policies With policies you can define permissions for users, groups and roles. Policies are the building blocks to define what action can be performed for what resource. Let’s take a look at a simple policy: { “Version”: “2012-10-17”, “Statement”: { “Effect”: “Allow”, “Action”: “s3:ListBucket”, “Resource”: “arn:aws:s3:::example_bucket” } } One can see that policies are defined with the help of the JSON syntax. With Action you tell what kind of actions are allowed (in this case List S3 bucket). Resources defines what resource this action affects (Here it’s the S3 bucket with the name example_bucket) Effect can either be “Allow” or “Deny”. You can read the policy above as follows: “Allow to list the stuff in the S3 bucket with the name example_bucket“. If you attach this policy to a user, this user will be allowed to perform this action. If you attach it to a group all users in that group can perform this action. Roles Roles are similar to users as they hold an AWS identity with permissions. Roles are often used if you e.g. want to grant access to AWS resources that the user normally doesn’t have. Another scenario would be that you want to grant an application access to your AWS resources without exposing your AWS credentials. Identity providers Identity providers enables you to let users gain access to your AWS resources with the help of an external identity provider (IdP). You may have used an external identity providers in the past if you’ve used your GitHub or Facebook account to sign in to another website. What is Lambda? What is it and how does the framework use it? AWS describes Lambda as a “data processing service which runs code when it’s externally invoked (e.g. through events or other triggers)”. This sounds abstract and hard to understand but believe me. It’s not that hard. It simply means that you can zip and upload your code to AWS and Amazon sets up everything for you so that the code can be run. Lambda was celebrated as a game changer in cloud computing when it was introduced at re:invent in 2014. And you’ll see why in the next parts. – R. Rajesh Networking Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-02-21"},
{"website": "Mallow-Tech", "title": "An Introduction to Web server", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/02/an-introduction-to-web-server/", "abstract": "In this blog, we are going to see in detail about the web servers, its usage, and its significance. Along with that, we are also going to see about the different types of web servers. Web server forms the core any hosting, without it launching a website online is impossible. What is Web Server and how it works? Web server is basically a program that uses HTTP to serve files that create web pages to users in based on their requests, which are forwarded by their computer’s HTTP connection. A server that delivers an XML document to another device can be called as a Web server. In other words, a Web server is an Internet server that responds to HTTP requests to deliver the content and services. It can be explained with a simple example, Let’s say if you are in front of your computer, browsing your Web, and you receive a message from a friend saying, “I had just read a great article! You can check it from the following URL. It’s at http://blog.mallow-tech.com/” So you will type that URL into your browser and press enter. And that’s it, no matter where the website hosted in the world, the page will be displayed on your computer screen. A web server is always connected to the internet. Every Web server will be provided with a unique address which was arranged with a series of four numbers between 0 and 255 separated by periods. Different Types of Web Servers There are different types of web servers available in open market. Let us see in detail about few of the popular web servers. Apache Web Server Apache is one of the most popular web servers in the world. It is developed by the Apache Software Foundation. Apache is an open source software and can be installed on almost all operating systems such as Linux, Unix, Windows, FreeBSD, Mac OS X. Around 60% of machines run on Apache Web Server. An Apache server can be customized easily as it contains a modular structure.As it is an open source, you can add your own modules to the server when to require and make modifications that suit your needs. It is stabler than any other web servers and is easier to solve administrative issues. It can be easily installed on multiple platforms successfully. Recent Apache releases provide you the feasibility of handling more requests when you compare to its earlier versions. IIS Web Server IIS is a product of  Microsoft. IIS server has all the features just like Apache, but it is not an open source and personal modules cannot be added easily and modification is a little bit difficult. Microsoft developed, maintains it, thus works with all the Windows operating system platforms. Also, they had good customer support if it had any issues. Nginx Web Server Nginx is another free open source web server, it includes IMAP/POP3 proxy server. Nginx is known for its high performance, stability, simple configuration and low resource usage. This web server uses event- driven architecture than of the threads to handle requests. The advantage of this architecture is that is more scalable and uses only a small amount of memory under the load. It is gaining popularity in the recent times and it is hosting about 7.5% of all domains worldwide. lighttpd lighttpd, pronounced “lighty” (don’t ask me why), is basically a free web server distributed with the FreeBSD operating system. This open source web server is fast, secure and consumes much less CPU power than many of the other web servers. Lighttpd can also run on Windows, Mac OS X, Linux and Solaris operating systems. These are the various types of web servers. One can use the type of web servers based on the requirement of the client. – R. Rajesh Networking Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-02-16"},
{"website": "Mallow-Tech", "title": "Android Instant Apps | Future of mobile apps and app marketing", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/02/android-instant-apps-future-of-mobile-apps-and-app-marketing/", "abstract": "“Mobile apps are the future” is one of the most common slogans which is seen all along. But for mobile apps to rule the internet and e-commerce certain constraints are hindering. Memory space is one of the major constraints among them. So Google came up with the instant apps so solve the biggest ever constraint mobile apps are facing. Instant apps work on the basis that you will get a link to access a particular portion of the app. You can access the particular part without installing the whole app. After using the users can dive deep into the app and decide if it is useful to install or not. The instant apps are at the beta stage and Google might make it available to all users by this year. The instant apps can be seen from the business perspective and user’s perspective. From a business perspective, this serves as the biggest advantage. Even for a great app that has been developed by a company, giving a chance to make a user try it is really tough. By the introduction of instant apps, all they have to do is give them a link and so a part of the app that is necessary can be accessed. App owners have a number of parameters for framing a business strategy. Key KPIs are app installs, time spent on the app and other usage are tracked to form the strategies. To bring the visibility an app deserves, a lot has to be done. By the introduction of Instant apps, the perspective and the metrics that has been used so far will be changed. With just sharing a single link the technology is giving the users to try out the app without installing it on the device. Google as of now is now working with a few set of partners and other developers like BuzzFeed, B&H Photo, Medium, Hotel Tonight, Zumper and Disney. The biggest hindrance is in the form to marketeers. It will be tough for the marketeers to retarget their audience as cookies are not available through instant apps. although the mobile app users account only a tiny portion of the business, reaching the wider base of the audience will be easier for them. This process might make the new users easy to acquire, which is tougher now. “A 2015 study indicated that consumers spend 85 percent of their time on smartphones using apps, but only use a small handful of third-party apps on a regular basis. This shift in consumer behavior means that it’s difficult for developers to get their app onto users’ devices – something that Instant apps could help to address”(Posted May 18, 2016, by Frederic Lardinois, Sarah Perez, on Techcrunch) By adapting to the instant apps, there might be a huge shift the way the business is done with the apps. When there is only an occasional usage of any app, they can easily use this tech and make the most out of it. From the perspective of users, The biggest fear of storage space is negated. This tech supports for the android version above 4.1 and majority of the phones are updated with that. By this, a user can access a large number of apps and at the same time not worry about the loss in space or data consumption. This supports to a user to try out as many as possible and make them explore many other apps.This tech is the greatest advantage for a user to explore as much as possible and have the choice to choose the best app. Similar to this Apple has also come up with a tech called App Thinning. This was introduced in iOS 9, it includes features such as app slicing and on-demand resources. App slicing downloads only the assets when the app requires. As far as on demand resources are concerned, the user will download only a portion of the app that needed to run. The complete portion will not be downloaded as the other parts are downloaded once the need arises. It is clearly evident that both the giants are developing the technology to deal with the issue of internal space and memory. Addressing this practical problem in a simplified and convenient way for the users is a welcoming move. Now it is in the hands of the developers to adapt the future apps to comply with these features. We at Mallow technologies are experimenting with this feature on a couple of our apps. In future adapting the existing apps to the new feature might play a major role and opens up many opportunities for the businesses. – Business Analyst Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-02-14"},
{"website": "Mallow-Tech", "title": "10 Thing to be considered before developing an App", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/02/10-thing-to-be-considered-before-developing-an-app/", "abstract": "It is evident that the future of the internet is vested largely with the mobile applications than in the World Wide Web. In the recent years the mobile app development industry has seen tremendous growth and with the introduction of a lot of technological advancement, the field would create a paradigm shift in the internet usage and business models. To develop a mobile application certain factors have to be concentrated and checked. In this post let us see in detail about ten things to consider before developing a mobile app 1. Platform The first and foremost factor to ponder is the platform in which the app has to be developed. Choosing the platform in which the app has to be developed depends largely on the demographics and geography. If the app is to be used primarily in the US market then it is wise to choose iOS platform than of Android. At some point, one might need to develop the application in all available platforms but then it depends on the needs. The prime directive is that it should reach a wide variety of audience. 2. Native or Hybrid Native apps application built specifically for an operating system such as Objective-C or swift for iOS and similarly Java for Android. The advantage with Native development is it is customized according to the guidelines of a specific Operating system. On the other hand, Hybrid apps are also becoming more and more popular due to savings in time and cost for multiple platform app development. Both have their pros and cons. So the person who wants an application should prioritize the needs and choose a technology based on the needs and constraints. 3. Backend The backend is another important area to be considered. The majority of the apps are API-driven but at the same, it is not necessary for every app to have a custom backend and connect to the mobile with the help of APIs. Based on the need a local database too can handle and opting for a backend support costs a lot. One must analyze the need for backend & cost constraints before opting for one. 4. Analytics Analytics in Mobile apps is on its early stage of growth. Analytics helps in understanding the performance of the application among the desired users. This gives a pretty clear picture of how the app is performing and helps in making necessary decisions. Analytics helps in understanding the user engagement, retaining the users and pinpointing certain functionalities to improve the overall experience of the user. It all comes down to the metrics used and metric purpose match. People should be clear if the metric necessary can be measured or not. 5. Target audience This is the first and foremost factor you must see before anything else. Understanding the target audience, creating a sample persona to completely understand the demographic & psychographic behavior of the persona. This helps in developing the clear understanding of the product to be developed and create a better value proposition to the users. 6. Wireframes Wireframes are very important to bring the client and developer on the same page. The client and developer, each have a different visual image of the product. Wireframe helps in bridging the gap in the perceived understanding of both the party. Apart from that, it is easy to make the changes in the basic wireframe stage rather than in the advanced stages. The features and functionalities of the app to be developed will be explained clearly through this. 7. UI/UX Design The success or failure of the app relies largely depends on the UI/UX. UI and UX have to be in sync with each other and it should provide a great experience to the users. If the Interface is tailored perfectly but rather fails to give the proper experience to the user, then the fate of the app is sealed. UI and UX are of a paramount importance that it can change the value proposition of the app as such. 8. Method of development Agile method and waterfall method are mostly used in the process of a software development. Opting for the either method entirely depends on the client needs and quality of information available. If you have only a vague picture of the product and the process might need a lot of iterations then it is better to opt-in for the Agile method. If the requirements are crystal clear with detailed breakdown then waterfall method is preferred. 9. Competitor apps Analyzing the competitor apps is pivotal before coming up with an app. They help in understanding the value proposition of the similar apps. By understanding it, one can develop an application which can propose a different value proposition to stand out from the crowd. The process of analyzing the competitor should be from a user point of view so that the value proposition can be understood pretty clearly. 10. App development standards Meeting the standards of the platform plays a crucial role in gaining popularity. The components available under each platform has to be used optimally to optimize the app and make it provide the perfect user experience. Following the same approach to Android and iOS won’t work. The specific approach has to be made for each platform. Conclusion The above are the 10 factors that have to be taken care of before the application development process. If some of the emphasized factors are not given importance then there is a high chance of the end product to falter. These factors are perfectly taken care before developing a product to make it see the limelight it deserves. – Business Analyst Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-02-09"},
{"website": "Mallow-Tech", "title": "How to Perform Software Product Testing", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/02/how-to-perform-software-product-testing/", "abstract": "In this blog post, we are going to learn about “How to perform Software Product Testing” Software products need their own unique approach to test frequently and efficiently. most of the time teams treat them as any other software(i.e. not used by the general public, nonrevenue generating) and that is the starting point of trouble Custom test style and strategy is used for software product testing to add value. A complex ecosystem itself sustained and software product development and adaptability is needed for a thrive testers. Let me take a little time to explain why it is so important and why development of a product is complex, composite and complicated, even at the best of times. Software Product development challenges: Here are some of the challenges that Software Product development teams face: Lack of control over user demographics, environments, platforms, devices, etc Foggy product vision: Aggressive timelines Fear of failure Lack of actionable feedback These challenges affect all areas of product development, marketing, and sustenance- And they inherently impact product testing too. To get ahead in the game, this type of testing has to take five key points into account: Speed of software development and releases Short term and Long term goals of the product Extent and nature of competition Target customers and their environments Requirements – Functional, performance, security, usability, configuration, etc. Before we go into more details, let’s understand product life cycle. Let’s see how to test at each stage. This is product test process, method, or life-cycle. Stage #1: Product Introduction TrackFast would be going out into the market, the idea is for making a good impression. Everything should be tested in every angle. And also lay the foundation for future testing. In this stage, a piece of product is ready at the end of 3-4 week sprints. So, never consider last sprint testing ‘done-and-delivered’. Repeat all the critical tests with all the sprint until release. And test the entire product that you have until that point. Stage #2:  Product Growth After the product initial stage, if everything goes well, expect an unstable of activity because the product is fast faced lane. You are now running with a tiger and loins and unless you keep up, you will be eaten. Here, the releases get smaller, the improvements done to the software became larger and extent of regression becomes unmanageable. The product testing should be worked with the pace that the software in the development stage and should not at the end of the process. Stage #3: Product Maturity When the product has come this far. At this stage, there will be no often changes in the features. Hence, the product is going to be more focused on bringing more business or their marketing efforts. Stage #4: Product Decline The product owners and businesses are getting smarter these days and know very well that they can’t keep their product the same and expect the users to stay loyal. Things move too fast and so do products. What makes you a successful product tester? Product testers should have a perfect business sense, understating of fast delivery development models and should be reliable testers who should be ready to experiment with tools and become coders themselves when needed. These things can have an effective impact on any type of testing. Another important quality is that a product tester must believe in the product and genuinely want it to succeed. When I as a tester think that the software is total garbage, there is little hope that I will do anything to make it better. Share the product/business owner’s vision. Unless you know where the product is going and how it is going to evolve, the testing will be super limited. Cross-functional skills are beneficial-Know how to test the DateBase, how to take performance benchmarks, how to enable security certificates, how to deploy, etc. Set no boundaries– don’t think that evaluating the user manual or checking the FAQs is not your job and a technical writer should take care of it. Well, they should and they will. But when you look at it as an insider as someone who knows the product inside out, your feedback is super useful. Seek end user feedback. The next big set of people who test after you are the real time users. Know and understand what kind of problems they are facing. This helps you improve your test design so next time you know what to do to avoid them those problems. Work fast and be a decision maker However, for a product, the testing strategy has to be changed depending on the current life cycle stage the product changes to the market dynamics(new devices and browsers, etc). Conclusion: At the end, the product testing strategy should be much more flexible to change and more adaptable for any environment. The next time, I’ll write about some other techniques of testing. PS: Image courtesy: softwaretestinghelp.com Kumaresan T, Test Engineer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-02-07"},
{"website": "Mallow-Tech", "title": "The future of Mobile Apps – Augmented Reality", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/01/the-future-of-mobile-apps-augmented-reality/", "abstract": "Augmented Reality ( AR ) is the integration of direct or indirect view of digital information, such as sound, video, graphics or GPS data, with the user’s environment in real-time. Picture the “Iron Man” or “Minority Report” style of interactivity. While Virtual Reality (VR) is the creation of a complete artificial environment, Augmented Reality uses the user’s existing environment and overlays digital information on top of it. Augmented Reality is the buzzword nowadays. The technology of Augmented Reality has evolved from Virtual Reality. It has been around in some form for years, for example, the heads-up display in many fighter planes as far back as the 1990s have been showing information of some sort. The evolution of Augmented Reality has caused a shift in the approach towards various businesses. Augmented Reality made sure that you no longer have to consider the technologies you awed at Science fiction movies as a distant dream. Last year Pokemon GO created a sensation with the use of Augmented Reality. It became a turning point not only for Nintendo but also for the future of the technology in mobile apps. Various apps and Startups using Augmented Reality technology have cropped up. Let’s see in detail some of the AR apps and startups which made perfect use of the technology. E-Commerce : It is one domain where the user had some restraints in buying things as it may or may not look perfect. The advantage in brick and mortar shops is that they can have trial use of the apparel or products. To counter that, Caratlane and Lenskart took the help of the AR technology and came up with a virtual trial room. Here users can test the product, how it looks on them before buying. This proved to be a massive success and gave a trust to the users to buy from these sites. Caratlane Catalogue App Furniture : IKEA adapted this technology and released an app through which users can see what potential furniture may look like in their living room, bedroom, or any other desired area. The app conveniently saves the user a trip to the store or an accompanying headache that goes hand-in-hand with discovering the user had the wrong dimensions all along. Social Apps : Inclusion of the Augmented Reality technology served as a USP for Snapchat and made it a huge success. It went on to become the first Augmented Reality social media platform. The various funny and intriguing filters made the app much more popular than its counterparts. Snapchat Gaming : In terms of popularizing the technology, the gaming industry takes away all the credit. Niantic came up with the game Ingress , which integrated Augmented Reality with Geolocation services. This is the company which gave the recent sensation Pokemon GO . Apart from the much known Pokemon GO, there are various games like Kickball AR Soccer , AR Zombies etc., Augmented Reality makes the games engaging, ensuring the players stay in it for a longer time. Pokemon Go Education : Star Chart is a free app when opened on the user’s Android or iOS device and pointed at the sky, will inform of what stars or planets the user is currently facing. It also has a feature called Time Shift, which allows the user to move up to 10,000 years forward or backward in time to see where the stars once were or will be. Star Chart App The Travel industry : It has a huge potential with the integration of Augmented Reality. Word lens was an app which proved to be a real game changer in terms of travel. Word lens has now been integrated into the Google Translate app and not available anymore as a standalone app. It helps in the real-time translation of the name boards and various other elements and so one can travel on their own without any help from the local or help themselves from embarrassment. Apart from this, there are AR browsers such as Layar and Wikitude , which help in incorporating the real world elements in the search criteria to give better results. Google Translate Augmented Reality in Mobile app development is the next big thing. With so many affordable VR head gears and glasses available, it is high time to see the shift. Last year, Mark Zuckerberg had announced that Facebook’s working on Augmented Reality glasses . This might sure make the Augmented Reality gears mainstream and hence promoting innumerable development in the sector. This will serve as a service or value differentiator to many products to gain an edge over the competitors. At Mallow Technologies , we have extensively worked with geo-location based apps. Including Augmented Reality Technology might just uplift the experience of the apps. And we are currently in the process of adopting some AR technology into some of the products we are working on. – Marketing Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-01-18"},
{"website": "Mallow-Tech", "title": "How to store files securely with AWS", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/01/how-to-store-files-securely-with-aws/", "abstract": "File uploads from a user’s machine to a server are stored in the server’s premises. But what happens in course of time is the data gets an inevitable growth and so their attachments. This leads to challenges like browser restrictions, machine speed, network speed, and server storage capacity. This can be solved by heading to a cloud-centric technical architecture so that we can provide a secure approach to upload large files. So, down to this blog, let’s see how to use cloud services for bringing the quality factors like speed, vast and secure. Yes, there are many services, but for the best, let’s dive into the world’s largest forest AWS, the leading provider of cloud services. Once you landed signing in at AWS, create an S3 bucket for your region following these directions . You would feel warm, breezy pitching a bucket in AWS. Now, you can have a look at bucket policies here . And follow a basic example that AWS provides demonstrating how to upload a file to S3 using their SDK . And, here comes the heart of the guide directing you to the secure way of uploading files. Key Properties: Pre-signed URLs SQS Two Bucket Security Approach Pre-signed URLs: Pre-signed URLs are used to enable your client/customer to upload an object to your bucket. This pre-signed URL makes the controls, such as providing only write permissions and lifespan of the URL, handy. You can generate a pre-signed URL Thus this pre-signed URL is given to the client and the client uploads his file to the path of your bucket you provided. It’s now we have to handle the uploaded object. First, we’ve to get an acknowledgement that the file’s been uploaded successfully. This is because, if we save the details of the storage without making sure of the upload action in the bucket, it would result in data inconsistency, if any problem occurred during the upload action. Thus acknowledgement is commendable. It can be accomplished through SQS. SQS: Amazon SQS queue gets the notification when certain actions(which you could mention based on your need) happen on your Amazon S3 bucket. That is, the notifications are pushed to the SQS queue on account of certain actions on your S3 bucket. You could set up an SQS queue for your Amazon S3 bucket. So that you could fetch the notifications by polling the queue for a period of time. Thus, we get acknowledged of a particular action to the bucket. Yes, now, we are safe to save the data of storage that is definitely consistent. Two Bucket Security Approach: The two bucket architecture establishes a strong security. The first bucket is a temporary loading dock that is externally exposed, allowing clients to write files while the second bucket is more secure and the files’ final burrow. External users don’t have access to it. OK, What happens to the files in the loading dock? Files can be automatically deleted via a lifecycle policy after a specified time limit. So, now, let’s move the files from loading dock bucket to the permanent bucket. And finally, save the path of the file at a permanent bucket. Store encrypted data: For high security, store only encrypted data at storage. This can be done by encrypting the files through secret keys. You can look into KMS Keys . Wrap-up: Pre-signed URL is generated and given to the client. The client uploads an object to the path provided. Meanwhile, SQS gets a notification, if the upload was successful. The server looks for the SQS data(i.e., in a queue) by polling. By that data, it is acknowledged that object is upload to the bucket. Move the object to a permanent bucket. Store the URL of permanent in the server. Thus, we’d accomplished our mission, establishing a secure architecture for storing sensitive data, leaving no loopholes for any treasure hunts. Such dark, mysterious Amazon! – Senthil Rhaj, ROR Development Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-01-12"},
{"website": "Mallow-Tech", "title": "What is Web Testing", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/01/web-testing/", "abstract": "From a Testers perspective, I have shared about web testing and how could it be tested effectively. We are going to look into the techniques on how to improve the web testing. What is Web Testing? Website Testing is nothing but checking and analyzing web application for bugs/errors before it’s made live or before code moves to live environment. During this process issues such as functioning of the site, UI of the site and web security and User Acceptance testing are done and its ability handle traffic is checked Testing website points to be considered: Client/server applications are websites —with web servers and ‘browser; clients websites are interactions between HTML pages, TCP/IP communications, internet connections, firewalls, applications that run in help if HTML pages i.e. applets, javascript etc..and application that run on the server side ie. CGI scripts, database, logging applications etc… There are a wide variety of browsers and servers with different versions of each, which has significant differences between them, variations in connection speeds, changing technologies. At the end major effort of testing for webAdditionally, there are a wide variety of servers and browsers, various versions of each, small but sometimes unique differences between them, variations in connection speeds, rapidly changing technologies, and multiple standards and protocols. The end result is that testing for websites can become a major ongoing effort. Other considerations might include: Expected loads on the server(e.g. number of hits per unit time?), and what kind of performance is required under such loads. and what kind of tools are used for performance testing(Eg. meter etc.) Analyzing the target customers? and What kind of browsers thy mostly using? and analyzing their network and connection speed?(intra-organisation with likely high connection speeds and similar browsers) or Internet-wide (thus with a wide variety of connection speeds and browser types)? Analysing client expectation on performance(eg., how fast should pages appear, how should animations, applets, etc. load and run)? Analyzing what kind of security will be required and how it can be tested and what are expectations for the clients What processes will be required to manage updates to the web site’s content? Analyzing the maintaining requirements, controlling page content, graphics, links, etc.? Which HTML specification will be adhered to? How strictly? What variations will be allowed for targeted browsers? Will there be any standards or requirements for page appearance and/or graphics throughout a site or parts of a site?? Analyzing the validations of internal and external links and how to update? and how often? Analysing how the testing can be done on the production system or by separate test system can be required? How is the browser caching, variations in browser option settings, dial-up connection variabilities, and real-world internet ‘traffic congestion’ problems to be accounted for in testing? How extensive or customized are the server logging and reporting requirements; are they considered as an integral part of the system and do they require testing? How are CGI programs, applets, javascript, ActiveX components, etc. to be maintained, tracked, controlled, and tested? Pages should be 3-5 screens max unless the content is tightly focused on a single topic. If larger, provide internal links within the page. The page UI and design elements should be consistent all over the site so that to ensure the user that they’re still within a site Pages should be as browser-independent, or pages should be provided or generated based on the browser type. Every page should contain links external to the pages, there should be no dead-end pages. The page owner, copyright date and  person/organization to contact should include on each page This concludes almost all the major ways to test a website efficiently. Conclusion: I have shared some of the techniques used to test web application, and it’s not possible to cover each and every point but I have shared major techniques of web testing. Kumaresan T, Test Engineer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-01-10"},
{"website": "Mallow-Tech", "title": "How to Improve Rails application performance", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/01/improving-rails-application-performance/", "abstract": "From a developers perspective, I have shared some tips to easily improve the performance of rails applications. We are going to look into techniqes that greatly improve the application’s performance. Querying database Rendering partials 1. Querying database a.) Avoiding Queries within loop Using queries within loop greatly reduces the performance by querying the database numerous times rather than a single time. b.) Avoiding N+1 Queries Most ORMs have lazy-loading enabled by default, so queries are issued for the parent record, and then one query for each child record. We can fix N+1 query problem by using pro-load child record when querying the database for parent record and we can use the bullet to gem to discover N+1 queries. c.) Using Counter Cache A counter cache will be used in few places but it slightly improves the performance. We can use counter cache to store child records count which avoids querying database for the count of child records. d.) SQL caching Query caching is a Rails feature that caches the result set returned by each query. If Rails encounters the same query again for that request, it will use the cached result set as opposed to running the query against the database again.The second time the same query is run against the database, it’s not actually going to hit the database. The first time the result is returned from the query it is stored in the query cache (in memory) and the second time it’s pulled from memory. However, it’s important to note that query caches are created at the start of an action and destroyed at the end of that action and thus persist only for the duration of the action. If you’d like to store query results in a more persistent fashion, you can with low level caching. e.) Low-level Caching Sometimes we need to cache a particular value or query result instead of caching view fragments. Rails caching mechanism works great for storing any kind of information.The most efficient way to implement low-level caching is using the Rails.cache.fetch method. This method does both reading and writing to the cache. When passed only a single argument, the key is fetched and value from the cache is returned. If a block is passed, the result of the block will be cached to the given key and the result is returned. f.) Using search engines Using search engines will highly increase the performance by quickly get data from the database. Fast search is one of the main advantages of search engines and search across multiple fields using search engines more efficient than SQL. Following are some of the search engines available in rails – Elastic search – Thinking Sphinx Most of the search engines are not ruby based but we can use them by Tire (Elastic search) , Thinking-Sphinx (Thinking sphinx) gems. g.) Using Third party services to monitoring and improving application performance Third party services like ‘ new relica’ depict the clear picture of time taken for every process(querying a database, rendering partials) in processing request. By using new relic we can easily discover and fix problems like slow response time, most time-consuming request. h.) SQL Indexing Indexing is more useful in using both text-based search and SQL-based search. SQL index is a data structure that improves the speed of operations on a database table. For every index on a table, there is a penalty both when inserting and updating rows. Indexes also take up space on disk and in memory, which can affect the efficiency of queries. Finally, having too many indexes can cause databases to choose between them poorly, actually harming performance rather than improving it. So while indexing it is important to choose carefully how to index our data. Note: Don’t index every table columns and use where ever index is needed(frequently used tables). There is a performance hit with indexes. Although select queries can be significantly faster, inserts and updates are marginally slower because there is overhead in maintaining the index. However, the small impact (milliseconds) during an insert is usually a small price to pay for what could be seconds (or even minutes) saved on certain queries. 2. Rendering partials a.) Avoiding queries in view side Avoiding queries in view side will not improve performance greatly but according to rails architecture writing queries in view side is bad practice. b.) Using Fragment caching Rails provide a mechanism called Fragment Caching for cache different parts of the page and it will be expired differently. Fragment Caching allows a fragment of view logic to be wrapped in a cache block and served out of the cache store when the next request comes in. Note : It may give unexpected result when failed to update the latest content. Conclusion: I have shared some easily used processes for improving Rails application performance and it’s not possible to cover everything in Ruby on Rail performance optimization in one post and I will share more things in a later post. I have only shared the usage and have not mentioned where to use them. Before using the above techniques, a good understanding is required, otherwise it may lead to unexpected results. – Premanandh, Junior ROR Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-01-05"},
{"website": "Mallow-Tech", "title": "How to User Authenticate using JWT", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/12/user-authentication-using-jwt/", "abstract": "In the previous blog , we saw why we need to shift to token based authentication, instead of the traditional authentication process and also we went into what is a JSON Web token. Now let us see in detail what JSON Web Token is and how it can be used for user authentication. JWT Structure As we have seen earlier JSON Web Token (JWT) is an open standard (RFC 7519) that defines a compact and self-contained way for securely transmitting information between parties as a JSON object. JSON Web Tokens consist of three parts containing encoded data, separated by dots (.), which are: Header Payload Signature Therefore, a JWT typically looks like the following. xxxx.yyyyy.zzzzz Header The header typically consists of the type of the token , which is always JWT, and the hashing algorithm being used, such as HMAC SHA256 or RSA. For example { “alg”: “HS256”, “typ”: “JWT” } when this is base64encoded, we have the first part of our JSON web token cbiuwirb3u48wecbuwieci2 Payload The second part of the token is the payload, which contains the claims. Claims are statements about an entity (typically, the user) and additional metadata. There are three types of claims: reserved, public, and private claims. Reserved Claims JSON Web Token defines some reserved claim names and defines how they should be used. JWT supports these reserved claim names: ‘exp’ (Expiration Time) Claim It specifies the time till which the token is valid. ‘nbf’ (Not Before Time) Claim The nbf (not before) claim indicates the time before which the JWT MUST NOT be accepted for processing. ‘iss’ (Issuer) Claim The iss (issuer) claim identifies the principal that issued the JWT. The processing of this claim is generally application specific. iss = Mallow Technologies Pvt Ltd. or https://mallow-tech.com ‘aud’ (Audience) Claim The aud (audience) claim identifies the recipients that the JWT is intended for. Each principal intended to process the JWT MUST identify itself with a value in the audience claim. If the principal processing the claim does not identify itself with a value in the aud claim when this claim is present, then the JWT MUST be rejected. ‘jti’ (JWT ID) Claim The jti (JWT ID) claim provides a unique identifier for the JWT. The identifier value MUST be assigned in a manner that ensures that there is a negligible probability that the same value will be accidentally assigned to a different data object; if the application uses multiple issues, collisions MUST be prevented among values produced by different issuers as well. The jti claim can be used to prevent the JWT from being replayed. The jti value is a case-sensitive string. ‘iat’ (Issued At) Claim The iat (issued at) claim identifies the time at which the JWT was issued. This claim can be used to determine the age of the JWT. Its value MUST be a number containing a Numeric Date value. Use of this claim is optional. Public claims These can be defined at will by those using JWTs. But to avoid collisions they should be defined in the IANA JSON Web Token Registry or be defined as a URI that contains a collision resistant namespace. Private claims These are the custom claims created to share information between parties that agree on using them. Signature To create the signature part you have to take the encoded header, the encoded payload, a secret, the algorithm specified in the header, and sign that. For example, if you want to use the HMAC SHA256 algorithm, the signature will be created in the following way: HMACSHA256( base64UrlEncode(header) + “.” +base64UrlEncode(payload),secret) How can JSON Web Tokens can be used for User Authentication? It is a stateless authentication mechanism where user’s state is never saved in the memory. The server will check for a valid JWT in the Authorization header, and if it’s present, the user will be allowed to access protected resources. As JWTs contains all the necessary information within itself, reducing the need to query the database multiple times. This allows you to fully rely on data APIs that are stateless and even make requests to downstream services. It doesn’t matter which domains are serving your APIs so Cross-Origin Resource Sharing (CORS) won’t be an issue as it doesn’t use cookies. How JWT Works User successfully logs in using his credentials. The server responds with a JSON Web Token, this token contains the details of the user which is used to be used by server often, it may be the user_id, username, email etc. The expiry time of the token must be configured using the exp claim. All these details are encoded based on some algorithm such as HMAC SHA256 or RSA. The token provided to the client must be saved locally and sent in the headers of each request. Server decodes the token and verifies the token is valid or not. If valid then it allows the user to access the restricted resource. When a JWT gets expired we need to refresh the token or we need to create a new token and allow the client to access the resources otherwise the user will have to sign in to the application frequently this will irritate the user. So a refresh token mechanism can be adopted. In addition to a JWT server will respond the client an additional token called refresh token which will have much higher expiry time when compared with JWT access token. When an access token gets expired client will send the refresh token to server verifies the refresh token and provides the new access token. Advantages of using JWT Since you have all details in the token itself server need not query about the details of the user from DB. As server don’t use any sessions for storing the details of the user, memory consumption is decreased and server can also be scaled up based on the traffic. Any client having a valid JWT can access the resource so this can also be used by mobile devices for consuming APIs. By setting the expiry time to a token, even if a token being misused it can’t be used for a long time as the token will expire will at a certain time. Disadvantages of using JWT Though JWT is advantageous in many ways it still has some limitation too, Token provided to the user after successful authentication will be valid even if the user logs out from the system. When the expiry time of a token is set to small time, then these token will get invalid within a little amount of time. But for an application where we need higher security, this small amount of time does play a vital role. Invalidating JSON Web Tokens As mentioned earlier a valid JSON Web Token of a logged out user can also be used for accessing the restricted resources. If you are building an application where you need high security you need to make sure this doesn’t happen. In order to implement a user authentication system for such kind of application, you need to compromise with some advantages of JWT. In such cases, you need to keep track of the token which is invalid/valid. A JWT will get expired based on the exp claim in the payload, after which the token cannot be used. There are also some scenarios in which the tokens must be invalidated before its expiry, those are When a user logs out from the application before the token gets expired. When the user resets the password. This can be handled by two ways Blacklisting Whitelisting Blacklisting In this process tokens which are not valid are stored in the DB. We need to handle the following situations, When the user changes his password note the change password time in the user DB, so when the change password time is greater than the token creation time, then the token is not valid. Hence the remaining session will get logged out soon. “iat” claim can be used for getting the token creation time. When User logs out , save the token in a separate DB (say: Invalid Token and remove the token from DB when token expires). Hence user logs out from the respective device, his sessions in other device left undisturbed. Whitelisting In this process tokens which are valid are stored in the DB and remove the tokens which get expired. You need to handle the following situations When User changes his password , delete all the tokens of the tokens, as these tokens become invalid. When User logs out , delete that particular token from the DB, as a single user may log in multiple devices, so delete a particular token. Conclusion As said earlier we have some limitations in JWT too. The process of invalidating the JWT is an optional one, this can be implemented when you think that the resources are more secure and it should not be at any point in time. If you think that the data of the application can be accessed by the user using the token which will expire within a shorter duration then this process can be skipped, as it leads to compromise with a stateless property of JWT. – Bala Karthik, Junior ROR Developer, Mallow Technologies Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-12-29"},
{"website": "Mallow-Tech", "title": "What is User Authentication? – An Introduction", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/12/what-is-user-authentication-an-introduction/", "abstract": "You might have heard about the word user authentication often, It’s nothing but verifying the user accessing to a system is genuine or not. There are many ways to accomplish this process, the most often used is authentication using passwords. A few major problems arose with this traditional authentication methods are, Sessions The server needs to store the details of the authenticated user when there are many users using the system this increases the overhead of the server in terms of its memory usage. Scalability As we are storing the details of the user in memory (sessions) this leads to the problem during scaling. For handling the application load cloud providers will replicate servers, having vital information in session will restrict our ability to scale. CORS When the data of our application is to be used by mobile devices we need to consider about cross-origin resource sharing (CORS). While using AJAX calls to access resources of other applications through their APIs our request can be forbidden. CSRF We will also have protection against cross-site request forgery (CSRF). As the users are already authenticated with a system lets say an e-commerce site where he would have stored the details of his bank-like credit/debit cards, he will be susceptible to CSRF attacks this could be taken advantage of when visiting other sites. With these problems, scalability being the main one, it made sense to try a different approach. Token Based Authentication Token-based authentication is stateless. We are not storing any information about our user on the server or in a session. This will be the solution to many of the problems with having to store information on the server. No session information means your application can scale and add more machines as necessary without worrying about where a user is logged in. Although the implementation of token based authentication may, the general process is: Client access a restricted resource with Username / Password. The server validates credentials. The server provides a token to the client. Client stores that token and sends it along with every request. The server verifies token for each request and responds with the data. Advantages of token based Authentication Tokens stored on client side. Completely stateless, and ready to be scaled. CSRF attacks can be prevented by using tokens. We can make the token to be valid for a particular period of time by setting expiry time for each token,  so when a user tries to access the system with an expired token he will be required to login once again. We could even create a permission based token and pass this along to a third-party application (say a new mobile app we want to use), and they will be able to have access to our data. Disadvantages of token based authentication The Client needs to send the access token to the server on every request, the server needs to retrieve the user who is accessing the resource from the databases based on the token. So server needs to interact with the databases on each request for obtaining the user details. If tokens are created without any expiry then these tokens can be misused by the attackers. Once an attacker gets a token, then he could get control of entire access. In the case of having the expiry time to a token then the user needs to log into the system frequently, this could irritate the user as he needs to enter his username, password as each token expires. Let’s see how to overcome these disadvantages As said earlier we need to make the token valid for a certain period only otherwise these tokens can be misused. But we need to consider the user experience too, as asking a user to login to the system frequently will irritate a lot. This can be solved using refresh token mechanism. The server will provide two tokens to the user after a successful sign-in, refresh token, and access token. The access token is what we discussed, refresh token will be a unique token provided to a user. Refresh token differs from access token in the time limit for its expiry. A refresh token will have higher validity than that of the access token. So whenever an access token expires then the client should use the refresh token for getting a new access token, the newly obtained token can be used in further requests for accessing the application resources. We would force the user to enter his credentials only if the refresh token expires. This will solve the problem of forcing a user to provide his credentials frequently. But how to solve the problem querying DB for getting the user details for each request, it is where JWT helps us. Now let’s see about the JWT (JSON WEB TOKENS) JSON Web Tokens JSON Web Token (JWT) is an open standard (RFC 7519) that defines a compact and self-contained way for securely transmitting information between parties as a JSON object. This information can be verified and trusted because it is digitally signed. JWTs can be signed using a secret (with the HMAC algorithm) or a public/private key pair using RSA. The reason why JWT is used: Compact Because of its smaller size, JWTs can be sent through a URL, POST parameter, or inside an HTTP header. Since the tokens are compact, transmitting the token will be fast. Self-contained The payload contains all the required information about the user, avoiding the need to query the database more than once. Conclusion We have seen why we should we use token based authentication and how does token based authentication works and also the advantages of using Tokens for authentication and also its disadvantages along with the measures that can be taken to overcome these disadvantages and a small intro of JSON Web Tokens. In the upcoming blog, we will see how to use JWT for user authentication. – Bala Karthik, Junior ROR Developer, Mallow Technologies Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-12-22"},
{"website": "Mallow-Tech", "title": "What are the Software testing metrics", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/12/software-testing-metrics/", "abstract": "Test Metrics: Generally, Metric is defined as a unit which is used for measuring any attribute. In software testing, Test metric is defined as a quantitative indicator of the degree to which a system, system component, or process possesses a given attribute. Test metrics helps to estimate the progress, quality and health of a software testing effort and also helps to take decision for next phase of activities. Test metrics improves the efficiency and effectiveness of a software testing process. Software Test Lead/Manager’s main responsibility is to generate software test metrics. Test Metrics Life Cycle The Testing Metrics Life cycle usually consists of 4 phases: Analysis Communication Evaluation Report Test Metrics Life Cycle Analysis: In analysis phase, testing team lead will identify the specific metric that is to be measured and define the identified metrics. Communication: In communication phase, testing team lead  will explain the need for metric to stakeholder and testing team and educate the testing team about the data points to be captured for processing the metric. Evaluation: In evaluation phase, testing team lead  will capture and verify the data used for generating the Metrics and Calculate the Metrics based on the data captured. Report: In reporting phase, testing team lead will develop the Metrics report with effective conclusion and distribute to the stakeholders and take feedback from the stakeholders for any improvements. Types of Metrics Metrics are usually of three types: Process related metrics : Process metrics are used to improve the efficiency of a process, for example, Software Development Life Cycle (SDLC). These metrics are mainly used for evaluating and improving the effectiveness of development and maintenance processes. Product related metrics: Product metrics relate to the quality of software products and identifying them and taking corrective actions that helps to improve the quality of the product. These metrics are used for describing characteristics of product such as it’s size, complexity, features, and performance. Project related metrics: Project metrics are used to measure the efficiency of a project team or used to measure the efficiency of any tools that are being used by the team members. These are useful in monitoring and controlling a project. It describes the characteristics of the project and its execution such as number of software developers, cost and schedule. Conclusion The  metrics  provided  by  testing  offer  a  major  benefit  to  executives which gives  visibility  into  the  maturity  and readiness for release or production, and visibility into the quality of the software product under development. The test metrics should be reviewed & interpreted on regular basis throughout the testing process and particularly after the application is released into production. This enables effective management of the software development process, by allowing clear measurement of the product quality and completeness of the product. – Deepa N, Test Engineer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-12-20"},
{"website": "Mallow-Tech", "title": "Firebase – Unified platform for app development", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/12/firebase-unified-platform-for-app-development/", "abstract": "Firebase is the latest outcome from Google. Firebase provides you with all the features required to build an Application with ease. It makes the work of developers much easier by providing them with all the features that are required, under the same roof. It provides support for Android, iOS, web Applications. The important features for developer provided by Firebase are listed below Authentication. Real Time Database. Storage. Cloud Messaging. Hosting. Test Lab. Crash Reporting. Authentication : Firebase provides backend services for Authentication and  also UI libraries to authenticate users to your app.These features can be easily integrated by the developers as all the scenarios are handled by Firebase. It supports various authentication processes such as e-mail/password Authentication. Google Authentication. Facebook Authentication. Twitter Authentication. Github Authentication. When the user is authenticated by firebase for the first time, it would generate a unique id and that should be used within the app even on further login by the user. Real Time Database : Firebase comes with a realtime database.It is a noSQL Database.The entire database would be in the form of json structure. The main feature in realtime database is that, when a data is changed in the database it could be reflected in the Applications using that particular data. It also provides a means for setting the accessibility rules, using this we can ensure security by allowing access to data’s based on the accessibility levels specified.It also provides offline capabilities for App’s, it stores data in the device when offline and once the connection is established it would add it to the Firebase. Storage : Firebase storage is based on Google Cloud Storage.The main advantage of Firebase storage over others it that it can download or upload data even in very poor network conditions.It also provides more security to users data.When a network connection is lost in the middle, the operations are paused and they would continue from the left over place once the network is connected. Cloud Messaging : Cloud Messaging enables you with a cost free messaging service across platforms. Firebase Cloud Messaging is a predecessor of Google Cloud Messaging, but also comes with few other additional options. We could send Notifications from our server to the targeted clint App’s. We can build our own App server to send Notification or use Firebase Notification Console for testing purposes. Hosting : Firebase provides us with a hosting service.Using this we can host a web App easily and faster.The main features in this are that it provides security by default, faster data transition, it provides methods for faster deployment and if you did something wrong then you can use on-click roll backs to quickly rollback to previous version Test Lab : Firebase provides a testing platform.But as of now it provides support for only android devices.It provides several features such as video, screenshots, log under a single package.Using this we can test an android App in multiple devices at the same time.This provides a huge advantage over testing and minimizing the amount of bugs within the Apps. Crash Reporting : Crash reporting would help us in finding the errors that has occurred to users worldwide.If an error occurs it would create a detailed report of the errors and group them based on their type.It is easy to set up just add dependency and custom logs to find the errors. But the crash reporting is still in testing (beta version). Conclusion: Hence firebase makes the work of App development look so easy, with providing all the necessary tools under the same roof, with a reasonable costing structure.As of now it a boon for developer making their work easy.There are many similar features provided separately in web, but nothing is as popular as firebase as it provides everything in a single place. – Raasesh R, Android Team , Mallow Technologies . Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-12-15"},
{"website": "Mallow-Tech", "title": "IoT in Rails with AWS IoT Data Plane", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/11/iot-in-rails-with-aws-iot-data-plane/", "abstract": "As we have already seen getting started with AWS IoT and implementing the AWS IoT with MQTT in previous blog posts, here we are going to see how to use AWS IoT Data Plane client which comes with the AWS SDK for publishing the payloads to the things. AWS IoTDataPlane: It implements a broker for applications and things to publish messages over HTTP (Publish) and retrieve, update, and delete thing shadows. A thing shadow is a persistent representation of your things and their state in the AWS cloud. For using this IoT Data Plane in Rails we need ‘aws-sdk’ gem so, we can start by installing the gem. Creating a client: We can create an AWS IoTDataPlane client with AWS credentials as below: Or, we can configure AWS with credentials by creating an Initializer as below: Make sure to set the correct region and endpoint of AWS IoT Thing.. Publishing to a topic: After connecting the client we can publish the payload to the topic as below: AWS IoT Rules: An AWS IoT rule consists of a SQL SELECT statement, a topic filter, and a rule action. Devices send information to AWS IoT by publishing messages to MQTT topics. The SQL SELECT statement allows you to extract data from an incoming MQTT message. The topic filter of an AWS IoT rule specifies one or more MQTT topics. The rule is triggered when an MQTT message is received on a topic that matches the topic filter. Rule actions allow you to take the information extracted from an MQTT message and send it to another AWS service. Rule actions are defined for AWS services like Amazon DynamoDB, AWS Lambda, Amazon SNS, and Amazon S3. AWS IoT rule actions are used to specify what to do when a rule is triggered. The following actions are supported: cloudwatchAlarm to change a CloudWatch alarm. cloudwatchMetric to capture a CloudWatch metric. dynamoDB to write data to a DynamoDB database. elasticsearch to write data to a Amazon Elasticsearch Service domain. kinesis to write data to a Amazon Kinesis stream. lambda to invoke a Lambda function. s3 to write data to a Amazon S3 bucket. sns to write data as a push notification. firehose to write data to an Amazon Kinesis Firehose stream. sqs to write data to an SQS queue. republish to republish the message on another MQTT topic. Creating AWS IoT Rule: From the AWS IoT dashboard you can create an IoT Rule where, you can specify your own SQL query through which you can filter the messages that is published to the topic. Specify ‘ *’ in attribute field to select all attributes or specify the particular attribute you need to retrieve and send to an action. Specify the topic from which the payloads to be selected. After filling these fields you can see the final SQL SELECT query in the Rule query statement field. Then, you can choose one or more actions that need to be performed with the received message. Using IoT Rule to send messages to backend server: Let us consider we need to subscribe to a topic and we need to do some process with the received messages on that topic in our Rails backend. For this scenario we can set the IoT rule action as SQS which send the filtered messages to an SQS queue. We can create a worker which process the messages received in the queue. This is better because all the processing of the messages are done in background. Thus, we have seen setting up IoT in AWS and using those credentials from AWS to connect with MQTT to perform publish/subscribe to the topics and in these series of blogs, we have seen how to use AWS IoT Dataplane for publish/subscribe operations. – Gokul, Junior ROR Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-11-29"},
{"website": "Mallow-Tech", "title": "Mobile Application Testing", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/11/mobile-application-testing/", "abstract": "In this 21st century, mobile phones are not only device used for making calls but are used as multipurpose personal/official gadgets. There has been a lot of technical improvement and mobile devices come in with, different Operating System like Apple iOS, Windows, Android, Blackberry, Symbian, Bada OS etc. Currently, billions of  people uses mobile phones and over trillions of business depend on these devices. And there are new challenges for hardware manufactures to stay in competition with the constant releases of devices in different sizes and configurations and due to this application developers are forced to deliver their best Apps over various platforms within a quick time. What is Mobile Application Testing and Why it is needed? In this highly competitive global market, mobile development cycle is forced to complete in a short period of time. For the vendors to ensure long term success, the App must be tested over different combinations of platforms, networks and operating systems before being launched to market, and functional and non-functional testing like usability testing, performance testing, security testing improves the quality of the mobile Apps. Significance of Mobile Application Testing: Testing applications on mobile devices are more challenging than testing web apps on desktop. Let us see why: Testing should be done, with mobile devices having different screen sizes, different configurations like virtual keypad, trackball etc. with wide varieties of mobile devices like Apple, HTC, Samsung, Nokia, etc. with different operating system like iOS, Bada, Windows and Android etc. with different operating system versions like Android 4.0, 4.4.4, 5.0, iOS 9x, 10x etc. with different mobile network operators like GSM and CDMA Mobile Operating Systems: The following table gives an overview of some of the popular mobile operating systems available in market Operating System Developed by Popularity (Low, Medium, High) Latest available version Android Google Inc High Marshmallow, Android 6.0.1 iOS Apple Inc High iOS 10.1.1 Blackberry Blackberry Ltd Low Blackberry 10.3 Windows Microsoft Inc Medium Windows 10 Mobile Symbian Symbian Foundation Low Discontinued Mobile Application Testing Strategy The Test strategy should make sure that all the quality and performance guidelines are met. A few pointers in this area: Selection of devices —Should widely analyse the market and choose the devices that are used globally. Popularity is the main factor and clients will also prefer apps which suits devices which are widely used. Emulators —Emulators should be used only at the initial stages of development, as they are easy, quick and efficient in checking the app. Emulators duplicates the features and work in real system. T ypes of Mobile Emulators Device Emulator – Provided by device manufacturers Browser Emulator – Simulates mobile browser environments. Operating systems Emulator – Apple provides emulators for iPhones, Microsoft for Windows phones and Google Android phones Types of Mobile Application Testing: Let’s see the testing process involved in Mobile App Testing. Functional Testing: Functional testing is a technique used to test the functional behaviour of the application to ensures that the application is working as per the requirements. Performance Testing: Testing the performance of the application by changing the connection from 2G, 3G to WIFI, sharing documents, battery consumption, etc. Memory Leakage Testing: Memory leakage testing checks the performance of the Mobile Applications to ensure that each application of the mobile device is using optimized memory for processing. Interrupt Testing: Is a process to replicate abrupt(Unexpected) interruption to the application. Interruptions can be; SMS/MMS/calls, battery removal, OS upgrade, switch off/switch on of the media player, etc,. An application should be capable enough to hold these interruptions by going into a suspended state and restarting afterwards. Usability testing: Usability testing is used to test the mobile applications in terms of usability, flexibility, and friendliness. The testing process makes sure that the mobile app is now easy to use and offers a suitable user experience to the user. Installation testing: Installation testing is used to test if the particular application is installing, uninstalling, and updating properly without any interruption (user experience is smooth and flexible with the application). Operational testing: Testing of backups and recovery plan if battery goes down, or data loss while upgrading the application from store. Security Testing: The purpose of security testing to test if the application’s data and network security is responding as per the given requirement/guideline. Test Cases for Testing a Mobile App In addition to functionality based test cases, Mobile application testing requires special test cases which should cover the following scenarios. Battery usage– It’s important to keep track of battery consumption while running an application on the mobile devices. Speed of the application- It’s important to check the response time on different devices, with different memory parameters, with different network types etc. Data requirements – For installation as well as to verify if the user with limited data plan will able to download and update. Memory requirement– again, to download, install and run and update. Functionality of the application– make sure application does not crash due to network failure or anything else. Conclusion Efficient test strategy design should choose the right mobile devices and mobile testing tools, which can make sure that 100% test coverage is done and help us include usability, performance, functionality, non functionality and security based tests in to out test suites. – Kumaresan.T, Test Engineer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-11-22"},
{"website": "Mallow-Tech", "title": "IoT in Rails with AWS & MQTT", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/11/iot-in-rails-with-aws-mqtt/", "abstract": "In our previous post we had seen how to setup IoT in AWS and we created the certificate and policy and downloaded the credentials(Certificate file, Private key, Public key and Root CA certificate) which are going to use it here to connect MQTT with AWS. Overview of protocols: The protocols are used by things (T) and servers (S) to interact and share data. Below are some of the protocols widely used in IoT: MQTT: a protocol for collecting device data and communicating it to servers. This protocol is mainly used for the interaction between the server and the things (T<->S) which is what we are going to discuss in this blog. XMPP: a protocol best for connecting devices to people, a special case of the (T<->S) pattern, since people are connected to the servers DDS: a fast bus for integrating intelligent machines, mainly used for communication between the things (T<->T). AMQP: a queuing system designed to connect servers to each other mainly used for communication between servers (S<->S). What is MQTT and why it is most widely used? MQTT stands for Message Queuing Telemetry Transport. It is publish-subscribe based, extremely simple and lightweight messaging protocol, designed for constrained devices and low-bandwidth, high-latency or unreliable networks. These principles also turn out to make the protocol ideal of the emerging “machine-to-machine” (M2M) or “Internet of Things” world of connected devices, and for mobile applications where bandwidth and battery power are at a premium. Quality of Service(QoS): The QoS ensures the delivery of the content to the receiver the use of the QoS levels are solely based on our need. Mostly, the QoS-1 is preferred as it handles retransmission of data for guaranteed transmission at least once to the receiver. The 3 levels of QoS: Qos-0 – At most once delivery: In this the response is not expected and no retry semantics are defined in the protocol. A QoS-0 message can get lost if the client unexpectedly disconnects or if the server fails. QoS-1 – At least Once Delivery: For this level of service, the MQTT client or the server would attempt to deliver the message at-least once. But there can be a duplicate message. QoS-2 – Exactly once delivery: This is the highest level of Quality of Service. The message is delivered once and only once when QoS-2 is used. Using MQTT in Rails with AWS: As, we have setup everything for using MQTT with AWS now, lets use those credentials we downloaded from the generated certificate to connect to AWS IoT. Connecting the MQTT client: After installing the ‘mqtt’ gem initialize the MQTT::Client with the credentials (certificate file, private key file and the root CA certificate file) that we have generated in the Step 2 of AWS IoT setup that we discussed in the blog Getting started with AWS IoT . Host is the REST API endpoint (Ex: abcedefghijkl.iot.us-west-2.amazonaws.com) of the thing we created in Step 1 of AWS IoT setup. We can copy this endpoint by clicking the IoT thing from the AWS IoT console. Now, you can publish and subscribe to a topic to send and receive the payload. Payload: Here, payload is nothing but the data that we are going to publish to a topic. Publishing: After connecting the client we can publish the payload to the topic with just one command as below: Subscribing : To subscribe to a topic just use the “subscribe” method with topic as the argument. Separate the topics by comma(,) to subscribe to multiple topics. For simulating this MQTT publish-subscribe we can use the MQTT.fx tool and create a connection profile in the tool with the credentials we downloaded from AWS as shown in the screen: As we have successfully implemented a MQTT client with AWS IoT credentials and performed publish-subscribe. In the upcoming blog we will be learning how to use AWS::IoTDataPlane instead of MQTT::Client. Gokul, ROR Junior Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-11-17"},
{"website": "Mallow-Tech", "title": "Getting started with AWS IoT", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/11/iot-with-aws/", "abstract": "IoT or the Internet of Things is new craze. This technology is touted to be future. Internet of Things is basically a network of interconnected electronic devices, physical objects, etc. (referred as “things”) and identified with a Unique Identifier through which they transfer data and interact with each other. Let us look in detail how to build an IoT application in Rails. AWS IoT: AWS IoT provides secure, bi-directional communication between Internet-connected things (such as sensors, actuators, embedded devices, or smart appliances) and the AWS cloud. AWS IoT consists of the following components: Message broker Rules engine Thing registry Thing Shadows service. Thing shadow Device gateway. Security and Identity service To learn about how the above components work see AWS interactive tutorial for IoT in this link: https://console.aws.amazon.com/iot/home?region=us-east-1#/tutorial/help?step=1 Setup for using AWS IoT: As the steps are already defined in AWS website here we try to give the glimpse of the steps: Creating a thing: First step is to create a thing with the optional device attributes to uniquely identify the connected devices. To create a thing click “Create a Resource” button in the Resources dashboard page of AWS IoT and choose ‘Create a thing’. Creating a certificate and activating it: After creating a thing we need to create a certificate which will be used to authenticate the communication to the AWS IoT. To create a certificate click “Create a Resource” button in the Resources dashboard page of AWS IoT and choose ‘Create a certificate’ and then we can generate 1-click certificate are upload our own. After creating, download the certificate, private and public key as public and private key cannot be downloaded after closing the create panel. Generate Root CA file: Copy the text generated in this link: https://www.symantec.com/content/en/us/enterprise/verisign/roots/VeriSign-Class%203-Public-Primary-Certification-Authority-G5.pem and save it as a file with extension(.pem) ex: ‘RootCA.pem’. After creating the certificate select it and choose ‘Activate’ from the “Actions” to activate the certificate. Creating a policy and attaching it to certificate: After creating the certificate we need a policy to authorize the communications to a thing. To create a certificate click “Create a Resource” button in the Resources dashboard page of AWS IoT and choose ‘Create a policy’ and input the name and the statement by specifying the actions (iot:publish, iot:subscribe, etc. ) and the resources (specify * to authorize for all resources or input the specific ARN) and then click ‘Add Statement’ and then click ‘Create’. After creating the policy click on the certificate that we created in the last step and from the ‘Actions’ menu select ‘Attach a policy’ and type policy name to attach. For more details in setting up AWS IoT see: https://docs.aws.amazon.com/iot/latest/developerguide/iot-gs.html In the upcoming post we will see in detail about the creating an IoT application with the help of MQTT . Gokul, ROR Junior Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-11-15"},
{"website": "Mallow-Tech", "title": "Best platform to develop a mobile app – iOS or Android?", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/10/best-platform-to-develop-a-mobile-app-ios-or-android/", "abstract": "You just thought of a brilliant idea for the perfect mobile app. It is new and nothing like it is in the market and you are certain it would be a big hit! But, you don’t know how to go forward with, if it needs to be developed in iOS or Android or Both. After spending almost two years as a designer and a marketeer at Mallow Technologies, I wish to share some insights I’ve learnt. Before developing any application you need to be sure of few things. What is that you are going to do? What is the problem that you are going to solve? or How is it going to make a part of the user’s life better? These questions answered, would define a clear goal for the app. An application has to be clear and precise in the idea of about how the problem is to be solved. The app has to be clear in the value it is going to add to the customer or the user. If that is not clear then it might not be a good option to proceed further. Next comes the big question of what platform should the app be done in. The prominent question is if the app is to be developed in iOS or Android or Both. This relies on various factors such as demographic, geographic and user segment. You have to have a clear idea of the user base you are addressing to. Android currently has the largest global platform share. It has a prominence in lower income areas and developing nations. Comparatively, iOS users have higher income, more engagement, and spend more per app. This doesn’t mean, those who have the same characteristics won’t carry an Android device. Rather, this is indicative of the general Android population. The user demographics decides the platform for the app to be developed and also if it is to be a paid app or a free app. If the business model is to generate revenue. Then it has to be sure that the user segment is right.  Android has a higher percentage of ad-supported apps and paying for apps is still more common on iOS. Now comes the time frame to develop the app. It has been observed that Android development consumes nearly twice the time needed to develop in iOS. So if time is a constraint and you have to go for one among the two platforms, then it will be better to go with iOS platform. Next, the version for which the app is to be developed has to be decided. Version discrepancies play a key role in app development and it cannot be ignored. Adoption factor of the OS forms a major factor. Even though Android is open source, it generally is locked down by the mobile manufacturers. This causes Android to lag behind iOS in adoption rate of its latest OS version. In case of, Android nearly 72% of the people don’t have an updated version of the recent OS. Whereas the adoption rate of iOS users is around 80%. Apple’s audience is more engaged and loyal, where as Android allows you to reach a wider audience. Since, Android is an open source operating system, it has “mods” like CyanogenMOD or Paranoid Android. It gives developers a lot of access into the OS. This can’t be done in iOS, making certain apps to be available only on Android. If you decide to develop on both the platforms, the question of whether to develop them simultaneously arises. Simultaneous development costs a lot and ROI is tough. And building an app that works well on just one device is challenging enough. My general advice is to start with the iOS platform first. During the first stages of any app, there would be a of learning about what’s working and what’s not. Trying to apply all that learning across two platforms is time and cost prohibitive. Developing in Android first makes sense, if the target audience is largely focused on Android. Especially in developing nations or certain user segments. There are number of factors that play a role in deciding the platform to develop an application. By analysing and answering each question, you can create a sustainable application. Each platform has its own pros and cons. And choosing one over the other is entirely based on the needs of the specific application. Marketing Team. Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-10-26"},
{"website": "Mallow-Tech", "title": "What is Automation Testing", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/10/automation-testing/", "abstract": "Automation Testing Manual testing is performed by a human sitting in front of a computer carefully executing the test steps. Automation testing is to test the same modules again and again without any deviation automatically without a person initiating the process each time. Test Automation demands ROI of money and resources. Each development process needs to be tested again and again.  To reduce the testing time and cost, we have to automate the testing script. Automation testing is to reduce the human effort and cost. Why Test Automation Automated Software Testing Saves Time and Money Testing is repeated for each and every cycle, this increases effort, time and cost, to reduce this, we have to automate the repeating modules by the help of automation tools, in each and every testing cycle if we run the test scripts it saves lots of time and money. Vastly Increases Your Test Coverage Automation testing increases the depth of testing. The lengthy test cases which are avoided during manual testing can be done by automation testing, We can even run the same script on multiple computers and different configurations. and internal program states to determine if the product is behaving as expected. Test automation can easily execute thousands of different complex test cases during every test run providing coverage that is impossible with manual tests. Testing Improves Accuracy Even the most efficient tester will make mistakes during the repetition of manual testing. Automated tests perform the same steps consecutively every time they are executed and never forget to record detailed results. Testers freed from repetitive manual tests have more time to create new automated test script and deal with complex features Automation Does What Manual Testing Cannot Even an efficient and largest team of tons of experience cannot simulate thousands of users in manual testing. Automated testing can simulate tens, hundreds or thousands of virtual users interacting with a network, software and web applications. Automated QA Testing Helps Developers and Testers Automated tests shared by testers can be used by developers to catch problems quickly before sending to QA. Tests can run automatically whenever source code changes are checked in and notify the team or the developer if they fail. Features like these save developers time and increase their confidence. QA and Dev Team Morale Improves By executing repetitive test case in automation testing gives more confidence which leads to work on many projects and which also improves the growth of the individuals and organisation. Test Automation Process: The test automation process has following steps. Each of these steps are explained below in detail. Assessment & Tool Evaluation Test Tool selection largely depends on the technology the Application Under Test is built on. Criteria for Tool Selection: For automating any application, the following parameters should be considered. Data-driven capabilities Debugging and logging capabilities Platform independence Extensibility & Customisability E-mail Notifications Version control friendly Support unattended test runs 2. Planning & Design After the identification of automation tool which lead to the realisation of potential benefits and before we start the implementation of automation, the technical feasibility of the process also needs to be established. During this process, QA teams need to understand the application requirement and validation types which would be required. next, they need to evaluate the project management tools available within the company to support these requirements, in which test management tools and automation tools are configured each other. 3. Implementation : After the planning and design, the most important step in automation testing process is the selection of accurate automation framework. Teams can select the appropriate test framework based in the requirement, which leads to reuse easy to maintain large test suit. A data-driven framework is generally better suited for highly repetitive testing involving similar data while the keyword driven framework is typically adopted when testing involves performing actions on the applications. It is advisable to evaluate the framework by conducting a proof-of-concept on a small scale involving a handful of test cases. 4. Test Execution &Report Automation Scripts are executed during this phase. Once executed they provide detailed test reports.  according to the input test data given. Execution can be performed using the automation tool directly or through the Test Management tool which will invoke the automation tool. 5. Maintenance Maintenance is another important process in test automation when new functionalities are updated to the existing project with successive cycles, the automation script needs to be added based on the new requirements and which leads to easy maintenance for each release cycle, maintenance becomes necessary to improve the quality of automation scripts. Who should be involved with test automation? When evaluating a testing solution, it’s important to have a tool that fits the needs of all of the different team members who will be involved in the testing process. These include: Manual testers Record and playback are important for manual testers, especially those who new to automation. while using the same recorded script with different input data can be a more easy while and finding and fixing problems across multiple environments . Automation engineers For automation engineers, robust support for scripting languages, integrations with CI systems, and the ability to verify the test reports and maintain the test scripts are important Developers: Implement testing into the development process requires the ability to configure tests within IDEs such as Eclipse and Visual Studio. Limitations of Automation Automation testing cannot completely replace manual testing. When ever there is UI changes, It needs script changes and continuous maintenance, in this cases manual is better than automation testing. It needs higher skill level of testers/team members. It can be performed only for positive flow, cannot handle negative flow. It needs more initial time to develop script for test case based on the requirement. – Kumaresan.T, Testing Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-10-17"},
{"website": "Mallow-Tech", "title": "10 common Software Errors and Bugs to watch for", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/10/10-common-software-errors-and-bugs-to-watch-for/", "abstract": "In this post we are going to look on the ten most common software bugs and errors. These are the errors that are most common in the software development and had to be given enough importance to clear of the project. First of all let us see what is meant by an error or a bug. As defined in Wikipedia “An error is a deviation from accuracy or correctness” and  “A software bug is an error, flaw, failure, or fault in a computer program or system that causes it to produce an incorrect or unexpected result, or to behave in unintended ways “. There are many types of error which we come across regularly. 10 Common Types of Software Errors/Bugs: 1) Crash: A crash is the sudden failure of a software application or operating system or of a hardware device such as a hard disk caused due to failure of handling exceptions 2) Functional Errors: Functionality is a way the software is intended to behave. If the behaviour of the software varies from the expected output, then it is said to be functional error. Ex: Expected Functionality for Submit button is that changes/entry entered should be submitted and saved. If the Submit button is not clickable then it is a functionality error. 3) Acknowledgement message error: This is an error caused when the user is acknowledged/given feedback with wrong message or no message after doing an action Eg: Failing to show message while adding/editing data Failing to acknowledge user with email after signing to a forum 4) Missing command errors: This error occurs when an expected command is missing. Ex) If an user creates a new profile and there is no option for the user to exit from this window without creating the profile then this is a missing command error. Since ‘Cancel’/‘Close’ option/button is not available to the user, 5) Grammatical Error/typo error: Syntactic errors are caused due to misspelled words or grammatically incorrect sentences. They are very evident while testing software GUI. 6) Error handling errors: Any errors that occur while the user is interacting with the software needs to be handled in a clear and meaningful manner. If not, it is called as an Error Handling Error. Eg1) The error message gives no indication of what the error actually is. Is it missing mandatory field, saving error, page loading error or is it a system error? Hence, this is an ‘Error Handing Error’. If the software has certain mandatory fields that need to be filled before they can save the information on a form, the validation messages should be clear and indicative of the action that is required by the user. 7) Calculation Errors: These errors occur due to any of the following reasons: •Incorrect data type •Incorrect logic •Incorrect formulae •Incorrect units In 1999, NASA lost its Mars climate orbiter because one of the subcontractors NASA employed had used English units instead of the intended metric system, which caused the orbiter’s thrusters to work incorrectly. Due to this bug, the orbiter crashed almost immediately when it arrived at Mars. 8) Control flow errors: The control flow of a software describes what it will do next and on what condition. For example, consider a scenario where user has to fill in a form and the options available to user are: “Save”, “Save and Next”, and “Cancel”. If a user clicks on ‘Save and Next’ button, the user information in the form should be saved and the form should should show next tab. If clicking on the button does not navigates to next tab of the form, then it is a control flow error. 9) Hardware usage errors: This Error occurs due to the usage of Wrong Device, Device unavailable, Underutilizing device intelligence, Misunderstood status or return code, Wrong operation or instruction codes. 10) Boundary related errors: This error is caused due to boundaries in loop, space, time, memory, mishandling of cases outside boundary. Apart from these if there is a hidden change in an algorithm it might also cause the boundary related errors. Reference: http://www.softwaretestinghelp.com/types-of-software-errors/ Kumaresan.T, Test Engineer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-10-04"},
{"website": "Mallow-Tech", "title": "Speech Recognition API – iOS 10", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/09/speech-recognition-api-ios-10/", "abstract": "In this blog post we are going to see about the introduction of Speech recognition API and how to incorporate it in iOS 10. Speech recognition API was introduced in iOS 10 to analyse speech and convert it into texts. It can be used in mobile apps where the user needs to type a lot. The apps which lets the user write notes, send email – text messages and search can use this which in turn saves a huge amount of time for the user. Some of the popular apps like dictionary.com uses speech recognition technology to search words from the database. Similarly app like Vlingo uses search, messaging, voice dialling and directions from the speech recognition. Also the social media platforms will also uses it as a major tool. The API uses two types of input: 1. Live audio spoken by the user (for example if an user says “Cheese” in a camera app to take a picture). 2. Prerecorded audio files(for example a song can be given as an input and the lyrics can be displayed). This API allows the app to work completely based on the user’s voice input like Voice Navigation (Maps), Voice purchasing (shopping online) etc., It uses SFSpeechRecognizer framework to convert the speech into text. The audio input will be given to the SFSpeechRecognizer and it then converts the audio into transcribed text. Apple has mentioned that it has a support to as major as 50 languages. but to avail few languages internet connectivity is needed. Another good thing is the usage of NSLinguisticTagger. It automtically recognises English text, although it supports many language it is used widely to classify the words into verbs, noun and adjective so that we can concentrate only on the specific words needed. Let us now delve into the process of Speech Recognition. Process of Speech Recognition: Explain why we need speech recognition in our info.plist file NSSpeechRecognitionUsageDescription key. Request authorisation from the user using SFSpeechRecognizer.requestAuthorization //Sample code: SFSpeechRecognizer.requestAuthorization { authStatus in OperationQueue.main().addOperation { switch authStatus { case .authorized: //Go further with the process case .denied: // Print corresponding error message case .restricted: // Print corresponding error message case .notDetermined: // Print corresponding error message } } } 3.Create recognition request using SFSPeechURLRecognitionRequest for pre-recorded audio   and SFSPeechAudioBufferRecognitionRequest for live audio. //Sample code: let recognitionRequest = SFSpeechAudioBufferRecognitionRequest() // Live audio let recognitionRequest = SFSpeechURLRecognitionRequest(url: path) // Prerecorded audio 4.Give the created request to recogniser using SFSpeechRecognitionTask to get the result in text. //Sample code: recognitionTask = speechRecognizer.recognitionTask(with: recognitionRequest) { result, error in if let result = result { print(result.bestTranscription.formattedString) // Transcribed text } } Rajtharan G, iOS Junior Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-09-29"},
{"website": "Mallow-Tech", "title": "What is Eddystone – Google’s beacon for Mobile Commerce", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/01/what-is-eddystone-googles-beacon-for-mobile-commerce/", "abstract": "Beacons: Beacons are low-cost, low-energy transmitters equipped with Bluetooth Low Energy transmission. This is also called as Bluetooth Smart. The BLE consumes low energy. It all started with Apple and iBeacon technology, announced in 2013. Their major purpose is to transmit advertisement packets on a periodic basis. Beacons transmit signals which are picked up by mobile devices that have a BLE receiver in it. The mobile devices use that signal to calculate how far it is to the beacon(i.e., proximity). Smartphones decode the info received to identify the beacon. Uses the signal strength to determine how far it is. Eddystone: Named after a lighthouse in the UK, Eddystone is Google’s answer to Apple’s iBeacon standard. It is a new format for BLE packets( a bunch of data) that beacons broadcast. It supports cross-platform Android, iOS and any platform that supports BLE beacons. Google provides Proximity Beacon API and Google Beacon Platform. These allow the developers to use Eddystone in their projects. Eddystone is an open protocol, i.e., its specification is available for everyone. Types of packets: Eddy stone broadcasts 4 different types of packets. They are: 1. Eddystone-UID: It is a number which defines an identifier of a beacon An app installed on the phone can use the identifier to trigger the desired action. It is 16 bytes long. The first 10 bytes are used for namespace and the next 6 bytes are used as a  unique identifier for the device. It is not compatible with iBeacon(a beacon format from Apple) frame. 2. Eddystone-URL: It is a compressed URL. It is 17 bytes long. It allows an app to read the URL and open it in the browser. 3. Eddystone-TLM: It is Telemetry frame. It encapsulates beacon’s  health status. It is also referred as the metadata about beacons & its current status like battery level. If the beacon has sensors like light sensor, accelerometer, the sensor data are embedded as telemetry packets. It is mainly used for fleet management and diagnostic systems. Beacons broadcast TLMs less frequently than data packets. This packet is broadcast alongside the Eddystone-UID or Eddystone-URL packets 4. Eddystone-EID: Eddystone-EID is a format similar to Eddystone-UID, but with a single 8-byte AES-encrypted identifier that rotates every few minutes, hours or days depending on configuration. A beacon transmitting EID must be registered with Google’s Proximity Beacon API using a registered project under a Google account. Devices detecting an EID transmission can tell an Eddystone-EID transmitter is nearby, but cannot make sense of its identifier without credentials for the Google project/account with which it is registered. To make sense of a transmission, Google’s Proximity Beacon API must be called to fetch usable information based on the ephemeral identifier. This adds an additional level of security for certain applications that may not want other parties to trigger app responses with their own beacons, or reuse beacon transmissions for their own purposes. Applications of Beacons: Beacons have a vast variety of usage in the field of Mobile Commerce. Proximity marketing has become a rage with the help of Beacons only. Beacons have a large role in digitizing and bringing in the smartphone generation to the Brick & Mortar shops. Let us see in detail about the practical applications of the Eddystone beacon in various places. 1. Eddystone for App distribution: You can use Eddystone to present your visitors with a link to your app on App Store or Google Play and encourage them to download it. And then once they’ve done so, the beacon will also broadcast a UID for the app to use. 2. Use the power of proximity with no app: Using Eddystone-URL you can link to any page of your choice so you can power up your business with proximity even if you don’t have your own app. For example, if you’re a restaurant, you may send a link to your online menu that shows up once someone enters your venue. Or, being a retailer, you may feature your current promotions, or display coupons when a mobile user is nearby. 3. Get and deliver more context The third frame type that Eddystone broadcasts is Eddystone-TLM (Telemetry). It’s sensor-driven data on the beacon’s state and, possibly in the future, the environment around it. You could use that data to control temperature and humidity in your warehouse. Telemetry would also enable you to trigger different actions based on various conditions. Therefore, depending on the weather, you could push notifications and invite passers-by to come by and have a cold drink or a cup of warming tea. In a hotel, you’d use that feature to adjust the temperature in rooms, based on conditions and particular guests’ preferences. Google gets the best of both worlds here. As an open source project, Eddystone gets lots of hardware support from vendors, but if developers want to give users the best experience and have an easier time themselves, they have to submit to the walled garden. Eddystone doesn’t need to be tied to Google though, and if developers want to use their own cloud solution or client API, they can. It’s Bluetooth, so really anyone could listen to Eddystone devices, but living outside of the Google Ecosystem just means doing a little more work. Madhan Kumar S, Android Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-01-31"},
{"website": "Mallow-Tech", "title": "AngularJs Directives", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/10/angularjs-directives/", "abstract": "In this post we are going to see about the directives in AngularJS. Also the types of the directives and how the directives helps in running a jquery plugin in Angular. A directive in the AngularJS is a reusable component. Directives in AngularJS covers all the behavioural properties and functionalities of an element in a correct way, thereby keeping all of the functionality together. Rather than tracking the changes on a global level, this helps to keep track of  the changes of one HTML section in one place in a script. Directives are markers on a DOM element (such as an attribute, element name, comment or CSS class) that tells the AngularJS’s HTML compiler ($compile) to attach a specified behaviour to that particular DOM element (e.g. via event listeners). It can be used even to transform the DOM element and its children. Example Directives: See the Pen QEVEzq by sasikala Jayaprakash ( @sasikalaJayaprakash ) on CodePen Custom directives: The Custom directives are used in the AngularJS to extend the functionality of HTML. Custom directives are defined using a “directive” function. A custom directive can simply replace the element for which it is activated. AngularJS application during bootstrap finds the matching elements and do an one time activity using its compile() method of custom directive and then process the element using link() method of the custom directive. It does it based on the scope of the directive. Example: See the Pen example2-directives by sasikala Jayaprakash ( @sasikalaJayaprakash ) on CodePen Directive types $compile can match the directives based on  the element names, attributes, class names, and also as comments. All of the Angular-provided directives match the attribute name, tag name, comments, or class name. The code below demonstrates the various ways a directive (myDir in this case) can be referenced from within a template: Element directives − Directive activates when a matching element is encountered. Attribute − Directive activates when a matching attribute is encountered. CSS − Directive activates when a matching css style is encountered. Comment − Directive activates when a matching comment is encountered. Restrict The “restrict” attribute tells Angular, with one letter, how are we going to create our new directive. A Restrict can take four different values ‘E’, ‘A’, ‘C’, ’M’ or combination of them such as ‘EA’, ‘AC’. Each one has it’s own meaning. Below are the example given for each restrict attribute with the code sample to demonstrate. Restrict Meaning Example E Implies we are going to use our directive as a new HTML element. <my-todo list=”todo” title=”Element”> </my-todo> A Means that our directive is going to take over any HTML element that has an attribute that matches our directive name. <div my-todo list=”todo” title=”Attr”> </div> C Indicates that our directive will be found in CSS classes. <div class=”my-todo” list=”todo” title=”Class”> </div> M Matches HTML comments. <!–directive:my-todo attributes goes here–> Element Directive: See the Pen Restrict-E-example by sasikala Jayaprakash ( @sasikalaJayaprakash ) on CodePen Arrtibute directive: See the Pen attribute-directive by sasikala Jayaprakash ( @sasikalaJayaprakash ) on CodePen Class Directive: See the Pen class directive by sasikala Jayaprakash ( @sasikalaJayaprakash ) on CodePen Comment Directive: See the Pen Comment directive by sasikala Jayaprakash ( @sasikalaJayaprakash ) on CodePen jQuery Plugins as Angular Directives jQuery Plugin On their own, jQuery plugins are easy to use: just initialize the plugin in  a document.ready event. See the Pen ZOrBQb by sasikala Jayaprakash ( @sasikalaJayaprakash ) on CodePen jQuery Plugin in an Angular App Using a jQuery plugin in an Angular app is tricky task. Unfortunately you cannot just move the initialization into your controller. It is not only a bad practice, but Angular won’t be aware of any changes to or interactions with the plugin. This means that data binding with the plugin will be broken. See the Pen yJxVVy by sasikala Jayaprakash ( @sasikalaJayaprakash ) on CodePen Use $scope.$apply() You can restore Angular’s data binding by using $scope.$apply(). This method hooks into Angular’s digest cycle, thus making your app aware of the changes made by the jQuery plugin to any of the $scope properties. See the Pen pbONRv by sasikala Jayaprakash ( @sasikalaJayaprakash ) on CodePen Creating a slider JQuery plugin as directive: To make a jQuery plugin code reusable, you can create a directive for the plugin. Any plugin initialization code should go in the directive’s link method. And then Include the directive in your HTML. See the Pen PzdbWx by sasikala Jayaprakash ( @sasikalaJayaprakash ) on CodePen jQuery plugin as AngularJs Directive. Example : See the Pen Jquery plugin by sasikala Jayaprakash ( @sasikalaJayaprakash ) on CodePen Conclusion: You can see that with the help of directives we were able to run a jquery plugin in Angular. This helps in many ways to run the plugins which are not available in Angular with the help of jquery. Also we have seen in detail the types and usage of the directives in Angular. Sasikala J, Junior Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-10-07"},
{"website": "Mallow-Tech", "title": "How to send Test version over the Air (OTA)", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/09/how-to-send-test-version-over-the-air-ota/", "abstract": "Testing forms an important part before deployment of the app. The testing for an iOS device is different from that of the Android devices. For an android application the apk file can be sent to the testing team and they can test the application. But for an iOS application the IPA cannot be sent. Usually the System is connected with the device and run directly so that the testing can be done with the same. This process is easy when testing team and development team are nearby. When the testing team is remote this forms a problem. We came across a situation where we have to work with the remote testing team. First option we had was Internal Tester. We had to rule out this option because we are using it to send the application to the client. We don’t want complicate the process by including the testing team, removing the clients and keep the looping process. There is a chance of client mistakenly getting the app to be tested and it will result in the chaos. So some of the options we are left with are the XCode, OTA, testfairy, Hockey and Beta. Among these Testfairy, Hockey and Beta are time consuming. Xcode – server method is  where a system is added as server. But the problem with that is you need the device to be connected with the all the time. This becomes another issue if you are testing multiple devices and mutiple products. But OTA is time consuming for setting up once, after updating won’t take much time. Another reason for choosing OTA is that the clients have preference in Testfairy and other services, so we choose OTA as our internal method to test the app. When we decided to go for the OTA (Over The App) process. As the application we are developing have to be in a secured space, we wanted to load the IPA in our own internal server rather than in a external server. We had another issue cropping up. The issue was with our internal server. As the internal server has issue of https with Qnap. To address this issue we went on with the IPA in server and Plist in dropbox. This process will be explained in the following steps. First of all the IPA was generated. After that get the link of the IPA and add in the plist. Once the plist file is generated, place it in drop box. Now get the link from the dropbox and construct an itms link with the dropbox link. You can send the itms link to the testing team to use the file for testing. This setting up is an one time process and for further changes and the updates you just replace the IPA file is the already uploaded path. The testing team in the remote can fetch the updated file with the same link path. A sample itms link is given below. itms-services://?action=download-manifest&url=https://myWebsite/myApp/myApp.plist itms-services://?action=download-manifest&url=<Dropbox URL> By this way solved the issue of testing of iOS apps with the team in a remote location. ———- Yogesh iOS Team Lead, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-09-27"},
{"website": "Mallow-Tech", "title": "Up and Running With Realm for Android", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/01/up-and-running-with-realm-for-android/", "abstract": "In this post, we are going to see in detail about Realm for Android. The realm is a lightweight database which is a very good alternative to SQLite and ORM Libraries in all of your Android Projects. Basically, Realm is a Multi-version Concurrency Control based database that is super fast and very easy to use. Some of the major reasons to opt in for Realm over the other databases are mentioned below Speed: Realm is much faster than its alternatives available in the market. This can be established from the speed test results of quiita.com . This shows the queries each DB can fetch in a second. Ease of use : This is another major factor that substantiates the use of Realm over the other applications. Although the tools like core-data are powerful, the usage is convoluted and consumes a lot of time. In that area Realm scores, a straight shot and eases the difficulty of a user. Also, the presence of Realm browser helps a lot in exploring and editing the content. Cross platform support : Cross-platform support is one of the major advantage Realm gives to the developers. Using the same data tools and models for both Android and iOS means saving a lot of resource time. This is will definitely change from a must needed feature in the upcoming period. As an early adopter in a database, Realm will have the first mover advantage. Detailed documentation : Above all the features, Realm is available for free which makes it easy for anyone to experiment and adopt. Another biggest advantage over other platforms is that Realm is well documented. Now let us see how to add Realm in an Android project in detail. This will give you a detailed explanation of the process involved. 1. Adding Realm to a Project To use Realm in an Android project, you need to add it as a compile dependency in the app module’sbuild.gradle file. compile ‘io.realm:realm-android:0.84.1’ 2. Creating a Realm Realm tools are similar to SQLite database. It has a file associated with it, which, once created, will persist on Android’s file system. in order to create a new one, you can call the static Realm.getInstance method from inside any Activity. Realm myRealm = Realm.getInstance(context); Note that calling Realm.getInstance, without passing a RealmConfiguration to it, results in the creation of a Realm file called default.realm . If you want to add another Realm to your app, you must use a RealmConfiguration.Builder object and give the Realm file a unique name. Realm myOtherRealm =         Realm.getInstance( new RealmConfiguration.Builder(context) .name(\"myOtherRealm.realm\") .build() ); 3. Creating a RealmObject JavaBean can be stored in a Realm once it extends to the RealmObject class. If you are wondering what a JavaBean might be, it is simply a Java class that is serializable which has a default constructor and has getter/setter methods for its member variables. For example, instances of the following class can be easily stored in a Realm: public class Country extends RealmObject { private String name; private int population; public Country() { } public String getName() { return name; } public void setName(String name) { this.name = name; } public int getPopulation() { return population; } public void setPopulation(int population) { this.population = population; } } If you want to use a member variable of a RealmObject as a primary key, you can use the @PrimaryKey annotation. For example, here’s how you would add a primary key called code to the Country class: @PrimaryKey private String code; public String getCode() { return code; } public void setCode(String code) { this.code = code; } 4. Creating Transactions While reading data from a Realm is very simple, as you will see in the next step, writing data to it is slightly more complex. The realm is ACID compliant and to ensure atomicity and consistency, Realm forces you to execute all write operations inside a transaction. To start a new transaction, use the beginTransaction method. Similarly, to end the transaction, use thecommitTransaction method. Here’s how you would create and save an instance of the Country class: myRealm.beginTransaction(); // Create an object Country country1 = myRealm.createObject(Country.class); // Set its fields country1.setName(\"Norway\"); country1.setPopulation(5165800); country1.setCode(\"NO\"); myRealm.commitTransaction(); You might have noticed that country1 was not created using the constructor of the Country class. For a Realm to manage an instance of a RealmObject, the instance must be created using the createObjectmethod. If you must use the constructor, don’t forget to use the copyToRealm method of the relevant Realm object before you commit the transaction. Here’s an example: // Create the object Country country2 = new Country(); country2.setName(\"Russia\"); country2.setPopulation(146430430); country2.setCode(\"RU\"); myRealm.beginTransaction(); Country copyOfCountry2 = myRealm.copyToRealm(country2); myRealm.commitTransaction(); 5. Writing Queries Realm offers a very intuitive and fluent API for creating queries. To create a query, use the where method of the relevant Realm object and pass the class of the objects you are interested in. After creating the query, you can fetch all results using the findAll method , which returns a RealmResults object. In the following example, we fetch and print all objects of type Country: RealmResults<Country> results1 = myRealm.where(Country.class).findAll(); for(Country c:results1) { Log.d(\"results1\", c.getName()); } // Prints Norway, Russia Realm offers several aptly named methods , such as beginsWith, endsWith, lesserThan and greaterThan , you can use to filter the results. The following code shows you how you can use the greaterThan method to fetch only those Country objects whose population is greater than 100 million: RealmResults<Country> results2 = myRealm.where(Country.class) .greaterThan(\"population\", 100000000) .findAll(); // Gets only Russia If you want the results of the query to be sorted, you can use the findAllSorted method. As its arguments, it takes a String specifying the name of the field to sort by and a boolean specifying the sort order. // Sort by name, in descending order RealmResults<Country> results3 = myRealm.where(Country.class) .findAllSorted(\"name\", false); // Gets Russia, Norway Reference link: https://realm.io/docs/java/latest/ Android Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-01-25"},
{"website": "Mallow-Tech", "title": "Challenges in laravel while using bootstrap modal", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/08/challenges-in-laravel-while-using-bootstrap-modal/", "abstract": "This week we will see on the challenges faced in Laravel Bootstrap Modal. One of the primary thing is on pre population of old values.  The important issue is to pre populate old values in the modal and display the error message against the respective textbox. We can solve this issue with the help of a Helper Class as we have described below. Helper classes The following functions are used for displaying old() values / current values and validation error  messages in a Model. Display the error messages function showErrorMessage($errors, $fieldName, $oldModalName = null, $modelName = null) { if ($errors->has($fieldName) && ($oldModalName == $modelName)) { return “<span class=’error errorMessage’><strong>” . $errors->first($fieldName) . “</strong></span>”; } } Pre-populate data function showOldData($errors, $fieldName, $object = null, $oldModalName = null, $modelName = null, $databaseFieldName = null) { if ((count($errors) > 0) && ($oldModalName == $modelName)) { return old($fieldName); } else { if ($object != null) { if ($databaseFieldName != null) { return $object[$databaseFieldName]; } else { return $object[$fieldName]; } } else { return ”; } } } View file <input type=”hidden” name=”customerModal” value=“edit-customer-modal-{{ $customer->id }}”> <div class=”form-group”> <label class=”control-label”>Name *</label> <input type=”text” name=”name” class=”form-control” value=”{{ showOldData($errors, ‘name’, $customer, old(‘customerModal’), ‘edit-customer-modal-‘ . $customer->id) }}”  required> {!! showErrorMessage($errors, ‘name’, old(‘customerModal’), ‘edit-customer-modal-‘ . $customer->id) !!} </div> In this view file, we call the showOldData() helper function to get the old values or to show the current values for particular modal. It is very useful when edit option is in the table or data table and displaying the edit option in modal without Ajax call. Arguments used in showOldData() method First : errors object. Second : pass the input field name (or corresponding database field name). Third :pass the object or collection( if it is edit option pass object , else if it is create option pass null). Fourth : pass the old value of current modal id (if the edit option is in the page, you need to give this as null). Fifth : pass the current modal id (if the edit option is in the page, you need to give this as null). Sixth : if the input element name and the database field name are different, pass the database field name(optional). Eg for sixth argument <input type=”email” name=”emails[]” class=“form-control” value=”{{ showOldData($errors, ’emails.0′, $customer->emails->first(), old(‘customerModal’), ‘edit-customer-modal-‘ . $customer->id, ’email’) }}” required> Arguments used in showErrorMessage() method First : errors object. Second : pass the input field name. Third : pass the old value of current modal id (if the edit option is in the page, it is not required). Fourth : pass the current modal id (if the edit option is in the page, it is not required). Hope this has helped you to display the error message and old values in the bootstrap modal but we can reduce the complexity if we start using  AngularJs or Vue.js so start concentrating to learn this which would help you lot in solving the above issues That’s all for now we will come back with a more interesting blog next time. Anandhan S, Junior Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-08-05"},
{"website": "Mallow-Tech", "title": "Multi tenancy for rails and active record", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/08/multi-tenancy-for-rails-and-active-record/", "abstract": "The term “software multitenancy” refers to a software architecture in which a single instance of software runs on a server and serves multiple tenants. A tenant is a group of users who share a common access with specific privileges to the software instance. With a multitenant architecture, a software application is designed to provide every tenant a dedicated share of the instance – including its data, configuration, user management, tenant individual functionality and non-functional properties . Multitenancy contrasts with multi-instance architectures, where separate software instances operate on behalf of different tenants. Multi-tenant application mainly has three type of users. 1) Admins 2) Managers 3) Users Advantages of multi-tenancy: 1) Cost savings 2) Scalability 3) Service 4) Upgrades Examples of multi-tenant applications Application like GitHub, where each user or organisation can have their own separate area within the application or Heroku where each user has their own separate app group. We, at mallow tech has built a multi-tenant app for one of our client and we have used gem called “Apartment” to achieve multi-tenancy Apartment provides tools to help you deal with multiple tenants in your Rails application. Apartment ships with cleverly-named “elevators” for switching between tenants. Apartment can support many different “Elevators” that can take care of this routing to your data. 1) Switch on subdomain 2) Switch on first subdomain 3) Switch on domain 4) Switch on full host using a hash 5) Custom Elevator We can switch between tenants on each request but still If you have some models that should always access the ‘public’ tenant, you can specify this by configuring Apartment using Apartment.configure. This will yield a config object for you. You can set excluded models like so: config.excluded_models = [“User”, “Company”] In gem apartment https://github.com/influitive/apartment , we can use separate databases for each company. This makes system more secure by considering data will not be sharable to other company. By default, ActiveRecord will use “$user”, public as the default schema_search_path. This can be modified if you wish to use a different default schema be setting: config.default_schema = “some_other_schema” With that set, all excluded models will use this schema as the table name prefix instead of public and reset on Apartment::Tenant will return to this schema as well. Apartment will normally just switch the schema_search_path whole hog to the one passed in. This can lead to problems if you want other schemas to always be searched as well. Enter persistent_schemas. You can configure a list of other schemas that will always remain in the search path, while the default gets swapped out: config.persistent_schemas = [‘some’, ‘other’, ‘schemas’] With this information hope you would have got some idea on how to build a multi-tenant app and please share us your feedbacks, if any and we will try to get back Logesh M, ROR Team Lead, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-08-05"},
{"website": "Mallow-Tech", "title": "Authentication and Authorisation", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/07/authentication-and-authorisation/", "abstract": "In today’s blog we are going to see about the usage of Authentication and Authorisation working in the Single Page Applications. Basically applications are designed in such a way that the user has to authenticate themselves to see certain data or to perform certain action on the application. This is where the Logging in action comes in to picture to identify the user. The server will be responsible to identify the end user. It exposes the user to an authentication point. At the endpoint the user will enter the credentials to log in which will be sent to the server for verification. Typically the service may respond with access token or object with name and role mentioned. Based on this the user can validate the credentials. With this only the user can access token in all secured requests made to server. From this action we can see that the access token will be used multiple times and hence it is better to store it on the client side. In Angular, the value can be stored in a service or as a singleton object on the client side. But the problem with storing as a singleton object is that it cannot be used once the page is refreshed thus prompting the action to enter credentials again. Thus is suggested to store the value preferable by SessionStorage, as it will be cleared only when the browser is closed. Implementing Login Let as assume that we have the server side logic implemented and the service exposes an endpoint to check the credentials and provide an access token. Let’s write a simple service that performs the action to login by a clickable button which is the authentication endpoint. Handling Page Refresh If the user hits the refresh button, then the service loses it state. Rather than asking for the credentials again we have to fetch the data from the browser’s sessionStorage and assign to the variable so as maintain the logged in status. As a factory is invokes only once, we can ser this variable in an initialization function. Logging Out If the user logs out of the application, then the corresponding API has to be invoked with the access token included in the request headers. Once the user is logged out, we should clear the data in sessionStorage as well. The following example contains the logout function that has to be added to the authentication service. See the Pen authServices by murali ( @murale ) on CodePen . Set and get the token using AuthToken service. login.js See the Pen yJXmmB by murali ( @murale ) on CodePen . Changing the state to be mange the process Change the state from one to another to check the token is present or not. If the token is present move another state else it moves to the login state. See the Pen appjs by murali ( @murale ) on CodePen . AuthToken service is get and set the token. Session Storage is to be storing the token details. Suppose the page is to be refreshing it gets the token into the session Storage. See the Pen mainjs by murali ( @murale ) on CodePen . Authorization and Role based permissions We will be adding 2 Layer to implement Authorization in our app UI manipulation – Showing or hiding part of the screens based on the user permission Routing – When the user access a route that he doesn’t have permission will redirect him to an error  route How will we implement it? We want to get all the user permissions before loading our app then we will store it (using a service) for showing/hiding sections of our app that require special permissions we will use a directive for that Then when we define a route we will add extra parameter permission and give it’s a value for the permission. Adding the permission service in app.js and login.js app.js See the Pen modifyApp by murali ( @murale ) on CodePen . login.js See the Pen modifylogin by murali ( @murale ) on CodePen . Set and get permission list set and get the permission list using permission factory. If access any page to the permission list. permission.js See the Pen permisison by murali ( @murale ) on CodePen . Has permission directive How to show/hide UI elements based on the user permissions In this part we will be building a directive that will show & hide elements based on the user permissions. haspermisison.js See the Pen haspermisison by murali ( @murale ) on CodePen . Show and hide the HTML element Single permission: See the Pen hideelemetsignle by murali ( @murale ) on CodePen . As seen in the example above we are using has-permission and passing it the permission name. Multiple permission If sometimes need for multiple permission at a single element so change the haspermission directive See the Pen mutliplepermisison by murali ( @murale ) on CodePen . It accept for multiple permission using AND,OR operator hide the Html element See the Pen multiplehtmlview by murali ( @murale ) on CodePen . Access Validation while calling the API What we have done so far is hiding the parts of the UI that the user doesn’t have access to, another part is putting permissions on the angular routes itself, so if the user writes the URL by hand the permissions will still work See the Pen root by murali ( @murale ) on CodePen . If check the permission is available in the permission list then it allowed to get the detail and allow to access the root . Murali M, Junior Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-07-08"},
{"website": "Mallow-Tech", "title": "FetchedResultsController(FRC) – Part 2", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/06/fetchedresultscontrollerfrc-part-2/", "abstract": "In the previous post we saw what is fetched results controller and its usage of single fetchedResultsControllers in a same view controller. In this post we will see the usage multiple fetched results controller in same view controller. Using multiple fetchedResultsControllers in same view controller: You may rise a question wether can we use multiple FRC in same view controller? Yes, we can. Let us take a scenario where we can use two FRCs in a single view controller. Think about a TODO application in which we need to list two sections in a tableView where first section will list the todo item which are un-completed from “UnCompleted” table, and the second section will list the completed todo list from “Completed” table. Create two instances of NSFetchedResultsController. //CODE //FRC instances @property (strong, nonatomic) NSFetchedResultsController *completedFetchedResultsController; @property (strong, nonatomic) NSFetchedResultsController *unCompletedFetchedResultsController; – (void)viewDidLoad { [super viewDidLoad]; //Initialize fetchedResultsController // Perform Fetch action NSError *completedError = nil; [self.completedFetchedResultsController performFetch:&completedError]; // Handle error if (completedError) { // Handle error here. (eg., alert, logging, retry option,…) } // Perform Fetch action NSError *unCompletedError = nil; [self.unCompletedFetchedResultsController performFetch:&unCompletedError]; // Handle error if (unCompletedError) { // Handle error here. (eg., alert, logging, retry option,…) } } //Initialize the two fetchedResultsController – (NSFetchedResultsController *)completedFetchedResultsController { //Return FRC if its already fetched if (self.completedFetchedResultsController!= nil) { return self.completedFetchedResultsController; } // Initialize Fetch Request NSFetchRequest *fetchRequest = [[NSFetchRequest alloc] initWithEntityName:@”Completed”]; // Add sort descriptors(Mandatory) [fetchRequest setSortDescriptors:@[[NSSortDescriptor sortDescriptorWithKey:@”updatedAt” ascending:YES]]]; // Add batchSize(Optional) [fetchRequest setFetchBatchSize:20]; // Initialize FetchedResultsController self.completedFetchedResultsController = [[NSFetchedResultsController alloc] initWithFetchRequest:fetchRequest managedObjectContext:self.managedObjectContext sectionNameKeyPath:nil cacheName:nil]; // Assign delegate for FetchedResultsController [self.completedFetchedResultsController setDelegate:self]; // Return fetched result controller return self.completedFetchedResultsController; } – (NSFetchedResultsController *)unCompletedFetchedResultsController { //Return FRC if its already fetched if (self.unCompletedFetchedResultsController != nil) { return self.unCompletedFetchedResultsController; } // Initialize Fetch Request NSFetchRequest *fetchRequest = [[NSFetchRequest alloc] initWithEntityName:@”UnCompleted”]; // Add sort descriptors(Mandatory) [fetchRequest setSortDescriptors:@[[NSSortDescriptor sortDescriptorWithKey:@”updatedAt” ascending:YES]]]; // Add batchSize(Optional) [fetchRequest setFetchBatchSize:20]; // Initialize FetchedResultsController self.unCompletedFetchedResultsController = [[NSFetchedResultsController alloc] initWithFetchRequest:fetchRequest managedObjectContext:self.managedObjectContext sectionNameKeyPath:nil cacheName:nil]; // Assign delegate for FetchedResultsController [self.unCompletedFetchedResultsController setDelegate:self]; //Return fetched result controller return self.unCompletedFetchedResultsController; } Now we have initialized two fetchedResultsControllers and has required data in the same view controller. Now we have to be careful while setting tableView delegate and datasource. Lets now configure tableView datasource and delegate methods by making use of the two fetchedResultsControllers we have, Implementing : UITableViewDataSource using two FRCs:- //Set number of sections – (NSInteger)numberOfSectionsInTableView:(UITableView *)tableView { return [[self.completedFetchedResultsController sections] count] + [[self.unCompletedFetchedResultsController sections] count]; } //Set number of rows in each section – (NSInteger)tableView:(UITableView *)tableView numberOfRowsInSection:(NSInteger)section { int rowsCount = 0; if (section < [[self.completedFetchedResultsController sections] count] ) {         //First FRC id<NSFetchedResultsSectionInfo>  sectionInfo = [self.completedFetchedResultsController sections][section]; rowsCount = [sectionInfo numberOfObjects]; } else {    //Second FRC id<NSFetchedResultsSectionInfo>  sectionInfo = [self.unCompletedFetchedResultsController sections][section]; rowsCount = [sectionInfo numberOfObjects]; } return rowsCount; } //Now configuring cell for row at index path, mostly there wont be any change in this datasource since the object received from “configureCell:atIndexPath” returns NSManagedObject there wont be any changes needed in cellForRowAtIndexPath. – (UITableViewCell *)tableView:(UITableView *)tableView cellForRowAtIndexPath:(NSIndexPath *)indexPath { UITableViewCell *cell = (UITableViewCell*)[tableView dequeueReusableCellWithIdentifier:@”Cell” forIndexPath:indexPath]; // Configure tableViewCell using fetchedResultController [self configureCell:cell atIndexPath:indexPath]; return cell; } //In configureCell:atIndexPath we need to return object based on the section in our case as shown below. – (void)configureCell:(UITableViewCell *)cell atIndexPath:(NSIndexPath *)indexPath { if (indexPath.section == 1) { // Get respective record from fetchedResultController //Instances for “Completed”(Subclass of NSManagedObject class) table Completed *completedObject *record = [self.completedFetchedResultsController objectAtIndexPath:indexPath]; // Update cell contents [cell.titleLabel setText:[record valueForKey:@“note”]]; } else if (indexPath.section == 2) { // Get respective record from fetchedResultController //Instances for “UnCompleted”(Subclass of NSManagedObject class) table UnCompleted *record = [self.unCompletedFetchedResultsController objectAtIndexPath:indexPath]; // Update cell contents [cell.titleLabel setText:[record valueForKey:@“note”]]; } Thats it, this is a sample shown above which shows how to handle multiple fetched results controller in a same view controller, but we can use multiple fetched results controller in many other cases based on your requirement. Some advanced topics in FetchedResultsController: mergeChangesFromContextDidSaveNotification: It merges the changes specified in a given notification. This method refreshes any objects which have been updated in the other context, faults in any newly-inserted objects, and invokes deleteObject:: on those which have been deleted. You can pass a NSManagedObjectContextDidSaveNotification notification posted by a managed object context on another thread, however you must not use the managed objects in the user info dictionary directly. For more details, see Concurrency with Core Data. Bharath R, iOS Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-06-15"},
{"website": "Mallow-Tech", "title": "Introduction to Glide, Image Loader Library for Android", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/08/introduction-to-glide-image-loader-library-for-android/", "abstract": "What is glide? Library used to download the image in android app. Advantage: 1. fast and efficient 2. Use less memory and disk space. 3. Very easy to implement. 4. support animated Gif file 5. Using in the list is very efficient. 6. In the latest version glide 3.7.0 fix the memory leak for gif files 7. Fix issue in releasing the memory while calling clear memory. 8. Having different method for clearing diskcache and also separate method to set. 9. Also we can also increase Glide’s Image Quality (builder.setDecodeFormat(DecodeFormat.PREFER_ARGB_8888)) 10. Having many options like loading images from resources, file and from Uri. 11. the clarity of the image while comparing to picasso, Gilde have more clarity of image and also memory utilisation is very low. 12. Glide loads an image to memory and do the caching is better than Picasso which let an image loaded far faster 13. Automatic job cancellation in lists where views are re-used. Below methods are very useful while comparing to other image downloading library. .setMemoryCache(MemoryCache memoryCache) .setDiskCache(DiskCache.Factory diskCacheFactory) .setDiskCacheService(ExecutorService service) .setResizeService(ExecutorService service) In the passed Google Developer Summit Thailand, Google introduced us an Image Loader Library for Android developed by bumptech named Glide as a library that recommended by Google , Must say that it looks 90% similar to Picasso I mport to project Both Picasso and Glide are on jcenter. You can simply import it to your project with dependency like this: Picasso : dependencies { compile ‘com.squareup.picasso:picasso:2.5.1’ } Glide : dependencies { compile ‘com.github.bumptech.glide:glide:3.5.2’ compile ‘com.android.support:support-v4:22.0.0’ } Please don’t forget to import support-v4 to your project like above as well. Basic Picasso : Picasso.with(context) .load(“http://inthecheesefactory.com/uploads/source/glidepicasso/cover.jpg”) .into(ivImg); Glide : Glide.with(context) .load(“http://inthecheesefactory.com/uploads/source/glidepicasso/cover.jpg”) .into(ivImg); Although it looks quite the same but in details Glide is designed far better since with doesn’t accept only Context but also Activity and Fragment. Context will be automatically extracted from those things you throw in. Features: A lmost all the same things just like Picasso can do with the same style of coding for example Image Resizing : // Picasso .resize(300, 200); // Glide .override(300, 200); Center Cropping: // Picasso .centerCrop(); // Glide .centerCrop(); Transforming: // Picasso .transform(new CircleTransform()) // Glide .transform(new CircleTransform(context)) Placeholder and Error image: // Picasso .placeholder(R.drawable.placeholder) .error(R.drawable.imagenotfound) // Glide .placeholder(R.drawable.placeholder) .error(R.drawable.imagenotfound) Difference image loader’s: Android Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-08-05"},
{"website": "Mallow-Tech", "title": "Digital Marketing meet-up", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/06/digital-marketing-meet-up/", "abstract": "Last week I had attended a Digital Marketing meet-up, at Rang Mahal, Chennai. The event was organised by ‘Sorav Jain’ of EchoVME . I participated representing Mallow and as a part of learning from the experts. The meet up had two eminent speakers. First one was ‘Dorai Thodla’. He is the founder of iMorph Innovation Center Private limited. He actively manages many businesses and is a techie with great eye for marketing. His session was about marketing automation. He classified the tools used for marketing automation into three categories; Free and easy to use tools, inexpensive tools and the expensive tools. One of the key takeaways from his session was, marketers should use the vocabulary of customers. A marketer is should always see from a user perspective than the perspective of an expert. Then the second session for the day was by ‘Peter Claridge’, Global Marketing Manager at Unmetric. He explained about the reach and the importance of measurement. More than measurement the metrics that is used was clearly explained. So the metric is not an universal measure but rather goal specific. It was kind of hard to believe the fact, that for company profiles and pages with more than 5 Lakh followers, the organic engagement is less than 3%. This explains the ways of engagement followed by the channels. Due to this reason, the need for the measurement is necessary. After this, the Digital Marketing Q&A session took place. The panel included experts from EchoVME along with the speakers of the day. Various discussions were held and the panel members cleared the doubts of many participants. All the participants are marketing personnel from various organisations. It was a great learning experience and the event gave us a better idea in our approach and methods. Gopalakrishnan. Marketing Executive, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-06-10"},
{"website": "Mallow-Tech", "title": "Request Life Cycle of Laravel", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/06/request-life-cycle-of-laravel/", "abstract": "When we start working on a framework or tool or service, we should have a detail knowledge on how it works from the scratch. This knowledge will make us more comfortable with that platform. This blog is to help you get to know about Laravel’s ‘ Request Life Cycle ‘ i.e, how this framework processes the given request in different stages and provide the response to the user. We will look into this as step by step process for better understanding. Auto Loader As a first step, the request will be triggered from the user’s browser, then it will reach web server. Web server (Apache or Nginx) will redirect the given request to Laravel public/index.php file which is simply a starting point for loading the rest of the framework. It loads the auto loader files which is generated by composer. Then it retrieves an instance of the Laravel application from bootstrap/app.php script. Laravel itself creates an instance of the application, is the initial/first step. Kernel Next step will occur on the Kernel part of the application. The incoming request is sent to either the HTTP kernel or the console kernel, depending on the type of request that is entering the application .These two kernels serve as the central location that all requests flow through. HTTP kernel, which is placed in app/Http/Kernel.php. It just receive a Request and return a Response. Bootstrappers that are defined by the Kernel class, which configures error handling, configure logging, detect environments and other tasks to be done before the request handled. HTTP Kernel will define the list of middleware that are passed through before handled by application. Service Providers Next step of the kernel is to load service providers as part of the bootstrapping action. Providers that are needed for the application are placed in config/app.php configuration file. While the register method calls, all the providers will be registered. Once all providers are registered, then boot method will be called. Dispatch Request Once the application have been bootstrapped and all service providers are registered and booted, the request will be handed over to the router for dispatching. The router will dispatch the request to a route or controller, as well as run any route specific middleware. Router: Now request will be dispatched by the Router and it will end up with the views as shown below: Router will direct the HTTP Request to a Controller or return a view or responses directly by omitting the controller. These routes will be placed in app/routes.php. Controller app/controllers/ performs specific actions and sends data to a View. View app/views/ formats the data appropriately, providing the HTTP Response. The above steps are clearly explained in the diagrammatical view below. Let’s see an example for a request Step 1 The user input http://xyz.com in the browser and hits ‘enter’. Step 2 Once the user hit this URL, the browser will send the page request over the Internet to the web server. Step 3 Web server will receive the request and analyze the request information. In web server’s configuration file, site’s root path is specified. Based on that, web server will look for index.php file in that root directory, since URL doesn’t contain any sub directory or any other routes. Step 4 Web server will direct the request to public/index.php file of laravel application. Step 5 In this step, PHP Interpreter is executing the code contained in the index.php file from the request. During this step, auto loader files which are generated by composer will be loaded. Step 6 Then it will create the laravel instance and bootstrapping the components of laravel. Step 7 The kernel will receive the request, load the service providers and will be redirected to router. Step 8 Router will render the view file content and return back to web server. Step 9 Web server receives the output from PHP and sends it back over the Internet to a user’s web browser. Step 10 The user’s web browser receives the response from the server, and renders the web page on user’s computer. Conclusion By understanding the flow of the request life cycle, we will have more confidence while developing a application. Also it will provide enough skill to debug the code in a faster way. We can easily track the issues during some unexpected situations. Gayathri.V, PHP Senior Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-06-14"},
{"website": "Mallow-Tech", "title": "jQuery Vs AngularJs", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/06/jquery-vs-angularjs/", "abstract": "JQuery: jQuery is a fast, small, and feature-rich JavaScript library. It makes things like HTML document traversal and manipulation, event handling, animation, and Ajax much simpler with an easy-to-use API that works across a multitude of browsers. jQuery features: Easily manipulate the contents of a webpage Apply styles to make UI more attractive Easy DOM traversal Effects and animation Simple to make AJAX calls Events Extensibility Core functionality 1.Easily manipulate the contents of a webpage Provides functions for editing and changing documents contents and working with CSS data such as positioning info. 2.User Interface Provides an official plug-in with commonly used interface widgets, like slider controls, progress bars, accordions and more.. 3.DOM Traversal Provides functions for finding content in documents and navigating amount the contents of the document. Example <p id=“”foo>This is a paragraph of text with a <a href=“/path/to/another/page.html”>link</a></p> 4.Effects and animation Provides functions for creating basic animations and effects, such as hiding and showing elements and moving objects  around. 5.AJAX calls Provides utilities for working with Ajax, such as loading contents from pages and dealing with JSON data. 6.Events Simplifies working with the modern DOM events and provides common event helper functions 7.Extensibility Enables the construction of jQuery plug-ins that enhance the functionality of the base library. 8.Core functionality Implements core jQuery functions as well as commonly used utilities. Example: $.trim(); $.trim( ”    Extra whitespace here   ” ); It’s returns “Extra whitespace here”. AngularJS AngularJS is a structural framework for dynamic web apps. It lets you use HTML as your template language and lets you extend HTML’s syntax to express your application’s components clearly and succinctly. Angular’s data binding and dependency injection eliminate much of the code you would otherwise have to write. AngularJS features: Two-Way data binding Dependency Injection Deep Linking MVC-based Pattern Full Testing Environment Directives Expressions Single page application Form Validation REST friendly Localisation Template Server Communication The Major features of AngularJs: One way data binding Vs Two way data binding. One way data binding: jQuery template system bind data in only one direction: they merge template and model components together into a view. After the merge occurs, changes to the model or related sections of the view are NOT automatically reflected in the view. Worse, any changes that the user makes to the view are not reflected  in the model. This means that the developer has to write code that constantly syncs the view with the model and the model with the view. One way data binding example: Link: See the Pen jquery Two-way bind by murali ( @murale ) on CodePen . Two-Way Data binding: Data-binding in Angular apps is the automatic synchronization of data between model and view components. The way that Angular implements data-binding lets you treat the model as the single-source-of-truth in your application. In two-way data binding, any change made in the view will reflect in model, similarly changes made in the model will reflect in the view. It is a two way process. Angular ng-model directive to create a data binding process. Two way binding  example: Link: See the Pen angular Tow-way bind by murali ( @murale ) on CodePen . 2.Dependency injection: Dependency injection is one of AngularJS’s best patterns. It makes testing much simpler, as well as making it more clear upon which any particular object depends. AngularJS is very flexible on how things can be injected. 3.Deep linking: Angular ngRoute module provides routing and deep linking services and directives for angular app. Deep linking allows to encode the state of application in the URL so that it can be bookmarked. The application can then be restored from the URL to the same state. Example: routes.js function Routes ($routeProvider) { $routeProvider.when(‘/’, { templateUrl: ‘main.html’ }); $routeProvider.when(‘/route1’, { templateUrl: ‘route/file1.html’, controller: ‘routeOneController’ }); $routeProvider.when(‘/route2’, { templateUrl: ‘route/file2.html’, controller: ‘routeTwoController’ }); } angular.module(‘MyApp’).config([‘$routeProvider’, Routes]); 4.MVC Architecture: Model The model is where your data are. Either the data we are talking about can be a static data or dynamically fetched from a data source, tucked in a server that is miles away from the client, using JSON. A model comprises of a simple JavaScript object called the scope. Tied to a controller, the model object receives the data (from the source) and delivers it to a view (HTML). myApp.controller( ‘myController’, [‘$scope’, function ($greet) { $greet.greetings = function () { $greet.theguest = ‘Hello ‘ + $greet.name; } } ] ); In the above script, the $scope is an object in the model. See how it is encapsulated inside the controller() method. View In Angular, the view comprises of HTML elements and directives. This is the section of application, which is visible to users (using a browser). Other than markups, every view has as an expression (with curly braces), which is tied up to the scope object. <div ng-app=”myApp” ng-controller=”myController”> <p>Enter your name  <input type=”text” ng-model=”name” /></p> <p><input type=”button” value=”Click Me” ng-click=”greetings()” /></p> <p> {{ theguest }} </p> </div> The above piece of markup, also known as Template in Angular, when bound, complied and loaded on the browser is then called the view. Controller The controller actually controls the entire business logic of your application. The initial stage is set here, that is, it initializes and registers the application by creating a new Angular Module. 4.Testing: The AngularJS team feels very strongly that any code written in JavaScript needs to come with a strong set of tests. They have designed AngularJS with testability in mind, so that it makes testing your AngularJS applications as easy as possible. So there’s no excuse for not doing it. 5.Directives: Angular Directives are attributes applied in the View. Attached to HTML elements, the directives augment the elements with new behaviors. Did you see the above examples, each element has directives, prefixed with ng-. Whenever we attach a directive with an element, it tells AngularJS that it is a part of Angular app and Angular treats it that way. 6.Expressions: Angular Expressions are JavaScript like expressions, however with lots of difference. Written inside two curly braces, these expressions will bind Angular application data to HTML elements. SINGLE PAGE APPLICATION Single page application is a web application or website that fits on single web page with the goal of providing a more fluid user experience similar to a desktop application. In a SPA, either all necessary code – HTML, JavaScript and CSS – is retrieved with a single page load. The page does not reload at any point in the process,nor does control transfer to another page, although the location hash can be used to provide the perception and navigability of separate logical pages in the application. Pros: No page refresh When you are using SPA, you don’t need to refresh the whole page, just load the part of the page which needs to be changed. Angular allows you to pre-load and cache all your pages, so you don’t need extra requests to download them. Better user experience SPA feels like a native application: fast and responsive. Ability to work offline Even if user loses internet connection, SPA can still work because all the pages are already loaded. Cons More complex to build You need to write pretty much javascript, handle shared state between pages, manage permissions, etc. To index your SPA app, search engine crawlers should be able to execute javascript. Only recently Google and Bing started indexing Ajax-based pages by executing JavaScript during crawling. You need to create static HTML snapshots specially for search engines. Initial load is slow SPA needs to download more resources when you open it. Where to use jQuery and  where to use AngularJS? Most of the time, people fail to comprehend the real value of these technologies during application development. AngularJS is best suited for the web application development as it works on the HTML code and JSON data which helps in developing for interactive and robust applications but using the same for a simple website development results in slow loading and quite erratic websites. While jQuery is a fast and feature-rich language which has a a commendable JavaScript library and a great tool for creating feature-rich websites. It has in-built features such as HTML document traversal, event handling, manipulation, animation and Ajax support and others which make it easier and simpler to develop hardcore websites. Therefore before utilizing any of these highly intuitive and robust languages, it is necessary to frame a sound approach dedicated either to develop an advanced web application or website development. Sasikala, Junior Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-06-10"},
{"website": "Mallow-Tech", "title": "Testing Checklist for Web Applications", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/06/testing-checklist-for-web-applications/", "abstract": "Designing websites can be a long and complicated process. Dealing with clients, designing prototypes, coding, programming, and testing – there’s a lot to keep track of and a lot to make sure gets done . That’s where checklists can make your life a whole lot easier. With lists of points covering multiple areas from content to usability to accessibility to standards, you’re a lot less likely to overlook important parts of a site. Keep in mind that there is no golden rule that fit your Website Testing. If one rule is suitable for testing of one website, it is not true for another website. In this blog I’ve listed the Testing Checklist for Web Application . This does not mean that you should follow this Website testing cheat-list for all types of Website Testing. This is the kind of checklist to remember while testing your website. The chance of Success (or failure) is deeply depends on the particular context! This way you will not miss any important step and will keep a check on quality too. If you doesn’t make any checklist or forget to include any task in it then it is possible that you might miss some of the important defects. Tailor your approach and ensure that your testing strategy is as effective, efficient, and timely as possible. Below is the checklist to make your design process easier and more organized . Consider using this checklist as a jumping off point for creating your own customized list, based on your own needs. Links Check that the link takes you to the respective page. Ensure to have no orphan pages (a page that has no links to it) Check all of your links to other websites Are all referenced web sites or email addresses hyperlinked? If we have removed some of the pages from our own site, set up a custom 404 page that redirects your visitors to your home page (or a search page) when the user try to access a page that no longer exists. Check all mailto links and whether it reaches properly Forms Acceptance of invalid input Optional versus mandatory fields Input longer than field allows Text box accepted character limit Default values on page load/reload(Also terms and conditions should be disabled) Is Command Button can be used for HyperLinks and Continue Links ? Is all the datas inside combo/list box are arranged in chronolgical order? Are all of the parts of a table or form present and correctly laid out? Does a scrollbar appear if required? Assure that leap years are validated correctly & do not cause errors/miscalculations. Numeric fields Assure that lowest and highest values are handled correctly. Assure that numeric fields with a blank in position 1 are processed or reported as an error. Assure that fields with a blank in the last position are processed or reported as an error an error. Assure that both + and – values are correctly processed. Assure that division by zero does not occur. Include value zero in all calculations. Assure that upper and lower values in ranges are handled correctly. (Using BVA) Alphanumeric fields Use blank and non-blank data. Include lowest and highest values.[Character limits] Include invalid characters & symbols. Include valid characters. Include data items with first position blank. Include data items with last position blank. Search functionality Search with invalid characters Search with valid characters Check for filter options like search by date, time, name, price etc Search result is displayed as “search on go” / dynamic Verify sorting is done properly UI Test Scenarios: Check either screen is responsive Check the site behavior in top priority browsers All fonts and text should be same as per the requirements. Verify graphical data representations [Pie chart, bar chart, Linear graph, histogram, etc] are shown correctly according to available data Verify pagination is done if auto-scroll feature is not implemented. Web page content should be correct without any spelling or grammatical errors All the error messages should be correct without any spelling or grammatical errors and the error message should match with the field label. Tool tip text should be there for every field. All the fields should be properly aligned. Enough space should be provided between field labels, columns, rows, and error messages. All the buttons should be in a standard format and size. Home link should be there on every single page. Disabled fields should be grayed out. Check for broken links and images. Confirmation message should be displayed for any kind of update and delete operation. Check the site on different resolutions (640 x 480, 600×800 etc.?) Check for error key values Check the tab should work properly. Scroll bar should appear only if required. If there is an error message on submit, the information filled by the user should be there. Title should display on each web page All fields (Textbox, dropdown, radio button etc) and buttons should be accessible by keyboard shortcuts and the user should be able to perform all operations by using keyboard. Check if the dropdown data is not truncated due to the field size and also check whether the data is hardcoded or managed via administrator. Check copyright year information Security Testing Verify that cookies can be used/cannot be used as per the requirement or regional rule. Verify the web page which contains important data like password, credit card numbers, secret answers for security question etc should be submitted via HTTPS (SSL). Verify the important information like password, credit card numbers etc should display in encrypted format. Verify password rules are implemented on all authentication pages like Registration, forgot password, change password. Verify if the password is changed the user should not be able to login with the old password. Verify the error messages should not display any important information. Verify if the user is logged out from the system or user session was expired, the user should not be able to navigate the site. Verify to access the secured and non secured web pages directly without login. Verify the “View Source code” option is disabled and should not be visible to the user.[ For data sensitive web applications like banking, finance, logistics etc ] Verify the user account gets locked out if the user is entering the wrong password several times. Verify the cookies should not store passwords. Verify if, any functionality is not working, the system should not display any application, server, or database information. Instead, it should display the custom error page. Verify the user roles and their rights. For Example The requestor should not be able to access the admin page. Verify the important operations are written in log files, and that information should be traceable. Verify the session values are in an encrypted format in the address bar. Verify the cookie information is stored in encrypted format. Check either robots.txt is accessible [ http://www.robotstxt.org/robotstxt.html ] Verify for list of User-agents, links allowed in robots.txt Verify either disallowed user-agents/links specified in robots.txt are not able to access These are some of the main terms which should be included in the Testing Checklist, however every organization has different approach and the Testing Checklist may vary. It is always a good practice to make a checklist so that testing can be done in a proper way and no important point should be missed. Periannan Test Engineer, Mallow Technologies Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-06-22"},
{"website": "Mallow-Tech", "title": "FetchedResultsController(FRC) – Part 1", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/06/fetchedresultscontrollerfrc-part-1/", "abstract": "NSFetchedResultsController(FRC) Fetched results controller is an effective way for binding Core Data with UITableView or UICollectionView. As we all know both UITableView and UICollectionView is constructed with sections and rows for each of those section. And the fetched results controller also constructed in such a way with both sections and rows for each section which will match for the UITableView / UICollectionView data source and can be used for it. Why its so effective ? Lets list out why Fetched result controller is so effective when using CoreData, If we want to display core data content in a UITableView then we have to fetch respective contents of entities present in the core data and display it. We may get a case where we want to update the table view data when new values are added in core data. In this case if we want to load the newly inserted data in the UITableView then we want to fetch the core data contents again and reload the table view. But in this method we may not know when to perform the synchronize process again and again. To overcome this Core Data comes with the following solution. Whenever a record is inserted, deleted or updated in the Managed Object Context(MOC), It will post three types of notifications through notification center. They are, 1) NSManagedObjectContextObjectsDidChangeNotification : Posted when new record is inserted, deleted or updated in managed object context. 2) NSManagedObjectContextWillSaveNotification : Posted before the pending changes are commited to the backing store(database). 3) NSManagedObjectContextDidSaveNotification : Posted after the changes are commited in the backing sore(database). Note : The above notification contents consists of the records that was inserted, deleted or updated. Now lets come to our scenario, now we know that we will get the above notifications whenever there is some change in the coredata. So now we can make the synchronization process whenever any of the above notification is received. But there is an another way to handle this scenario, this is when Fetched results controller comes in, FRC is specifically suited for managing core data data with UITableView or UIColletionView and to do the above synchronization process by itself i.e., it takes care of all the synchronization process and updates the UI data whenever any change is made in core data and it does it in efficient manner by making use of the userInfo that the above listed notifications comes with. Ok, now I hope this explains better about FRC’s effectiveness. Lets step into the process involved in configuring FRC. How to configure FRC ? The following steps are followed for configuring a Fetched results controller, Create an instance of NSFetchedResultsController. //CODE @property (nonatomic, strong) NSFetchedResultsController *fetchedResultsController; Create a NSFetchRequest with an entity name in the database for which we need to construct fetched result controller for and – (Mandatory) : The above fetcth request should contain atleast one sort descriptor which is used to sort the results. – (Optional) : You can also set “setFetchBatchSize” value to specify the number of objects returned i.e, it splits into batches when the fetch request is executed. By default the batch size is 0 which is treated as infinite. //CODE – (void)viewDidLoad { [super viewDidLoad]; // Initialize Fetch Request NSFetchRequest *fetchRequest = [[NSFetchRequest alloc] initWithEntityName:@”TimeSheet”]; // Add sort descriptors(Mandatory) [fetchRequest setSortDescriptors:@[[NSSortDescriptor sortDescriptorWithKey:@”updatedAt” ascending:YES]]]; // Add batchSize(Optional) [fetchRequest setFetchBatchSize:20]; Initialize the fetch result controller instance. You do this by passing four parameters namely, The fetch request that we constructed above. Managed object context object. (Optional) : You could specify “sectionNameKeyPath” the fetch result controller uses this keypath to split the results into sections like in a tableview/collecitonview. If you pass nil for this argument then it will create all the results under a single section. (Optional) : You could specify “cacheName”, Using this cache can avoid the overhead of computing the section and index information. If you pass nil for this argument then it prevents caching. //CODE // Initialize FetchedResultsController self.fetchedResultsController = [[NSFetchedResultsController alloc] initWithFetchRequest:fetchRequest managedObjectContext:self.managedObjectContext sectionNameKeyPath:nil cacheName:nil]; Configure the fetched result controller by setting its delegate as below, //CODE // Assign delegate for FetchedResultsController [self.fetchedResultsController setDelegate:self]; Perform Fetch action //CODE // Perform Fetch action NSError *error = nil; [self.fetchedResultsController performFetch:&error]; // Handle error if (error) { // Handle error here. (eg., alert, logging, retry option,…) } Now set the data for tableview/collectionview with fetchedresultcontroller instance as shown below(shown how to use in a tableview), Implementing : UITableViewDataSource :- //CODE //The sections in fetchedResultController holds all the section info, these sections are formed based on sectionNameKeyPath value we mentioned while initializing fetchedResultController. – (NSInteger)numberOfSectionsInTableView:(UITableView *)tableView { return [[self.fetchedResultsController sections] count]; } //Under each sections there may be any number of objects based on the content present in your database. – (NSInteger)tableView:(UITableView *)tableView numberOfRowsInSection:(NSInteger)section { NSArray *sections = [self.fetchedResultsController sections]; id<NSFetchedResultsSectionInfo> sectionInfo = [sections objectAtIndex:section]; return [sectionInfo numberOfObjects]; } – (UITableViewCell *)tableView:(UITableView *)tableView cellForRowAtIndexPath:(NSIndexPath *)indexPath { UITableViewCell *cell = (UITableViewCell*)[tableView dequeueReusableCellWithIdentifier:@”Cell” forIndexPath:indexPath]; // Configure tableViewCell using fetchedResultController [self configureCell:cell atIndexPath:indexPath]; return cell; } // Method for retrieving data for cell at particular index path, This method will get the NSManagedObject for respective index path and we get the details from it. – (void)configureCell:(UITableViewCell *)cell atIndexPath:(NSIndexPath *)indexPath { // Get respective record from fetchedResultController NSManagedObject *record = [self.fetchedResultsController objectAtIndexPath:indexPath]; // Update cell contents [cell.taskTiming setText:[record valueForKey:@”timing”]]; [cell.taskDescription setText:[record valueForKey:@”description”]]; } Implementing the NSFetchedResultsControllerDelegate Protocols: NSFetchedResultsController comes with few delegate methods which are used for denoting the status of updation of data in coredata, they are, controllerWillChangeContent: controllerDidChangeContent: controller:didChangeSection:atIndex:forChangeType: controller:didChangeObject:atIndexPath:forChangeType:newIndexPath: We can make use of these delegates for updating the tableView with respect to the coredatabase changes. //CODE // controllerWillChangeContent : Denotes before any changes are made to the data which is managed by FetchedResultsController. – (void)controllerWillChangeContent:(NSFetchedResultsController *)controller { [self.tableView beginUpdates]; } // controllerDidChangeContent : Denotes after all the changes are made to the data which is managed by FetchedResultsController. – (void)controllerDidChangeContent:(NSFetchedResultsController *)controller { [self.tableView endUpdates]; } // controller:didChangeObject:atIndexPath:forChangeType:newIndexPath : Denotes the change made in core data at particular //Arguments for the above delegates are as follows An instance of NSFetchedResultsController. The changed/updated NSManagedObject instance. Current index path of object in fetched results controller. Change type : The changes are of many types namely Insert, Update, Delete or Move. New index path of the object in the fetched results controller. Type of changes that can take place are as follows, NSFetchedResultsChangeInsert NSFetchedResultsChangeDelete NSFetchedResultsChangeUpdate & NSFetchedResultsChangeMove //CODE – (void)controller:(NSFetchedResultsController *)controller didChangeObject:(id)anObject atIndexPath:(NSIndexPath *)indexPath forChangeType:(NSFetchedResultsChangeType)type newIndexPath:(NSIndexPath *)newIndexPath { switch (type) { case NSFetchedResultsChangeInsert : { [self.tableView insertRowsAtIndexPaths:[NSArray arrayWithObject:newIndexPath] withRowAnimation:UITableViewRowAnimationFade]; break; } case NSFetchedResultsChangeDelete : { [self.tableView deleteRowsAtIndexPaths:[NSArray arrayWithObject:indexPath] withRowAnimation:UITableViewRowAnimationFade]; break; } case NSFetchedResultsChangeUpdate : { [self configureCell:(UITableViewCell *)[self.tableView cellForRowAtIndexPath:indexPath] atIndexPath:indexPath]; break; } case NSFetchedResultsChangeMove : { [self.tableView deleteRowsAtIndexPaths:[NSArray arrayWithObject:indexPath] withRowAnimation:UITableViewRowAnimationFade]; [self.tableView insertRowsAtIndexPaths:[NSArray arrayWithObject:newIndexPath] withRowAnimation:UITableViewRowAnimationFade]; break; } } } In the next post we will see the usage of multiple fetchedResultsController in the same view controller. Bharath R, iOS Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-06-14"},
{"website": "Mallow-Tech", "title": "Indexing With Example", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/06/rawevent-indexing/", "abstract": "We had a task of reading the database values which is time based. So without indexing, the code takes a lot of time to fetch the values. One such situation was that when the reading was interrupted in between and the code now has to read a huge amount of data to fetch a single record which are present already along with the data coming in seamlessly. So in this blog post we are going to see how the problem was solved by using various order in indexing. Here cost and time plays a major role in choosing the index. NOTE : All the queries ran in the Local Machine QUERY: SELECT “public”.”raw_events”.* FROM “public”.”raw_events” WHERE (timestamp >= 1449008122 and device_id = ‘logan134’ and account_id = ‘logan’ and processed = ’t’ and id != 11227294) LIMIT 1; ANALYSYS: 1. Indexing on Account_id: 2. Indexing on Device_id: 3. Indexing on Timestamp (Default): 4. Composite Index with Timestamp and Device_id: 5. Composite Index with Timestamp and Account_id: 6. Composite Index with Device_id and Account_id: 7. Composite Index with Timestamp, Device_id and Account_id: 8. Indexing on Device_id with Composite Index on Device_id and Account_id: 9. Indexing on Device_id and Account_id (separate): 10. Composite Index with Device_id and Timestamp: 11. Composite Index with Device_id, Account_id and Timestamp: CONCLUSION: Based on the Analysis we found, creating composite index with Device_id, Account_id and Timestamp (Topic 11) is consuming less cost than the other indexes. Surender T, ROR Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-06-10"},
{"website": "Mallow-Tech", "title": "Slick – Embedding Photoswipe plugin", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/05/slick-embedding-photoswipe-plugin/", "abstract": "Slick is basically a jQuery plugin for creating responsive, customisable and mobile friendly carousels/sliders. Slick is chosen to embed the photoswipe plugin for popup gallery. But when slick is used in a collapse, the Photoswipe plugin does not load properly. The images stay in a column(vertically). This issue is a major concern, as most of the sites uses collapse and slick together. In this post I will explain the way to rectify the issue. Issue Faced While using slick inside a collapse, slick does not work properly. We used the collapse function which came with the template. In the template they had used “slideToggle” function for collapse. Where as in slideToggle, it toggles between “display : none; & display: block”. The issue arises only when “display : none;”. Codepen: See the Pen Slick inside collapse issue demo by Satheesh ( @satheeshmallow ) on CodePen . Solution: We realised the cause for this issue. We also got to know that, this issue happens when used in bootstrap non-active tabs  ( https://github.com/kenwheeler/slick/issues/341 ). From the above reference we got an idea on how to remove this issue. We used collapse function in bootstrap framework. There we just changed “ display: none to display: block ” , and to hide the container we added the style “ height: 0px; overflow:hidden ” for the class “ collapse ”. Voila, now slick get it’s dimensions and works fine. Codepen: See the Pen Slick inside collapse workaround by Satheesh ( @satheeshmallow ) on CodePen . This awesome jQuery plugin is developed by kenwheeler . For more Advanced Usages, please check the demo page or visit the official website. Satheesh. UI/UX Designer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-05-26"},
{"website": "Mallow-Tech", "title": "4 Strict Don’ts for Mobile Start-ups to avoid failure", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/08/4-donts-to-avoid-failure/", "abstract": "Taking a new project to market always involves risks. Nearly 90 percent of tech startups fail in that. It’s impossible to predict whether a particular product will succeed or fail. Here is a list of strict “ don’ts ” that every tech start-ups should be aware of before they launch a product. There are many reasons why mobile start-ups fail. They fail because there is little demand for their product; sometimes they fail because the competition is too tough. Here are four strict don’ts to avoid failing of a new venture. 1. Don’t develop a product that you personally like without conducting a proper market research. Many of us are tempted to dive into developing a product before we’ve taken the opportunity to answer one very important question. “Does our product solve a real problem?” Investing in app development when the app itself might not have market/product fit is one of the most certain ways to go bankrupt. An illustrative example of a product that didn’t solve an actual problem is Dinnr, a failed same-day ingredient delivery service in the United Kingdom. Dinnr founder Michal Bohanes did some initial research — conducting one-on-one interviews — and found that 70 percent of his interviewees said they would use Dinnr’s delivery service. But in retrospect, Michal acknowledged that this interview-based research hadn’t reflected the real state of the market. Speaking about lessons he learned from his failed product, Michal says he knows what went wrong: instead of asking people about their challenges with grocery shopping or getting take-out from a restaurant, he pitched his product. When you pitch a product, people subconsciously try to compliment you — and no one can honestly predict their future behaviour. Pitching your product in place of conducting solid market research will give you great statistics on paper and disappointing user acquisition in the real world. Lesson to learn: Before you start working on your project, consider how you can solve a specific problem experienced by a specific group of people. For example, Dinnr failed because they were targeting a social group that had no real problems with the existing infrastructure (Dinnr’s target audience was young educated professionals and single people in large cities). If they had targeted a different audience with more specific needs (for example, young mothers who can’t easily go grocery shopping, or senior citizens who can’t drive to the mall), their startup would have had a better chance of survival. 2. Don’t develop a product that competes with market leaders for the same sector of the market. When there are several startups that offer similar or identical products, their survival depends on getting a bigger share of the market. After some period of time, users become loyal to a particular service and are reluctant to switch to any alternative. Very often this means that the product that gets the biggest share of the market initially will ultimately push others out of the market altogether. Experience shows that even in a sizeable market like the US there’s only enough space for a few big players. If you want to stay afloat you have to fight tooth and nail during your initial expansion. Sidecar was launched as an on-demand car service. They had a well-thought-out business model and were highly innovative. All the same, Sidecar failed. Sidecar launched right when the on-demand delivery services and taxi services were getting big, and consequently, they had to compete with Lyft and Uber. By the end of 2015, Sidecar had fallen too far behind Lyft and Uber and went out of business as a taxi service. Sidecar CEO Sunil Paul explains how Sidecar was pushed out of the market even though Sidecar pioneered many aspects of ridesharing services. They were actually the first shared rides, upfront pricing and other features that were later adopted by Lyft and Uber. Sidecar serves as an example of how even an innovative product may not be able to successfully compete for long-term with the bigger players. Having more money, Uber and Lyft had more opportunities to implement more complex features and to implement them faster and better. Eventually, Sidecar just couldn’t keep up. Lesson to learn: If you end up in a position where you have to compete with market leaders for a relatively narrow segment of the market, it’s important to understand whether your product can survive the tough competition. Sometimes it is wiser to shift your focus to a less populated area of the market at the initial stages of product development. 3. Don’t develop a product that breaks the law or lets users get away with illegal activities. It’s not unprecedented for business owners to come up with a seemingly genius idea that later costs them a fortune in legal fees and fines. Exact offences vary from state to state, but in the case of mobile apps, the most common legal issues involve copyright infringement or online harassment. A year ago, in April 2015, Grooveshark, which started as a promising music-sharing service, announced that they were going out of business. Grooveshark was forced to settle with several major recording companies in the United States and promised to stop their activities and wipe their servers clean to avoid further complaints from musicians and copyright owners. Grooveshark’s co-founders were inspired by YouTube and hit the market when the time was right. At the beginning of the startup journey, Grooveshark was as successful as Spotify. But Grooveshark’s business model existed within the grey segment of the market, and it had a significant flaw: it could only survive as long as people didn’t care too much about piracy and copyright laws — i.e. in the early days of streaming web services. Eventually, the legal grey areas caught up with Grooveshark. Even signing a contract with EMI in 2009 in a bid to go legit didn’t work out. They still ended up getting sued by EMI when EMI claimed that Grooveshark failed to provide an accurate accounting of all the songs they streamed. Alongside these legal issues, the market was changing: users were now willing to pay for the music they were streaming. Spotify was gaining more and more users, and Grooveshark’s days were over. Another example of a mobile service that failed after struggling with legal (and moral!) concerns is Secret. Secret, an anonymous social network and one of the most popular apps of 2014, shut down even though they managed to secure $35 million in funding during their last year. What went wrong? The app initially lets users publish anonymous posts to be shared with their phone contacts and Facebook friends. It became popular among people in Silicon Valley and was widely used for spreading rumours within the tech community. Secret failed because of the nature of the app itself: anonymity is great for attracting people who want to gossip, but it also incentivizes certain types of behaviour like cyber bullying. Secret was severely criticised for not moderating their content and for providing perfect opportunities for online harassment. This posed a challenge because Secret couldn’t exist without anonymity and complete freedom. As soon as they introduced new rules prohibiting certain types of posts (for example, posts with real people’s names in them), users started leaving the app. If you build your product around the idea of uncensored content and full anonymity, you can’t just back away without losing your users. On top of the shaky moral grounds, Secret broke another important rule of product development: you can’t rebrand your product into something completely different and continue targeting the same audience. Lesson to learn: When you come up with a business idea, make sure there is a fully legitimate way to implement it. Don’t break the law. You should investigate legal matters and avoid product ideas that might make you liable for harassment or piracy. Be wary of apps that allow users to share sensitive information, download or stream music and videos, share images, etc. Additionally, it’s important to consider what moral concerns your app might raise (think Secret).   Even if your product doesn’t break the law, it may still become a pariah. 4. Don’t think that developing a great product will market itself. Investing everything you have into development instead and failing to come up with a solid marketing strategy is one of the most disappointing ways to fail your business venture. Concentrating too much on the development side and ignoring marketing and promotion spells failure. You can have the most innovative, user-friendly app of all time — but it won’t matter if your users can’t find it. This is what happened to Everpix, one of the best solutions ever designed to manage a library of photos. Within their two years of operation, Everpix attracted more than 50 thousand users, but it never got enough traction to have sustainable growth and eventually went bust. Everpix’s co-founders were focused on creating an ideal product, and so they invested heavily in development, spending $1.8 million to build the service. At the same time, they didn’t promote the service, and when they finally realized their mistake it was too late. The revenue was not enough to pay the bills, not to mention to develop a successful marketing strategy. Everpix is an example of how a high-quality product can fail whereas less perfect apps can gain traction and eventually succeed. Lesson to learn: In mobile development, success is about finding a balance between building a high-quality product and complementing it with an appropriate marketing campaign. One doesn’t work without the other. Don’t assume that your product will market itself, no matter how great your app is. The following four are the major don’ts that stop you from failing miserably in your venture. To succeed many other factors have to be considered the above mentioned will save you from a major fall. Jagajeevan, Business Analyst, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-08-01"},
{"website": "Mallow-Tech", "title": "My Intern days at Mallow Technologies", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/05/my-intern-days-at-mallow-technologies/", "abstract": "‘Ignoring Online marketing is like opening a business but not telling anyone’ Being a digital marketing enthusiast, I joined Mallow Tech as an intern two weeks back. My responsibilities include taking care of the digital proceedings, analyzing its strength and weakness. With experience in social media tools ( Facebook , Twitter and Linkedin ), it is an intriguing profile to learn my ways. The freedom to explore new and innovative ways to brand the product helps me in pushing my limits. I am learning a lot in this process. As a professional management student, one should know how to optimise the content, suiting the needs of the customer. Various marketing tools are available at my disposal. And it is necessary to understand the customer to do so. This is my key take away from these past two weeks experience. Another great thing about Mallow is the culture. The work culture is too good, which has given autonomy to work my way. Also the culture supports independent decisions, innovation and so on. These are the prime indicators of the growth of a company in the right direction. It is indeed, a grand welcome for my corporate life. If I say only about the company and culture, then I won’t be doing any justice to the place it is located at. The company is headquartered in Karur, Tamil Nadu . Karur built on the banks of river Amaravathi, has a history of being a trade center. And following its history, it still is a trade center for exports of textile products. Along with it bus-body building, mosquito nets manufacturing are the other leading businesses. The people are always busy as a bee and you can see the rush on the weekdays. Majority of the people rely on these businesses on weekly or contractual wages. The life style of the place might not be as advanced with the metro cities but their hearts are indeed. Mallow Tech has done a great job of locating their HQ at a place where few tech companies prefer. The clear advantage is that businesses don’t have to rush to tier 1 cities to get digital solutions. This also opens the avenue for people to experience working on cutting edge technologies in their home town. Karthikesh. Marketing Intern, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-05-20"},
{"website": "Mallow-Tech", "title": "An Introduction to Laravel Valet", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/05/laravel-valet/", "abstract": "This week we will see a more interesting topic of “ Laravel Valet ”. It is a local development environment for Mac developers. There is no need of installing Vagrant, Apache, Nginx and no changes need to be done in /etc/hosts file. The most special feature of using Valet is that you can even share your sites publicly so that it can be viewed from anywhere in the world. Let’s see the step by step installation and the configurations that need to be done. Installation Installing Valet is very easy, it requires Mac operating system, composer and latest version of Homebrew. Install or update Homebrew to the latest version using brew update . Then install PHP 7 by, brew install homebrew/php/php70 Install Valet with Composer using. composer global require laravel/valet Make sure the ~/.composer/vendor/bin directory is in your system’s “PATH”, you can check this by running: echo $PATH If you can’t see it there, then you need to add this to your ~/.bash_profile: export PATH=$PATH:~/.composer/vendor/bin Finally, run the following command, valet install Serving Valet Site After Valet is installed, create a new folder to hold all your sites at “~/Projects”. cd into this directory: cd ~/Projects Next run the Valet park command: valet park This command will register your current working directory as a path that Valet should search for sites. Next, create a new Laravel site within the parked directory: laravel new TestValet Once it finishes installing visit TestValet.dev in the browser. If you want to remove the parked directory from the parked directory list by using the command: valet forget ~/Projects Sharing Sites Using Valet, you can share your local sites with the world. To share your site, navigate to the site’s directory in your terminal and run the following command: valet share A publicly accessible URL will be inserted into your clipboard and is ready to paste directly into your browser. That’s it. To stop sharing your site, hit Control + C to cancel the process. Sites outside of your parked directory You can link the projects in other places on your file system by using “link” command. cd ~/Laravel-Projects/TestBlog valet link TestBlog Now you can hit TestBlog.dev in the browser and this site will load. If you ever want to see a list of linked sites Valet offers the following command: valet links Then if you ever want to remove one: valet unlink TestBlog Securing a Valet site Valet uses plain HTTP by default and with the release of 1.1.9 you can now easily serve sites over HTTPS by running: valet secure TestBlog Then to revert back to HTTP: valet unsecure TestBlog This is all managed by Caddy Server. You can start, restart and stop the Valet daemon by valet start valet stop valet restart You can uninstall the Valet daemon entirely by valet uninstall Valet provides a blazing fast local development environment with minimal resource consumption, so it’s great for developers who only require PHP / MySQL and do not need a fully virtualized development environment. Hope this blog has helped you in installing and using the Valet. We will come back with more interesting and useful blog next time keep watching for updates. Anandhan S, PHP Development Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-05-26"},
{"website": "Mallow-Tech", "title": "How to run cron job in AWS EBS worker tier?", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/05/how-to-run-cron-job-in-aws-ebs-worker-tier/", "abstract": "Elastic Beanstalk a product in Amazon Web Services (AWS), which gives you the ability to deploy applications with ease, auto-scale as you need to and you can tune and tweak however should you ever want to. We use EBS at Mallow, and one issue that comes up frequently is how to run scheduled background tasks or jobs in an EBS environment. In this post, we’ll explore how to set up scheduled tasks using the cron.yaml configuration file in an EBS Worker Tier environment. Running cron job in AWS is simple and easy. There is no need for any external tools, for all types of application(ruby, python, node.js, etc) Include cron.yaml with following content into project root path. The worker automatically executes job from this file version: 1 cron: — name: “job-name” url: “/path-to post method” schedule: “* * * * *” * name – is unique for each job * url – app method to send HTTP post request * schedule – cron expression for time to execute(in this example the job executed every minute) You can configure multiple cron job in one file with unique names. If you want to update cron, you can update and re-deploy your application it will automatically updates. Successfull cron deployment logs in  INFO event in environement log. You can find cron logs in cron.log file If you need multiple cron jobs, you can do this by having multiple blocks in the cron section of this file. Note: 1. It will be executed based on the UTC time zone. If you need to adjust time to your time zone if needed. 2. It executes messages from SQS queue. If there are large number of messages in the queue, then process will delay. So AWS recommends separate worker for this. 3. Exclude cron post method from your web tier, otherwise it leads un restrickted post request. 4. Careful while copying cron.yaml file from AWS site, some characters might get included instead of ‘-‘. Thanks for reading. Prakash S, ROR Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-05-20"},
{"website": "Mallow-Tech", "title": "Scenarios to be considered in making network request (iOS)", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/05/scenarios-to-be-considered-in-making-network-request-ios/", "abstract": "There are lot of chat and social networking apps blooming everyday. Network request has an integral part in these apps. In this blog we will see the various scenarios in which the network request can be applied. We will learn about the scenarios to be considered for network request. Let’s assume that we are not using core data and socket. 1.) View Will Appear: Consider you are developing an app where you need the updated screen only when the user checks the screen. In this case put request in ViewWillAppear for screens which you would like to have updated data whenever you visit that screen. So that whenever the screen appears we will be updated with the recent data from server. Objective-C: – (void)viewWillAppear:(BOOL)animated { [super viewWillAppear:animated]; [self fetchUpdatedDataFromServer]; } Swift: override func viewWillAppear(animated: Bool) { super.viewWillAppear(animated) self.fetchUpdatedDataFromServer() } 2.) Background to foreground: The other scenario is that the screen might not be in the foreground. In that case if the app goes to background and enters foreground means need to put network request to fetch the latest details. You can achieve this by making use of UIApplicationWillEnterForegroundNotification notification. This can be seen evidently in the apps such as WhatsApp where the push notifications play a major role. Note:* Add the notification in viewWillAppear & remove the notification in viewWillDisappear methods in order to avoid unwanted notifications getting called for irrelevant screens or notifications listening when it’s not used. In Objective –C: – (void)viewWillAppear:(BOOL)animated { [super viewWillAppear:animated]; [[NSNotificationCenter defaultCenter] addObserver:self selector:@selector(fetchUpdatedDataFromServer) name: UIApplicationWillEnterForegroundNotification object:nil]; } – (void)viewWillDisappear:(BOOL)animated { [super viewWillDisappear:animated]; [[NSNotificationCenter defaultCenter] removeObserver:self name: UIApplicationWillEnterForegroundNotification object:nil]; } In swift: override func viewWillAppear(animated: Bool) { super.viewWillAppear(animated) NSNotificationCenter.defaultCenter().addObserver(self, selector:”toFetchDetails”, name: UIApplicationWillEnterForegroundNotification, object: nil) } override func viewWillDisappear(animated: Bool) { super.viewWillDisappear(animated) NSNotificationCenter.defaultCenter().removeObserver(self, name: UIApplicationWillEnterForegroundNotification, object: nil) } 3.) Pagination: If we make use of pagination it will be much better way to avoid delay (If we need to get all the data in a single request then it could take long time to get the data) which makes user to wait for long time. Using pagination will get data only when it’s needed. We can set our own limits for number of data to be fetched on each request.  This scenario can be seen in the case of browser view of Facebook. The app will load to a particular set of data and once you reach the bottom then the other set of data will be fetched. This pagination will avoid user waiting for long time and improve user experience. 4.) Pull to refresh: Use pull to refresh for screens which contains dynamic or ever changing/updating data. We can use pull to request to fetch the latest data from server and update the screen content. This scenario can be predominantly seen in the mobile view of the facebook apps, where you need to pull to refresh. This used in those kind of apps where the data is high if it fetches continuously and hence can be fetched manually when necessary by the user. 5.) Handling network failure & Synchronisation: For example let’s consider that we are posting a comment for a post or sending a message or mail in those scenarios we could do the following, i.) Before sending a message check whether internet is connected or not. If it’s not connected then don’t allow the message to get posted instead show an alert to user that you are not connected to network, please try again later. ii.) Else if you have core data (local DB), you can synchronise the network calls by saving the message in database and whenever network available you can put network request by passing the parameters which is saved in core data. iii.) In case if you decided to go with synchronising and send stored request when network avails we need to handle an important scenario i.e, if the user logout from the app when there are pending requests in database then while user perform logout we can need to clear all the data(pending requests) form the database. Other scenarios to be considered: If the initial request failed means we can have the retry option . The retry button may be placed in centre of the screen or in the navigation bar. If load more option i.e, request for certain amount of friends failed means, we can have retry option . The retry button may be placed in the last cell . If user initiates 2 or more requests at the same time which are irrelevant the user will be facing the delay if multiple requests process at a time. In this case we can stop the request which are not needed currently which will reduce the time delay. If you are using the NSURLSession to download the details, we can control the task states . If the app goes to background means you can suspend the task , which is nothing but pausing the request and if it enters fore ground means you can resume (to start from the pause) the task. These scenarios has to be based on the requirements of the application. If you can define the working and the necessary functions of the application then the network request can be called to fit the needs. iOS Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-05-17"},
{"website": "Mallow-Tech", "title": "What is Defect Life Cycle – An Overview", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/05/defect-life-cycle/", "abstract": "Identifying a defect plays a major role in software development. This follows a cycle of process called Defect life cycle. The process starts when a bug or defect is found and stops when the defect is closed or rectified. The bug has different states in the Life Cycle. The Life cycle of the bug is shown diagrammatically. Identifying a defect plays a major role in software development. This follows a cycle of the processes and is called Defect life cycle. The process starts when a bug or defect is found and stops when the defect is closed or rectified. The bug follows different stages in its Life Cycle. The Lifecycle of the bug can be explained as follows: Bug or defect life cycle crawls through the following stages or status: New: When a defect is logged and posted for the first time. It is mentioned as new. Assigned: Once the tester has posted the bug, the lead of the tester approves that the bug is genuine. He then assigns the bug to the corresponding developer and the developer team. It’s state given as assigned. Open: This is the state at which the developer starts analyzing and fixing the bug. Fixed: At this stage, the developer makes the necessary changes in the program and verifies it so that it performs the task. Retest: Here the tester once again performs the testing of the changed code which developer has given. It is to ensure whether the bug is fixed or not. Verified: After the retest process, if the tester found no bug then, he changes the status to be verified. Reopen: The status will be set as reopened if the bug continues to exist even after the bug is fixed by the developer, the bug goes through the life cycle once again. Closed: Once the bug is fixed, it is then again tested by the tester. If the tester feels that the bug no longer there in the software, then he changes the status of the bug to be “closed”. This state means that the bug is fixed, tested and approved. Duplicate: Duplicate status is given to a bug if it behaves exactly as another bug which we already know. Rejected: The status of the bug is changed to rejected if the developer feels that the bug is genuine in his/her context. Deferred: The bug is changed to deferred state means the bug is expected to be fixed in next releases. The reasons for changing the bug to this stage might be of many factors such as the priority of the bug may be low, lack of time for the release or the bug may not have a major effect on the software. Not a bug: If there is no change in the functionality of the application then not a bug status will be given. For an example: If a customer asks for some change in the UI of the application like the change of colour of some text then it is not a bug but just some change in the looks of the application. Reference: istqbexamcertification.com/what-is-a-defect-life-cycle/ Periannan, Testing Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-05-11"},
{"website": "Mallow-Tech", "title": "Integration of payment gateway in Laravel 5.1", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/05/integration-of-payment-gateway-in-laravel-5-1/", "abstract": "In Laravel Cashier we had about integrating Stripe Payment Gateway for users out off India. Now we will see how to integrate Indian Payment Gateways in Laravel 5.1. Laravel has a package called “IndiPay – Indian Payment Gateways ” which supports payment gateways like CCAvenue, PayUMoney, EBS, CitrusPay, InstaMojo. Step 1: First we will Install the package through composer. composer require softon/indipay Step 2: Add the service providers to the app.php file in the config folder. ‘SoftonIndipayIndipayServiceProvider’, Step 3 : Add alias for the Facades to config/app.php file ‘Indipay’ => ‘SoftonIndipayFacadesIndipay’, Step 4: Then, publish the vendor to have a config file in Laravel config folder. How to implement it in our project? It is always a best practice to keep configuration variables in .env file. Update the .env file with the appropriate Gateway Keys. Then, edit the config/indipay.php file and set the Gateway name that we used in .env file. Steps to Initialise the payment request with a Controller. 1.Add Facades in the beginning of the controller use SoftonIndipayFacadesIndipay; 2.After that in the method where the payment has to be achieved, include the following code: $parameters = [ ‘txnid’ => ‘XXXX’, ‘redirect_url’ => ‘XXXX’, ‘purpose’ => ‘Testing’, ‘amount’ => 2500, ‘buyer_name’ => ‘XXX’, ‘allow_repeated_payments’ => <true/false> ]; We need all the above POST parameters to successfully do the payment transaction. 3.After specifying the parameters, you need to two more lines to make payment request. $order = Indipay::prepare($parameters); return Indipay::process($order); The above line of code will generate the below form, <html> <head> <title>IndiPay</title> </head> <body> <form method=”get” name=”redirect” action=”{{ $longurl }}”></form> <script language=’javascript’>document.redirect.submit();</script> </body> </html> that will be submitted automatically due to the statement return. And then the page will be redirected to the specified Payment Gateway that we have configured. After the successful completion of the money transfer, it will be redirected to the URL which we have specified in the parameter list. 4.To get the response from the Payment Gateway, we can use the below lines of code to get the status of the transaction whether success or failure. public function response(Request $request) { $response = Indipay::response($request); dd($response); } Sample response : { “payment_request”: { “id”: “92e58bd771414d05a5e443b0a85f8b43”, “phone”: “+919999999999”, “email”: “foo@example.com”, “buyer_name”: “David Doe”, …more properties… “payments”: [ { “payment_id”: “MOJO5a07005J30161862”, “quantity”: 1, “status”: “Credit”, …more properties } ], }, “success”: true } Each payment response has a key “status” if the value of the key is “Credit” then the payment was successful otherwise it has failed. Hope this blog has helped you in integrating Indian Payment gateway. We will come back with more interesting and useful blog next time keep watching for updates. Suguna K, PHP Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-05-12"},
{"website": "Mallow-Tech", "title": "Stripe Subscription Integration", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/05/stripe-subscription/", "abstract": "If you are developing a sales or subscription site, then billing and payments play a major role. To integrate billing various software are available. Stripe is one among them, the advantage of stripe is that you don’t need a merchant account or gateway as it act as one. Integrating stripe in your site can be done in two ways: Create a plan that defines how much should be billed and at what interval Associate a plan with a customer to create a subscription 1: Create a plan To create a plan in Stripe you need to define two components namely Plans and Customers. Plans basically explains cost set for the payment and billing cycle. You can add n number of plans based on your requirement. The plan creation can be done by two ways In the Stripe Dashboard, on the plans page Via the API Note : Stripe support only the plan id, name, metadata (set and unset metadata), statement_descriptor details of plan will be changed in future. 2: Subscribing a customer to a plan The typical second part is the customers. The process is not complete without the users. This is basically associating the users with the stripe account. The customer data contains some metadata association such as email id. It should also stores the details such as credit card details and payment method associated with the user. You can create customers via the Dashboard, but as you’ll likely create them as part of the workflow at your site, it makes more sense to use the API. Upgrading and Downgrading Plan Stripe also provides the facility to upgrade and downgrade the plans. Upgrading and downgrading is nothing but altering the subscription price, billing cycle, interval and so on. This is possible at any time and Stripe will prorate the difference automatically. Effective time: The change in plan will be effective immediately. If you upgrade to a premium plan then the updated features will be effective immediately and at the same time if your downgrade from a premium plan to a basic plan then the premium features will be effective till the completion of the billing period. Once the billing period is over the new features will be effective. Note : Stripe will charge the customer same day the subscription is created. Implementation of the plan The above logic can be achieved in one of the following method, Upgrade plan We can upgrade the plan by delete existing subscription of the customer and create the new subscription for the customer and we can prorate the customer by creating invoice for remaining unused days. Stripe change the billing cycle to current subscription creation date and charge the customer accordingly. Note : Stripe will not prorate the customer automatically on deleting(unsubscribe) the subscriptions. Downgrade plan We can downgrade the plan simply by update the subscription and set proration to false when update subscription. This means the amount charged for the old plan will not be refunded and next plan start from upcoming billing cycle. This explains the ways to integrate stripe as a subscription tool in your site. Stripe is a startup growing rapidly and its advantage of negating the merchant account helps many in creating an easy solution of subscription plan and easy to alter the same. Premanandh, ROR Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-05-05"},
{"website": "Mallow-Tech", "title": "Laravel Spark", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/04/laravel-spark/", "abstract": "This week we will try to explore Laravel Spark. The main goal of Laravel Spark is in building out business oriented SaaS applications. It has features like user roles, team management, recurring billing through Stripe and many more. If you have developed a team management and a billing system manually you would know how much time it consumes. But by using Spark it is so easy it takes care of all the designing and invoice creation process. Even though it has been commercialised  it is worth buying which makes us focus a lot on our business. There are two ways to install one by using a installer and other by a manual process . We will now see the implementation part. Before installing we need to know the few requirements of Laravel Spark. * Laravel Framework 5.2 * Laravel Elixir * Composer * Bootstrap 3 Spark uses vue.js a Javascript Framework on the registration and setting page. But it is our choice do we use the framework or not. We can install using a installer by downloading the Spark Installer. Laravel Spark has a very handy installer which will create a new Larval application and installs the Spark in the directory which we chose. Note: Care must be taken to install Laravel installer before we go for a Spark installer. First we need to clone the Laravel/spark-installer repository from GitHub to any location in our machine. Once we have cloned the installer we must make sure to run the composer install command within the cloned directory so that all the dependencies get installed automatically. Note: Care must be taken to add the spark-installer directory to the system $PATH variable to locate the Spark executable file. Registering our API token We can create an API token from the settings dashboard which can be used with the installer using  register command spark register token-value To view the currently registered token, we can use spark token Creating a Spark Project We can easily create a Spark project once we have installed the Spark installer and registered our API token  using the below command spark new project_name The above command creates a Laravel project with the given project_name. Spark gets installed and configured automatically. Note: We need to do the database migration with php artisan migrate command. Once all the above task is done we can start configuring our application. Manual Download Method We can Manually also configure the same using the “ZIP” archive. Step 1 : Extract the content of the zip and place it into our project root directory. Step 2 : Add spark directory as repository to our projects composer.json file. Step 3 : Add laravel/spark requirement to your composer.json file Step 4 : Run composer update command  so that all the dependencies will get installed Step 5 : Add LaravelSparkProvidersSparkServiceProvider class to our app.php configuration file. Step 6 : Run spark:install  in the command prompt Step 7 : Add the below service providers to our app.php configuration file Note: Care must be taken to install npm, gulp, and php artisan migrate commands. Hope this blog has given you a basic Idea on what Laravel Spark is and how to install it. we will come back with a more interesting blog in the upcoming weeks. Vijayanand P, PHP Team Lead, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-04-26"},
{"website": "Mallow-Tech", "title": "SOFTWARE TESTING LEVELS – II", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/04/software-testing-levels-ii/", "abstract": "In our previous post , we saw the first two levels of testing. In this post, we will see about System Testing and Acceptance Testing processes. System Testing System testing phase starts once the integration testing phase is completed successfully. In this phase, the system with all components integrated is ready for further testing as a whole. In system testing the behaviour of whole system/product is tested as defined by the scope of the development project or product. System testing is usually required before and after a system is put in place It may include tests based on risks and/or requirement specifications, business process, use cases, or other high-level descriptions of system behaviour, interactions with the operating systems, and system resources. System testing is most often the final test to verify that the system to be delivered meets the specification and its purpose. System testing is carried out by specialists testers or independent testers. System testing should investigate both functional and non-functional requirements of the testing. Some system testing types are, Usability Testing – Usability testing mainly focuses on the user’s ease to use the application, flexibility in handling controls and ability of the system to meet its objectives Load Testing – Load testing is testing of application software under real-life loads. Load testing is performed to determine a system’s behaviour under both normal and anticipated peak load conditions. Regression Testing – Regression testing involves testing done to make sure none of the changes made over the course of the development process has caused new bugs. It also makes sure no old bugs appear from the addition of new software modules over time. Recovery Testing – Recovery testing is done to demonstrate a software solution is reliable, trustworthy and can successfully recoup from possible crashes. Migration Testing – Migration testing is done to ensure that the software can be moved from older system infrastructures to current system infrastructures without any issues. Functional Testing – Also known as functional completeness testing, functional testing involves trying to think of any possible missing functions. Testers might make a list of additional functionalities that a product could have to improve it during functional testing. Hardware/Software Testing – IBM refers to Hardware/Software testing as “HW/SW Testing”. This is when the tester focuses his/her attention on the interactions between the hardware and software during system testing. Acceptance Testing Acceptance testing is a test conducted to determine if the requirements of products are met. Acceptance testing is basically done by the user or customer although other stakeholders may be involved as well. Acceptance testing is most often focused on a validation type testing. User Acceptance testing: User Acceptance testing is the software testing process where a system is tested for acceptability & validates the end to end business flow. Such type of testing executed by the client in a separate environment (similar to the production environment) & confirm whether the system meets the requirements as per requirement specification or not. Alpha testing: Alpha testing is conducted by Customer at the developer’s site, it is performed by potential users like developer, end users or organization users before it is released to external customers Beta testing: Once the alpha testing is over, beta testing follows in order to improve the quality of the product and see that the product is as per the requirement of the customer. This form of testing is done a couple of days or weeks before the launch of the product. Beta Testing is always open to the market and public. It is carried in the real world scenario with the people who are actually going to use the product. Contract Acceptance Testing Contract Acceptance Testing means that a developed software is tested against certain criteria and specifications which are predefined and agreed upon in a contract. The relevant criteria and specifications for acceptance must be defined when the contract itself is defined and agreed upon. Regulation Acceptance Testing Regulation Acceptance Testing, also known as Compliance Acceptance Testing, examines whether the software complies with the regulations. This includes governmental and legal regulations. Operational acceptance testing Also known as Operational Readiness Testing or Production Acceptance Testing, these test cases ensure there are workflows in place to allow the software or system to be used. This should include workflows for backup plans, user training, and various maintenance processes and security checks. This comprises of the various level of testing. It essential to spend a considerable amount of time in each of the levels. As the progression of the software entirely depends on the level of testing done. Testing Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-04-28"},
{"website": "Mallow-Tech", "title": "Support Libraries in Android", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/04/support-libraries-in-android/", "abstract": "The Android Support Library is a collection of libraries with lots of levels of API, that help in focusing the unique parts of an app. We listed some of its uses; Support libraries in android are used to provide backward-compatible versions of Android framework APIs. It helps us to use the features available on latest APIs and still compatible with devices with lower level APIs. Use of android support libraries is considered as a best approach while creating Android applications. The Android Support Library package contains several libraries that can be included in our application. Lets see some of the most common libraries provided by android 1. v4 Support Library : This library is designed to be used with Android 1.6 (API level 4) and higher. It includes the largest set of APIs compared to the other libraries, including support for application components, user interface features, accessibility, data handling, network connectivity, and programming utilities. App Components: Fragment NotificationCompat LocalBroadcastManager User Interface: ViewPager PagerTitleStrip PagerTabStrip Drawer Layout SlidingPaneLayout Accessibility: ExploreByTouchHelper AccessibilityEventCompat AccessibilityNodeinfocompat AccessibilityNodeProviderCompat AccessibilityDelegateCompat Content: Loader FileProvider 2. Multidex Support Library: This library provides support for building apps with multiple Dalvik Executable (DEX) files. Apps that reference more than 65536 methods are required to use multidex configurations. 3. v7 Support Libraries: There are several libraries designed to be used with Android 2.1 (API level 7) and higher.These libraries depends on v4 support libraries. v7 appcompat library: ActionBar AppCompatActivity AppCompatDialog ShareActionProvider v7 cardview library: This library adds support for the CardView widget. v7 gridlayout library: This library adds support for the GridLayout class. v7 mediarouter library: The mediarouter library provide a means of controlling the routing of media channels and streams from the current device to external screens, speakers, and other destination devices. v7 palette library: The v7 palette support library lets you extract prominent colors from an image. v7 recyclerview library: The recyclerview library adds the RecyclerView class which provides support for the RecyclerView widget, a view for efficiently displaying large data sets by providing a limited window of data items. v7 Preference Support Library: The preference package provides APIs to support adding preference objects, such as CheckBoxPreference and ListPreference, for users to modify UI settings. 4. v8 Support Library: This library is designed to be used with Android 2.2 (API level 8) and higher. v8 renderscript library: It adds support for the RenderScript computation framework 5. v13 Support Library: This library is designed to be used for Android 3.2 (API level 13) and higher. It adds support for the Fragment user interface pattern with the (FragmentCompat) class and additional fragment support classes. 6. v14 Preference Support Library: The android.support.v14.preference package provides APIs to add support for preference interfaces such as PreferenceFragment.OnPreferenceStartFragmentCallback and PreferenceFragment.OnPreferenceStartScreenCallback, along with classes, such as MultiSelectListPreference and PreferenceFragment 7. v17 Preference Support Library for TV: The android.support.v17.preference package provides APIs for providing preference interfaces on TV devices. v17 Leanback Library: BrowseFragment. DetailsFragment. PlaybackOverlayFragment. SearchFragment. 8. Annotations Support Library: The Annotation package provides APIs to support adding annotation metadata to your apps. 9. Design Support Library: The Design Support library adds support for various material design components and patterns for app developers to build upon, such as navigation drawers, floating action buttons (FAB), snackbars, and tabs. 10. Custom Tabs Support Library: The Custom Tabs package provides APIs to support adding and managing custom tabs in your apps. 11. Percent Support Library: The Percent package provides APIs to support adding and managing percentage based dimensions in your app. 12. App Recommendation Support Library for TV: The App Recommendation package provides APIs to support adding content recommendations in your app running on TV devices. STEPS IN DOWNLOADING SUPPORT LIBRARIES: Start the android SDK Manager. In the SDK Manager window, scroll to the end of the Packages list, find the Extras folder. Select the Android Support Library item. Click the Install packages button. ——————————————— ADDITIONAL LIBRARIES AVAILABLE FOR ANDROID 1. Google Play Services : To develop an app using the Google Play services APIs, you must add Google Play services Library to your app. To develop an app using the Google Play services APIs, you need to set up your project with the Google Play services SDK. It helps us to use all the services provided by google in our Application. 2. GSON : GSON is a JSON parsing library developed by Google, to quickly parse the JSON into Java objects with very minimal work required. 3. JODA : Joda-Time provides a quality replacement for the Java date and time classes. The design allows for multiple calendar systems, while still providing a simple API. 4. NINE OLD ANDROIDS: Android library for using the Honeycomb (Android 3.0) animation API on all versions of the platform back to 1.0! Animation prior to Honeycomb was very limited in what it could accomplish so in Android 3.x a new API was written. With only a change in imports, we are able to use a large subset of the new-style animation with exactly the same API. This library also includes support for animating rotation, translation, alpha, and scale on platforms prior to Honeycomb! 5. PICASSO : Picasso is open source and one of the widely used image downloader library in Android. It simplifies the process of loading images from external urls and display on your application. 6.OTTO : Otto is an event bus designed to decouple different parts of your application while still allowing them to communicate efficiently. Forked from Guava, Otto adds unique functionality to an already refined event bus as well as specialising it to the Android platform. Otto is a great way to communicate between your activity and fragments or to communicate between an activity and a service. 7. SLF4J : The Simple Logging Facade for Java ( SLF4J ) serves as a simple facade or abstraction for various logging frameworks allowing the end user to plug in the desired logging framework at deployment time. 8. CROUTON: One way to notify users is to use Toasts. But Toasts have the problem that they might pop up in totally unrelated contexts. They are displayed for a defined duration on the screen no matter what the user does. The user might even have changed the app, with the result, that your Toast simply confuses the user. To overcome these we use crouton libraries which are customisable. 9. BUTTER KNIFE: Butterknife is a light weight library to inject views into Android components. The @Bind annotation allow to inject views and performs the cast to the correct type for you. The @@OnClick(R.id.yourid) annotation allows to add OnClickListener to a view. You can optional define the method parameter of the view in case you want it injected. 10. GUAVA : Guava is an open source, Java based library developed by Google. It facilitates best coding practices and helps reduce coding errors. It provides utility methods for collections, caching, primitives support, concurrency, common annotations, string processing, I/O, and validations. 11. OKHTTP : OkHttp is an HTTP client that’s efficient by default: HTTP/2 support allows all requests to the same host to share a socket. Connection pooling reduces request latency (if HTTP/2 isn’t available). Transparent GZIP shrinks download sizes. Response caching avoids the network completely for repeat requests. 12. DAGGER : Dagger is a fully static, compile-time dependency injection framework for both Java and Android. It is an adaptation of an earlier version created by Square and now maintained by Google. Dagger aims to address many of the development and performance issues that have plagued reflection-based solutions. Conclusion : The goal of using android support library is to simplify our development by offering more APIs that we can bundle with our application so we can worry less about platform versions. Android Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-04-26"},
{"website": "Mallow-Tech", "title": "SOFTWARE TESTING LEVELS – I", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/04/software-testing-levels-i/", "abstract": "In the SDLC, testing is rather an important phase. In this phase, the software is checked whether it meets the requirements? Behaves as expected by the developers? Performs as expected and usable as expected in the desired environment? Achieves the desired result? All of these are checked and once the results are satisfied then the product will be moved to delivery. There are four levels of software testing: Unit Testing Integration Testing System Testing Acceptance Testing Among these levels let us see the first two levels in detail in this post and for the rest click here . Unit Testing It is basically done by the developers to make sure that their code is working fine and meet the user specifications. The smallest independent and testable part of the source code is referred to as a unit. It is the first step in software testing environment and is generally conducted by the developers or their teammates. The primary goal of unit testing is to take the smallest piece of testable software in the application, isolate it from the remainder of the code, and determine whether it behaves exactly as you expect. Each unit is tested separately before integrating them into modules to test the interfaces between modules. Unit testing is carried on the smallest testable component of the project so the number of test cases and test data are less, and it is not always possible to check all the scenarios for functional and information flow of software application. If unit testing is carried out properly then it would also result in a lot of cost saving as the cost of fixing a defect in the final stages of software development is much higher than of fixing them in the initial stages. Integration Testing Once the unit testing phase is over, integration testing is done. In Integration testing, the individual tested units are grouped as one and the interface between them is tested. Integration testing identifies the problems that occur when the individual units are combined i.e it detects the problem in the interface of the two units. There are three different types of integration testing approach in software testing. Big Bang Top Down Bottom Up Big Bang: Big Bang Integration testing approach is performed by integrating all the modules simultaneously to create a software system as a whole. The test is performed on the created system to see if the original requirement is met with or not. Top down: In Top down integrated testing approach, all Top level integrated modules are tested first and its submodules are tested subsequently from top to bottom hierarchy in a step by step manner. Bottom-up: In Bottom-up integrated testing approach, all bottom (Sub Modules) level integrated submodules are tested first and its main modules tested from bottom to top hierarchy in a step by step manner. These two forms the first two stages of testing. These stages play an important role in the SDLC and determine the quality of the product to be delivered. Testing Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-04-21"},
{"website": "Mallow-Tech", "title": "Laravel Envoy", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/04/laravel-envoy/", "abstract": "What is it? It is a tool which provides us for running and automating the common tasks in server efficiently .This may involve things like: Tasks that should run on remote server. Eg 1: When we want to compile a C program online, we should compile the program on the server by running a command. (“in Server’s Terminal”). This can be clearly said as: “when we write the code in C and when we click compile button .This button compiles the code in the server by executing the compile command for C language”. Eg  2: Things like running GIT commands etc… Configure envoy in ubuntu: First we need to install laravel envoy command globally so that no matter in which directory we are we can run the command. composer global require “laravel/envoy=~1.0” Provide Executable permission to envoy: chmod +x ~/.composer/vendor/bin/envoy For easier access create symbolic link sudo ln -s ~/.composer/vendor/bin/envoy /usr/bin/envoy Now, lets try running “ envoy ” from our terminal. This should give us the following response, Laravel Envoy version 1.1.0 Usage: command [options] [arguments] Options: -h, –help                        Display this help message -q, –quiet                       Do not output any message -V, –version                  Display this application version –ansi                                Force ANSI output –no-ansi                         Disable ANSI output -n, –no-interaction     Do not ask any interactive question -v|vv|vvv, –verbose    Increase the verbosity of messages: 1 for normal output, 2 for more verbose output and 3 for debug Available commands: help     Displays help for a command init       Create a new Envoy file in the current directory. list        Lists commands run       Run an Envoy task. ssh        Connect to an Envoy server. tasks    Lists all Envoy tasks and macros. Creating Tasks: To create tasks we can use Blade style syntax but Laravel Envoy doesn’t require Blade template engine, it just uses Blade syntax to define tasks. To start lets create an “Envoy.blade.php” in the root folder of our project and we will create a simple task as below @servers([‘homestead’ => ‘vagrant@192.168.10.10’]) @task(‘list’, [‘on’ => ‘homestead’]) ls -la @endtask As we can see, an array of @servers is defined at the top of the file. we can refer these servers with the “on” option of our task declarations. Within our @task declarations we should place the Bash code that will be run on our server when the task is executed. The init command may be used to easily create a stub Envoy file: envoy init vagrant@192.168.10.10 Running Tasks: To run a task, we need to run  the below command for Envoy installation: vagrant@homestead:~/apex$ envoy run list Multiple Servers: We can easily run tasks across multiple servers by adding additional servers to our @servers declaration. For each server we should assign a unique name. Once we have defined all our additional servers, simply we need to list the servers in the task declaration’s as array @servers([‘web-1′ => ‘192.168.91.92’, ‘web-2’ => ‘192.168.91.93’]) @task(‘deploy’, [‘on’ => [‘web-1’, ‘web-2’]) cd default git pull origin {{ $branch }} php artisan queue:listen @endtask We can run this by, vagrant@homestead:~/apex$ envoy run deploy —branch=testing By default, the task will be executed on each server serially. Meaning, the task will finish running on the first server before proceeding to execute on the next server. Parallel Execution: If we would like to run few tasks across multiple servers in parallel then we can add the parallel option to our task declaration as below @servers([‘web-1′ => ‘192.168.91.92’, ‘web-2’ => ‘192.168.91.93’]) @task(‘deploy’, [‘on’ => [‘web-1’, ‘web-2’], ‘parallel’ => true]) cd default git pull origin {{ $branch }} php artisan queue:listen @endtask Using Envoy, we can easily setup tasks for deployment, Artisan commands and many more. Currently, Envoy supports Mac and Linux operating systems only. Hope this has given a you a clear and easy way to do tasks. Sridhar, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-04-28"},
{"website": "Mallow-Tech", "title": "Importance of Indexing and efficiency of indexing – Part 2", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/04/importance-of-indexing-and-efficiency-of-indexing-part-2/", "abstract": "Types of Indexing In the (previous blog) Importance of Indexing and efficiency of indexing – Part 1 we had gone through the basics of indexing and how to create an Index. Now we are going to know about the Types of indices. There are different types of indices that can be created against a Table. But, the main goal of all of it to improve database query performance. Single Column Index Unique Index Composite Index Single Column Index: Indexing on a single column of a table is the simplest and most widely used index. Single Column Index is the now which is created based on only one column of a Table. Yeah, you are correct, in the previous blog we have created single column index. Syntax: CREATE INDEX INDEX_NAME ON TABLE_NAME(COLUMN_NAME); Example: CREATE INDEX index_employees_on_phone_number ON employees(phone_number); Unique Index: Unique index is like Single Column Index, but it does not allow duplicate values to be inserted on the Table based on the Indexed column. Its not only for performance but also for data integrity. In the previous example, we have indexed the “phone_number” column on the Employee table, we can use the same column for the Unique Index also. Syntax: CREATE UNIQUE INDEX INDEX_NAME ON TABLE_NAME(COLUMN_NAME); Example: CREATE UNIQUE INDEX index_employees_on_phone_number ON employees(phone_number); Unique indices may apply on person’s Social Security Number, Employee ID and etc. In our case, Phone Number of each Employee should be different. Composite Index: Composite Index is an index created on more than one column of a table. There will be performance issue will occur while creating the Composite Index. For that we have to properly order the column while creating the Index. The ordering of the column in Composite Index play a vital role in data retrieval. (Lets look into that deeply on upcoming blog) Syntax: CREATE UNIQUE INDEX INDEX_NAME ON TABLE_NAME(COLUMN_1, COLUMN_2); Example: CREATE UNIQUE INDEX index_employees_on_last_name_dept ON employees(last_name, dept); Note: You have to decide whether to use Single Column Index or Composite Index based upon the columns which are you going to frequently query. Clustered Index: Clustered Index stores and sorts the data based on the column (or columns) which are specified for the Index. Clustered index contains all the data for the table in the index, sorted by the index key. If the database engine can use a clustered index during a query, the database don’t need to follow the reference back to the rest of the data like normal indices. The result is less work for the database and consequently, better performance for a query using a clustered index. Syntax: CREATE CLUSTERED INDEX INDEX_NAME ON TABLE_NAME(COLUMN_NAME) Example: CREATE CLUSTERED INDEX index_employees_on_social_security_number ON employees(social_security_number); As a general rule of thumb, every table should have a clustered index. If you create only one index for a table, use a clustered index. Not only is a clustered index more efficient than other indexes for retrieval operations, a clustered index also helps the database efficiently manage the space required to store the table. In SQL Server, creating a primary key constraint will automatically create a clustered index (if none exists) using the primary key column as the index key. The suitable example for Clustered Index is Telephone Directory, at where the data are sorted alphabetically. Note: Only one Clustered Index can exist for a table. Its good practice to create a Clustered Index on Primary key and Foreign key column, because key values generally do not change. Disadvantage of Clustered Index: If we update a record and change the value of an indexed column in a clustered index, the database might need to move the entire row into a new position to keep the rows in sorted order. This behavior essentially turns an update query into a DELETE followed by an INSERT, with an obvious decrease in performance. Non-Clustered Index: Non-Clustered Index contains index key value and a reference to the actual data. If there is no clustered index, the row locator is a pointer to the row. When there is a clustered index present, the row locator is the clustered index key for the row. Non-clustered indexes can be optimized to satisfy more queries, improve query response times, and reduce index size. There can be more than one Non-Clustered Index allowed for a Table. The suitable example for Non-Clustered Index is the Index of a Book, at the words with the reference of its page number. Syntax: CREATE NONCLUSTERED INDEX INDEX_NAME ON TABLE_NAME(COLUMN_NAME) Example: CREATE NONCLUSTERED INDEX index_employees_on_last_name ON employees(last_name); Difference between Clustered and Non-Clustered Indices: Lets see you in the next blog about “ How ordering the column in a Composite Index plays an important role in increasing the performance ”. Tell us about the before-and-after. I bet you’ll have something to say!!! Surender, ROR Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-04-01"},
{"website": "Mallow-Tech", "title": "What is Black Box Testing in software testing methods?", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/04/black-box-testing-design-techniques/", "abstract": "Black box testing tests the functionality of the application without having the knowledge of code. It is also called as Specification based testing. Black box testing design techniques are: Decision table testing All pairs testing State transition testing Equivalence partitioning Boundary value analysis Error Guessing Decision Table testing It is the testing of scenario which has yes or no condition. In this decision-based testing, we will test for both the conditions. What happens when the variable status is “Yes” or what happens if it is “No”?  This is mostly like if-then-else, switch cases with each condition having some actions to perform.  So we need to test all the actions. All pairs testing All pairs testing is a method to test all the possible discrete combinations of the parameters involved. Consider an application where we need to supply value to some three input parameters. So we need to test all possible combinations of input based on probability.  We have to consider all possible scenarios like, If we give value for all 3 parameters If we do not give value for all 3 parameters If we give value for 2 parameters. This testing is mainly to produce an optimal number of test cases.  We do not want to perform the entire test based on the probability (3 * 2) since we have 3 parameters but we can achieve the result by some combinations of input. State transition testing: This table shows the current state of the machine and to which status the machine will move to based on input parameters. For example, if you request to withdraw $100 from a bank ATM, you may be given cash. Later you may make exactly the same request but it may refuse to give you the money because of your insufficient balance. This later refusal is because the state of your bank account has changed from having sufficient funds to cover the withdrawal to having insufficient funds. The transaction that caused your account to change its state was probably the earlier withdrawal. Equivalence partitioning Equivalence Partitioning is a common black box testing technique and aims to reduce the number of redundant test cases by eliminating those that generate the same output and do not necessarily reveal defects in a program functionality. As the aim of testing is to find defects, then a successful test case is the one that does find a defect. The process of equivalence partitioning technique involves identifying the set of data as an input condition that give the same result when executing a program and classifying them as a set of equivalent data (because they make the program behave in the same way and generate the same output) and partitioning them from another equivalent set of data.This involves partitioning the data into some sets/group so that one test case is enough to cover each partition.  Consider an application where the app will work only if the value supplied by the user is between 10 to 100. So we can divide these as “1 to 10 as one partition 10 to 100 as second > 100 as third.” So while testing any one value from each partition is enough to test. After portioning we have to apply boundary value cases in order to select the best-suited test case from each partition. Boundary value analysis For each range, there are two boundaries, the lower boundary (start of the range) and the upper boundary (end of the range) and the boundaries are the beginning and end of each valid partition. We should design test cases which exercise the program functionality at the boundaries, and with values just inside and just outside the boundaries. Minimum Value, Minimum Value + 1, Minimum Value -1 Maximum Value, Maximum Value + 1, Maximum Value – 1 Error Guessing: The Error guessing is a technique where the experienced and good testers are encouraged to think of situations in which the software may not be able to cope. In using more formal techniques, the tester is likely to gain a better understanding of the system, what it does and how it works. With this better understanding, a person is likely to be better at guessing ways in which the system may not work properly. Typical conditions to try include division by zero, blank (or no) input, empty files and the wrong kind of data (e.g. alphabetic characters where numeric are required). If anyone ever says of a system or the environment in which it is to operate ‘That could never happen’, it might be a good idea to test that condition, as such assumptions about what will and will not happen in the live environment are often the cause of failures. A structured approach to the error-guessing technique is to list possible defects or failures and to design tests that attempt to produce them. These defect and failure lists can be built based on the tester’s own experience or that of other people, available defect, and failure data, and from common knowledge about why software fails. Periannan, Testing Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-04-01"},
{"website": "Mallow-Tech", "title": "Implementing Laravel Cashier", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/04/implementing-laravel-cashier/", "abstract": "This time we will discuss how to implement Stripe’s billing service using Laravel Cashier. Laravel Cashier provides an expressive and fluent interface for Stripe. It handles almost all the code we need for  subscription management, Cashier can handle coupons, swapping subscription, subscription “quantities”, cancellation grace periods, and even generate invoice PDFs. We will go step by step in the implementation process. Configuration Composer First, add the Cashier and Stripe package to your composer.json file. And run this command inside your terminal. composer update Service provider Add the package to your application service providers in config/app.php file. Migration Before using Cashier, we’ll need to add several columns to your database. Don’t worry, you can use the cashier:table Artisan command to create a migration to add the necessary column. For example, to add the column to the users table runs the command: php artisan cashier:table users It’s create a following column in users table Once the migration has been created, simply run the migrate command php artisan migrate Model Include Billable trait and also implement Billable contract inside your User model. Adding the columns to your model’s $dates property will instruct Eloquent to return the columns as Carbon / DateTime instances instead of raw strings Stripe Key Finally, set your Stripe key in your config/services.php configuration file: Add key to .env Stripe Account Create Now Sign-up the stripe account After creating an account, you can use test or live mode. Now I drive in test mode. You have an API key in stripe Account Setting -> API Keys. Its show Test Secret Key as well as Live Secret Keys. Now we will see the following process Setup Stripe Create a Plan Subscribe the user Create a coupon Subscribe user with coupon User Status Changes the plan Subscription status Subscription Quantity Subscription cancel Subscription resuming Invoices Set API Keys StripeStripe::setApiKey(env(‘STRIPE_SECRET’)); 2.Create a Plan Create a basic plan for subscriptions. Now we create plan for subscriber. Plan intervals are either day, week, month or year . Currency is 3-letter ISO code. ID is unique for plan. 3 . Subscribe the user Now we create a customer with cards details and get token to subscription. 4 . Create a Coupon Create a coupon for subscriptions. Coupon percent of offer, duration have the three type of values. Forever,  once and repeating. Duration in a month is numerical values. ID is unique for coupon. 5.Subscribe the user with a coupon Customer subscription is with a coupon. 6.User Status Customer Status 7.Change the Plan Subscription Plan changes Stripe API Cashier If user want to subscribe the prorate basis use Stripe API Cashier API User immediate invoice 8.User Subscription Status Customer Subscription Status Stripe API Cashier API 9.Subscription Quantity Increase or decrease the quantity. Stripe API 10.Subscription Cancel Strip API Cashier API 11.Subscription Resume Strip API Cashier API 12.Invoices Strip API Cashier API Hope this blog might have helped you in implementing the feature very clearly. We will try to discuss on the implementation of using an Indian Online payment gateway in the next coming blog. Balasubramani, PHP Senior Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-04-01"},
{"website": "Mallow-Tech", "title": "Centre UICollectionView Cells Horizontally", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/04/horizontally-center-alignment-position-in-uicollectionview-cells/", "abstract": "I am new into iOS app development. I had to do this for a project recently so thought I would share. Introduction to Collection View Overview: UICollectionView generalizes the familiar patterns of UITableView to make any layout possible. It manages a collection of ordered items on the screen using layouts. The patterns for providing data to a UICollectionView to create items and interact with those items, follow the same delegation and data source patterns commonly used in iOS. However, Collection View works with a layout subsystem that is independent of the UICollectionView itself. Therefore, simply providing a different layout can easily change the presentation of a Collection View. iOS provides a layout class called UICollectionViewFlowLayout that allows line-based layouts such as a grid to be created with no additional work. Also, custom layouts can also be created that allow any presentation you can imagine. Cells Cells are objects that represent a single item in the data set that is being presented by the collection view. Each cell is an instance of the UICollectionViewCell class, which is composed of three different views, as shown in the figure below: The UICollectionViewCell class has the following properties for each of these views: ContentView – This view contains the content that the cell presents. It is rendered in the topmost z-order on the screen. SelectedBackgroundView – Cells have built in support for selection. This view is used to visually denote that a cell is selected. It is rendered just below the ContentView when a cell is selected. BackgroundView – Cells can also display a background, which is presented by the BackgroundView . This view is rendered beneath the SelectedBackgroundView . By setting the ContentView such that it is smaller than the BackgroundView and SelectedBackgroundView, the BackgroundView can be used to visually frame the content, while the SelectedBackgroundView will be displayed when a cell is selected, as shown below: Procedure: CollectionView Cells Horizontally Center Alignment Position step 1 : set the collection view Scroll Direction : Horizontal step 2 : set the Constraint to collection view. – height fixed. – vertically centre – set (zero) leading space and trailing space to source view. step 3 : Before Using the below code know about the following terms. – frame width – collectionView Cell width – collectionView insets(left) var insets = self.collectionView.contentInset frameWidth = self.view.frame.size.width collectionViewWidth = (self.collectionView1.collectionViewLayout as! UICollectionViewFlowLayout).itemSize.width leftInsets = (frameWidth! – (collectionViewWidth! * CGFloat(strImages.count))) * 0.5 – (CGFloat(strImages.count-1) * 5) if leftInsets <= 0 { leftInsets = 0 } insets.left = leftInsets! self.collectionView1.contentInset =  insets sample output (one image): sample output (two images): sample output (four images): sample output (Three images in Portrait): This blog is useful to know about CollectionViewCell Position. Please make use of it. Gowthaman, iOS Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-04-01"},
{"website": "Mallow-Tech", "title": "Google places API implementation to retrieve the location details in Android", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/03/google-places-api-implementation-to-retrieve-the-location-details-in-android/", "abstract": "Our world is moving at very fast phase, technologically. As newer technologies develop, the world becomes smaller and smaller and we humans, being very curious, try to explore as many things as possible. What is Google Place API: Google Places API for android is such a thing. With it, the world is now in your hands. If you are lost or need to locate businesses or places nearby, you don’t need to find a guide or a map to help you, Google is now providing Google Places API. Using the Google Places API for Android, you can build location-aware apps that respond contextually to the local businesses and other places near the device. This means that you can build rich apps based on places that mean something to the user, to complement the straightforward geographic-based services offered by the Android location services . The release of Android places API not only simplifies the data access but also spares the developers from keeping track of latitudes and longitudes. Earlier, to access place data in Android, one had to retrieve all the information from a web service by passing various parameters like latitudes and longitudes to it. The API used at that time was Google Maps API . But now thankfully, nothing of this sort needs to be done. As the new Android places API is powerful enough to detect your current location and retrieve all the place data automatically. Places API is integrated with google maps search which offers more consistent search across Maps and the Places API. Features of Google Places API: 1. Place Picker UI widget 2. Auto Complete UI widget 3. GeoData Api 4. PlaceDetectionApi 5. Current Place 6. Place Report and Details Using the above , you can build rich apps based on places that mean something to user. Google has replaced the type restriction parameter with a new type search parameter. Type search works similarly to types restriction, but it only supports one type per request. Requests using the types parameter and those specifying multiple types (for example, types = hospital | pharmacy | doctor) will not work from now. Request type with multiple type will no longer supported. To ensure the best possible results for the user, do use single type in search request. Google have also added autocomplete functionality to the place picker UI widget that helps users communicate their current location, such as places, address or location on the map, which makes even easier to pick specific place by starting to type its name or address. If you already using Place Picker in your app, it will automatically gain the autocomplete feature with no action required on your part. Whenever your app displays information about places sourced from the Google Places API for Android, the app must also show all relevant attributions that are returned by the API. See the documentation on displaying attributions . Some apps using google Places API are: WhatsApp : WhatsApp uses Google Maps API and Google Places API, helps you keep in touch with friends through mobile messaging that allows to send your location. Citi Bike : Citi Bike uses Google Maps Direction API and Google Places API, to find the bike nearest you with Citi Bikes. Dash : Dash uses Google Maps Geocoding API, Google Maps Roads API, Google Maps Roads API, this app provides real-time diagnostics for drivers’ cars, helping them save time and money. Expedia : Expedia used Google Maps Android API, Google Maps Geocoding API, Google Places API, combines into one form of app which helps you to travel around the world and back, using Expedia to find hotels in the center of the action. Sun Surveyor : Sun Surveyor uses Google Maps Elevation API, Google Maps Time Zone API, Google Maps SDK for android, which brings augmented reality to photographers using Google Maps APIs. Harley Davidson : Harley Davidson uses Google Places API, Google Maps Android API, helps motorcyclists plan and share road trips on any platform. Implementation in Android: On Android, you can add the autocomplete widget as a Fragment and add an event listener to retrieve the autocompleted place reference back in the application. Alternatively, you can invoke the autocomplete widget with an Intent. Adding a Fragment In the XML layout file for your Activity: <fragment android:id=”@+id/place_autocomplete_fragment” android:layout_width=”match_parent” android:layout_height=”wrap_content” android:name=”com.google.android.gms.location.places.ui.PlaceAutocompleteFragment” > Adding an Event Listener in your Activity’s onCreate() method: PlaceAutocompleteFragment fragment = (PlaceAutocompleteFragment) getFragmentManager().findFragmentById(R.id.place_autocomplete_fragment); fragment.setOnPlaceSelectedListener(new PlaceSelectionListener() { @Override public void onPlaceSelected(Place place) { // Handle the selected Place Log.i(TAG, “Place: ” + place.getName()); String placeDetailsStr = place.getName() + “n” + place.getId() + “n” + place.getLatLng().toString() + “n” + place.getAddress() + “n” + place.getAttributions(); txtPlaceDetails.setText(placeDetailsStr); } @Override public void onError(Status status) { // Handle the error Log.i(TAG, “An error } Creating an intent to invoke the autocomplete widget: try { Intent intent = new PlaceAutocomplete.IntentBuilder(PlaceAutocomplete.MODE_FULLSCREEN).build(this); startActivityForResult(intent, PLACE_AUTOCOMPLETE_REQUEST_CODE); } catch (GooglePlayServicesRepairableException e) { GooglePlayServicesUtil .getErrorDialog(e.getConnectionStatusCode(), getActivity(), 0); } catch (GooglePlayServicesNotAvailableException e) { // Handle the exception } public void onPickButtonClick(View v) { // Construct an intent for the place picker try { PlacePicker.IntentBuilder intentBuilder = new PlacePicker.IntentBuilder(); Intent intent = intentBuilder.build(this); // Start the intent by requesting a result, // identified by a request code. startActivityForResult(intent, REQUEST_PLACE_PICKER); } catch (GooglePlayServicesRepairableException e) { // … } catch (GooglePlayServicesNotAvailableException e) { // … } } @Override protected void onActivityResult(int requestCode, int resultCode, Intent data) { if (requestCode == REQUEST_PLACE_PICKER && resultCode == Activity.RESULT_OK) { // The user has selected a place. Extract the name and address. final Place place = PlacePicker.getPlace(data, this); final CharSequence name = place.getName(); final CharSequence address = place.getAddress(); String attributions = PlacePicker.getAttributions(data); if (attributions == null) { attributions = “”; } mViewName.setText(name); mViewAddress.setText(address); mViewAttributions.setText(Html.fromHtml(attributions)); } else { super.onActivityResult(requestCode, resultCode, data); } } A Place is defined as a physical space that has a name. Another way of thinking about place is that it’s anything find on a map which includes local businesses, point of interest and geographic locations. In API, place is represented by Place interface, which includes information such as name of the place and its address, geographical locations, place ID, number, place, type, website URL, and so. In this Blog, you have learned how to use the Place Picker component, guess the user’s place, present them with predictive results when searching, and find a place based on a given ID. The Places API is a powerful tool for making your apps aware of the user’s location to provide them with contextual information. Android Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-03-16"},
{"website": "Mallow-Tech", "title": "Deploying Laravel applications using AWS Elastic Beanstalk", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/03/deploying-laravel-applications-using-aws-elastic-beanstalk/", "abstract": "In this blog we will discuss how to deploy Laravel applications using AWS Elastic Beanstalk and the step by step process, to have a clear view of the configuration to be done. What is AWS Elastic Beanstalk? AWS Elastic Beanstalk is a platform as a Service ( PaaS ) Which allows developers to deploy applications at an ease. It uses the following AWS products. Elastic Compute Cloud (EC2) Simple Storage Service (S3) CloudWatch Simple Notification Service (SNS) EB can also be managed with AWS Relational Database Service ( RDS ) instance but this is not recommended for a Laravel application as an RDS instance created in association with EB environment will also be terminated when the environment is terminated. Requirements that need to be checked before startup. Git repository should have initialized with the Laravel application. AWS account must have been created Need to know the basics of Web Server Environment. Creating an RDS instance We need to create an MySQL RDS instance for our Laravel MySQL database . Step 1: Step 2: Depending on our application requirement we can chose whether we want Multi-AZ deployment for the Database. As we are using it for Development we can use free tier usage. Step 3: Settings for DB If we have one RDS instance running at a time we can use free usage tier. Step 4: Advanced Settings We can select a default VPC and default DB Subnet Group. Finally we can give a database name and Launch DB Instance Name. Step 5: Security Credentials If we already have an Access Key ID and Secret Access Key for our account, we can skip this section else we can select create key Pair. The Key Pair is downloaded as .pem we need this file to do SSH for our EC2 instance. Step 6: Install the EB CLI We can interact with Elastic Beanstalk by GUI in the AWS Management Console. For quicker and easy way we need to use eb command line interface (CLI).  we can download the tool from http://aws.amazon.com/code/6752709412171743 . We need to Navigate to the root directory of our Laravel git Repository and type the command eb init We will be promoted to enter our AWS Key ID and AWS Secret Key. Which we generated in the previous step 5. We can choose single instance to ensure that we are in free usage tier and as we are only in development. Next we need to attach an instance profile. This gives EC2 instance to create security permissions to access other AWS services such as S3. This Creates the Elastic Beanstalk application associated with a git. In the Management Console we will see our application listed under “All Applications”  by navigating to our project directory we will see a new directory “.elasticbeanstalk” which contains a config file with all our preferences which we just set. This Directory is also added in the .gitignore file. There is  also an option to create RDS instance Manually using the code method. We can off the auto-scaling option by giving Max and MinSize both as 1. This means that we will have only one server in running if that servers gets down another server gets launched automatically. If we have the RDS instance in the same zone as EC2 instance this will cost less and at the same time it will be faster. Next step is we will edit the EC2KeyName with the same name as the key pair which we created this will allow us to SSH into our EC2 instance . The aws:elasticbeanstalk:application:environment contains our environment variables, which are added by our config files it just displays them and there is no impact on edit. Step 7: Modification needed under aws:elasticbeanstalk:container:php:phpini . We need to set composer_options to –no-dev, so that dev add-ons aren’t installed when composer install is running. Last, we’ll set document_root to /public so that it points to Laravel’s public folder. Step 8: Add Environment Config Files Located in the .ebextensions directory in the root of the project, the config files (*.config) contain commands for the environment to run and options to set. These config files run every time git aws.push is run (i.e., the environment is updated or a new EC2 instance within the environment is started), and they are run in alphabetical order. These config files SHOULD NOT be in your .gitignore file. To start, we will create three files: 00environmentVariables.config, 01composer.config,  and 02artisan.config. Environment Variables In the 00environmentVariables.config file, we will place all of the instructions for the application to modify the environment’s options, in this case to create environment variables (e.g., DB_HOST). Add the following code to this file: option_settings: – namespace: was:elasticbeanstalk:application:environment option_name: DB_HOST value: mysqldbname.ebs.us-east-1.rds.amazonaws.com – option_name: DB_PORT value: 3306 – option_name: DB_NAME value: EBS – option_name: DB_USER value: EBS – option_name: DB_PASS value: EBS Here, namespace refers to the specific groups of options in . elasticbeanstalk/optionsettings.app-environment-name . Using the namespace elasticbeanstalk:application:environment we are stating that the options and their values below are for that namespace. DB_HOST will be the endpoint shown in the RDS dashboard for the RDS instance set up earlier. All other environmental variables need to be the same. Composer Commands In the 01composer.config file, we will place all the composer commands to be run when a new instance is created or an existing instance is updated. Add the following code to this file: commands: 01updateComposer: command: export COMPOSER_HOME=/root && /usr/bin/composer.phar self-update option_settings: – namespace: was:elasticbeanstalk:application:environment option_name: COMPOSER_HOME value: /root container_commands: 01optimize: command: “/usr/bin/composer.phar dump-autoload —optimize” commands are executed first, which are run before the application and web server are set up. Here we self-update composer.phar to ensure the latest version is running on the instance. Next we set a COMPOSER_HOME environment variable. Note:  If a Vendor Folder is not there in the root directory EB will automatically run composer.phar install if it sees a composer.json file in the root directory. If your vendor folder is not in .gitignore, you will need to add composer.phar install to this file ourself. Artisan Commands In the 02artisan.config file, we specify container commands to run migrations and seeding. These commands should ideally be run only once, or if you are adding/modifying tables. I also tend to just migrate:refresh the database every now and then on the development server, as error tend to compound themselves and exceptions start cropping up in my app. container_commands: 01migrateSeed: command: “php artisan migrate –force” 02seed: command: “php artisan db:seed —force” Here we migrate to create the new database (including migrating the Auth Token package) and seed the database. Step 9: Git Commit With all of these changes now complete, commit these changes to your git repository. Step 10: Add Security Group Inbound Rule This is the last thing to do to give the Elastic Beanstalk application access to the MySQL RDS instance. Go to AWS Management Console and click on “Security Groups” under “Network & Security”. Here we can see two security groups: the default security group and a security group created for you Elastic Beanstalk application. We need to click the Elastic Beanstalk security group and copy the Group ID. Next we need to Right click on the default security group and select “Edit Inbound Rules”. Here we need to add a MySQL type rule with a Custom IP equal to the Elastic Beanstalk security group’s Group ID. Step 11: Execute the EB environment Commands as required eb start eb status git aws.push eb stop eb delete eb Deploy : AWS will set the resource necessary for our environment. : To Check the Environment Status : To upload the Git repo to the environment : To Terminate the Environment : To Delete our Application : Deploys the application source bundle from the initialised project directory to the running application. Hope this blog has cleared you how to deploy the Laravel applications using AWS Elastic Beanstalk. We will also see the things that need to be concentrated in the code while doing SSL In the next coming blogs. Vijayanand, PHP Team Lead, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-03-16"},
{"website": "Mallow-Tech", "title": "How to add Core Spotlight to index content in your app", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/03/how-to-add-core-spotlight-to-index-content-in-your-app/", "abstract": "Introduction: Before getting into the above topic lets have a short preview about what is a spotlight search for those who are new to iOS. Spotlight Search : Spotlight search is an iOS feature through which you can search for anything in your iPhone/iPad (apps, music, videos, contacts and even information stored inside apps). The following screenshot will let show how a spotlight search looks like in a iPhone device. To access spotlight you have to perform a swipe down action in your home screen. Now lets get into our main goal of this blog. •From iOS 9  Apple has added many new features one such feature gives us a way to display content of our apps through spotlight search which are called search APIs. •In this blog let us see the key components involved in the search API and make our app content display as a result of spotlight search. •The two main key component involved in search APIs are, ◦ NSUserActivity ◦ Core Spotlight Framework . Short Notes: ◦ NSUserActivity: Helps to capture and restore app state through a process called Handoff(Lets users to begin an action in one device and continue the action on another device). ◦ Core Spotlight Framework: Helps to add, edit and remove items from the on-device index for Spotlight search. Steps to use Core spotlight Framework to index our app content: To use this framework to index our app content perform the following steps, ◦ First of all add the Core Spotlight framework into the project. To add the core spotlight framework Goto, Project Navigatior -> Select the Project -> Build Phases tab- > Link Binary With Libraries ◦ And press the “+” button, a search box opens search with keyword “corespotlight.framework” and also add another library called “MobileCoreServices.framework” . ◦ Then the following steps has to be added to make your app content visible in the spotlight search result. 1.) First create an CSSearchableItemAttributeSet object with following details, -> Its ”title”,  “contentDescription” & “thumbnailData” as your wish. 2.) Create  an CSSearchableItem object with, “uniqueIdentifier” : Any unique string value which you would like to assign for your search item. “domainIdentifier” : A domain string value as you like & “attributeSet” : set of keywords using which you would like to search the search item created above. 3.) Use “ CSSearchableIndex . defaultSearchableIndex(). indexSearchableItems ([ CSSearchableItem ])” method to add the above created search object into the index. The following sample code helps you understand it better, //Adding app content into on-device index. func createSearchableItemAndAddToIndex() { // First Create an attributeSet object let attributeSet = CSSearchableItemAttributeSet (itemContentType: kUTTypeItem as String ) let titleString = “Title goes here” let titleDesctiption = “Description goes here” // Add details into attributeSet attributeSet. title = titleString attributeSet. contentDescription = titleDesctiption attributeSet. thumbnailData = UIImageJPEGRepresentation( UIImage (named: “profileImage.jpg” )!, 0.5) // Create keywords based on which we can able to search in the spotlight var searchKeywords = titleString.componentsSeparatedByString( ” “ ) searchKeywords.append(titleDesctiption) attributeSet. keywords = searchKeywords // Create a CSSearchableItem with a uniqueIdentifier, domainIdentifier & attributeSet let item = CSSearchableItem (uniqueIdentifier: “uniqueID” , domainIdentifier: “identifier” , attributeSet: attributeSet) // Add the item to the on-device index. CSSearchableIndex . defaultSearchableIndex(). indexSearchableItems ([item]) { error in if error != nil { print(error?. localizedDescription ) } else { print( “Search item has successfully added to Core Index” ) } } } After executing the above code you can see the above search item in the spotlight search result as shown in the following screenshot. Now we have added our app content into on-device index and displayed it in the spotlight search result. Now on the other hand, by default when the user clicks on the search result it will take the user to the respective app. To make the app do our custom action like opening a specific screen in the app when user clicks on the search result we have to handle it. This can we done with the help of following steps. Using NSUserActivity we can achieve this. So learn about NSUserActivity before proceeding further. I have given a sample overview of how this could be achieved. //Custom action for search result items Whenever a user clicks the search result item the following delegate method will get called in AppDelegate. func application(application: UIApplication, continueUserActivity userActivity: NSUserActivity, restorationHandler: ([AnyObject]?) -> Void) -> Bool; If you would like to make custom action for your search result selection action you can make use of this method and perform your required action by calling the method “ restoreUserActivityState ” from the above delegate method. An example code for handling custom user action is shown below, //AppDelegate func application(application: UIApplication , continueUserActivity userActivity: NSUserActivity , restorationHandler: ([ AnyObject ]?) -> Void ) -> Bool { if userActivity. activityType == CSSearchableItemActionType { let uniqueIdentifier = userActivity. userInfo ? [ CSSearchableItemActivityIdentifier ] as ? String let splitController = self .window?. rootViewController as ! UISplitViewController let navigationController = splitController. viewControllers.first as ! UINavigationController navigationController. topViewController ?. restoreUserActivityState(userActivity) } return true } Next you have to override the “restoreUserActivityState” method in your view controller and from there you can perform your required actions like showing the required screen or any actions as you would like to perform. An example for overriding the restoreUserActivityState is shown below, override func restoreUserActivityState(activity: NSUserActivity ) { if let contactNumber = activity. userInfo ![ CSSearchableItemActivityIdentifier ]! as? String { // Perform your custom action here or make the user to move to other screen in your application self . performSegueWithIdentifier ( “viewController” , sender: self ) } } I am an iOS developer and the this feature helps me to expose my app contents in spotlight search, which makes it easy in accessing the contents from my apps without even navigating many pages into my app, to get to that particular detail. Until Next Time…… Bharath, iOS Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-03-08"},
{"website": "Mallow-Tech", "title": "Importance of Indexing and efficiency of indexing", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/03/importance-of-indexing-and-efficiency-of-indexing/", "abstract": "Glad to present something useful to many. I have tried to cover the topic of “What is indexing and where to use it?”. “A database index is a data structure that improves the speed of data retrieval operations on a database table at the cost of additional writes and storage space to maintain the index data structure. Indices are used to quickly locate data without having to search every row in a database table every time a database table is accessed.” – Wikipedia An index is a specific structure that organizes a reference to your data that makes it easier to look up. When accessing data, Postgres will either use some form of an index if it exists or a sequential scan. Sequential scan – is when it searches over all of the data before returning the results. Advantages: • Adding an index to a column will allow you to query based on a column faster. • Indices like primary key index and unique index help to avoid duplicate row data. Disadvantages: • They decrease performance on DML Commands. • They take up space (this increases with the number of fields used and the length of the fields). The whole point of having an index is to speed up search queries by essentially cutting down the number of records/rows in a table that need to be examined. By default the Primary Key on every table will be indexed. To create index on SQL: CREATE INDEX index_name ON table_name (column_name); Example: For example lets take User table which contains 10k records. and we need to find an user with user’s Phone Number which is saved under “phone_number” column. The query will be, SELECT * FROM employees WHERE phone_number = ‘1234567890’; Without index on Employees Table the Query will take some time to process. We can get the query details by using “EXPLAIN” command. EXPLAIN SELECT * FROM employees WHERE phone_number = ‘1234567890’; Seq Scan on employees (cost=0.00..32769.75 rows=1 width=297) Filter: (“phone_number” = 1234567890) (2 rows) Come lets create index on “phone_number” for our Employees Table. CREATE INDEX index_employees_on_phone_number ON employees (phone_numbers); Congrats… We have created index on Employees table. Now lets see our Query’s performance with Index. EXPLAIN SELECT * FROM employees WHERE phone_number = ‘1234567890’; Index Scan using index_employees_on_phone_number on employees (cost=0.42..8.44 rows=1 width=297) Index Cond: (“phone_number” = 1234567890) (2 rows) You can see the impact of Index on Employees table. The query time is radically decreased. To remove index: DROP INDEX index_name; Index will use some disk space to store the values. For every DML action(INSERT/UPDATE/DELETE) made on a indexed table it also do the action on index. If we create many indices for a heavy-write table the DML query cost will be increased but the query cost will be minimal. Create indices based on the frequency of the Index accessed. To know more about Indices have a look at this Importance of Indexing and efficiency of indexing – Part 2 Surender, ROR Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-03-08"},
{"website": "Mallow-Tech", "title": "Building Android Application", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/03/building-android-application/", "abstract": "Build variants are specific builds that, you can produce from Gradle, based around shared core source code. While a standard app may have a debug and release build type, you can expand on this, by adding flavor dimensions. Flavor dimensions allow you to use the folder structure of your project, to change how individual builds look and act for your users. This enables developers to easily produce multiple similar apps, with different styles and configuration. Each build that you create, will need a unique application-Id, in order to differentiate it from the other builds. Since any application that you build, will have at least one flavor from each dimension, you only need to define the application-Id in each node for one dimension. Android application can be build by using the following ways, Build the app using Android Studio. Build by using command line Build by using Maven Building a project using Android Studio a. Create a new project. b. Click Next c. Project will be opened like this. d. Click Run icon in the tool bar  (or) choose in the menu – Run->Run”app”->Click to build project. e. Get APK file in the project root directory: 2. Building and Running Project using Command Line Reference: http://developer.android.com/tools/building/building-cmdline.html Building in debug mode: a. Open->Terminal->Open your project directory b. Use Gradle command to build the project: $ chmod +x gradlew $ ./gradlew assembleDebug c.Show the tasks: ./gradlew tasks Building in release mode: a. Open->Terminal->Open your project directory b. Run the below command $ ./gradlew assembleRelease This creates your Android application .apk file inside the project bin/ directory, named <your_module_name>-unsigned.apk. The .apk file is unsigned at this point and can’t be installed until signed with your private key. c. Build signed and aligned i. Open a command-line and navigate to the root of your module directory. ii. Edit the build.gradle file to build your project in release mode: android { … defaultConfig { … } signingConfigs { release { storeFile file(“myreleasekey.keystore”) storePassword “password” keyAlias “MyReleaseKey” keyPassword “password” } } buildTypes { release { … signingConfig signingConfigs.release } } iii. When prompted, enter you keystore and alias passwords. Caution:  As described above, your password will be visible on the screen. 4. This creates your Android application .apk file inside the module build/ directory, named <your_module_name>-release.apk. This .apk file has been signed with the private key specified in build.gradle file and aligned with zipalign. It’s ready for installation and distribution. 3. Build Application using Maven The android-maven-plugin plug-in allows to build Android applications via Maven. In most cases, development of Android applications is done within the Android studio based Android Development Toolkit ADT . The optionally generated Apache Ant based build can be used to build applications outside the IDE. The Android Maven Plugin was created to allow development teams to build, deploy and release Android applications with Apache Maven, taking advantage of all the powerful features available like dependency management, reporting, code analysis and much more. Following steps are involved in maven build a. Installing Maven in the system. b. Define a simple Maven build c. Build Android code d. Rebuild Android code with dependencies a. Install Maven in the system Now you have a project that you can build with Maven. The next step is to install Maven. Maven is downloadable as a zip file at http://maven.apache.org/download.cgi . Only the binaries are required, so look for the link to apache-maven-{version}-bin.zip or apache-maven-{version}-bin.tar.gz. Download and unzip the file, then add the bin folder to your path. To test the Maven installation, run mvn from the command-line: mvn -v If all goes well, you should see installation information like this: Apache Maven 3.2.1 (ea8b2b07643dbb1b84b6d16e1f08391b666bc1e9; 2014-02-14T11:37:52-06:00) Maven home: /usr/local/apache-maven/ apache-maven-3.2.1 Java version: 1.8.0, vendor: Oracle Corporation Java home: /Library/Java/JavaVirtualMachines/jdk1.8.0.jdk/Contents /Home/jre Default locale: en_US, platform encoding: UTF-8 OS name: “mac os x”, version: “10.9.2”, arch: “x86_64”, family: “mac” You now have Maven installed. b. Define a simple Maven build Now that Maven is installed, you need to create a Maven project definition. You define Maven projects with an XML file named pom.xml. Among other things, this file gives the project’s name, version, and dependencies that it has on external libraries. Create a file named pom.xml at the root of the project and give it the following contents: pom.xml <?xml version= “1.0” encoding= “UTF-8” ?> <project xmlns= “http://maven.apache.org/ POM/ 4.0.0” xmlns:xsi= “http://www.w3.org /2001 / XMLSchema-instance” xsi:schemaLocation= “http://maven.apache.org / POM /4.0.0 http: // maven.apache.org / maven-v4_0_0.xsd” > <modelVersion>4.0.0</modelVersion>> <groupId>org.hello</groupId> <artifactId>gs-maven-android</artifactId> <version>0.1.0</version> <packaging>apk</packaging> <properties> <!– use UTF-8 for everything –> <project.build. sourceEncoding> UTF-8 </ project.build. sourceEncoding> <project.reporting. outputEncoding> UTF-8 </ project.reporting. outputEncoding> </properties> <dependencies> <dependency> <groupId>com.google. android </groupId> <artifactId>android</artifactId> <version>4.1.1.4</version> <scope>provided</scope> </dependency> </dependencies> <build> <plugins> <plugin> <groupId> com.jayway.maven. plugins.android. generation2 </groupId> <artifactId> android-maven-plugin </artifactId> <version>3.9.0-rc.1</version> <configuration> <sdk> <platform>19</platform> </sdk> <deleteConflictingFiles> true </deleteConflictingFiles> <undeployBeforeDeploy> true </undeployBeforeDeploy> </configuration> <extensions> true </extensions> </plugin> <plugin> <artifactId> maven-compiler-plugin </artifactId> <version>3.1</version> <configuration> <source>1.6</source> <target>1.6</target> </configuration> </plugin> </plugins> </build> </project> The <packaging> element specifies an apk. This is the simplest possible pom.xml file necessary to build an Android project. It includes the following details of the project configuration: • <modelVersion> . POM model version (always 4.0.0). • <groupId> . Group or organization that the project belongs to. Often expressed as an inverted domain name. • <artifactId> . Name to be given to the project’s library artifact (for example, the name of its APK file). • <version> . Version of the project that is being built. • <packaging> . How the project should be packaged, in this case as an Android APK. The <dependencies> section declares a list of dependencies for the project. Specifically, it declares a single dependency for the Android library. Within the <dependency> element, the dependency coordinates are defined by three subelements: • <groupId> . Group or organization that the dependency belongs to. • <artifactId> . Library that is required. • <version> . Specific version of the library that is required. • <scope> . Scoped as compile dependencies by default. That is, all dependencies should be available at compile-time. In this case, the <scope> element has a value of provided . Dependencies of this type are required for compiling the project code, but will be provided at runtime by a container running the code. For example, the Android APIs are always available when an Android application is running. The <build> section declares additional configuration for building an application. Within the build section is a <plugins> section, which contains a list of plugins that add additional functionality to the build process. This is where you define the configuration for the Android Maven Plugin . As with dependencies, plugins also have <groupId> , <artifactId> , and <version> elements, and they behave as previously described. The plugin declaration also has these elements: • <configuration> . Plugin-specific configuration. Here you specify which Android Platform SDK to use in the build. • <extensions> . Combination of specifying a value of true and apk for <packaging> directs the [Android Maven Plugin] to become involved in the build process. At this point you have defined a minimal yet capable Maven project. c. Build Android code Maven is now ready to build the project. You can execute several build lifecycle goals with Maven now, including goals to compile the project’s code, create a library package (such as a JAR file), and install the library in the local Maven dependency repository. Try out the build: mvn compile This command runs Maven, telling it to execute the compile goal. When it’s finished, you should find the compiled .class files in the target/classes directory. Because it’s unlikely that you’ll want to distribute or work with .class files directly, you’ll probably want to run the package goal instead: mvn package The package goal compiles your Java code, runs any tests, and packages the code in a JAR file within the target directory. The name of the JAR file is based on the project’s <artifactId> and <version> . For example, given the minimal pom.xml file shown earlier, the JAR file will be named gs-maven-android-0.1.0.jar. Because you set the value of <packaging> to “apk”, the result will be an APK file within the target directory in addition to the JAR file. This APK file is now a packaged Android application ready to be deployed to a device or emulator. The Android Maven plugin provides several more Maven goals that you can use to initiate the various phases of the build process, or interact with the device and emulator. You can see a list of all the available goals by running the following command: mvn android:help d. Rebuild Android code with dependencies Now if you run mvn compile or mvn package , Maven should resolve the Joda Time dependency from the Maven Central repository and the build will be successful if we added as a dependency. Here’s the completed pom.xml file: pom.xml <?xml version= “1.0” encoding= “UTF-8” ?> <project xmlns= “http://maven.apache.org/ POM/ 4.0.0” xmlns:xsi= “http://www.w3.org /2001 / XMLSchema-instance” xsi:schemaLocation= “http://maven.apache.org / POM /4.0.0 http: // maven.apache.org / maven-v4_0_0.xsd” > <modelVersion>4.0.0</modelVersion>> <groupId>org.hello</groupId> <artifactId>gs-maven-android</artifactId> <version>0.1.0</version> <packaging>apk</packaging> <properties> <!– use UTF-8 for everything –> <project.build. sourceEncoding> UTF-8 </ project.build. sourceEncoding> <project.reporting. outputEncoding> UTF-8 </ project.reporting. outputEncoding> </properties> <dependencies> <dependency> <groupId>com.google. android </groupId> <artifactId>android</artifactId> <version>4.1.1.4</version> <scope>provided</scope> </dependency> </dependencies> <build> <plugins> <plugin> <groupId> com.jayway.maven. plugins.android. generation2 </groupId> <artifactId> android-maven-plugin </artifactId> <version>3.9.0-rc.1</version> <configuration> <sdk> <platform>19</platform> </sdk> <deleteConflictingFiles> true </deleteConflictingFiles> <undeployBeforeDeploy> true </undeployBeforeDeploy> </configuration> <extensions> true </extensions> </plugin> <plugin> <artifactId> maven-compiler-plugin </artifactId> <version>3.1</version> <configuration> <source>1.6</source> <target>1.6</target> </configuration> </plugin> </plugins> </build> </project> Hope this information is useful. Android Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-03-08"},
{"website": "Mallow-Tech", "title": "Laravel – Elixir", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/02/laravel-elixir/", "abstract": "Asset pipeline can be defined as a tool or service mechanism to compress, minify and concatenate the assets like css, javascript. With this process, we can improve our app performance by minimising the number of http request. In laravel, we can achieve this using the built in package called “Elixir” which was added in Laravel 5. It will be running on the gulp tool. Gulp makes the process easier. Let us look into the elixir in detail. What is Elixir? Jeffrey Way has evolved Elixir which simplify the process of asset compression,  concatenation and compilation, it includes some basic type of tasks: 1. Compilation of sass, less and coffee files 2. Concatenation 3. Versioning 4. Copying files Configuration & Installation Setup Before using Elixir, you need to have node.js installed on your machine. To check this installation, run this command, node -v Then, you need to pull in Gulp as a global NPM package: npm install --global gulp package.json file will have the contents and the dependencies for the elixir command to run. To use elixir, from the root of your Laravel application run the command (before running this command, make sure that the user has admin permission to install this) : npm install In the root folder, you may have gulpfile.js file to execute your tasks(minify,concatenate,merge multiple files into a single file) Laravel provides methods to compile the less, sass, coffee scripts and for combining the multiple css and script files. Let’s see those methods below in detail. Less & Sass Less and Sass methods are used for compiling less and sass files into css correspondingly. elixir(function(mix) { mix.less('app.less'); }); This will compile a less file named app.less which is placed under resources/assets/less. Once the compilation is done, the file will be stored in public/css. You can also mention the destination directory as an optional parameter to the less method as below. elixir(function(mix) { mix.less('app.less', 'public/stylesheets/style'); }); To compile sass files, you would do the same thing but instead of storing the sass file in resources/assets/less you would save it in resources/assets/sass folder and compile it using elixir(function(mix) { mix.sass('app.scss'); }); Here also you can customise the destination folder as said above. Also multiple less or sass files can be used in this method in first argument as array. Coffeescript Coffee method allow you to compile the coffee script into plain javascript. The output files will be stored in resources/assets/coffee directory. elixir(function(mix) { mix.coffee(['app.coffee', 'controllers.coffee']); }); The above method will compile all the scripts mentioned in the array and will generate a single file called app.js in public/js directory. Concatenation You can concatenate files with elixir, to combine your stylesheets just use styles method. It will combine the mentioned css files into a single file and output css file will be placed in public/css/all.css elixir(function(mix) { mix.styles([ 'normalize.css', 'main.css' ]); }); The same is applicable for script files using the scripts method. Here output javascript files will be stored in public/js/all.js. mix.scripts([ 'module1.js', 'module2.js' ]); You can also combine the list of css files or script files under a particular directory by simply mentioning the directory name instead of mentioning all the file names separately. mix.stylesIn('public/css'); and for javascript files mix.scriptsIn('public/js'); Versioning Elixir provides the versioning concept for the complied css and script files. To version a file you simply: mix.version('path/to/file'); You are allowed to pass multiple files for this method to add versioning. Once the versioning process is done, all files will be stored in public/build. Output filenames will be generated by appending a query string to the file or using random strings. Versioned files will be included in blade template using the below code, <link rel=\"stylesheet\" href=\"{{ elixir('css/main.css') }}\" /> <script src=\"{{ elixir('js/main.js') }}\"></script> Copying files The copy method can be used to copy files and directories to new locations. All these operations are relative to the project’s root directory: elixir(function(mix) { mix.copy('vendor/foo/foo.css', 'public/css/abc.css'); }); elixir(function(mix) { mix.copy('vendor/package/views', 'resources/views'); }); Running Elixir tasks To run the tasks listed above, you can simply run gulp This will run all the tasks mentioned in gulpfile. If you are in production environment, you can run this gulp --production To watch the file for frequent changes, you need to run gulp watch This will listen for the changes in css and script files for the changes. If any changes are done, compilation will be done automatically and updated file will be used in your application. Finally with the help of gulp tool and elixir helper functions, we have done the process of compilation and versioning of styles and scripts. Elixir is a useful tool to integrate Gulp into your Laravel projects. You can make use of this, to make your app to perform faster. Gayathri, PHP Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-02-24"},
{"website": "Mallow-Tech", "title": "Stripe ACH + Plaid + Rails", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/02/stripe-ach-plaid-rails/", "abstract": "Stripe ACH processes large volumes of credit and debit transactions. Its also connected with plaid for instant verification of bank account. You can directly charge on customer once it’s verified. Here I’ve explained on how to integrate it with ruby. Plaid and Stripe have partnered to offer frictionless money transfers without the need to ever handle an account or routing number. Use Plaid Link to instantly authenticate your customer’s account and automatically generate a Stripe bank account token so that you can accept ACH payments via their ACH API. Step 1. Setup Strip and Plaid First you need setup stripe and plaid . If not please use following links Stripe: https://dashboard.stripe.com/register Plaid: https://dashboard.plaid.com/signup/stripe/ Then you need to activate ACH Access. If you see following link in ACH Guide after sign up, Click ‘Accept Terms of Service’ to enable your Stripe account for ACH To verify that your Plaid account is enabled for the integration, go to the account dashboard. If you see: Click the ‘Connect With Stripe’  and follow the steps. If you did not connect to your stripe to plaid you can’t get stripe bank token. Once your Stripe account is connected, you’ll see: Your Plaid account is now set up for the integration! Step 2: Integrate with Plaid Link Once your Plaid account is setup and connected to your Stripe account, add Plaid Link to your site. <button id='linkButton'> Open Plaid Link< /button> <script src=\"https://cdn.plaid.com /link/stable/link-initialize. js\"> < /script> <script> var linkHandler = Plaid.create({ env: 'tartan', clientName: 'Stripe / Plaid Test', key: '[Plaid key]', product: 'auth', selectAccount: true, onSuccess: function(public_token, metadata) { // Send the public_token and account ID to your app server. console.log('public_token: ' + public_token); console.log('account ID: ' + metadata.account_id); },}); // Trigger the Link UI document.getElementById ('linkButton').onclick = function() { linkHandler.open(); }; </script> Step 3: Integrate with rails using plaid-ruby library Include plaid-ruby in your gem file and configure plaid in config/application.rb Plaid.config do |p| p.customer_id = 'Plaid provided customer ID here' p.secret = 'Plaid provided secret key here' p.environment_location = 'URL for the development or production environment' # i.e. 'https://tartan.plaid.com/' for development, or # 'https://api.plaid.com/' for production end Step 4: Integrate With Stripe ACH With Stripe, you can accept ACH payments in nearly the same way as you accept credit card payments, merely providing a verified bank account as the source argument for a charge request. However, accepting bank accounts requires a slightly different initial workflow than accepting credit cards: 1. Bank accounts must first be verified. 2. Bank accounts must be authorized for your use by the customer. Plaid provides the quickest way to collect and verify your customer’s banking information. Using the Stripe + Plaid integration, you’re able to instantly receive a verified bank account, allowing for immediate charging. To get stripe bank token you request plaid with exchangeTokenResponse = Plaid.exchange_token( public_token, account_id) it will return following details { \"sandbox\": false, \"access_token\": \"[Plaid API access token]\", \"stripe_bank_account_token\": “[Stripe Bank Token]”, \"account_id\": \"[Plaid Account ID]\" } You can attach this token to a Stripe Customer object, or create a charge directly on it. Stripe.api_key = “stripe_secret_key” customer = Stripe::Customer.create( :email =>’email’, :description => “description\", :source => exchangeTokenResponse. stripe_bank_account_token) You can use this customer object to charge Stripe.api_key = “stripe token\" Stripe::Charge.create( :amount   => 1500, :currency => \"usd\", :customer => customer_id ) You can use this token for linking bank account to stripe account. But the stripe bank valid for one time usage. Request once again to get exchangeTokenResponse and link your bank to stripe. stripe_account = Stripe::Account.retrieve (‘Connected Account id’) stripe_account.external_accounts. create( :external_account => exchangeTokenResponse. stripe_bank_account_token) This will create bank account for connected stripe account Hope this is helpful.. Prakash, ROR Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-02-24"},
{"website": "Mallow-Tech", "title": "NIGHT SHIFT feature in iOS", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/02/night-shift-in-ios/", "abstract": "What is Night Shift : This is a cool new feature which is available from iOS 9.3 for all iOS device users. As the name, ‘night shift’ suggests this feature is designed to help the user at night. Night Shift uses your iOS device’s clock and geolocation to determine when it’s sunset in your location. Then it automatically shifts the colors in your display to the warmer end of the spectrum, making it easier on your eyes. In the morning, it returns the display to its regular settings. Why Night Shift? Many studies have shown that exposure to bright blue light in the evening can affect your circadian rhythms and make it harder to fall asleep. Electronic displays like those on phones and tablets have a higher concentration of blue light than the sun. So, when you’re lying in bed at night playing your favorite game or streaming your favorite flick, then you’re over exposing your eyes to the blue light and damaging your circadian rhythm. In simpler words, it resets that feeling of tiredness and hurts our sleep cycle. What’s Blue Light? Blue light, it is the light on the spectrum that makes our computer, tablet, and phone screens bright and great during the day because it mimics a bright morning. Blue wavelengths wake us up, boosts our attention, and let us know it’s time to start the day. But at night, blue light is less desirable because that’s the time when our bodies should be getting ready to relax and take a good sleep. Although all light disrupts the circadian rhythm, the blue light has been proven to be the most disruptive. On a Kelvin scale used to determine color temperature, an iPhone 6 display measures in at about 7100K, while an iPad Air 2 display is slightly warmer at 6900K. On the lighting spectrum, 6900K and 7100K blue light levels are similar to the light you would see on a bright, cloudy day outdoors. Blue light is also harder on the eyes, especially in an indoor room that’s lit with a dimmer yellow light. How to activate Night Shift? Night Shift mode works by shifting the iPhone or iPad’s display from a blue tint to a much more yellow tint, either on demand, or automatically at sunrise and sunset, or on a custom user defined schedule. Night Shift is turned on in the Settings app. Steps to activate Night Shift: Open settings app. Scroll to the Display & Brightness section. Tap on it, to locate the Night Shift. Manual Mode : Tap on the “Manual” toggle. Adjust screen temperature as desired. With no schedule set, Night Shift mode will automatically turn off in the morning. Automatic Mode : In the Night Shift menu, tap on “From and To” to set Night Shift activation times. Tap on “Sunset to Sunrise” to set Night Shift to come on when the sun sets based on your iPhone’s clock. When the sun sets in your local area, the display will shift from regular mode to Night Shift mode over the course of a minute. Tap on “Custom Schedule” to set your own times for Night Shift to turn on and off again. Note: Additionally, the “Setting Time Zone” feature under Location Services also needs to be enabled. This can be accessed by going to Privacy –> Location Services –> System Services. Make sure “Setting Time Zone” is toggled on. Quick Access : For quickly turning on or disabling Night Shift, there’s a Control Center option for Night Shift. The Control Center can be accessed by swiping up from the bottom of an iPhone or iPad’s display, where Night Shift is represented by an icon that depicts a crescent moon in an eye. Tapping on the icon will bring up options to turn Night Shift on or to disable it until the next day. The menu also displays current Night Shift settings. Availability: Night Shift is a feature in iOS 9.3, but as it turns out, it isn’t a feature that’s available on all of the devices able to run iOS 9. Night Shift requires a 64-bit processor, which encompasses the A7, A8, A8X, A9, and A9X. Devices Processor Night Mode Availability iPad 2, iPhone 4s, iPod touch 5G, iPad mini A5 NO iPad 3 rd generation A5X NO iPhone 5, iPhone 5C A6 NO iPad 4 th generation A6X NO iPhone 5s, iPad Air, iPad mini 2, iPad mini 3 A7 YES iPhone 6, iPhone 6 Plus, iPad mini 4, iPod touch 6G A8 YES iPad Air 2 A8X YES iPhone 6s, iPhone 6s plus A9 YES iPad Pro A9X YES This feature is a necessary one for all the iOS users. This feature optimizes the mobile phone usage and helps in getting a good night sleep without hurting our eyes. Arasuvel, iOS Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-02-24"},
{"website": "Mallow-Tech", "title": "Software Testing Life Cycle", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/02/software-testing-life-cycle/", "abstract": "Lifecycle in simple term refers to the sequence of changes from one form to other form. These changes can happen to any tangible or intangible things. Every entity has a lifecycle from its inception to retire / demise. In a similar fashion, Software is also an entity. Just like developing software involves a sequences of steps, testing also has steps which should be executed in a definite sequence. This phenomenon of executing the testing activities in a systematic and planned way is called testing life cycle. What is Software Testing Life Cycle (STLC) Software Testing Life Cycle refers to a testing process which has specific steps to be executed in a definite sequence to ensure that the quality goals have been met. In STLC process, each activity is carried out in a planned and systematic way. Each phase has different goals and deliverables. Different organizations have different phases in STLC; however the basis remains the same. Software Testing Life Cycle consists of six phases: Requirement Analysis Test Planning Test case Design Test Case Execution Re-testing and regression Final Testing and Closure 1. Requirements Analysis In this phase the testing team analyse the client requirements and discuss with developers during the design phase to see which requirements are testable and how they are going to test those requirements. It is very important to start testing activities from the requirements phase itself because the cost of fixing defect is very less if it is found in requirements phase rather than in future phases. 2. Test Planning: A test plan defines how we are going to proceed testing with the requirements that we have for a project Scope of testing Testing Strategies (Black Box, White Box, etc.) Testing Levels (Functional, Integration testing, Regression testing, Performances, security etc.) Limitation (if any) Testing Techniques Testing Tools, Test devices, OS, browsers and Databases Test Reporting and Bug reporting (How would bugs be reported) Milestones Resource allocation 3. Test Design ·        In this phase, Test cases are created with reference to spec available for a project. During test case creation, The test cases are categorised under test suits,which have a bunch of test cases for particular module. In the test-case document, it should have test summary, test inputs, expected result, actual result section. The test cases prepared by the QA team are reviewed and approved. ·         The QA team analysis the cases to be automated for the milestones and writes the automated test cases. Test data may also be created in this phase by the QA team if test environment is available to them. The test cases should cover all Positive and negative scenarios along with input datas. 4. Test Execution (Unit / Functional Testing Phase) Test Case execution is a process of executing test cases/scripts in a logical sequence with specific test data (if available). Unit test are carried out by the developers and other functional and non-functional test cases are executed by dedicated testing team. If any Test Case/Script or Test Scenario fails, Testing Team logs the bug in Bug Tracking tool (Bugzilla, Jira, MantisBT, etc.). Simultaneously a dedicated team of developers would be fixing the bugs and release the fixes in next build. Testing team will verify the reported bug and accordingly update the Bugs logged. This cycle continues till all the bugs identified in product are fixed. Finally a Regression or Ad-hoc Testing is performed after that the test results are updated. 5. Re-testing and regression testing phase By this time, at-least one test cycle (one round of test execution) would have been completed and bugs would have been reported. Once the development team fixes the bugs, then a second round of testing begins where re-testing and regression testing is carried out. Re-testing is testing of corrected/enhanced module. And regression testing is done to ensure that fixed bug do not affect the remaining functionality of the modules and also the functionality of the same module. Here is where automation tests are extremely useful to repeat the same test cases again and again. During this phase – review of test cases and test plan could also be carried out. 6. Final Testing and Closure When the planned test cycles are completed, then the final testing is done. Ideally this is System or Integration testing. Also any remaining Stress and Performance testing is carried out. Inputs for process improvements in terms of software metrics is given. Test result analysis is done in order to find out the defect distribution by type and severity. Then final Test reports, test release notes are prepared and final auditing is done for closing the testing process in order to release the tested product. I think I have addressed all major points of Software Testing Life Cycle (STLC). I would like all of you to please share you experience on STLC in below comment section. Periannan, Test Engineer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-02-24"},
{"website": "Mallow-Tech", "title": "Zeplin – Collaboration between UI designers & Front-end developers.", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/02/zeplin-collaboration-between-ui-designers-front-end-developers/", "abstract": "Photoshop was the goto tool for UI Designers for a long time. But in wake of the mobile industry boom, especially apps, agile methodology, etc., UI Designers now use variety of tools like Sketch , iDraw , inVision etc. These tools do not offer tons of features like Photoshop and Illustrator, but when it come to UI designing, they have every thing that is needed and simplified. When a designer works using Photoshop, he/she has to provide the style guides(colors, font) and image assets to the developer separately. This is a complicated process, even for a small change. This is were Sketch helps out, it reduces the time spent on developing prototypes, exporting assets based on mobile OS (iOS and Android) and other simple features. But still there was a gap between the design and development processes. This is where Zeplin comes in! Zeplin enables collaboration between UI designers and front-end-developers. In this blog I have explained some of the features that Zeplin has and how it makes life easier for Front-end developers like me. Zeplin: Zeplin was launched on July 2015, with the mission in bridging the UI designers and the front-end-developers. Zeplin is available as both, a web tool and as a Mac App (MacOS). There is a plugin for Sketch through which the selected art-boards or if need be, the whole project can be directly exported to Zeplin, using the shortcut cmd+E , this works only with the Mac App. In case of the web tool, whole of the project as .sketch file can be imported to it. Now let us see how Zeplin enables collaboration between designer & developer: Zeplin has many cool features to enable a smooth collaboration between the UI designers & front-end developers. I have briefed some of the features below. Color Palette: It depends on the kind of project platform you require, you’ll be able to export the color palette in XML for Android, as required for Objective-C or Swift in iOS and in plain CSS or SASS, LESS and Stylus incase of web projects, all of this with code snippets. This is a great time saving feature for both the designer and developer. Assets: We can export the assets according to platform we have selected. If you select Android as the platform, you will get the asset in all of the sizes as of mdpi, hdpi, xhdpi, xxhdpi, xxxhdpi and for iOs you can export them as @1x, @2x, @3x with ease. Typo: This feature helps us to find the exact font size used in the design and also we can get the type of font used. Zeplin also allows us to copy the contents directly. Position: We can also know the position of the components placed in the design. Just by clicking the component, it shows the X, Y position. Latest Update! As I was writing this blog, a new feature has been updated. Generating CSS for web components. After updating Zeplin, select web as the platform to get css for the selected component. You can copy the code and use it. You can also have a look at our blog on Choosing right screen size while importing from Sketch Thanks to Zeplin, it has reduced the dependency gap between designers and developers in our company. Satheesh, FronEnd Developer Trainee, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-02-12"},
{"website": "Mallow-Tech", "title": "Laravel Testing", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/02/laravel-testing/", "abstract": "Software Testing Software testing is  done to provide stakeholders a quality rich product and service. It also helps us to understand the risks of software implementation. In this blog we will see the importance of testing and the ways of implementing in Laravel. We have also included our open source support for testing. Importance of testing Testing is essential to know how your software product respond to different kinds of scenarios. Testing the software or application helps us in finding the bugs. It saves us lot of time where we will have to test repeatedly for checking the same result. That is one of the main reasons to automate Testing and considering testing as a “Process”. Even in “Software Development Life Cycle” testing is a process that is given a great importance and it is defined as a process of “Validating and Verifying” the Software products. Types of Testing There are different kinds of Testing that are currently in use today. Among these techniques the widely used Industry Testing Techniques are Unit Testing – Testing a single isolatable part or unit of an application. This testing may involve testing a method, class etc.. Integration Testing – This can be summarised as “Testing the functionalities of components when they are combined”. Testing implementation using Laravel Laravel supports unit testing. To run Laravel Tests you need to end the class name with Test. For example, if you are testing PostController ,name your Test case as PostTest. To do this just run the following command, php artisan make:test PostTest Let’s check whether string is present in the webpage or not with Laravel Testing php artisan make:test ExampleTest Checking whether a string is present in the webpage: Method-1: Class ExampleTest extends Testcase{ Public function sampleTest(){ //Check whether a page exists or not $response = $this->call(‘GET’,’/’); //Get request to home page(root). var_dump($response->getContent()); //Get the Content of the page. //Checks whether the response has “Hello!!” is present or not. $this->assertTrue(strpos($response->getContent(),‘Hello!!’)!==false); } } Method-2: Class ExampleTest extends Testcase{ Public function checkString($text){ $crawl = $this->client->getCrawler(); $found = $crawler->filter(“body:contains(‘{$text}’)”); $this->assertGreaterThan(0,count($found),”Expected to see {$text}”); } } Our open-source support for Testing The most common things done in testing are: The basic CRUD operations are successful. A default layout is written for testing and each time they copy and paste the same layout class for their future tests. REST API Testing with JSON requests and responses. We have developed a simple package for testing considering the above common things which you can make use of it and build your additional testing on top of it. Package link : https://github.com/MallowPhp/test Download and install the package by following the instructions in the URL. After following all the instructions run the following command in your Terminal php artisan You will find a command mallow:test . Now when you look at the source code of LayoutTest.php in the package(look in github or look in /vendor/mallow/testing/BaseTestcase) You have eight attributes: $token – To save the token. Leave this null as this is used by getToken() method. $link – Specify the default path of your resource you want to check. $link = “localhost:8000/topics” If there is “posts” under route prefix group topic. Define as $link = “localhost:8000/topic/posts” $table – It indicates the table name. This is for checking whether the data is stored after testing in the table. $credentials – Data in JSON to validate user credentials and generate token. { “email”: “ admin@mallow-tech.com ”, “password”: ”123456” } $data1 and $data_update are JSON objects with the data you give. $checkDataExistsInTable and $checkDataAfterUpdate are for checking the data you send is stored in the table you mentioned. Don’t to give this in an array. You will find four methods: First Method getToken() is used for providing authentication token to other methods. testStringAndResponseThatExists() is the method that checks the response in database with the string you specify after you save new resource. It returns “OK” if this is successful when you run phpunit. testStringAndModifiedResponse() is the method that checks the response in database with the string you specify after you update the existing resource. It returns “OK” if this is successful when you run phpunit. testIndex() is the method that checks whether it returns the data with 200 response. Execution: php artisan mallow:test MallowTest After execution check tests folder in your project root directory. You will find “ MallowTest.php ” with the file contents defined in “ LayoutTest.php ” inside BaseTestcase folder(comes with package installation) except the class name here would be replaced with “MallowTest” from “LayoutTest”. These methods are few samples for testing your “REST API”. You can always feel free to define your LayoutTest.php by replacing the file contents with your contents. To do this first go to the following path, /vendor/mallow/testing/src/BaseTestcase/LayoutTest.php Copy and paste your Testcase Layout contents in the file above mentioned. And Don’t forget to define the classname as “LayoutTest”. This LayoutTest will be automatically replaced with the class-name you specify in the command, php artisan mallow:test NewLayoutTest Now, ”NewLayoutTest.php” in tests will have the contents you define and with the class name “NewMallowTest”. There are many assertions available apart from what we have seen. Check Laravel Testing Documentation for more details. Hope this will also help you to get ideas on how we can also create a package and contribute to the open source. Happy Coding!!! Sridhar, Intern @ Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-02-12"},
{"website": "Mallow-Tech", "title": "Fetching data for data tables using ajax method", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/02/fetching-data-for-data-tables-using-ajax-method/", "abstract": "DataTables can take the data that it is to display from a number of different sources like DOM, JavaScript array, Ajax source, Server-side processing. DOM: DataTables a reference to a table which already exists in your HTML page.DataTables will read all of the information about the table from the page (the DOM) and add features such as filtering, paging and sorting. For example we declare the table head and body in HTML page. JavaScript: Data is computed by javascript or when adding a table to a page dynamically. For example we declare the table body content as array in javascript. Server-side processing: Dealing with large data sets (for example 20 million rows) the web-browser simply can’t cope with the amount of processing that is required for DataTables.The server-side process will do all of the pagination, sorting, filtering etc, while DataTables will simply display the results and handle user interaction Ajax source: Data can be get from server and displayed in dataTable. A common use case for this is when you are displaying live information which could be periodically updated. Benefits of using DataTables 1.We can load the table data through json which makes the HTML page render faster. 2. It can support client side and server side searching, sorting and pagination through AJAX/HTML request. 3.It create a DOM element only when required so we can not load all data and render page as very fast. 4.We can handle millions of data in table using server-side processing. 5. we can handle every row data and can be conditionally restrict the table reDraw functions easily. In this example i am using AJAX source for displaying a DataTable. Step 1 (HTML file): Declare the following Data Table structure. In this line ui-jq=“datatable” which tells AngularJs that this is the data table and ‘ui-options’ tells AngularJs to use the setting from scope variable names ‘ajaxOptions’. <table id=“ajaxExample” class=“display” width=“100%” ui-jq=“datatable” ui-options=“ajaxOptions”> <thead> <tr> <th>Name</th> <th>Age</th> <th>Position</th> <th>Office</th> </tr> </thead> </table> Step 2(Controller): Define scope variable named “ajaxOptions” which will be used as setting for the data tables. Inside scope variable define the AJAX  method.Please note here “url” is request ajax url and “headers” is request header and then “dataSrc”  is success response source array of objects . we cannot need to specify “ Request type” as GET. I have Sample GET request API    “http://datatable.getsandbox.com/datatable” In this API we get the following sample success response Success JSON Data : { “users”: [ { “name”: “Airi Satou”, “age”: 20, “position”: “Chief Executive Officer (CEO)”, “office”: “Tokyo” }, { “name”: “Rhona Davidson”, “age”: 29, “position”: “Chief Operating Officer (COO)”, “office”: “Tokyo” } ], “total_persons”: 13 } Here “Users” is a array of object for dataSrc and “total_persons” is another key and values. AJAX declaration for AngularJs controller: $scope.ajaxOptions = { “ajax”: { “url”: “http://datatable.getsandbox.com/datatable”, “dataSrc”: “users”, “headers”: “Content-Type: application/json” }, “columns”: [ { “data”: “name” }, { “data”: “age” }, { “data”: “position”}, { “data”: “ office”} ], }; When we use dataSrc in ajax options we cannot get other objects and key from dataSrc. In this example we cannot get “total_persons” from table. In DataTable AJAX we can use many call back function. Using Callback method for DataTable AJAX: fnPreDrawCallback : Called at the very start of each table draw and can be used to cancel the draw by returning false, any other return (including undefined) results in the full draw occurring. In this callback ajax call will work and get dat from success response but we can decide the DataTable are draw or not. In this example i am using checkbox for deciding dataTable are drawn or not. If checkbox are checked the ajax request called but dataTable not filled otherwise dataTable draw normally. Example: “fnPreDrawCallback”: function (oSettings, json){ if ($scope.select.data) { return false; } } In this example  “$scope.select.data” is a checkbox value if the value is true it’s return false and cancel the draw otherwise its return always true value. fnInitComplete: Called when the table has been initialised. Normally DataTables will initialise sequentially and there will be no need for this function, however, this does not hold true when using external language information since that is obtained using an async XHR call. This callback can be called after DataTable has been fully initialised. We can get other objects like outside of “dataSrc” object. Example: “fnInitComplete”: function (oSettings, json) { $scope.$apply(function() { $scope.total = json.total_persons; }); } In this example init function called after dataTable was drawn and get all JSON data from success response as key name “json”. I will get a total_persons object value that is outside of “users” object and assign values to $scope.total. fnDrawCallback: This function is called on every ‘draw’ event, and allows you to dynamically modify any aspect you want about the created DOM. In this example i am using setInterval function for ajax reload ajax.reload() : it is often useful to be able to reload the table, showing the latest data. This method provides exactly that ability, making an Ajax request to the already defined URL (use ajax.url() if you need to alter the URL). Example: setInterval( function () { $(‘#ajaxExample’).DataTable().ajax.reload(); }, 30000 ); In this example AJAX method called every 30 sec and get a latest success response data. The latest data (dataSrc object) can be redraw automatically because of reload function but outside of dataSrc object values cannot be get. So using this DrawCallback function we get all AJAX reload function data and we initialise it. Example: “fnDrawCallback”: function (oSettings, json){ alert(“DataTables has redrawn the table”); $scope.$apply(function() { $scope.total = json.total_persons; }); } In this example we get a latest data form json value and i am reinitialise the latest total_persons value to $scope.total value. fnRowCallback: This function allows you to ‘post process’ each row after it have been generated for each table draw, but before it is rendered on screen. This function might be used for setting the row class name etc Example: “fnRowCallback”: function( nRow, aData, iDisplayIndex, iDisplayIndexFull) { var oSettings = $(‘#ajaxExample’).dataTable().fnSettings(); $(“td:first”, nRow).html(oSettings._iDisplayStart+iDisplayIndex +1); $(nRow).attr(“id”,’row_’ + aData.id); return nRow; } RowCallback function return many values. Here “nRow” is every dataTable row and “aData” is JSON data of every row and “iDisplayIndex” is index values of every row and “iDisplayIndexFull” is index of the data in the full list of rows. In this example i set a serial number for every row with pagination using “iDisplayIndex” value and i set a attribute “id” for every row. Sample project using ajax: https://github.com/SasiMallow/datatable_ajax How to use Datatables in AngularJS application Sasikala, ROR Junior Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-02-05"},
{"website": "Mallow-Tech", "title": "How to add a custom code snippet in Xcode", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/08/how-to-add-code-snippets-in-xcode/", "abstract": "Code Snippets is a useful and valuable feature in Xcode(IDE). Developers who use Xcode for their App or any other project development can use code snippets. It saves a lot of time. Instead of duplicating codes or rewriting, we can use code snippet. It also helps a lot in avoiding the mistakes in a code. How To Add a Custom code Snippet? In Xcode, You can add your own code snippets. For adding the custom code snippets, just drag and drop the selected code into code snippet library. Once the code is dropped in the snippet library, it will prompt a window for adding a title, shortcut, language, and summary. Also if you want to edit the custom code snippet, you can do it. How to identify custom code snippets in snippets library? In the code snippet library, you can see “User” text in the bottom right corner of the open&close flower braces icon. Custom Parameter in Code Snippet: You can also have custom parameters in the code snippet. In the code, if you put the text as <#paramName#>, then the code will ask for the parameter. There you can add our parameter based on the code. Title: Name of the code snippet. The title is used to identify the code snippet. Summary: You can specify what this code snippet will do. You can give your own comments for the explanation. What is Shortcut in code snippet? You can add a shortcut in the code snippet. If you type the shortcut text in the code editor, then the auto-completion code will pop up. By using this you can save time. What is language in code snippet? When inserting a new code snippet, you can specify for what languages this snippet should show. If you specify the language as swift, then the Xcode will automatically detect the file editor type and show the corresponding code snippets in the snippets library. How to edit a code snippet? By clicking the code snippet,  a pop-up window appears. And in the pop-up window, there is an edit button, in the bottom left corner, by selecting the edit button you can edit the code snippet in the library. Note: You can’t edit the default code snippets in the library. Being an iOS developer Code snippets helped me to a greater extent in making my development processes efficient. Code snippets made the process easier, cleaner and simpler. Yogesh, iOS Team, Mallow Technologies . Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-08-08"},
{"website": "Mallow-Tech", "title": "An Introduction to INTERNET of THINGS [ IoT]", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/02/internet-of-things-iot/", "abstract": "What is IoT? Internet of Things (IoT) is an ecosystem of connected physical objects that are accessible through the internet. The ‘thing’ in IoT could be a person with a heart monitor or an automobile with built-in-sensors, i.e. objects that have been assigned an IP address and have the ability to collect and transfer data over a network without manual assistance or intervention. In short, it is the concept of basically connecting any device with an on and off switch to the Internet (and/or to each other). This includes everything from cell phones, coffee makers, washing machines, headphones, lamps, wearable devices and almost anything else you can think of. Here, the Cloud-based applications are the key to using leveraged data. The Internet of Things doesn’t function without cloud-based applications to interpret and transmit the data coming from all these sensors. The cloud is what enables the apps to go to work for you anytime, anywhere. Why IoT? An article by Ashton published in the RFID Journal in 1999 said, “If we had computers that knew everything there was to know about things – using data they gathered without any help from us – we would be able to track and count everything, and greatly reduce waste, loss and cost. We would know when things needed replacing, repairing or recalling, and whether they were fresh or past their best. We need to empower computers with their own means of gathering information, so they can see, hear and smell the world for themselves, in all its random glory.” This is precisely what IoT does for us. It enables devices/objects to observe, identify and understand a situation or the surroundings without being dependent on human help. What is the scope of IoT? IoT can connect devices embedded in various systems to the internet. When devices/objects can represent themselves digitally, they can be controlled from anywhere. The connectivity then helps us capture more data from more places, ensuring more ways of increasing efficiency and improving safety and security. IoT is a transformational force that can help companies improve performance and deliver better results. Businesses in the utilities, oil & gas, insurance, manufacturing, transportation, infrastructure and retail sectors can reap the benefits of IoT by making more informed decisions, aided by the torrent of interactional and transactional data at their disposal. How can IoT help? IoT can help organisations reduce cost through improved process efficiency, asset utilization and productivity. With improved tracking of devices/objects using sensors and connectivity, they can benefit from real-time insights, which would help them make smarter decisions. The growth and convergence of data, processes and things on the internet would make such connections more relevant and important, creating more opportunities for people, businesses and industries. “By 2020, there will be 21 billion connected devices in a global Internet of Things: Gartner Group” Periannan, Testing Team, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-02-05"},
{"website": "Mallow-Tech", "title": "Ruby dev’s benefit with HTTP/2 changes", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/01/ruby-devs-benefit-with-http2-changes/", "abstract": "HTTP/2: HTTP/2 (originally named HTTP/2.0) is the second major version of the HTTP network protocol used by the World Wide Web. It is based on SPDY(pronounced as speedy). It was developed by the Hypertext Transfer Protocol working group of the Internet Engineering Task Force. Difference from HTTP 1.1: HTTP/2 leaves most of HTTP 1.1’s high level syntax, such as methods, status codes, header fields and URI’s, the same. HTTP/2 allows the server to “push” content, that is, to respond with data for more queries than the client requested. This allows the server to supply data it knows a web browser will need to render a web page, without waiting for the browser to examine the first response, and without the overhead of an additional request cycle. Additional performance improvements in the first draft of HTTP/2 come from multiplexing of requests and responses to avoid the head-of-line blocking problem in HTTP 1, header compression and prioritisation of requests. Changes that benefits: Here’s a couple of things that will benefit almost every web application. Header Compression: One of the major drawbacks of HTTP 1.1 is that headers cannot be compressed. Recall that a traditional HTTP request might look like this: accept:text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8 accept-encoding:gzip, deflate, sdch accept-language:en-US,en;q=0.8 cache-control:max-age=0 cookie:_ga=(tons of Base 64 encoded data) upgrade-insecure-requests:1 user-agent:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.73 Safari/537.36 Cookies, especially, can balloon the size of HTTP requests and responses. Unfortunately, there is no provision in the HTTP 1.x specification for compressing these – unlike response bodies, which we can compress with things like gzip. Headers can make up 800-1400KB of a request or response – multiply this to Web Scale and you’re talking about a lot of bandwidth. HTTP/2 will reduce this greatly by compressing headers with something fancy called Huffman coding. You don’t really need to understand how that works, just know this – HTTP/2 makes HTTP headers smaller by nearly 80%. And you, as an application author, won’t need to do anything to take advantage of this benefit, because the compression/decompression will happen at lower levels (probably in Rack or some new layer directly below). This compression will probably be one of the first HTTP2 features that Rails apps will be able to take advantage of, since header compression/decompression can happen at the load balancer or at the web server, before the request gets to Rack. You can take advantage of header compression today, for example, by placing your app behind Cloudflare’s network, which provides HTTP/2 termination at their load balancers. Multiplexing: Multiplexing is a fancy word for two-way communication. HTTP 1.x was a one-way street – you could only communicate in one direction at a time. This is sort of like a walkie-talkie – if one person is transmitting with a walkie-talkie, the person on the other walkie-talkie can’t transmit until the first person lets off the “transmit” button. On the server side, this means that we can send multiple responses to our client over a single connection at the same time. This is nice, because setting up a new connection is actually sort of expensive – it can take 100-500ms to resolve DNS, open a new TCP connection, and perhaps negotiate SSL. Multiplexing will completely eliminate the need for domain sharding, a difficult-to-use HTTP 1.x optimization tactic where you spread requests across multiple domains to get around the browser’s 6-connections-per-domain limit. Instead of each request we want to make in parallel needing a new connection, a client browser can request several resources across the same connection. I mentioned domain sharding was fraught with peril – that’s because it can cause network congestion. The entire reason the 6-connections-per-domain limit even exists is to limit how much data the server can spit back at the client at one time. By using domain sharding, we run the risk of too much data being streamed back to clients and causing packet loss, ultimately slowing down page loads. One area where Rails apps can take advantage of multiplexing today is by using an HTTP/2 compatible CDN for serving their assets. Stream Prioritization: HTTP/2 allows clients to express preferences as to which requests should be fulfilled first. For example, browsers can optimize by asking for JS and CSS before images. They can sort of do this today by delaying requests for resources they don’t want right away, but that’s pretty jank and fraught with peril. Again, Ruby app can take advantage of this right now by using an HTTP/2 compatible CDN. Latency Reduction: HTTP/2 will especially benefit users in high-latency environments like mobile networks or developing countries. Twitter found that SPDY speed up requests in high-latency environments much more than in low-latency ones. Binary HTTP/2 is a binary protocol. This means that, instead of plain text being sent across the wire, we’re sending 1s and 0s. In short, this means HTTP/2 will be easier for implementers, because plain-text protocols are often more difficult to control for edge-cases. But for clients and servers, we should see slightly better bandwidth utilization. Unfortunately, this means you won’t be able to just telnet into an HTTP server anymore. To debug HTTP/2 connections, you’re going to need to use a tool that will decode it for you, such as the browser’s developer tools or something like WireShark. One connection means one TLS handshake One connection means TLS handshakes only need to happen once per domain, not once per connection (say, up to 6 TLS handshakes for the same domain if you want to download 6 resources from it in parallel). Rails applications can experience the full benefit of this HTTP/2 feature today by being behind an HTTP/2 compatible web server or load balancer. How Rails Apps Will Change with HTTP/2 All of the changes I’ve mentioned so far will generally benefit all Ruby web applications – but if you’ll permit me for a minute, let’s dive in to Rails as a specific example of your applications may have to change in the future to take full advantage of HTTP/2. Primarily, HTTP/2 will almost completely upend the way Rails developers think about assets. Concatenation is no more In essence, all HTTP/2 does is make requests and responses cheaper. If requests and responses are cheap, however, suddenly the advantages of asset concatenation become less clear. HTTP/2 can transport a JS file in 10 parts pretty much as fast as it can transport that same file in 1 part – definitely not the case in HTTP/1.x. In HTTP/1.x-world, we’ve done a lot of things to get around the fact that opening a new connection to download a sub-resource was expensive. Rails concatenated all of our Javascript and CSS into a single file. Some of us used frameworks like Compass to automatically sprite our images, turning many small .pngs into one. But since HTTP/2 makes many-files just as cheap as one-file, that opens up a whole new world of advantages for Rails: • Development mode will get waaaay faster. In development mode, we don’t concatenate resources, meaning a single page often requires dozens of scripts and css files. HTTP/2 should make this just as fast as a single concatenated file in production. • We can experiment with more granular HTTP caching schemes. For example, in todays Rails’ world, if you change a single line in your (probably massive) application.js, the entire file will need to be re-downloaded by all of your clients. With HTTP/2, we’ll be able to experiment with breaking our one-JS and one-CSS approach into several different files. Perhaps you’ll split out high-churn files so that low-churn CSS won’t be affected. • We can amortize large amounts of CSS and JS over several page loads. In today’s Rails world, you have to download all of the CSS and JS for the entire application on the first page load. With HTTP/2 and it’s cheap connections, we can experiment with breaking up JS and CSS on a more granular basis. One way to do it might be per-controller – you could have a single base.css file and then additional css files for each controller in the app. Browsers could download bits and pieces of your JS and CSS as they go along – this would effectively reduce homepage (or, I guess, first-page) load times while not imposing any additional costs when pages included several CSS files. Server push really makes things interesting HTTP/2 introduces a really cool feature – server push. All this means is that servers can proactively push resources to a client that the client hasn’t specifically requested. In HTTP/1.x-land, we couldn’t do this – each response from the server had to be tied to a request. Consider the following scenario: 1. Client asks for index.htm l from your Rails app. 2. Your Rails server generates and responds with index.html . 3. Client starts parsing index.html , realizes it needs application.css and asks your server for it. 4. Your Rails server responds with application.css . With server push, that might look more like this: 1. Client asks for index.html from your Rails app. 2. Your Rails server generates and responds with index.html . While it’s doing this, it realizes that index.html also needs application.css , and starts sending that down to the client as well. 3. Client can display your page without requesting any additional resources, because it already has them! Super neato, huh? This will especially help in high-latency situations where network roundtrips take a long time. Interestingly, I think some of this means we might need to serve different versions of pages, or at least change Rails’ server behavior, based on whether or not the connection is HTTP/2 or not. Hopefully this will be automatically done by the framework, but who knows – nothing has been worked on here yet. How to Take Advantage of HTTP/2 Today If you’re curious about where we have to go next with Rack and what future interfaces might look like in Rails for taking advantage of HTTP/2, I find that this Github thread extremely illuminating . For all the doom-and-gloom I just gave you about HTTP/2 still looking a ways off for Ruby web frameworks, take heart! There are ways to take advantage of HTTP/2 today before anything changes in Rack and Rails. Move your assets to a HTTP/2 enabled CDN An easy one for most Rails apps is to use a CDN that has HTTP/2 support. Cloudflare is probably the largest and most well-known. There’s no need to add a subdomain – simply directing traffic through Cloudflare should allow browsers to upgrade connections to HTTP/2 where available. The page you’re reading right now is using Cloudflare to serve you with HTTP/2! Open up your developer tools to see what this looks like. Use an HTTP/2 enabled proxy, like nginx or h20. You should receive most of the benefits of HTTP/2 just by proxying your Rails application through an HTTP/2-capable server, such as nginx. For example, Phusion Passenger can be deployed as an nginx module. nginx, as of 1.9.5, supports HTTP/2. Simply configure nginx for HTTP/2 as you would normally, and you should be able to see some of the benefits (such as header compression). With this setup, however, you still won’t be able to take advantage of server push (as that has to be done by your application) or the websocket-like benefits of multiplexing. Hope the above information will be useful. Until next time. Logesh, ROR Team Lead, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-01-22"},
{"website": "Mallow-Tech", "title": "Zeplin – Choosing right screen size while importing from Sketch?", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/01/zeplin-choosing-right-screen-size-while-importing-from-sketch/", "abstract": "I came to know about Zeplin through one of our clients. Zeplin is a collaboration tool between designers and developers. It helps in generating style guides and resources automatically. I faced an issue when exporting the assets from Zeplin. The images size (@1x, @2x, @3x) seemed to differ than the required size. I found that, it is because I had chosen the wrong screen size (density) while importing the Sketch file (screen). So when you import the Sketch file into Zeplin, make sure you choose the right density same as what you had used in Sketch. e.g. I wanted to share this, since I could not find any official explanation and hoping it would be of some help to people facing this issue. To know more read Zeplin – Collaboration between UI Designers and Front-end Developers Satheesh, FronEnd Developer Trainee, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-01-22"},
{"website": "Mallow-Tech", "title": "AVAudioPlayer – How to work it.", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/01/avaudioplayer-how-to-work-it/", "abstract": "In this blog we will learn about how to work with audio files in iOS(swift). Framework: A framework is a bundle that contains a dynamic shared library along with associated resources, such as nib files, image files, and header files. When you develop an application, your project links to one or more frameworks. For example; iPhone application projects link by default to the Foundation, UIKit, and Core Graphics frameworks. AVFoundation:(iOS FrameWork) AV Foundation framework provides essential services for working with time-based audiovisual media on iOS. By using this, you can easily play, capture, edit or encode media files. About Audio: • To play sound files, you can use AVAudioPlayer. • To record audio, you can use AVAudioRecorder. AVAudioPlayer: The AVAudioPlayer class lets you play sound in any audio format available in iOS. The properties of this class used for managing information about a sound such as the playback point within the sound’s timeline, and for accessing playback options such as volume and looping.This class is available from iOS 2.2. AVAudioPlayer class provides playback of audio data from a file or memory. AVAudioPlayer Initialization Methods 1. – initWithContentsOfURL:error: Initializes and returns an audio player for playing a designated sound file. Parameters: url : A url identifying the sound file to play. error: If an error occurs, upon return the NSError object describes the error. 2. – initWithData:error: Initializes and returns an audio player for playing a designated memory buffer. Parameters: data: A block of data containing a sound to play. error: If an error occurs, upon return the NSError object describes the error. 3. – initWithContentsOfURL:fileTypeHint:error: Initializes and returns an audio player using the specified URL and file type hint. Parameters: url : A url identifying the sound file to play. utiString: A UTI that is used as a file type hint. error: If an error occurs, upon return the NSError object describes the error. 4. – initWithData:fileTypeHint:error: Initialises and returns an audio player using the specified data and file type hint. Parameters: data: A block of data containing a sound to play. utiString: A UTI that is used as a file type hint. error: If an error occurs, upon return the NSError object describes the error. AVAudioPlayer Methods: - play Plays a sound asynchronously. Returns YES if the audio played successfully. – pause Pauses playback, sound remains ready to resume playback from where it left off. - stop Stops playback and undoes the setup needed for playback. - prepareToPlay Prepares the audio player for playback by preloading its buffers. – playAtTime:(time) Plays a sound asynchronously, starting at a specified point in the audio output device’s timeline. Parameters: time: The number of seconds to delay playback, relative to the audio output device’s current time. Returns YES if the audio played successfully. Properties of AVAudioPlayer Playing Returns a boolean value that indicates whether the audio player is playing (YES) or not (NO). Volume The playback volume for the audio player, ranging from 0.0 through 1.0 on a linear scale. Pan The audio player’s stereo pan position. Rate The audio player’s playback rate. EnableRate A Boolean value that specifies whether playback rate adjustment is enabled for an audio player. NumberOfLoops The number of times a sound will return to the beginning, upon reaching the end, to repeat playback. Delegate The delegate object for the audio player. Settings The audio player’s settings dictionary, containing information about the sound associated with the player. NumberOfChannels The number of audio channels in the sound associated with the audio player. ChannelAssignments An array of AVAudioSessionChannelDescription objects associated with the audio player Duration Returns the total duration, in seconds, of the sound associated with the audio player. CurrentTime The playback point, in seconds, within the timeline of the sound associated with the audio player. DeviceCurrentTime The time value, in seconds, of the audio output device. URL The URL for the sound associated with the audio player. Data The data object containing the sound associated with the audio player. Supported audio formats AAC (MPEG-4 Advanced Audio Coding) ALAC (Apple Lossless) AMR (Adaptive Multi-rate) HE-AAC (MPEG-4 High Efficiency AAC) iLBC (internet Low Bit Rate Codec) Linear PCM (uncompressed, linear pulse code modulation) MP3 (MPEG-1 audio layer 3) µ-law and a-law Advantages AVAudioPlayer can play songs when app is in background. AVAudioPlayer can handle files of any duration unlike System Sound Services that has a 30 second limit. The source for Audio data and AVAudioPlayer can either be files or in-memory sources. AVAudioPlayer can be set to loop a certain number of times or infinitely. AVAudioPlayer can also handle playing multiple sounds from multiple sources simultaneously. Disadvantages AVAudioPlayer has some timing ability, it’s not precise. AVAudioPlayer has a limited ability to alter the data stream. AVAudioPlayer cannot play songs from a playlist. Sample code in swift First you need to import AVFoundation Then create instance for it for example, let player: AVAudioPlayer = AVAudioPlayer() Then you can load the url in the instance of the AVAudioPlayer like let path = NSBundle.mainBundle().pathForResource(file as String, ofType: type as String) // Instead of file you need to use your file name(audio file name). let url = NSURL.fileURLWithPath(path!) do { try self.player = AVAudioPlayer(contentsOfURL: url) } catch { //To handle if error occurred print(“Player not available”) } To play the audio @IBAction func playButtonPressed(sender: AnyObject) { self.player.play() } To pause the audio @IBAction func pauseButtonPressed(sender: AnyObject) { self.player.pause() } To stop the audio @IBAction func stopButtonPressed(sender: AnyObject) { self.player.stop() } I hope you have learnt from this blog on how to work with audio files such as to play, stop and access the information about the audio file in the supported format. Mohanapriya, iOS Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-01-21"},
{"website": "Mallow-Tech", "title": "Git Worktree", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/01/git-worktree/", "abstract": "We have been using ‘ Git ’ as it was easy to handle everything from small to large projects with speed and efficiency. Also it was the widely used version control system with flexibility in place. It was easy to learn and moreover all, the lightning fast performance tends to make us of it. We have always had a sort of trouble whenever we work on a “branch X” and the other “branch Y” needs change. In this case we would usually stash the changes that we made and switch over the branch and work on it and come back and apply stash but this looked some kind of extra work though it is not. But since Git 2.5 has introduced a new command “worktree”, the above said work can be reduced. A new worktree command allows you to maintain multiple checked out work trees of the same root repository. It’s fantastic. Before this command existed one had a few ways to switch context and work on different streams at the same time: • Stash the current uncommitted changes and checkout a different branch (using git stash). • Create work-in-progress (i.e. WIP ) commits in the current branch to save ones work and switch branch. • Create a separate full clone of the repository to keep two ongoing development efforts separate and parallel. • Set the GIT_WORK_TREE or GIT_DIR environment variables, as explained here. With worktree one can create a sub-folder of the root project with a specific checked out branch – or ref for that matter – and keep working on it until done. The command saves you from having to create separate – out of band – clones. So imagine you’re happily working on the develop branch but you are tasked to work for a few days on the rewrite branch that has massive changes. You can create a worktree for this extended work and leave your other ongoing effort where it is. The syntax of the command is: git worktree add [-f] [–detach] [-b <new-branch>] <path> [<branch>] So in our example the command would become: git worktree add rewrite-folder rewrite The command creates a sub-folder in the root of your project named – surprise – rewrite-folder which contains the checked out branch rewrite. We can push and pull from that sub-folder as if we are at the root of our Git project and when we are done with that work we can simply delete the folder rewrite-folder. The administrative files stored in .git/worktrees will be eventually pruned, but if you want to be thorough you can easily prune that data with: git worktree prune [-n] [-v] [–expire <expire>] Hope the above information will be useful until next time. Logesh, ROR Team Lead, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-01-18"},
{"website": "Mallow-Tech", "title": "AVSpeechSynthesizer", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/01/avspeechsynthesizer/", "abstract": "The AVSpeechSynthesizer class introduced from iOS7 produces synthesized speech from text on an iOS device, and provides methods for controlling or monitoring the progress of ongoing speech. This class is a part of the powerful AVFoundation framework. This class is responsible for carrying out the heavy work of converting text to speech. It’s capable of initiating, pausing, stopping and continuing a speech process. AVSpeechUtterance is an intermediate class that interact directly with the text. Properties of AVSpeechUtterance class: 1. rate : Rate at which the utterance will be spoken. Type : Float Range from AVSpeechUtteranceMinimumSpeechRate and AVSpeechUtteranceMaximumSpeechRate. Lower value for slow speech and higher value for vice versa. 2. pitchMultiplier : The Pitch at which the utterance will be spoken. Type : Float Default value – 1.0 Allowed values – 0.5 (lower pitch) to 2.0 (higher pitch). 3. volume : Volume to be used when speaking. Type : Float Default value – 1.0 Allowed values – 0.0(silent) to 1.0(loudest) 4. speechString : Text to be spoken in the utterance. Type : String Note : Utterance text cannot be changed once it is created. To Speak different, create a new utterance. 5. voice : The voice used to speak the utterance Type : AVSpeechSynthesisVoice class Default value is nil speaks in default voice 6. preUtteranceDelay : The amount of time a speech synthesiser will wait before actually speaking the text. Type : NSTimeInterval 7. postUtteranceDelay : The amount of time a speech synthesiser will wait after actually speaking the text. Type : NSTimeInterval Properties of AVSpeechSynthesizer class : 1. speaking : A Boolean value that indicates whether the synthesiser is speaking which is readonly. 2. paused : A Boolean value that indicates whether speech has been paused which is readonly. Methods of AVSpeechSynthesizer class : 1. func speakUtterance(utterance: AVSpeechUtterance) : Enqueues i.e add an utterance to be spoken to the queue. Calling this method adds the utterance to a queue. Utterances are spoken in the order in which they are added to the queue Note : Attempting to enqueue AVSpeechUtterance multiple times throws an exception 2. func stopSpeakingAtBoundary(boundary: AVSpeechBoundary) -> Bool Stops all speech at the specified boundary constraint Boundary values can be Immediate or word Immediate – Indicates that speech should pause or stop immediately word – Indicates that speech should pause or stop after word currently being spoken Returns true if speech has stopped or false otherwise 3. func pauseSpeakingAtBoundary(boundary: AVSpeechBoundary) -> Bool : Pauses all speech at the specified boundary constraint Returns true if speech has paused or false otherwise 4. func continueSpeaking() -> Bool : Continues speech from the point at which it left off Returns true if speech has continued or false otherwise Delegate methods of AVSpeechSynthesizer class : All the delegate methods of AVSpeechSynthesizer class are optional. 1. func speechSynthesizer(synthesizer: AVSpeechSynthesizer, didStartSpeechUtterance utterance: AVSpeechUtterance) : This tells the delegate when the synthesizer has began speaking an utterance 2. func speechSynthesizer(synthesizer: AVSpeechSynthesizer, didFinishSpeechUtterance utterance: AVSpeechUtterance) : This tells the delegate when the synthesizer has finished speaking an utterance. 3. func speechSynthesizer(synthesizer: AVSpeechSynthesizer, didPauseSpeechUtterance utterance: AVSpeechUtterance) : This tells the delegate when the synthesizer has paused while speaking an utterance. 4. func speechSynthesizer(synthesizer: AVSpeechSynthesizer, didContinueSpeechUtterance utterance: AVSpeechUtterance) : This tells the delegate when the synthesizer has resumed speaking an utterance after being paused. 5. fun speechSynthesizer(synthesizer: AVSpeechSynthesizer, didCancelSpeechUtterance utterance: AVSpeechUtterance) : This tells the delegate when the synthesizer has canceled speaking an utterance. 6. func speechSynthesizer(synthesizer: AVSpeechSynthesizer, willSpeakRangeOfSpeechString characterRange: NSRange, utterance: AVSpeechUtterance) : This tells the delegate when the synthesizer is about to speak a portion of an utterance’s text. Sample Code : let synthesizer = AVSpeechSynthesizer() var speechUtterance = AVSpeechUtterance(string: “”) speechUtterance = AVSpeechUtterance( “Your String” ) speechUtterance.rate = 0.3 speechUtterance.pitchMultiplier = 0.25 speechUtterance.volume = 0.75 speechUtterance.postUtteranceDelay = 0.001 speechUtterance.voice = AVSpeechSynthesisVoice(language: “en-GB”) synthesizer.speakUtterance(speechUtterance) Supported languages for the voice: As of iOS 8.1, [AVSpeechSynthesisVoice speechVoices] the following languages and locales are supported: Arabic (Saudi Arabia) – ar-SA Chinese (China) – zh-CN Chinese (Hong Kong SAR China) – zh-HK Chinese (Taiwan) – zh-TW Czech (Czech Republic) – cs-CZ Danish (Denmark) – da-DK Dutch (Belgium) – nl-BE Dutch (Netherlands) – nl-NL English (Australia) – en-AU English (Ireland) – en-IE English (South Africa) – en-ZA English (United Kingdom) – en-GB English (United States) – en-US Finnish (Finland) – fi-FI French (Canada) – fr-CA French (France) – fr-FR German (Germany) – de-DE Greek (Greece) – el-GR Hindi (India) – hi-IN Hungarian (Hungary) – hu-HU Indonesian (Indonesia) – id-ID Italian (Italy) – it-IT Japanese (Japan) – ja-JP Korean (South Korea) – ko-KR Norwegian (Norway) – no-NO Polish (Poland) – pl-PL Portuguese (Brazil) – pt-BR Portuguese (Portugal) – pt-PT Romanian (Romania) – ro-RO Russian (Russia) – ru-RU Slovak (Slovakia) – sk-SK Spanish (Mexico) – es-MX Spanish (Spain) – es-ES Swedish (Sweden) – sv-SE Thai (Thailand) – th-TH Turkish (Turkey) – tr-TR Thus Text to Speech feature is made easier with AVSpeechSynthesizer class. This TTS feature can do even more to help blind or disabled users to make the text messages to speak. You can test this feature in simulator itself which adds to its advantage. It only takes five to six lines of code to add speech to your app!. Bhavani, iOS Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-01-21"},
{"website": "Mallow-Tech", "title": "FetchRequest Template", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/01/fetchrequest-template/", "abstract": "I had been using core data fetch request for a long time and while browsing about the fetch request, I came across a feature called Fetch Request Template. This blog describes about the  FetchRequestTemplate in detail. What is Fetch Request Template : Fetch request templates allow to pre-define queries and their parameters in the model (with the tool) – typically they contain variables that need to be substituted at runtime. How It Works : Let have a model with the entity student and attributed listed below : Step 1 : Create the Template Approach 1: NSManagedObjectModel *model = // reference to model NSFetchRequest *requestTemplate = [NSFetchRequest new]; NSEntityDescription *entityDescription = [[model entitiesByName] objectForKey:@“Student”]; [requestTemplate setEntity:entityDescription]; NSPredicate *predicateTemplate = [NSPredicate predicateWithFormat: @”(name like[cd] $NAME) AND  (age > $AGE)”]; [requestTemplate setPredicate:predicateTemplate]; [model setFetchRequestTemplate:requestTemplate forName:@“StudentWithNameWithAge”]; Approach 2: Go to your model (xcdatamodel) file, then Editor -> Add Fetch Request . The UI makes it easy to write a complex fetch request. Unlike the previous approach, you cannot store things like sort descriptors. You’d have to add those after you retrieve the template. Step 2 : Access the Template NSManagedObjectContext *moc = // reference to context NSManagedObjectModel *model = // reference to model NSError *error = nil; NSDictionary *substitutionDictionary = [NSDictionary dictionaryWithObjectsAndKeys: myName, @“NAME”,  age, @“AGE”, nil]; NSFetchRequest *fetchRequest = [model fetchRequestFromTemplateWithName:@“ StudentWithNameWithAge ”  substitutionVariables:substitutionDictionary]; NSArray *results = [moc executeFetchRequest:fetchRequest error:&error]; // Process results Points to Consider : 1If the template contains a predicate with substitution variables, you should instead use fetchRequestFromTemplateWithName:substitutionVariables: to create a new fetch request. 2If you use fetchRequestFromTemplateWithName:substitutionVariables: . The variables dictionary must provide values for all the variables. If you want to test for a nil value, use [NSNull null].  This method provides the usual way to bind an “abstractly” defined fetch request template to a concrete fetch. 3If you use setFetchRequestTemplate:forName :. This method raises an exception if the receiver has been used by an object graph manager. Happy Coding…. Arasuvel, iOS Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-01-07"},
{"website": "Mallow-Tech", "title": "UI Documentation Controller", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/01/ui-documentation-controller/", "abstract": "In this blog we are going to see how to open/preview a document stored in iOS device. In iOS we have a class called UIDocumentInteractionController which helps in achieving the above need of ours i.e., It helps us to preview document which are stored locally in the iOS device memory. UIDocumentInteractionController provides an user interface for previewing a document or can open it in other apps that supports the file type and also it provides few other options like opening, copying, printing, sharing and so on for interacting with a specified file. The file which we mention here may be of any kind such as pdf, image, videos, zip file, etc. Using UIDocumentInteractionController we can mainly perform the following actions A. Preview a document B. Present a view which lists other applications which are all supports to open the specified file type and it also lists some of the actions like copying, printing, mailing, etc,… which acts upon the specified file. The following screenshots shows us the difference between the above two methods. In this blogs let see how to preview a document, but before that lets see few basic details regarding UIDocumentInteractionController: Availability : From iOS 3.2 and later Subclass of : NSObject Delegate : UIDocumentInteractionControllerDelegate A.) 3 simple steps to use UIDocumentInteractionController to preview your file right away: Step – 1. The first step is to create a instance of the class by passing the file URL as shown below, // Initialising UIDocumentInteractionController with fileURL let documentController: UIDocumentInteractionController = UIDocumentInteractionController(URL: fileURL) where the fileURL is the path(URL) of the file which you would like to open. Eg., let documentsURLPath = NSFileManager.defaultManager().URLsForDirectory(.DocumentDirectory, inDomains: .UserDomainMask).first! as NSURL let fileURLPath = documentsURLPath.URLByAppendingPathComponent(“YourFileName”) – The above URL path denotes the path of the document named “YourFileName” present inside the document directory of your app memory. Step – 2. Next step is to set the delegate property for the class and implement its required methods, – Add the delegate “UIDocumentInteractionControllerDelegate” to the viewController where UIDocumentInteractionController is being used, then configure the delegate property as follows. // Configure UIDocumentInteractionController self.documentController.delegate = self – After setting the delegate property we should set some of the following delegate methods to preview the document i.) In which one of the delegate method is “ documentInteractionControllerViewControllerForPreview” method, It tells the UIDocumentInteractionController class where to open the document, it returns a viewController, as of now we will use the same viewController as the resulting viewController by returning self. func documentInteractionControllerViewControllerForPreview(controller: UIDocumentInteractionController) -> UIViewController { return self } ii.) One another method is “presentPreviewAnimated” delegate method which specifis wether to allow or not to preview document. Returning “true” will enable preview mode. func presentPreviewAnimated(animated: Bool) -> Bool { return true } Step – 3. Now use the “presentPreviewAnimated” method of the class UIDocumentInteractionController to preview the file specified in the URL. // Preview the specified file self.documentController.presentPreviewAnimated(true) When the above 3 line of code is executed a full-screen view will be presented by displaying the contents of the file that is presented in the given file URL. B.) The second method can be implemented by the following methods, • presentOptionsMenuFromRect(_:inView:animated:) • presentOptionsMenuFromBarButtonItem(_:animated:) • presentOpenInMenuFromRect(_:inView:animated:) • presentOpenInMenuFromBarButtonItem(_:animated:) We can use any of the above listed methods and present the user with various options like opening, copying, printing, mailing, etc., You can notice that there is a difference in the above mentioned methods namely, – OptionsMenu and – OpenInMenu Where, OptionsMenu : This will list all the apps which are capable of opening the specified file and also this will list possible options like copying, printing, etc., OpenInMenu : But in this type this will list only the apps that are capable of opening the specified file type. Note: If you just want to list the apps that are supported to open the specified file then go with the “OpenInMenu” option instead. You can also notice that there are two ways in which the current method can be added, namely – MenuFromRect and – MenuFromBarButtonItem Where, MenuFromRect : Specifies a rect area from which the options menu will be presented. MenuFromBarButtonItem : The options menu will be presented from the specified bar button item. We can do lots more using UIDocumentInteractionController like making your application to support for opening specific kinds of files and list your application on the options menu whenever your application supporting file is opened anywhere in the device. To instead present a menu that contains only a list of apps capable of opening the current document, the presentOpenInMenuFromRect:inView:animated: method instead. Until Next Time…… Bharath, iOS Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-01-07"},
{"website": "Mallow-Tech", "title": "How to Make the Resources Theme Dependent", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/01/making-resources-theme-dependent/", "abstract": "Hello Readers, In this blog post, we will be seeing in detail about how to change the themes dynamically in Android platform. Theme dependent Resources are used by the system at runtime based on the current theme of the application. A theme can be set to each activity in the app dynamically using the code below: activity.setTheme(R.style.Theme_LargeText); The resources can be generated by following the below steps: 1. Create an attrs.xml file which contains the references to the theme dependent resources. 2. Suppose that we have two themes, for example, black and white. Consider that avatar.png is the drawable resource we are going to use in the specified themes. 3. First, create two drawables and name them like avatar_black.png and avatar_white.png. 4. Create reference for the drawables in the attrs.xml as <resources> <attr name=“ avatar ” format =“reference”/> </resources> 5. Create styles for the above said two themes in styles.xml and declare the drawable to be used based on the theme as Black theme: <resources> <style name = “ThemeBlack”> <item name = “ avatar ”>@drawable/avatar_black</item> </style> </resources> White theme: <resources> <style name = “ThemeWhite”> <item name = “ avatar ”>@drawable/avatar_white</item> </style> </resources> 6. Then use the reference for the drawables in the views as: <ImageView android:id=”@+id/imageview_theme” android:layout_width=”wrap_content” android:layout_height=”wrap_content” android:src =“?attr/ avatar ” /> The bolded “avatar” is the reference for the theme dependent resources which is referred at runtime based on the theme. Likewise, theme dependent color resources can be generated. The steps are same for drawables except that the format should be given as “color” or “color|reference” <resources> <attr name=“ currentColor ” format=”color” /> </resources> If the format as given as “color” then the color resources can be used as follows Black theme: <resources> <style name = “ThemeBlack”> <item name = “ currentColor ”> #000000</item> </style> </resources> White theme: <resources> <style name = “ThemeWhite”> <item name = “ currentColor ”> #FFFFFF</item> </style> </resources> If the format as given as “color|reference” then the color resources can be used as follows Declare color values in the colors.xml file as <resources> <attr name=” currentColor ” format=”color|reference” /> </resources> Declare color values in the colors.xml file as <resources> <color name=“black”>#000000</color> <color name=“white”>#FFFFFF</color> </resources> Black theme: <resources> <style name = “ThemeBlack”> <item name = “ currentColor ”> @color/black</item> </style> </resources> White theme: <resources> <style name = “ThemeWhite”> <item name = “ currentColor ”>@color/white</item> </style> </resources> Note: In the above both cases, refer the color resources in the views as android:background=”? currentColor ” We will be back with some more exciting features in the future posts. What features do you think is exciting and want us to explore? Mention in the comments section. – Android Team , Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-01-07"},
{"website": "Mallow-Tech", "title": "How to write Test Cases for applications effectively", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2017/07/writing-effective-test-cases/", "abstract": "A test case is a set of conditions defined by the tester to determine whether the system performs or not under the given condition. The test case is written so that to check the working of an application under different constrained environment. This ensures that each and every feature is of the application is working In today’s blog, we will see in detail on how to write the test case effectively. Below are the 11 factors that have to be considered for writing a test case effectively. 1. Naming the test case Naming the test case plays a major role in making it perfect and easy to access. It is always a good practice to name the test cases in a way that it makes sense to anyone who is going to refer the test cases in future. A best practice is naming the Test Cases to represent the module name or functional area we are going to verify in that test case. This can be explained with an example. Consider a project called “Online” which has a functional area named “Login” Now, we want to write a test case to verify a simple check whether the user is able to login to the website using an email and password. To keep things simple, instead of naming the tests as TC_01, we could use the below-naming convention for our test case so that it gives a brief idea of what the test is for just by looking at its name. TC_01_Online_Login_Success or, TC_01_Online_Valid_Case and likewise… Quick Note: As a best practice, name the Test Cases to represent the module name or functional area you are going to verify in that test case. This will really help the peers or new testers. 2. Test Case Description The description of the test case is where we mention all the details about what we are going to test, and the particular behaviour being verified by the test. What needs to be verified, which test environment it needs to be verified in, which test data is to be used – all this information goes into the description. We should enter as much information as possible in the Test Case description! Mainly, we would find the below information in a well-written test case description: • Test to be carried out / behaviour being verified • Preconditions and Assumptions (any dependencies) • Test Data to be used • Test Environment Details (if applicable) • Any Testing tools to be used for the test 3. Assumptions and Preconditions While writing test cases, we should communicate all assumptions that apply to a test, along with any preconditions that must be met before the test can be executed. Below are the kind of details we would like to cover as part of this section: • Any user data dependency (e.g. the user should be logged in, which page should the user start the journey, etc.) • Dependencies on test environment • Any special setup to be done before Test Execution • Dependencies on any other test cases – does the Test Case need to be run before/after some other Test Case? We should add as much information as possible for any conditions to be met before running the test case. Quick Note:  Include as much information as possible for any conditions to be met before executing the test case. 4. Test Data Input Identifying test data can be really a time-consuming activity – many times test data preparation takes most of the time in a testing cycle. It may sometimes need we create a test data afresh as creating a new data might take lesser time compared to identifying it Also, we can give Test Data to be used for the Test Case within the test case description or with the specific Test Case step. This saves a lot of time in the long run as we won’t have to hunt a new test data every time we need to execute the test. If the test only involves some values to be verified, we can opt to specify the value range or describe what values are to be tested for which field. We can do the same for negative scenarios as well. Testing with every value is impractical so we can choose a few values from each equivalence class which should give good coverage for the test. We could also decide to mention the type of data which is required to run the test and not the real test data value. This applies to projects where the test data keeps on changing as multiple teams use it and may not be in the same state when we use it the next time. 5. Cover all Verification Points in Test Design Steps Another important part of a well-written test case is the properly defined Test Case Steps covering all the verification points for the behaviour under test. The Test Design Steps should not only cover the functional flow but also each verification point which must be tested! By comparing the Test Case steps with the artefacts (Requirement Documents, Use Cases, User Stories or Process Maps) given for the project, we can make sure that the Test Case optimally covers all the verification points. 6. Expected Result A well-written Test Case clearly mentions the expected result of the application or system under test. Each test design step should clearly mention what we expect as the outcome of that verification step. So, while writing test cases, mention in detail about the page/screen we expect to appear after the test and, any changes we expect to be done to any backend legacy systems or Database. We can also attach screenshots or specification documents to the relevant step and mention that the system should work as outlined in the given document to make things simpler. 7. Divide Special Functional Test Cases into Sets For effective test case writing, we should consider breaking down the Test Cases into sets and subsets to test some special scenarios like browser specific behaviours, cookie verification, usability testing, Web Service testing and checking error conditions etc. For instance, Test Cases that check error conditions should be written separately from the functional test cases and should have steps to verify the error messages. While writing these scenarios into sets, a particular feature has a lot of input combinations, we can separate the test into sub-tests. For example, if we need to verify how the login feature for any application works with invalid input, we can break this negative testing for login functionality into subtests for different values like: Verify with invalid email id,  Verify with invalid password , Verify with blank email id field and so on. 8. Legible & Easily Understandable While designing Test Cases we should always consider that these Test Cases will not always be executed by the one who designs it.So, the tests should be easily understandable, legible and to-the-point. 9. Review With Test Cases playing an important role in Software Testing Lifecycle, making sure they are correct and conform to standards becomes even more necessary – that is where the Test Case review process comes into the picture. Test Case Review can be done by peer testers (termed ‘Peer Review’), BA, developers, product owners or any relevant stakeholders.However, we do need to take care of a few prerequisites for the review process to start because of which the review process could be harmful as well! 10. Reusability We should write test cases keeping in mind that they could be re-used in the future for some other project/teams. Existing test cases which were written earlier around the same module can be updated instead of writing new test cases so that for any journey we always have the updated test cases in place. This might not apply if we are a new project, however, we can try to write test cases in a way that they could be re-used for some other future project. Also, if we need a particular test case to execute some other test case, we can simply call the existing test case in the preconditions or at the specific test design step. 11. Post Conditions Post-conditions basically specify the various things that need to be verified after the Test has been carried out. In addition, post-conditions are also used to give guiding instruction to restore the system to its original state for it not to interfere with later testing. For example, this is quite useful if we mention the changes to be made to a test data for it to be used for a later Test Case for the same functionality. These are the 11 factors that have to be considered to write a test case effectively. It is important to perfect a test case so that it gives the necessary results. Blog reference: Amandeep’s Quickway of testing blog. Testing Team , Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2017-07-04"},
{"website": "Mallow-Tech", "title": "The Features of AWS in a Nutshell", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/01/the-features-of-aws-in-a-nutshell/", "abstract": "Even though the user % of Cloud Computing service has increased still the awareness of Cloud Computing Service and the fear of billing for a small startup company still exists. To give a clear picture on this we have made this blog. Advantages of Cloud Computing The Main Advantage of using Cloud Computing is Cost Saving, Reliability, Scalability & Manageability Cloud Computing Service Providers Now a days there are many cloud computing services you can just google to get the complete list of providers, almost all of them give at the same nearby rate but there is a lot of difference in the technological service they provide. Many statistical reports and depending on the customer satisfaction AWS seams to have a lead. AWS Account Creation Step1 : Sign up for an AWS account. Step2 : You need to Enter your billing address and credit card information. That’s it you now use the AWS free for 12 months with some limited access and you will not be charged until you exceed the free usage limit. Features of AWS We will discuss some of the features of AWS and how we can use effectively and do cost cutting in bills. Amazon S3 Amazon Simple Storage Service (Amazon S3) as the name we can use to sore data and retrieve data. more frequently stored and accessed data can be in this. In free usage we get 5 GB of Storage, 20,000 Get Requests and 2,000 Put request. It is highly scalable for n for websites with only static content, including HTML files, images, videos, and client-side scripts such as JavaScript. Each object in Amazon S3 has a unique HTTP URL address. Ideal Usage For static website content Cost reduction tips. you pay for what you use no minimum fee. It has 3 pricing components Storage per GB per Month Data Transfer per GB per Month Requests per n thousand request per month. As the cost is based on the above points don’t use this to sore Idle data such as backups of your database. You can use data Lifecycle to move data from S3 to Glacier. Amazon Glacier It is an extremely low-cost with Amazon Glacier, we can store data for as little as $0.01 per gigabyte per month. Ideal Usage It is used to store data that is not frequently used and may be a long time old data backups. Cost reduction tips. It also has the same pay for what you use no minimum fee. It has 3 pricing components Storage per GB per month. Data transfer out (per GB per month), Requests (per thousand UPLOAD and RETRIEVAL requests per month). So it is very clear that we should not use this for frequently access content. You can retrieve up to 5% of your average monthly storage (pro-rated daily) for free each month. Amazon EC2 Amazon Elastic Compute Cloud (Amazon EC2) is a virtual Server Hosting In free usage you get 750 hours per month free for 1 instance. It is used to run dynamic websites using PHP, Rails etc. It can increase or decrease capacity within minutes. Cost reduction tips . Pricing of this depends on the No of instance running pre hour per month. The configuration of the instance. So if we find any complete Ideal time You can stop the instance from running by using scheduling Amazon Data Pipeline for starting and stoping the instance on time line. Choosing the Configuration of the instance also plays a major role on cost saving. Due to time constrain we have discussed about only two features we will continue this in our next blog. Until then try to a signup and use a free account to explore the real power. Vijayanand, PHP Team Lead, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-01-07"},
{"website": "Mallow-Tech", "title": "How to use datatables in AngularJS application?", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2015/12/how-to-use-data-tables-in-angularjs-application/", "abstract": "What is datatable? DataTables is a plug-in for the jQuery Javascript library. It is a highly flexible tool, based upon the foundations of progressive enhancement, and will add advanced interaction controls to any HTML table. (Source : https://www.datatables.net/ ) Why do we need to use datatables in AngularJS application? In the modern web applications, most of us are likely to develop single page application, to do so most of us use AngularJS. Usually, table manipulation in AngularJS is easier than in normal JQuery. But still, search, server side pagination are not straight forward in AngularJS. Hence we can use datatable in AngularJS too. Part 1: Use static data to display the table – datatables in AngularJS Application. In this tutorial, we are going to see how to use the static data to display the records in datatables. Needed JS & CSS files in order jquery.dataTables.min.css jquery-2.1.4.min.js jquery-ui.min.js jquery.dataTables.min.js angular.js angular-route.js angular-ui-util/ui-utils.min.js You can use whatever method that suits to you to include the above files (like Bower, Copy the source in your project, CDN files). Step 1 (HTML file): Type the below line in your html file. Please note that in this file you can see ui-jq=“datatable” which tells AngularJS that this is the data table and ‘ui-options’ tells AngularJS to use the settings from scope variable named options. <table id=”example” class=”display” width=”100%” ui-jq=”datatable” ui-options=”options”> Step 2 (Controller): a. In your Angular app, you need to inject ‘ui.utils’ as follows. angular.module(‘myApp.datatable’, [‘ngRoute’,’ui.utils’]) b. After that declare a local variable called dataSet, which is used as row data in data tables, in which I have just placed some static values of a person like name, position, office, extend, start date, salary as an array. You can use object based dataSets also like JSON, in this case you need to define data variable in column definition (like columns : [{title: “Name”, “data”, “name”}]) var dataSet = [ [ “Tiger Nixon”, “System Architect”, “Edinburgh”, “5421”, “2011/04/25”, “$320,800” ], [ “Garrett Winters”, “Accountant”, “Tokyo”, “8422”, “2011/07/25”, “$170,750” ] ]; c. Then define scope variable named options which will be used as settings for the data tables. In this, we are just declaring data as dataSet and columns by title. >$scope.options = { data: dataSet, columns: [ { title: “Name” }, { title: “Position” }, { title: “Office” }, { title: “Extn.” }, { title: “Start date” }, { title: “Salary” } ] }; }]); Download sample project: https://github.com/JPMallow/datatables-in-angular To run this project, you need to install bower components, after downloading run the bower command to install it in your root directory. (If you have not installed bower already, please look here http://bower.io/ ) In the next part, I will explain how to use AJAX call in datatables to input the data. Syntax and Sample data credits: https://www.datatables.net/ I hope you have found this blog useful. I would appreciate if you share the word to others! Jayaprakash, Technical Lead, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2015-12-18"},
{"website": "Mallow-Tech", "title": "Ruby 2.3.0 – Review", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2016/01/ruby-2-3-0-review/", "abstract": "Good to see you again… We have seen the features implemented in Rails 5, in the earlier blog. Now its time to go with Ruby 2.3.0 This is the first stable release of Ruby 2.3 series and it has come up with many new features. We are going to see some of them in this post. # Install using RVM rvm install 2.3.0 # Install using Rbenv rbenv install 2.3.0 Frozen String Literal Pragma: With Ruby 2.1, “str”.freeze has been optimized to reduce object allocation. Ruby 2.3 introduces a new magic comment and command line option to freeze all string literals in the source files. Using frozen (immutable) strings gives us improved performance because Ruby now has to allocate fewer objects. To make the transition easier, Ruby 2.3 allows you to optionally make all strings literals frozen by default. Fresh arrivals: new pragma, frozen-string-literal has been experimentally introduced. –enable/–disable=frozen-string-literal options also have been introduced. command line options –debug or –debug=frozen-string-literal enable additional debugging mode which shows created location with at frozen object error (RuntimeError). Safe Navigation Operator: “ &.” , which already exists in C#, Groovy, and Swift, is introduced to ease nil handling as “ obj&.foo ”. It can be very useful in cases where you need to check if an object is nil before calling a method on it. It will return nil if the object equals nil, otherwise it calls the method on the object. did_you_mean: When a NameError or NoMethodError occurs because of a typo in the name, the did_you_mean gem automatically suggests other names similar to the method name. Making error messages more helpful has a huge impact on making the language easier to use, especially for beginners. “Array#dig” and “Hash#dig”: The new #dig instance methods provide concise syntax for accessing deeply nested data. We can now access nested elements in arrays and hashes with a much simpler API. Dig in action with Array Dig in action with Hash Hash Comparison: Hashes now have the comparison methods defined on them. It provides “Hash#<=“, “Hash#<“, “Hash#>=“, and “Hash#>” operators to perform superset and subset operations. Hash#to_proc: “Hash#to_proc” returns a lambda that maps the key with the value. When you call the lambda with a key, it returns the corresponding value from the hash. Enumerable#grep_v: This method is inverse of the method “Enumerable#grep”. The grep_v method is equivalent to the -v option in the command line grep utility. It returns the list of items that do not match the condition. Numeric#positive? and Numeric#negative?: These functions have been around in Rails core extensions for a while, and now have been included in Ruby. Numeric values now have predicate methods that check if the subject is positive or negative. Until next time….. Surender, ROR Developer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2016-01-07"},
{"website": "Mallow-Tech", "title": "Agile Model Vs Waterfall Model", "author": ["Mallow"], "link": "http://blog.mallow-tech.com/2015/12/agile-model-vs-waterfall-model/", "abstract": "What is Agile? AGILE is a methodology that promotes continuous iteration of development and testing throughout the software development life cycle of the project. Both development and testing activities are concurrent unlike the Waterfall model Agile versus Waterfall Method: Agile and Waterfall model are two different methods for software development process. Though they are different in their approach, both methods are useful at times, depending on the requirement and the type of the project. Agile Model Waterfall Model 1. Agile method proposes incremental and iterative approach to software design 1. Development of the software flows sequentially from start point to end point. 2. The agile process is broken into individual models that designers work on 2. The design process is not broken into an individual models 3. The customer has early and frequent opportunities to look at the product and make decision and changes to the project 3. The customer can only see the product at the end of the project 4. Agile model is considered unstructured compared to the waterfall model 4. Waterfall model are more secure because they are so plan oriented 5. Small projects can be implemented very quickly. For large projects, it is difficult to estimate the development time. 5. All sorts of project can be estimated and completed . 6. Error can be fixed in the middle of the project. 6. Only at the end, the whole product is tested. If the requirement error is found or any changes have to be made, the project has to start from the beginning 7. Development process is iterative, and the project is executed in short (2-4) weeks iterations. Planning is very less. 7. The development process is phased, and the phase is much bigger than iteration. Every phase ends with the detailed description of the next phase. 8. Documentation attends less priority than software development 8. Documentation is a top priority and can even use for training staff and upgrade the software with another team. 9. Every iteration has its own testing phase. It allows implementing regression testing every time new functions or logic are released. 9. Only after the development phase, the testing phase is executed because separate parts are not fully functional. 10. In agile testing when an iteration end, shippable features of the product is delivered to the customer. New features are usable right after shipment. It is useful when you have good contact with customers. 10. All features developed are delivered at once after the long implementation phase. 11. Testers and developers work together 11. Testers work separately from developers 12. At the end of every sprint, user acceptance is performed 12. User acceptance is performed at the end of the project. 13. It requires close communication with developers and together analyse requirements and planning 13. Developer does not involve in requirement and planning process. Usually, time delays between tests and coding Agile Methodologies types: • Scrum • Crystal Methodologies • Dynamic Software Development Method [ DSDM ] • Feature driven dvelopment • Lean Software development • Extreme Programming (XP) Keep visiting to us, Happy Learning! Periannan, Test Engineer, Mallow Technologies. Share this: Click to share on Twitter (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Google+ (Opens in new window) Like this: Like Loading... Related", "date": "2015-12-18"}
]