[
{"website": "NewYork-Times", "title": "talking technology aaron dignan and spencer pitman", "author": ["Nick Rockwell"], "link": "https://open.nytimes.com/talking-technology-aaron-dignan-and-spencer-pitman-1bc26be64b07", "abstract": "Code Data Product and Design Workplace Culture Work with Us For this installment of Talking Technology, I interviewed The Ready founder Aaron Dignan and early employee, Spencer Pitman. Tell us a bit about yourselves and The Ready. What are you guys up to, and why? Aaron: I’ve spent my career looking for the most interesting problem, whatever that might be. That led to years exploring disruptive and exponential technology. But after a decade of that work, I realized that the technology wasn’t the problem, it was our ability to metabolize change. Despite the best of intentions, nearly every organization becomes a stifling bureaucracy over time. I became obsessed with organizational adaptivity — how to create organizations that learn and get better every day. Three years ago, I started The Ready to accelerate the adoption of new ways of working that unlock that potential. Spencer: Like so many others, I came to The Ready through a circuitous path that included software, hardware and a continued focus on how my workplace can be transformed into a place I actually want to be. That’s where we play. We partner with some of the most impactful organizations on the planet to figure out how to reinvent their organizational ‘operating systems.’ We help them clear up the organizational (and sometimes technical) debt, and replace it with systems that are responsive to change and desirable to the people making it all happen. There’s so much energy and attention going into the idea of “the new work.” It’s very attractive and taps into the deep frustration I think most of us who work in any kind of organization feel. Do you think anything is actually changing? Is change possible? Aaron: Self-management, agile, and lean work styles have existed on the fringe for decades. The difference now is that globalization, digital technology and increased expectations are forcing every organization to ask how they can learn and adapt faster while creating a workplace that is more (not less) human. We’re still in the very early days of this evolution, fewer than one in a hundred organizations is really challenging the old model, but it is happening if you know where to look. Not to mention some of the structural innovation that are taking place: certified B corporations, benefit corporations and the Long-Term Stock Exchange are all signs of progress. If you could sum up your core ideas or principles, how would you do it? Organization design can be pretty wonky, can you make it simple for us? What are the key ideas? Aaron: The first and most important idea is that we inherited our way of working from a factory floor over 100 years ago, and we can change it. We engage teams in a simple process. We ask them, “What’s stopping you from doing the best work of your life?” and then we help them design experiments to remove what stands in the way or add what is missing. Along the way, we share some of the principles that represent the future of work. Principles like: Purpose over Profit, Freedom over Control, Open over Closed, Progress over Perfection and Consent over Consensus. Extreme ideas like Holacracy, where teams self-organize instead of following traditional management hierarchy, attract a lot of attention. Do you think that can tarnish more moderate attempts to change how we work? Spencer: It’s funny to think of Holacracy as “extreme” in the context of work, but of democracy as imminent when we think about government. Holacracy may feel extreme simply because it’s a pretty big departure from the command-and-control defaults that have become normal for a lot of us, but the truth is that the context has changed substantially. Corporate life expectancy is shorter than ever, employee engagement is lower than ever, and most companies are so complex they spend half their year on their annual operating plan. We don’t necessarily advocate for Holacracy at The Ready, but we use and recommend several of its practices. What matters is that teams take ownership over their way of working, regardless of where they draw their inspiration. When the press paints new ways of working in a controversial light, it certainly generates more clicks, but it’s not helping the broader movement. Luckily, the frustration with the status quo is so high that people are more open to the extreme than we expect. I have been thinking lately that the explicit effects of power remain pretty unexplored at many companies. In fact, we’ve taken a step back in some ways. Where power dynamics were clearly drawn on the org chart in the past, now it’s often more hidden. Do you see this happening? What are the effects? Aaron: This all stems from our narrow view of power — as a scarce resource and zero sum game. In that view, hierarchical power is only attainable by moving up in the world. But power doesn’t have to work that way. It can be shared. It can be multiplied. Regardless, it doesn’t evaporate when we decide to erase the org chart. Every organization has a formal power structure and an informal one. When we set aside positional power, reputational power becomes more pronounced. Unfortunately, if we don’t change how we think about freedom and control, power will always be used in dysfunctional ways. Similarly, I think explicit discussion about ego — the ego of the leader or manager — is rare. The new leader is supposed to be a leader-servant, and should leave our egos at the door. I think this is harder than it sounds, especially as most of us have been successful by leveraging our egos, our own ideas and experience and our confidence. This is also still the paradigm of the “strong” leader. Do modern leaders really have to change so radically? Aaron: Yes. And while we all need to master our ego and increase our self-awareness, our first step is really to redefine our role. We’re no longer here to ensure perfect execution (which isn’t possible in complexity anyway). We’re here to ensure continuous growing capacity . That means getting out of the way and letting our teams and colleagues try, fail (or succeed!) and learn. Our teams don’t need us to be the hero, they need us to create the conditions for great work to happen autonomously. When we talk about changing how we work, there’s a lot of pressure to prove that it yields better results, whether we are talking about diversity, transparency or decentralization of control. Do you think it ever makes sense to change things even if we can’t prove it to be more effective, “just” because it makes us happier and reflects our values? Spencer: On some level, isn’t that also yielding a better result? Is shareholder value really the pinnacle of human achievement? The vast majority of people don’t believe that, but it’s how we’ve structured corporate incentives for a long time now. Interestingly, focusing on what can be measured hasn’t necessarily panned out. The costs of ignoring adaptivity, complexity, humanity and participation in work are not only clear, they’re grave. From Enron and MCI to Kodak; Equifax and Wells Fargo; To the massive data and privacy issues now being faced by most of the consumer technology industry, the consequence of treating companies like machines rather than like living systems is becoming clear. They say, “you can’t manage what you don’t measure,” but I think the more potent lesson is, “what gets measured is what gets made.” Measuring companies by short-term stock performance means that what gets made is short-term efficiency at the cost of longevity. Tech companies and especially software companies are the source of a lot of the new ideas about organization, leadership, how to work or at least we seem to be obsessed with the topic. Why do you think that is? Can these ideas work outside of software? Spencer: There is a collection of papers written in the 1920s by a woman named Mary Parker Follett that outline a tremendous amount of the work practices that people are calling “new” today. She was writing a decade before Hewlett-Packard was even founded so I think the notion that these ways of working are either new or are restricted to software organizations isn’t entirely accurate. The tech space is romanticized because its impacts are so tangible to people. You explain Moore’s “Law” to someone and they can immediately connect it with their own experience. The relatability of the impact coupled with the aspirational photos of incredible offices, or the volume of capital software companies generate, or the American Dream-like stories we tell about founders (whether they are true or not) probably drive all of that intrigue. But we have real living examples of these ways of working that are separate from the organizations born on the web. Svenska Handelsbanken in finance, Skunkworks in aerospace, Morning Star in food, Toyota in manufacturing, the list goes on. And the point isn’t that any of these places are perfect, or that they’re done improving themselves. It’s that they’re pressing on each day toward a more participatory, adaptive and abundant future. Aaron: And that’s really what it’s all about. A future where work works . Nick Rockwell is the CTO at The New York Times. Find him on Twitter and Medium . How we design and build digital products at The New York Times 218 Management Technology Leadership Conversations 218 claps 218 Written by SVP Engineering at Fastly, ex-CTO at NYT. Passionate about tech, music, science, art, helping others be their best. How we design and build digital products at The New York Times. Written by SVP Engineering at Fastly, ex-CTO at NYT. Passionate about tech, music, science, art, helping others be their best. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-07-17"},
{"website": "NewYork-Times", "title": "giving readers control announcing two new options in the new york times ios app", "author": ["Véronique Brossier"], "link": "https://open.nytimes.com/giving-readers-control-announcing-two-new-options-in-the-new-york-times-ios-app-4f48283e63b8", "abstract": "Code Data Product and Design Workplace Culture Work with Us I visited Cuba in November of 2016. While I was in Havana, Fidel Castro passed away. Footage of his life and favorable testimony played on a loop on the government television for days, but there was very little coverage of the reaction from the outside world. I was not able to retrieve fresh news using the New York Times native app because my hotel network logged me out every time I attempted to update content, seemingly because the amount of data was too taxing. The country has very limited infrastructure and the cost of internet access, at around $1.50 per hour, is very expensive for most Cubans who earn the average government salary of $30 a month, according to Reuters . My experience in Cuba inspired me to assess the feasibility of our app for the many people who only have a limited data plan and reduced access to broadband, not just on a small Caribbean island, but in the United States, and around the world. I am a senior software engineer on The New York Times iOS app. I am also an avid reader of news and a world traveler. I developed a low bandwidth mode during last year’s Maker Week, The Times’ annual week-long event where employees can experiment with new ideas, and I am very pleased that the feature has been incorporated into the iOS app as a valuable setting for our users. The app content is made up of almost 40 sections, each with an average of 25 articles and their zoomable high resolution images. On the web, data is only fetched when the user selects a section or an article. But on the mobiles apps, we download the content to the device when the user is online, so it is available when she is offline. This allows us to make news available without connectivity for readers on the move. Text is small with only a few bytes per file, but images can be big, at over a megabit per crop for the larger ones. Our Pulitzer-winning photography is a great enhancement to any story. However, removing the visual narrative in exchange for making the story available to the bandwidth-challenged reader can be a valuable compromise. Turning off the Download Images setting suppresses the retrieval of images and allows for a much quicker update. This also prevents the display of images at the section level (images are still displayed in articles) and offers a text-only experience. It gives a new modern meaning to The Grey Lady. This setting became available in version 6.7 of our app released in May 2018. Try it, here and on your next trip abroad. In 2017, my team and I rewrote the newsreader app from scratch using Apple’s new language, Swift. Working with our Product and Design colleagues, we gave it a new look and feel for a universal experience (the same app runs on the iPhone and the iPad using an adaptive layout). It was a tremendous effort. Some changes were made and one setting, Automatic Refresh, was removed. Many old users missed it and requested that we bring it back — I was one of them. I am very pleased to say that it is back in version 6.7 of the app. Why does it matter? Imagine reading a newspaper. Yes, a paper. I know; stay with me. You flip through the pages, see a few headlines of interest, then put the paper down knowing that you can come back to the articles at a later time. Using the native app, you can swipe between sections, browsing for compelling articles in the same way. However, when the content refreshes, these articles may be replaced by new ones. iOS, the Apple operating system running on your iPhone or iPad, offers the capability of a background app refresh, under good network and battery conditions, so that data is updated independently of user action. We use this technology to give you the freshest news. Turning off the Automatic Refresh setting disables the always-up-to-date feature of the app, giving you complete control over when the app fetches new data. The same articles you noticed the day before are still available when you are ready for them. Only when you execute Apple’s refresh gesture, by pulling and releasing the top of a section, will new data become available. You can read the news at your own pace. In a world where a news subscriber has many options, giving her control over when and how she reads information is a novel and potentially attractive approach. The text-only mode in particular may be of great benefit to any news organization interested to expand its audience to curious readers all over the world. How we design and build digital products at The New York Times 204 2 iOS Code Product Development iOS App Development Accessibility 204 claps 204 2 Written by How we design and build digital products at The New York Times. Written by How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-06-01"},
{"website": "NewYork-Times", "title": "introducing lock key", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/introducing-lock-key-37f20435cc0b", "abstract": "Code Data Product and Design Workplace Culture Work with Us Editor’s note: The post on Lock & Key was posted prematurely and has been removed. Here are some suggestions for keeping your login information safe: Use a password manager. There are many good ones out there, some are even free. See this Wirecutter piece for more information. Use two-factor authentication. If the site you’re logging in to supports the use of a second factor such as a security key or authenticator application, enabling it will make it more difficult for your account to be compromised because having only your password will no longer be enough to gain access. For more tips from our Information Security team, see this article from The Times’s Tech We’re Using section. How we design and build digital products at The New York Times 154 6 154 claps 154 6 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-01-31"},
{"website": "NewYork-Times", "title": "reimagining the new york times digital story experience", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/reimagining-the-new-york-times-digital-story-experience-ff698541ac09", "abstract": "Code Data Product and Design Workplace Culture Work with Us By FRANNIE HANNAN, JOSH HOELTZEL AND PETER RENTZ The New York Times publishes more than 150 articles a day to our iOS and Android apps, and our desktop and mobile websites. All of these platforms were originally developed by separate teams, so each had its own implementation and user experience. Though it may not have been obvious to the users of our products, we were maintaining a fragmented experience spanning multiple applications. Every time we built a new feature or even implemented something as simple as a stylistic change, we needed to build it separately in each place. That meant replicating work, coordinating roadmaps and releasing code across multiple teams — mobile web, desktop and in each of our native news apps, which required a full app release to roll out even the most minor changes. At the same time, editors producing articles saw a rendering that didn’t represent what the content would ultimately look like on our platforms. This did little to help them envision their work as users would see it. In short, we were blocked by inefficiencies from delivering the best product to our users. May 8, 2018, marks the culmination of a years-long project to create an article ecosystem that promotes internal efficiency and delivers an enhanced reading experience for our users. We now have a single responsive article for both mobile and desktop on the web, and we use a subset of the same code to render stories in our native apps, Google’s Accelerated Mobile Pages (AMP) and our content management system. Here are the biggest benefits of the work we’ve done: In order to create a consistent reading experience on all of our platforms that we could iterate on in tandem, we had to make major changes to how our native apps render articles. Prior to the “hybrid” project (i.e. a hybrid between native and web), each native app parsed article data and rendered the headlines, bylines, paragraphs and media natively to display the article. Now, articles are rendered on the server and delivered to the apps as an HTML string that the native apps display in a web view. This means that as we add new features or change the way we treat existing ones, we can do it with a single web application release without updating the apps in the store. Another efficiency of the new article system is the introduction of shared components. As we add elements to our article experience, we are building them in an abstract way outside the context of any specific application. This allows them to be shared across applications, pulled in anywhere that the component needs to be rendered in user-facing applications, as well as content creation tools like our CMS. As an example, consider our bylines: We recently made changes to include headshots and a short blurb about the author, so we built a shared component that would render the byline with these enhancements. We could then utilize that component in the hybrid article, the web article and the CMS, as well as any future application that might need it. Implementing this approach required a lot of planning, experimentation and coordination across teams. Engineers throughout the tech organization and in the newsroom worked together to make it happen. Today we are sharing more than 40 components across our web, native, CMS and off-platform apps. The desktop story page is where we made the most transformational user-facing changes. We’ve moved away from a model that is standard for many news organizations on the internet — an article template that has a right rail crowded with ads and other content that draws a reader’s attention away from what they came for: the story. With this new launch, articles are presented in a focused, single-column layout that intentionally strips away the clutter and puts our journalism front and center. We now have a clean slate on which to build elements that truly add value for readers. In conjunction with Oak — our new visual article editor — we will create and enhance story forms that take advantage of the space and flexibility on the new story page. The single-column story page was designed to create an integrated reader and advertising experience, built around our proprietary FlexFrame display units. We’ve removed the cluttered right rail of small, standard banner ads in favor of premium, full-bleed, in-stream units that are responsive to the page’s width. Ads on the new page are achieving twice the click-through rate of our old design, and initial studies show higher brand recall and four-times the reader attention to ads. “With the new Story page, we’ve successfully integrated our reader and advertising experiences with a pristine, user-focused design,” says Allison Murphy, vice president of ad innovation. “A more engaging page is better from every angle: it means more connection with our journalism, and more connection with the messages of our marketers.” This marathon effort to reimagine The Times article has given us the infrastructure to build features faster and better meet the needs of users and advertisers on all of our platforms. In January 2017, an innovation group within The Times released a report titled Journalism That Stands Apart . It lays out how the company must change in order to meet aggressive goals and thrive in the media landscape of the future. Key recommendations included a more visual report and more diverse forms of storytelling. We believe the new article page is a critical step toward allowing us to evolve how we tell digitally native stories that make The Times stand apart. Frannie Hannan is a senior product manager at The Times overseeing the story page. Josh Hoeltzel is the senior development manager for the story page. Peter Rentz is the design director for the story page. How we design and build digital products at The New York Times 1.2K 3 Design Code Product Management Product Design 1.2K claps 1.2K 3 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-05-14"},
{"website": "NewYork-Times", "title": "super tuesdays newsroom programmers gear up for the 2018 midterms", "author": ["Jeremy Bowers"], "link": "https://open.nytimes.com/super-tuesdays-newsroom-programmers-gear-up-for-the-2018-midterms-9de5b41211eb", "abstract": "Code Data Product and Design Workplace Culture Work with Us Election night is newsroom programmer super bowl. In a tiny conference room on the second floor of the New York Times headquarters, a crew of designers, developers and graphics editors huddle over laptops, with a television on the wall displaying a scrolling feed of terse messages logged by our software. We’re watching in real time to see how we’re performing. How many readers are on the page right now? How much faster do we have the latest update versus our competition? What does our model say is actually happening? Has anyone made a call yet? For most people watching our election results, the tension rises until it’s clear who won. For programmers working on election data, the moment of relief comes early, not with the final results but when the very first results show up on the site. Why do we do this? Why do newsroom programmers love elections so much? An election is a unique engineering challenge. We have to process hundreds of thousands of rows of data in a few seconds and then do it again less than five seconds later. The amount of data flowing through our elections stack can measure in the terabytes during an odd-year general election. And there are more people looking at those pages than at our homepage for several hours at a time. Worse, it’s not just the scale of the data or our readership. Every five seconds, we have to add votes for every candidate across thousands of races, calculate the percentage of precincts reporting, and standardize results to the county level even in places like Alaska, which has no counties. The most exhilarating part of an election night is the opportunity to give our readers what they want when they want it. Of course we could just publish the results the next morning. There’d be no rush and we would have the night to make sure the tallies were correct. But our readers want to follow along. They love the in-the-moment updates and we love to provide them. It’s no secret that our elections results pages are popular. What you might not know is that they are so popular, they show up in the ranks of our most popular stories . For many programmers working in newsrooms, an election is a community event. Programmers at our competitors are also breaking out new software for their readers, and we love to see what they’ve got. It’s both competitive and and collegial. The Times poured resources into an open-source software library called Elex that any organization can use to get real-time election results from the Associated Press. But we also work in secret on new features that we can’t wait to show off on election night to our readers. Many good (and bad) memories are formed in the crucible of an election season, so elections feel familiar and elicit a feeling of duty and honor. And for those who are just starting out, one way to get instant recognition in our community is to provide updates swiftly or through some novel technical means. And, of course, the most compelling reason for newsroom programmers to work long hours in preparation for an election night: the food . How we design and build digital products at The New York Times 164 Elections Code News Software 164 claps 164 Written by Engineering director at The Washington Post. Foodie. Dilettante oenophile. Espouser of obscure baseball statistics. Believer in coding hubris. Runes and such. How we design and build digital products at The New York Times. Written by Engineering director at The Washington Post. Foodie. Dilettante oenophile. Espouser of obscure baseball statistics. Believer in coding hubris. Runes and such. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-04-24"},
{"website": "NewYork-Times", "title": "cindy taibi named chief information officer of the new york times", "author": ["Nick Rockwell"], "link": "https://open.nytimes.com/cindy-taibi-named-chief-information-officer-of-the-new-york-times-fe3f74cfa2bf", "abstract": "Code Data Product and Design Workplace Culture Work with Us I couldn’t be more pleased to announce that I have promoted Cindy Taibi to Senior Vice President and Chief Information Officer of The New York Times. It’s a little unusual for us to post a promotion announcement on Times Open, but I think that this one is special and I couldn’t resist. For us at The Times, this is a very exciting moment. As a 37-year veteran of The Times, Cindy embodies the values the institution. She has worked across the company in a variety of roles: as a developer in our core print News Systems group; overseeing I.T. for our regional media group in the mid-2000s, as the architect of our print advertising and business systems; and recently, overseeing our international infrastructure, including our bureaus. She knows the company inside and out, and truly embodies our shared experience and values. What does C.I.O. mean to us? For us, the C.I.O. is responsible for applying technology to support our business, in every way. This means the infrastructure — networks, phones and computers worldwide. It means the productivity tools we all use every day to get our jobs done. And it means the critical applications that are the nervous system of our business, including our financial systems, our talent management systems and our legal and compliance systems. In contrast, my role as Chief Technology Officer focuses on the products that our customers use. To me, the C.I.O. role is in the process of being reinvented. For years, the range of problems and technical solutions available to the C.I.O. were very stable: You bought Office and Outlook, a bunch of Cisco gear and machines from Dell or H.P., and then hung on until you had to change the Enterprise Resource Planning system, which you did for a couple of years (and for tens of millions of dollars), and then you got fired. Today, everything is changing. In the world of Slack, enterprise productivity is being reinvented from the ground up. G Suite and Office 360 have evolved from beachheads of consumer I.T. to a critical set of tools that go far beyond what Outlook and Exchange were capable of in the past. We expect our corporate infrastructure to be fast, well-designed, real-time, accessible anywhere and evolving as rapidly as the consumer landscape. This opens up enormous challenges and enormous opportunities. Indeed, few roles can have more of an impact on how the whole company works: whether we come in dreading a slog through I.T. hell or feel empowered (or even super-powered) to do our best work. The role has tremendous responsibility and scope. Needless to say, Cindy is the first woman to hold the post at The New York Times. Cindy has been a great leader on my team since I arrived two and a half years ago. She has also been a great support and a source of inspiration. She has co-led our Women in Technology group, a self-organized task force that has driven a huge wave of positive change within our team. She’s been adaptable, open, reliable and pretty much ready to rock at all times. I am very excited to see what Cindy can do. So far, I have not been able to stump her, and I have tried! And I hope that her story and success will be an inspiration to others, as it should be. So watch this space to see what she gets up to — I will be! How we design and build digital products at The New York Times 73 Tech Jobs Women In Tech Technology 73 claps 73 Written by SVP Engineering at Fastly, ex-CTO at NYT. Passionate about tech, music, science, art, helping others be their best. How we design and build digital products at The New York Times. Written by SVP Engineering at Fastly, ex-CTO at NYT. Passionate about tech, music, science, art, helping others be their best. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-04-19"},
{"website": "NewYork-Times", "title": "diversity inclusion and culture steps for building great teams", "author": ["Tessa Ann Taylor"], "link": "https://open.nytimes.com/diversity-inclusion-and-culture-steps-for-building-great-teams-ca157bd98c07", "abstract": "Code Data Product and Design Workplace Culture Work with Us As a software engineer who happens to be female, I’ve long been committed to increasing diversity in the technology workforce. In my free time, I often read about issues impacting underrepresented groups and strategies to create an inclusive environment, and I devote time to mentoring the next generation of women in technology. I recently became an engineering manager on the CMS team at The New York Times, and have gotten to experience the issues of diversity and inclusion from a new perspective: that of a hiring manager and a team leader. One of my first tasks as a engineering manager was to fill my old role by hiring a software engineer. I’d experienced the hiring process as a candidate, interviewer and referrer of candidates, but this was my first experience as a hiring manager. Watching applications and referrals roll in allowed me to see first hand that, without a specific eye on diversity and inclusion, it is incredibly easy to have a homogenous group of candidates. Had I accepted my initial candidate pool as is, I would have almost exclusively interviewed people from over-indexed groups. This experience also really drove home one reason why homogenous teams and companies stay homogenous: the pressure of interviewing and hiring referrals. Determined to change the makeup of my candidate pool, I set out to find candidates from underrepresented groups. Everyone wants a silver bullet for recruiting people with diverse backgrounds: “Just post your job on this website, and your candidate pool will instantly diversify.” I’m here to tell you that’s not the case (or if it is, send that website on over!). Finding and recruiting people with diverse backgrounds takes time, effort and dedication. Let’s take a step back and talk about why recruiting, hiring and retaining people with diverse backgrounds is important. Namely, in addition to being the right thing to do, it’s a smart business decision. There is a wealth of research that says diverse teams perform better because each team member brings a different perspective to the table. This creates dialogue, challenges the status quo and ultimately results in a more thoughtful and robust product. While selfishly I think it’s nice to have other women in the room, my primary responsibility is to build the best team and the best products possible. I firmly believe (and research agrees) that such a team is made up of variety of people and perspectives, and that this team will build the best products. So, how does one build a diverse team? Let’s go back to recruiting and the candidate pool. After I joined The Times as a software engineer, I attended and recruited at conferences like Grace Hopper, Society of Women Engineers, Lesbians Who Tech and a variety of hackathons that cater to women and under-represented groups. Additionally, another woman in the technology department and I collaborated to encourage The Times to recruit at single-sex schools such as Smith College and Wellesley College, and schools that have shown a commitment to diversity in their Computer Science departments, such as Harvey Mudd. Spending time attending these events, and building and maintaining these relationships and networks paid off; The recruiting team and I were able to significantly change the makeup of the candidate pool and find some great candidates we otherwise would not have considered. After diversifying my candidate pool, I took a look at our interview process. As a team, we make a concentrated effort to ensure that the process is as fair and unbiased as possible. Each candidate sees the same — or close to the same, schedule allowing — group of people, all of whom ask the same — or close to the same — questions. There are also a variety of people on the interview panel: some to assess technical ability and some to assess soft skills. Additionally, The Times has a policy stipulating that interview panels must contain at least one woman who has technical knowledge. This policy is extremely important, as it ensures female candidates will see someone who looks like them during interviews, and it allows us to suss out gender bias in other candidates before they have a chance to become employees. The final hiring decision is consensus-driven, and all aspects of the candidate are taken into consideration. We look at technical skills, soft skills and extras that a particular candidate would bring to bear. While I loathe the term “culture fit” as it can be misused to preserve homogeny, I would say that we assess for “not a culture fit’” (for example, a candidate showing less respect to any member of the interview panel or having a non-collaborative attitude). All of a candidate’s skills and attributes are factored into the final hiring decision. The first step to leveraging the strength of a diverse team is, of course, getting unique voices to the table, but the work doesn’t end there. Once people are at the table, it’s important to create an inclusive environment where they can share their thoughts and perspectives. This requires effort on the part of the team to maintain open and respectful communication, as well as a continued focus on change and growth. It’s worth noting that though diversity and inclusion best practices are meant to benefit people from underrepresented groups, they actually benefit everyone and create a stronger team overall. Diversity doesn’t usually exist if there isn’t a good team culture, and a strong team is a byproduct of diversity. If you’re wondering where to start on your team, start with culture. Before I was in a position to create, influence and codify the culture on my team, I got to experience the difference a good culture can make. I’ve worked on all-male technology teams for my entire career, but when I arrived at The Times and joined the CMS team as a software engineer, I immediately noticed something was different. At the time, the team was still all-male, but no one ever treated me differently for being female. In fact, I felt like my gender was never considered, it was simply not part of any thought process or conversation. Everyone on the team was open, happy to answer questions and smart but modest. Collaboration was valued over being right, and everyone was truly committed to moving the whole team forward, rather than personal victory. There was also a commitment to work-life balance where home and family obligations were valued alongside work priorities. Interestingly, because the team was all-male, it was the men who modeled behavior of calling out to take care of a sick kid or taking off early to see a school play. This was really cool and encouraging to see, and it spoke to the great team culture. When I became an engineering manager and focused on hiring, this culture made me feel comfortable hiring more women. At the same time, I realized that it was my responsibility to maintain, codify and elevate the culture. The biggest test of team culture is how the team onboards a new member. This is an opportunity to take a look at the process and code through fresh eyes, and expose inefficiencies and gaps. My first exposure to onboarding as a manager was with our summer intern, which was fortuitous because onboarding an intern is more intensive than onboarding a regular team member. You can’t say, “Hey, here’s the code and some tickets,” as you might to a full-time hire. Before our intern started, I created a backlog of small tasks to help get her acquainted with our projects and code. These tasks were a combination of quick wins with a focus on understanding the full picture around a particular piece of the app, and stretch assignments designed to push her understanding of our systems and inspire questions. During her first week, another team member was designated as her go-to person for questions and trouble-shooting while she was getting set up and tackling her first tasks. Additionally, she had knowledge-sharing 1:1s with members of the team to give her a high-level overview of various pieces of our tech. As she progressed beyond onboarding tasks and into building full features, she had a dedicated partner for each of her projects. This partner was tasked with either pair-programming with her or answering questions when she was coding on her own. This ensured that there was always someone available to help and advise her; it allowed her to get comfortable asking questions of various team members; and it gave team members the opportunity to mentor a junior engineer. Throughout the summer, I made sure to solicit feedback from her about our team and the onboarding process. I asked if there was anything we could change or improve, and whether she felt supported in her projects and as a member of the team. Through this feedback, I iterated on the onboarding process and created documentation for onboarding future interns and team members. Onboarding a full-time team member looks very similar to intern onboarding on our team. There is a backlog of onboarding tasks, as well as informational and project-based pair-programming sessions. This allows the new hire to get familiar with the code and to ensure they are comfortable with various team members and feel like they can ask questions; and it ensures that established team members have the bandwidth to help with any questions or stumbling blocks. In response to feedback from our summer intern, the general onboarding 1:1s for full-time hires are staggered throughout their first few months and delivered when they are relevant to a current project or task, as opposed to being delivered all up front. This slow ramp up with an emphasis on learning sets up new hires for success by allowing them to understand the “why” of various tasks and parts of the code base; it also sets the expectation that asking questions and constant learning are a daily part of the job. In addition to onboarding new team members, it is important to create and/or codify good processes and practices that ensure everyone on the team feels included, heard and recognized. Our team explicitly documents our roles and responsibilities to ensure that people feel comfortable speaking up where appropriate and necessary (for example, part of an engineers’ role is to collaborate with product and design to drive product decisions). We also document team norms around things like pull requests and remote culture to ensure that everyone’s voices are heard and respected. Finally, we set quarterly goals around improving team culture, in addition to our quarterly product and technology goals. There are a few other things that we do to make sure that the CMS team is inclusive. First, we have multiple women on the team work together on a project, as opposed to splitting them up and assigning them to different projects. Also, some team events don’t involve alcohol and many of them are held during business hours (for example, we have a team lunch every Friday). Our events are also activity-inclusive: a recent dry, in-office event during work hours was a games party that included both video games and analog games. So, what are the results of all of this work? Tangibly, we’ve significantly changed the demographics of the team and it includes a female engineering manager (me). What’s more impressive are the products we build and the work environment that we’ve cultivated. Our products are technically complex, visually sophisticated and power an evolving world-class newsroom (you can read about the text editor we’re building ). We work collaboratively and leverage each team member’s unique skills and experiences. The work to promote diversity and inclusion is never done, but I’d say we’re off to a great start. There is no silver bullet. Put in the effort and reap the rewards. Give first — mentor at Hackathons, present at universities, teach coding. Leverage the recruiting team — they’re here to help. Don’t over-emphasize referrals from current employees. Standardize the panel for a given position. Standardize the questions for a given position. Discuss each candidate fully, allowing the space to talk about any special positives or red flags. Consider hard skills and soft skills for every role. Emphasize learning over results. Facilitate collaboration through structured pairing and onboarding sessions. Document your team’s processes, norms and code. Always be iterating, and seek feedback on your processes, norms and code. Value collaboration over being right. Emphasize the gains of the team over the individual. Ensure that team events are inclusive (dry, during work hours, etc). Acknowledge and reward work to improve diversity and inclusion. How we design and build digital products at The New York Times 751 4 Diversity Inclusion Women In Tech Team Building Workplace Culture 751 claps 751 4 Written by Director of Engineering @newyorker . Building great teams, solid platforms, and awesome products. She/her/hers How we design and build digital products at The New York Times. Written by Director of Engineering @newyorker . Building great teams, solid platforms, and awesome products. She/her/hers How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-06-14"},
{"website": "NewYork-Times", "title": "the future of meta tag management for modern react development", "author": ["Scott Taylor"], "link": "https://open.nytimes.com/the-future-of-meta-tag-management-for-modern-react-development-ec26a7dc9183", "abstract": "Code Data Product and Design Workplace Culture Work with Us React Helmet ( react-helmet on npm) is a fantastic library for managing your app’s <head> tags from within your React component tree. The API might be familiar to anyone who has developed sites using React: This is a nice API, because it allows your components to trigger side effects that will affect a disparate piece of your application — namely, the meta tags for your HTML document. <Helmet> can be rendered multiple times, so you can render it once with default values for some of your head tags and attributes and override those values deeper in the tree. If your app is rendered on the client (browser) only, you do not need to do anything else. It Just Works™. This is not the case for many apps, though, including ours at The New York Times. Server-Side Rendering (SSR) is a first-class citizen in our stack, and it affects everything that we do. When rendering your app on the server, this is how Helmet works: If you notice, Helmet.renderStatic() is a static method call, which means it is not tied to any particular instance of Helmet. This only works properly if nothing in your response pipeline is asynchronous. renderToString() is synchronous, so most people won’t notice any issues. But if you do add asynchronous operations to your render pipeline, you are susceptible to corrupted and leaky data between requests on your Node server. We care about performance and are constantly turning knobs and making tweaks to get better SSR performance. Many of the solutions we have looked at involve introducing asynchronous rendering into our server response pipeline. This makes sense because Node is single-threaded, and synchronous rendering blocks the event loop. Finding ways to yield to the event loop and allow multiple requests to be served in parallel is the goal. That being said, not all React-adjacent projects have code or idioms that are thread-safe. It is important for us to consider how libraries support SSR, how they interact with each other, and how active the development is on the projects we choose to integrate into our codebase. If you are using Apollo/GraphQL to query your data and you are server-rendering your app, you are probably experiencing this issue — provided that your site receives enough traffic to cause your Node server to queue requests. This is obviously the case for a highly-trafficked website like nytimes.com. SSR with Apollo looks like this: The async/await portion is where we get into trouble. This is not a bug in Apollo. It is a bug in one of Helmet’s dependencies. Local variables inside of JavaScript modules live in memory for the life of the Node server process. They are not reset for each request. This makes them a dangerous choice to be the source of truth for application state. react-side-effect contains such variables. Helmet has react-side-effect as a dependency. As such, if react-side-effect is not thread-safe, Helmet is not thread-safe. In fact, all projects that use react-side-effect are not thread-safe. This is surprising, because react-side-effect is maintained by Dan Abramov, who just sent shockwaves through the React community with his talk at React Conf Iceland about the new “suspense” APIs slated for React 17. React is moving toward async rendering in the releases leading up to 17. Helmet.renderStatic() returns the value of a scoped variable called “ state ” within withSideEffect . That variable is initialized exactly once, when you wrap a React component with the result of withSideEffect . It is read and wiped out every time SideEffect.rewind() is called statically. Helmet.renderStatic() is an alias for SideEffect.rewind() . A request comes in to your Node server — no other requests can be served in parallel unless the process yields to the event loop — that happens once we request our data with Apollo, or Relay, or whatever data fetching mechanism we decide to use. Because we are no longer blocking, another request can be served in parallel. There is nothing stopping the second request from calling Helmet.renderStatic() before our first request has been served. If the second request calls it before the first, the second request will get either: its data the data associated with the first request The first request is now susceptible to receiving: its data the second request’s data no data This is why, when viewing the HTML of a page, you might see the correct page content with the wrong meta tags. Or the correct page content with empty values for the meta tags. Not. Good. I was in the office over the winter holidays and noticed that tweets from some of our reporters were linking to the wrong stories. I had a hunch that parallel requests were wiping out data. I wrote a shell script to try to reproduce this behavior. In order to see it locally, I had to run the script in two separate terminal tabs with a list of URLs I pulled from our logs: Sure enough, I was able to reproduce the proper conditions for the leaky data immediately. Update : 1.0.0 just released ! React Helmet is no longer being actively-maintained by the NFL. There have been no commits to the repo in months. This issue has been logged in their tracker since last year. All of these things being true, I decided to fork the repo and solve this problem. Priority #1 : Scope the Helmet side effects on the server to the current request only. As long as the data is properly scoped, no amount of async can leak the data between requests. Priority #2 : Ensure that Helmet is written in a way that is up to date with React 16, so it isn’t a blocker for sites that want to use the latest React APIs. I did just that, and today we are officially open-sourcing react-helmet-async as a project supported by The New York Times. Here is how it works on the client: And on the server: The API is basically the same, save for the fact that your React tree includes <HelmetProvider> on the client and server. The “state” for each request is held inside that instance of <HelmetProvider> . Each new server request will instantiate a new instance, which will hold fresh state. This solved our problem. The React ecosystem is moving forward at breakneck speed, and it’s important to properly maintain its fragile projects. If you’d like to contribute or follow along with the development of the project, follow the Issue tracker on GitHub . How we design and build digital products at The New York Times 1.2K 2 React GraphQL Node Code 1.2K claps 1.2K 2 Written by Musician. Lead Software Engineer at the New York Times. Married to Allie. How we design and build digital products at The New York Times. Written by Musician. Lead Software Engineer at the New York Times. Married to Allie. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-03-20"},
{"website": "NewYork-Times", "title": "how the new york times uses software to recognize members of congress", "author": ["Jeremy Bowers"], "link": "https://open.nytimes.com/how-the-new-york-times-uses-software-to-recognize-members-of-congress-29b46dd426c7", "abstract": "Code Data Product and Design Workplace Culture Work with Us Even if you’ve covered Congress for The New York Times for a decade, it can be hard to recognize which member you’ve just spoken with. There are 535 members, and with special elections every few months, members cycle in and out relatively frequently. So when former Congressional Correspondent Jennifer Steinhauer tweeted “ Shazam, but for House members faces ” in early 2017, The Times’s Interactive News team jumped on the idea. Our first thought was: Nope, it’s too hard! Computer vision and face recognition are legitimately difficult computer science problems. Even a prototype would involve training a model on the faces of every member of Congress, and just getting the photographs to train with would be an undertaking. But we did some Googling and found the Amazon Rekognition API . This service has a “RecognizeCelebrity” endpoint that happens to include every member of Congress as well as several members of the Executive branch. Problem solved! Now we’re just talking about knitting together a few APIs. As we began working on this application, we understood that there are numerous, valid privacy concerns about using face recognition technology. And Interactive News, a programming team embedded in the newsroom, abides by all aspects of The Times’s ethical journalism handbook including how we gather information about the people we cover. In this case, we decided that the use of Rekognition’s celebrity endpoint meant we would only recognize congress people and other “celebrities” in Rekognition’s database. By the end of the summer, Interactive News interns Gautam Hathi and Sherman Hewitt had built a prototype based on some conversations with me and my colleague Rachel Shorey. To use the prototype, a congressional reporter could snap a picture of a congress member, text it to a our app, and get back an annotated version of the photograph identifying any members and giving a confidence score. However, we discovered a new round of difficulties. Rekognition incorrectly identified some members of Congress as similar-looking celebrities — like one particularly funny instance where it confused Bill Nelson with Bill Paxton . Additionally, our hit rate on photographs was very low because the halls of the Capitol are poorly lit and the photographs we took for testing were consistently marred by shadow and blur. Bad connectivity in the basement of the Capitol made sending and receiving an MMS slow and error-prone during our testing. And, of course, there were few places in the Capitol where we could really get the photographs we needed without committing a foul. Gautam and Sherman got around the “wrong celebrity” problem with a novel approach: A hardcoded list of Congresspeople and their celebrity doppelgangers . We grew more confident taking photographs and only sent the ones where members were better lit. A text-based interface is easiest for reporters to use, so while texting is slow, it’s superior to a web service in the low-bandwidth environment of the Capitol. In addition to confirming the identity of a member, Who The Hill has helped The Times tell some stories we couldn’t have reported otherwise. Most recently, Rachel Shorey found members of Congress at an event hosted by a SuperPAC by trawling through images found on social media and finding matches. If you’re interested in running your own version, the code for Who The Hill is open sourced under the Apache 2.0 license. The latest version includes a command-line interface in case you’d like to use the power of Amazon’s Rekognition to dig through a collection of photographs on your local machine without sending a pile of MMS messages. Our service is far from infallible. But Times reporters like Thomas Kaplan love having a backup for when they can’t get a moment with a member to confirm their identity. “Of course,” says Kaplan, “the most reliable way to figure out a member’s identity is the old-fashioned way: Just ask them.” How we design and build digital products at The New York Times 722 3 Congress News Politics Code Software Development 722 claps 722 3 Written by Engineering director at The Washington Post. Foodie. Dilettante oenophile. Espouser of obscure baseball statistics. Believer in coding hubris. Runes and such. How we design and build digital products at The New York Times. Written by Engineering director at The Washington Post. Foodie. Dilettante oenophile. Espouser of obscure baseball statistics. Believer in coding hubris. Runes and such. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-06-06"},
{"website": "NewYork-Times", "title": "talking technology lara hogan", "author": ["Nick Rockwell"], "link": "https://open.nytimes.com/talking-technology-lara-hogan-f430159bb094", "abstract": "Code Data Product and Design Workplace Culture Work with Us For this installment of Open Questions, I interviewed Wherewithall co-founder and coach Lara Hogan about her work in technology, managing technologists and “roaming the wilds” as a consultant. Q. Do you think managing technical people is different from managing people from other backgrounds or with other skills? A. Nope! I really don’t. I know that this errs on the end of controversial, but really: humans are human. We share core needs like respect and clarity; we all benefit from managers who are transparent, trusting and supportive. I think that when you manage people in a particular discipline (like engineering), it helps to have an understanding of the kinds of problems that they solve, so you can develop a variety of ways to help them get “unstuck.” This is true for any discipline! But the fundamentals of management skills are shared, I believe, across disciplines. How has it felt to go from working within a company like Etsy, that takes so much care with its culture, to roaming the wilds as a consultant and coach? “Roaming the wilds” is a great way to put it! I love this study that looks at a variety of experts in fields like firefighters, nurses and chess players, and how they developed expertise: “the straightforward way to achieve expertise is through direct experience, but this involves more than time-on-the-job. It involves the number, range, and difficulty of challenges faced, and it involves the way a person is able to learn from each incident, along with factors such as degree of engagement with the task” I wanted to get hands-on experiences in a broad variety of organizational cultures, company sizes, strategic roadblocks, etc. so that I could grow much more as a leader and manager. I love it, and I feel lucky to get to help companies solve for all different sorts of leadership and management challenges. As an example, my Wherewithall co-founder Deepa Subramaniam and I have now written and clarified a spectrum of an organization’s career ladders for their product, design and engineering teams. Each company has a different way they use and define those ladders, but we get to see a lot of commonalities, too! As we coach managers and leaders, we get to continually learn new nuggets of wisdom, and share them back in a way that levels up a variety of organizations (like this blog post on how to handle folks’ emotions about desk moves !). Do you miss writing code? Ha, nope! I get to write some code in personal projects when I feel like it. I totally respect that other folks who grow into a management track miss the hands-on individual contribution work in their day job, but I don’t! So much is changing now with respect to our view of power and our tolerance (lack thereof) for it’s abuse. But management inevitably includes very real power over others. How do you advise managers to navigate the use and restraint of the power we have? First, continually develop your awareness of the power you have; think about how it affects people and how people perceive it. You may not feel like you have a ton of power, but others’ perception of your power is important to know and be sensitive to. (And, I promise: if you have the power to hire and fire, to promote, to adjust compensation, you have tremendous power!) Remember that when you speak to a group of people — no matter how private the channel or how small the group — your voice carries extra weight because of your role. People may apply more weight to it than you would assume. You talk and write about management, and you also talk and write a lot about inclusion and diversity. How do you relate those two things? A good manager prioritizes inclusion, and a good manager understands that diversity is what will make their team stronger. No matter the problem space, no matter the team size, no matter how far up their company’s hierarchy they sit, a good manager builds inclusion into their management practice and team culture. A good manager is also curious to learn more about these issues, aware of their own privilege, and eager to continue to improve their management and inclusion practices, too. Lara Callender Hogan is an engineering leader, coach, and consultant at Wherewithall . Lara is also the author of Designing for Performance , Building a Device Lab , and Demystifying Public Speaking . She champions engineering management as a practice, helps people get comfortable public speaking, and believes it’s important to celebrate career achievements with donuts. Follow her on Twitter . Nick Rockwell is the CTO at The New York Times. Find him on Twitter and Medium . How we design and build digital products at The New York Times 22 Management Coaching Careers Career Advice Conversations 22 claps 22 Written by SVP Engineering at Fastly, ex-CTO at NYT. Passionate about tech, music, science, art, helping others be their best. How we design and build digital products at The New York Times. Written by SVP Engineering at Fastly, ex-CTO at NYT. Passionate about tech, music, science, art, helping others be their best. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-03-08"},
{"website": "NewYork-Times", "title": "thinking like entrepreneurs our experience with matter a design thinking vc program", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/thinking-like-entrepreneurs-our-experience-with-matter-a-design-thinking-vc-program-b836f4271c6a", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Hannah Cassius, John Thai and Ben Solwitz One of our co-workers sent us an email asking if we wanted to be a part of “The Matter Bootcamp.” She described it as a design thinking workshop, meant to support both entrepreneurs in the media space and larger media companies (like The New York Times) in developing ideas to build a more informed, empathetic and inclusive society. We took the workshop along with a few other Times employees and admired the focus on the user-centered, prototype-driven product design process. At the end of the four days, we all had created product prototypes ranging from silent disco meditations to a dog-petting program. These ideas were more extreme than what we would actually create, but they got us outside of our comfort zone. The four-day workshop is the kickoff for the extended 20-week program we participated in. The Times is one of Matter’s media partners, which lets a number of Times employees participate in their bootcamp. We learned valuable design and entrepreneurial skills that help us do our jobs better. For a publication that is nearly two centuries old, we have to embrace continuous digital change to move forward. We have internal innovation challenges, like Maker Week, a week-long, cross-functional event where folks from Design, Product, Project, Marketing and Technology come together to work on envisioning, designing and developing cool new projects. The idea behind Maker Week is to allow people real freedom to work together with people they don’t usually interact with, to think about new problems, get creative, and explore wild ideas. We used Maker Week as a way to get feedback on our idea. We took paper prototypes of our idea down to the food court under Rockefeller Center. We asked for people’s feedback and then incorporated it back into what we were building. Because of this process, we were better able to articulate what people wanted. We heard consistently that people felt like they were trapped in a news bubble, and that they often ended up going to the same sections or types of articles because it was what was algorithmically suggested to them. We came up with a prototype for diversifying a reader’s news diet. We spoke to Corey Ford, Matter’s co-founder, about how internal innovative thinking programs like Maker Week differs from a program like Matter. “Many of our partners are doing great work with ‘inside out’ innovation with programs like Maker Week at The Times,” he said. “But we think it’s important to reinforce those efforts with an ‘outside-in’ approach like the Matter Partner Program. Since Matter is a neutral, independent place that serves both early stage media entrepreneurs and mission-aligned media partners we are able to create an immersive experience that challenges internal cultures and process and inspires them to take more risks, be more-human centered, be more iterative, and to think about their projects more like a multidisciplinary venture.” Hannah Cassius: As a product manager, I like to spend time upfront before any project to ensure that we are capturing a market need and achieving product-market fit. The challenge in a large company like the Times is that we have a lot of projects and limited time. Being able to focus most of our efforts on defining the problem, refining our solution based off of continuous feedback, and doing all of this work before committing to build anything differs from how projects are traditionally done. One of the more interesting parts of being in the Matter program for me is that we were working alongside entrepreneurs. They encouraged us to be bolder and take risks, since that’s what they do on a daily basis. By taking a human-centered, prototype-driven approach the entrepreneurs in the Matter program are looking at media in a unique light. For example, one of the companies, Purple , created an SMS platform that connects users and journalists in a two-way messaging-based conversation . Another company, Gretta , is working to open up podcasts to search engines for greater discovery in audio storytelling. It was fascinating being able to work alongside them because they were always thinking outside the box of how to improve the media landscape. Ben Solwitz: I have been a developer for about ten years and had very little experience with product design prior to the Matter program. Usually the requirements for projects that I work on are relatively static, and determined before they get to me. The idea of exploring an open-ended problem with many possible solutions was intimidating at first because I didn’t know where to start. The user-centered, prototype-driven approach we learned gave me the tools to generate lots of ideas while remaining focused on specific needs of real users. I learned a lot about how to quickly iterate and generate prototypes based on user feedback. Many of the developers on my team asked me if we had built any of the prototypes that we showed them, to which I replied that I wasn’t sure if we had come up with anything that anyone would really want yet. I realized how much more efficient it was to get feedback on a Sketch or Invision prototype than a fully-functional app. Interviewing users with our prototypes helped keep us focused on solving the needs of real users, and not focusing on only what we personally would find useful. John Thai: Having the opportunity to participate in the early stages of a new idea is sometimes hard to come by depending on what stage your product is at. For me, having worked with legacy systems and somewhat mature products, I’ve mainly focused on feature optimizations where the need came from already known problems and the solutions were fairly scoped and constrained. The Matter program allowed me to start from scratch where the immediate focus was the end user and the solution was validated by the end user. During ideation where you’re not concerned with constraints nor scope, our team was able to let our minds flare, thinking freely and radically. We then trimmed down to focus on an idea that would be desirable, feasible, and solve a real user need. By iterating on a high fidelity prototype and tweaking things based on user feedback, we had something we were able to move forward with and build incrementally. After participating in this program, I have tried to always start with the end user wherever possible and to keep them engaged throughout the process whether it be a new idea or optimizing an existing feature. I really enjoyed the program! One of the challenges we face today is figuring out how best to implement the solutions we came up with during The Matter program. It’s great to understand user needs and develop innovative ideas, but we also have to work through getting buy-in and stakeholder agreement internally to build any product that requires significant staffing. If we could do the program all over again, it would be great to have parallel goals internally around buy-in and metrics, in addition to the design reviews with Matter. For example, this could mean including stakeholders from different teams, such as finance, marketing and analytics, in the process as opposed to focusing on just our idea and using design-thinking to refine it. Having them actively involved, and helping to measure the success of our prototype, throughout the process is something that would have been helpful at getting more buy-in. Overall though, using this type of design-thinking methodology, not just within the design organization, but across a team of people who may not regularly be exposed to it, was vital to crafting new innovative ideas. This type of program from Matter, and the thinking it promotes, makes us all better at our day-to-day jobs and being open to the fact that ideas can come from anywhere. We are grateful to have had the chance to develop new ideas that work towards building a more informed, connected, and empowered society. How we design and build digital products at The New York Times 249 Design Thinking Entrepreneurship The New York Times Design 249 claps 249 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-04-26"},
{"website": "NewYork-Times", "title": "agrarian scale kubernetes part 3", "author": ["Michael Strickland"], "link": "https://open.nytimes.com/agrarian-scale-kubernetes-part-3-ee459887ed7e", "abstract": "Code Data Product and Design Workplace Culture Work with Us Part 1 of this set covered the basics of setting up your development environment for Kubernetes on Google Kubernetes Engine, and creating your first cluster on Google Cloud Platform. Part 2 covered deploying and updating an application on your cluster. So far we’ve created only resources that live within a Kubernetes cluster. To route traffic from the public internet to our app, we’ll need to provision some additional resources on the larger Google Cloud Platform. Much of the magic we saw with deployments in Part 2 are brought to us by Controllers , Kubernetes code that creates, updates or deletes resources. But controllers aren’t limited to the resources within Kubernetes — they can run any code we tell them to, like hitting the APIs for other Google services. Certain cloud providers (like Google and Amazon) have platform-specific controllers included as part of Kubernetes that can manage resources outside the cluster, such as firewall rules. These controllers and the resources they create act as roots that grow from your cluster, allowing non-Kubernetes resources to respond to Kubernetes events, letting it take advantage of other services your cloud provides. This becomes essential for networking. Kubernetes uses an Ingress object where you can specify at a high level what traffic should be routed to what application. For example, traffic for example.com should go to App A, and example.net to App B. The GCP-specific controller listens for changes to your Ingress, and knows how to create the firewall rules, backend services and IP addresses (and one day even DNS records) necessary to route traffic. This is another example (along with Deployments) of declarative configuration . Keeping the ingress configuration high-level — and relying on platform-specific controllers to provision all other resources — theoretically will let you use the same configuration to deploy an app in Google Kubernetes Engine as you would in a cluster in Amazon Web Services or Azure. (Once controllers for those platforms exist.) Let’s create two more types of Kubernetes resources: a Service to identify that your pods can accept traffic on a certain port, and an Ingress to configure how external traffic reaches that service. Services work like a telephone switchboard that lets you standardize access to your apps. Each service targets one or more ports on a set of pods, and can expose those ports outside of the cluster to allow incoming traffic. kubectl expose is another shorthand way to create objects in Kubernetes, in this case Services. Specify a deployment you want to expose, and the resulting service will route traffic just to those pods. The other arguments let you fine-tune which ports should be linked up. This service gives us a lot of options for accessing our app for free: Within your cluster, a dedicated IP address (e.g. 10.11.248.199) and hostname (kube-test-app.default.svc.cluster.local) that both route traffic to your app. A dedicated port (e.g. 30606) that is accessible from outside your cluster (firewalls permitting). There isn’t a built-in kubectl command to create an Ingress, but since any object in Kubernetes can be represented as YAML, we can sculpt an artisanal Ingress object by hand, then use kubectl create to upload it into our cluster. After a minute, we should see an IP address listed next to the ingress: In the background, the Google Cloud controller took care of creating a number of resources. Let’s list some of them: This ingress funnels all incoming traffic to our one test app, but you can also set up host- and path-based routing if you’re running multiple services. For some more fun, or if you want to play around with additional routing rules, you can use the kubectl edit command to update your Ingress. This command opens up your default text editor ( careful, it might be vim ) where you can modify an object’s configuration, save the file, and Kubernetes will update the object in your cluster. We should finally be able to hit the Ingress’s public IP and see our app load. Open a browser and enter the IP address listed in get ingress . You can also set up a DNS entry if you want to host this application on a domain, sending traffic to the public IP address. At this point, your cluster can update your app, or deploy additional apps and set up additional routing using the existing Ingress object. You’re a devops engineer! There are a few additional notes below about debugging the above setup, and next steps you can take with Ingresses. Another way of routing traffic to your app is to create a Kubernetes Load Balancer Service . However, this creates a GCP Network Load Balancer , while Ingresses create HTTP(S) Load Balancers . The latter offers additional features like path-based routing and managed SSL termination and support for more apps. If you see “Error: Server Error” when trying to access your app, the health check the Load Balancer uses to make sure your app is running might be failing. This guide can help you update the health check to use a different path. Ingress health checks default to hitting the “/healthcheck” endpoint on your service, so we use that as our convention. The HTTP(S) Load Balancers created by Ingresses also support several features that are useful for both public and internal apps. With how easy it is now to obtain free SSL certificates , the hardest step in securing your app is integrating the certificate into your hosting provider. Google lets you upload an SSL certificate and attach it to a Load Balancer entirely through the web console, and doesn’t require any changes to your app code. Once you’ve created an Ingress, you can view the Load Balancer in the web console . Click the edit button, and then the Frontend configuration tab. Click Add frontend IP and port , and you should be able to use the existing IP address already associated with your Ingress. Choose HTTPS for the protocol, and select an existing SSL certificate, or upload a new one. Hit save, and you’re done. The load balancer will terminate the SSL connection and forward traffic to your cluster already decrypted. Note this means that traffic is only encrypted via SSL over the public internet, and is not encrypted between the load balancer hardware and your cluster hardware within Google’s network. However, Google has other encryption in place between services. Ingress Load Balancers are meant to be public and don’t offer any way to restrict access by IP address. However, they support Google’s Identity-Aware Proxy (IAP), which is an included service that can place access to your app behind a Google login . Using the web console , you can choose a list of Google accounts or groups that should be allowed access, and then enable IAP on any of the backend services that correspond to your Kubernetes services. While there are additional steps you should take in production to secure your app, using IAP gives your cluster a layer of protection against DDoS attacks, as unauthenticated requests never reach your hardware. Kubernetes is an incredibly flexible platform, and the individual objects we’ve set up can be used in endless configurations. But since most of our applications are fairly similar, we’ve come up with some guidelines for how to structure our resources so they’re consistent from app to app. Services should normalize ports exposing web apps on port 80 (sending traffic to a target port specific to the app, like 3000 for rails apps), so that Ingresses use a single port for routing. Apps should generally consist of a deployment, secret and service, which should all be given the same name (“my-app”). Better yet, their names should correspond directly to their repositories on GitHub. (Sorry, no underscores.) Kubernetes allows you to have multiple “namespaces” to group sets of objects. Switching namespaces can be repetitive on the command line, so it’s helpful to use them only when you want to isolate services from each other, and not for organization. Wherever possible, this setup uses the “Always Free” tier of Google Cloud services. The two items that end up costing extra are the worker node(s) and a base charge for using network load balancing. Worker nodes: $8.18/month (or $13.80/month if using g1-smalls). Load Balancer: $18.25/month. (This is the “minimum network forwarding rule” charge, which is a fixed rate up to five Load Balancers, and includes the add-ons above. The free tier includes up to 1GB/month of ingress traffic free. Total: $26.43/month In the end, it’s noticeably more expensive than running a single micro instance and accessing it over it’s included public IP address, largely due to the load balancing costs. However, a lot of extra features are included in the minimum network charge. Additionally, Google offers a free trial of up to $300 in your first 12 months to try the service out, which is enough to run this setup for a year at no cost. Google Cloud Platform Community on Slack #kubernetes-engine kubernetes-users Google Group Dockerizing a Node.js web app Google Kubernetes Engine: creating a cluster Google Kubernetes Engine: deploying an app How we design and build digital products at The New York Times 19 Docker Kubernetes Google Cloud Platform Google Kubernetes Engine Code 19 claps 19 Written by assistant editor @nytinteractive @nytimes. infrastructure, olympics, running. ex-nyu/gallatin student. How we design and build digital products at The New York Times. Written by assistant editor @nytinteractive @nytimes. infrastructure, olympics, running. ex-nyu/gallatin student. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-04-26"},
{"website": "NewYork-Times", "title": "https open nytimes com the new york times as a tor onion service", "author": ["Runa Sandvik"], "link": "https://open.nytimes.com/https-open-nytimes-com-the-new-york-times-as-a-tor-onion-service-e0d0b67b7482", "abstract": "Code Data Product and Design Workplace Culture Work with Us Today we are announcing an experiment in secure communication, and launching an alternative way for people to access our site: we are making the nytimes.com website available as a Tor Onion Service. The New York Times reports on stories all over the world, and our reporting is read by people around the world. Some readers choose to use Tor to access our journalism because they’re technically blocked from accessing our website; or because they worry about local network monitoring; or because they care about online privacy; or simply because that is the method that they prefer. The Times is dedicated to delivering quality, independent journalism, and our engineering team is committed to making sure that readers can access our journalism securely. This is why we are exploring ways to improve the experience of readers who use Tor to access our website. One way we can help is to set up nytimes.com as an Onion Service — making our website accessible via a special, secure and hard-to-block VPN-like “tunnel” through the Tor network. The address for our Onion Service is: https://www.nytimes3xbfgragh.onion/ This onion address is accessible only through the Tor network, using special software such as the Tor Browser . Such tools assure our readers that our website can be reached without monitors or blocks, and they provide additional guarantees that readers are connected securely to our website. Onion Services exist for other organizations — most notably Facebook and ProPublica, each of which have created custom tooling to support their implementations. Our Onion Service is built using the open-source Enterprise Onion Toolkit (EOTK) , which automates much of the configuration and management effort. The New York Times’ Onion Service is both experimental and under development. This means that certain features, such as logins and comments, are disabled until the next phase of our implementation. We will be fine-tuning site performance, so there may be occasional outages while we make improvements to the service. Our goal is to match the features currently available on the main New York Times website. Over time, we plan to share the lessons that we have learned — and will learn — about scaling and running an Onion Service. We welcome constructive feedback and bug reports via email to onion@nytimes.com . Finally, we would like to extend our thanks to Alec Muffett for his assistance in configuring the Enterprise Onion Toolkit for our site. Runa Sandvik is the Director of Information Security at The New York Times How we design and build digital products at The New York Times 2.5K 5 Privacy Infosec VPN Security Code 2.5K claps 2.5K 5 Written by Director of Information Security at The New York Times How we design and build digital products at The New York Times. Written by Director of Information Security at The New York Times How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-04-26"},
{"website": "NewYork-Times", "title": "how to grow as an engineer working remotely", "author": ["Thompson Marzagão"], "link": "https://open.nytimes.com/how-to-grow-as-an-engineer-working-remotely-3baff8211f3e", "abstract": "Code Data Product and Design Workplace Culture Work with Us There are many articles out there about being an effective remote worker. Most of them focus on the basics, like building the ideal home office , following strategies for effective video conferencing , managing cabin fever , avoiding becoming a remote developer black box or improving self-discipline, motivation and communication . But where do you go from there? People often ask me that. Julia Evans at Stripe has done a great job writing about this , and I’d like to give you my take as well. I have over 20 years of experience as an engineer or engineering manager. I’ve spent the last seven years working for The New York Times, and have been remote for the past three years. How do I keep myself constantly learning and growing, both personally and professionally, while at the same employer, especially now that I’m a remote worker? As an engineer, you’re not paid to write code ; you’re paid to solve problems. It’s also not enough to just solve any problems. You need to be solving the right ones. You should constantly make sure there’s alignment between what you want and what the business needs, as organizational context and business priorities are constantly changing. It’s the path with the greatest rewards: You’ll mature professionally. Solving the right problems means working on tasks that bring the most positive impact to your team. This can be at odds with what you might be most interested to learn at the time or what you personally think is the most important problem. Being right is usually not worth much if others don’t agree. It’s important to have personal interests and preferences, but at work, you have to learn how to live at the intersection of what your preferences are and what the business needs. You’ll find out if you’re working with the right manager and team. Working with them to discover the right problems to solve will give you the experience to decide if you are working with people you can trust and who can support you. You’ll learn how to bring others along for the journey. In almost every context, you should not jump in and try to solve problems on your own. That’s a lonely and ultimately unscalable path. You’ll need to convince others to join you by figuring out how they can grow alongside you. Learn to communicate that constantly and effectively. But how exactly do you figure out what the right problems are to solve? It depends on the situation, but you can look for patterns : Considering your roadmap and your goals, what is keeping you from doing things more efficiently, with more quality, or more reliably? A low-hanging fruit in the form of a simple or small task that can be easily added to your current workload can be best at testing if a type of problem is the right problem to solve. Remote pro-tip : As a remote worker, by necessity, I ended up becoming proficient at noticing what is going on across the organization by leveraging the company’s group messaging tool (Slack) and I use that proficiency to learn about some of the problems affecting multiple groups. I pick a relevant problem to solve (say, improving observability across our tech stack) and decide how far I’d like to get with it. I then convince my manager that I can work with others on a solution for the problem. Chances are, a problem that affects our team has the potential to be adopted more widely or to be done in partnership with others. Consistency is one of the main traits of a senior engineer. Even if you are solving the right problems, there are different classes of right problems to solve: standardization, performance, resiliency, quality, innovation, developer productivity and so on. Explicitly choosing a class of problems you want to tackle and defining what your world will look like when you have some solutions in place bodes well for your career: You’ll be increasingly recognized for it. You might not want to call it your specialty, so that you’re not pigeonholed, but solving problems that are related to each other will help you to successfully solve similar problems in the future. People will seek your expertise and will look for your leadership. You’ll be able to work at different levels of abstraction. By creating a recognizable theme around the work you do, you’ll be able to go deep but also lead a broader related effort when the need arises. You’ll develop perseverance. By defining a coherent vision of what you want to achieve and reminding yourself of it often, you’ll feel less bothered by short-term obstacles and you’ll come across as someone who is calm, collected and passionate. To avoid over-engineering, each solution you implement should stem from a vision that revolves around concrete use cases. Being remote, it’s especially important to work alongside others and share responsibility for these solutions. Remote pro-tip : In Slack, I get to watch a real-time feed of issues and problems facing the organization, so I keep tabs on the patterns that come up. I had originally been a full-stack developer, then a back-end engineer. Over the past few years though, especially since becoming remote, I have been able to witness a greater need for more automation at the operational level. So although I work up and down the tech stack as necessary, the theme around the problems I’ve worked on more recently lives at the intersection of application development and delivery engineering . This includes leveraging Consul for service discovery, Terraform for infrastructure configuration, Docker for portable workloads, Drone for continuous integration and Kubernetes for efficient resource scheduling. This year, I’m working with the web rendering platforms team at The Times — a team that has an established roadmap with existing milestones. So, while the theme I’ve chosen defines the nature of my work, my team’s collective vision helps to keep us all grounded and focused on a valuable delivery. As you progress in your career, you will learn that you have to prioritize both pragmatism in how you work and maintainability for the code you write. One of the most direct paths to achieve those objectives is by focusing on simple solutions: Spend some time planning what you need to do. Focus on the value that your solution is bringing to your organization and your users. Any architecture, technique, strategy, algorithm or component that increases complexity but makes no difference in the final result is superfluous and detrimental to the longevity of your solution. It’s easier to get something more focused when you do it a second time. So, when faced with an unfamiliar challenge, do a proof of concept. Use that proof of concept to measure the value of your solution. Use those metrics to make decisions on how to simplify what you actually end up building. Write a document that describes how you plan to solve your particular problem. Show it to others. Gather feedback early and often. Find out if you can make it even simpler. All that being said, sometimes the best way to implement a simple solution is to not write any code at all. Find out if a different team or group has already solved a similar problem and reuse or retrofit their solution for your needs. Leverage open-source components if you can. Or outsource it all to a vendor or service provider. For some engineers with many years of experience, it’s as if each one of those years were the same, repeated over and over again, like a perpetual Groundhog Day . One of the best ways to learn is to challenge yourself, and one of the best ways to challenge yourself is to switch teams: Switching to a new team can be refreshing: new people, new problems, new processes, new goals. Yet, you’ll be at the same company, leveraging relationships you have already made over the years to get up to speed faster and more efficiently. Working with and eventually transferring to other teams will show to the company that you can be flexible, that you can adapt to different situations and work with all kinds of people. That is a valuable impression to give others around you, who will look to you as a person who might be able to help with tricky and unusual situations. Working with other teams will organically give you the experience needed to bring people together when they can’t seem to agree. You might even know people on both sides of the argument and can use that knowledge to more easily guide both sides to an agreement. Switching teams can lead to learning more about yourself and your organization. You might learn about what you don’t like or what is not a good fit for you, or that maybe it was a good fit and no longer is. When that happens, work with your manager and be upfront about what is working and not working for you. If you find that it’s really not going to work, prepare for the move by finishing your projects the best you can, doing explicit knowledge-sharing and documentation to make sure others in your team can do the work you are doing and maybe even working to find a replacement for your role. Trying your hardest on those efforts will consolidate your reputation as someone who is responsible and mindful of how your decisions affect your team and the organization as a whole. Remote pro-tip : In seven years at The Times, I have switched teams seven times. Being remote has made that process even easier. I don’t have to wait to switch desks and I don’t have to interact just with the folks who sit next to me. When remote, it doesn’t matter if someone is not on my team, not on my floor, or not on my city. It also matters less if they are an engineer, a manager, a director or a CTO. It’s just easier to talk to anyone. I talk and interact with more people now that I’m remote than before. Talking to more people increases the chances you’ll find out what other interesting work is out there in your organization and you’ll more easily build diverse relationships that can facilitate switching teams. This is sometimes counterintuitive: grow professionally by making yourself dispensable. By making yourself dispensable, you show that you can take on larger or more complex challenges: Instead of hoarding knowledge, processes and insight, write them down. Instead of doing the same task over and over again, teach others how to perform it or write a script to do it. Don’t do it all yourself. Break it apart and share in the ownership and implementation with others. You’ll most likely not be able to do this with everything, but with the time that you gain, think about the next best thing you could be doing. You’ll improve your strategic thinking in addition to improving the tactics you use to perform your job. In order to choose what you could automate about the work you do today, you have to think about priorities, your roadmap, your team, your goals and your future. Ultimately, by automating away the work you perform, you gain mastery over it and you show to your team, your manager and your organization that you’re ready to tackle the next challenge. You show that what you do is reproducible, can be done more efficiently, and can scale beyond what you can do by yourself. Being on call is one of the most powerful ways to learn more about the system you are responsible for. You don’t have to take just my word for it . Most importantly, when things break, figuring out what broke helps you to decide where improvements are most needed: You’ll find out how effective your testing strategy is based on how often you have obvious defects or regressions after you deploy a new release. After you find and fix a bug in production, write a test that reproduces the problem and make that test pass. You’ll learn how changes to other systems and their availability affect the behavior and output of your system, especially when you rely on external data sources. Make sure your system can degrade gracefully, including defaults for missing data, useful error messages and flexible business logic that can return meaningful results even when you get unexpected, badly formatted data or no data at all. Improve your integration tests and practice fuzzing . You’ll learn how resilient your architecture is to infrastructure failure and how it scales when encountering unexpected high load. Even when you have done load testing and chaos engineering , you might still encounter outages. When faced with an outage, write a blameless postmortem and take steps to minimize or eliminate the impact of a similar situation. You’ll find out how well your system is documented, how meaningful your alerts are and how useful your monitoring setup is. If you get an alert and it’s not actionable, it should not have been an alert. If you find gaps in your documentation or monitoring, fill them. Ultimately, you’ll find out how much observability you truly have . Remote pro-tip : When I get paged during off-hours, I’m usually able to react to the incident just as quickly as I react to problems during regular work hours, because I’m used to working from home. My co-located peers in the same off-hours situation sometimes have more trouble with that in terms of setting up their workstation at home and accessing various services outside of the office. To minimize that, I have written documentation about how others can set up their workstations at home to triage and diagnose problems more effectively, like running a script to open up all the different monitoring dashboards all at once. In much of the work you do, you’ll grow faster if you work with others. What better way to do this than to create groups of people who have a common goal or interest? Show to your manager that you can lead others in becoming better professionals and better people outside as much as you do inside your own team: You’ll become a better practitioner of your craft by participating or leading a group focused on a specific technical aspect of your job. It can be a group focused on a programming language or tool that you use or a specific cross-cutting functional area like performance, security or architecture. You’ll become a better corporate citizen by participating or leading a group focused on non-technical aspects of your job, such as public speaking or improving diversity efforts. You’ll engage in more personal relationships with others who might share non-work related interests, such as different sports, physical activities or hobbies. Remote pro-tip : As a remote employee, you could help other folks in their own journey toward becoming remote themselves. I have done this, and it’s helped me to think about my own journey toward becoming a better remote employee. It has also given me the motivation to help craft a remote work policy for the engineering department, which eventually was adapted into overall corporate policy. Nowadays I’m known as someone who can help others learn how to work more efficiently from home or even make the decision and the transition to becoming remote employees themselves. I’m proud to say that I’ve helped retain some folks who otherwise would have left the company if they hadn’t been able to work remotely. If you’re an engineer in a fairly well-run team, you most likely have 1:1 meetings with your manager regularly. Why not have 1:1s with a couple of your peers as well? Or meet regularly with managers and engineers outside your team, folks from different backgrounds or who have mastered different skills, like designers or product managers? You’ll learn a more diverse set of points of view about your company and the world around you. Can you learn from them? Can you help them? You’ll find out more about how other engineers in your team approach their work and manage their careers so that you can learn from one another. You’ll increase your reach and influence by meeting engineers outside your team and finding out what else is going on that you could potentially help with, like increasing adoption of a standard or helping to solve a technical issue you have solved before. You’ll learn to have a more holistic perspective of the products and services your company creates. You’ll make long-term working relationships healthier and easier to come by if you seek to meet one-on-one with folks from different backgrounds than yours. By connecting at a more personal level, you’ll better understand their challenges, both at work and in life, and how they differ from your own. Remote pro-tip : Being remote makes it easy for me to reach across physical space over the entire organization and just talk to anyone, as they are just as close to my chat sessions and video conferencing as anyone else. I have 1:1s with my manager, my manager’s manager, a couple of my peers in my team, in my department and in other departments. As master of my own calendar, I then put those 1:1s as close together as possible to minimize context-switching with my other work. One of the hallmarks of engineering seniority is the ability to mentor others. As you grow professionally, it’s important to allow yourself to be continually mentored by others and to make yourself vulnerable, open to accept and act on feedback from folks at all levels of experience. The best mentorship relationships have an element of mutual benefit, where both sides are expected to help each other with their own challenges. What that means is that when you’re mentoring someone, you should also ask your mentees how they can help. Allow them to contribute. As a mentor, try to refrain from telling your mentee what to do about a problem or how to approach a new situation, even when they explicitly ask you for it! Help them instead to figure it out for themselves. Be willing to listen and give constructive feedback rather than assume you know the best solution. Act as a facilitator and let them take control and come up with the narrative of their careers. As a mentee, you should not restrict yourself to mentors who have “more experience” or a “higher title” than you. Every single person, peer, intern, contractor, boss, young and old you meet has had a different life experience than you. Most senior engineers are passionate about something related to their work. You can almost see a twinkle in their eyes when the subject comes up. It’s not a requirement for growing professionally, though, as there are great engineers who are just happy to do the best job they can, efficiently and reliably, while their true passion lies elsewhere. Also, there’s some confusion about what being passionate about your work really means: Being passionate does not necessarily mean working more hours than required. That is just not sustainable and often leads to hopelessness, bitterness, burnout and regret. Being passionate does not necessarily mean coding on personal side projects. Lots of tasks at work and in life have the tendency of becoming not so fun when you do them too often or push too hard. Being passionate does not necessarily mean working on open-source projects. While open-source leadership can demonstrate entrepreneurship and creativity, one can demonstrate similar qualities by leading internal groups and discussions during regular work hours. It’s also possible to be too passionate about something. So passionate that it makes it hard to be humble, to listen and to admit imperfection and pragmatism, all of which will actually prevent your professional growth. Being passionate, as with being right, is not that useful if it’s done in a vacuum. Having passion productively means sharing, evangelizing and getting others just as excited as you are about a subject. Empathy is the ingredient that will give you the greatest return on investment for your personal and professional growth. You need empathy toward past mistakes and technical debt. You need empathy toward everyone you work with, no matter what role. You also need it toward the people who will have to face the consequences of the decisions you make today. Ultimately you need to remember that software engineering is more about people and their relationships to their work and others than it is about coding. Remember: there are many factors that go into decision making. It’s especially important to remember this when confronted with seemingly illogical engineering decisions. Maybe the engineer or team was pressed for time, didn’t have the right experience, was faced with conflicting priorities, was crushed by an overwhelming amount of work, chose the wrong tasks due to mismanagement or was troubled by problems of a more personal nature. Try to understand the larger context and you’ll increase your chances of improving a snippet of code, a component or an entire system beyond what is possible by just focusing on the present situation. Don’t make superficial judgments about the work and, most erroneously, about the people responsible for it. Perform code reviews like they are a conversation. Don’t use them as an approval process. It’s a process for incremental course correction, mentorship and learning. It’s a friendly sanity check on the code, not a judgment on the person who submitted the code. It’s an opportunity to understand what your teammate wanted to accomplish and to be understood yourself, in your attempt to make things better and share responsibility. Reach out in person if you think that there are basic, fundamental problems with the code you’re reviewing to prevent you and others from overwhelming the code review with corrections and negative comments. Practice programming to an interface with other developers in mind. Sometimes in our field, we are told to design programming interfaces to foster code reuse and improve the extensibility of our solutions . But it’s more than that. You should design interfaces while thinking about your fellow engineers and even your future self. Ask yourself: how can you make it easier for them to understand intent? How can you make it easier for anyone to just take your code, read your documentation and run with it? How can you organize your code in such a consistent and coherent way so that it requires less maintenance and adheres to the principle of least surprise ? Remote pro-tip : As a remote employee, I learned to have even more empathy for folks who might not be able to be present in all forms of informal work discussions, especially when those happen after work hours. Over time, I found that the groups that depend the most on those after-work interactions are the least mature in terms of promoting an inclusive and welcoming environment for people of all sorts of experiences and backgrounds. It takes quite a bit of conscious effort to work toward your own professional growth, whether you work remotely or not. Being a remote worker might even give you some extra superpowers if you work thoughtfully enough to achieve them. Thanks to Sara Simon , Julia Evans , Deep Kapadia , Jose Muanis Castro , Phil Calçado , Willian Molinari and others for their feedback. How we design and build digital products at The New York Times 1.8K 3 Remote Engineering Productivity Workplace Culture Work Life Balance 1.8K claps 1.8K 3 Written by Software Engineer, Brazilian. Working for the New York Times. Working from home. How we design and build digital products at The New York Times. Written by Software Engineer, Brazilian. Working for the New York Times. Working from home. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-08-17"},
{"website": "NewYork-Times", "title": "in a confusing world context is key a times intern sets out to improve search results", "author": ["Aana Bansal"], "link": "https://open.nytimes.com/in-a-confusing-world-context-is-key-a-times-intern-sets-out-to-improve-search-results-7b2ceb07cde2", "abstract": "Code Data Product and Design Workplace Culture Work with Us The past few years have seen the rise of “context-aware” systems : technologies that can predict your intentions based on information about your environment. If you ask Google’s intelligent personal assistant, “How tall is that building?” it will use your phone’s GPS to see what buildings are near you and guess which building you are asking about. Or, if you add “pick up milk” to the Reminders app on your iPhone, you can choose to have the app remind you the next time you are within a block of a grocery store. This use of this technology is a response to one of the most challenging problems of human-computer interaction: humans are terrible at articulating what they want in ways that computers can process. We are used to communicating with other humans who largely exist in the same context as us — they are able to infer what we mean, even if what we say is ambiguous. Algorithms that interface between humans and computers must “guess” the human’s intention, which is the crux of information retrieval (i.e. search) problems. I took a stab at this problem during my internship at The Times last summer. In formulating my approach, I made an important assumption: because The New York Times is a news platform, it’s likely that when readers search for things on the website, they are looking for articles that are the most topical. This may not be a fair assumption for all use cases: a high-schooler writing a term paper may be looking for archived articles as primary sources, or a print reader may be looking for the digital version of a story to email to a friend. While these use cases do occur, they are much less frequent, so relevance to current news stories was a compelling objective. Currently, the search feature on nytimes.com uses Elasticsearch , which operates on a principle called “TF/IDF” (Term Frequency/Inverse Document Frequency). The basic idea is to determine the significance of each term in an article by looking at how many times the term is repeated, then dividing this by the number of times it appears in all of the documents in The New York Times archive. That way, common terms like “said” and “Mr.” are weighted less heavily than terms like “Amazon” or “Game of Thrones.” Articles are then ranked based on how significant the user’s query terms are to each story. So while the current approach may work well for scientific and encyclopedia articles, it’s not the best approach for news stories. This is because news stories don’t have a ton of repetition. Let’s look at this article published on August 1, 2017 in The Times’ Travel section that details how a restaurant at The Mohonk Resort was able to scale farm-to-table dining to hundreds of guests every night. This idea is summarized in the opening paragraph: Can you create a farm-to-table restaurant if you have 100 tables in an 8,750-square-foot main dining room, 80 more tables downstairs, nine in a cozy lounge, 50 outside overlooking an Arcadian lake and, on certain nights, eight in a capacious kitchen? Now, let’s look at the seven most frequently used terms in the article. Mr. Mohonk Palmeri New York Dining Restaurant The top five terms don’t appear in the first paragraph at all. Based on just term frequencies, the article could just as easily be a restaurant review or a profile of the chef, Jim Palmeri. Word counts don’t tell the whole story so it’s very difficult to tell how relevant a story is to current events just from this information. So how can an algorithm determine whether a story is topical or not? This is where we can use topic clustering. With this technique, an algorithm “learns” what the main dialogues are at the moment by looking at all of the articles published over a one or two week period. From this set of articles, it extracts the major topics, which are defined by a set of terms. Here are a few examples: Topic 1: Trump, staff, house, secretary, Kelly, director, communications, chief, press, President, white, Scaramucci, Spicer, Priebus Topic 2: Korea, north, nuclear, Pyongyang, missile, states, united, military, test, China, Korean, south Topic 3: affordable, Americans, would, people, percent, republicans, obamacare, health, plan, coverage, medicaid, insurers, insurance, care The above topic definitions are produced by using an unsupervised learning algorithm based on a Latent Dirichlet Allocation (LDA) model. I’m going to give a brief overview here, but if you’re interested in learning more, Edwin Chen has published an excellent explanation. Before we begin, let’s define a few things. Each article is distributed over a set of k topics. So if we let k = 4, this article may be 60% about the Republican Party, 20% about the 2020 election, 20% about President Trump and 0% about penguins. Each topic is defined by a distribution over the entire English vocabulary. So if the 2020 election is a topic, 10% of it may consist of the term “2020,” 5% would be the term “Pence,” 5% would be the term “Cuomo,” and so on. (In reality, these numbers are much smaller, around < 0.5%.) So, if 50% of an article is about the 2018 elections and 5% of the election topic consists of the term “Cuomo,” we would expect that 2.5% of the terms in this article are “Cuomo.” We begin by assuming that all the articles were stochastically generated in this way, meaning each term is randomly chosen from a given probability distribution. For each article, we decide how long it will be according to a Poisson distribution and what the topic mixture will be according to the Dirichlet distribution . In Bayesian statistics, we call this the prior because it’s what we believe about the data prior to doing any analysis. Our goal is now to backtrack to try to learn what the topic mixtures, P(T|D), and topic distributions, P(W|T), actually are. To help illustrate this, here’s some pseudocode: We perform this process thousands of times until we reach a steady state. At this point, we have a pretty good idea of what the current major topics are. I spent the second half of my internship developing a way to use these topic clusters to return more relevant search results. I’ll call the algorithm I built ClusterSearch. ClusterSearch maps the user query to a topic if any of the terms were one of the top 15 terms in the topic definition. There are more sophisticated ways to do this — you could take into account the weight of each term in the definition — but this method worked well for my project. Once ClusterSearch has determined which topics are relevant, it expands the user query with the top 15 terms from each topic’s definition. Finally it performs Elasticsearch on this expanded query, giving more weight to terms from the user’s original query. Let’s look at an example. I did topic clustering on all the articles from the last two weeks of July over 100 topics. Let’s say the user searched for “Simpson,” which maps to one topic definition. Here are the top 15 terms: O.J. Simpson receiving parole was a major story at the end of July. The numbers to the right are the term weights, so the term “simpson,” makes up about 5% of the topic definition. For now, ClusterSearch ignores those weights and just uses the top 15 terms. We expand the user’s query with these terms. So the new query becomes, “simpson former parole friend years prison robbery board nine vegas angeles hearing thursday nevada.” We boost terms from the user’s original query so “simpson” is weighted slightly heavier than the other terms. This way, even if different user queries map to the same topic, we may return slightly different results to emphasize what the user originally entered. Finally, we run good old Elasticsearch on this expanded query. Here are the top three results produced by ClusterSearch: O.J. Simpson Wins Parole, Claiming He Has Led a ‘Conflict-Free Life’ Simpson, Daniel Simpson, April And here are the top three results with Elasticsearch: Simpson, Daniel Simpson, April Simpson Manufacturing Company Inc. Daniel Simpson and April Simpson are both reporters who left The Times over a decade ago; Simpson Manufacturing is an engineering firm that produces construction materials, but nothing has been published about them recently. In short, ClusterSearch gives us more “topical” results which are more likely to satisfy the user’s intention. So how feasible is Topic Clustering? I ran 3000 iterations on 9853 articles over 100 topics. It took about 90 minutes on my CPU. However, we’re lucky because we only need to topic-cluster once to learn what the major news stories of the moment are so we can topic cluster offline. Running the algorithm once a week or even once a day is actually quite practical. Search algorithms are really difficult to assess for two reasons. You don’t know what the user was looking for There’s no “ground truth” to judge results against. A user searching for “New York” may be looking for travel guides or they could just as easily be looking for news about the upcoming gubernatorial elections. We can only guess. Different users have different preferences Even if you know what users are searching for, deciding the best ranking of articles can still be tricky. Should more recent articles go first? Should more relevant articles go first? These aren’t trivial questions. To really understand how well ClusterSearch performs, the next step would be to do some user testing. In addition, there are a few other things we need to do before it’s deployed: Learn optimal number of topics to cluster over. This can be done through Hierarchical Dirichlet processes Determine how frequently we should run the topic clustering algorithm. This will take some experimenting Integrate ClusterSearch into The Times’ search API. A huge thank you to everyone at The Times I had a chance to work with over the summer; every panel, coffee chat and event left me feeling inspired and excited. A special thank you to my managers John Daniels and Boerge Svingen; my team mentor, Jeremiah Via; my intern buddy, Will Dunning; and the Women in Technology Task Force. I was lucky to have such a wonderful set of mentors and friends to guide my internship. It was an incredible summer interning at The Times. If you have any questions, feedback or want to hear about the time Nicholas Kristof caught me pointing him out to friends in the cafeteria, feel free to get in touch with me at aanab@princeton.edu How we design and build digital products at The New York Times 142 Machine Learning Data Science Search Elasticsearch Code 142 claps 142 Written by Applied Math @Princeton ’18, Founder @PulsePal — I’m passionate about data science, healthcare, open access to information, and diversity in tech. How we design and build digital products at The New York Times. Written by Applied Math @Princeton ’18, Founder @PulsePal — I’m passionate about data science, healthcare, open access to information, and diversity in tech. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-04-26"},
{"website": "NewYork-Times", "title": "improving our video experience part two our live streaming platform", "author": ["Flávio Ribeiro"], "link": "https://open.nytimes.com/improving-our-video-experience-part-two-our-live-streaming-platform-68d27104e844", "abstract": "Code Data Product and Design Workplace Culture Work with Us By FLAVIO RIBEIRO , JOHN WHITEHEAD , SAID KETCHMAN This is the second post in a series about the progress and achievements of our video delivery platform. It will focus on detailing the problems we solved on our live video streaming platform. Our first post was Part One: Our On-Demand Video Platform . When we first started broadcasting live streaming events at The New York Times , Flash was still a thing. We used proprietary protocols and components from the signal reception to the delivery. At the of end 2015, we decided to remove Flash components from our video player and switch to HTTP Live Streaming (HLS) as our main protocol. During the 2016 presidential election cycle, the newsroom expressed interest in doing more live events, including the coverage of live debates on the homepage and live blogs. With a mindset of making live events easier and more affordable for the company in the long run, the video technology department decided to invest more in the infrastructure and bring the signal reception and streaming packaging in-house. We upgraded our on-premises video recording and streaming appliances to a multichannel GPU-accelerated server. With this physical all-in-one solution in place we had more flexibility to set up and broadcast live events, including streaming and serving our content to partners such as YouTube and Facebook. Most of our live content is produced by third parties on location and sent to us at broadcast quality. For example, if we want to stream a press conference from the White House, we make use of our subscription to the network television pool feed. Depending on the event, the feed may be a single camera angle or a more polished “line cut” switching between multiple angles. The feed is delivered via a point of presence local to the event, which we can route to New York City. This can be expensive, since it is a dedicated circuit transmitting uncompressed HD-SDI signals, but it gives us the highest quality and most flexibility. This way, we avoid the delay and image degradation from extra compression/decompression passes and the potential IP packet loss of transmission over the public internet. The signal is then delivered to our main building via one of our dedicated video fiber lines. Once in our building, the signal is sent to our live encoding server. Our current solution can simultaneously encode up to eight HD-SDI feeds and distribute to any format needed. For the live streaming events that we broadcast on nytimes.com, we use our live encoding server to generate six different HTTP Live Streaming (HLS) outputs from the incoming feed. The outputs are composed of H.264/MPEG-TS segments of 3 seconds length in a range of bitrates and resolutions. This allows our video player to adapt and select the best output based on a user’s current connection and device capabilities. We also set the creation of the manifest (M3U8) files of each output in appending mode, where the manifest aggregates all video segments from the beginning to the end of the transmission. This is preferable to rolling mode, since it enables us to do an extremely fast switch on the video asset from live to video on-demand (VoD) once the event is over. From the same input used on the live streaming events, we also generate an Apple ProRes QuickTime output on our shared Storage Area Network (SAN), which our video editors use for chase editing during the live event or for cuts after. As shown in the picture below, after our Live Encoding Server generated each individual MPEG-TS segment, they would then be sent individually over the open internet to our CDN. Each packet was sent using HTTP, and our NetStorage/CDN was responsible for hosting, caching and serving the assets. The transmissions of the election debates and related events went well, but the number of requests to the CDN proved to be a problem: some players were getting stuck buffering as the M3U8 manifests were taking too long to be updated with new segments. We investigated the cause, digging into the live encoding server logs, and began to notice a pattern of errors when pushing segments over the open internet via HTTP PUT. Even after setting automatic retries, since we shared the same internet connection for operations and development in our office, we found that the live feed was competing for bandwidth with other network activities. We needed a more robust approach if we wanted to continue streaming live events. Another major pain point was the need to have technical staff in-house during live events setting up the feeds and making sure we were live streaming to the right endpoint and saving the Apple ProRes QuickTime version on the right path. The process was mostly manual and very stressful. The truth was, we needed a simpler and more resilient way to create, start, and monitor live events. It had to be easy enough that someone with very little technical knowledge could intuitively manage our events. The delivery challenge we faced was due to the very nature of the HTTP protocol over the open internet. After discussing possible solutions with our networking team, we realized our best bet was to avoid the internet all together for delivery to our CDN. Instead, we decided to leverage our Direct Connect with Amazon Web Services, solving our bandwidth and latency issues. Direct Connect is essentially a dedicated network connection that allows for consistent performance between our building and Amazon Web Services. Unfortunately, we didn’t have it enabled for S3 (where we wanted to store our video segments), but we took an approach of proxying via EC2 (which was enabled for Direct Connect). Since our connection to our EC2 proxy was dedicated, and the same for EC2 to S3, we eliminated the chances of packet loss over HTTP. As a bonus, we open-sourced the service that we created and called it the s3-upload-proxy . After the segments were available on S3, we configured a caching layer for spreading the content around the world. Our second challenge was the need for technical staff to be on-site and available during each of our live events. In order to avoid this, and reduce the number of error-prone manual steps involved, we decided to implement a Live Streaming Manager. It consists of a web application that is responsible for talking to our live encoding server and coordinating with other components through REST API calls. Although the entire application hasn’t been open-sourced, we did make available our elemental-live-client , which allows for easy interactions with the encoding server we use. The actual design of the application was meant to be user-friendly and simple. It consists of three different screens, that allow a user to create, operate, and end their live streaming event. Below is a short breakdown of each of these screens: Event Setup Screen : It allows anyone to preview the inputs, decide whether they want to ingest the stream to partners and schedule or start the event. Operation Screen: It allows the one in charge of the event to preview how the event is showing up for the audience on our internal player, tweak the volume of the input, and stop the event. Trim Screen: It shows up right after finishing the event. This allows us to remove pre-roll and post-roll that we don’t want to keep for the on-demand version. The interface makes it possible for editors to mark the start and end of the event and republish the video asset quickly without re-encoding the entire program. This way, users that view the video after the event has completed are able to watch from the beginning without having to skip past uninteresting setup and delays. This project has been a huge success and so far, we’ve successfully managed over 100 live events using it. We would like to support DVR actions in our video player during live events, much as we do for VoD content. Since we are already generating the HLS level playlists in appending mode, as mentioned earlier, we are just one step away. All media playback engines we use on our players are able to seek, so we essentially just need to expose the functionality for the users. For our Live Streaming Manager, our team requested additional features, such as integrations with more partners and the possibility to clip straight to social media networks. For our last post in the Improving Our Video Experience series, we will explain how we added Closed Captioning support for our videos, including on our web and native players. We’ll also cover how we added accessibility support for our player’s controls. How we design and build digital products at The New York Times 303 Live Streaming Http Live Streaming Cdn AWS Online Video 303 claps 303 Written by Brazilian, Senior Director of Engineering at ViacomCBS. How we design and build digital products at The New York Times. Written by Brazilian, Senior Director of Engineering at ViacomCBS. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-02-07"},
{"website": "NewYork-Times", "title": "how we manage new york times readers data privacy", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/how-we-manage-new-york-times-readers-data-privacy-d39627d79a64", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Kelsey Johnson When I first started working on the Data Governance team at The New York Times in 2017, I would often be met by blank stares when I tried to explain my job. Over time, I perfected my elevator pitch: I work on privacy, ethics and governance at The Times, and it’s a bit like herding cats . As the second member of The Times’s Data Governance team, I dove straight into the high-profile General Data Protection Regulation (G.D.P.R.) project , which required that our organization follow strict ground rules for handling the personal data of our users located in the European Economic Area. Our two-person Data Governance team collaborated with colleagues in Program Management and Legal to discover every way our business operations were processing the data of our users, while creating and implementing rules to honor our users’ G.D.P.R. rights. A small group of colleagues, over 70 product teams and five months to get it all in place. Don’t let anyone tell you herding cats is easy. G.D.P.R. was just the beginning. There are now over 100 privacy laws in other countries . In the United States, there are numerous bills that have either been introduced into state legislatures or have been signed into law. Not only do each of these laws apply to specific geographic regions, but they each tend to have their own unique requirements. This means that companies like The Times have to implement complex sets of rules to ensure their websites and apps are in compliance no matter where users are located. New regulations often go into effect with short grace periods, so companies have very little time to make changes to their technology stacks. Because technology is constantly evolving, legislation will need to adapt as technology changes. This means companies need to be ready to modify their interpretations of the law anytime a law gets amended. That leaves companies with two options: to reactively respond any time a change is required, or to invest in privacy as part of their business strategy and dedicate resources to the task. The Times has chosen the latter. It was 2019 when we retired our cat-herding hats and harnessed our brain power to build PURR: Privacy, Users, Rules and Regulations. PURR is our homegrown system that operationalizes The Times’ privacy offerings. The system centralizes our business logic and rules, and it communicates with our front-end products, instructing them on how to carry out the privacy rights of each unique user that visits us. It also connects to an internal preferences system that allows us to securely save and sync logged-in users’ privacy preferences across all of our products. [We’re hiring. Come work with us !] This enables us to easily and efficiently adjust our interpretations of data regulations and it simplifies the implementation of such changes across our suite of products. Because of PURR, we have said goodbye to year-long privacy projects and roadmap disruptions whenever a new regulation is passed. Now, a single team can independently implement most changes. Purr-fect, right? I like to think of PURR as a privacy machine. It consumes information about a reader, analyzes that information based on knowledge it has been given about our company’s interpretations of privacy regulations, and then outputs instructions on how that reader should be treated from a privacy perspective when they interact with one of our products. Each Times product, such as News, Cooking or Games, is required to ask PURR for instructions on how to treat every single reader that visits. These instructions are called Directives. There are several types of directives that a product needs to be given when it comes to privacy — right now, there are eight. We have broken them down into two categories: user interface directives and data handling directives. The former tells products when they need to show a certain element on the page, such as a cookie banner, a marketing consent checkbox or an opt-out button. The latter tells products how to handle a user’s personal data. For example, a data handling directive might block certain third party tracking mechanisms from collecting data about a user. Directives are sent via three different methods: request headers, a cookie called `nyt-purr` and JSON. These give Times products the flexibility to choose how they want to consume the information from PURR. Let’s say you are in Europe and you visit our NYT Cooking homepage to get some inspiration for your weeknight dinner. Upon loading the page, you will be shown a banner, like this one. This is what we call our G.D.P.R. Tracker Banner. NYT Cooking showed it to you because it received the “user-interface” directive called PURR_DataProcessingConsentUI from PURR. When you loaded the page, PURR knew you were in Europe and G.D.P.R.-eligible, so it delivered a value of show with the PURR_DataProcessingConsentUI directive, which told our products to present you with a banner that allows you to opt in or opt out. If, however, you visited NYT Cooking from New York City, the directive would have delivered a value of hide . This is just one example of a directive. Some other examples include PURR_AcceptableTrackers , which tells products what type of trackers can be fired when a user visits a page; PURR_DeleteIPAddress , which instructs our first-party analytics tool whether to delete the IP Address of a user; and PURR_AdConfiguration , which tells products what types of ads are permitted on the page, such as non-personalized ads instead of behaviorally targeted ads. For PURR to know what directives to issue to products, it needed to be programmed with privacy logic, which we refer to as Rules. The Data Governance team works in collaboration with the Times Legal and Engineering departments to write these rules. Rules are written expressions that PURR must evaluate. They can become quite complex, but a rule basically says, “Hey PURR, you need to look at those inputs, and when these circumstances are met, you need to issue these specific directives.” It’s because of rules that we can provide a custom privacy experience to every user who visits our site. Let’s go back to the NYT Cooking example. In order for PURR to know whether a user needs to be shown our G.D.P.R. Tracker Banner, it first needs to know whether the user is located in a country that is subject to the G.D.P.R. and whether they’ve already opted in or opted out. In plain text, the rule would be written like this: IF user is in a G.D.P.R.-eligible country AND user has no set preferences with NYT, THEN show banner. In SQL, the rule gets translated into the following expression: In order to operationalize Rules and Directives, we needed systems that could bring them to fruition. We first had to find a place where we could write and save the rules — a rules producer, of sorts. Luckily for us, we didn’t have to build anything from scratch. In recent years, The Times had built ABRA (which is short for “Abra Basically Reports ABtests”), our homegrown testing and targeting platform. Because ABRA provides the ability to translate human-friendly rules into a widely adopted, open-source and machine-friendly format, it was a simple engineering choice to expand its capabilities to support PURR. In addition to a system that would allow us to write and save the rules, we needed a way to run the rules. We refer to these as Rules Executors, which ingest the ABRA rules and execute on those rules in order to send directives to our products. Because the Times has over 70 products and a diverse landscape of technical stacks, we wrote three separate Rules Executors: one for products under the nytimes.com domain that use Fastly; another for products that are under the nytimes.com domain but do not use Fastly; and one for products not on the nytimes.com domain, such as our vendor-managed sites. It’s important to note that the PURR system does not stand on its own. It relies on several other capabilities within The Times’s data and core platforms, such as a homegrown system that keeps track of our user’s data privacy preferences. It also interacts with Samizdat, another homegrown system that our native apps leverage to integrate with PURR. And lastly, we built a customized AMP-PURR endpoint which allows us to integrate with our Google AMP products. We have proven that PURR can adapt as new privacy laws are passed. When the United Arab Emirates passed a data privacy law in the summer of 2020 , we were able to bring over 60 products into compliance within four working days and with zero roadmap disruptions to the product teams. When Brazil’s privacy law came into effect shortly after, it took us only one day to ensure our products were compliant. Over time, we hope to implement new directives that foster privacy-forward features in our products. And as The Times explores new product offerings, such as NYT Kids , we believe PURR will be a reliable way to ensure such products are ethically built while also meeting strict legal requirements. Although our cat herding hasn’t been reduced to zero, we have learned that implementing data governance regulations doesn’t need to be a resource-zapping, roadmap-destroying burden. It can be an opportunity to innovate and provide users with a privacy-focused digital experience. If you’d like to learn more about PURR, check out a full talk we gave at a recent Privacy_Infra() event. And if you are seeking to expand your network of privacy peers, don’t hesitate to email us: data-governance@nytimes.com! Kelsey Johnson works in Data Governance and Privacy at The New York Times, where she and her team are tasked with leading their company’s data privacy and protection efforts. She likes to think of her work as “ethics at scale.” She is a civil engineer by trade (a proud Bucknell Bison and VTech Hokie) and has past experience working in the engineering and insurance sectors. Prior to joining The Times she spent a year in Seattle pursuing her passion for female empowerment through education. Kelsey loves running (a proud marathoner), spending summers by the ocean or in the mountains, and is a devoted sea glass collector. Follow her on Twitter and LinkedIn . [If this type of work is interesting to you, come work with us !] How we design and build digital products at The New York Times 135 1 Data Privacy Privacy Software Development Data Code 135 claps 135 1 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-05-13"},
{"website": "NewYork-Times", "title": "meeting tony giaccone senior software engineer at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-tony-giaccone-senior-software-engineer-at-the-new-york-times-56ce6f213a87", "abstract": "Code Data Product and Design Workplace Culture Work with Us What are your pronouns? He/Him What is your job title and does it mean? Senior Software Engineer. It means I have significant experience and I can not only solve complicated technical problems, but I can also mentor and provide guidance to other engineers. How long have you been at The Times? On July 15th, it will be eight years. Most Times employees are working remotely right now. What does working from home look like for you? I have an office in my home. I also have a nice window to the outside world that includes a bird feeder; A look to the right and I’m virtually outside. Working from home essentially means I enter my work space, log into my laptop and get started. But before I start, I usually take the dog out for a walk and then I make coffee, so getting in the rhythm of work means grabbing my coffee and reviewing the tasks for the day. My day usually starts with a good morning announcement in our group’s development channel on Slack. Back in the 1990s, when I got my first job where I could work from home, I learned pretty quickly that the best thing about working from home was that my bedroom was 20 feet from my office, and the worst thing about working from home was that my bedroom was 20 feet from my office. Nothing has changed since then. How do you start your day? I check our Slack channel to see if the clients who use our services contacted us about anything, then I check email. After that, I scan Slack to see if any of my teammates had anything to say while I was away and then I review yesterday’s work and get ready for our stand-up. What is something you’ve worked on recently? Our subscriptions system is part of a larger monolith known as Plato. We are in the process of building a microservice to extract from Plato the management of subscriptions that come to us from Apple through iTunes. So today, I’m working on extracting information about the subscriptions from the Plato database and figuring out how to get that data into the new microservice database. Tell us about a project you’ve worked on at The Times that you’re especially proud of. About two years ago, we built a microservice called the Cohort Manager, which allows us to adjust subscription packages in response to marketing, production or pricing changes. For example, when a reader purchases a New York Times subscription, they choose a particular bundle of products, such as seven-day home delivery or weekend-only delivery. Sometimes we need to update the bundle for a subset of subscribers, like when a newspaper distributor decides to stop offering Saturday deliveries to a particular region. To respond to this change, we would have to move readers subscribed to a bundle with a Saturday delivery to a bundle without a Saturday delivery. It used to be that these changes had to be done by hand, but now the Cohort Manager moves the list of subscriptions from the original bundle to the new bundle. This was the first microservice we built, and I had an instrumental role in making it happen. It’s been working consistently for over two years with very few errors. What is the biggest challenge you faced in your career and how did you overcome it? Knowing what you know now, would you do things differently? I had a significant health problem arise a couple of years ago. It had a big impact on me and I didn’t do a good job of communicating with my team about my need for time away from the office. It caused a great deal of tension on my team at the time, and I was responsible for not explaining what was happening to my colleagues. Knowing what I know now, I would be more communicative with my team and perhaps take some time off when dealing with these types of situations. What was your first job? My first computer-related job was in 1979 when I worked for a small retail computer store called Mr. Computer. I was the service manager and I was responsible for both working on the floor selling computers, and for dealing with repairs and returns if customers had issues. I had this position for a little over a year and I learned a lot about how computers work and how to deal with people. The highlight of my job was a trip to King of Prussia, Pennsylvania. I drove from Poughkeepsie, New York to King of Prussia in my 1967 Triumph Spitfire. I took a three-day class on how to repair the Commodore PET, one of the very first personal computers that was a contemporary of the original Apple (which we also sold). It was my first time traveling for work. What is something most people don’t know about you? In April of 1984, I was working in Boca Raton, Florida on a co-op assignment through my school, the Rochester Institute of Technology. On the 6th of April that year, there was a launch of the Space Shuttle Challenger. I drove up the night before and parked on the road about 10 miles from the Kennedy Space Center. I was parked by myself that night, but when I awoke the next morning, there were cars parked all along the road. At 8:58 a.m., we all got to watch as the Challenger launched. It was probably one of the most amazing things I’ve seen in my life. Listening to hundreds of cars radios all tuned to the same broadcast was something I’ll never forget. Do you have any favorite life hacks or work shortcuts? Simplify and isolate. When you’re having a technical problem, or you’re trying to understand how a new framework works or how a new piece of technology is manipulated, the best thing you can do is simplify it to its essence. Extract your work from the bigger problem and isolate the solution so that it’s focused on just the one thing you need to figure out. By doing this, you make the number of variables you have to figure out as small as possible. This technique — simplify and isolate — has served me well for most of my career. What is your superpower? There are no superpowers; there is only observation and your own mental model of how things work. Find a path that describes the situation, take the model you have in your head — that is, your understanding of how things work — and bend it, twist it, change your viewpoint. Try to find the place where your model and the world clash, then figure out what you need to change to account for this new observation. Divide and conquer. What or who are you inspired by? My parents inspire me. At 85 and 88, they are still terrific people to whom I owe so much of who I am. My father spent 25 years at IBM as a programmer (what we called people who do my job back when things were complex in different ways). And my mother worked both in the home and as a computer lab manager for the local community college. I take inspiration from how they have lived their lives and aspire to be as good a person as I can be . Complete this sentence: Over time, I have realized __________. There’s often a push to bring new ideas to market as quickly as possible, and in my professional experience, there is often immense pressure to rush new features into production. However, a feature that has been coded for the purposes of demonstration might not stand up to the demands of production code. One solution I have found is to implement a proof of concept in a technology stack that isn’t available for use in production. In doing so, I can quickly demonstrate the feature and potentially expose its pitfalls. And because the technology stack isn’t approved for production work, I can be reasonably certain that this lightly engineered and potentially weak proof of concept isn’t going to be rushed into production before it’s ready. Another solution we use extensively at The Times is to limit the scope of new features to a minimum viable product, or MVP. This reduced set of capabilities is more easily engineered and can be tested in production. We often try these MVPs out with a small portion of users to see if it makes sense to continue down that path. The advantage of this technique is that the time to market is reduced and redundant work is avoided. What is your best advice for someone starting to work in your field? Software engineering has grown exponentially for my entire 35-year career. The number of developers doubles every five years. Keep those numbers in mind. In five years in this business, you’ll have more experience than half of the people you meet. Technology changes significantly every two to three years. So, if you want a long-term career, keep your mind focused on how you analyze problems and don’t get too wrapped up in the technology. Chances are good that your problem-analysis techniques will last your entire career, but your technical skills will change every five to seven years. Meeting… Ahmed Bebars, Lead Software Engineer at The New York Times Meeting… Vanessa Jiménez, Associate Software Engineer at The New York Times Meeting… Cindy Taibi, Chief Information Officer at The New York Times How we design and build digital products at The New York Times 48 1 Nyt Open Meeting Software Development Software Engineering Personal Development Work 48 claps 48 1 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-05-06"},
{"website": "NewYork-Times", "title": "4 steps to win advocates and implement a technical change", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/4-steps-to-win-advocates-and-implement-a-technical-change-b2a9b922559b", "abstract": "Code Data Product and Design Workplace Culture Work with Us This is part one of a two-part series on how The New York Times Android team implemented several major library migrations. To read the technical details of the change, see part two here . By Lauren Yew Last year, many of the Android teams at The New York Times had an ongoing debate: should we use RxJava or Kotlin Coroutines and Flow? While the question was simple, the answer and technical solution were not. We were using both in our client apps and RxJava in our core libraries, which meant we had two fragmented technologies to support. My team, the App Platforms team, manages the core libraries and features that are used by Times mobile app teams, and part of our responsibility is to model technical best practices. We wanted to work with our Times Android colleagues to choose the best solution. Many of our colleagues believed that migrating to Kotlin Coroutines would improve performance , the readability of our code, increase developer velocity and speed up unit testing. But, some of our colleagues preferred to stick with RxJava because of its many features. We needed to first build consensus across all of the Android teams on what technology to use as a best practice. The App Platforms team’s hypothesis was that Coroutines would be the better option for our core libraries, however, we couldn’t rush towards implementation because any technical change to our core libraries could have cross-departmental effects. In addition to building consensus, we had to articulate how the change was worth the product roadmap disruption and the shift in developer practices, and how it would positively impact our business goals. Here’s how we did it. Determine the level of effort Our first step was to determine the level of effort it would take to make these changes. We looked at where the changes needed to happen: in new features, in legacy code and across several apps and teams. At The Times, we use T-shirt sizing for the level of effort : small, medium, large and extra large. Knowing how long things will take helps establish a timeline for the change and allows teams to define the work based on priority, dependencies and difficulty. T-shirt sizing does not have to be exact — it helps to approximate how long a project will take. A good rule of thumb is if the size of a given problem is greater than medium, the problem itself needs to be split or spiked to get a more reasonable, smaller estimate. For the Kotlin Coroutines project, the total project T-shirt size was large because we needed to migrate over four legacy core libraries and integrate them into our client News app. From there, we split each effort into the specific libraries that needed to be migrated (size: medium) and the integration (size: small). Get everyone on board Because we wanted to make changes that included new features, refactoring old code and future-proofing, we had to identify who needed to be convinced that this work was important. We needed advocates in Product to prioritize the work, partners in Engineering who could provide feedback and share the workload, and support from QA to identify any testing concerns. Product and Engineering were interested in Coroutine’s promise of performance improvements and increased developer velocity. QA approved the proposal to integrate regression testing as well as the improvement in unit testing. Assess the idea and get feedback We use a Request for Comments (RFC) process at The Times whenever an engineering team sets out on a big project. The idea behind an RFC is to document the changes we would like to make and to get feedback from our peers. This exercise includes documenting and addressing any drawbacks or alternatives to the proposed solution, and it helps prepare us for any issues that might arise. As part of our RFC, we considered drawbacks and we proposed solutions: To use Kotlin Coroutines and Flow , all files would need to be migrated from Java to Kotlin. We already had an engineering decision that we wanted to move to Kotlin and any files that had to be changed should be moved to Kotlin, so this ended up being a non-issue. The time and effort required to do the conversion were significant , and making new features might slow developer velocity. However, the benefits from the conversion — improved performance, easier testing — outweighed the level of effort and made the project a high priority for the product team. The new technology would also help developers improve their velocity over time. Some teams still using RxJava needed a way to access the new Kotlin Coroutines and Flow APIs. We proposed using kotlin-coroutines-rx2 library , as well as backwards-compatible RxJava APIs (that use Coroutines behind-the-scenes) to support teams who could not migrate immediately. By going through this RFC process for the migration, we were able to address concerns that came up around our technology change. The App Platforms team uses tech spikes to create proofs of concept. We try to keep our tech spikes to a maximum of five working days. If our spike appears it might take longer than five days, we reevaluate the problem and think about ways it might be broken down into a more manageable bucket of work. The data generated from a spike can help strengthen the case to make a technical change on a larger scale. For us, quantifiable results can come in many different forms: The change reduces the number of crashes or bugs. For example, if the app routinely crashed, we could compare the original build (with crashes) to the spike build (without crashes) and document the percent-change in results. The performance improves across different metrics , such as speed, CPU, memory, thread usage and network data usage. The change makes developers’ lives easier . There are fewer lines of code that have to be written, code test coverage percentage changes and developer velocity improves. To provide quantifiable evidence that our migration to Coroutines would improve our app, we set up a five-day tech spike. In a small core library that integrates with The Times News app, we migrated all instances of RxJava to Coroutines, updated the unit tests in the app and integrated into a sample app and the News app on a branch. Then we used Android Studio’s Profiler to compare the average CPU, memory and thread usage of the branch with the News app. We also put in code timers to calculate the differences in timing. With our spike results, we saw an improvement of 34 percent in CPU usage, 13 percent improvement in memory usage, 12 percent improvement in thread usage, and 21 to 63 percent improvement in speed on parts of our News and sample apps that touched the updated library. With this strong performance improvement data, we were able to reinforce the enthusiasm of our advocates and convince those who were skeptical that migrating our core libraries to Coroutines and adopting Coroutines as best practice threading technology across Android teams was the best move. Once we knew that we would move forward with the conversion to Kotlin Coroutines and Flow, we had to set up a timeline for the work. For us, our plan consisted of these steps: Define the timeline . A timeline makes it easier to envision and enact a plan. It also prevents dependency conflicts and keeps track of work in progress. Short timelines are best (half a year, at most. Tech fatigue is real). Our timeline started after our RFC (which took about one month to spike, write and approve), and we planned for about two months of work. Incremental plans are best. We found that breaking a large plan into smaller pieces that could be developed, completed, merged and then improved upon later allowed us to achieve each goal faster and avoid a giant, unmergeable branch. Our migration plan was broken into separate core library releases and integrations. We then had several developers working on each library in parallel and created a flexible timeline with other library changes. Think backwards-compatible . Some of our client app teams were not ready to move away from RxJava. So, we created RxJava-compatible library modules for them to use, and suggested using the kotlin-coroutines-rx2 library as a workaround to allow developers to transition between RxJava and Coroutines. Ensure a smooth transition . Consider the level of effort for all teams involved, such as QA, and communicate widely about the changes coming up. To reduce bugs, we worked out the testing plan for feature branches with our QA team and added unit test coverage requirements. Record quantifiable results . These can be used to demonstrate the value and impact of the work being done to management. As we completed each migration, we measured and published the results of the work, making sure the changes were creating performance improvements. All core library releases included release notes as well as updates by our devs to the working team at large of any breaking API changes or library releases. Each change also included performance testing, as well as documentation. As we worked through our game plan, we demoed the performance improvements for the entire team — gaining advocates in product, engineering and management along the way. Once we got engineering and product approval to add our proposal to the roadmap, we consolidated our working group to divide up the work. During the migration process, we kept an eye on our proposed timeline to make sure we didn’t have any scope-creep or blocked items. The migration vastly improved different areas of our core libraries and News app integrations. Kotlin Coroutines sped up feature creation, significantly improved app and library performance, and simplified unit testing. Moving forward, we’re building all new core libraries and features with Coroutines and Flow and refining our best practices working with Coroutines. We’re also working with the Cooking app team in an advisory capacity as they migrate to Coroutines. Overall, we believe that the work we did to assess, prove and create a proposal for change is paying off in dividends. Lauren Yew is a Senior Software Engineer working on Android with the App Platforms Team at The New York Times. Lauren is a tech lead in the efforts to improve the shared core libraries used across the News, Cooking and Games apps. When not at work, Lauren enjoys training her three dogs. You can follow her on Medium , LinkedIn or her personal website . Thanks to Wojciech Dziemianczyk. How we design and build digital products at The New York Times 1 Android Software Development Engineering Kotlin Android App Development 1 clap 1 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-05-13"},
{"website": "NewYork-Times", "title": "threading at the speed of light", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/threading-at-the-speed-of-light-6ae31257307a", "abstract": "Code Data Product and Design Workplace Culture Work with Us This is part two of a two-part series on how The New York Times Android team implemented several major library migrations. To read the high-level overview of how they made it happen, see part one here . By Lauren Yew When a reader opens The New York Times on Android, our app makes a series of calls to our core libraries. Each feature that is rendered for the reader might depend on multiple back-end calls, user input and other parallel business logic flows. To ensure that our readers are served with a fast and reliable mobile app experience, we do a lot of asynchronous work, or threading, within our app. We use our threading technology to not only offload network calls and heavy business logic, but to also chain together complex sets of processes that are updated at different times and can affect multiple observing business logic flows. For the last few years, The Times’s Android teams have used both RxJava and Kotlin Coroutines and Flow for threading in the core libraries that power our News, Cooking and Games apps. To unify our stack, we decided to choose one technology and dug into the performance differences between RxJava and Coroutines. While RxJava was a powerful tool, its CPU, thread usage and general complexity as a language made it an increasingly cumbersome technology for our needs. We have monitored the progress of Kotlin Coroutines and Flow and determined that it not only covered all of our feature needs, but it also had significant performance improvements. In order to iteratively migrate our apps and libraries to Coroutines, we first needed to update our core libraries. Here are some best practices we developed during our migration. Use Coroutines suspend for basic threading When we migrated to Coroutines, we found that whenever we needed to use basic asynchronous code that returned a single result (or a RxJava Single ), we could replace that code with an equivalent suspend function . For example: Example RxJava vs. Kotlin Coroutines: ControlledRunner pattern to handle multiple calls to same function While we were migrating, we ran into multiple cases where we had several suspend functions that needed to join and wait for a single result. This was particularly important for situations when we had multiple calls in parallel for the same user-state information and we needed to avoid flooding the back-end with calls. Instead of making duplicate calls for the same result, we used the ControlledRunner pattern . The pattern’s joinPreviousOrRun function will discard any new tasks and have the calling task wait on the result of the original task. This is useful if several areas have made the same call and expect the same result. We also used ContolledRunner’s cancelPreviousThenRun function to cancel old tasks and always run the latest task — which helped in situations where a new event supersedes the previous event. Using Flows for reactive or observable streams When we needed a function that could emit multiple values at different times, we used Kotlin Flows . Flows are very much like RxJava Observables: collect{...} or collect() acts like RxJava’s subscribe() . We used mapping functions to update the result or onEach{...} to create side effects for each result. launchIn(scope) was very helpful to launch and collect the Flow in a given scope so we didn’t have to nest our Flows in a scope.launch . We made it a best practice that our library APIs always use Flow<T> in their client-facing interfaces to prevent outside sources from interfering with our Flow business logic. In order to avert memory leaks or using up our thread pool, we needed to prevent long-running or duplicate Flows. To do this, we made sure to cancel the Flow’s Job when the lifecycle of the object finished. Here’s some examples of Flow patterns: Handling Lifecycles and Scopes When possible, we tried to use the built-in Android lifecycle-aware scopes (such as viewModelScope or lifecycleScope ), which are automatically cancelled and cleaned up with the Android lifecycle. If we made our own scope within a class, we had to remember to cancel it. So, we found it was more efficient to make suspend function APIs and call them from the view model or lifecycle-aware scopes. (This also helped us with unit testing because we could test the functions directly in the unit test instead of trying to access them from the encompassing class.) Passing Dispatchers in Class Constructors We often had to switch between Dispatcher types : using IO Dispatchers for network calls, default Dispatchers for most business logic and Main Dispatchers for UI updates (because Android will crash if there is a UI update on a non-Main thread Dispatcher). When we unit tested our suspend functions , we found that passing the Dispatcher types through the class constructor and providing the TestCoroutineDispatcher to our class constructor helped us easily mock our asynchronous suspend functions. Some of our client apps contained legacy RxJava code that wasn’t quite ready to migrate to Coroutines. To support this, we used the kotlin-coroutines-rx2 library to convert between RxJava and Coroutines. The library’s rxSingle and rxObservable functions converted our Coroutines suspend functions into RxJava, and the await() or asFlow() methods converted RxJava into Coroutines. One important note, however, is that while the library does create both threading services, it does not replace the work of manually migrating code from RxJava to Coroutines. It was simply a workaround that allowed us to iteratively migrate parts of our code to Coroutines, while leaving the remaining parts in RxJava. One of our challenges was migrating legacy RxJava unit tests to Coroutines. When dealing with unit tests that were previously for RxJava Single results, we used runBlockingTest to make our new suspend functions run consecutively and return the results. When working with Flows that used to be RxJava Observables, we used a TestCollector pattern (see example below) to gather and verify the values from our Flows. When we hit a roadblock in getting our expected results from a Flow, we found that most often the issue was that our Flow was not using the TestCoroutineDispatcher in its scope. Having another Dispatcher in use caused the test to fail or be flaky (since it was not a mocked test Dispatcher but a real threaded dispatcher). Here’s an example of a suspend method test and a Flow test: With each migration to Coroutines, we saw performance improvements in speed, memory usage, CPU and thread usage. Using Android Studio’s Profiler, we ran debug branch builds to compare our app’s performance before and after the migration. To get reliable metrics, we averaged over six user sessions with the same steps and the same user states. For more accurate timing data , we used coded metrics that were already built into our app. Our production metrics captured start-up time, along with feature-open and feature-load timing. Since these metrics were gathered from production, the amount of data captured allowed us to average across different devices, locations and user sessions. Here is an example of results from one of our larger core library migrations: Migrating from RxJava to Kotlin Coroutines opened up new opportunities and improvements for our app and development teams. Because we are now able to take advantage of the powerful threading of Jetpack libraries like Room and Lifecycle, we can set up and query databases with a couple lines of code and we no longer have to worry as much about lingering threads outside of lifecycles. We have been using Coroutines to revisit our app architecture patterns: cleaning and simplifying them, and improving our test coverage. As each migration and iteration completes, our threading work becomes faster and more reliable, so our readers can experience Times journalism and the background work truly stays hidden in the background. Lauren Yew is a Senior Software Engineer working on Android with the App Platforms Team at The New York Times. Lauren is a tech lead in the efforts to improve the shared core libraries used across the News, Cooking and Games apps. When not at work, Lauren enjoys training her three dogs. You can follow her on Medium , LinkedIn or her personal website . Thanks to Wojciech Dziemianczyk and Fabio Collini. How we design and build digital products at The New York Times 4 Android Android App Development Code Software Development Kotlin 4 claps 4 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-05-13"},
{"website": "NewYork-Times", "title": "we dont get bitter we get better", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/we-dont-get-bitter-we-get-better-b5d2783d5cd3", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Tim Burke When The New York Times launched its first website in 1996, it had already been using software to send the layout of the next day’s paper to the printing presses. The website introduced some basic web technology into The Times’s portfolio. Twenty-five years later, that portfolio has grown to include systems that deliver articles, documentaries, newsletters, games and recipes, both online and in print, to millions of readers every day. It’s a technology landscape that is diverse and complicated. Our systems use both bleeding-edge and legacy technologies that are deployed to multiple clouds and data centers all over the world. Because of the breadth of Times products, our engineering teams have the freedom to make their own decisions about their technology stacks and the architecture of their systems. As a result, some of The Times’s systems have been around since before Amazon Web Services had a web console, and other systems use the latest tools from Google Cloud Platform. With such a broad portfolio comes a range of operational thinking and preparedness across our engineering team. Over the past couple of years, the Operations Engineering team (formerly Site Reliability Engineering) has worked to foster a culture of operational maturity that allows our engineers to efficiently build and maintain our technology while ensuring that we deliver a consistent experience to our readers. Part of our work has been to define what operational maturity means in the context of The Times. For us, it is requiring teams to take a hard and objective look at their practices and ask, “ how is she though? ” Does a system have a disaster recovery plan? Does a system have a failover configuration in place in the case of a cloud provider outage? Does a team ineffectively translate business metrics into supply metrics and just over-provision and pray? Ultimately, we want teams to recognize that failure is a part of growth, and consistent recovery from failure comes from having mature practices and playbooks for what to do when things go wrong. We took inspiration from the Production Maturity Assessment released by Google’s Customer Reliability Engineering team, and using their example, we developed our own Operational Maturity Assessment to provide insight into the operational maturity of The Times’s engineering teams. The Operational Maturity Assessment is an activity that teams do together. A member of the Operations Engineering team facilitates each session, and the activity is designed to foster discussion and self-reflection within the team. (When we designed this assessment, we imagined teams gathering in person to eat pizza and complete it together. But, that was before the pandemic. Alas.) Each session lasts from one to two hours and a member of the team drives the assessment from their screen using a tool we built. The assessment tool we built was inspired by tax preparation software and breaks six top-level categories down into manageable sections. As the team moves through the categories — we will get into them in a minute — they answer prompts around topics that are intended to inspire conversation about whether their systems meet the maturity expectations of The Times. We want the assessment to provide a framework for thinking through parts of the system that may need to be addressed and prioritized alongside new feature development work. The assessment goes over our Operational Maturity Model which lays out the dimensions and scales of operational maturity at The Times along six categories: Monitoring and Metrics: Does the service have defined service-level indicators, objectives and agreements in place (things like uptime or ability to handle a certain number of requests per second)? Are data about those metrics visualized consistently and in an easy place to find by the team and downstream system teams? Do the metrics accurately reflect the experience of users? Capacity Planning: Do the product and engineering teams work together to forecast business metrics, such as users or sales, and convert those into supply levels like servers, storage or bandwidth? Does the team acquire capacity based on forecasted business and supply metrics, and is utilization of that capacity monitored for efficiency? Change Management: Does the team conduct releases at a predictable cadence; do they have defined practices for reviewing changes and releases; and do they automate most or all of the work of doing releases via continuous integration and deployment tools? Emergency Response: Does the team have an organized on-call rotation? Does the team regularly analyze automated alerting to make sure engineers aren’t bombarded with alerts that don’t require human attention? Does the team conduct effective learning reviews after incidents, with metrics, lessons learned and clear steps to prevent issues in future? Service Provision and Decommission: Does the team use infrastructure-as code-tools? Is the tooling standardized across the team, department and organization? Reliability: Does the team design and deploy their systems to be high availability, such as running workloads and data storage across multiple data centers or availability zones? Does the team have a documented disaster recovery plan with automated backups and regular testing? Are the team’s services deployed in multiple geographic regions or with multiple cloud providers? The questions in each section help drive discussion within the team. This discussion aims to educate teams on best practices and inspire new ideas. [We’re hiring for our Delivery Engineering team. Come work with us .] As the team works through each category, they score themselves on a scale of one to five against a maturity rubric; Each section includes a range from “chaotic” to “continuous improvement.” For example, from the Reliability category’s sub-topic, Multiple Region Support: Chaotic: Service runs in a single region. Managed: Service runs in a single region but can be spun up in a second region. Defined: Services run in multiple regions with manual failover. Measured: Services run in multiple regions with automated failover. Continuous Improvement: Services run in multiple regions, across clouds with automated failover. After completing the assessment, the team is presented with a report that outlines areas of strength and areas for improvement, compared to all other engineering teams at The Times. Not only does this process encourage engineering teams to discuss their strengths and weaknesses in a structured way, it gives them real data about technical and architectural debt that needs to be prioritized alongside new feature work. This also helps teams communicate their reliability improvement needs to company leadership. Our team, Operations Engineering, collects these team-level scores and collates them on a dashboard that allows us to see trends across the engineering organization. In aggregate, trends help us, and the leaders in engineering and product, understand where the organization as a whole needs to focus time and resources to drive improvement. In the visualization below, each column belongs to a category, while each row belongs to a team. The columns show us cross-team trends within each metric. By using a color range of light orange to dark orange, we can see how well teams perform in a particular metric. We have relatively high scores in the Change Management (third column group, from left) and Service Provision and Decommission (fifth column group, from left) sections, which are a direct result of previous organizational initiatives for improvement. Other categories, such as Monitoring and Metrics (first column group, from left), indicate an opportunity for improvement. The column for SLO Definition and Measurement, within the Monitoring and Metrics group, shows weaker scores overall, which helped us clarify a gap and allowed us to expand our Observability team. In the Reliability column group (far right), the Disaster Recovery column indicates a weakness in defining disaster recovery plans. We are beginning to push teams to build their disaster recovery plans to improve our overall reliability. As The Times continues to grow its subscription base , more and more readers come to our platforms for news. This means it is increasingly important for our teams to be ready for breaking news and system failures. For the last three American election cycles, we convened a cross-engineering readiness team to manage the efforts to prepare our systems for those events, which involved significant heroics on the part of those who joined. By defining system maturity and reliability standards, and then encouraging consistent operational thinking for all engineering teams at The Times, our hope is that we eliminate the need for heroic efforts in the future. Our ultimate goal is to make high-traffic news stories non-events, where our systems are mature enough to handle the load without the need for extra attention beyond marveling at the traffic charts. While the assessment today is a collaborative and fairly detailed exercise, we want to automate as much as possible. Our team is looking to augment our existing capabilities, and add more monitoring, metrics and change process automation (think deploy-on-green, canary deployments and automated rollbacks). Eventually we want to incorporate more mature practices like Chaos Engineering. This stuff won’t replace collaborating with teams, but it will augment the process with better data. If you are interested in solving any of these problems with us, please check out our roles on the Delivery Engineering team at https://nytco.com/careers . We’d love to speak with you. Tim Burke is a Senior Software Engineer and Site Reliability Engineer in our Delivery Engineering, Operations Engineering team, is a RuPaul’s Drag Race obsessed superfan, and is a frequent contributor to The Times’s #just-yelling channel in Slack. Special thanks to Vinessa Wan, Shawn Bower and the Delivery Engineering team. How we design and build digital products at The New York Times 244 1 Sre Engineering Code DevOps Technology 244 claps 244 1 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-04-15"},
{"website": "NewYork-Times", "title": "how we rearchitected mobile a b testing at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/how-we-rearchitected-mobile-a-b-testing-at-the-new-york-times-78eb428d9132", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Julian Locke and Sameer More In early 2020, the mobile engineering teams at The New York Times noticed an issue: our A/B tests were separating users at the wrong ratio. Tests that were supposed to allocate users into control and experimental groups were sometimes off by five percent or more. This was a big problem. The Times uses A/B tests to make decisions about the products and features we release. Our A/B testing system works by separating users into groups that see different variants of the feature we’re testing. We then collect data on user behavior around the feature, and we draw conclusions on the effectiveness of our test. If a test’s participation ratio is skewed — as we were seeing across many tests on our mobile platforms — it affects our confidence in feature roll-outs. When we test features, it’s important that we have control over how we allocate users into testing groups. To figure out why this was happening, we turned to our in-house A/B testing library. Our A/B testing SDK was built for simplicity and had a synchronous API that a client could check for a test allocation. However, behind-the-scenes, the library would periodically query for results of A/B allocations and persist them across app sessions. If no result had been found and the network call had not yet returned, each test was hard-coded to fall back to a default variant, which was almost always the control. Our hunch was that the hard-coded fallback was catching users who were browsing offline or had slow network connections. This was a problem because we needed unbiased allocation to successfully test new features. We had to figure out what was happening. In order to make our SDK more accurate, we deployed two changes over the next few months. First, we increased reporting and we added an analytics field to indicate the source of the allocation for a user, server or hard-coded fallback. While this didn’t make allocations more accurate, it did allow us to filter out non-random allocations during data analysis. Second, we developed an app-side hack for reliable allocations by simply neglecting to configure the test and using native logic to assign a random variant. This was especially useful for UX tests for first-time users that had little chance of being fetched prior to the user reaching them. Together, these changes allowed teams to continue testing, but each came with downsides. Filtering the non-random allocations from analysis shrunk our pool of testers and biased our tests to measure only users with great network connections. Our app-side hack separated all users fairly, but it limited our ability to make changes to the allocations once the apps shipped. Adding native allocation logic was a less maintainable solution because it created a second source of truth for test configurations. It also duplicated the allocation logic and the configuration validation logic that already existed on the server. Even with the downsides, we were encouraged by the truly random synchronous allocations afforded by the native logic. We started to investigate whether we could formalize and port the logic into our shared library, while mitigating the inherent issues of the native logic. From here it’s helpful to go a little more in depth about the constituent parts of the existing system: First, tests are manually configured in a server-side GitHub repo. For each test, developers specify a name, test variants and proportions and the integration. An integration is similar to an environment, but it also specifies the application, such as `ios-newsreader-production`. On each change to this repo, server-side tooling creates a new JSON rules object for each integration. It’s a distillation of the latest test configurations for that integration. On launch, the mobile app sends a list of tests, an integration and targeting parameters to the allocations endpoint, which then returns a dictionary and allocations for each test. The allocations endpoint computes the testing distribution using a short JavaScript allocation script. The test and targeting parameters from the app, as well as the relevant rules object, are passed into the allocation script. The script returns allocations for each test. The allocations endpoint call returns the allocations to the mobile app. We use JavaScript alongside native code in our mobile apps at The Times. Sometimes the JavaScript displays web technology-based UIs, and it occasionally executes small chunks of cross-platform logic. With that in mind, we imagined a reconfiguration of the A/B library’s components that was inspired by the JavaScript for event validation work of our colleague Krzysztof Zablocki, who wrote a simple analytics event validator that shared code with our web app. Elements of this work inspired our design here; we were able to adapt portions of it on iOS and implement analogous components on Android. We envisioned our new configuration as a series of steps: Teams would their app-side allocation tests to the server-side configurations repo, just as they did for the old system. At app compile time, the tooling would download both a recent JSONLogic rules object and a recent allocation script, which it would ship to the app. The tooling would use the rules object and the script to synchronously allocate all tests at app launch. This removed the network call to the allocation endpoint completely out of the picture. This configuration would mitigate most of the issues with our native logic hack, but it would still inhibit our ability to make changes after an app release. Because our engineering teams needed the options to pull the plug on bad tests or roll them out incrementally, this was a significant roadblock. [We are hiring! Come work with us .] We looked back to Krzysztof’s work on JavaScript for event validation, which included a class that served as an abstraction of a remote asset. We created one instance each of the class to represent the JSONLogic rules object and the allocation script. The classes would periodically fetch the latest allocation script or asset, falling back to local versions if needed. This allowed us to update test configurations on an app already in flight. The one caveat with this approach is that it’s not possible to apply the most up-to-date allocation rules for a user launching the app for the first time. This is because the binary may be stale and there is no time for a server call. Initial allocations rely on the rules that were live when the latest app release was cut, which may be up to two weeks old. To implement our new A/B testing library on Android, we had to choose the right JavaScript engine to run the allocations script and we considered WebViews, J2V8 and Duktape-Android. While we had used WebViews before, they were hard to manage and couldn’t execute code synchronously. J2V8 was faster and easier to use, but it would have added about 20MB to our app’s size. We ultimately decided on Duktape-Android because it only added 2MB to our app. Verifying Allocation Code At Runtime We added a validation step that stops the library from trying to execute a nonfunctional script. This step reads the JavaScript and attempts to run it in Duktape-Android. However, if an exception occurs, the library will revert to the script it currently has. Asset Management For our A/B testing library, we relied on Store4, which brought support for coroutines. Store4 provides a framework to specify a source of truth (which in our case, are the A/B assets stored in the file system). The framework also provides a fetcher for retrieving and validating assets from the network and a reader for processing those assets. We decided to use the Apple framework JavaScriptCore to execute the allocation script because it runs in process. While it is slightly slower than other engines we could have chosen, we opted to use it for security reasons. Asset Management We adapted a useful abstraction from Krzysztof’s app-side JavaScript work called the `RemoteAssetManager`. For assets like our allocation script or rules object, an instance of this manager can handle all the tricky logic around making the latest version synchronously available. The abstraction reads and materializes the asset out of the app binary, fetches new versions of the asset from the web and writes the version to disk between app runs. The `RemoteAssetManager` is written to be flexible and capable of handling arbitrary assets. Its initializer takes a few closure arguments that allow the caller to tell it where to access assets, how to materialize assets from data, how to compare and choose the best of these assets, and how often to attempt to fetch new versions. The core of the app-side allocation code can instantiate one of these managers and from then on synchronously access the latest and greatest possible version of the asset. Analytics Because an A/B test would be useless without data, our apps trigger an expose event, which reports the test name and variant at the time a feature is used. The event is our only way to know that an audience is seeing the correct test. We added additional data including: Metadata for how tests are allocated. An error field for exceptions. The allocation script response. The input parameters to the script. The version of the rules object and the integration that was used. This information is sent to the analytics service and is made available for our data team. Because of our additional analytics, we no longer need to guess why a test isn’t reaching the target audience. In early October, 2020, we integrated this new A/B testing library into the New York Times Beta app and distributed it to a few thousand users. To test it out, our product team organized an A/A test — a 50–50 test that reported user analytics but didn’t vary the experience — and our data analysts verified the results. Because we didn’t significantly change the SDK API or the server-side test configuration storage location, the update automatically moved all running tests over to the new system. In the beta app, we verified that users who were allocated into one group via the old SDK were allocated into the same group via the new SDK. They were. We rolled out the release to the main Times apps. Since then, tests have been predictable, analyzable and deterministic, which means that our feature teams can deploy tests knowing that the data they get back is reliable. Julian Locke is a Senior Software Engineer on the App Platforms team at The New York Times. Sameer More is a Senior Software Engineer on the App Platforms team at The New York Times. How we design and build digital products at The New York Times 102 Android iOS Engineering Testing Code 102 claps 102 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-03-04"},
{"website": "NewYork-Times", "title": "meeting cindy taibi chief information officer at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-cindy-taibi-chief-information-officer-at-the-new-york-times-795022c3428f", "abstract": "Code Data Product and Design Workplace Culture Work with Us What are your pronouns? She/Her What is your job title and what does it mean? Chief Information Officer. To me, it means that I lead the teams that a) empower our company and our workforce to work productively, efficiently and safely; b) run all the back office systems to keep the company doing business; and c) support all things print. How long have you been at The Times? 40 years. I started when I was 10. Just kidding, but really some days it feels like those years have flown by, and other days it feels like it has been 10 lifetimes. I love thinking back to some of the world events I have seen unfold through the lens of working for The Times. What a long, strange trip it has been! Most Times employees are working remotely right now. What does working from home these days look like for you? Well, I’ll just say I don’t enjoy working from home. I would rather be around people, and I think I work better around people. For me, it’s hard to replace the value of social interaction. Tell us about a project you’ve worked on at The Times that you’re especially proud of. That would be our migration to the cloud, completed just about three years ago. The tech department migrated roughly 95 percent of our computing workloads to either the Amazon or Google public cloud environments, and it was all on hard deadlines having to do with ending our leases and shutting down four terrestrial data centers. Dozens of people worked on the project across the tech department and they met all of the major deadlines. What is the biggest challenge you faced in your career and how did you overcome it? Knowing what you know now, would you do things differently. In the early 1990s when my two children were born, I had to transform myself into a full-time working parent. Becoming a mother is a huge challenge and doing it while working was incredibly difficult. Learning to prioritize, being the best mom I could be, and for a while, managing with very little sleep! Would I do it again? YES. There’s nothing more rewarding. The Times has six core values (Independence, Integrity, Curiosity, Respect, Collaboration and Excellence) by which the company operates. Is there one that you find best describes your work? Collaboration. For me it’s mostly about the people, and I believe that we encourage each other to do better when we do it together. What change do you hope to see in your community? Well, right now I would just like to see my community come out on the other side of this pandemic so that we can all be real neighbors again in a safe and healthy way. What or who are you inspired by? My father. He taught me so much about how to figure things out for myself, and how to advocate for myself. What is your best advice for someone starting to work in your field? Job satisfaction has many aspects to it, but there are three aspects which I think are fundamental. If you have work that you think is meaningful, a boss who appreciates you and you are fairly compensated, then you should have job satisfaction. You may not always be working on the most exciting project and you might not always be paid at the high end, but finding job satisfaction is important. Other aspects may wax and wane over time, but those three are the fundamentals. Meeting… Natasha Dykes, Senior Software Engineer at The New York Times Meeting… Corina Aoi, Technical Product Manager at The New York Times Meeting… Jessie Wu, Software Engineer at The New York Times How we design and build digital products at The New York Times 59 Nyt Open Meeting Women In Tech Technology Leadership Management 59 claps 59 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-03-08"},
{"website": "NewYork-Times", "title": "meeting natasha dykes senior software engineer at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-natasha-dykes-senior-software-engineer-at-the-new-york-times-ec52c502e459", "abstract": "Code Data Product and Design Workplace Culture Work with Us What are your pronouns? She/Her What is your job title and what does it mean? I’m a Senior Software Engineer on the Messaging Pipeline team. I work on a microservice application that is mainly written in Go, but has a little JavaScript sprinkled in. How long have you been at The Times? Since October 2018, so a little over two years. Most Times employees are working remotely right now. What does working from home these days look like for you? Working from home has been a rollercoaster. I have enjoyed getting back the time I would usually spend commuting, and I have been able to spend more time with my cats. I set up a little bird feeder on the fire escape so my cats can have some entertainment on the windowsill next to my desk. Turns out, I enjoy bird watching as much as they do! But, it’s been a challenging time, too. When the pandemic first started in New York, I really struggled to find balance between my work time and my free time. It felt oppressive and I couldn’t really disconnect the same way I was able to when I physically left the office. The idea of being able to make my lunch during lunchtime was quickly thwarted by last-minute meetings or long slack conversations, despite my attempts to reclaim my calendar. The biggest struggle for me was getting enough movement in the day. I went from going to the gym three to five times a week and walking 20 blocks from the gym to the office in the morning to having walked only 800 steps by 6 p.m. according to my fitness watch. It was bad. After a year of working from home, I have recalibrated my work-from-home experience and sandwiched my workday with a “commute” around my neighborhood; I have designated work areas to help define the lines of work and home; and although I haven’t unlocked the secret to maintaining a lunch hour, I have leaned on meal prep to ensure I have something good to munch on when lunch time rolls around. I still watch the birds peck at the seeds on the fire escape while my cats look on with unflinching focus and restless tails. Tell us about a project you’ve worked on at The Times that you’re especially proud of. In 2019, my team worked to migrate functionality from a seven-year-old legacy system to our current messaging platform. The system was a PHP application that was responsible for sending push notifications and it had not been actively maintained in some time. My team’s goal was to shut down the application because most of the system’s original authors had left the company and the tech stack did not fit the current skill set on the team. I had joined The Times a few months earlier with no prior experience working in Go and no professional experience working with back-end systems (other than Node applications). My role was to build functionality that took the payload scheduled for an alert and send it to the respective Android or iOS platform. I didn’t know what the payload looked like, so I had to do a bit of reverse engineering, while learning Go and building a proof of concept, to verify our assumptions. After I built the proof of concept, I was able to complete the transformations and client setup to allow our current platform to send push notifications. I was especially proud of it because it was pretty intimidating; I never expected to be responsible for this kind of work, but I was able to build and ship it. What is the biggest challenge you faced in your career and how did you overcome it? Knowing what you know now, would you do things differently. Learning the language necessary to ask the right questions. It came with experience, as most things do, and being comfortable enough with my teams and my mentors along the way to ask for guidance when I needed it. Knowing what I know now, I would have stuck with my Computer Science degree instead of changing majors! I would have sought help from environments that promote “growth courses” and not “weed-out courses.” The Times has six core values (Independence, Integrity, Curiosity, Respect, Collaboration and Excellence) by which the company operates. Is there one that you find best describes your work? Integrity. It’s how I approach development. I come from a QA background, so I tend to think of edge cases first and then I try my best to ensure that I ship sound and stable code. It’s also how I approach the work with my team. It’s also how I approach my extracurricular work with some of The Times’s advocacy groups like Women in Tech, Black and Latinx in Tech and our Architectural Review Board. I believe that honest conversations move us forward. What is a goal you hope to accomplish this year? For my personal life, I would like to complete a century bike ride this year. For my professional life, I would like to commit to putting more of my focus in increasing my technical depth and saying “no” to opportunities that don’t work towards that goal. As a Software Engineer working on a digital product, how do you approach your work with inclusivity in mind? I focus on end users. It doesn’t matter if you complete the work outlined in the ticket if the work that gets shipped doesn’t provide value or leaves out a group of people. This involves a lot of conversations with product and team leads, asking questions and most importantly, listening to others. What change do you hope to see in your community? I can’t say that there’s any major change that I would like to see specifically in my community. The community I identify with is compassionate, ambitious, resourceful, eager; but there’s only so much one side can do. I’d love to see communities outside of my own be more open, transparent, equitable and compassionate. I’d really like to see more spaces that I occupy as a professional look more like the cities that house them, the clientele they aim to serve and the world at large. Do you have any favorite life hacks or work shortcuts? When you want to create a new Google Doc type “docs.new” into your browser and a new Google Doc will load; It’s the same for Sheets. It’s a pretty useful shortcut for my workflow. What or who are you inspired by? I’m inspired by engaging and sprawling conversations that leave me with books to read, music to listen to and perspectives to examine. Fill in the blank: What is the best part of being ______? If you had it your way, what could make it better? What is the best part of being in quarantine? Some days I really can’t stand it and I want to fast forward to when we can meet up in real life. But, it’s not all bad. In many ways, quarantine has forced me to be more intentional with myself and the people I care about. I have been able to learn a lot more in my free time, ranging in subjects from algorithms to feminist theory. The pandemic has motivated me to regularly check on friends who I would not have reached out to until we hung out in person, which can be many months for friends in different parts of the country. It has taught me to listen to my body; It’s pretty wild how many mild inconveniences and discomforts a body can accumulate before you realize how garbage you feel. I have been able to try out different meal plans that hit my nutritional goals rather than grab something that’s quick and convenient and I’m feeling much more energized from it. All of that said, I’m ready for things to get back to what they once were. I plan on taking some of the habits I learned into my post-quarantine life. If I could have it my way, I would have a full vaccine roll-out tomorrow. Complete this sentence: Over time, I have realized __________. That the work will still be there tomorrow. What is your best advice for someone starting to work in your field? Take time to explore what it is about technology that piques your interest and learn by doing; experience is the best teacher and it doesn’t always come from school or work. Meeting… Corina Aoi, Technical Product Manager at The New York Times Meeting… Jessie Wu, Software Engineer at The New York Times Meeting… Angelica Hill, Associate Product Manager at The New York Times How we design and build digital products at The New York Times 93 Nyt Open Meeting Software Engineering Women In Tech Code Developer 93 claps 93 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-03-24"},
{"website": "NewYork-Times", "title": "meeting alice liang sr manager of data insights at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-alice-liang-sr-manager-of-data-insights-at-the-new-york-times-e302967c3490", "abstract": "Code Data Product and Design Workplace Culture Work with Us What are your pronouns? She/Her What is your job title and what does it mean? Senior Manager, Data & Insights (Engagement Analytics) I manage a team responsible for data on our newsletters, push notifications and some of our personalized surfaces. We identify opportunities for our products to grow, build pipelines to power enterprise reporting, run experiments to inform business strategy and more. How long have you been at The Times? Just over three years. Most Times employees are working remotely right now. What does working from home these days look like for you? I’m currently working from home in Michigan but plan on going back to New York soon. Working from home these days looks like having coffee with my sister in the mornings and saying hi to my mail carrier in the afternoons. Tell us about a project you’ve worked on at The Times that you’re especially proud of. I was part of the team that first introduced the dynamic meter on our site. This involved an innovative and scrappy small core team that pushed my technical skills, as well as a highly cross-functional set of stakeholders who challenged me to communicate data insights in better ways. It was an incredibly complex project at the forefront of what the industry is doing, and it’s still powering part of our paywall today. What is the biggest challenge you faced in your career and how did you overcome it? Knowing what you know now, would you do things differently. Earlier in my career, I was in a pre-doctoral program with an amazing cohort of people who were all planning on getting their PhDs. I knew internally that getting a doctorate and having a career in research wasn’t for me, though I had already done a lot of preparation for it. It was difficult to overcome the expectation that was set for me in the program to pursue grad school. I started talking to folks in other industries, found allies in my cohort that also were deviating from the grad school route and got a job here at The Times! I would tell myself to trust my instincts more readily. The Times has six core values (Independence, Integrity, Curiosity, Respect, Collaboration and Excellence) by which the company operates. Is there one that you find best describes your work? Curiosity — the “open-minded inquiry” at the heart of The Times’s journalism is also the key to good data analytics. What is a goal you hope to accomplish this year? This year, it’s important for me to support my team and coworkers in the best way I can and to allow myself to be supported by them. Hitting the one year mark since the start of the pandemic is not easy for any of us. My goal is to make space for my team to feel like they can learn and grow in their work. Outside of my job, I’ve been working on a manuscript for a few years that I would like to finish up this year. As an analyst working on a digital product, how do you approach your work with inclusivity in mind? As an analyst, it’s your job to keep an open mind and to challenge assumptions, to put yourself in the position of a reader and to approach analysis with empathy. As a people manager, inclusivity is even more important. People managers can focus more on hiring and growing people who are underrepresented in technology, to hear from different perspectives, to develop policies and expectations that are inclusive for everyone. What change do you hope to see in your community? I hope to see more people of color and women thrive in data, and I hope to see more people who work in the industry foster environments that support the success of people of color and women. I’m encouraged by some of The Times’s recent commitments to diversity and inclusion, and I want to push our technology and data functions to do more. Do you have any favorite life hacks or work shortcuts? Life hack: you can regrow green onions forever by just placing their ends in a jar of water. Work shortcuts: write down everything you have worked on at the end of the week or at the end of a month, including small ad-hoc tasks. Whether you’re writing a year-end review or just looking back on your day-to-day, this will help you have a clear sense of all that you have accomplished. What or who are you inspired by? I teach a citizenship class and every week, my students inspire me to be persistent, patient and dedicated to a life of continuous learning. Complete this sentence: Over time, I have realized __________. Over time, I have realized the importance of having good colleagues by your side. Even with good work-life balance, you end up spending so much of your life at work. Having people to joke around with, to vent to, to cheer you on, to bounce an idea off of and to support you in times of need is so critical. What is your best advice for someone starting to work in your field? Stay curious! Follow your interests to explore beyond what’s expected of you. Approach your work with empathy. Advocate for yourself and find mentors, sponsors and managers who will advocate for you. And wherever you are in your career, there’s someone you can mentor and bring up behind you. Meeting… Cindy Taibi, Chief Information Officer at The New York Times Meeting… Natasha Dykes, Senior Software Engineer at The New York Times Meeting… Corina Aoi, Technical Product Manager at The New York Times How we design and build digital products at The New York Times 130 Nyt Open Meeting Data Analytics Work Women In Tech 130 claps 130 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-03-10"},
{"website": "NewYork-Times", "title": "meeting carrie price lead software engineer at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-carrie-price-lead-software-engineer-at-the-new-york-times-ac86943ca0d5", "abstract": "Code Data Product and Design Workplace Culture Work with Us What are your pronouns? She/Her What is your job title and what does it mean? I am a Lead Software Engineer. Generally, that means I write a lot of JavaScript for our website. Currently, my team builds and promotes features that enhance the value of a New York Times subscription with the aim of retaining subscribers. Our journalists create an amazing breadth of content every day and we want to help our readers discover all we have to offer. How long have you been at The Times? About seven and a half years. Most Times employees are working remotely right now. What does working from home these days look like for you? I’ve been staying in New Jersey with my family for the last 11 months. A typical day consists of working at the desk in my childhood bedroom, taking breaks to hang out with my two cats or our family dog, and watching Jeopardy during dinner. Tell us about a project you’ve worked on at The Times that you’re especially proud of. I’m extremely proud of the work I’ve done on The Weekender . It started as a group project during Maker Week (an annual event where we are free to explore and build whatever we want), and it has now grown to be a weekly feature. I have gotten to work with some amazing people in the newsroom and I learned a lot about the editorial process that I wouldn’t have learned otherwise. What is the biggest challenge you faced in your career and how did you overcome it? Knowing what you know now, would you do things differently. A challenge I still face today is maintaining confidence in my abilities. I started at The Times right after I graduated from college. In my first year, my goal was to learn as much as possible from those around me. Achieving this was easy because my teammates were all very helpful. As I continued my career here, I started to understand enough about our systems to be able to contribute answers rather than just ask for them. I had spent the majority of my life in school where there was always a right answer and a person to tell me what it was. It was a challenge for me to gain the confidence to embrace the ambiguity of real-life decision making. For a long time, I wouldn’t share my opinion without first asking for validation from everyone around me. If I had trusted my gut earlier, I would have been brave enough to take chances and accept that it’s O.K. to be wrong sometimes. I think a healthy dose of skepticism in your own ideas makes you a better collaborator, but it should be balanced with some trust in yourself. The Times has six core values (Independence, Integrity, Curiosity, Respect, Collaboration and Excellence) by which the company operates. Is there one that you find best describes your work? All of these values are important to my work but I think collaboration is probably the best fit. I believe our job as developers at The Times is to create a stable infrastructure and a suite of tools that allow the newsroom to be creative and reach our readers. There’s no way to do that work without listening and learning constantly. What is a goal you hope to accomplish this year? I’m not much of a formal goal setter, especially at a time when it feels like everything is constantly changing around us. My informal goals this year are to learn some new things, work with great people and take things as they come. As a lead engineer working on a digital product, how do you approach your work with inclusivity in mind? One of my favorite parts of my job is when I get to sit in on our user research sessions. I love hearing from a wide range of readers, gaining insight into how they use our features and challenging my own assumptions. I try to bring those same concepts to my day-to-day work by asking for feedback and working to make sure those opinions come from a diverse group of colleagues. What change do you hope to see in your community? I think this year has taught us a lot about how necessary it is to have flexibility in our work-life. I hope we continue to give people the space they need to figure out how to achieve work-life balance in a way that makes sense for their circumstances. Do you have any favorite life hacks or work shortcuts? I am a very big fan of the split screen feature on Mac . It allows you to take any two apps and put them side-by-side in a single view. It’s so nice to be able to see faces in a meeting even if I’m sharing my screen. What or who are you inspired by? Work wise, I’m inspired by all of the complex, critical and sometimes life threatening work our journalists do every day. It’s kind of surreal that I work for the same company that they do. Life wise, I’m inspired by those who use humor to help themselves and others process the complexity of life. Laughing is my favorite coping mechanism. Fill in the blank: What is the best part of being ______? If you had it your way, what could make it better? My favorite part of being an engineer, especially a web developer, is being able to rapidly prototype. It’s so satisfying to be able to quickly spin up a useful website that looks professional. I also love working with responsive design. Few people in real life spend time resizing their browser, but I love watching components seamlessly rearrange to fit the space. Complete this sentence: Over time, I have realized __________. Over time, I have realized that I get to define what a successful career looks like to me. I’m still working through what that means for me, but right now it includes working on a supportive team, building systems that reinforce The Times’s mission and bending the formal role of an engineer to include learning about disciplines outside of development (design, user research, product management, journalism). What is your best advice for someone starting to work in your field? When I start a project that will require learning something new, the long list of things I don’t yet understand can feel daunting. I take time at the end of those projects to remind myself of that feeling and to recognize that it was only temporary. This small habit has built up my confidence for when I face new unknowns and I highly recommend it. Meeting… Alice Liang, Sr. Manager of Data & Insights at The New York Times Meeting… Cindy Taibi, Chief Information Officer at The New York Times Meeting… Natasha Dykes, Senior Software Engineer at The New York Times How we design and build digital products at The New York Times 11 Nyt Open Meeting Software Engineering Code Women In Tech Technology 11 claps 11 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-03-12"},
{"website": "NewYork-Times", "title": "meeting gerardo núñez senior data analyst at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-gerardo-núñez-senior-data-analyst-at-the-new-york-times-11610055d029", "abstract": "Code Data Product and Design Workplace Culture Work with Us What are your pronouns? He/Him What is your job? I’m a Senior Analyst for Audience and Coverage. What does that mean? I look at ways that insights from data can provide answers to questions like, ‘Which social media platform works best to promote certain pieces?’ and ‘How does reader interest in our journalism vary by region?’ My job is a combination of data analytics, data engineering and data science. I spend most of my time interpreting data, some of my time making sure we have infrastructure that supports our work and the rest of my time applying advanced techniques that help provide more insights. How long have you been at The Times? Since September 28th, 2020. Most Times employees are working remotely right now. Where are you working from these days? I’ve been working from Coral Springs, FL. How do you start your day? I’ll start my day at 7:30 a.m. with my eight-pound Cavachon, Kovu, asking me to walk him around the park nearby. My wife will wake up a little later and start preparing tea and breakfast, which we’ll enjoy together on the balcony. We usually spend some time there with Kovu, just observing the birds and turtles gather in the canal behind our apartment while the sun rises over the trees. What is something you’ve worked on recently? At The Times, we collect a lot of complex data that can be hard to analyze, so we spend a lot of time making sure we get the insights right. I’ve been working with my team to create a way to simplify how we gather insights and share them with our colleagues. Tell us about a project you’ve worked on at The Times that you’re especially proud of. Currently, I’m looking at the performance of Times enterprise stories, which are big journalistic projects that might take years to produce, such as the series on former President Donald J. Trump’s taxes . What’s interesting about this project is that whenever we say ‘Enterprise Story’ we automatically assume that it will outperform other stories in every possible way, which is not necessarily true. For example, a story specific to New York City will probably perform well there, but might not be the most-read story in every state or outside of the United States. This is important because, given the amount of effort these stories take to produce, we want to get better at setting our own expectations. What was your first job? I was a theater usher back in Venezuela. What is something most people don’t know about you? I spent four years working in a libertarian think tank in Venezuela. What is your secret to career success? I strongly believe that if I first focus on being a good human being, success will follow — not only in my career, but in my life. What is your superpower? Learning and sharing knowledge. What are you inspired by? Most artistic expressions, and philosophy. Name one thing you’re excited about right now. The world after COVID. What I’ve seen during this time is not limited to the pain and struggles of many close to me, but also their resilience, their creativity and their ability to adapt. And all those learnings make me hopeful for a future where we all go above and beyond to connect meaningfully with one another. What is your best advice for someone starting to work in your field? Technology is a fast-changing industry, and it can sometimes feel challenging to stay on top of the latest developments. If you can stay curious, you can turn this challenge into an opportunity to learn new things. At least, that’s how it’s worked for me. Meeting… Angelica Hill, Associate Product Manager at The New York Times Meeting… Corina Aoi, Technical Product Manager at The New York Times Meeting… Jessie Wu, Software Engineer at The New York Times How we design and build digital products at The New York Times 80 1 Data Audience Engagement Data Analysis Engineering Nyt Open Meeting 80 claps 80 1 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-02-25"},
{"website": "NewYork-Times", "title": "announcing the new york times app for slack", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/announcing-the-new-york-times-app-for-slack-eb2bfd1e01bd", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Anna Dubenko and Scott Sheu Over the last few years, The New York Times Audience team began paying attention to how Times journalism was shared in private messaging spaces like text, email and other chat platforms. The team began thinking about how to deliver our journalism that fit our readers’ needs. We knew that some readers wanted the latest breaking news, while others wanted guidance on what to cook, what to watch and what to read. Still others came to The Times to understand their industries better, and to share information and stories with their colleagues. It was this professional context that we wanted to explore. The Audience team — which sets our audience strategy and oversees search, social and community, as well as data insights and analysis in the newsroom — connected with our Audience Product team to build a Times app for Slack that would do three things: 1) Help Slack users connect to the Times stories their colleagues were sharing and discussing; 2) Allow Slack users to save Times articles to read later; and 3) Offer a single great read of the day, selected by our editors. We’re excited to announce that we have launched our first app for Slack . Since Slack’s launch in 2013, it has grown as a platform for workplace communication. We thought it would be a good place for us to connect with a key audience of professionals who want to stay informed and use their time efficiently. Slack’s users are on the platform for work, but they also use it to talk about topics that touch their work, such as issues that impact working parents, remote work and more. When we set out to build a Slack app, we didn’t want to duplicate The Times’s existing products. Our Slack app didn’t need to send users breaking news alerts or give them a list of stories they could find on our homescreen. To create an experience that fits within the Slack ecosystem, we thought a lot about features that would add to the workday. Starting with a list of fifteen features, we ultimately winnowed them down to three: The Popular in Your Workspace feature allows users to easily discover the top stories their colleagues are sharing across channels. Our “ home tab ” within Slack also displays the three most-popular articles in a user’s workspace. The Recommended Read is a daily story, selected by an editor, that we hope will delight and inform users on Slack. This feature can be shared within any channel by typing “/nytimes” or can be found in the app’s home tab. All Times articles are accompanied by a Read Later button, which enables users to save the article to a reading list within Slack that can contain up to 50 articles. This gives users the ability to customize their own reading routines. Using Slack’s Block Kit builder, we designed an interface based on those three features and built a working prototype that we tested with our colleagues at Wirecutter who kicked the tires and caught any bugs. Afterwards, we set up a more formal beta test with a couple hundred employees at a design consulting firm. After receiving quantitative and qualitative feedback from our early users, we felt pretty good about launching the Slack app more widely with the features we had in place. To prepare for public distribution in Slack’s app Directory, our teams focused on building out the app infrastructure to enhance its resiliency and its ability to handle a much larger audience. We also worked with our legal, data governance and security teams to ensure the app not only met Slack’s requirements but also fully represented The Times’s security and privacy practices . Users are not required to have a Times subscription in order to use our Slack app, however our normal business rules apply for articles that are read on the Times website and mobile apps. In order to install the app in Slack, users will be required to approve certain data permissions through an authorization page . While these permissions are necessary to enable features, monitor performance and troubleshoot issues, The Times will not collect users’ names, email addresses or any other contact information through the Slack app. To help us understand app performance and where improvements can be made to the app experience, we collect aggregated data around feature usage and activity. All data collected is approved and enabled by Slack’s API, and subject to both The New York Times’s Privacy Policy and Slack’s Privacy Policy . This is just the beginning of our experiment on Slack. We’re excited to see this app in the hands of many more users to see what features they like, which ones we can add and what we can do to better understand how our journalism is shared. For more information or to install the app, visit the NYT Slack app directory page or search for it under “New York Times” in the Slack App Directory . Questions or feedback? Email us: slack-support@nytimes.com Anna Dubenko is the deputy director of Audience in the newsroom overseeing Facebook, Twitter and emerging platforms Scott Sheu is an associate product manager and social product lead at The New York Times Special thanks to the team: Engineering: Sid Nutulapati, Katerina Iliakopoulou and Erik Jönsson Design: Andrei Kallaur Data: Jason Michaels and Tommy Glickson Project management: Victoria Niemeyer Product Marketing: Kaitlin Yapchaian Audience: Michelle Dozois And Kourtney Bitterly and Ian Macartney Come work with us: https://www.nytco.com/careers/ How we design and build digital products at The New York Times 119 Work News Journalism Social Media Design 119 claps 119 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-02-18"},
{"website": "NewYork-Times", "title": "a more accessible web", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/a-more-accessible-web-fa87592da6d2", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Shilpa Kumar Last year marked the thirtieth anniversary of the Americans with Disabilities Act being signed into law, which banned discrimination against people with disabilities in all areas of public life. The A.D.A. required that accommodations be made in places like schools and businesses, and on transportation to allow equal access for people with disabilities. The A.D.A. is often talked about in reference to physical access. There is currently a legal debate about whether the A.D.A. should apply to digital locations, too. No matter how that legal question gets resolved, as more of our modern lives are spent online, websites and apps need to be accessible, too. Web accessibility, also known as a11y, broadly refers to web applications that can be used by all people regardless of their cognitive, physical or visual impairments, their technical proficiencies or their situational circumstances (such as poor internet connections). Implementing web accessibility standards is not always hard. There are numerous ways designers and developers can incorporate accessibility principles in their web applications by using basic CSS and HTML. At The New York Times, we have taken steps to improve the web accessibility of our products . Here are some of the web technologies we have leveraged in recent years to enhance the user experience of our website and apps for all. Semantic HTML simply means HTML that is structured, organized and adds meaning to the page. Each element tag should indicate the type of content it contains, such as a heading or a button. At The Times, we use semantic HTML across all of our platforms. Semantic HTML isn’t just a good practice in web development , it ensures that everyone can access your content. Modern web browsers read semantic HTML tags to know what kind of content is contained within them and how they should be presented to users. Similarly, screen readers use semantic HTML tags to communicate where a user is on a web page. ARIA is a W3C specification that consists of attributes that can be applied to any HTML element to describe the properties, roles and states of that element. The aria-label attribute can be assigned a string, such as “Main Menu” or “Main Content,” that will help provide context to someone using a screen reader. We implemented ARIA landmarks in numerous places across our platforms. Our Games team implemented dynamic ARIA landmarks, which change as the state of the page changes, to improve the user experience of the Crossword. The team applied the aria-label attribute to the <button> HTML tag that renders the Crossword’s play and pause button. When a user starts or pauses a game, the string in the aria-label attribute changes to reflect the state of the game. This is particularly useful for someone using a screen reader to navigate the game. Another place where the Games implemented dynamic ARIA landmarks was in the crossword itself. The game was built using the SVG HTML tag <rect> to render each crossword square. When a user tabs to each square, the ARIA landmarks dynamically change to give more context about their location on the page. The user’s screen reader can tell them which clue they are responding to and the number of letters needed to solve the clue. If a user is not logged in to their Times account, or if they have reached their monthly free-article limit, they will be met with a paywall banner on most articles pages. The banner is located after the HTML footer of the page, which means it wouldn’t normally be read by a screen reader, so we need to provide more context for how it can be interacted with. To help users with screen readers navigate this dynamic part of the page, we added ARIA landmarks to each part of the banner. The elements in the login and registration component, which is how users access their Times subscriptions, are visually distinct. Black buttons and text against a white background provide enough contrast so they can be viewed clearly, especially by users with visual impairments. All of the buttons and links in the component change color in their hover state to indicate that these elements are interactive. Increasing the color contrast serves users with color blindness, as well as users who might be in bright lighting conditions (such as direct sunlight). Color contrast should be used for buttons, links, icons and images to convey the importance of elements in a web application. Keyboard-accessible web applications are crucial for users who are unable to use a mouse. The tabbing order of the interactive elements should be in a logical order as the user progresses through the page, from left to right and top to bottom. Usually, the DOM position of HTML elements informs how tabbed navigation will traverse the page. However, it is possible to configure the tab order without affecting the DOM. The HTML attribute tabindex can be applied to HTML elements to indicate whether they can be accessed by tabbed navigation — and in what order. tabindex takes any number as a value, however it is not recommended to use values greater than “1.” <div tabindex=\"0\"/> : This element can be accessed by the tab key. <div tabindex=\"-1\"/> : This element cannot be accessed by the tab key. When tabindex is set to a value greater than “1,” it will cause the element to be prioritized to the top of the tab order. If there is more than one element with a tabindex attribute greater than “1,” the tab order will start at the lowest value and work its way up. tabindex also controls which elements get a visible border around them to indicate that they are interactive. Every element that can be accessed via the keyboard should have a focusable border around it. Most interactive elements have the focusable border by default, but it’s possible to add focus to an element by using tabindex=\"0\" . [If this work is interesting to you, come work with us. We’re hiring! ] Our Games team specified tab order in the Crossword to improve the usability of the game. When a user pauses the game, a model appears at the center of the page with the option to resume. The tab order of the page has been set so that the user can either tab to the resume button or continue to the links farther down the page — without needing to tab through each crossword square. The Games team also ensured that each interactive element on the page has a focusable border around it. For users who have cognitive impairments or for those who are not technologically experienced, directional cues are very important because they indicate how to interact with an element. Directional cues can include tooltips, arrows, modals or messaging with explicit “calls to action.” The Crossword’s modal explains a new autocheck feature and instructions on how to explore the page outside of the game. This prompt is a visual cue that guides users on how to navigate the game. We added a skip-to-content link to the top of our site that lets users tab to an anchor link at the start of the main content of each page. The “skip” link allows users to easily bypass content that is always present at the top of our pages, such as navigation links and header images. The “skip” link is particularly useful when a user has reached our paywall. When a paywall is present, the “skip” link takes the user directly to the prompts to log into their account or sign up for a subscription. To accomplish this, we change the tab order of the page so it skips all of the page content and goes directly to the subscriber messaging. These are just some of the ways we have improved our web accessibility for some of our key site features at The Times — we also have added closed captions to videos and transcripts for “The Daily.” Our hope is to intentionally build our products so they can be accessed and enjoyed by all. Shilpa Kumar is a software engineer for The New York Times and lives in Brooklyn. Her third-culture-kid upbringing makes her passionate about connectivity through accessibility for all beings. Outside of work, you can find her performing or attending a music gig in the Big Apple. Special thanks to Jazz Lyles, Leigh Scherrer and Garrett Amini for sharing their web accessibility work. How we design and build digital products at The New York Times 174 1 Accessibility Software Development Code User Experience Design 174 claps 174 1 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-03-01"},
{"website": "NewYork-Times", "title": "meeting angelica hill associate product manager at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-angelica-hill-associate-product-manager-at-the-new-york-times-39b43ee420e7", "abstract": "Code Data Product and Design Workplace Culture Work with Us What are your pronouns? She/Her What is your job? I’m an Associate Product Manager on the Messaging team. What does that mean? My team is responsible for building and maintaining the back-end infrastructure for newsletters, emails and push notifications. These platforms are part of our shift to delivering tailored messages to Times readers. How long have you been at The Times? Almost three years as a full-time employee, although I was lucky enough to have been an intern while completing my undergraduate degree in 2016. Most Times employees are working remotely right now. Where are you working from these days? My studio apartment on the Upper East Side in Manhattan. How do you start your day? I try to get outside for a run or a walk along the East River to clear my mind and kick-start my body. What is something you’ve worked on recently? We built an A/B testing tool for newsletters that enables us to test different formatting options to see what best engages our readers. Tell us about a project you’ve worked on at The Times that you’re especially proud of. I led the migration of 51 newsletters from an old platform to a new content-creation platform. The new platform also publishes content to the Times website, so it’s a more familiar tool for editors who also work on articles. It was the first project I led from start to finish, including training editors and ironing out the inevitable bugs. I’m proud of what the team delivered and the collaborative way we worked together. What was your first job? This is my first full-time job. As a student I had the usual part-time jobs (tutoring, bartending, waitressing) but the most satisfying job was as a carer for an elderly woman with dementia. What is something most people don’t know about you? My background is firmly in the arts — I studied acting at the Royal Academy of Dramatic Arts, and English Literature and Drama at Queen Mary University of London — but I’ve spent the last year learning more about software development and I was a keynote speaker at GopherCon last year. What is your secret to career success? Follow your passion. And never stop looking for interesting people to learn from. What is your superpower? Listening. Spending time really listening to those who have more experience than I do and are happy to share it is a shortcut to learning and improvement. What are you inspired by? People who have a passion for what they do, are open to learn and willing to admit mistakes. Sometimes it’s hard to admit weaknesses and lack of knowledge; I most respect those who do. Name one thing you’re excited about right now. One of the few upsides of the pandemic has been the acceleration of digitalization and new ways of working. Innovation is working at pace fueled by new technologies such as machine learning and data analytics, helping us better engage our readers. The opportunity to ride this wave, and see where it takes us is amazing. What is your best advice for someone starting to work in your field? Keep learning, but not just from those in your specific field. Learn from everyone working in related disciplines: whether it’s design, engineering, marketing or project. And don’t forget to listen to the journalists and editors — they are at the heart of what we do. Meeting… Corina Aoi, Technical Product Manager at The New York Times Meeting… Jessie Wu, Software Engineer at The New York Times Meeting… Steven Nedlin, Data Engineering Director at The New York Times How we design and build digital products at The New York Times 56 Nyt Open Meeting Product Management Tech Women In Tech DevOps 56 claps 56 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-02-04"},
{"website": "NewYork-Times", "title": "we recommend articles with a little help from our friends machine learning and reader input", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/we-recommend-articles-with-a-little-help-from-our-friends-machine-learning-and-reader-input-e17e85d6cf04", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Joyce Xu If you create an account with The New York Times, you are presented with a list of popular interests you can choose to follow. It’s a simple idea: tell us what you’re interested in and we will recommend stories in email newsletters and in certain sections of our apps and website. From a technical standpoint, executing on that idea is less straightforward. If you choose to follow interests like innovation, education or pop culture, we need to know whether a given story fits one of those interests. In the past, we determined whether an article belonged under an interest by querying tags attached to the story by its editors. Our taxonomy includes thousands of tags, ranging from broad to hyper-specific, that are arranged hierarchically (the “Food” parent tag has “Seafood,” as well as “South Beach Wine and Food Festival” as children). Some tags are used often, while others are used only once or twice. Some articles are labeled with many tags, while others just have a few. While the tags represent valuable semantic data about the subjects in a story, the queries to manage them have run into issues: Interests might not correspond to the tags for articles . In such cases, the query must be approximate and must string together many related tags, with an ever-growing list of items to include or exclude. For example, there is no single tag for the interest “Parents & Families,” but instead many component tags. At the time of this writing, the query for “Parents & Families” filters over a hundred different tags. Query writing requires knowledge about how the tags are applied, and how they have been used over time. The guidelines for tagging Times articles date back to 1851 and require that articles are tagged as specifically as possible. For example, to query all movie content, one would need to know that from 1906–2013 articles about movies were tagged “Motion Pictures”; we now use “Movies.” Tags represent a literal topic, while interests often represent a nuanced interpretation of that topic based on context. For example, “Children” is one of the component tags that feeds the “Parents & Families” interest. Yet, many stories that have children as their subject might get the tag, such as this news story about children who fled the conflict in the Tigray region of Ethiopia . While that story does focus on children, it is not a good fit for an interest channel about parenting. Algorithmic Recommendations — the team I interned with this past semester — was convinced there was a better way. We thought that if we could automatically detect whether an article fits in an interest by programmatically reading article text, we could move away from these cumbersome queries. For years, the Algorithmic Recommendations team has been applying a variety of natural language processing models to rank and recommend relevant content. One of our longest-standing recommender algorithms is based on Latent Dirichlet Allocation, or LDA, which models each article as a mixture of underlying “topics.” To decide whether to recommend an article to a user, we compare the distribution of topics across the user’s reading history to the distribution of topics in the article. We call the distributions “topic vectors.” The closer the user’s and the article’s topic vectors are, the more likely we are to recommend the article. Unfortunately, we do not directly control which topics the LDA algorithm learns, only the number of topics. In LDA, topics are learned based on the co-occurrence of words across the documents. We have no way of guaranteeing that one of these topics corresponds to one of our established interests — or even that these topics are human-interpretable at all. In order to develop a representation of the interests that users sign up to follow, we needed a new model that associates articles with specific topics of our choosing. We tackled this problem by building a machine-learning model that predicts interests based on the text of an article. This approach is known as “ multi-label classification ” because each data point (in our case, an article) is classified into zero or more labels (or interest groups). To create a training dataset of articles paired with interest labels, we used the existing hand-crafted queries, even though we knew they were imperfect and often miss articles that belong to the dataset. In the table above, the article about cuff links could very reasonably be recommended to a user who follows “Fashion & Style,” but due to imperfect queries, the article is missing the correct label. Similarly, the article about buying jewelry on Instagram is labelled only “Business & Technology” because it is missing the relevant tags to be labelled “Fashion & Style.” Noisy labels can still be useful, as long as the model does not memorize and reproduce occasional inaccuracies in the training data. To minimize the risk of inaccurate labels unduly influencing our model, we preferred small, simple models over large, complex ones, and we averaged predictions from multiple different models. We used an ensemble of logistic regression models: each model independently leverages its previously predicted labels to help predict the next label. This approach is known as an ensemble of classifier chains. Since our classifier models were relatively simple, we made sure to extract rich and expressive feature representations of articles for the classifiers to use. After many rounds of testing, we landed on a final representation with three components: An LDA topic vector, as discussed above. A vector based on keywords: words that are unusually common in the article. A Universal Sentence Encoder embedding. The Universal Sentence Encoder, or USE, is a neural network that transforms input text into a vector representation: texts that are close in meaning produce vectors that are close in distance . [If this type of project sounds interesting to you, come work with us .] To encourage the model to encode semantic knowledge, the original researchers at Google trained it on tasks such as predicting Q&A responses or inferring logical implications. It is one of the few models that is designed to handle longer-than-sentence-length inputs, making it handy for encoding our articles. While the first USE model was trained on datasets pulled from Wikipedia and online discussion forums, we retrained our instance of the model on Times articles. Because The Times has been publishing journalism for nearly 170 years, we had plenty of content to fuel our dataset. Once we obtained these embeddings and combined them with the LDA and keyword vectors, we applied the classification model, which produced a probability score for each interest. We were able to establish a cut-off probability for each interest, and compare them to the query-based labels for evaluation. As we suspected, the machine-learning model casts a wider net for each interest than the hand-crafted queries, and it returns more relevant articles. When we took a deeper look at a few of the incorrect labels, we could often understand why the model assigned the label, but saw that correcting the mistake requires human judgement. It takes knowledge of history and society, as well as the ability to recognize context to intuit that some articles are better suited for some interest categories than others. We came to realize that even though our model outperforms the existing query-based system in many ways, it would be irresponsible to let it curate interests without human oversight. Readers trust The Times to curate content that is relevant to them, and we take this trust seriously. This algorithm, like many other AI-based decision-making systems, should not make the final call without human oversight. This interest classifier is already in use as one of a number of inputs our algorithms use to calculate article recommendations. Looking forward, we intend to set up a collaborative editor-in-the-loop workflow with the newsroom and incorporate this algorithm further into our personalized products. With more precise recommendation algorithms and editorial oversight, we can offer readers better reading experiences across the wide range of content that The Times produces every day. Anne Bauer, director of data science at The New York Times, contributed writing. Joyce Xu studies Computer Science and History at Stanford University. She was a Data Science Intern with Algorithmic Recommendations at The New York Times. Follow her on Twitter . How we design and build digital products at The New York Times 137 Machine Learning Data Data Science Algorithms AI 137 claps 137 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-03-04"},
{"website": "NewYork-Times", "title": "traffic turkey and no knead bread", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/traffic-turkey-and-no-knead-bread-e3d5f54e15f", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Tiffany Peón Most years, the writers and editors of the New York Times Food section begin preparing Thanksgiving stories in the summer, sometimes cooking entire turkeys in their sweltering homes to test recipes. The engineering team for NYT Cooking starts preparations just as early, though our work doesn’t usually involve sweating over poultry. When decorative gourd season still seems impossibly far away, we start planning technical improvements to handle our annual traffic increase. While most of the year is spent working on new features, we take a break as the holiday nears to ensure that we’re ready for our ever-growing traffic. In late July we revisit the list of discoveries from the last Thanksgiving traffic bump to determine whether performance optimizations or infrastructure changes should be prioritized in the fall to make sure we don’t find ourselves in a crunch. After the holiday, we review how everything went and we make plans for improvements that we implement throughout the year. Early this year, we had just finished some of the post-holiday work — a database upgrade and API performance improvements — when we were brought a new challenge in the form of unprecedented traffic to NYT Cooking in March. As many people began staying home because of the coronavirus pandemic, they started baking no-knead bread and learning how to use that Instant Pot they had never taken out of the box. By April, traffic to NYT Cooking hit Thanksgiving levels every day. Until that point, all of our efforts to improve site stability and performance hinged on the assumption that our traffic was seasonal and came in short but predictable bursts. But in April, our database was overloaded, our free-trial enrollment system was backed up by a week and our web servers were unable to process the number of requests coming in at once. With no end to our new traffic baseline in sight, we needed to act quickly. Luckily, we bought ourselves some time with the changes we made at the beginning of the year, and had a list of potential improvements to address right away. Our site gets the majority of its data from a Postgres database that holds our recipe, collection and user information. As our traffic increases year over year, we find that certain parts of our application begin to stress our database due to non-performant queries. In the month leading up to Thanksgiving, we rely on monitoring tools like DataDog to find bad queries and investigate endpoints that experience latency increases during periods of high traffic. Depending on the data needed for each page, we take different approaches to fix these bottlenecks. In some cases, we simply need to rewrite our database queries to be more efficient. In past years, we looked at the data from the month of November to find problem areas that needed to be fixed. However, due to the sustained high traffic we’ve experienced this year, we’ve been able to identify more of these non-optimal queries and have been working to improve them. In other cases, the recipe data that we need for some pages is also available through a GraphQL API that is maintained by a number of teams at The Times. In early 2019, we switched the way we access the data, calling the GraphQL API rather than querying our database. This helped relieve some of the load across all of our recipe pages, and throughout the year we continued to move database calls over to the API wherever we could. We realized that Postgres wasn’t always the right tool for some features — like Recently Viewed, which keeps track of each recipe a reader views — so we rewrote the features to use a different data storage method. Before last Thanksgiving, we migrated our Recently Viewed service from a Postgres database where we used a json_blob data type that was non-performant for writes. We moved to Google Cloud Platform’s datastore, which allowed us to optimize for both writes and reads. One unintended effect of relying on more external APIs to relieve our database load was that our web server workers began timing out at lower traffic rates. Our application’s back-end is written in Ruby, which has a blocking I/O, meaning that a worker has to wait for each request to be resolved before it can respond to a new request. Last Thanksgiving, we discovered that our web servers were throwing errors during high-traffic periods because all of the workers were in use. As a quick fix, we adjusted our autoscaling policy to allow Amazon Web Service’s EC2 to scale up to a larger number of web instances. The fix worked, but a colleague pointed out that the CPU usage on our web instances remained low, even with no available workers. This meant we weren’t making the most of the available resources on each web server and we were paying for extra instances that we didn’t need. In April, we changed our web server configuration and increased the number of workers per web instance. After some monitoring with DataDog, we confirmed that by processing more requests with each instance, we could reduce the number of web servers we use in EC2 again, which saved us some money and allowed us to get more from our existing instances. Any new user who comes to our site is automatically enrolled in a free trial for NYT Cooking . We don’t require credit cards or any sort of opt-in, so this number scales proportionally with new traffic to the site. Before April of this year, we knew that periods of high traffic led to a backup of free-trial jobs. This was caused by the library we use, DelayedJob, which doesn’t perform well when there are over 100,000 jobs in the queue. In order to alleviate this, we separated our free trial jobs into their own queue. Then we introduced worker pools that can simultaneously process the free trial queue and a queue for all other jobs. Additionally, our colleagues on the Subscription Management team improved the average speed it takes for our back-end to check whether or not a visitor is eligible for a free trial, allowing us to work off our backlog of free trial enrollments within a week. Due to the extreme traffic we experienced in the first half of this year, we were pushed to complete a good deal of the stability work we would usually wait until the fall to address. By the end of September, the work we started discussing in July was defined and ready for development. In a shift from previous years, this year’s preparations for Thanksgiving involved improvements to our SEO and content strategies, with only two performance-based initiatives we had decided were not critical in the spring. While we have learned the value of making incremental improvements and the cumulative impact they can have on our stability, this year has taught us that setting aside time to do major software upgrades can help improve our ability to maintain our applications and identify issues. NYT Cooking is growing, and with this new approach, we can ensure that our software grows along with it. Tiffany Peón is a Lead Software Engineer for NYT Cooking. She spends her free time in the kitchen, likely making recipes from NYT Cooking. How we design and build digital products at The New York Times 50 Technology Code DevOps Software Development 50 claps 50 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-11-23"},
{"website": "NewYork-Times", "title": "how the new york times technology teams prepared for the 2020 election", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/how-the-new-york-times-technology-teams-prepared-for-the-2020-election-3928ce7f923c", "abstract": "Code Data Product and Design Workplace Culture Work with Us What does it take to prepare The New York Times for a presidential election during a pandemic? For the teams that manage the website, apps, CMS and other technology systems, it took over a year of extensive planning, testing and coordination to ensure that the newsroom could reliably publish the news on election night and that readers could access it. A few weeks before the election, Sarah Bures, editor of NYT Open, talked to Alexandra Shaheen, program lead, Megan Araula, tech lead, and Suman Roy, engineering director, via video chat about their work leading the Election Readiness project. This conversation has been edited for clarity and length. Sarah Bures: What is the Election Readiness project? Can you walk me through what that means? Alexandra Shaheen: The purpose of this project was to assess the systems that are critical to our success on election night, to see where those systems are in terms of reliability and resilience and to improve the systems to meet the traffic levels expected on election night. Bures: When did you start working on this project? Shaheen: Our team was assembled two weeks prior to the democratic debate that The New York Times co-hosted with CNN in October, 2019 , and support for that event truly kicked things off. Bures: How many teams do you work with? Shaheen: The scope of this project is really the entire Tech organization at The Times. Bures: Vinessa Wan and Kriton Dolias wrote about some of the election preparedness work that they led in 2018. Is this essentially a continuation of the work that they started? Suman Roy: It is a continuation, but the scope and the ambition are much greater. We are able to aim higher because we had a solid foundation laid by Vinessa, Kriton and many others. Bures: What are some of the assessments that you did with all of the teams? Megan Araula: We did architecture assessments for user-facing and print-facing publishing applications, e-commerce, login, registration and personalization applications. We saw a few commonalities via these assessments, particularly a lack of documentation and preparation on application architecture, monitoring and mitigation procedures. Bures: How did you put together the criteria for the architectural reviews? Did you look at past elections to make a list of what was expected of applications? Araula: The Delivery Engineering team created the criteria for architecture assessment, which was refined by the Election Readiness team within the past year. We helped formalize the process by creating documentation and best practices around it. We made sure that there was a guideline document that had the criteria and recommendations. We also made sure that there was a process to on-board future reviewers. The architecture assessment is divided into eight sections; architecture and application design, application deployment, cloud configuration, security, capacity planning, logging and monitoring, failure and outages, and service maturity. These sections help us identify how well a system is prepared for a big event, how well the engineering team understands their system and how prepared they are if an issue arises. These assessments are not the final word on architectural or operational decisions, but they are recommendations intended to better prepare teams for an event. Shaheen: In addition to the architecture reviews, we conducted operational maturity assessments to ensure that the teams had a good level of observability into their systems, and that the alerting was set up to monitor these things appropriately. We also wanted to determine whether there were enough people on the team with knowledge into all of the systems that the team owned. So we looked at, not only just the nuts and bolts, but how we as humans are monitoring these systems. We also did stress tests, where we threw artificial loads at systems to see how things degrade. This provided insight into what users would see (like generic 500 error messaging versus graceful degradation) if our systems failed. Additionally, we wanted to see where systems could take out another system. Between stress tests, architecture reviews and operational maturity assessments, we could see where things stood with each of these systems, which systems would benefit from additional investment, and where there were single points of failure in terms of our ability to support the critical business workflows that they map to. Bures: How do you decide which applications are higher priority or more critical? Shaheen: This is a conception of criticality that Vinessa pioneered, where she identified and ranked the most important workflows at the company. For example, the workflow of being able to publish content and then being able to view that content via the website and in print is our most critical workflow. And that ranks above being able to receive payment for a subscription. If all else failed, we’d want to be able to get the news out. Our revenue would fall second to that. We then structured our resilience investment based on which systems fell into critical workflow buckets. Most of the publishing workflows related to digital or print content production are considered to be Tier Zero. The e-commerce flows are Tier One, which are still very important to us, but not as important as getting the news out. And things like targeted advertising and sending newsletters are still important, but considered to be Tier Two. Bures: That’s really interesting. What are some of the worst-case scenarios that you prepare for? Roy: We looked at every one of our Tier Zero workflows and every system that serves these workflows. We looked at existing business continuity plans, hardened them if necessary and devised new continuity plans to fill in the gaps. In case of a system outage, we built a backup New York Times website that produces the homepage, interactives and articles. Shaheen: On election night, we need to be able to communicate effectively, as this impacts the triaging of, and mobilization around, an incident. To manage incidents in an ordered, effective and repeatable way, we rely on a rotation of incident commanders to steward communication, which allows system subject matter experts to focus on resolving defects effectively. We’ve also had to think about how our unique remote situation this year impacts us. For example, our remote work adds more traffic and strain to our VPN. Given this circumstance, how can proactively fortify the VPN so that it can handle a higher increase of users? As an organization, we’re always thinking about these things, but we need to also understand how this year presents additional nuances. Examining silos within the organization and opportunities for knowledge sharing has also been a major theme. How many members of our teams are really versed in the steps that are needed to do a fail-over? Instilling norms around sound documentation and running practice drills have helped us share knowledge and become more confident. We need a plan for everything, a backup plan for everything, and then an idea of what we should do if both of those plans fail. Bures: So many plans. How do you figure out who needs practice and who doesn’t? Or do you say, “Today we’re going to do a drill and everyone’s going to participate”? Shaheen: Sometimes things happen in production which removes the need to plan drills for practice. Looking at how teams respond to events in production gives you an inkling of how well prepared we are. Was it a really tough incident where people didn’t know what to do and it took a while to come to the right understanding of how to proceed? If so, that’s maybe an indicator that more practice is needed. Roy: The months leading up to the election gave us ample opportunities for practice: any system that can fail, has failed. We observed how the teams fared and then we planned drills to address gaps in preparedness. We also practiced for scenarios that are very unlikely to happen but scenarios that we must nonetheless be prepared for. As an example, the systems that support our print production are reliable and haven’t caused us to miss a print deadline in decades. Even so, our editors practiced producing the print editions without the help of Scoop, our primary CMS. Bures: So you’re not just working with the Technology team, you’re working with editors and producers, as well. Roy: Yes, absolutely. It is a true collaboration. Shaheen: Honestly, we can’t take credit for most of this stuff. This has been the hard work of this entire organization. And a lot of times we’ll have a conversation with folks and they will take it upon themselves to improve their systems. It’s important to recognize that. Shaheen: This is a highly irregular year and effort. We went from supporting the Iowa Caucus and Super Tuesday in a way that was similar to past years to confronting a general election that will be unlike any other. Now we’re modeling our support plan on something that’s completely ambiguous. We don’t know if we are going to be supporting a one-day event or a 40-day event. Bures: I keep thinking about how there’s so much that isn’t known about how long this election might last. We just don’t know what’s going to happen. Shaheen: We don’t. In past years, we’ve had an election night where everyone’s in a room together and if there are problems, they can jump on them. Right now, we have two designated shifts where over a hundred engineers will sit on a video call while actively monitoring their systems. Bures: And everyone will be there in case anything happens. Shaheen: Exactly. Hopefully this video call is silent the entire night. There’s no need to talk unless something is happening! [ Read more: Readers Stayed Glued to The Times to Understand the Election ] How we design and build digital products at The New York Times 180 Technology Code Engineering Systems Thinking Project Management 180 claps 180 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-11-12"},
{"website": "NewYork-Times", "title": "meeting shay culpepper software engineer at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-shay-culpepper-software-engineer-at-the-new-york-times-5dedb47389fe", "abstract": "Code Data Product and Design Workplace Culture Work with Us What is your name? Shay Culpepper What are your pronouns? She/Her What is your job? Software Engineer What does that mean? I work on tracking and analytics for our home screen, both on our website and our mobile apps. Right now, I’m building a dashboard so the newsroom can monitor click-through rates on the home screen. How long have you been at The Times? Almost a year and half. Most Times employees are working remotely right now. Where are you working from these days? I’m working from a little makeshift desk next to my bed from my apartment in Morningside Heights, a neighborhood in Manhattan. It’s one of those cheap IKEA desks. I took two of the legs off and it rests on my windowsill. How do you start your day? I’m a Texan, so the most important thing I do every morning is make a giant glass of iced tea. It is just Lipton tea over ice and it is delicious. The next most important thing I do is pick out a dress and loud earrings for the day. Once I’m ready to work, I look over the paper planner that I use to keep meeting notes, a to-do list and most importantly: my daily wins. I like to check in the morning to make sure I have written down something I’m proud of from the day before. Next, I look over the to-do list items that haven’t been checked off yet. Then I check my google calendar for what meetings I have for the day. The most important step is then planning what tasks I will complete in specific blocks of time (Thank you to my colleague Carolyn Price for this tip). What is something you’ve worked on recently? Lately my team, Core Product Data, has been working with the data visualization team to rethink how we build dashboards for the newsroom. We have been sketching out the architecture for a completely new platform that would allow teams to quickly and easily build new dashboards. I find creating projects from the ground up fun because you end up getting to do a lot of research. Tell us about a project you’ve worked on at The Times that you’re especially proud of. This isn’t part of my core job responsibilities, but I’m very proud of the work I have done through Women in Tech as part of the leadership committee. Women in Tech is an internal task force at The Times that works to improve diversity and equity in recruiting, retainment and advancement. My teammate Shelly Seroussi and I launched a buddy program for new employees in technology. We match new employees with veteran staffers to help them network across the organization and acclimate to Times culture. The buddies meet regularly for the first three months the new hire is on staff. What was your first job? I served fried chicken at a place called Chicken Express. I had access to so much fried okra. I love okra in all of its forms, but fried is truly the best. What is something most people don’t know about you? All three of my brothers are engineers, my mom is an IT administrator and my dad is a scrum master. We all got into tech by very different paths, and it is fun to share tech as a family. I like to think of us as “The Developeppers,” but that name sadly hasn’t caught on. What is your secret to career success? Beyond luck, privilege and working hard, I like to think I owe most of my success to radically being myself and opening space for others to be their full selves. This means being upfront and honest about my weaknesses, and it has meant being upfront about my mental health. The fact that I’m bipolar doesn’t come up too often, but I have found that being willing to talk about it breaks down barriers. I have had several colleagues open up to me about their own journeys as a result. Being upfront also means owning mistakes and apologizing: I made some bad calls during a big project last year, which made the project stressful for my entire team. I had to own that, apologize and spend time doing the work to be better during future projects. I also like to open up spaces for one-on-one communication with my teammates. Sometimes that’s coffee, sometimes that’s small silly Slack conversations and sometimes it is virtual hang outs after work. Being intentional about developing relationships helps you build trust and your work will be better for it. I should also note that a lot of this isn’t possible without taking care of myself. While companies might offer support healthcare and paid time off, they can’t make me take those days off and they can’t make me go to the doctor. I have to take care of myself and my mental health. No one can do that for me. What is your superpower? I can whip up very silly presentations in a bind. What are you inspired by? Times journalism and my colleagues keep me going every day. I’m constantly pinching myself. I count myself very lucky to be part of an organization that produces such excellent journalism. Name one thing you’re excited about right now. I’m pursuing a master’s degree in Data Analysis and Visualization at The Graduate Center, which is part of City University of New York. Next semester, I have a data visualization course that is studio style, meaning there will be lots of critique. I’m excited because there is nothing as helpful as feedback when it comes to visualizations: you need to know if your audience understands your intended message. What is your best advice for someone starting to work in your field? For your first job, just try to get your foot in the door somewhere. Working at the big companies can come later; Once you have a couple of years under your belt, a lot opens up for you. Where you worked is less important than what you worked on. Meeting… Ashka Gami, Marketing Director for New York Times Games Meeting… Gaëlle Sharma, Technical Product Manager Meeting… Jeremy Gayed, Lead Software Engineer How we design and build digital products at The New York Times 15 Nyt Open Meeting Developer Software Development Code Women In Tech 15 claps 15 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-01-12"},
{"website": "NewYork-Times", "title": "meeting sara pena designer at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-sara-pena-designer-at-the-new-york-times-68188defe960", "abstract": "Code Data Product and Design Workplace Culture Work with Us “Meeting…” is an ongoing series from NYT Open that features New York Times employees from different corners of the company. In this installment, we meet Sara Pena, a designer. What is your name? Sara Pena What are your pronouns? She/Her What is your job? Designer What does that mean? I’m a designer on the Commerce team, which means I work with Times Journeys, The School of The New York Times, The New York Times Store and The New York Times Wine Club on different marketing projects. How long have you been at The Times? I’ve been at The Times for two and a half years. Most Times employees are working remotely right now. Where are you working from these days? I’ve primarily been working from a house near the Jersey Shore. How do you start your day? Typically I wake up around 7 a.m., check the news, play with my dog, Pocco, and then I will go for a run, do yoga or go on a bike ride. I’ve been trying to get a few minutes of meditation in before I have breakfast and begin checking emails. What is something you’ve worked on recently? I’m currently working on a dog book with the Store that features a combination of Times articles, photos and original illustrations dating back to the 1800s. Tell us about a project you’ve worked on at The Times that you’re especially proud of. When I started on the Commerce team, I primarily worked with Times Journeys to redesign a lot of the marketing materials. The biggest redesign project was for the 100-page catalog we send out each year to showcase our trips, experts and photography. Last year, we decided to reimagine its layout and ended up with three smaller booklets that streamlined our content, incorporated multiple illustrations and a foldout of a map of the world highlighting a number of our trips. With the smaller sizes, we were not only able to decrease costs but increase mailing numbers by more than double to expand our reach. What was your first job? I worked in a frozen yogurt and smoothie shop, then I left to assist in a custom framing gallery. What is something most people don’t know about you? I’m a Phish fan! What is your secret to career success? I’ve always tried to stay motivated and positive even if things don’t go my way. I’m also a big believer in using the resources I’ve had and keeping my connections going — you never know who knows whom in the design world. What is your superpower? My attention to detail. What are you inspired by? I love printmaking and am especially inspired by letterpress. Anything bold or graphic makes me want to get back into the studio life. Name one thing you’re excited about right now. I’m going to be spending a few days in Montauk soon, and I can’t wait to bike ride around and explore! What is your best advice for someone starting to work in your field? Keep in touch with people from your past: a classmate, a teacher, a mentor, a former coworker or boss. They’re all great contacts to have, and you never know when you’ll need a reference for something. How we design and build digital products at The New York Times 34 Nyt Open Meeting Design Work Jobs 34 claps 34 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-11-16"},
{"website": "NewYork-Times", "title": "finding the right words", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/finding-the-right-words-491b93b8b668", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Sarah Duncan Words have meaning. This statement shouldn’t be a surprise coming from The New York Times, but for the technology industry at large, it’s something that has been increasingly discussed in recent years. Whether it’s terminology like “master” or “blacklist,” words with harmful connotations have been baked into tech communication for decades. Words like these bring with them the weight of slavery and discrimination, and signal that those who have held power in the tech industry have had the privilege to ignore the impact of these antiquated terms. People of color are still underrepresented in tech, and the industry’s continued use of these terms acts in direct opposition to an inclusive and equitable culture. However, tech culture is changing. In 2014, Drupal replaced “master” and “slave” with “primary” and “replica.” Then, in 2018, Python adopted new terminology such as “worker” and “helper.” More recently, Github announced that they would permanently change their default naming conventions for initial repository branches from “master” to “main.” Like many other organizations, The Times is re-examining the language we use to be more mindful of how we describe our technology. With the support of our technology leadership and product stakeholders, a group of Times engineers and product designers wrote a set of guidelines for our own naming conventions. We are sharing them here with the hope that advocating for these changes adds to the momentum we’ve seen in the technology industry to create a safe and inclusive culture for all. Alternate terminology to replace “master/slave” Primary: This denotes the database that is the source of truth. Standby: A Standby serves as a replica that follows the state of the Primary database. Alternate terminology to replace “master” Primary: This communicates prioritized, shared content. It is a source of truth. Base: This communicates a source or template from which other items can be derived. Main: This communicates order or hierarchy, especially in navigation or information architecture contexts. Original: This communicates the first instance of something or the origin of a copy. Source: This is similar to “base” or “original” and can serve either purpose. Central Plan / North Star: These will replace terms like “Master Plan” in contexts where they are needed. Alternate terminology to “master” and “slave” Controller, Manager, Mediator: This references an object that distributes tasks or encapsulates how a set of objects interact. This is the Mediator in the Mediator Design Pattern, commonly used to coordinate between different workers as described in this Dive into Design Patterns . Worker, Colleague: This is an object that executes a task or process, coordinated through a dispatcher or parent process. This is the Colleague in the Mediator Design Pattern. Alternate terminology to replace “whitelist” and “blacklist” Although “whitelist” and “blacklist” carry implications of the history of slavery and discrimination, they are largely arbitrary terms that are not particularly precise or explanitory. Some alternatives that overcome those limitations include: Allowlist: This references a list of users or resources which are granted access to a particular system or set of systems. Denylist, Blocklist: This references a list of users or resources which are denied access to a particular system or set of systems. Access Control List (ACL): This references a list of rules which indicate which users or systems are allowed access to a particular set of resources. When in doubt, be specific! For example, if you’re filtering banned words, specify why those words are banned using phrases like, “insensitive word list” or “offensive word list.” Alternate terminology to replace “master” branches main: If an alternative to “master” is needed for a source of truth, production-ready branch, we recommend “main.” Any additional options, like using “production” or “develop” also work! With the understanding that making these kinds of changes takes time, all of our digital product teams will be incorporating these new terms into engineering, product and design work by the end of the first half of 2021, with exact timelines decided by the magnitude of the changes required. Going forward, we are asking teams to abide by these guidelines in all new work. Recognizing that this is an iterative process, we also encourage our colleagues to propose additions to the guidelines. As a journalism and technology company, we believe in using words that align with our values . And we believe in fostering an inclusive, equitable and diverse culture. Changing the terminology we use is one small piece of that larger mission. Sarah Duncan is a Senior Data Engineer from Brooklyn, NY, working as the Tech Lead for the Media Innovations team in Data Engineering. Over her two years at The New York Times, Sarah has started the Python Community of Practice and joined and chaired the Architecture Review Board. She has a passion for making software reusable, data easily accessible and tech communities inclusive. How we design and build digital products at The New York Times 377 Product Code Language Work Workplace Culture 377 claps 377 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-11-19"},
{"website": "NewYork-Times", "title": "meeting kendell timmers vp ad and growth data at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-kendell-timmers-vp-ad-and-growth-data-at-the-new-york-times-89507b54f726", "abstract": "Code Data Product and Design Workplace Culture Work with Us “Meeting…” is an ongoing series from NYT Open that features New York Times employees from different corners of the company. What is your name? Kendell Timmers What are your pronouns? She/Her What is your job? Vice President for Advertising and Growth, Data and Insights What does that mean? I manage the data teams responsible for advertising analytics and subscription growth analytics. It’s exciting to get to work on two intertwined but very different parts of the business at once. How long have you been at The Times? Two and a half years already, although I still feel new! Most Times employees are working remotely right now. Where are you working from these days? My home in Glen Ridge, NJ, with my husband, two kids and an absurdly loud cat. How do you start your day? I start the crossword, then take a spin through the Slack channels and the headlines on The Times. What is something you’ve worked on recently? Launching the first-party targeting product for advertising. Tell us about a project you’ve worked on at The Times that you’re especially proud of. Launching first-party targeting made me especially proud because it was an impressive cross-functional effort — it proved that a group of brilliant Timespeople in data science, data, ad product and engineering could compete with a giant third-party data provider. What was your first job? First job out of college, I worked as an “inventory analyst” to tweak the overbooking system at an airline. If you ever got bumped off a flight to Florida on US Airways … that might’ve been my fault. Sorry. What is something most people don’t know about you? I am a voracious reader; I read more than 100 books last year. (This year… not so much.) What is your secret to career success? Try new things. Be curious. Fail and try again. What is your superpower? Curiosity. I am interested in solving problems and almost ANY problem can be interesting to me. What are you inspired by? My co-workers! I’ve never met such a talented, interesting and dedicated group of people as the folks I work with across The Times. Name one thing you’re excited about right now. There’s a gelato place that just opened within walking distance of my house. Lucky for me they are only open four days a week… What is your best advice for someone starting to work in your field? Never assume you can’t do it. Even if you know nothing about an industry or application today, if you have basic skills, attention to detail and willingness to learn, you can move into anything you want to do. Meeting… Ashka Gami, Marketing Director for New York Times Games Meeting… Gaëlle Sharma, Technical Product Manager Meeting… Jeremy Gayed, Lead Software Engineer How we design and build digital products at The New York Times 41 Nyt Open Meeting Data Adtech Advertising Audience 41 claps 41 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-10-29"},
{"website": "NewYork-Times", "title": "meeting jeremy gayed lead software engineer", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-jeremy-gayed-lead-software-engineer-81ce9f612010", "abstract": "Code Data Product and Design Workplace Culture Work with Us “Meeting…” is an ongoing series from NYT Open that features New York Times employees from different corners of the company. In this installment, we meet Jeremy Gayed, a lead software engineer. What is your name? Jeremy Gayed What are your pronouns? He/Him What is your job? Lead Software Engineer What does that mean? Typically, I work with other engineers across teams and projects to help lead technical decisions. How long have you been at The Times? Time flies! It’ll be six years in December. Most Times employees are working remotely right now. Where are you working from these days? I’m working from my home in northern New Jersey. How do you start your day? Typically, it starts with my son or daughter providing a too-much-energy-for-this-hour-of-the-morning wake-up call. What is something you’ve worked on recently? Most recently, I’ve been working on our GraphQL strategy at The Times. Tell us about a project you’ve worked on at The Times that you’re especially proud of. A few years ago, we were fortunate enough to work on a green field project: the replatforming of our core site architecture. It started out with the home page and story pages, but it has grown to support multiple reader-facing products today, such as the video and audio pages. What was your first job? I think it was at Blockbuster, back when renting physical movies was a thing. I thought I’d love the perk of free movie rentals, but the job was super boring so I only lasted a couple months. What is something most people don’t know about you? I really enjoy seeing other people completely nerd out on a passion of theirs — it’s so fun seeing how much enjoyment someone gets out of something they care a lot about. What do I enjoy nerding out on? Halo! What is your secret to career success? I have learned a lot from others. It’s an order of magnitude better and faster than figuring things out on your own. What is your superpower? I love picking up a topic I know little about and digging deep into the rabbit hole to understand all the nuances that usually takes a lot of time and experience to understand. What are you inspired by? I’m inspired most by my dad. He’s a person of profound wisdom, but he also has deep humility and finds great joy in helping others. Name one thing you’re excited about right now. The NBA is back! It’s been such a slow grind these past few months without some elite-level basketball to watch. What is your best advice for someone starting to work in your field? Don’t be afraid to ask questions! Nobody really knows what they’re doing and we’re all just figuring it out. If someone else already has the answer, it usually just means they started earlier than you — there’s no shame in that. Meeting… Tiffany Peón, Senior Software Engineer at The New York Times Meeting… Nimpee Kaul, Lead Program Manager at The New York Times Meeting… Natalya Shelburne, Senior Software Engineer at The New York Times How we design and build digital products at The New York Times 66 1 Nyt Open Meeting Tech Code Work Software Engineering 66 claps 66 1 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-09-22"},
{"website": "NewYork-Times", "title": "how we made a design system for nyt cooking on android", "author": ["Jayne Lee"], "link": "https://open.nytimes.com/how-we-made-a-design-system-for-nyt-cooking-on-android-c57ce7f0905e", "abstract": "Code Data Product and Design Workplace Culture Work with Us In a perfect product development scenario, a designer could sketch some boxes on a napkin and hand it to an engineer who would know exactly what to build. The boxes would correspond to elements in an established design system that codified things like color, typography and structural components. A design system ensures that everyone working on a product has a reference point for all of the features in the project. It allows teams to build and ship features faster. When the NYT Cooking team started preparations to build an Android app in April 2019, we didn’t have a design system. At the time, our design team was made up of two designers and a design manager, which meant we often juggled a lot of work. As the sole designer on the Android project, I knew that it was the perfect opportunity to create a design system that the NYT Cooking Android team could use. These are some of the steps I took. Because I had created design systems before, I knew it would be a process of trial and error. It’s normal to not know whether design elements included at the beginning of the process will still be there when the system is finished. To introduce some clarity, I defined loose guidelines, which anchored my decisions down the line. Design principles. The team wanted to ensure that the app felt native to the Android ecosystem, which meant we would utilize native Android design patterns and paradigms. We decided to use Google’s Material Design framework as a foundation for the UI elements, while making sure that we upheld the NYT Cooking brand through styling and typography. System users and software. The design system users were members of the design and engineering teams: designers would actively contribute to the system and engineers would reference the system. We used Figma because of its powerful Team Library feature and its ease of use for engineers. A living design system document is the place where designers actively contribute to and update the system; it’s the most frequently updated document. A design system reference is a polished document that explains the system in detail, which is most useful for non-designers. Brad Frost describes the living document as the designer’s workshop and the reference as the shopfront. To streamline the workflow for future team members, I decided that the format of the design system documentation would be simultaneously a living document and a reference. The two most important features in Figma for a design system are Styles and Components. Styles are basic elements such as color and typography. Components are more complex elements, such as buttons or navigation bars; I like to think of components as templates. Metaphorically, a Style is an atom and a Component is a molecule . When combined, they become templates and pages, according to the atomic design structure laid out by Brad Frost . Atomic design is the ideal way to structure a design system because it anticipates change. If we decided to change our brand color or the font size of a headline, we would update it in one location and it would be implemented throughout the entire system. This reduces the amount of time needed to make a style or design change and ensures the change is reliably applied in every design. I had the benefit of our existing suite of products, so I audited our iOS app and website to decide what design elements to keep. Audit Our recipe pages are the most visited pages in our entire app, so the NYT Cooking product manager, design director and I decided to tackle this view first. Any recipe view — even a recipe in a book — is almost all typography, so the two things I needed to define first were the spacing system and typography. Spacing Since I was leaning on the Material Design framework, I decided to use their recommended spacing system. We use increments of eight, and occasionally use increments of four, for spacing, as Material Design suggests. Typography Recipes have many types of information, so to distinguish each part of a recipe and establish a clear hierarchy, I chose a succinct number of weights and styles from NYT Cooking’s three typefaces: Cheltenham, Karnak and Franklin Gothic. Recipe views were the most challenging to design, but once the typography was set, they informed the typography on other views. Though we had the established iOS app that we could have drawn from, I used the new Android designs as an opportunity to modernize our typography from our existing platforms. Color From a product perspective, we use color minimally as a way to support the content that our editors work so hard to produce. We use a variety of grays; full black is reserved for the New York Times logo. To streamline the number of grays we use across NYT Cooking, I started designing with two grays and carefully added more when they were warranted. We ended up with eight grays, ranging from a dark, almost-black gray to a light, almost-white gray. In addition to our palette of grays, I used the NYT Cooking-brand red as our accent color. In digital product design, red is almost always reserved for cautionary actions and messaging. Using it as an accent color is not a common choice because it can conflict with the platform-native red of things like error messages in form fields. However, we do not use many form fields in NYT Cooking. I styled our UI elements with a tasteful amount of red without conveying that users made an error. I used a brighter shade of red to indicate error states. Iconography Because we were building a design system while simultaneously launching our Android app, we opted to use some of the icons provided by Material Design. I didn’t see the need to reinvent the wheel at that point of the app lifecycle. The only exception we made was for our save icon, which is prominently displayed throughout our app. Creating Components Components are templates for elements like a button or navigation menu; The key thing about components is that they are reusable. I started creating components once I found myself reusing the same element in multiple places, like our cards. Cards Cards are our primary components and are used throughout our entire app. Our cards provide an abbreviated look into the content, whether it is a recipe, a collection or a guide. These three content types are fundamentally different so we made them visually distinct. It was hard to anticipate how these cards would look across screen sizes. While there are a standard set of breakpoints for iOS and the web, Android tends to have a wider variety of screen sizes. I defined the base card size to align with the smallest screen size on Android, so that the design would adjust to subsequently larger screen sizes. We have strict rules about how our content is displayed. The hierarchy of the content on a card is: image, title, byline, action. Our recipes can have long titles that break to multiple lines of text, and they can have long or double bylines. I tried to display as much content on our cards as possible by slightly enlarging the card containers. The logic for text to be displayed on our recipe cards is borrowed from iOS and was adapted for Android. Having a design system in place has helped our team immensely. Designers who are new to the system have used it to guide their designs, which has allowed the team to ship features faster than before. The Android design system is still a work in progress, but its proven success has kickstarted the process of cementing a design system for our iOS app and web product. Jayne Lee is a product designer on the NYT Cooking team. Follow her on Twitter . How we design and build digital products at The New York Times 140 1 Design Design Thinking Design Systems Product Development 140 claps 140 1 Written by designer in NYC | http://maryjaynelee.com How we design and build digital products at The New York Times. Written by designer in NYC | http://maryjaynelee.com How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-09-24"},
{"website": "NewYork-Times", "title": "innovating from home maker week at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/innovating-from-home-maker-week-at-the-new-york-times-50ecfa38aca1", "abstract": "Code Data Product and Design Workplace Culture Work with Us Maker Week is an annual tradition: New York Times employees in Data, Design, Marketing, Product and Technology are given the freedom to step away from their normal responsibilities and work on self-directed projects. The event is time for our colleagues to experiment with new ideas or iterate on old ones. This year, our colleagues worked on over 96 projects and participated in 24 peer-led workshops over five meeting-free days. We asked some of our colleagues to share their projects and what they learned. By Aiyana Brooks (software engineer) and Alice Fung (senior data analyst) AcroBot is a Slack bot that enables users in The New York Times workspace to easily look up acronyms used within the company. This can be extremely helpful when onboarding new employees, or when forming cross-functional teams, as teams tend to have their own sets of jargon. The bot provides the definition of the acronym along with helpful context about how the acronym is used. AcroBot is built using Python and uses the Slack API to interact with Slack. The data is backed-up on a Google Sheet, which makes it extremely easy to share and view the complete dataset. By Jeremy Chen (senior software engineer) Auditorial uses the Google Natural Language API to process New York Times audio transcript data and parse important and salient keywords. It then subsequently recommends relevant Times Tags using the NYT Semantic API. The goal of this project was to explore the feasibility and efficacy of programatically analyzing and classifying audio content. Ideally, this is a service that we can integrate into the audio publishing workflow to promote and encourage the application of Times Tags, and to increase the effectiveness of our search and recommendation engines. By the end of Maker Week, I had built a full-stack web app that displays up to 10 recommended Times Tags for the top 10 salient keywords. The app also has a tab that lets you observe the actual data returned by the Natural Language API. The service itself simply intakes a URL that hosts transcript data in the form of an .srt or .txt file. The transcript data is first sanitized (by removing things like timestamps, speaker tags and noise tags) before entering the classification pipeline. Theoretically, since the input is just text, Auditorial is not just limited to audio content; it can be leveraged for any data that is in the form of text. Technology used on the back-end includes Typescript, Node.js, Express, Google Natural Language API and NYT Semantic API, while the technology used on the front-end includes React, Context API, React Router and React Bootstrap. By Eddie Velez (lead software engineer), Amandeep Singh (consultant) and Brian Lavery (senior software engineer) For our Maker Week project, we created an automated testing process that notifies data analysts and engineers if their data doesn’t meet their expectations; it also stops any associated data processing jobs. We built on top of the Apache Airflow and Great Expectations open-source projects to create a reusable piece of code called an “Airflow operator,” which interrogates the data in a Google BigQuery database to see if it meets expectations. Users can write their expectations to a JSON file and check it into Github along with their data processing code. By Chandana Bhimarao (data analyst intern), Jasper Cheung (back-end engineering intern), Jenna Kolodny (front-end engineering intern), Stephanie Lu (front-end engineering intern) and Jenna Kim (product design intern) Our team of interns created a Chrome extension that enables collaborative play on The New York Times Crossword. Users in the same session can utilize a chat box and view each others’ progress in real time, effectively allowing them to solve a crossword together. None of us had created a Chrome extension before, so our project involved a lot of learning. We took inspiration from and reviewed the source code of Netflix Party, an extension that synchronizes video playback so that friends can watch movies together remotely. We implemented real-time communication and collaboration using web sockets: clients either create a session or join an existing session, and are then connected to the same server. When a user types in a crossword cell, the information is sent to the server, and the other users’ crossword grids are updated accordingly. By MacKenzie Gibson (manager, Data & Insights) Analysts often use color as a way to visualize data and present insights to stakeholders. While color can be a powerful tool to help us interpret trends and extract meaning from datasets, there are no accessibility standards set by The New York Times’s Data & Insights group. I completed research about colorblindness, how color is perceived and best practices in creating colorblind-safe color palettes. I compiled this research into a guide for creating data visualizations that are colorblind accessible. Additionally, I created a few colorblind-safe themes in Chartio that can be used throughout the Times company . By following the proposed guidelines we can create a more inclusive environment with more effective visual representation of data. By Ethan Lipkind (software engineer), Daniel Antonio (software engineer), Aditya Natraj (senior software engineer), Laisha Calalpa (Marcy Lab fellow), Enmanuel de la Nuez (Marcy Lab fellow), Devonte Duncan (Marcy Lab fellow) and Mark Griffith (Marcy Lab fellow) This Maker Week, we partnered with The Marcy Lab School, an immersive program based in Brooklyn which creates pathways into tech careers for underestimated youth, empowering them to take control of their future. Our goal was to guide a group of Marcy Lab fellows as they conducted research and built a full-stack data visualization application focused around a topic of their choosing. After spending the first day brainstorming ideas, the fellows defined a specific research question focused on racial inequality in maternal morbidity outcomes. The following day, we guided them as they searched the internet for a dataset that would give them insight into their research topic. Eventually they decided to use a dataset from the CDC, which had to be transformed using a very dense user guide as a map. Next, we helped them massage the data and train a machine-learning model set using scikit-learn and Google Colab. We then guided them as they built an application that allowed a user to input certain maternal characteristics and generate a data visualization representing the complications most likely to occur during childbirth according to their model’s prediction. Finally, we helped the fellows put together a presentation, which they delivered to over 200 Times employees during the Maker Week show and tell event at the end of the week. We were blown away by the level of curiosity, determination and raw talent these young people demonstrated throughout Maker Week. To go from an idea to a full-stack web application backed by a machine-learning model in four days was truly remarkable work. We hope this will be the first of many collaborative learning experiences between The Times and Marcy Lab! By Lauren Yew (senior software engineer) and Kathy Li (data science intern) For this project, we built several features for the NYT Cooking app, adding calories counts to recipes, the ability to filter by calorie count and grocery lists that are sorted by aisle. We also built a feature that allows a user to copy ingredients to a calorie-tracking app. We succeeded in providing demos for each feature, and we laid out the steps for them to be integrated with the production version. By Mark Paul Keefe (senior software engineer), Kate Cullinane (senior product designer) and Jamel Charouel (software engineer) We set out to create an app that allows Apple TV owners to discover our popular NYT Cooking videos in a way that is effortless, fun and engaging. By An Yu (software engineer) The quarantine had made me antsy, and I wanted to create something tangible in my personal time. I had a Raspberry Pi lying around and I was musing about what to make with it when I came across a project that printed out comics on a little receipt. I loved it, and with Maker Week coming up, thought it would be neat to make a bot that printed out a little version of The New York Times Mini Crossword of the day. This was my first electronics project, so while the concept was simple, I hit a number of small bumps along the way. I also wanted to make it in a way that could be replicated by fans of the Mini outside of The Times , so I took the scraping route to retrieve the Crossword instead of using an internal API. It was refreshing getting to learn and build something different from day-to-day work, but also something that wasn’t entirely screen-based. I hope others can enjoy building their own Times Mini Crossword bot at home! By Ami Berger (software engineer), Anish Vankayalapati (data engineering intern), Anna Davies (scrum master), Anna Guidi (data analyst), Deepak Goel (technology intern), Denise Wang (technology intern), Jenni Lee (product design intern), Leah Anton (product designer), Michael Abela (technology intern), Rashika Singh (data engineering intern), Saadhvi Umesh (technology intern) and Zhen Xu (senior data analyst) For Maker Week we made Readerversary, an experience that celebrates our readers’ subscription anniversaries by providing a look into how they consume Times content. Through teamwork, we built a complete app and created a design that is in line with the Times brand. By Ilya Gurevich (software engineer), Charlotte Rymar (graphic designer), Hannah Towey (marketing intern) and Hannah Miao (marketing intern) We reimagined the Opinion section of The New York Times with improved visual acuity and labeling that signals to the reader that they are reading content in the Opinion section. We did this by normalizing headline fonts, utilizing a new logo, adding the Opinion blue for bylines, and we added descriptions for columnist and op-ed contributor roles. We also came up with a new product called “Dialogues” that allows for packaged opinion articles that cover a similar topic. By Meghna Dholakia (product designer), Christian Evans (engineering manager), Nina Feinberg (senior product designer), Justin Fuller (software engineer), Erik Kernan (associate product manager), Yassi Mortensen (software engineer) and Jenny Xing (software engineer) Today, New York Times users can save articles to a list that is available only to them. We decided to build on the current save experience by creating a feature where users can sort their saved articles into collections. We also wanted to have the ability to make collections public so users can share them with friends or family. We hypothesized that giving people more control over their saved articles would make them more likely to revisit and share them. To accomplish this, we formed a cross-functional team in the days leading up to Maker Week, based on a shared interest in saved articles. We bounced around some ideas before the week began, settling on a plan Monday morning. After deciding on our approach, we began to divide and conquer. In addition to building this feature, we also used this opportunity to learn new skills and experiment with new technologies. So, several of us stepped outside of our comfort zones for the week. Our priority was to explore designs and to research technical limitations. Then we began designing and building components and even conducted some informal user research. On Thursday and Friday, our engineers wrote code like their fingers were on fire, so we could present a working feature at an internal show and tell event on the last day of Maker Week. We’re proud of everything we did, but we would love to see this go further. We think there’s a real opportunity to give New York Times readers more ways to organize and manage the stories that intrigue them. By Mike Abrams (senior editor), Veronique Brossier (senior iOS engineer), Anna Dubenko (deputy audience director), Penina Kessler (software engineer), Aditi Sarkar (senior data analyst) and Isaac White (senior software engineer) There’s no great way for editors, writers and others around the newsroom to get better acquainted with New York Times style. The physical stylebook is out of date (we update style too frequently for it to be useful) and perusing entries digitally is less than ideal. Times employees can look up specific entries using Stylebot, a Slack bot that responds to queries on specific terms, but that’s only good for entries they search for. We added a feature to Stylebot that allows users to opt in to receive a random entry from the stylebook via DM. The entry is also posted to an existing channel for style questions, so that users can discuss the tip of the day. We used Node.js and Botkit to enhance the existing stylebook Slack bot that replies to DMs and slash commands, Sequelize and Postgres to persist subscribed users and previously sent tips, and a small cron npm module to easily schedule the daily tip. By Sara Samuel (technology intern) Times ARchive is an augmented reality app that allows readers to view archived New York Times newspapers in physical space. Most readers probably do not have physical copies of archived papers and can only access them in PDF form. The Times ARchive app enables readers to view the newspapers as they would have appeared during the time periods in which they were published. For my demo, I chose front pages that reported historically significant events ranging from 1865 to 1973. Taken together, these pages form a virtual “timeline” of historical events as they were reported by The Times . Times ARchive uses Unity with C# scripting, Vuforia image target tracking, as well as PARCH (our archive of electronic page images). By Alastair Coote (senior software engineer) There is a lot of commonality between The New York Times on the web and its iOS and Android apps, but it’s difficult to share logic across the three platforms. I built an early prototype of a JavaScript “worker” platform that can be shared across all three platforms, and it can be updated outside of the app release cycle. How we design and build digital products at The New York Times 185 1 Innovation Work Workplace Culture Makers Design Thinking 185 claps 185 1 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-08-21"},
{"website": "NewYork-Times", "title": "meeting nimpee kaul lead program manager", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-nimpee-kaul-lead-program-manager-98952c684fcc", "abstract": "Code Data Product and Design Workplace Culture Work with Us “Meeting…” is an ongoing series from NYT Open that features New York Times employees from different corners of the company. In this installment, we meet Nimpee Kaul, a lead program manager for the Messaging Platforms group. What is your name? Nimpee Kaul What are your pronouns? She/Her What is your job? I am a lead program manager for the Messaging Platforms group within the Core Platforms mission. What does that mean? I work closely with Messaging platform teams to enable them to operate effectively and deliver work efficiently. My primary focus is on planning, execution and communication for the teams and projects I work on. I also program manage key strategic initiatives across the organization. How long have you been at The Times? It’s been over a decade now. I can’t believe it’s been so long — it feels like I started yesterday! Most Times employees are working remotely right now. Where are you working from these days? I live in Princeton, NJ with my family, and that’s where I am working from these days. How do you start your day? I make myself a warm cup of lemon and ginger tea, and I read the news. What is something you’ve worked on recently? I program managed the Verizon High School Access Initiative , which provided free digital access to the Times website to every high school student and teacher in the United States. Tell us about a project you’ve worked on at The Times that you’re especially proud of. I am proud of most of my projects, but the recent Verizon High School Access Initiative was one that made my heart swell with pride due to the social aspect attached to it. What was your first job? I was an analyst at a pharmaceutical company. What is something most people don’t know about you? I love assembling furniture. What is your secret to career success? Take full ownership of your story. What is your superpower? I am persistent. What are you inspired by? Heroic stories of real people. Name one thing you’re excited about right now. My yoga journey started with the Art of Living program about five years ago and today I can safely say that I can recommend different asanas for different physical conditions. At this stage, I am excited to be very close to becoming a yoga instructor. What is your best advice for someone starting to work in your field? Don’t be afraid of failure; learn from it. Meeting… Tiffany Peón, Senior Software Engineer at The New York Times Meeting… Storm Hurwitz, Senior Analyst at The New York Times Meeting… Jasmine Chan, Engineering Manager at The New York Times How we design and build digital products at The New York Times 75 Nyt Open Meeting Project Management Interview People Work 75 claps 75 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-08-05"},
{"website": "NewYork-Times", "title": "meeting katerina iliakopoulou lead software engineer", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-katerina-iliakopoulou-lead-software-engineer-82b1dec8cc18", "abstract": "Code Data Product and Design Workplace Culture Work with Us “Meeting…” is an ongoing series from NYT Open that features New York Times employees from different corners of the company. In this installment, we meet Katerina Iliakopoulou, a lead software engineer. What is your name? Katerina Iliakopoulou What are your pronouns? She/Her What is your job? Lead Software Engineer What does that mean? I help build products that enable the newsroom to reach our readers. How long have you been at The Times? Four years. Most Times employees are working remotely right now. Where are you working from these days? I’m working from my apartment in Astoria, Queens. How do you start your day? I usually try to go out for a run for 30 minutes. I’m lucky to live right next to the waterfront, which means I get to enjoy the skyline views. Also, there are very few people outside early in the day. When I get back home, I get ready, make coffee and start working by checking email and Slack. What is something you’ve worked on recently? I’m working on understanding how New York Times content ranks on Google Search and collaborating with the newsroom to develop the tools that help them optimize for off-platform performance. Tell us about a project you’ve worked on at The Times that you’re especially proud of. That would be the work I did as the tech lead of the messaging group to scale our in-house messaging platform that sends newsroom-produced newsletters and push notifications. I led my team to redesign the platform architecture so that it can still send newsletters and push alerts to an increasingly growing audience, while also improving their delivery speed. I presented this work at O’Reilly’s Software Architecture conference in New York at the beginning of 2020. What was your first job? I worked as a research assistant in the Centre for Research & Technology — Hellas (CERTH) in Greece on a European-funded project for viral news detection. During this project I had the opportunity to work with journalists from different news organizations, such as the BBC and Deutsche Welle, to develop a tool that helps reporters find breaking stories from social media posts. What is something most people don’t know about you? I dance tango! What is your secret to career success? Work hard and help others as you would hope they help you. What is your superpower? If I’m tired, I can fall asleep anywhere regardless of what’s happening around me. I have fallen asleep in clubs, loud bars, parties, on the beach, you name it. What are you inspired by? My fiancé. He is brilliant and a constant inspiration for me to do more and aim higher. Name one thing you’re excited about right now. I have been focusing a lot on my yoga practice, so I’m excited to start reaching some new levels, such as being able to do a handstand. What is your best advice for someone starting to work in your field? Be intentional in your work. Know how you want to grow in your career and look out for opportunities that will help you build those skills. At the same time, be open to working on things you didn’t plan to. You might be surprised. How we design and build digital products at The New York Times 30 Code Nyt Open Meeting Workplace Culture Women In Tech Software Development 30 claps 30 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-08-20"},
{"website": "NewYork-Times", "title": "publishing assets we had a few", "author": ["Doug Donohoe"], "link": "https://open.nytimes.com/publishing-assets-we-had-a-few-c3a844e98bac", "abstract": "Code Data Product and Design Workplace Culture Work with Us The New York Times has been publishing since 1851. At first, we printed dozens of articles a day in the paper, then we gradually added photographs, recipes and reviews. When we moved to the internet, we added slideshows, videos, interactives and podcasts. Collectively, we call these items “publishing assets.” After nearly 170 years of publishing, we have accumulated over 59 million assets. And that number is constantly growing. To process the number of assets that The Times has generated, we created a publishing pipeline in 2017 using Apache Kafka open-source software. That year, we began storing every revision of every asset on a single-partition Kafka topic that we call the Monolog. Think of the Monolog as a long, ever-growing list. When a new asset is published, it is added to the end of the Monolog. Numerous Times applications — such as the website, mobile apps and search index — constantly monitor the Monolog for new assets so they can refresh when new content is available. In order to display an article online, our engineering teams must combine multiple assets, such as an article, an image and a reporter’s bio (we call this a “person asset”). In database terms, data on the Monolog is normalized, but when the data is combined for display purposes it becomes denormalized. In order to render an article, the image and person assets need to appear on the Monolog prior to the article asset. It would make sense for the data on the Monolog to start with the first articles from 1851 and continue chronologically until the present day. As is the case with most things in software engineering, the reality is a bit different. When we launched the Monolog in 2017, we immediately began adding new assets as they were published online. Shortly thereafter, we added a handful of historical articles from 2000 to 2016, including a 2001 article that commemorated The Times’s five-year anniversary on the web. We then added selected articles from 1950 through 2000, followed by three major bulk archive republishes that added articles from 1851 through 2000. To correct data bugs and introduce other enhancements, we did occasional bulk republishes that were much smaller. This scattered asset loading process caused several problems: Chronological disorder. If someone wanted to find all of the assets for any given year, they would have to process all 59 million assets, which could take over 24 hours. This was especially problematic for machine learning or personalization projects that only needed data from the last couple of years. Topological disorder. Articles often reference other assets, such as images, recipes and people. Because we added assets published before 2017 to the Monolog in batches, assets that referenced each other were often at different places along the Monolog. These missing references led to an incomplete view when denormalizing an asset, such as an article with a missing image or a recipe review with a missing recipe. Duplicate disorder. Because of things like republishes and — ahem — bugs, there were often multiple copies of the same asset on the Monolog. In one case, there were over 900,000 duplicates. These duplicates took up space and forced unnecessary processing. It was clear that the way the Monolog was ordered was unsustainable. My team decided that the best way to solve this problem was to create a new Monolog that was sorted in chronological and topological order. Ordering the Monolog chronologically meant we could use a Kafka feature to jump to a specific offset using a timestamp, meaning we could precisely get assets from a particular time frame without processing the whole thing. Ordering the Monolog topologically meant we could eliminate incomplete denormalized assets. And since we would be looking at all of the assets, we could remove all of the duplicates. The question was: how would we accomplish this? Was this a big data problem to be solved with tools like Hadoop or Spark? Would a more traditional database fit the bill? Or, would the solution be something else? The team started by inserting metadata for each asset into a SQL database. However, the need to correct data issues, especially missing references, meant a simple sort to order the data wouldn’t suffice. This approach led to a series of increasingly complex queries that took woefully long to run (we’re talking weeks in some cases). But more importantly, these queries did not produce a correctly ordered Monolog. We needed a solution that ran quickly and efficiently. I was new to The Times, and my team asked me to take a fresh look at the ordering problem. As I reviewed the previous work and struggled to understand the queries, I felt like SQL wasn’t the right tool for the job — it was getting in the way of progress. So I paused, took a step back and looked for an alternative approach. While 59 million assets taking up 330 GiB of disk space is big, it is not big data big, which often falls in the range of billions of records or petabytes of data. My new laptop had 16 GiB of memory, and I wondered if it could fit all 59 million assets in memory. I did the math: 16 GiB divided by 59 million was roughly 300 bytes. With some clever encoding, it seemed possible. I would still need to persist data and I began thinking of alternatives to SQL. I had an ah-ha moment. An algorithm was beginning to materialize in my head. Key-value databases are extremely efficient for certain patterns of data access. I envisioned a multi-step algorithm which leveraged this efficiency. Step one would consume the entire Monolog and convert each asset into a small encoded format that preserves only essential information such as a unique id, the publication date, references to other assets and a data fingerprint used to detect duplicates. This encoded asset would then be inserted into the key-value database where the key is a unique publication date and the value is the encoded asset. Multiple assets might share the same publication date because they were published on the same day — this was primarily an issue with assets that had been published before The Times had a website. To ensure that each asset has a unique date, we added nanoseconds to the date. Step two would look for and resolve missing references. The algorithm would inspect each asset in chronological order and flag references to other assets that hadn’t yet been seen up to that point in time. Later on, when a flagged reference was seen, we would resolve the problem by making a copy of the referrer and setting the publication date to just after the found asset by adding nanoseconds. The reference to the missing asset in the original referrer could then be deleted. Though this solution would fabricate revisions of assets that never occurred, it would do so in a way that did not alter history in a material way. It simply corrected the data to reflect what should have happened when the assets were first published. This solution is similar to a real-life scenario when an editor adds an image to an already published article, then republishes both the image and the article. Step three would look for duplicate assets once all of the missing references have been fixed. Once again, each asset would be inspected in chronological order and a record would be kept of the fingerprint of the previous revision of the asset. If the fingerprints are identical (accounting for deleted references), the latter one would be deleted. Step four would iterate through the assets one last time to fetch the original asset and adjust for altered references or publication dates. Everything would then be published to a new sorted Monolog Kafka topic. The algorithm drove a couple of critical requirements of the key-value database. It had to be able to efficiently iterate over the keys in chronological order and it had to work within the confines of available memory. Not all key-value databases fulfill these requirements, but two types do: LSM-Trees and B-Trees. Because many teams at The Times use Go, I began searching for Go key-value databases and chose BadgerDB, an open-source LSM-Tree database that is actively maintained. For step one of the algorithm, I was able to encode each asset into 233 bytes on average. This meant the majority of the data could be kept in memory at the same time. Using BadgerDB, it took about four hours to extract all 59 million assets, but most of that time was due to network latency talking to Kafka. The remaining steps required that we iterate through all 59 million assets. These proved to be very fast as well, taking seven to 15 minutes depending on the task (up to 140,000 assets per second). This was an enormous win. By having the advantage of speed on our side, the cost of failure was low and we could experiment with getting the complex details of implementation just right. In the end, it took about eight weeks to get to a final solution (which was still faster than the five months spent on the SQL approach). After hundreds of iterations and tweaking, the algorithm was refined and finalized. The production version runs in the cloud on a virtual machine not that different from my laptop. After data is extracted from Kafka, it only takes about 90 minutes to do the entire ordering process. It takes another day and a half to re-publish the ordered assets to a new Kafka topic. By removing duplicates, we reduced the number of assets to just over 35 million. The offset and publication date now increase in tandem and we can easily pull all assets from a particular year. The results are beautiful: When many of today’s technology problems entail enormous amounts of data, it may not seem cutting edge or cool to work on a problem that can be solved on a single laptop. But finding a solution to a complex problem is satisfying, no matter the size. Doug Donohoe is a Senior Software Engineer for the New York Times, living in Pittsburgh, Pennsylvania. He’s been to all seven continents and looks forward to exploring the world again soon. Check out his Twitter , where you might catch a glimpse of his dog, Dexter. How we design and build digital products at The New York Times 195 2 Publishing Golang Database Code Tech 195 claps 195 2 Written by Seasoned, top-notch technology leader with deep hands-on skills. Polyglot programmer (Scala, Go, Java, Python, …) How we design and build digital products at The New York Times. Written by Seasoned, top-notch technology leader with deep hands-on skills. Polyglot programmer (Scala, Go, Java, Python, …) How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-07-31"},
{"website": "NewYork-Times", "title": "meeting megan araula lead software engineer", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-megan-araula-lead-software-engineer-38303ffca94e", "abstract": "Code Data Product and Design Workplace Culture Work with Us “Meeting…” is an ongoing series from NYT Open that features New York Times employees from different corners of the company. In this installment, we meet Megan Araula, a lead software engineer with the Delivery Engineering Team. What is your name? Megan Araula What are your pronouns? She/Her What is your job? Lead software engineer What does that mean? I’m part of the Delivery Engineering Team and we build and maintain developer tools for The Times. I get to work and collaborate with awesome people across missions. How long have you been at The Times? Six years! Most Times employees are working remotely right now. Where are you working from these days? Kips Bay in New York City How do you start your day? I start with a cup of coffee and I talk to my plants. What is something you’ve worked on recently? I’m currently working on a Disaster Recovery solution for our CDN (Fastly). Tell us about a project you’ve worked on at The Times that you’re especially proud of. In my second year at The Times, we decided to build the Times Trending page as our Maker Week [a meeting-free innovation week that The Times annually holds for employees] project. We presented it and won the innovation challenge. Then a few months later, it became a real product and we deployed it to production. It was surreal. It was the first application that I built from the ground up for The New York Times. What was your first job? I worked as a server in my high school cafeteria. What is something most people don’t know about you? English is my second language. I moved to the United States 13 years ago from the Philippines. I was taught English at a young age, but I never used it on a daily basis. When I moved to the United States, my English was pretty bad because learning it formally at school and casually speaking it are totally different. When I tell people this, they are surprised; I guess I’ve gotten better through the years. What is your secret to career success? I have a great support system. I don’t think I would have made it this far if I didn’t have good people around me. Name one thing you’re excited about right now. I’m not a runner. A week after shelter-in-place in New York was announced, I needed a reason to get out of the apartment, so I started running. It’s amazing what the body can do when you train it. I just ran a 10k over the weekend at a 9 minute per mile pace. I still can’t believe it. What is your best advice for someone starting to work in your field? Don’t be afraid to ask questions, most people are willing to teach and help. Meeting… Nimpee Kaul, Lead Program Manager at The New York Times Meeting… Tiffany Peón, Senior Software Engineer at The New York Times Meeting… Storm Hurwitz, Senior Analyst at The New York Times How we design and build digital products at The New York Times 29 Nyt Open Meeting Work Software Engineering Code Women In Tech 29 claps 29 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-08-06"},
{"website": "NewYork-Times", "title": "how the new york times thinks about your privacy", "author": ["Robin Berjon"], "link": "https://open.nytimes.com/how-the-new-york-times-thinks-about-your-privacy-bc07d2171531", "abstract": "Code Data Product and Design Workplace Culture Work with Us If, dear reader, we met and you invited me to your home, we might end up chatting about your day over a glass of Côtes du Rhône. As you recounted your latest adventures, I would learn about you, but in no way would that be a violation of your privacy. However, if you happened to catch me listening in through the window as you depicted the same events to someone else, I would be a creep breaching your privacy and would deserve my comeuppance at the hands of your just fury. Eavesdropping is not the only privacy misdeed, however. I could listen to you in confidence and blab to your colleagues. I could discreetly record our conversation, keeping evidence for unspecified future purposes. I could broadcast the more humiliating of your misfortunes in a blog post. There are numerous ways one might betray another’s privacy, but they are evident in most everyday situations. It’s unlikely that the examples above made you feel compelled to locate your nearest ethicist and pepper them with questions. The line between acceptable in-person interactions and violations of privacy is clear. Why, then, is digital privacy such a contentious topic? Why is The Times making substantial changes to how we handle personal data? But first — what even is privacy? The privacy implications of a chat over wine are straightforward. But step into the digital realm and privacy looks like the hangover from a kindergartener play date. The ground is strewn with cookies and their entourage of layperson metaphors, from privacy policies , to data brokers and an endless stream of consent dialogs . And, in the end, the learned helplessness of knowing you have lost all control over who knows what about you. Privacy should not be confused with the clutter surrounding it, no more than it should be confused with secrecy , having a private room or the right to be left alone . Privacy is “ a right to appropriate flows of information ,” according to Helen Nissenbaum , a professor of Information Science at Cornell Tech. Any given context in which personal information flows from a sender to a recipient has ethical norms that govern whether or not that flow is appropriate. Respect for these norms is what we collectively call “privacy.” These norms are contextual because what can appropriately be observed or shared about someone is different if it happens at home or at work; at a doctor’s office or at a party; in public or one-on-one. Privacy contexts can be described with their actors (subject, sender, recipient), attributes (what is being shared) and transmission principles (constraints on the flow of information). Returning to our chat over a glass of wine, if I were to blab to your co-workers the following day, the actors and attributes would remain the same, but I would be betraying the trust of an open-hearted discussion with a friend. This betrayal is a violation of privacy. Equating a violation of privacy to a betrayal is not arbitrary: privacy is about trust. And at The Times, the trust of our readers is essential . As our publisher, A. G. Sulzberger, wrote last year , we have been concerned about our contribution to the current muddle of online privacy. As a group, news organizations have garnered a dismal reputation in terms of privacy. In an investigation of third-party tracking on German news sites, The Global Editors Network concluded, “ we used to read the newspaper, now the news reads us .” Nieman Journalism Lab reported on a study showing that “ European news sites are among the worst offenders when it comes to third-party cookies and content. ” That’s Europe, where the relatively comprehensive General Data Protection Regulation (G.D.P.R.) privacy regulation should be keeping the worst privacy infractions at bay. Looking at the United States, researchers Tim Libert and Reuben Binns reported that news websites rely heavily on third-party trackers. This has “fostered an environment of pervasive surveillance,” and the “widespread adoption of opaque and poorly disclosed tracking practices.” Their research found that news sites rely on third-party tracking more than non-news sites. Why is the state of online privacy in news media so grim? Most publishers rely on one of two business models: subscriptions and advertising. Some publishers, like The Times, rely on both. Subscription models depend on finding new subscribers through marketing tactics, many of which depend on third-party data collection . Advertising models track as much of each user’s digital presence as possible to enrich the personal profiles maintained by third-party companies. Then, for a majority of ads that a user sees, that personal data is broadcasted to advertising intermediaries so that companies can bid on showing ads targeted to that user. This digital ecosystem has a long way to go before it respects users’ privacy. Until then, The Times has been fostering better privacy standards for the parts we can control. We have completely rewritten our Privacy Policy with legibility in mind (now rated at a 7-year-old readability level), and we added a Frequently Asked Questions section. Over the past two years, we have made our internal data practices significantly more mindful of our readers’ privacy. Improved privacy in marketing Our marketing goal is to attract new subscribers, which we accomplish through a variety of tactics. Not all of these tactics require us to share data about our readers with other companies, but some do. And those tracking companies typically have independent control over the data they collect, which they can then repackage for other purposes. These are data controllers . As of April 2019, we removed all third-party data controllers from our homepage, section fronts and articles. We limited them to marketing-related parts of the site, such as subscription offer pages. This reduced the amount of data we shared with third-party data controllers by over 90 percent. We are working on ways to improve this number, but for the time being our marketing goals still rely on these tactics. Additionally, we have been developing means to advertise to potential subscribers without sharing data. One example is TAFI , a tool used to advertise our content on social media. We are also following the development of privacy-preserving technologies that support marketing purposes . Towards better privacy in advertising Advertising is a set of practices used to support other companies that promote products or services on a platform. There are many ways in which advertising can be carried out: some as simple as handing out flyers in the neighborhood and some more complex. To say that digital advertising sits at the more complex end of this spectrum severely undersells just how intricate and opaque it is , particularly in how it distributes and exploits personal data. Virtually all online advertising operates through third-party software that is included in sites or apps. What happens through this software in advertising can be entirely legitimate — fraud prevention is one example. But the technology used for defensible purposes is the same as that used for pervasive surveillance, which makes separating user-friendly options from user-hostile ones challenging. This has not stopped The Times from making progress. Across our digital properties in Europe, as well as in our mobile apps worldwide, we have removed open-market programmatic advertising, which broadcasts personal data to dozens of third parties in a way that publishers have very little control over. We are decreasing our reliance on third parties by developing our own capabilities to serve ads that are not based on tracking readers across their entire connected lives. To make ads effective without knowing anything about who they are being presented to, we have built improved contextual targeting capabilities . Our research at The Times shows that readers are broadly comfortable with us, the first party, seeing some data about them. But they are overwhelmingly unhappy with data being shared with third parties that can use the data for entirely different purposes. With this in mind, we are phasing out third-party data in ad targeting . Our hope is to push this even further. In pursuit of that goal, we have been reaching out to others in the industry to help design a better advertising ecosystem. Eventually, we want to provide accountability for every data processing step involved in serving ads to readers. In response to surveillance, people have been seen to silence their minority opinions and to restrict what they search for online . At The Times, we believe in a world of fearless and unfettered curiosity. We wish to develop positive norms of data privacy so that our digital society can not just exist, but flourish. Privacy is contextual, but it can be difficult to know what is appropriate in digital contexts. While it is easy to notice that the doctor’s does not have the same vibe as your regular dive bar, our digital experience involves staring at shiny slabs of plastic that all look the same. You can catch someone spying through your window, but most people cannot see the code surveilling them. In the same way that we don’t need to think hard about privacy in everyday life, The Times is helping build norms for the internet to make it a context that users can trust . Such work was started fifty years ago (PDF) when the United States formed a committee that established the initial Fair Information Practices to address “concern about the effects of computerized personal data systems.” The committee’s principles, often summarized more than is reasonable as transparency and control, are still in use today. The focus on transparency and control, however, yields insufficient guidance for today’s data economy. The volume of personal data processed in the 1970s was relatively low. It was reasonable to expect users to review a handful of privacy policies and to convey their preferences by controlling the finer details of what data was collected about them. Given the ubiquity of today’s data collection, that is no longer a defensible position. Returning to the example of my earlier eavesdropping: transparency is the claim that you can always check who is spying through your window, and control is the contention that you can close the curtains in every room you visit. That works if you have two conversations a year, but quickly falls apart if you socialize more regularly. It is unfair for a company to benefit from personal data while making its users do the labor to ensure that their data is processed appropriately. At The Times, we feel it is essential to modernize the guiding principles for privacy and we are participating in discussions to do so. Data processing has changed radically since the 1970s, but so has our understanding of privacy and our awareness of its importance to human well-being. We see privacy not as a constraint on our work but as an opportunity to bring about the next digital transformation. We are adamant that respecting our readers’ privacy is our responsibility and that the work to evolve in that direction is ours to shoulder. We will continue to build atop the changes we have already made, and are committed to working with you and with other organizations to define privacy for the digital era. Robin Berjon leads Data Governance at The New York Times. When not chatting with friends over a glass of wine, he spends his time tinkering with web technology and reading about philosophy, science and politics. If you liked this article, follow him on Twitter . How we design and build digital products at The New York Times 203 2 Privacy Governance Tech Governance And Tech Data 203 claps 203 2 Written by VP Data Governance at The New York Times. Privacy, Web, Science, Politics, Philosophy. How we design and build digital products at The New York Times. Written by VP Data Governance at The New York Times. Privacy, Web, Science, Politics, Philosophy. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-01-11"},
{"website": "NewYork-Times", "title": "meeting storm hurwitz senior analyst at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-storm-hurwitz-senior-analyst-at-the-new-york-times-37013ad483bc", "abstract": "Code Data Product and Design Workplace Culture Work with Us “Meeting…” is an ongoing series from NYT Open that features New York Times employees from different corners of the company. In this installment, we meet Storm Hurwitz, a senior analyst on the News Products Analytics team. What is your name? Storm Hurwitz What are your pronouns? He/Him What is your job? Senior Analyst, News Product Analytics What does that mean? I use data to help The New York Times understand how their readers engage with Times stories. How long have you been at The Times? One year and 10 months! Most Times employees are working remotely right now. Where are you working from these days? I am working from my apartment in Harlem with my dog, my partner and his dog. How do you start your day? My partner and I team up on the start of the day. We both get up, and he takes the dogs for their morning walk as I get coffee ready. We then both sit together and read the news as we have our coffee before we dive into our first meetings of the day. What is something you’ve worked on recently? I’m currently helping bring standardization and a data perspective to our recommended articles on article pages. The work is very detailed, but it is exciting to help set the product teams and newsroom up to more efficiently and effectively compare each of the recommendation blocks with the goal of helping readers access the depth and breadth of our coverage. Tell us about a project you’ve worked on at The Times that you’re especially proud of. Slowly, but surely, helping The Times understand how to classify whether an article pageview was “engaged.” Our product teams care about measuring engaged pageviews, as a way to understand whether our readers are getting value from the product experience. This is a long-term project that has many stakeholders, so it is very much a work-in-progress. But, leveraging data to help readers find stories they want to engage with is a dream of mine. There are so many reader behaviors to account for in thinking about this classification problem, all of which are interesting to better understand and surface for my product stakeholders. What was your first job? I worked at the Lesbian, Gay, Bisexual & Transgender Community Center in New York, essentially creating statewide HIV-prevention campaigns and advising over 50 LGBTQ organizations across the state on their digital marketing strategy. What is something most people don’t know about you? I have never eaten meat. I was raised a vegetarian! What is your secret to career success? Reflective persistence. I think it is very important to consistently and frequently take stock of what is making me happy and to trust that instinct. As I hone my ability to pinpoint what inspires happiness, I lean into making those drivers a part of my overall career strategy — be that what jobs I apply for, what problems I look to solve at work and how I advocate for myself. What is your superpower? Process thinking. I am, sometimes to a fault, very process oriented. But, I love efficiency. What are you inspired by? Passion, intellect and love. Name one thing you’re excited about right now (can be non-work related). My Intern! I will manage an intern this summer and she totally rocks. I am thrilled that The Times is still hiring and offering internship opportunities during the coronavirus pandemic, and I cannot wait to learn alongside her. What is your best advice for someone starting to work in your field? Technical skills are great, but do not forget to actively seek to grow your data storytelling skills. Meeting… Jasmine Chan, Engineering Manager at The New York Times How we design and build digital products at The New York Times 107 Analytics Work Data Nyt Open Meeting Media 107 claps 107 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-06-25"},
{"website": "NewYork-Times", "title": "from print to digital making over a million archived photos searchable", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/from-print-to-digital-making-over-a-million-archived-photos-searchable-b146037705d2", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Jonathan Henry A block away from the hustle and bustle of Times Square in New York City, buried three floors below street level, lies The New York Times archive. The archive is housed in a sprawling room that is packed with hundreds of steel filing cabinets and cardboard boxes, each containing news clippings, encyclopaedias, photographs and other archival material. Started in the late 1800s, the archive first served as a collection of news clippings about newsworthy events and people. In the late 1960s, it was merged with a photo library managed by The Times’s art department. The archive (which is sometimes referred to as “the morgue” ) now contains tens of millions of news clippings and an estimated five million printed photographs. Many of these historical documents are available only in print form, however in 2018, The Times embarked on a project — as part of a technology and advertising collaboration with Google — to preserve the photographs in the collection and store them digitally. A team of technicians manually scan about 1,000 photographs per day into a server, and in July, 2019, they scanned their one millionth photograph. Many of these photographs have found a new life in stories produced by The Times’s archival storytelling project, Past Tense . With a digital photographic archive now at over a million scans, we needed to build an asset management system that allows Times journalists to search and browse through the photos in the archive from their laptops. To architect our asset management system, we drew inspiration from the archive itself. The organization strategy in the physical archive is loosely similar to the Dewey decimal system, where an index references the location of photos associated with a subject. The archive contains well over 700,000 index cards that are alphabetically sorted by subject from A. Cappella Chapel Choir to ZZ Top. Each index card contains the location of the folder in which the corresponding collection of photos can be found. Occasionally, a subject is divided into subtopics with multiple references to different folders. As an example, an index card about Amelia Earhart is further broken down into multiple subtopics, such as portraits, individual snapshots and European receptions. If we were to be interested in European Receptions, we would find the folder labeled “4794-L-8.” Some folder covers may contain additional text that provides a high-level description about the collection of photos found within the folder; this text is especially useful when it’s the only text associated with a photo. The backs of individual photos usually contain contextual data, such as stamps of publication dates and folder names, handwritten notes, crop marks and taped news clippings indicating publication. The team of technicians scan folders and photos; the index card catalog was scanned a couple of years ago. Technicians scan the fronts of the folders and both sides of the photos. Preserving this contextual data is of utmost importance since it is needed to classify and index data for our internal search tool. We store the scanned photos as TIFFs because the file format uses lossless compression, or no compression at all, which ensures we save the full quality of the archived images. Once several filing cabinet drawers have been scanned, the photos are then uploaded to Google Cloud Storage (GCS) and sent through the ingestion pipeline, which involves several Go microservices running in a Google Kubernetes Engine (GKE) cluster. Each service communicates with the others via Cloud Pub/Sub, which is used to asynchronously deliver events to each service. In our case, the event we care about is uploading an image to GCS. When an image is uploaded, a Pub/Sub notification gets published and our ingestion process begins. To prepare the image for potential publication on the Times website or apps, this service converts the image from TIFF to JPEG. We do this for two reasons: JPEGs tend to be more efficient for the web and they also tend to offer a better size-to-quality ratio. The JPEG is then resized twice in order to store additional dimensions of the photo. Additional data such as GCS file path, photo side (front or back), folder and drawer association are stored in a Cloud SQL Postgres database for other services to query. All JPEG copies are then saved to GCS, which triggers a Pub/Sub notification to a topic subscribed to by our analyzer service for the next step of the pipeline. In order to make images searchable, we first need to digitally extract the text from the photos. We built an analyzer service to store contextual data from the photos. To extract text from our images we decided to use Google’s Vision API, which provides optical character recognition (the process of converting handwritten or printed text into machine-encoded text) and label classification of images via pre-trained models. After we extract text from the photos with the Vision API, we save the results to our Postgres DB. We then normalize and index the data so it can be searched. The final step of the ingestion pipeline is indexing and structuring photo metadata to perform full-text queries. We utilize ElasticSearch, which is a near real-time search platform that is built on top of Lucene, an open-source full-text search engine. Although indexing and structuring metadata is straightforward for index cards, it gets tricky for folders and photos. A folder might lack the text for a meaningful search result, so we map it to its associated index cards and parse the relevant text describing the contents of the folder. The same is done for photos, but the additional text is gathered from its folder. This is where we leverage Postgres to query for the folder-to-index-cards and photo-to-folder relationship. Once we’ve built these relationships and parsed all relevant text, we store our data in ElasticSearch. This data then becomes immediately accessible to Times journalists via a searchable interface in our asset management tool. Although we still have millions of photos left to scan, Times journalists can currently search over one million photos and the complete index card catalogue in the archive. We continually improve the search experience by cleaning data that might result from an imperfect optical character recognition result, and we continue to experiment with new methods that will allow us to gain better insight into how to structure and classify our images. Jonathan Henry previously served as the tech lead for the Photo team at The New York Times. He is currently an engineer at Spotify. Special thanks to the team responsible for this project: Aleksandr Afanasiev, Alex Sobolev, Benny Benedetto, Chris Grillo, Danil Karetnikov, Frank Borell, Jenny Hottle, Konstantin Chukhlomin, Monica Landrove, Suman Roy and William P. Davis. Photographs from The New York Times Archive. Top collage photographs by, clockwise from left: Sam Falk/The New York Times, Eddie Hausner/The New York Times, Chester Higgins Jr./The New York Times, Sam Falk/The New York Times, Ruby Washington/The New York Times, Larry C. Morris/The New York Times and Sam Falk/The New York Times. End collage photographs by, clockwise from left: Tim Koors for The New York Times, Larry C. Morris/The New York Times and D Gorton/The New York Times. How we design and build digital products at The New York Times 74 2 Technology Systems Thinking Database Photography Code 74 claps 74 2 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-05-28"},
{"website": "NewYork-Times", "title": "to apply machine learning responsibly we use it in moderation", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/to-apply-machine-learning-responsibly-we-use-it-in-moderation-d001f49e0644", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Matthew J. Salganik and Robin C. Lee It’s a common refrain on the internet: never read the comments. All too often, the comment section is where trolls and toxic behavior thrive, and where measured debate and cordial conversation ends. The New York Times comment section, however, is different. It is generally civil, thoughtful and even witty. This did not happen by itself; it is the result of careful design and hard work by the Times Community Desk. For years, people on the Community Desk manually moderated all comments that were submitted to Times articles. The work led to high-quality comments , but it was time consuming and meant that only a small number of stories could be open to comments each day. In 2017, this changed. To enable comments on many more stories, The Times introduced a new system named Moderator , which was created in partnership with Jigsaw . Moderator is powered by a widely available machine-learning system called Perspective that is designed to help make the comment review process more efficient. After deploying Moderator, The Times dramatically increased the number of stories that are open to comments . This might sound like another machine learning success story, but it is not that simple. Since 2017, researchers have discovered that some well-intentioned machine-learning tools can unintentionally and invisibly discriminate or reinforce historical bias at a massive scale. These discoveries raised important questions about how to use machine-learning systems responsibly, and they led us to take a second look at how machine learning was being used in The Times’s comment moderation process. When a comment is submitted by a reader, Perspective assigns it a score along a number of dimensions, such as whether the comment is toxic, spam-like or obscene. A comment that includes the line, “free Viagra, free Viagra, free Viagra” might get a high spam score, and a comment that uses a lot of four-letter words might get a high obscenity score. Perspective assigns these scores entirely based on the content of the text; it does not know anything about the identity of the commenter or the article that attracted the comment. In addition to providing scores, Perspective also identifies specific phrases that it thinks might be problematic. Next, the Community Desk, made up of about 15 trained moderators, reads the highlighted comments for each story and decides whether to approve or deny them for publication based on whether they meet The Times’s standards for civility and taste . This review is enabled by Moderator’s interactive dashboard, which was designed to empower the human moderators, making it easier for them to do their work efficiently and accurately. The dashboard presents the scores and the potentially problematic phrases, as well as other contextual information about the original story. All of the human moderators have a background in journalism and have been Times employees for many years. In other words, the work of moderation is not outsourced; instead, it is treated as an important responsibility. Together, this hybrid system combines sophisticated machine learning and skilled human moderators to sift through the thousands of comments submitted each day. It has allowed The Times to foster high-quality conversations around our journalism. With the concern about potential bias in machine-learning technology in mind, our colleague Robin Berjon, who is the Vice President of Data Governance at The Times, decided to run an experiment to see if he could trick Perspective, the machine-learning system that powers Moderator. Berjon created duplicate pairs of fake comments with names that are strongly associated with different racial groups to see whether Perspective gave different scores to the comments. It did. This looked bad for Perspective, but it was actually more complicated. The fake comments that Berjon created didn’t look anything like the real comments that readers submit to The Times — those are typically long and almost never include anyone’s name. And Berjon only attempted to trick Perspective; his fake comments never made it to The Times’s human moderators, who would have detected them. Despite these limitations, Berjon’s demonstration inspired us to further investigate. We discovered that we were not the first people to be interested in biases in Perspective’s scores. A team of researchers at the University of Washington assessed Perspective using Tweets and found that the machine-learning software was more likely to rate African-American English as toxic. Researchers at Jigsaw — the very people who created Perspective — published several academic papers attempting to understand, describe and reduce the unintended biases in Perspective. Critically, none of this research was available in 2017 when The Times first started using Perspective as part of the comment moderation process. Like Berjon’s experiment, this academic research was provocative but incomplete for our purposes. None of it used comments like those submitted to The Times, and none of it accounted for the human moderators who are part of the Times system. One might suppose that the right response to this research is to build a better machine-learning system without bias. In an ideal world, this response would be correct. However, given the world and the state of current technology, we don’t think that’s possible right now. Roughly speaking, machine-learning systems learn from identifying patterns that exist in data. Because the world contains racism and sexism, the patterns that exist in data will likely contain racial and gender bias . As an example, a machine-learning system might learn that comments are more likely to be toxic if they include the phrase “Jewish man.” This pattern might exist in the data because the phrase is more frequently used in online comments with the intent to harass. It is not because Jewish men are toxic or because the algorithm is biased against Jewish men. If the machine-learning system was taught to unlearn this pattern, it could make the system less useful at identifying anti-semitic comments, which might actually make the system less practical for promoting healthy conversation. Given that a quick technical fix was not possible, we decided to build on prior research and conduct our own investigation to see how these issues might play out in the context of The Times. Our investigation of the role of machine learning in Times comment moderation had three parts: digging through the comment moderation database logs; creating comments that tried to trick Perspective; and learning more about the human moderators who ultimately decide whether a comment gets published. Combing through the database logs of past comments, we wanted to know whether comments scored as more problematic by Perspective were getting rejected by the Times moderators more often. They were. Then, we looked for cases where Perspective and the moderators disagreed. We examined some comments that Perspective scored as risky but were published by The Times’s human moderators, and some comments that were scored as not risky but were rejected. We did not see any systematic patterns related to issues like race or gender bias. To further test how Perspective works with Times comments, we created a set of 10 identity phrases such as, “Speaking as a Jewish man” and “Speaking as an Asian-American woman,” and we added them to the beginning of one thousand comments that had been published on the Times website. We then had Perspective score all of these modified comments and we compared the results to the scores for the original, unmodified comments. Similar to what others have found , we saw that these identity phrases led Perspective to score the comments as riskier. But, critically, we saw that these effects were much smaller when the identity phrases were added to real comments, rather than submitted on their own. And we found that the longer the comment, the less impact the identity phrase had on the scores. The distinctive, and perhaps most important, part of the Times system is the human moderators. We wanted to understand how the moderators used and interpreted the Moderator software to make decisions about what comments to publish on the Times website. To learn more about the process, we went through comment moderator training and shadowed moderators as they worked. Through observation and discussion, we learned that the moderators felt free to overrule the scores generated by Perspective (and from the log data we could see that this did indeed happen). The human moderators were keenly aware of Perspective’s limitations, yet they found Moderator’s user interface to be helpful, especially the way it highlights phrases in comments that might be problematic. They told us that having comments ordered by estimated risk makes it easier to make consistent decisions about what to publish. To be clear, Perspective is not perfect and neither are the human moderators. However, creating a system that maximizes the number of Times stories that allow comments, while also fostering a healthy and safe forum for discussion, requires trade-offs. An all-human model would limit the number of stories that are open for comment, and an all-machine-learning model would not be able to moderate according to The Times’s standards . Just as Perspective and the moderators are imperfect, so is our investigation. We ruled out large patterns of racial and gender bias, but we might have missed small biases along these dimensions or biases along other dimensions. Also, our investigation happened during a specific point in time, but both Perspective itself and the comments submitted to The Times are always changing. Overall, our three-pronged investigation of the role of machine learning in comment moderation at The Times led us to conclude that the system — one that combines machine learning and skilled people — strikes a good balance. Our investigation focused on the role of one specific machine-learning system in comment moderation at The Times. However, the concerns that sparked our investigation apply to all machine-learning systems. Therefore, based on our investigation, we offer three general recommendations: Don’t blindly trust machine-learning systems Just because someone tells you that a tool was built with machine learning does not mean that it will automatically work well. Instead, examine how it was built and test how it works in your setting. Don’t assume that machine-learning systems are neutral, objective and accurate. Focus on the people using the machine-learning systems An imperfect machine learning tool can still be useful if it is surrounded by dedicated, experienced and knowledgeable people. For example, it did not matter if Perspective occasionally produced inaccurate scores as long as the human moderators ultimately made the correct decisions. Sometimes the best way to improve a socio-technical system is to empower the people using the machine-learning system; this can be done by providing training on how the system works and by giving them the authority to push back against it whenever necessary. Socio-technical systems need continual oversight. The initial deployment of a machine-learning system can require difficult technical and organizational changes, but the work does not end there. Just as organizations routinely audit their operation and accounting, they should regularly assess the use of machine-learning systems. The New York Times has created a thriving comments section through years of effort and innovation. We hope this investigation contributes to that long-term project and also serves as a blueprint for examining the responsible use of machine learning in other areas. Matthew J. Salganik was a Professor in Residence at the New York Times, and he is a Professor of Sociology at Princeton University, where he serves as the Interim Director of the Center for Information Technology Policy. He is the author of “ Bit by Bit: Social Research in the Digital Age ”. Follow him on Twitter . Robin Lee is a PhD student in Sociology at Princeton University. He was a Data Analyst for the Data & Insights team at The New York Times. Outside of work, he’s a data meetup organizer. Follow him on Twitter . How we design and build digital products at The New York Times 228 Machine Learning Technology New York Times Audience Social 228 claps 228 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-04-30"},
{"website": "NewYork-Times", "title": "a new look for the morning newsletter", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/a-new-look-for-the-morning-newsletter-36bb135b5c79", "abstract": "Code Data Product and Design Workplace Culture Work with Us When readers of the Morning Briefing opened their inboxes on Monday morning, they were greeted with a redesigned and renamed newsletter. The Morning , as the newsletter is now called, has been restructured and given a fresh look, with more space for graphics. David Leonhardt, a Times journalist, will be the main writer for the newsletter, guiding readers through the day’s biggest stories. Sarah Bures, editor of NYT Open, recently spoke via video call to Adam Pasick, editorial director of newsletters, Barbara deWilde, executive creative director, and Frannie Hannan, a director of product, about how they approached this redesign, how they collaborated across departments and what they hope readers will gain from a redesigned newsletter. This conversation has been edited for clarity and length. Sarah Bures: The Morning Briefing was last redesigned in late 2018 ; what inspired the change this time around? Adam Pasick: The biggest factor in all of this was that the audience for the Morning Briefing has totally skyrocketed . Frannie Hannan: With so many new people reading the Briefing, it gave us a whole moment to introduce people to The Times, and part of that introduction was this email. So, it really became much more of a front-and-center introduction for The Times for so many millions of people. Pasick: Right. We quickly realized that the Morning Briefing is now one of the most-read touch-points for The Times. And so we started thinking about how we can match its ambition, its scale and general excellence as a product to the huge new audience. Hannan: That’s the gist of it. Having our product and editorial ambitions match the scale of the readership. Pasick: The previous redesign looked really carefully at what users wanted, and we’re still very concerned about that, but we started from a different point in this redesign. If the Morning Briefing is a distinctive product in its own right, what would it look like? Bures: What are some of the big changes that readers can expect to see? Barbara deWilde: The redesign is about hierarchy: which is the most important story that we want the reader to understand when they first wake up? What are the other condensed and concise things they need to know, and how can they have a rich Times experience? Those are just some broad questions that you ask yourself when you’re designing and working with an editorial partner. We start with the biggest story at the top of the newsletter. It has a slightly differentiated headline styling. Next in the hierarchy is “The Morning Five,” five important top stories with very concise summaries. And then a backstory or a thoughtful, reflective piece from the news or something thoughtful, fun, cultural — I’m hesitant to say “fun” because that always sounds like people need dessert. It’s a story that is not hard news, but is delightful. Pasick: I should also say that what we’re doing is not a radical change. We’re pulling out and amplifying a lot of the stuff that was already in the Briefing. Andrea Kannapell’s team and especially Chris Stanford writing the U.S. Morning Briefing — we’re following the roadmap that they established and put so much amazing time and work into. We’re trying to spotlight the things that feel singular and will give people an entry point to understanding what The Times does and why its journalism is valuable. deWilde: To leverage the voices of the newsroom more, and that does seem like a departure from what we currently do. Pasick: We’ve been slowly incorporating many of the changes over the last six months, pushing the Morning Briefing towards what this new thing would be. We try to have Q&A’s with reporters threaded throughout, so that the newsletter feels like a conversational, personal medium. You want to understand the story on that level, not necessarily within the confines of a New York Times online or print story. Talking to the journalist behind the story can shed new light and insight. Bures: The Morning is going to be written by David Leonhardt, right? Pasick: He’ll be the lead writer. There’s a whole team of people working on it. Bures: How much will his voice play into the tone of the newsletter? Pasick: Quite a bit, we hope. David’s voice as a writer, as a journalist and as someone who’s built a career on explaining the news in an interesting way — we hope that’ll be the linchpin that this whole thing is built around. [ Read more about how David Leonhardt is thinking about The Morning newsletter. ] Bures: What part did prototyping play in this process? deWilde: We began the prototype process back in the fall. Adam and his editors would create a Google Doc, and it would design and delineate the big story, five smaller stories and the list of delightful items that would follow. Working with Jeff Glendenning [creative director for the Brand Identity team], we would take the Google Doc and set type. We’d print the prototypes out and tape them to the wall where Adam, Sam Dolnick [an assistant masthead editor] and others could come and read and give comments. We did this week over week. Over time, we settled on an edit and a design that we liked. We continued that process through the end of last year, and then we paused. When David Leonhardt came on board, the prototyping process started again. In this last phase, the prototype was written into an email and sent to an internal audience [of Times employees]. Hannan: One other thing that’s been remarkable about the product process: since David has come on, we’ve had daily meetings that have a really broad array of people in them. It’s super cross-functional, including engineering, project management, data insights, audience insights and everyone on the product team, plus David and Adam. And those have just been unlike anything that I’ve done cross-functionally at The Times, in terms of the amount of openness to feedback from other disciplines. It feels like everyone’s opinion gets listened to and respected in a nice way, including from people who are not an editor. We’re functioning kind of as a user group, in addition to people who are actually working on the project. Bures: How was the collaboration process with so many people from so many different groups? Pasick: It’s been pretty incredible how — not just how well we’ve all gotten along — product and editorial is not always the easiest relationship in a lot of organizations. It’s been remarkably smooth here. A lot of really great ideas have come out of our conversations. If the teams were working in a more separate way, I don’t think we would have gotten to this point. So even down to the fine-tuning: we’ve been having daily meetings for two weeks now or something like that. And I feel like every single time, something really interesting comes out of there: with editorial people talking to product people, who are giving us feedback that we’re not hearing from our newsroom colleagues. I think we’re probably pushing into product-land on some of the hard questions and ideas. So, it’s been really rewarding. Bures: Can you walk me through a typical daily meeting? Hannan: It’s a real hodgepodge. It’s mixed between high-level critiques of the day’s send, plus philosophical questions about what different sections of the newsletter should be. And then we’ll swing completely in the other direction and start talking about how we make sure that this small piece of work to reduce clipping is in, or other technical things. It can really go from very theoretical to very tactical, depending on what’s urgent that day, but there is usually some talk about how well everyone thinks the day’s send did in terms of our goals for the email. deWilde: The other aspect that has been wonderful to see: the growth of people’s understanding of the constraints of email. We can’t do much with this medium. At first, the group’s suggestions were quite pie in the sky and we couldn’t possibly build what was being asked. Now the group is pretty grounded and realistic. We can make small changes with big impact. Pasick: It’s the constraints that make you more creative, right? [laughs] Bures: What do you think the highlight of this process has been? Pasick: The highlight for me is working with a huge range of people in the newsroom, and especially the Briefings team and Sam Dolnick, and Barbara, with Frannie, with Design and Product. It really has gelled in a way that feels super rewarding. I think we all feel quite good about the end product. But the process to get here, I mean, I think we started talking about this like nine months ago, right? deWilde: Yeah, it’s crazy. Pasick: We’ve come up with better ideas together than we ever would have on our own. deWilde: I have a real fondness for the engineers on this team, and I love that they are front and center in our collaboration. We needed to move really fast last week and build something in a day. And I’m going to take a victory lap with them on this one. Pasick: Not yet! Save your victory lap for Tuesday. deWilde: O.K. [laughs] Just by shipping: shipping that code. That’s what I was happy about. Bures: When you say you built something: are you rapidly prototyping different templates? deWilde: The goal is to make it easy for the editors to write, to try different things and to do test sends. And then ultimately, what we send to our user is a good representation of the brand. It’s not just the end result that we care about. We want the editors to feel really comfortable using the tools of the newsroom to publish. And that’s an important part of the work that the team has done leading up to this very large project. It’s not a complicated thing, but it’s good that we got it done. Pasick: Can I throw one more thing in? Way back when we were getting started, I guess it was probably back in fall 2019. We did a really exhaustive thing where we asked dozens and dozens of people in the newsroom to sit down and brainstorm with us about what the next version of the Morning Briefing could be. And it’s remarkable about how many of the ideas that we ended up going with came out of those conversations, not just in the newsroom, but on the business side: product, engineering and beyond. We really tapped into the collective brainpower of The Times in a way that felt like a really cool process to me. Bures: Will you carry some of the things you’ve learned through this project to future projects? Pasick: I hope so. We can collectively put our brains together and come up with something that we’re all happy with. There weren’t trade-offs where it was a zero-sum game, but it was more than the sum of its parts. That will be a dynamic that I try to create, or try and cultivate in other projects, for sure. Hannan: When we think about the different kinds of work that we can do in product and email, so much of it is really close to the newsroom and to editorial. We can do things like send lots of programmatic emails, and we’ll do some of that, but I think we all believe that the most powerful thing we can do with email is to use the voice of our newsroom to connect to readers. At least having one project at a time that is integrated across product and the newsroom is definitely a goal of mine. deWilde: I love working with editors, with Adam. It’s something that is a real privilege. I’d love to replicate this experience, but I think it’s very personal. The people that you’re working with; working with Frannie has been wonderful. I would love to always be as collaborative between these different partners. Bures: What do you hope readers gain from this rethought newsletter? Pasick: I want something that people look forward to opening every morning. Because it gives them the feeling that they are well informed about what’s going on in the broader world. And that by inviting us into their inbox every morning, we can hold up our end of the bargain by never wasting their time, by always telling them an accurate story about what’s going on in the world, and that they create a lifelong relationship with The Times. Hannan: Yeah, I would say, very similarly, having a morning habit that people feel good about. We hear a lot in research about — and I personally do this, too: you wake up and you scroll through Instagram for 15 minutes and you don’t feel great. And I think having something that people can do in the morning that makes them feel both entertained and informed and kind of virtuous. That’s what I hope we can do for them. deWilde: I think that it would be wonderful if with each send, a reader came away with something. Whether it’s one more piece of information or one delightful idea that they hadn’t been exposed to. So that each time it feels like they got something rewarding. And I think that is quite possible because of the richness of the editorial experience. It feels really valuable to me. I hope people recognize that and feel that too. Want to get The Morning by email? Here’s the sign-up . How we design and build digital products at The New York Times 124 Design Design Thinking Product Newsletter Collaboration 124 claps 124 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-05-05"},
{"website": "NewYork-Times", "title": "we built a plugin but its not a secret", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/we-built-a-plugin-but-its-not-a-secret-dfdf68b0e44f", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Ling Zhang and Shawn Bower The New York Times has a lot of apps. No, we’re not talking about the apps that you can download from app stores, although we do have a couple of those. We’re talking about the applications and services that we’ve built in-house to power everything from our front-end website to back-end services. It’s a lot to keep track of. To get all of these apps and services to securely talk to each other, we employ secrets, which are similar to the passwords that online accounts require. Secrets allow our apps to connect and share information, but like any good password, they need to be changed regularly. For a long time, we statically generated secrets, but this raised some issues and was hard to manage. Static secrets are often shared by multiple applications, which can make it difficult to audit appropriate usage. When they are shared, it can become close to impossible to rotate or even revoke them. Because most applications require secrets to be in a configuration file or injected into an environment, the risk of a static secret unintentionally ending up in an application’s log file is high. A single exposure can have an outsized effect on security. We needed a better solution, so we decided to shift to dynamic secrets using our secrets management tool, HashiCorp Vault. Dynamic secrets are much safer than static secrets because they can be generated whenever an application requires them, and they can be set to expire after a short period of time. To best serve Times readers around the world, we use a Content Delivery Network (CDN) that caches static content and delivers it from servers closest to where readers are located. This allows us to send news to our readers as fast as possible. Our current system uses Fastly as our CDN. For each domain that uses a CDN, we have a separate Fastly service to handle configuration. Every time we want to make changes to one of those services, we need a dedicated Fastly token for the service so we can authenticate with the Fastly platform. Rather than wrestle with the Fastly API and Vault every time we need to generate a secret — which would take us farther away from dynamic creation — we created a Vault plugin to do it for us. We are open-sourcing the plugin, which we’re calling the Vault Fastly Secrets Engine , for anyone to use. The transition over to dynamic secrets turned out to be less straightforward than we expected. We started digging into the Fastly API to see what it would take to pull this off. Quickly, we realized we had an issue: we use multi-factor authentication (MFA) for a lot of our platforms and our Fastly account is set up to require an MFA for all users. While this might have been fine with static secrets, because we could manually retrieve the special log-in code needed to connect to Fastly, our platforms couldn’t whip out a phone every time they need to log-on. This meant that we needed a way to authenticate with MFA whenever we generated Fastly tokens for the platforms. We dug into Vault’s open-source code, which already has a TOTP backend and we realized that we could pull the library in and use it to meet the MFA requirement. We designed the workflow for the plugin to log into Vault and obtain a Vault token. Then the user/application can request a Fastly token from Vault, which will validate the token request with the user/application’s policy. Vault will pass the request to the plugin which generates the Fastly token. The plugin will pass the Fastly token back to Vault which will in turn pass it back to the user/application. The plugin must be configured in advance with credentials for accessing Fastly’s API; these steps should be completed by a Vault operator or a configuration management tool. To begin, start your Vault and log-in as a root user. In order to use the plugin you must first register it with the Vault plugin catalog by providing the SHASUM of the plugin code. The SHASUM acts as a unique fingerprint of the plugin code. When the plugin is loaded for the first time, Vault will calculate the SHASUM of the plugin code it has and compare that with the SHASUM in the plugin catalog. If there is a match, the plugin will be run, if they do not match then Vault will return an error and not run the plugin. This process helps us ensure the plugin code has not been tampered with. Using the code below will ensure that your registration for the plugin is correct. It will generate the SHASUM for your plugin, and write the SHASUM into the catalog path of Vault. This should be a one-time operation that should be done by your Vault administrator. After running this, and the commands in the rest of this post, you should expect to see a message saying it was successful. After registering the plugin with Vault, you still need to enable it with the following command: By default, the secrets engine will mount at the name of the engine (Vault Fastly Secrets Engine). To enable the secrets engine to use a different path, you can use the -path argument. In the example above, we have mounted the engine to the path “/fastly.” In order for the engine to make API calls to Fastly, we must store a username, password and a one-time code (known as a TOTP code). The username and password can be stored under the “/fastly/config” path. The sharedSecret key corresponds to the key produced by Fastly when you configure an MFA login. This key will be used to authenticate with Fastly using Vault TOTP functionality when generating the Fastly tokens. (Note: the username, password and sharedSecret shown here are for illustrative purposes only. Please don’t use this in your app.) This should be a one-time configuration with your vault. You will not need to repeat this unless you change the Fastly admin account that is used to create tokens. Access to the plugin can be restricted by using Vault policies, for more detailed information on policies in Vault please refer to the HashiCorp documentation . After you’ve registered the secrets engine and configured it with the proper permissions, the plugin can generate tokens. Here are a few examples of what you can do with the plugin. (Note: the service IDs and tokens used here are for illustrative purposes only and should not be used in your application.) You can generate a new Fastly token by writing to the “/fastly/generate” endpoint with the scope of the desired token, as well as the service ID. The above command returns the token you can use to interact with the fastly API as well as the time to live (TTL) of the token. You can provide multiple service IDs by using a comma-delimited string. This is helpful if you need to act on a set of services at the same time. The command provides the same information as before, however the only difference is the range of services that it can affect. The default TTL for each token is five minutes, after which, the token will expire. Five minutes is typically enough time for setup, but anyone using this plugin can adjust the expiration using the command below. Throughout this process, we learned a lot about how to write a plugin for Vault. By open sourcing this plugin with the developer community , we hope that it will demystify the process for others. Our team is hiring. Apply to work with us here . Shawn Bower is a principal engineer with the Delivery Engineering team at The New York Times. Currently, Shawn is Tech Lead on our elections readiness project making sure our systems are resilient and ready for traffic around elections events. When not at work Shawn is busily working on his project farm; this year he is adding bees and chickens! Ling Zhang joined The New York Times after interning as an engineer on the testing team. Since joining Delivery Engineering in 2017, Ling has been a prolific contributor to code and process related to our Fastly integrations, as well as contributing to general CI and tooling for our cloud platforms. She recently joined the Web Frameworks team to work on monorepo projects, AMP and hybrid projects. Don’t be surprised if you see her climbing a mountain, solving a puzzle or flying drones. Perhaps all at the same time. How we design and build digital products at The New York Times 232 Open Source DevOps Developer Tools Code Tutorial 232 claps 232 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-04-10"},
{"website": "NewYork-Times", "title": "how the new york times works from home", "author": ["Sarah Bures"], "link": "https://open.nytimes.com/how-the-new-york-times-works-from-home-e86be507a707", "abstract": "Code Data Product and Design Workplace Culture Work with Us A version of this story was published in the Times Insider section of The New York Times on April 3, 2020. When Jack Wheeler got his job as a product manager at The New York Times in September 2019, he joyfully left a remote-work life behind, and to commemorate the occasion, he sold his desk. Yet when Times leadership asked the majority of employees to begin working from home on March 13 as a precaution against the global spread of the coronavirus, Wheeler had to readjust. He bought a new desk. Such has been the shift among Times employees over the last few weeks. Meetings that once filled conference rooms were moved to virtual rooms, where they were suddenly punctuated by the cameos of pets, children, roommates and significant others. Slack channels captured everything from team check-ins and project coordination, to home-cooked lunches and work-from-home tips. Times employees grappled with a new reality of what will likely be a prolonged stint of remote work against a backdrop of anxiety, while continuing to do the jobs they’ve always done . Times journalists have been working around the clock to ensure readers have access to the latest information on a complex and rapidly developing story. But working alongside them — remotely — are designers, developers, technicians, project managers, systems analysts, data scientists and many others whose expertise on the website, apps and other digital products helps maintain the flow of information to readers. To support a newly distributed work force, the group that provides computers and technical assistance for employees spun into overdrive, helping people troubleshoot home internet connections and fielding over 1,100 requests for computer equipment since mid-March. To date, they have shipped nearly 400 monitors to people’s homes. Even as The Times worked to ensure employees have the equipment they need, it encouraged people to take time to care for themselves and their families. In what is shaping up to be a marathon, people from all levels of the company worked to balance the ordinary in extraordinary times. With most schools closed, the days now take more planning than ever before. School at home is something M. Ryan Murphy, an archivist working with The New York Times Store, now navigates with his 9-year-old in Mamaroneck, N.Y. His days are split between devising a home-school curriculum, team meetings and helping Times readers order reprints of articles. Jaymin Patel, a senior software engineer working on election coverage, wakes up before 6 a.m. to eat breakfast and plan a schedule for the day that includes homework help for his kids and a walk around their neighborhood in Sayreville, NJ. While some Times employees have always worked remotely, others have had to adapt to an entirely new lifestyle devoid of impromptu in-person chats and built-in break time between meetings as people walked from one conference room to another. Some teams began rethinking how to best collaborate on projects and whether calendars normally packed with meetings could be lightened. For the meetings that will stay on the schedule, some people have experimented with new ways of connecting with and motivating their colleagues. Gaëlle Sharma, a product manager who works on the technical aspects of the login page on the Times website and apps, joins her team’s daily check-ins from Brooklyn and reads poems from Lin-Manuel Miranda’s book, “Gmorning, Gnight!” Sharma said, “I try to keep it in line with the mood of the day or what we’ll be working on.” On the UX Foundations team, which seeks ways to improve how readers experience the Times website and apps, the first person to sign on in the morning shares a question for the team to answer — questions range from, “What’s your favorite show to binge-watch?” to “Do you prefer the local or express train?” It’s a way for everyone to connect on something silly before digging into the day’s work. For the team that handles email, push notifications and personalized content recommendations, daily team meetings end with The Times’s word-formation game, Spelling Bee . “Everyone just shouts out words and one person types them in,” said Dan Schlosser, a senior product manager on the team who signs on from Manhattan’s Upper West Side. Just as teams connected in work meetings, people have been meeting virtually to talk more casually over lunch, coffee and happy hours. Lauren Rollins, an associate marketing manager from the Games team, said that she and her colleagues recently held a virtual happy hour in honor of a colleague headed to a new job. Everyone made a drink from their homes — Rollins made an Aperol Spritz — and dialed into a Google Hangout for a little over an hour. The gathering evolved into a show-and-tell where members from the team shared items from their homes: a Woody figurine from “Toy Story,” a microphone for recording music, art and gaming setups. Rollins’s contribution was a limited edition makeup palette inspired by the Japanese manga “Sailor Moon.” The locus of The Times’s culture has primarily revolved around the Times building, with many conversations happening over casual coffees and quick chats while waiting for the elevators. This put remote employees at a disadvantage because they couldn’t participate in casual in-person conversations, and joining video calls was an imperfect solution. Now, with everyone on video calls or Slack, the rules of communication have been equalized. “It’s easy to get your words in” during team meetings, said Vicki Crosson, a software engineer on The Times’s search team. Crosson, who has been working remotely from Boston for over a year, said that people on her team are doing more to make sure everyone is heard. Where Times employees do their jobs has changed, but how they do the work and support one another has not. “I’ve been so inspired by my colleagues,” Meredith Kopit Levien, chief operating officer at The Times, wrote via email. “They’re working from kitchens and bedrooms, between home schooling lessons, while caring for loved ones, and for many, facing unprecedented solitude and anxiety.” Over the last couple of years, The Times has promoted ways that encourage employees to bring more of themselves to work. For now, however, employees are defining what it looks like to bring their whole homes. Sarah Bures is the editor of NYT Open at The New York Times. She is working remotely from Brooklyn, NY. How we design and build digital products at The New York Times 115 Work Workplace Covid 19 The New York Times Work Life Balance 115 claps 115 Written by Picture taker, rock climber, pun enthusiast. // Editor of @timesopen at The New York Times How we design and build digital products at The New York Times. Written by Picture taker, rock climber, pun enthusiast. // Editor of @timesopen at The New York Times How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-04-03"},
{"website": "NewYork-Times", "title": "how to dox yourself on the internet", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/how-to-dox-yourself-on-the-internet-d2892b4c5954", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Kristen Kozinski and Neena Kapur No one wants their home address on the internet. That is personal information we typically only give out to friends, family and maybe our favorite online stores. Yet, for many of us, that information is available and accessible to anyone with an internet connection. And increasingly for journalists, public figures and activists, this kind of information is dug up and posted to online forums as a form of harassment, or doxxing. Doxxing (also sometimes called “doxing”) is a low-level tactic with a high-impact outcome: it often does not require much time or many resources, but it can cause significant damage to the person targeted. Once sensitive information — such as home address, phone number, names of family members or email addresses — about a targeted individual is posted to public forums, it can be used by others for further targeting. The tactic is typically used to intimidate and silence, to prove a point or to discredit someone’s work. In 2019, a far-right group that disagreed with news coverage posted the personal information for three dozen journalists from news organizations in the United States, including The New York Times, on a site run by the group. After Christine Blasey Ford testified before the Senate Judiciary Committee in 2018, her personal phone number, home address and more were posted on Twitter and she soon started receiving death threats and harassment. During the Hong Kong protests in 2019, doxxing was a tactic used by both sides to expose personal information of protestors, police officers, journalists and social workers. These attacks demonstrate that people dox — and are doxxed — for a variety of reasons. But regardless of the motive, an attack can be dangerous. With that in mind, it is particularly important to take proactive digital security measures. Protecting personal information is more than just securing data, it guards against further digital attacks or even the possibility of physical harm. In 2017, the New York Times Information Security team began exploring the numerous ways personal information spreads through the internet. We wanted to understand how this information surfaces and how to clean up an online footprint — which includes everything from personal information like phone numbers, to what you like and who you follow on social media — in order to decrease the threat and impact of doxxing. Doxxing itself relies on open-source data as well as data that may be circulating in spaces like the dark web. While we cannot control all the information about ourselves on the internet, we can take steps to make data more difficult to find. When our team begins looking into the personal information that is available online for a colleague, we think like doxxers and use some of the same readily available online resources that doxxers may use to surface personal information: Search engines: This is where we start. A search with a journalist’s name and the words, “phone number” or “address” might bring up a people-search site or the journalist’s social media accounts. Targeted searches can lead to sites that reveal a lot of information about someone and their behavior online. Data broker and people-search sites: Targeted searches on search engines often lead to data broker or people-search sites, which provide holistic profiles of individuals and package sensitive information into a single report that is usually available for free or for a minimal cost. These sites collect the personal and behavioral information of consumers from public records, open-source information and other data brokers, and sell that information to other companies and individuals. Social media: A doxxer might scroll through a journalist’s social media sites to gather more intimate details about their life, such as insights into their relationships, habits, personal photos, emotional state, and their likes and dislikes. While doxxers use these tools to do harm, journalists can use them to control the amount of personal information that is available online. From locking down social media profiles to opting out of major data broker websites, there are concrete mitigation strategies that anyone with an internet connection can do. It just takes a little time. It’s impossible to control all the personal information that is out there, but we can take steps to make it more difficult to find. If a doxxer can’t find a journalist’s information in a few hours, then that may discourage them from pursuing the journalist as a target for doxxing. To help our Times colleagues think like doxxers, we developed a formal program that consists of a series of repeatable steps that can be taken to clean up an online footprint. Our goal with this program is to empower people to control the information they share, and to provide them with tools and resources to have a better awareness around the information they intentionally and unintentionally share online. We are now publicly releasing the content of this program for anyone to access. We think it is important for freelancers, activists, other newsrooms or people who want to take control of their own security online. Whether you run through this process once or twice a year, or take these steps before publishing an article that may cause a stir on social media, incorporating this digital cleaning practice should be a part of general online hygiene. Of course, we can’t completely erase ourselves from the internet, but we can make it harder for people with ill intent to find our personal information. The resources we are publishing are for anyone to use and share. The materials can be accessed here and include: Doxxing Guide : This guide details steps that you can walk through on your own or with a group to begin cleaning up your online footprint. It includes a list of data broker websites that offer opt-out options, targeted techniques for search engines and tips for locking down your social media accounts. Social Media Security and Privacy Checklist : This guide includes checklists of recommended security and privacy settings for several popular social media websites that will ensure your profiles are locked down and that you’re only sharing information that you’re comfortable sharing. Doxxing Curriculum Outline : A high-level overview of the curriculum we used when running doxxing workshops at The New York Times. If you’d like to bring a version of this program to your newsroom or organization, or to a group you work with, this resource will help you build out a formal training session. We hope you find these resources helpful. Today’s information security threats against journalists are dynamic and ever-evolving, which means that the best way to improve the safety and security of journalists today is to share and collaborate on best practices and resources. Kristen Kozinski is the Information Security Training Manager at The New York Times. She focuses on providing educational resources and training about digital security for our newsroom and business operations. @dontclickonthat Neena Kapur is the Security Intelligence Manager at The New York Times, where she focuses on proactively understanding and defending against digital security threats targeting The New York Times and the media industry. @neenahyena Floyd Muir, Information Security Trainer, and Yulini Persaud, Information Security Intern, also contributed to the resources associated with our Doxxing program. How we design and build digital products at The New York Times 350 4 Information Security Journalism Data Training Work 350 claps 350 4 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-06-03"},
{"website": "NewYork-Times", "title": "connecting the dots on game development", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/connecting-the-dots-on-game-development-a28214b513bf", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Andrew Dore, Ashley Riccardi, Carron White and Sam Von Ehren The game idea that would eventually become Vertex was born the weekend Sam Von Ehren moved to New York City. In the middle of unpacking, Von Ehren took a break to attend a friend’s party, where he met Deanna Destefano, one of the product designers on the New York Times Crossword app. Destefano told Von Ehren that her team was beginning to brainstorm ideas for new games, but all they could come up with were word games. “It would be cool,” she said, “if we did something with colors and shapes.” While the party raged on, Von Ehren, a game designer by training, kept turning that prompt over in his head. How might one make a Times game without words, he wondered. When he went home, he drafted up a prototype for a game that asked players to create two triangles from four dots. The idea combined a tangram puzzle with the dots and boxes game often played on pencil and paper. Two years later, Von Ehren had gotten a job as a game designer on The Times’s the Games team and was leading the brainstorming for new games. The team had just launched Tiles , its first non-word game, and wanted to prototype more non-word games. Von Ehren fished out the old prototype he had designed his first weekend in New York and showed it to the team. While the team thought the game was interesting, they didn’t think solving it felt like a big enough accomplishment. The solving experience needed to feel revelatory, like the flash of insight that comes when solving a crossword puzzle. That’s when the team had their own “ah-ha” moment: instead of centering the game around drawing triangles, they reoriented it so the shapes reveal an image when connected. As players connect the dots, the shapes fill with color, hinting at the final image. To keep players engaged and hint at the final image, the team included a clue, similar to those found in traditional crossword puzzles. At its core, a vertex puzzle is a drawing game with a logic component. A clue adds an element of riddle to the puzzle. The team had their game concept down—and a name for the game: Vertex . The dynamics of the game were defined, but the team still needed to know whether users would actually play it, so they built a web-based prototype with basic features and minimal design to see how users responded to the game. It was linked at the bottom of the news feed on the mobile version of the Times website for two weeks. The team tracked the number of users who played the game, how they interacted with it and whether they returned to play again. (They did.) Armed with positive user data and the green light to build a full-fledged game, the team had to decide what the final game would look like and how it would be built. For Andrew Dore, a product designer on the Games team, the weeks after the prototyping phase were dominated by design discovery. Because the game is a blend of geometry and low-poly art, Dore started his design inspiration there and brainstormed ways to create an engaging playing experience. The challenge for a game based on mathematics, however, is to prevent it from feeling like homework. Games are emotional experiences created, in part, by how they look. Dore knew that simply highlighting the game’s geometry component would create a one-dimensional experience. So he started to explore how a visual narrative could convey the object of the game while elevating the experience of playing it. Since players connect dots by drawing lines, much like stargazers might do in the night sky, Dore decided to use the visual metaphor of a constellation in the game design. Most people are familiar with the concept of drawing shapes by connecting dots, so Dore thought that leaning into this metaphor would help teach users how to play Vertex. Dore created a moodboard with examples of geometry and constellations, as well as visual references to designs that use simple shapes and color, and started working on designs. How it feels to play a game is just as important as how it looks, especially in a digital environment. To design the feel of Vertex, Dore created a number of simple animations and prototypes. While the dots and lines in the game are simple, it took some experimentation to decide how they should react to user actions. Dore considered whether the dots should be firmly set as if they were pins in a pinboard; or whether they should slide around as if they were on ice; or if they should float as if suspended in water. For the action of line drawing, he tested interactions that emulated wire being pulled from a tightly wound spool, and if released, the line would retract automatically. To keep track of all of the user interactions, the team created a large diagram with every user input and possible animation. This is where the process shifted from exploring visual treatments to building out the game. Building an interactive game can be complicated. This is especially true with Vertex, as it has numerous moving parts and points of user interaction. The game is also built for the web, which means it needs to work on a variety of screen sizes, from desktop to mobile. The front-end engineering team, made up of Ashley Riccardi and Carron White (with some help from Greg Skiano), decided to build the game using HTML Canvas because of its drawing capabilities. The beginning of the development phase raised a user experience issue: on small devices, some dots appeared so close together that users couldn’t access them. The engineering team realized that Vertex needed pinch and zoom capabilities. Since they were using HTML Canvas to build the game, the team tried the built-in Canvas functions for transforming and translating the interface. This worked to a point, but didn’t provide the control they wanted users to have when navigating the interface and it negatively affected other features in the game. The team opted to build their own zoom and pan functions. When users zoom in the game, the functions calculate how large each shape on the screen should be and they redraw the shape; the same thing happens when a user pans. This functionality became the technical foundation for the rest of the game. Just as Dore considered how the game feels in his designs, the engineers factored “game-feel” into their development process. With so many points, lines and triangles on the page, performance was being negatively impacted and it didn’t feel good. Initially, they drew all of the shapes on a single canvas element. This meant that anytime a user drew a line from one point to another, every single shape (which could amount to hundreds on certain puzzles) had to be redrawn. And since this would happen anytime a user’s cursor moved while drawing, this could mean redrawing hundreds of shapes, possibly hundreds of times over the span of a few seconds. The game felt laggy. To fix this issue, the engineers separated elements onto different canvases and layered them on top of one another. The triangles are on one canvas, completed lines on another and the points on a third. These three layers are topped by a blank canvas that renders the line that is actively being drawn. This protects the other elements while the user is drawing the line. Once a shape has been successfully created, the line and triangle are added to their respective canvases. No clearing or redrawing required. In the end, this amounts to a game that doesn’t weigh down a browser and feels good to play. Since launching Vertex, the team has learned a few things: namely, that building a game as interactive as this one was really hard. But as they rose to the challenge, they created a strong technical foundation that will allow them to experiment with other visual game ideas in the future. They also have some post-launch improvements queued up: they intend to improve the touch experience on mobile and implement new design features such as UI color themes that enhance the solving experience and additional animations. Check out Vertex here . Andrew Dore is a Senior Product Designer on the Games team at The New York Times. Ashley Riccardi is a Software Engineer on the Games team at The New York Times. Carron White is a Software Engineer on the Games team at The New York Times. Sam Von Ehren is a Game Designer at The New York Times and has made analog, digital, VR and AR games. How we design and build digital products at The New York Times 109 5 Design Game Development Game Design Product Games 109 claps 109 5 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-03-06"},
{"website": "NewYork-Times", "title": "how we implemented a baseline grid using css", "author": ["Gabriel Gianordoli"], "link": "https://open.nytimes.com/how-we-implemented-a-baseline-grid-using-css-cb13cac45201", "abstract": "Code Data Product and Design Workplace Culture Work with Us To commemorate the 100th anniversary of the Bauhaus, the German design school known for its adherence to functional design ethos, we published a story in The New York Times featuring architecture from around the world that had been inspired by the school. While designing the digital presentation for the story, I, along with my design colleagues Rebecca Lieberman and Eden Weingart , decided to add a small Bauhaus-like detail for design-history aficionados: a baseline grid. Baseline grids are evenly spaced horizontal lines to which the bottom of text is aligned. They are commonly found in book and magazine publishing, but the practice can be found in historical artifacts like the Gutenberg Bible , which used a baseline grid in its two-column layout. Print graphic designers often favor baseline grids for the vertical rhythm they give a page of text. On thin paper, baseline grids also prevent text from opposite sides of a sheet from affecting each other. If those lines are not aligned, they can end up making the text harder to read. While the practice is widely used in print design, baseline grids aren’t often found in digital design. Print publishing software, such as inDesign, has an option to align text to a baseline grid, but there is no built-in way of doing this with CSS. On the web, the lift to achieve a proper baseline grid is significant and usually requires a painful process of trial and error. The main argument against it is that the benefits are not worth the cost of set-up. Type on the web behaves differently than type in print publishing software. In print, type is set along a bottom line and leading, or the space between lines of text, is the distance from one baseline to the next. But on the web, the type “floats” within each line of text. Instead of leading, we have line-height , which is a measure of the vertical space occupied by each line of text. Think of it as if the text were aligned to a central axis, and the line height grows both up and down. To make this more complicated, pictures and other visual elements have to align to the grid as well, otherwise they might push text out of the grid. The most straightforward solution is to set fixed sizes for all elements, however this is at odds with the flexibility needed when designing for a multitude of digital screen sizes. Because of all that, some digital designers opt for a vertical text grid on the web without baseline alignment. That is not so hard to accomplish, requiring only a modular scale for type size and line height . On our Bauhaus story, we went for the real “on the baseline” grid. This is how we did it. There are several approaches for implementing a baseline grid on the web. Some involve pseudo-selectors, such as :before and :after , while others use margin and padding. There are also some CSS frameworks ready to download and use, however third-party frameworks are often not workable solutions for us because they affect how the elements built into New York Times story page templates render. In our Bauhaus story, we had a pretty limited set of elements that repeated down the page, so creating rules for each of them was laborious but doable. The main principles we followed are outlined in this post by Razvan Onofrei. In short, they are: Shift elements up or down to align them to the grid; Set text line height according to the grid spacing; Add an extra space after to make sure elements leave the flow on the grid. On our Bauhaus story, we based the size of the grid on the body copy, using the line-height for grid spacing: font-size: 19px; line-height: 28 px . This means each grid square measured 28 pixels. To ensure that the baseline of the text sits on the baseline of the grid, we had to shift the paragraph down a little. Onofrei has a formula you can use that is based on the font’s cap-height (the height of the capital letter, measured from the bottom to the top): font-size * (line-height — cap-height) / 2 . We simply tweaked the settings until they looked right. Notice that we needed the padding-bottom to ensure each paragraph ends on the grid. You may wonder why we combined margin and padding instead of just using margins: this is because of a CSS behavior called margin collapsing , where CSS combines the top and bottom margins of adjacent siblings. This happens in other cases too, like parent and child elements. Once we got the body copy right, putting the rest of the type on the grid was a matter of manual work. As with the body copy, we set the margin-top and padding-bottom of the first element. We then repeated that for each following element. Notice in the screenshot above that the padding-bottom for the name of the city ( g-place ) element does not reach the baseline. In order for it to sit on the grid, we would have had to add a full baseline grid between it and the following header ( g-name ), which would have looked too loose, typographically speaking. Because g-place and g-name always appear together in our Bauhaus story, we weren’t worried about breaking the grid. For images, the easiest approach is to define a fixed height based on the grid unit, but it is against common practice to define image height. In responsive design, we usually define the image size in relation to the width of other elements or the screen. In our Bauhaus story, we had a vertical grid on the page that elements needed to align to, as well. The images had a 3:2 aspect ratio, which meant that they would only work when both their dimensions fit the grid. To solve this, we set four fixed widths for the large images based on three different breakpoints. The code below uses SASS variables: You can define as many sizes as you want, as long as the formula n * 1/aspect-ratio — where “n” is how many grid-units wide you want the image to be — results in an integer. For example, on the image above 24 * 2/3 = 16 , so the image will be 24-grid-units wide and 16-grid-units tall. Our captions were too small to use a line-height that fit the grid. That would not have been a problem if we had subdivided our lines, but that would have created too much visual clutter. We couldn’t just add padding because on mobile it sometimes made our captions break into two lines, which would have broken the grid. Our solution was to add a min-height to prevent that from happening. You might have noticed in the code snippets above that all our values were set in pixels. For accessibility purposes, setting spacing dimensions in rem is more recommended. I find writing specs in pixels more intuitive, so I sometimes use a SASS function to convert them to rem. Whatever you decide to do, just make sure your computed values are pixel integers. Browsers behave in different ways when dealing with pixel fractions: some try to emulate them, others simply round them. In both cases, chances are that your grid will break at some point on the page. As I mentioned before, there are several other ways of implementing a baseline grid on a web page. What you end up choosing depends on several factors: Do you have full control of your environment, or is your page running under some CSS rules not accessible to you? Are you designing a one-off page or a system that needs more flexibility? Is there enough text on your page to justify this effort? It’s important to consider those questions before attempting to implement a baseline grid. No matter what you choose to do, it will still be some sort of hack — and you might as well decide to create your own. Gabriel Gianordoli is a Graphics and Multimedia Editor with the Digital News Design team at The New York Times. How we design and build digital products at The New York Times 510 Typography CSS UX Design Tutorial 510 claps 510 Written by http://gianordoli.com/ How we design and build digital products at The New York Times. Written by http://gianordoli.com/ How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-11-21"},
{"website": "NewYork-Times", "title": "its all part of the plan", "author": ["Angela Guo"], "link": "https://open.nytimes.com/its-all-part-of-the-plan-e165dba39842", "abstract": "Code Data Product and Design Workplace Culture Work with Us The New York Times print paper is sometimes referred to as ‘The Daily Miracle’ for the astounding amount of coordination and labor it takes to produce. The miracle isn’t confined to the printed paper, however. It includes the numerous people who work on a single story, readying it for publication. It involves the planning of publication dates and promotion strategies for the more than 200 original pieces of journalism that are published daily — only some of which end up in the printed paper. It’s the production of our homepage and our apps, and the curation of our presence on social media. The amount of coordination across all of these fronts is nothing short of miraculous, but with so many moving parts, collaboration and cross-desk transparency can be difficult. Over the years, editors developed their own methods for documentation and often created complicated planning flows that involved an ever-evolving combination of platforms and tools. In addition to being chaotic, this sometimes resulted in duplicated administrative work, data inconsistencies and siloed knowledge; sometimes it meant great stories weren’t properly promoted. We needed a solution that would improve our newsroom workflow. Before we started, we had two main questions: How can we create a system that makes coordination across dozens of desks, each with their own needs and workflows, simple and flexible? How can we help platform and off-platform editors program content on our home page and social media accounts? Our initial answer: we didn’t know! But we did know we needed a tool that made print and digital production transparent, where all types of editors could easily find the articles they’re working on and collaborate. We also knew we needed a unified system for editors to plan and publish their daily report, because better tools and simpler planning workflows lead to a better experience for readers. After evaluating third-party solutions and comparative products used by competitors, we didn’t find a silver bullet that would work for our newsroom workflow. So project leads Johna Paolino and Kellen Henry worked with Tessa Taylor, Dylan Nelson and me on the engineering side and we experimented. Working with editors from the Business, Climate and Science desks, as well as editors in charge of platform and off-platform programming, we designed and built a prototype of a planning tool. The prototype featured a single view with all relevant planning data across desks, which allowed editors to make decisions in context. It also had status indicators that showed whether a step, like promotion on Facebook, had been completed. We called it Project M, as a nod to the goal of putting management back into our content management system. For two weeks, participating desk editors used our prototype to plan their report. This short experiment taught us about critical moments in the production process and points of high friction in the current system. It confirmed some ideas, like the need for a search result design that had a “show don’t tell” attitude towards story status and a way to capture a story’s priority. It gave us confidence in our direction. Using insights gained from the prototype, we built a planning tool, called Story Dashboard, that now lives permanently in our CMS. The dashboard pulls data from our core publishing system — the same system journalists use to write and publish stories. Editors can search for specific stories or stories relevant to their desks by using filters and keywords; Searches can also be shared with other people in the newsroom. The dashboard provides custom views based on user preferences, which editors can enhance with saved searches. This helps the newsroom find, organize and evaluate the status of stories, so editors can make decisions about their reports. We built a user interface that clearly shows the status of each asset, such as whether a headline has been written or if all necessary photos have been inserted. We found this to be more impactful and effective for communicating status than a tag marking the asset as done. Clicking into a result gives more detailed planning and promotion information, as well as a live preview of the story. In a publishing ecosystem where a single article might be published several different times across multiple distribution platforms, a single publication date isn’t useful. To address this, we built separate digital and print publication date indicators. Editors can search for articles that fit whichever date type is most relevant to their work. Because search functionality isn’t the best fit for every use case, we created a couple of specialized workspaces. We built a Planned workspace that shows all upcoming stories, grouped by publication date, for an editor’s assigned desk. At a glance, desk editors can see what work remains to be done for stories that are scheduled for publication on a particular date and they can plan for what’s coming up; To change an article’s publication date, an editor simply needs to drag and drop the story onto another date. Editors can optionally look at the stories that have already been completed. Another key lesson we learned from Project M was that editors needed to see distribution feedback. It’s important for desk editors and social platform editors to be able to see whether a story has been promoted on a specific platform. Prior to the launch of Story Dashboard, this step required a lot of in-person communication, which could be challenging if numerous people were working on a story or if someone wanted to quickly get this information for all stories across a single desk. We partnered with the Metro and Styles desks, and helped them move their planning flows entirely into Story Dashboard. Onboarding the first desks fully to our system further clarified what we got right and what we still needed to build. We enriched the planning capabilities of the dashboard by building a calendar view that gives editors a visual understanding of their week ahead. Editors can easily plan their short-term and long-term report in context and share plans with colleagues. Editors told us that they needed a place to capture in-progress ideas for stories. There was no place to do this in our tools, which lead to fractured brainstorming and lost ideas. We built a workflow called Tentative into Story Dashboard to capture those ideas that are influx or might not run. Newsroom planning is extremely complicated: it requires collaboration, transparency and a shared understanding of status. By consolidating all of our newsroom’s planning needs into one tool from disparate and unlinked systems enables everyone to have full context when making decisions. The easier this work is, the more our editors can focus on editorial decisions instead of wrangling administrative tasks, which makes The Times better for readers. As digital production continues to evolve, so will the planning and promotion requirements of our newsroom. When workflows change, we’ll continue to build tools that help editors do their work efficiently and produce our daily print and digital miracle. Angela Guo is currently the tech lead of the Workflow team at The New York Times. The Workflow team is: Nathan Ashby-Kuhlman, Matthew Tanzer, Will Dunning, Jill Kacere, Matthew Clawson, Donna Rickles, Artur Charaev, Michael He, Lauren Peterson and Aaron Lee. Thanks as well to former project leads Tessa Taylor, Matt Berkowitz and Caroline Cox-Orrell, and especially to Johna Paolino and Kellen Henry who created the vision for this project and without whom this team would not exist. Illustration by Jackie Ferrentino. How we design and build digital products at The New York Times 947 Journalism Code Product Development Innovation Design 947 claps 947 Written by How we design and build digital products at The New York Times. Written by How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-11-14"},
{"website": "NewYork-Times", "title": "how the new york times is experimenting with recommendation algorithms", "author": ["Anna Coenen"], "link": "https://open.nytimes.com/how-the-new-york-times-is-experimenting-with-recommendation-algorithms-562f78624d26", "abstract": "Code Data Product and Design Workplace Culture Work with Us The New York Times will publish around 250 articles today, but most readers will only see a fraction of them. The majority of our readers access The New York Times online, not on paper, and often using small devices, which means we have a “real estate” problem: we produce more journalism than we have space to surface to readers at any given time. To help our readers discover the breadth of our reporting, The Times is experimenting with new ways to deliver more of our journalism to readers. We are building real-time feeds, specialized newsletters and customizable parts of our news app . We are also using recommendation algorithms to highlight articles that are particularly relevant to our readers. Algorithmic curation at The Times is used in designated parts of our website and apps. We use it to select content where manual curation would be inefficient or difficult, like in the Smarter Living section of the homepage or in Your Weekly Edition , a personalized newsletter. Personalization algorithms are used to complement the editorial judgment that determines what stories lead our news report. One recommendation approach we have taken uses a class of algorithms called contextual multi-armed bandits . Contextual bandits learn over time how people engage with particular articles. They then recommend articles that they predict will garner higher engagement from readers. The contextual part means that these bandits can use additional information to get a better estimate of how engaging an article might be to a particular reader. For example, they can take into account a reader’s geographical region (like country or state) or reading history to decide if a particular article would be relevant to that reader. The algorithm we used is based on a simple linear model that relates contextual information—like the country or state a reader is in—to some measure of engagement with each article, like click-through rate. When making new recommendations, it chooses articles more frequently if they have high expected engagement for the given context. One model we implemented is a geo-bandit that tries to optimize the expected click-through rate of a set of articles based on the state in which the reader is located. To illustrate this, let’s say we’ve shown two articles—article A and article B—to readers, capturing data about the states that readers were located in and whether they clicked on the articles. [“recommended”: “article B”; “reader state”: “Texas”, “clicked”: “yes”][“recommended”: “article A”; “reader state”: “New York”, “clicked”: “yes”][“recommended”: “article B”; “reader state”: “New York”, “clicked”: “no”][“recommended”: “article B”; “reader state”: “California”, “clicked”: “no”][“recommended”: “article A”; “reader state”: “New York”, “clicked”: “no”] Once the bandit has been trained on the initial data, it might suggest Article A, Article B or a new article, C, for a new reader from New York. The bandit would be most likely to recommend Article A because the article had the highest click-through rate with New York readers in the past. With some smaller probability, it might also try showing Article C, because it doesn’t yet know how engaging it is and needs to generate some data to learn about it. Over time, it will get a really good estimate of every article’s click-through rate given every possible location and then mostly show articles it expects to perform best in a given context. We chose to use approximate geographical location because it’s one type of contextual information that is readily available in web browsers and apps. While location is not always relevant for news consumption, parts of our report are more relevant to readers in certain parts of the United States or the world. There are many other types of contextual information, some of which we have implemented. They include a reader’s device type; the time of day where a reader is located; how many stories a reader has viewed in a particular news section, from which we can gauge interest in a particular topic. We have found that depending on the type of articles we’re recommending, different kinds of context variables help the model perform better. We tested a version of the geo-bandit described above in a recommendation module called Editors’ Picks, which shows up in a right-hand column alongside our articles. As the name suggests, editors choose about 30 noteworthy pieces of journalism for the module. We then use a geo bandit to select which particular articles to show to readers based on their location (which we broadly defined by state or region). Here are some examples of headlines from articles the geo-bandit recommended to readers in different states. I Know the Struggle’: Why a Pizza Mogul Left Pies at Memorials to 4 Homeless Men Scientists Designed a Drug for Just One Patient. Her Name Is Mila. Chasing the Perfect Slice, Bread and Salt in Jersey City Looks to Rome The Phones Are Alive, With the Sounds of Katie Couric When My Louisiana School and Its Football Team Finally Desegregated This Is an Indian House, According to One Architect No One Needs a Superyacht, but They Keep Selling Them The Phones Are Alive, With the Sounds of Katie Couric When My Louisiana School and Its Football Team Finally Desegregated The Phones Are Alive, With the Sounds of Katie Couric 36 Hours in Milwaukee No One Needs a Superyacht, but They Keep Selling Them Note how the recommendations include articles that are popular across all of the regions (“The Phones Are Alive, With the Sounds of Katie Couric”), while also capturing different regional interests (“36 Hours in Milwaukee”). By making regionally relevant recommendations, we were able to increase the click-through rate on the Editors’ Picks module by 55 percent, compared to randomly choosing from the pool of articles selected by editors. Although the underlying algorithm is relatively simple, contextual bandits can be challenging to implement. Bandits must be continuously re-trained with new data on reader engagement with articles on the Times homepage or apps. This means that not only do we need accurate data on which articles readers read (click data), we need accurate data on what articles were shown to readers (impression data). Further complicating bandit implementation is the need to do these calculations quickly. As readers visit our page, recommendations need to be made in real-time to avoid blank sections of the page. This real-time requirement also means that any contextual information about the reader has to be made available for our algorithm along with the recommendation request. Keeping these requirements in mind, we re-train on the most recent data generated by readers interacting with content on our site, and we re-deploy bandit models every 15 minutes. The models are deployed via Kubernetes and training runs are orchestrated using Kubernetes cron jobs. The training data comes from our main event tracking store in BigQuery. To ensure we have an accurate measurement of what articles were shown to readers, along with data about which articles were read in full, we implemented impression tracking. We found it particularly useful to store a unique ID for every article impression and carry that ID forward whenever a reader clicks on an article. This allows us to join impressions and clicks easily during training. Using BigTable, we maintain a low-latency store that allows us to quickly access a reader’s recent reading history; We use the articles a reader has read in the past 30 days to build some of the contextual features. We wrote our contextual bandits in Python, but to ensure they can respond fast enough to meet our latency requirements, we rewrote some of the functionality in Cython, a compiler that translates Python to equivalent C code. Using contextual bandits got us pretty far in terms of increasing reader engagement. But like any algorithm, contextual bandits have strengths and weaknesses. Bandit algorithms are great at quickly adapting to changing preferences and efficiently it exploring new options. A downside is that they are not primarily designed to make recommendations that feel personalized . Next, we want to combine contextual multi-armed bandits with other models in our recommendation toolbox—like collaborative filtering or content-based recommenders—that include a more fine-grained representation of readers and their interests. By adding outputs of these models as context features to a contextual bandit, we hope to leverage the strength of each approach and get another step closer to our goal of helping our readers discover the coverage most relevant to them. Anna Coenen is a Senior Data Scientist at The New York Times. She also enjoys plants, cats and cognitive science. How we design and build digital products at The New York Times 665 4 Machine Learning Data Science Algorithms News Data 665 claps 665 4 Written by Senior Data Scientist at The New York Times and Cognitive Psychology PhD How we design and build digital products at The New York Times. Written by Senior Data Scientist at The New York Times and Cognitive Psychology PhD How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-10-17"},
{"website": "NewYork-Times", "title": "the case of the mysterious disappearing bug", "author": ["Goran Svorcan"], "link": "https://open.nytimes.com/the-case-of-the-mysterious-disappearing-bug-588b27675650", "abstract": "Code Data Product and Design Workplace Culture Work with Us It was a very regular day on the Games Team at The New York Times. Our little workshop of puzzles and code was humming along and the iOS team was wrapping up a release of our Crossword app for Apple iOS 12. It was the first version of our app for the new operating system, so our QA team was scrubbing through all of our features to make sure everything worked. Sometimes when the QA team reviews features they find bugs, and this time they found a glaring one: if the log-in form was filled out, the log-in button wouldn’t work. Not a problem, we thought. Lets throw the QA ticket in our sprint, tighten a few screws here, blow out some dust there and we’ll be ready to ship in no time. But when we re-ran the app, the bug was nowhere to be found. Perhaps we had sent the QA team the wrong build, or maybe we hadn’t said the proper incantations that Apple’s certification process sometimes requires. So we rebuilt, muttered the obligatory chants and sent the build back to our QA team. When they opened the app, the bug was still there. We started searching for the bug, and this time we meant business. We ran our app in all kinds of configurations until, finally, we got the bug to show up in one of our debug builds. We rejoiced, and then we lamented. Not only had we reproduced the bug, we revealed a few other seemingly unrelated errors. And the errors differed every time we ran the app. It became clear to us that this was the scariest bug of all: the inconsistently reproducible kind. A large part of our app is structured to conform to a reactive programming style. This involves many things, but a key bit is: the app uses objects called observables that broadcast certain kinds of data at varying intervals and configurations. Other objects can become subscribers to observables and act when data is transmitted. The log-in fields — username and password — broadcast the text entered into them, and the log-in button subscribes to the data transmitted by the log-in fields. The button is only enabled after it has received confirmation that the fields have been filled out. These types of objects don’t exist within the native Apple framework, so we imported a library written in-house by New York Times developers to provide them. Because this structure is so fundamental to many parts of our app, there was no one clear way of finding a solution, so we opened up our Apple toolkit and got to work. Even though we were seeing multiple errors, we decided to focus on the initial one: the broken log-in button. Like someone trying to eradicate a ghost from a century-old home, we proceeded to try everything. First, we littered our code with print statements at every point an action could happen in response to user input; We numbered each statement so we could track which parts of our code were being hit. This confirmed that yes, sometimes our log-in button would just not receive the transmission from one or both of the log-in fields. But it brought us only more confusion because it didn’t explain the inconsistency between different launches of the app. We then took a more hands-on approach and put breakpoints at each part of the user flow, inspecting the states of each object along the way. Again, we confirmed that the error was indeed happening, but we were also able to see that while a transmission was being sent from the log-in fields, the log-in button wasn’t getting it. So the problem didn’t seem to be with the observable, but rather with the subscriber. Moving on, we noticed that the log-in button wasn’t the only subscriber to the log-in field observables, so we tried to rearrange the order in which subscribers were added to the fields. At first we thought we were on to something because this seemed to fix the problem. But sadly this reprieve was fleeting, as the error popped up again on a subsequent launch. Then we tried another common debugging tool that will be familiar to many developers: utter frustration and desperation. We decided to take a break from the bug hunt for a day. After a good night’s sleep, we decided to further pursue the idea that the issue had something to do with the subscription logic for observables. We dug into our in-house library that provided us these objects and that’s when things got interesting. We found that each observable would keep a log of all the objects subscribed to its broadcasts. The log contained references to each subscriber that appeared as values in a standard key-value dictionary. To create the keys required, the observable would look at all of its current keys to find their maximum hash value. It would then increase that value by one to create a new key, associate that key to the new subscriber and move on. This seemed a little odd because there was no guarantee that we wouldn’t get overwrites. For example, say the following steps occur: - First subscriber is added under key 0 // Current keys: [0]. - Second subscriber is added under key [0] plus one. // Let's say the hash of 0 is 99, making this new key 100. // Current keys: [0, 100]. - Third subscriber is added under the minimum hash of the current keys, plus one // Let's say the hash of 0 is 99 and the hash of 100 is 50, making this key 100. // Current keys: [0, 100] and now we have an overwrite. Sometimes subscribers would overwrite one another, which meant they would be unable to receive and respond to broadcasts. Our log-in button wasn’t always receiving the broadcasts from our log-in fields that users had filled in the fields. It would seem that we had found our answer! This would explain the inconsistent behavior because hashes could differ between runs of the app. Even with our answer, we still didn’t know why this error hadn’t creeped up before and why it was suddenly so prevalent. Our detective work was not over yet. One clue was that we had started seeing the error after the first release of our app on iOS 12. After looking through the release notes for the new OS, we noticed that there was a change to how the hash values for integers were calculated. An integer’s hash used to be its own value, but now it was a proper randomized hash. Before iOS 12, the subscription process above would simply create a list of keys in incremental values, but after iOS 12 it started indiscriminately writing over subscribers. Our sleuthing paid off. With the root cause of the bug identified, our next step was to find a solution. As often happens in the development journey, this turned out to be the least glamorous part. It turned out we were behind in the version of in-house library; The logic had been fixed in the latest version. All we needed to do was update our dependencies. With everything up-to-date, we gave things a good polish, got the O.K. from our QA team and shipped the latest build of our app to users. An unceremonious end to a maddening bug. However, we did learn three whole lessons from just one bug, so let’s chalk it up to a mixed success: Keep your libraries up-to-date (or at least know why you are not). Comb through Swift and iOS version release notes. Don’t play with hash values lightly. Goran Svorcan is a full-time iOS engineer on the Games Team at The New York Times and a part-time horror movie enthusiast. How we design and build digital products at The New York Times 68 1 iOS Software Development Apps App Development Code 68 claps 68 1 Written by How we design and build digital products at The New York Times. Written by How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-10-24"},
{"website": "NewYork-Times", "title": "to design better products consider the language", "author": ["n.k. feinberg"], "link": "https://open.nytimes.com/to-design-better-products-consider-the-language-f17b923f8bae", "abstract": "Code Data Product and Design Workplace Culture Work with Us Picture this: your company has been working on a big project for months, or possibly years. Development is nearly complete, which means it’s time to add the copy. However, when you go to do this, you find that the text doesn’t quite fit in with the product. All too often, we think of the words in an app or website as separate and we only consider them at the end of the product development process. This can lead to language that’s inaccurate, ineffective or ill-suited to the overall experience. We don’t have to work this way; In fact, my design team at The New York Times has found that we create better products when we incorporate writing into our processes. Having spent over six years at The Times as a technical writer, a UX writer and now a product designer, I’ve come to believe that language is one of the most powerful design tools we have. I spent 2017 and 2018 embedded in a cross-functional team that was tasked with building a new account page for our subscribers and readers, who are located around the world and have very different needs. Initially, we approached copy in a fairly siloed way. When I saw that a design file called for a title, I wrote one. When an engineer requested a message for an error state, I provided one. Over time, I recognized that we could create better work (and do it more efficiently) if we rethought our process. Rather than rely on lorem ipsum placeholder text, I began to draft titles, links and other messages as soon as we started work on a page or feature. This helped our small product and design team evaluate whether we were using the right components to deliver the right messages. We often found that a problem we thought could be solved with an informational message actually required more significant revisions to the structure of the feature or page. I discovered that we were able to create a stronger and more deliberate product when we considered the words we used. These days, I split my time between multiple projects, which means I need to be more thoughtful about how I work with different groups. I’ve developed some strategies to help colleagues think about language earlier, more collaboratively and with more flexibility. The earlier you consider language, the better. At the beginning of a project, the team is usually trying to understand and align on the problem that they’re tasked with solving. This may be a chance to consider who your users are and ask some of the following questions about them: Why might they use your product and what are their goals? How might they feel at the beginning of their interaction? How do you want them to feel at the end of the interaction? How might they want to be spoken to? Thinking through questions like these can help you strike the right tone in your work. At The Times, this often means balancing our brand with user needs in a particular moment. As soon as your team has gotten to a place where you’re exploring design ideas, it’s worth including text in your mocks. This language doesn’t need to be polished; it’s there to help you identify what to say and the best way to say it. Think back to the questions you asked about your users and try to identify what you need to make clear to them in order to meet their needs. Once you have a general sense of this, you can start to fine-tune your word choices. If your team has regular design reviews or check-ins, these can be great venues for feedback. However, it can also be useful to have dedicated time to work through specific messaging problems. Here are some exercises that I’ve found helpful, depending on the situation: If you’re working through how to phrase a specific statement, try writing out every possible piece of information you could provide. Then, prioritize what’s most important to provide in the moment. This can be particularly effective for error messages or other instances where you need to deliver bad news. If you’re working on figuring out where in your interface to include specific information, try assembling a low-fidelity version with blank areas for language. Gather teammates or stakeholders together in a room and ask them to “fill in the blanks” in response to specific prompts. I’ve suggested drafting copy that addresses only the user need or only the business goal in order to eventually arrive at a hybrid, but you can get creative here. The point is to encourage participants to think critically about what needs to be said, and how. If you’re working to refine your tone across an experience, try printing out different messages and highlighting language that feels on or off-brand. By doing this, you can get a better sense of how you want to communicate with your users. This is also a good way to evaluate what might need to change depending on how you’re messaging users, whether via email, a pop-up or other channel. You’re likely to have gotten to a pretty good place by workshopping your content with your coworkers, but now it’s time to test out words with actual users. At The Times, we conduct regular user research and usability studies. These are opportunities for us to assess what resonates with our users and what’s confusing for them. By paying attention to their reactions, we can feel more confident in our decisions or make updates as needed. Research is a great time to evaluate the names and labels you’ve chosen for areas of your product, and to assess the instruction you’re providing to guide users. If participants don’t understand what a certain term means, or if they race through a series of screens without stopping to read necessary text, you may need to rethink the experience. If you’ve been considering, workshopping and testing your content, you’ve probably come to some conclusions about the tone you want to strike and the words you want to use. I’d suggest documenting your decisions — for yourself, for your teammates and for anyone who might find themselves working on this or a related experience. By approaching words as vital elements of digital products, and by encouraging the people we work with to do the same, we can create experiences that are more empathetic, more inclusive and ultimately more effective. Nina Feinberg is a senior product designer at The New York Times. How we design and build digital products at The New York Times 520 1 UX Copywriting Usability Design Product Design 520 claps 520 1 Written by How we design and build digital products at The New York Times. Written by How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-10-11"},
{"website": "NewYork-Times", "title": "how we built nyt parenting", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/how-we-built-nyt-parenting-341f0acf0d2", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Taylor Poulos, Youngna Park and Juliette Melton “The Health of Children — A Seasonable Warning” reads the title of the childcare section of The Housekeeper’s Column that appeared in the pages of The New York Times on November 7, 1875. The temperature had been fluctuating that year, so the column advised readers to dress their children according to the weather and clothe “them comfortably, to cover the little legs, not only with stockings and gaiters, but with skirts which will hang as near to the ground as may be without impeding the little feet.” Though it might seem quaint today, the advice was one of the first instances of parenting coverage from The Times. Over the last 144 years, both the job of parenting and The Times’s advice about parenting have changed dramatically. A few months ago we launched NYT Parenting , a stand-alone product that aims to provide trustworthy guidance to new and expectant parents, so they can make choices for their families with confidence. To get to this point, it took a cross-disciplinary team months of research, design and iteration. Here’s a little bit of what we learned along the way. The first step in our product discovery process was to understand what real parents actually want and need. To do this, we did in-home interviews with a dozen parents representing a variety of family structures, parental roles and geographies; the families had different numbers of children, all of different ages. Through our conversations, we heard that those expecting children or with very young children often felt the most overwhelmed, reaching out to Google, family, friends and other resources for answers. When they did, they had a few common challenges they felt current parenting products didn’t adequately address. Other parenting resources primarily focus on child needs and often ignore the needs of the parent. Parenting isn’t just about child-rearing, it’s also about a transformation in relationships, bodies and identity. Finding answers can be overwhelming. There are lots of parenting resources on the internet, but many are unreliable, contradictory or judgemental. It’s hard to know who to trust. The learning curve can be steep. Especially with first-time parents, there’s a lot to learn and it can be difficult to know where to start. Through our discovery process, we identified an opportunity to be a digital parenting destination that provides trustworthy guidance on the daily challenges of modern parenting. We developed an initial hypothesis: if we leveraged The Times’s rigorous reporting and editing standards — and our access to industry experts — we could build a product that offered this guidance is an accessible, synthesized and time-saving way. Our ideation culminated in a clickable prototype, created with a hybrid of a custom-built CMS and an interface built in InVision.The prototype included drafts of content, written by Times editorial staff. Working with The Times’s in-house research group, we recruited over 50 new and expecting parents into a diary study, which is a method of user research where participants self-report behaviors, emotions and preferences over a specified period of time. The participants in our study used our prototype over the course of a week, and responded to prompts that asked them to assess the usefulness and functionality of the prototype. We subsequently selected seven participants and conducted in-depth, one-on-one conversations with them to dig even deeper into their experience with the prototype. In our conversations, we heard that we were hitting the right notes for topics, breadth and depth of content, but we could simplify the UX, clarify the hierarchy of information on the homescreen, and improve the design of the landing pages. In the concepts and prototypes that were part of our initial research, we segmented content by type, like guides, articles, essays and milestones. Separating each section by type made sense to our team: if each content type serves a different user need, they should be in different parts of the site, right? Wrong! Our users didn’t notice, or particularly care, that the content was presented in different formats. What they did care about, though, was the content itself, and the topics that were covered. We realized that we needed a better way to organize everything. That realization brought us to our next phase of research. We first compiled a huge list of topics — including everything from how to choose baby names to mental health — that our product could potentially address. We knew that the next step was to develop a human-centered way to organize it all. We wrote these topics on note cards and, using a research technique known as card sorting, asked several parents to classify them in whatever way made sense to them. Our participants organized the information in remarkably consistent ways. For the most part, they sorted child-focused topics into relevant stages, like newborn, toddler and adolescent. We included many topics — such as family life and relationships — that didn’t fit into stage-based categories, and participants tended to group these topics together. We asked them to name this batch, and they came up with a few labels, including “Love and Life” and “Adulting.” Their creative groupings helped us shape how we thought about this content, which we were betting would be a core differentiator for our product from what already existed in the market. This insight — that information should be organized into either a child’s developmental stage or into the yet-unnamed “Adulting” category — helped us build a robust content taxonomy of over 50 topics and subtopics. While establishing how to structure content and topics in the product, we also invested in developing the site’s visual language. We knew that we needed to build on The Times’s brand equity while making our product feel distinct and premium, much like Cooking and Crosswords We did this primarily through choices around color and type, as well as defining our own style for art direction. We wanted a primary product color that could stand on its own, but also live as part of the Times family in the same way that NYT Cooking’s red does. We picked a shade of green for its warmth, associations with growth and gender neutrality, and then complemented it with an orange-red and shades of gray. We also established our brand through type and drew from The Times’s broad custom type palette. We picked NYT Karnak Condensed for our headline font, complemented by Cheltenham, Imperial and Franklin. This mixture of typefaces gives us a large dynamic range to pull from, and visually aligns us with the rest of The Times’s core products. In early May, we launched parenting.nytimes.com in beta. Our goals for this early version were to validate that our content was valuable to new and expectant parents, to gain a signal on people’s willingness to pay for this content, and to solicit feedback around what could make the site even more useful to our audience. We’ve been live for four months and the initial feedback has been incredibly positive. Over this time, we have conducted multiple surveys of our beta audience and have begun analyzing how users behave on the Parenting site. We will continue to learn about how we can address our users’ greatest needs, and how we can evolve the product to make it even more valuable for parents and parents-to-be. Colleagues from Research, Editorial, Product, Design, Engineering, Marketing and Content Strategy were partners at every stage of moving the product from zero to one. The team arrived at the product vision together, and we’re constantly finding new ways to work more closely together. As a brand new group building something inside of an existing organization, we get so much value out of being a part of The New York Times, in our design, editorial process and tech stack. But to remain agile, sometimes it was necessary to create our own solutions. What do you think? We’re always open to feedback. Check out our beta and send us feedback . Taylor Poulos is a digital product designer on Parenting at The New York Times. Youngna Park is the executive product director for Parenting at The New York Times. Juliette Melton is the director of design research for New Products and Ventures at The New York Times. How we design and build digital products at The New York Times 128 1 UX Product Branding Design Design Thinking 128 claps 128 1 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-09-18"},
{"website": "NewYork-Times", "title": "to build 5g enabled technology for times photojournalists we studied how they work", "author": ["Jimmy Chion"], "link": "https://open.nytimes.com/to-build-5g-enabled-technology-for-times-photojournalists-we-studied-how-they-work-99f7298ca587", "abstract": "Code Data Product and Design Workplace Culture Work with Us We’ve all felt the frustration of trying to post a photo or video to social media from a crowded event. When thousands of people are sharing the same cell networks, even a photo with a relatively small file size can take a while, or not upload at all. For New York Times photojournalists who are tasked with transmitting significantly higher resolution photos (with much larger file sizes) on a deadline, slow uploads are not an option. Seven years ago, The Times developed the ability to live-stream photo thumbnails from the field to our newsroom editors, who could then select which photos they’d like to receive from the photographer’s camera in full. This system is powered by a small computer, a cellular router for internet connectivity and a cellular multiplexer, which can combine the power of multiple internet and cellular data connections to send photos. (You can read more about this system, called the Backpack, in our last post .) This year, The Times’s 5G Journalism Lab has been exploring how increased speed and bandwidth could unlock new storytelling capabilities for our newsroom. As part of our research, we dug into the workflows and needs of the photojournalists we work with to explore how we might leverage advancements in media transmission technology to make the Backpack an even better tool for our newsroom. To learn about how the Backpack might be improved, I interviewed over a dozen Times photographers, editors, photo technologists and archivists. Of the key takeaways from this research, here are the major concerns that we felt we could immediately start working to address: A typical process for sending photos is pretty straightforward. In a nutshell: a photographer shoots a lot of photos and at natural breaks in time, somebody — sometimes an assistant, if the photographer has to keep shooting — takes the full memory card to a room where they’ll download those photos to a computer, select the best shots and send them to the newsroom. Many of the photojournalists I interviewed described difficulties uploading photos to newsroom servers using their own laptops over WiFi: poor connectivity, slow upload speeds and failed file transfers are frequent issues. When sending a day’s worth of photos over WiFi or a mobile hotspot, freelance photographer Adam Dean told me, “it’s not uncommon to get an email that says, ‘Received, but you need to resend.’ When you’ve been up for 20 hours, the last thing you want is trouble. You just want a smooth way of filing.” Sending photos faster and more reliably is something the Backpack has helped solve. But the Backpack is large and it can easily overheat or its wires can get tangled, which can be burdensome and complicated compared to a photographer’s usual workflow. As a result, many photographers use the Backpack only when the story they’re covering requires extreme speed or greater bandwidth. Staff photographer Doug Mills, for example, has used it at bigger events, like the State of the Union and the Inauguration, when area WiFi has too many users to reliably transfer photos. The photo editors and archivists I interviewed said that with or without the Backpack, many photos our photojournalists capture don’t end up on our servers. Photos that aren’t hand picked by photographers or photo editors may be left abandoned on SD cards, or scattered across personal hard drives. This represents a significant loss of potentially important material, like photos that we might not consider important at the time of capture, but might later like to access or publish. To start targeting the issues identified in my research, I prototyped an updated photo transmission Backpack with new hardware and software capabilities. To test how it might perform in field conditions, my colleague Niko Koppel and I met up with freelance photographer Christian Hansen while he was on assignment photographing this year’s Kentucky Derby in Louisville, KY. The Times was publishing live updates about The Derby online, and having photos to match the incoming updates was critical to sharing the story as it happened. Christian captured the event with his camera plugged into our new Backpack prototype. As the day progressed, the Backpack automatically sent the photos in their original, full-size formats to the newsroom as they were captured. This was the first time we’ve automatically sent photos of this size and fidelity to our newsroom in real time. Niko and I monitored Christian’s photo stream from the media room, allowing us to maintain visibility over all the photos coming in and flag any issues to Christian proactively. Coverage of an event like the Kentucky Derby is often predictable: a photographer can typically expect to take pictures of fantastic hats, sprinting horses and a triumphant jockey in the winner’s circle. But this year’s race was different. Over 22 minutes after the horses had crossed the finish line, it still wasn’t clear who had won . The deadline to get a photo of the winner into the next day’s paper was soon approaching. After reviewing video of the final moments of the race, the officials declared that Maximum Security, the horse that finished first, had committed an illegal interference in the final stretch of the race by jumping a puddle and nearly knocking into another horse and rider. Maximum Security would be demoted to 17th place, with victory awarded to the second place finisher, Country House. It marked the first time in the race’s 145 year history that the first place finisher was disqualified for interference. As all of this unfolded, Christian, equipped with our prototype, was already in the Winner’s Circle documenting Country House and his jockey Flavien Prat. According to the assignment editor, Christian’s photos got to the newsroom about 20 minutes ahead of any image from the wire services. This enabled our newsroom to publish high definition photos of the developing story online instantly — well before any other publication — and file with our printing services for the next day’s paper just minutes before the submission deadline. The success of our trial was a surprise: we hadn’t dreamed that our prototype test would yield this kind of advantage at the event. Still, running this trial in a news situation, in which we were competing for bandwidth over a high-traffic network on a deadline, helped us identify some ways we might iterate on our creation: The first issue that became apparent was our Backpack prototype’s size and shape. After upgrading the system with smaller hardware components, we built our current prototype into a durable plastic case that holds a built-in monitor and keyboard so we could troubleshoot on the spot. We knew this wouldn’t be the most comfortable container to carry, but watching Christian struggle with the case — switching it from shoulder to shoulder every 30 minutes because of discomfort — was enough to inspire us to start sketching new ideas on site. While Christian was shooting with the Backpack, the device’s computer memory filled up unexpectedly, which was a result of many weeks of testing without clearing out the drive. This caused a transmission backlog, which stopped image transmission to the newsroom. We diagnosed this problem quickly, but it took 30 minutes to debug the software and get the process running again. Before this field test, we had been reliably testing our prototype over our 5G Lab’s fiber-powered WiFi, but when we arrived at the Derby, we found that the highly trafficked 4G LTE network’s file transfer rate was extremely limited. Even with the Backpack’s ability to combine many cell connections, 29 of the 2,000 photos Christian captured did not come through. Thankfully, our system still live-transmitted most of the photos, including an image of the winner. But this intermittent connection shows that one of our goals for the Backpack — real-time RAW file transfer for every image a photographer takes from the field — will be achieved more reliably over expected 5G upload speeds or a very fast WiFi connection. We’re taking what we learned from these lessons to improve the next iteration of the system. Our goal is to make the backpack more accessible and helpful to every photojournalist in our newsroom. Based on what we’ve learned, this means it should be more comfortable, powerful, organized, easy to use and inexpensive to reproduce. In time, this might mean that the hardware component is as simple as a 5G phone. Until then, we’re working hard to improve what we have. And we’re working with the newsroom to imagine where this technology might take us. Jimmy Chion is a Creative Technologist with the 5G Lab at The New York Times. How we design and build digital products at The New York Times 126 5g Photojournalism Innovation User Research Design 126 claps 126 Written by Creative technologist @ NYTimes. Creator of ballot.fyi. Formerly @IDEO, @Stanford How we design and build digital products at The New York Times. Written by Creative technologist @ NYTimes. Creator of ballot.fyi. Formerly @IDEO, @Stanford How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-06-27"},
{"website": "NewYork-Times", "title": "were helping times photojournalists deliver images to the world faster", "author": ["Jimmy Chion"], "link": "https://open.nytimes.com/were-helping-times-photojournalists-deliver-images-to-the-world-faster-2d04dea5acd0", "abstract": "Code Data Product and Design Workplace Culture Work with Us A mobile 5G-enabled system could allow us to send raw, high-resolution photos from a camera to the cloud almost instantaneously. When New York Times photographer Doug Mills covered the State of the Union address in February of this year, he took 1,000 photos in under an hour. On the whole, Times photographers will capture anywhere between hundreds and thousands of photos for a given event. Taking tons of photos is part of the job: sometimes photographers need to shoot a lot to get that one perfect image. But once the event is over, getting those photos from the field to The Times newsroom is tedious and time consuming — two things journalists like to avoid during live news situations. Typically, once a photographer is done shooting, they will go to their laptop and transfer the images from their camera. From there, they’ll select just a handful to crop and tone, add captions and upload the selected photos to the newsroom’s servers. This process takes time, which is a problem for things like sports events or natural disasters that we cover live. Over the last few years, we’ve experimented with ways that leverage mobile internet technology to transmit our photos and get the story to our readers faster. In 2012, Josh Haner, a Pulitzer Prize-winning photographer and senior editor at The Times developed a tool that automatically sends thumbnails of Times photographers’ photos to the newsroom as the photos are captured. Haner worked with The Times’s Interactive News team to build the device, called the “ remote streaming photo backpack ” (later, just “the Backpack”). The system fits together a computer, a cellular router for internet connectivity and a cellular multiplexer, which can send data across several cell networks at once. The multiplexer can also combine the throughput power of multiple internet connections, like wifi, ethernet, 3G and 4G. As the photo thumbnails are transmitted live to the newsroom, photo editors in New York are able to review the thumbnail feed and selectively download high-resolution JPEG versions for publication. The Backpack has been a powerful tool for our reporting, enabling a new capability of real-time photo coverage of events — from protests and debates to red carpets and sports . It also frequently helps us publish photos online minutes before our competitors, and sometimes a full day ahead in print. Beyond being much faster, the Backpack’s amalgamated connectivity allows it to work well even when bandwidth is limited. When the power went out at the Super Bowl in 2013 , for example, The Times was one of the few media companies to get photos out of the stadium. Over the last couple of months, The Times’s 5G Journalism Lab has been exploring how higher and faster bandwidth could enable new ways for us to tell stories, and for our readers to experience them. As part of our research, we’ve taken on the work of improving the Backpack and pushing its capabilities forward. Our goal is to rebuild the technology to make it faster, smaller and adaptable to more types of media and new devices. Before we built anything, we needed to understand what our photographers’ workflow looks like in different situations. I interviewed staff photographers and freelancers who have had connectivity problems while on the job in places like war zones in Syria, villages destroyed by earthquakes and the middle of Times Square on New Year’s Eve. To get a deeper look, I shadowed Doug Mills, The Times’ White House photographer and frequent user of the Backpack, to learn about The Times’s photo workflow and the rhythm of a typical photo assignment. Observing Mills and interviewing his colleagues gave us the understanding needed to start building something that could actually be used. Our latest take on the Backpack, pictured below, has many of the same features as its predecessor, but we’ve updated the components to make the transmission of data faster and to reduce power consumption. We also plan to significantly reduce its size. For now, though, it’s most important to be able to troubleshoot our prototype on the spot, so we built this first version into a portable workstation that includes a built-in screen. Here are some of the upgrades that we’re most excited about: Transmission of full RAW images: The old Backpack would compress and downsize images before automatically transmitting them back to the newsroom. In the new version, we’re automatically sending every full uncompressed RAW image to newsroom servers at the moment the photo is taken. This will ensure that every photo is stored on our servers, equipping our editors with a robust repository of tagged photos for future use. USB tethering: Because the old system used an ethernet cable, it could only connect to DSLR cameras. The new version allows USB devices to be connected, which dramatically expands the type of media it can transmit. This opens up the possibility of using formats with massive file sizes and long production times — like 360-degree video and 3D volumetric content — in breaking news situations. 5G ready: The new version is built to connect to 5G networks once they roll out. The mobile 5G standard claims it will enable us to send high-quality 40MB RAW photos in under a second (an expected order-of-magnitude improvement). This would significantly enhance our ability to cover live events. The Backpack’s new hardware, firmware and server setup have proven to work well together in our lab tests, but reporting from the field presents unpredictable challenges. To test the new Backpack’s performance in a live news situation, we recently handed it off to photographer Christian Hansen while he was out on assignment to cover the Kentucky Derby for The Times. We’ll share what we learned in our next post. Jimmy Chion is a Creative Technologist with the 5G Lab at The New York Times. How we design and build digital products at The New York Times 205 1 Journalism Photojournalism Innovation 5g Code 205 claps 205 1 Written by Creative technologist @ NYTimes. Creator of ballot.fyi. Formerly @IDEO, @Stanford How we design and build digital products at The New York Times. Written by Creative technologist @ NYTimes. Creator of ballot.fyi. Formerly @IDEO, @Stanford How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-11-01"},
{"website": "NewYork-Times", "title": "innovation and experimentation 3 projects from the new york timess maker day", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/innovation-and-experimentation-3-projects-from-the-new-york-timess-maker-day-23e3b0923209", "abstract": "Code Data Product and Design Workplace Culture Work with Us A few times every year, a large group of New York Times employees participate in our Maker events, where they take a break from their normal jobs to work on self-directed projects and participate in workshops. These are Technology-sponsored events that provide the opportunity for many departments (including Data, Product and Design) to dedicate time to innovation, collaboration and learning. Maker events are intended to be meeting-free to give time for participants to explore new ideas and collaborate with people they don’t normally work with. Sometimes participants take the time to address an item on their to-do list, or they build prototypes that explore design solutions for a specific problem. Sometimes participants take a break from their computers to create physical objects, like the Arduino project below or last year’s newspaper upcycling project . What our Times colleagues work on is up to them. We asked a couple of our colleagues to share what they worked on at our last Maker event. Here’s what they said. By JP Robinson For several years, Times developers published and shared specifications for our internal APIs on a hacked implementation of a LucyBot documentation site. The site had a Rube Goldberg-like architecture for updating those specs, which included a service running on App Engine Flexible that used Cloud Endpoints and API keys for authentication. When the APIs were updated, the service would check out the current specs from a GitHub repo, alter them and push them back to the repo. This kicked off a GitHub webhook to call a Google Cloud Function in a separate Google project that would attempt to restart the service hosting the docs. The hope was that an embedded git submodule would have updated with the updated spec. This last service relied on Google’s Identity-Aware Proxy to authenticate users. Not surprisingly, this rarely worked as expected and was not a sustainable solution. I spent Maker Day adding some sanity to the project. It now runs in a single App Engine Standard service using Google Cloud Storage for persistence, and Google sign in and instance identities for authentication. Instead of LucyBot, the UI is a simple index page that lists the available docs and has a second page built with Swagger UI to visualize the documentation. Instead of taking 10–15 minutes for API docs to possibly be updated, the updates now reliably appear instantaneously. By Alice Liang and Ryan Lakritz In our non-Maker Day work, we work in the Data team to build machine learning models for different parts of The Times’s subscription business. In one of these models, we have a specific parameter that our marketing partners can change. One day, we joked that it would be funny if we had a physical knob that could take in such a value. We have been known to take jokes quite far, so we decided to make an Arduino device to do just that. As part of Maker Day, other coworkers held a “Making Things with Arduino” workshop that we took. The workshop was crucial in helping us to set up the device, connect it to the code we wrote, and power it. We spent most of the day connecting the wires to our breadboard and Arduino between our Panel Mount 10K potentiometer, a 16x2 LCD screen and a red on-off button. We wrote some Arduino code based on C — the basics of which we learned on the spot — to detect any changes from our potentiometer. The code would output the changed value to the LCD screen and prompt the user to send the selected value if they were ready. Finally, we wrote code to save the given value when the red button was toggled on. Then, we turned to Python, which we more regularly code in, to read in that value given a connection to the Arduino port. The Python code pushed the value to Google Cloud Storage, where it could be incorporated into our model — this is all hypothetical, of course. The Arduino now sits on our desks and, while it’s not a device in regular use, it has served as a mascot to the model. The Arduino has garnered a lot of excitement from our colleagues in the subscription growth business and has been a surprisingly helpful tool when discussing the complex statistical components of the model. We enjoyed getting away from debugging our modeling code and into a hands-on hardware project for a day. Who knows what new jokes we’ll take on next for Maker Week. By Bill French At The New York Times, we’re constantly looking for novel ways to increase readership and engagement. For Maker Day this year, I started with a thought: what if readers could listen to audio versions of all Times stories? This, of course, raises a few questions: how would the recordings be produced? Would we hire voice actors to do the reading? Would such a feature help persuade occasional readers to become subscribers? Recent advances in speech synthesis offer an answer to these questions. Google Cloud Platform has unveiled a new set of WaveNet voices, accessible via its Text-to-Speech API, that provide more natural sounding synthesized speech than the monotonous, tinny, robotic tones that we all often endure. By taking advantage of the API, I was able to write a simple Node web service that converts article body text into an equivalent spoken word audio file The audio can then be embedded as an MP3 asset on a web page and listened to from within a web browser. The function tasked with synthesizing speech takes both raw text and speech synthesis markup language, or SSML, as input. The latter provides explicit instructions for things like how to pronounce certain words, where to insert pauses, and what to ignore so the readout sounds realistic. Writing SSML is labor-intensive and doesn’t immediately fit into existing work streams here, so it raises more questions: who would be responsible for this markup? Would this become a new step in the editorial process? Will speech synthesis reach a high enough quality that we’ll be willing to accept the occasional mispronunciation in exchange for audio? My hunch is mispronunciations would be considered as undesirable as typos; not showstoppers, but still best to be avoided. The Text-to-Speech API has also revealed itself to be a quick study. In late March, before Mueller Report speculation had monopolized all media outlets, the synthesis engine incorrectly pronounced “Mueller” as MYOO-ler in its renderings of articles about the special counsel. By early April, the stress and vowel articulation had changed to the true pronunciation of Robert Mueller’s last name: MUH-ler . It’s clear this technology will soon be ready for primetime, and that we should be thoroughly exploring it now. This summer, when Maker Week rolls around, I’ll continue developing the Story Player, building an interface that allows users to create daily, individualized article playlists. If working in a mission-driven environment, with an emphasis on work-life balance and comprehensive parental leave sounds good to you. Come work with us .We’re hiring. How we design and build digital products at The New York Times 72 Work Workplace Culture Design Innovation Makers 72 claps 72 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-06-06"},
{"website": "NewYork-Times", "title": "we all experience imposter syndrome this is how a new york times data analyst overcame it", "author": ["Storm Hurwitz"], "link": "https://open.nytimes.com/we-all-experience-imposter-syndrome-this-is-how-a-new-york-times-data-analyst-overcame-it-e637f21b39aa", "abstract": "Code Data Product and Design Workplace Culture Work with Us During my senior year of high school, I stood in a row doing a kickline in heels while playing the Emcee in Cabaret. Now, I navigate stitching together and analyzing billions of rows of data using SQL and Python. The way my past life has informed my present life is what makes me strong, but it has taken me some time to realize this. While working on my first project at The New York Times, I opened up Google BigQuery — the tool we use to access our data — to see that one of the tables I was working with had billions of rows of data. Billions. Surrounded by my brilliant teammates, many of whom received technical educations, I felt like a fraud. Five years ago, I was pursuing a degree in musical theater; am I even qualified to be doing these analyses? The truth is, as a graduate of The New School with a couple years of data analysis work under my belt, I am qualified. To get my job with The Times, I passed the SQL and logic tests that are a part of the screening process for all new Data & Insights hires. My managers were giving me projects because they, as they assured me, knew I could do the work. Yet, I was still overcome with doubt. Nine months into my career at The Times, I can look back at those early days and see that my persistent self-doubt over my legitimacy in the workplace was imposter syndrome. And I know that I’m not alone in my experience. It is estimated that 70 percent of people will experience impostor syndrome at least once in their lives. It took me some time to build up my self-confidence. I implemented two strategies to help me overcome my feelings of inadequacy: self-reflection and vulnerability. Growing up, I was a complete musical theater geek and I followed the traditional path to pursue a performance career. I worked off-Broadway (or off-off-Broadway, depending on whom you ask) when I was 16-years-old and then attended an arts boarding school for my last two years of high school. Afterwards, I went to a conservatory. By using this prescribed formula to reach success as an actor, it was easy for me to feel like any success I might achieve in the future would be well-deserved; I had done what everyone expected me to do in order to be cast on Broadway. Then things changed. Already dissatisfied with the lack of rigorous academic studies at the conservatory, I decided to leave when I encountered administrative challenges. I left the school that week. From there, life became one big exploration. For the first time, I was confronted with no clear path forward. I took college classes and did five internships. My first job was at The LGBT Center of NYC, a non-profit, creating health campaigns and then I worked at an advertising agency doing analytics. My friends and advisors often asked me what I was doing with my life, as they sought to interpret where I was headed given my career choices. I kept pushing those external doubts to the back of my mind. However, soon after starting at The Times I realized that the outside sentiment had caught up to me. Every day I left work deeply questioning my ability to succeed. In a last-ditch effort to build self-confidence, I tried mapping out my path chronologically to see if I could unearth a pattern behind my choices. I wrote out what I had done each semester of college, and my internships, career moves and professional development choices. Upon deep reflection, it became clear: where others may have seen a lack of clarity, I saw that there were always intentions behind my choices. While my path might seem jagged, I was able to try new things and dig into what I liked and avoid what I did not like. I learned a lot about myself, and I applied that knowledge to my career decisions. By writing down and interpreting my career moves, I realized I had implemented a test and learn strategy to career development. That strategy is core to my analytical passion: to test, learn and optimize in creative ways that help further knowledge about how things work and what drives change. Taking time to reflect on my past and how it led to my present was key in helping me cope with feelings of inadequacy. With a better understanding of myself, I felt less like an imposter but I still felt alone. In moments like this, I always search for solidarity with the people around me. I wanted to know whether my colleagues also struggled with feeling inadequate. So, I contacted The Times’s internal LGBTQ+ Employee Resource Group, Times Out, knowing that the odds of being able to relate to a fellow LGBTQ+ identifying person were greater than a randomly selected Timesperson. After many coffee chats with Times Out members, one theme emerged: every person I spoke with had experienced impostor syndrome. Further, many of them shared that these feelings returned at different stages throughout their careers. They told me that it is not about overcoming impostor syndrome, but learning how to manage it. One colleague suggested I spend an hour every week writing down everything I had accomplished that week no matter how big or small the task. I started setting aside time on Fridays and called these notes my Weekly Snippets. Documenting my weekly wins — no matter how small the project — helps me see the value I add to my team and also enables me to look back over time to see how I have grown. In addition to weekly journaling, my colleague had another suggestion: to tell my manager that I was struggling with imposter syndrome. This was most intimidating. It felt like such a vulnerable step to take and I didn’t know how my manager would react. When I worked up the courage and talked through what I had done to combat the negative feelings, my manager jumped in to tell me they were there to support me and reassured me of my value on the team. And then, something clicked. I looked around and realized my public vulnerability enabled me to have more clarity in knowing how people perceived me, both as an employee and a person. Instead of being afraid that I was alone in feeling like an imposter, I now could openly bring it up during one-on-one conversations. My vulnerability, rooted in self-reflection, normalized the experience for me and I feel more comfortable turning to others for support when I need it. Of course, this doesn’t mean I’ll never feel inadequate again, but I now have tools to help manage feelings of being an imposter. While everyone has unique and individual experiences of imposter syndrome, here are some of the strategies that worked for me. Create a list of your educational and career moves. This could include anything from educational experiences, internships, volunteer work, career moves, professional development or anything else you find meaningful. Take that list and spend time journaling about what you liked and did not like at each of those junctures. Look for common themes across your experiences. How did they lead you to what you’re doing today? Begin doing your own weekly snippets. On the last day of your workweek, spend some time listing out everything you accomplished that week — no matter how big or small — and everything you are currently working on. After you finish filling in the details for the current week, spend time reflecting on your week and the prior weeks. Reward yourself for the work you did. Talk to colleagues. Set up time to meet one-on-one with people in your workplace you feel comfortable sharing your experience with and ask for their advice. Communicate up. If you can, let your manager(s) know you are experiencing impostor syndrome. You may be surprised at how they respond. Stay humble. Remember you’re not alone. Take time to reflect on the path that led you to where you are today: remember you successfully attained your job and you’re there for a reason. Impostor syndrome may show up at different times throughout your career, but it’s important to develop tools to cope with it. I hope these tips help, and if you have other tools, feel free to share them in the comments. How we design and build digital products at The New York Times 151 2 Imposter Syndrome Work Work Life Balance Self Care Self Confidence 151 claps 151 2 Written by Data @nytimes | https://www.linkedin.com/in/storm-hurwitz/ How we design and build digital products at The New York Times. Written by Data @nytimes | https://www.linkedin.com/in/storm-hurwitz/ How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-05-15"},
{"website": "NewYork-Times", "title": "to keep track of reddit discussions around new york times content we built a slack bot", "author": ["JP Robinson"], "link": "https://open.nytimes.com/to-keep-track-of-reddit-discussions-around-new-york-times-content-we-built-a-slack-bot-4d9e6484f8dd", "abstract": "Code Data Product and Design Workplace Culture Work with Us Last fall, my colleague James Robinson (no relation) sent me a direct message on Slack. “Hey old friend. Are you free for a quick question?” he wrote, “I’m looking to rebuild an old project and would love your perspective.” In a previous newsroom analytics role at The New York Times, James had built a suite of incredibly interesting tools that happened to run on a finely-tuned Windows PC under his desk in the newsroom. He wanted to talk about rewriting one of those tools and putting it on a server. The project was a tool that checked Reddit for conversations around Times content and alerted the newsroom via a Slack channel. Once our writers and editors knew that a story was being discussed, they could get real-time feedback from the Reddit community and even join the conversation . It is a useful tool and James, now the director of international analytics on the newly-created Audience team at The Times, wanted it rebuilt. Since the process was running locally, it stopped reporting in late 2015 when James changed teams. When I looked at the code, I realized I was not going to be able to reuse anything because it was written in Perl. My plan was to rely on many of Google’s managed services, which don’t support Perl. I decided to rebuild this system during The Times’s quarterly Maker Day using all of the new tooling we have available to us at The Times. To prepare, I started to formulate how everything would fit together. For infrastructure that required minimum maintenance, I decided to use the Google App Engine standard environment and a basic scheduled cron to kick off a process every couple of minutes. From there, the rest of the system would look something like this: App Engine cron job will hit our service to kick off the process. The service will grab the top 300 nytimes.com links shared to reddit via their JSON endpoint . The service will use Google Cloud Datastore to store comment counts to determine what to alert and what has already been alerted. The service will use NYT’s internal GraphQL Sangria server to fetch additional metadata about the nytimes.com article. The service will post an update to a Slack channel with the real headline, the title of the Reddit post, the subreddit the post occurred in and how many comments currently exist. I wanted to spend most of Maker Day hacking, so I made sure I had everything I needed ahead of time. This included access to James’ Google Cloud project in order to deploy the service but also access credentials for our GraphQL service. We use HashiCorp Vault to share secrets, like API credentials and database passwords, so once my request was made, someone from our GraphQL team just needed to hand me a vault unwrap command . With that command, I was able to securely get the secrets and put them into my own project’s Vault store. At start-up, the application would fetch the credentials via gcp-vault . Once Maker Day arrived, I was ready to hit the ground running. I quickly created a basic endpoint that could scan Reddit for the most commented Times articles. From there, I saved basic information to Cloud Datastore with minimal effort as no schema or set up was required. To fetch article metadata, I needed to build a GraphQL query. With the help of our GraphQL team and their handy interface for exploring our schema, I was able to build a query to fetch only the information needed to post to Slack. Finally, to make sure the Slack messages were easy to read and aesthetically pleasing, I reused code from an old Times project of mine, Newshound . By the end of the day, I was able to hook the service into Drone with our drone-gae plugin and the entire system was ready to automatically deploy on any commit to the master branch. We have plans to add more, but the system is a better state than its prior days on that Windows PC under James’ desk. How we design and build digital products at The New York Times 543 3 Reddit News Technology Work Code 543 claps 543 3 Written by Senior Software Engineer at Datadog. A user of Go. A lover of cats. How we design and build digital products at The New York Times. Written by Senior Software Engineer at Datadog. A user of Go. A lover of cats. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-05-23"},
{"website": "NewYork-Times", "title": "how building a slack bot helped us send news notifications", "author": ["Jeremy Gayed"], "link": "https://open.nytimes.com/how-building-a-slack-bot-helped-us-send-news-notifications-f28c681a5b3b", "abstract": "Code Data Product and Design Workplace Culture Work with Us “ Accuracy, quality and speed, in that order.” That’s the topic for the #notifications Slack channel at The New York Times. This is the channel where we pen push alerts: those notifications that are sent straight to your phone and signal everything from urgent breaking news to long-form feature pieces. We do not take the notification permissions our readers grant us lightly. Every push alert is carefully crafted to be accurate, of high quality and timely. We ensure this with a series of sign-offs and approvals that every alert must go through before it’s sent. Typically, the process looks like this: an alert owner (the person in charge of guiding an alert through the whole vetting process) works with a desk editor to pitch alert language for a piece that was just (or is soon to be) published. At least two people are assigned to read the alert; they are responsible for ensuring the language of the alert embodies the sentiment of the piece. The alert owner is also responsible for specifying the audience that should get the alert. For breaking news, everyone receives an alert, but sometimes we just push an alert to readers in a specific state or region, or on a particular platform, like Apple News. The owner also assigns someone to send the alert once all approvals have been made. Traditionally, the pitch would be made in the #notifications channel and the language would be edited in the channel or in a thread off of the original message. The people assigned to approve the alert would indicate their fact-checking and approval via emoji replies, or by writing out that they had approved along with their initials to signify sign-off. Usually this goes smoothly, but it can quickly become confusing if there’s a lot of back and forth on the language or when there are multiple alerts being pitched at the same time. During last year’s Maker Week , our annual innovation week, we thought about creating a Slack bot to assist the newsroom with this workflow. In just about a week, I had built an interactive Slack bot to codify this workflow and it has since been put to good use by the newsroom. Here’s how it works. To pitch an alert, an alert owner initiates the bot via the /alert Slack slash command, where a dialog allows the owner to enter as much or as little information about the alert as needed. Once this dialog is submitted, the bot creates a new message in the channel with all the details of the alert. This message is kept up to date with any edits or approvals of the latest state of the alert. Action buttons on this message allow anyone to make edits to the alert. Reader and sender roles can be assigned by clicking the “Roles” button. Readers can signal their approval by clicking the “Approve” button. Or, if approval has already been given verbally, this can be indicated by anyone via the “More actions” menu. Along the way, any edits or approvals are signaled by the bot via a thread reply to the original message. This acts as a sort of change log while also indicating what the next step in the workflow is. Once all approvals have been made, the alert is ready to send! After it’s sent, the sender can mark the alert as such. The original message will turn green and collapse in the thread so it does not clutter the main channel. The bot is built in NodeJS using the @slack/client and @slack/interactive-messages npm modules. The bot is a relatively simple Express server deployed to Google App Engine that listens for any commands from the Slack service. The Slack API is surprisingly robust, allowing for fairly comprehensive support for things such as direct messaging people, setting up reminders, acting on emoji reactions and other features that we may take advantage of in the future. One of the key architectural decisions in making this bot was to keep it entirely stateless. That is, the bot is not backed by any database or persistence layer on the backend. When a user clicks on one of the action buttons, Slack provides the original_message as part of the action payload. This object is parsed in order to recreate the state of the alert in memory before applying the desired action for the user. For example, when a user clicks the approve button, the following object is sent to the server: We loop through the list of users in the approvals list of the original_message and if the user is not already in this list, we add them (to a msg object) and then make a web.chat.update() call to update the original message with the new approval. We then also post a thread reply to update everyone on what just changed. Currently the bot is purely informational. That is, it just assists the newsroom with the alert authoring workflow; it does not integrate with our Content Management System (CMS) to pull in any information about the article’s slug, nor does it send the alert. We’ll continue to iterate on this bot to ensure it’s first effectively solving the problem of editing and approving alerts, and then may consider building in further capabilities such as CMS integration. If your company relies on Slack for part of their workflow, consider if augmenting with a bot would help streamline that process. Getting started is easier than you might think and can help multiply the effectiveness of Slack as a tool for your organization. In fact, building a Slack bot can be a lot of fun and if anything, could prove to be a great learning experience. I personally didn’t expect the bot to actually be used by the newsroom, but am so glad to see that the #notifications channel topic now reads: “Accuracy, quality and speed, in that order. /alert to trigger alert bot.” How we design and build digital products at The New York Times 75 Process Slackbot Workflow Work Code 75 claps 75 Written by Coptic Orthodox Christian. Lead Software Engineer @nytimes. Lover of all things JavaScript 🤓 How we design and build digital products at The New York Times. Written by Coptic Orthodox Christian. Lead Software Engineer @nytimes. Lover of all things JavaScript 🤓 How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-04-25"},
{"website": "NewYork-Times", "title": "reducing distractions we dim the android status bar when users are reading", "author": ["Roberto Orgiu"], "link": "https://open.nytimes.com/reducing-distractions-we-dim-the-android-status-bar-when-users-are-reading-55be5cd7fcb", "abstract": "Code Data Product and Design Workplace Culture Work with Us The status bar on Android devices may only take up a fraction of the screen, but it holds one of the most distracting features: notifications. To help reduce the distraction, we introduced a feature that dims the status bar when users are reading. But in Android, figuring out whether a user is reading is not as easy as it seems. As is often the case, seemingly small changes can be the most complex to engineer. To track whether a user is reading, we listened to the scroll event in the components that display articles. Unfortunately, not all the Views in the Android system were built with scrolling capabilities in mind, so we had to add this ability wherever we needed it. In our News Reader, we have two systems that display article content, depending on the type of content: a RecyclerView for native applications and a WebView for hybrid web content. Depending on the Android OS version, certain WebViews do not have a setOnScrollChangedListener , so we created a custom scroll change observer interface ( OnScrollChangedObserver ) that polyfilled the functionality missing from the API. Luckily, RecyclerView support was simple, so all we had to do was extend the RecyclerView.OnScrollListener , which is available right out of the box. But finding a solution for WebView s wasn’t as easy. Because not all Views support the OnScrollChangeObserver we created, we needed a way to distinguish between a View View that supports this listener and one that doesn’t. Some View s don’t support native scrolling, so we had to find a way to see which View s needed the extra support. We had to create another interface that would let us add a reference to the observer so we could attach it to the View and act on it. Every View already listens for scroll events, but since these events are usually consumed inside the View itself, the View needs a little extra help passing events through so they can be managed externally. To accomplish this, we extended the system WebView with a custom View and implemented a ScrollableViewCompat interface. This allowed us to add a listener that the event would notify during a scroll — we did this by overriding the onScrollChange() method. After all of that set up, we’ve come to the most interesting part: wiring it all together so our Views can react to scroll events. We implemented the OnScrollChangedObserver and created two versions of the attachTo() method. The first method type accepts a ScrollableViewCompat parameter in order to get a reference to the attached Activity . The second takes a RecyclerView and AppCompatActivity parameter in which the View is inserted, so that we can add a listener to the RecyclerView and hold a reference to the container. Because we extended RecyclerView ‘s scroll listener, we had to implement two methods that would allow the app to know when a user is scrolling and reading. onScrollChange() will be invoked by the WebView when scrolling, while onScrollChanged() will be called by the RecyclerView . Both methods will then redirect to onScrollingInvoked() , which accepts an Int value. For WebViews, to see whether a user has started scrolling, we check the vertical Y axis. If the Y axis is greater than zero, we pass scrollY to onScrollingInvoked() . In order to achieve the same effect for RecyclerViews, we check whether the first completely visible child (with index zero) is hidden. If it is, we know the user has started scrolling. To see whether a user has scrolled back to the top, both the scrollY and the first completely visible child would be zero. The last part of this puzzle was to determine when to dim the status bar. Whenever the parameter dy that is passed to onScrollingInvoked() is greater than zero, we fade the status bar by setting the View.SYSTEM_UI_FLAG_LOW_PROFILE flag to the system UI. However, whenever the parameter dy is exactly zero, we reset it to the default, which is View.SYSTEM_UI_FLAG_VISIBLE . Configuration changes introduce a glitch: if a user scrolls down and triggers a dim but then rotates their device, the system resets these window flags and the next scroll event will re-trigger a dim. To avoid this glitch, we leveraged the host Activity by saving the flag in the onSaveInstanceState() method and setting it back in the onCreate() . In this way, the configuration change is taken into account and we can finally provide a seamless experience to our users. How we design and build digital products at The New York Times 138 Thanks to Wojciech Dziemianczyk . Android Code Technology UX Apps 138 claps 138 Written by Android developer and GDE for Android How we design and build digital products at The New York Times. Written by Android developer and GDE for Android How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-05-15"},
{"website": "NewYork-Times", "title": "what if child care were as standard as coffee at tech conferences", "author": ["Natalya"], "link": "https://open.nytimes.com/what-if-child-care-were-as-standard-as-coffee-at-tech-conferences-568c5fba028e", "abstract": "Code Data Product and Design Workplace Culture Work with Us I almost gave a conference talk while holding my baby. It was a moment so absurd that if it were a plot point in a movie, I would have called it sloppy writing. “This is just too obvious,” I would have laughed. “That kind of bad timing would never happen in real life.” But, I guess that’s the thing about real life: even the best-laid plans can fall apart. I had been invited to speak at ScotlandCSS about the technical details of implementing CSS Grid on The New York Times’s Watching app. This wouldn’t be my first time traveling to a tech conference as a speaker, but it would be the first time as a primary caregiver. I felt confident traveling alone, but completely overwhelmed by the extra logistics of bringing an 8-month-old along. I couldn’t leave her at home, but even though the conference had child care, I had no idea how to manage bringing her and still do my job as a speaker. It felt like my only option was to stay home and decline the invitation, but when my husband heard this, he said he’d rearrange his schedule so he could come with me. If I were a single parent or did not have a supportive partner who could work remotely, this story would have already ended, as it does for so many primary caregivers in tech. Instead, we bought an extra plane ticket and figured we would tackle this conference the same way we tackle co-parenting: like a team. The conference was wonderful. There was a particularly pleasant moment during a break: attendees were drinking coffee or tea and talking in a lounge area. I had just returned from breastfeeding, so I grabbed myself a cup of coffee and joined a conversation. In that moment, I still couldn’t believe that I was getting to talk tech and participate fully while holding my daughter, who was playing with my conference badge. I thought about how much planning and coordination it took for my husband and me to make that perfect moment happen. I was taking an extra minute to enjoy it. With the break nearing its end, it was time for me to clip the mic to my blouse and head to the stage to present my talk. All I had to do was walk over to my husband, who was working on his computer, and hand him our happy wide-eyed little baby. At the precise moment I approached him, he got a call from work about a critical issue that needed his attention and he had to deal with it immediately. Like I said, it felt like sloppy writing in a bad movie. With my husband unable to watch our daughter, I didn’t know what to do. Instead of panicking, I took a breath and remembered that Peter Aitken, who runs ScotlandCSS, worked with a corporate sponsor to provide child care at the venue. I am embarrassed to admit that although I had signed up, I hadn’t taken advantage of it that morning because I still couldn’t believe it: quality child care for all attendees? I felt like there had to be a catch. But there wasn’t, and what happened next still feels like magic. My husband took our daughter downstairs to a room full of toys and was able to keep working while professional caretakers watched her. Meanwhile, I was able to head straight to the stage and deliver my talk. Simply put, because of the on-site child care, I could do my job and my husband could do his. We didn’t have to play career roulette. After giving my talk, I began to process what happened. I was grateful that my husband could join me for the conference, but disappointed that despite our best efforts, our plan didn’t quite work out. I joked to the other attendees that if the conference hadn’t offered child care, I would have had to present my talk while holding my baby. But the truth is that I simply would not have attended in the first place. Recently, I posted a poll on Twitter, asking the tech community what they would do if they were a primary caregiver and wanted to attend a conference that didn’t offer child care. The poll got over two thousand responses. The overwhelming response was galvanizing. I received messages of support, solidarity and shared frustration. There were photos of women giving tech talks while holding infants, and stories of children sitting in the audience as their parents spoke. Many more parents, especially single parents, replied that they were simply unable to participate without child care support, and they had no choice but to stay home. There were a couple of people who responded negatively, questioning why parents should want to participate in conferences, but they were in the minority. People started connecting and sharing experiences with each other, and conference organizers connected with sponsors and brainstormed solutions. While there are tech conferences that do provide child care, the majority still do not. The reality is that it is currently not feasible to participate in most conferences without bringing a trusted caregiver along — and even then, full participation is a challenge. If a primary caregiver decides to attend a conference with their child, as many people who responded to my Twitter poll said they would, there is a lot of planning ahead of them. Here are some logistics a parent might have to tackle: Secure and pay for a trusted caregiver to accompany them to the conference. If breastfeeding, confirm that the conference will provide a private room. If pumping, ask for a private room with a lock and an outlet, and access to a refrigerator to store pumped milk. Call the hotel to request a crib or child-safe bed and a refrigerator, at minimum. Make sure the location is accessible with a stroller, and bring a car seat if traveling by car. Accept that there will be no sleep during travels and add extra days to the itinerary to recover sleep. This is a lot, and the complexity only increases depending on the age, needs and number of children. For every person who has the resources to attend, there are countless people who have no alternative but to stay home. Their voices are missing from these events. I’ve seen conferences go above and beyond to provide perks for their attendees and speakers, but so rarely is child care on that list. In the United States, cost and liability hurdles often stand in the way of willing conference organizers. But in an industry that prides itself on its ability to innovate, surely we can come up with a solution. While some conferences are finding ways to add child care, it will probably be a while before child care is as standard as coffee stations and branded T-shirts. In the Twitter thread following my poll, people who have shaped this industry reported having to opt out of conferences and events for years at a time while their children were young. Can you imagine if they had the support to attend? The need for child care access extends beyond conferences, but the tech industry is missing a massive opportunity for improvement. Conference organizers wondering why their demographics skew a certain way should re-evaluate their perks. Companies sending employees to conferences should reimburse for child care. Corporate sponsors should specifically earmark funds to assist conference organizers with providing child care — this is what enabled ScotlandCSS to offer the service. One day, I would like to share a different story about attending tech events as a primary caregiver. Instead of listing the obstacles, I want to list the many ways that parents are supported. I want conference goers to tell me that their attendance is no longer at the substantial personal expense of securing extra child care. I want to tell a story about how I was able to meet an engineer from another part of the world, and how our children got to play together while we talked. Most of all, I want to be able to say that I love going to conferences with my daughter, not despite her. How we design and build digital products at The New York Times 175 Code Parenting Work Personal Development Diversity In Tech 175 claps 175 Written by Designer, engineer, author, fine artist, speaker, educator, illustrator, relentless optimist, and doer of good deeds. How we design and build digital products at The New York Times. Written by Designer, engineer, author, fine artist, speaker, educator, illustrator, relentless optimist, and doer of good deeds. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-09-04"},
{"website": "NewYork-Times", "title": "remembering a programming language that helped shape the digital new york times", "author": ["hamman"], "link": "https://open.nytimes.com/remembering-a-programming-language-that-helped-shape-the-digital-new-york-times-cd809d707c74", "abstract": "Code Data Product and Design Workplace Culture Work with Us NYT4, the fourth and longest living version of nytimes.com died in March, 2018 after serving New York Times content for 17 years. NYT4 is survived by Jeff Damens and Oliver Karlin, the engineers who invented Context, a programming language that powered the site, and dozens of other engineers who worked on the site over the years. Context was born in 2001 in the office of Scott Meyer, then general manager of nytimes.com. Meyer wanted to make the New York Times website more personal by adding readers’ usernames to the top of the homepage. At the time, nytimes.com was a static site that could not be customized for each person, but Meyer wanted that to change. Damens and Karlin could have hacked something together just to add the username. They could have used PHP and CGI, which were common technologies in 2001. But, as Karlin pointed out, “You didn’t want to CGI-up the homepage to put one dynamic text in there.” The developers had concerns that CGI wouldn’t scale to handle traffic on the homepage, which even then was growing quickly. They were also skeptical that Meyer’s vision for personalizing nytimes.com would end with the addition of a username. Instead, they created Context, a lightweight language that was compiled to run on The New York Times’s servers and optimized for speed. Damens said they were able to get speeds a hundred times faster than CGI in early tests. But they didn’t stop at creating a language. Anticipating that editors would one day want to add more dynamic sections to the site, Damens and Karlin designed Context to support newsroom workflows. Editors were familiar with adding tags to their page layouts to change elements, such as the weather, for different regional editions. Rather than asking editors to learn a programming language, the developers tied the language into the macros the editors used to send formatting instructions to the printing press. What started as a request for a username turned into a programming language, a compiler, a pre-processor that scanned every page on the site and converted it into a context program, and a virtual machine to run those context programs on The Times’s servers. “We probably over-engineered it, I guess,” Damens said. But Context wasn’t just an elaborate username-printing system for long. Soon, the system would be used to add a weather widget to the homepage. Then it was used to streamline the process for publishing movie showtimes online. Within a few months, a Context program was put into service to paginate articles, which was a major driver of page views. Context quickly became the technology powering the bulk of nytimes.com. While it had a reputation for being fast and reliable, Context was also controversial. Engineers bristled at having to learn a programming language only used at The Times. Only a few learned enough to help add new features or extend its abilities. Recruiting new engineers was sometimes a challenge because candidates had to accept that they were joining an organization with a homegrown programming language and build system. Looking back, Damens and Karlin regret not picking an existing syntax of a language, like PHP, to make it easier to adopt. Context probably would have been phased out quickly were it not for another personalization challenge that required its speed. This time the problem was ads. Later in 2001, Zip-code targeted ads were slowing down the site and by this time Context had credibility as a fast and reliable solution. Damens and Karlin were called in to help. They used Context to create a fast ad server called AdX, which used regular expressions to match ad slots according to targeting parameters for each ad campaign. The regular expressions ran against metadata in the page (such as a reader’s zip code and what section of the paper they were visiting) to target ads to specific users. AdX also kept track of how frequently ads were shown so it could manage overall ad inventory. All of this was able to run on the existing servers of The Times. By the end of 2001, Context was powering nearly all pages and advertising for The Times. It went on to serve more than a decade in this capacity, seeing the transition from a supplement to the printed newspaper, to the way most readers consume The Times. It survived traffic surges during elections and major news events. AdX expanded to serve increasingly sophisticated targeting, including marketing messages on the site. With all that Context did at The Times, it never ventured outside the walls of the building; it was never open sourced or sold. The years that Context was the most creative and powerful as a system were long before The Times had a culture that embraced open source. But perhaps that isolation helped keep it alive until earlier last year. With only a handful of contributors, the language was spared being pulled in different design directions. Fewer than a dozen engineers knew how the build system worked. Maybe a hundred engineers learned to ever write Context code. Without a large community of engineers, Context was spared from the drag that new features can add to a system, which meant it stayed small, nimble and able to scale to meet the growing traffic of The Times for a decade after its creation. As the last files of nytimes.com were rewritten using newer technologies , Context disappeared entirely from The Times. While the language could have grown into something larger had it been open sourced, it instead served to help The Times find its footing on the internet. Damens and Karlin were right: The Times news offerings have expanded from a static website to include apps and more personalized features. But one thing has stayed the same: readers can still find a link to their username on the homepage. How we design and build digital products at The New York Times 458 3 Programming Technology Journalism Code Web Development 458 claps 458 3 Written by I'm a VP of Engineering at the New York Times. How we design and build digital products at The New York Times. Written by I'm a VP of Engineering at the New York Times. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-10-23"},
{"website": "NewYork-Times", "title": "how we prepared new york times engineering for the midterm elections", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/how-we-prepared-new-york-times-engineering-for-the-midterm-elections-2a615fe4196e", "abstract": "Code Data Product and Design Workplace Culture Work with Us By KRITON DOLIAS and VINESSA WAN In the news industry, any day can be a big news day. For those of us who manage news websites, big news means large audiences and stress to our systems. At The New York Times, we work constantly to make sure our website and apps are ready to handle the influx of readers who come to us by the hundreds of thousands when news breaks. But sometimes we experience a confluence of factors that create unique traffic events and bring new challenges to our systems. This happened in September 2018 when our Opinion desk published an op-ed written anonymously by someone in the Trump Administration. The piece quickly went viral, putting a burden on our systems that affected load times and required us to disable some components on our site. With the impending midterm elections and the guaranteed spike in site traffic — the 2016 election drove traffic to more than 10 times our normal daily peak — we took what we learned from the op-ed traffic spike and rallied to fix some of the issues that came up. Elections are a big deal at The Times. Our readers rely on us to share the latest, most accurate results in real time, and our newsroom colleagues expect our website to function reliably. In the Technology department, we’re responsible for delivering this content, and we have to ensure that the site performs to the expectations of the newsroom and our readers, no matter the demand. A lot changed between the 2016 election and the run-up to the 2018 midterms. With the increased national attention on politics, The Times’s digital news subscriber base had almost doubled . This meant we were facing a guaranteed increase in audience numbers that would tax our systems. This would have been daunting in normal circumstances, but we had just changed how our website was served. In 2017, we moved from hosting our site from on-premises data centers to a distributed cloud based architecture. In this new structure, each team is responsible for their own infrastructure and their own incident management. Our challenge was to figure out how to coordinate incidents across teams in this decentralized structure. With seven weeks until the midterms, we sprang into action. Our mission was to organize a cross-team effort to ensure that election news and interactive content is stable, performant, always up-to-date and displayed as the newsroom intends for our readers. We assembled over 20 teams that have a hand in ensuring our election coverage is reliably served across all of our platforms. With so many teams to manage, we created an election leadership team that was led by a Directly Responsible Individual (DRI), a deputy DRI and two program managers. The election leadership team worked as the intermediary between our Site Reliability Engineering team (SRE), company stakeholders and the engineering teams. Getting so many teams on the same page is no small feat. Some teams’ systems were more prepared than others, so our first step was to evaluate each system’s readiness level. We then led each team through a series of workstreams: This was the first step and it covered the reliability, monitoring and failure scenarios of each system or application. Once that initial review was complete, we had a better idea of where the teams stood and we were able to assign tasks for them to work on. Because we had a clear picture of each team’s domain, we were able to group teams with known dependencies, and we scheduled meetings to dig into their architecture needs. We develop our software and systems to be as scalable and resilient as possible, but without testing, it’s impossible to know how they’ll perform when hit with the type of traffic we get on election nights. So part of our standard development process at The Times is to run load tests on our applications to see how they perform. This helps validate our cloud environment architecture decisions. Because we expected an unprecedented amount of election night traffic for the 2018 midterms, we decided to stress test our systems, as well. Stress testing is designed to find weak spots in systems. Perhaps more importantly, it shows how our teams respond when things break. We conducted two rounds of stress testing. To achieve optimal results and replicate an election night load as closely as possible, we made the decision to run tests against The Times’s live production environment. This meant that we had to guard against the possibility that a major news event could happen in the middle of our test, so we coordinated timing and developed a process with our newsroom to “pull the plug” if needed. Much like fire drills prepare people in the event of an emergency, we treated these tests as a rehearsal for election night. To help promote a culture that embraces learning, our SRE team introduced blameless post-mortems , which we call learning reviews. After each of the production stress test, we held a review to capture what went well and address how we needed to improve. These findings guided not only technical tasks, but also informed how we could better communicate across teams. Timelines are a key part of our learning reviews. As these learning reviews were pre-planned, we captured a timeline of our stress tests in real-time, documenting timestamps, events and the teams involved. By providing an accurate, objective and detailed recording of the tests, the timelines were helpful guides for both of our learning reviews. After the stress tests and learning reviews, our election leadership team scored each application by its team’s preparedness, communication and technical readiness for the expected elections traffic. This proved useful in escalating concerns and issues, and it helped build confidence among management and individual teams. Because The Times hosted its own servers for years, we had a centralized Systems team that triaged and responded to incidents. After our migration to a cloud-based infrastructure, individual teams became responsible for managing their own incidents. It’s important that teams know how to best respond to an incident and can communicate with each other efficiently, especially when incidents span more than one team. To improve our practices, we had everyone go through a training program created by our SRE team. The training covered best practices for incident management, cross-team coordination and communications. People who are versed in these skills are best suited to be an Incident Commander — someone who coordinates the response, actions and communications during an incident. With a project of this size and complexity, coordination was key. We had active on-call shift coverage and documentation for how to degrade core systems gracefully. This was done to ensure that if a system or dependent system was failing, engineers had a playbook to quickly fix the issue while ensuring the best possible experience for our readers. As an extra precaution, we assigned Incident Commanders to a second on-call rotation. Having all teams in the same room during this time wasn’t feasible — there were just too many people — so we grouped teams by technology stack and each group worked from a conference room (another lesson learned from our production stress tests). The different groups stayed connected by being on the same video chat and messaging platforms — with protocols in place to minimize noise, such as limiting discussions on the video chat to incident responses only. We also documented our incident management process with our vendors, many of whom were on site to support us. The 2018 elections drove record traffic numbers for a midterm election at The Times. The work we did to get our teams aligned and our systems in good shape meant that we were able to scale, even with some services getting 40 times the normal traffic. Incidents did occur but with limited downtime and impact to our readers. To take on a project of this size in such a short time span, we had to focus on organizational structure. Assigning a DRI proved to be tremendously effective. When navigating difficult decisions across so many teams under tight deadlines, having one person make tough calls saved time; the deputy DRI made decisions if the DRI was unavailable. This structure was widely communicated and was easy to digest, which meant that teams were better aligned. Input from the SRE team helped define the work to be done. Because they worked closely with teams on tasks like prepping for the production stress test, it allowed the election leads to focus on other aspects of the project, like working with stakeholder. In future projects, we’d like to explore having more functions represented in the leadership team. We’d seek to supplement our engineering and project management leads with a colleague from both product and the newsroom to broaden our leads’ perspectives. The more stakeholder voices involved in the planning process will pay dividends in the end result. Whether it’s a special event, like an election, or a normal news day, teams need to be prepared to perform reliably when things break. We know that it’s unreasonable to think that a website of our size will be up and functioning 100 percent of the time. Using the table of nines as our guide, we designed a metric for site reliability that acts as our measure of acceptable downtime. Through discussions with our product management and newsroom colleagues, we developed a product degradation strategy, which detailed the apps and features that could be shut down in case of failure and our backup plans. This ensured that everyone was on the same page about what would happen if a system failed and engineers could take immediate action knowing they had product approval for expected scenarios. Accepting that failure happens is why we emphasized incident management training. Running teams through drills leading up to the midterms meant that we could limit the impact of an outage during peak traffic periods. There were incidents on election night. Fortunately, these were handled swiftly and we have conducted learning reviews so we can be even more prepared for the next time big news breaks. Kriton Dolias is a Technical Program Manager for the Publishing Pipeline at The New York Times. Follow him on LinkedIn . Vinessa Wan is the Principal Program Manager for Delivery Engineering at The New York Times. Follow her on LinkedIn and Twitter . How we design and build digital products at The New York Times 246 1 DevOps Technology Code Project Management Teamwork 246 claps 246 1 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-02-15"},
{"website": "NewYork-Times", "title": "from med school to code school a career path full of twists and turns", "author": ["Charity Garcia"], "link": "https://open.nytimes.com/from-med-school-to-code-school-a-career-path-full-of-twists-and-turns-ffc57a9ec028", "abstract": "Code Data Product and Design Workplace Culture Work with Us When I was 12 years-old, I knew I wanted to be a doctor. I was a really big fan of Bill Nye the Science Guy and medicine, so I decided to combine my interests and set my sights on becoming an Anesthesiologist. Three years into pre-med, I learned I couldn’t pursue medicine due to circumstances outside of my control. I had to reevaluate what I wanted to do. Science was a passion of mine, but the prospect of studying science without it leading to a medical degree was too upsetting. I opted to switch my major to sociology, and finished school on time. After graduating, I worked for a few major telecommunication companies in sales, customer service and as a technician fixing cell phones on the user end. Part of my role as a technician was to identify and report bugs to the manufacturers. Finding technical bugs was fun. After I sent a couple of major bugs to these companies, I started to think about the possibility that I could fix these bugs, rather than just report them. That night, I went home and I searched for websites where I could learn Ruby or Javascript, and I started teaching myself how to code. When I finally looked at the clock, 10 hours had passed and it only felt like one hour. In that moment, I knew I had discovered a passion: coding filled that spot in my heart that had been empty since I left the pre-med program. I began to study code while I saved money for a coding bootcamp. But bootcamp was further off than I expected. About two weeks after I started learning to code, a friend and I were driving to her house when another car hit us head-on. Both my friend and I were injured in the crash, and I sustained major brain trauma. In the months afterward, I had to relearn how to walk and speak clearly because my vocabulary severely regressed. Reading even a single sentence could trigger a migraine that lasted more than six hours. I could not remember what was said more than five seconds in the past. After two months of physical therapy and daily use of brain game apps, I finally was able to read a page and retain the information. With my migraines less severe, I went straight to the computer and started to teach myself how to code again. Within a year of the car accident, I was accepted on the first try to Fullstack Academy in New York City. After graduating from the program, I started a job as a software engineer at a tech startup in Boston. Less than three years after the accident, I started working as a software engineer on the Cooking team at The New York Times. Starting a career in tech can be overwhelming, and not having a traditional computer science background can make it that much more daunting. I haven’t let that stop me. Here are 10 things I’ve learned over the past few years. It’s okay to say “I don’t know.” Throw that ego out the window. If you truly do not know something, making things up along the way is NOT the way to go. If you are stuck for more than 20 minutes, ask for help . There’s nothing worse than not making progress on an issue for hours; don’t be afraid to ask for help or quickly pair with someone to get unblocked. Learn Bash commands . This is a life saver! Learning Bash commands will help you save a tremendous amount of time as you work on more advanced issues. Some helpful commands to know: ls — lists the folder and file names that are in your current working directory mv — moves files and folders cd — changes your directory to the root directory (used alone) or a specified directory cp — copies files and folders. rm — deletes files and folders. Be extra careful with the rm command: you could accidentally delete something you don’t want to. Learn Git commands, too! Knowing at least some basic Git commands is a must. Do not `git rebase` unless you know what you are doing. Everyone hates resolving merge issues and `git revert` is not fun after branches have been merged into development or master. If you are new to git, refer to the point above and ask for help, or look it up. Always Be Learning. The tech field is ever-changing, which is one of the reasons why I chose to become a software engineer. Keep up with the latest technology and sharpen your skills. Having ongoing personal projects will only benefit you in the long run. Some useful resources are Udemy.com , FreeCodeCamp.com , and Youtube tutorials ( Traversy Media , The Net Ninja and LevelUpTuts are some of my favorites). NETWORK! Keep active in the tech community inside and outside of work. It’s great to have friends when you are entering a new scene. By connecting with people in the industry, you can learn from their experiences, share career advice and you might even find a new job through your network. Stay humble . You don’t know everything. There’s always going to be someone who knows more than you — and that’s OK. Work on your soft skills . Communication is important. Teamwork and empathy makes for a better work and culture atmosphere. Ego gets in the way of communicating with others. Work for a company you believe in . Money is good — we all love it — but doing what makes you happy while working for a company that is aligned with your values in some way makes the day go by faster. Be passionate about your career . Keep that passion and find people who support you. Every engineer, regardless of their position or experience, I’ve spoken to has said they experience self-doubt. It’s a normal feeling that will happen again and again. Never give up and remember why you became a software engineer. Here I am: a young, Black, female software engineer working in a predominantly male dominated profession. After much perseverance, I have my dream job at The New York Times on an awesome team (shoutout to NYT Cooking!) and I could not be happier. As I look back, I can see how far I have come, but I also know that my journey has just begun. I’m excited about software development and I created a group to help other women of color get into the tech industry. Feel free to reach out on Instagram or Twitter . How we design and build digital products at The New York Times 305 1 Software Engineering Women In Tech Code Codingbootcamp Careers 305 claps 305 1 Written by Charity is a Software Engineer for the New York Times. You can follow her on IG and Twitter: @CharInReelLife How we design and build digital products at The New York Times. Written by Charity is a Software Engineer for the New York Times. You can follow her on IG and Twitter: @CharInReelLife How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-01-17"},
{"website": "NewYork-Times", "title": "faster and lighter moving ad tech server side", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/faster-and-lighter-moving-ad-tech-server-side-ef4bd6d2f2eb", "abstract": "Code Data Product and Design Workplace Culture Work with Us By EDGAR VELEZ and PRANAY PRABHAT Rendering ads on web pages is a complex process. The process requires collecting the data needed to serve the most relevant ad, and configuring the code responsible for rendering that ad. Most of the heavy lifting to place an ad typically falls to the browser, with negative implications on page weight. Over the past year, the Digital Ad Systems team at The New York Times has transitioned some of our ad rendering logic to the server. We developed a framework that allows our team to configure rules that can be executed before an ad call is made. For a media company like The Times, defining how ads are displayed requires extensive planning and engineering to make sure the right ads show up in the right places and to the right audience. Moving that logic to the server is no small feat, though it is worth it in the long run. Server-side ad rendering not only lightened our page load, it allowed us to build a suite of ad products with more robust ad targeting. We now have more flexibility in defining the parameters that get passed to ad campaigns. Below is how we built our framework and how it works. We decided to use a microservices architecture to handle all of this in an efficient and scalable way. The first version of the project was built using Java 8 and the Spring Boot framework, and we deployed into Google Kubernetes Engine (GKE) and used Drone for deployment. Later, our Data & Insights team built machine learning models that connected to new microservices we built. Our microservices use Google App Engine (GAE), Go and Marvin to enrich the ad targeting data by doing real-time lookup for specific data associated with Times articles. The component diagram below shows the entire flow of the systems involved, and how our framework supplies the ad targeting data back to the page for the ad server call. Web Front-End The Times’s main app, which we call VI, is built using React.js and Apollo, and it is responsible for serving and rendering nytimes.com. Our ad library is embedded in the main app, and it is also built using React.js. It serves DFP, and handles the ad targeting parameters and ad rendering logic on the page. Content Provider Service (Scala, GraphQL) A highly scalable and resilient system built using Scala and GraphQL to serve content to all front-end applications. Our content provider service interacts with the service built as a part of this project to pull the ad targeting parameters and pass those back to VI. Ad Library Rules Engine (Java 8, Spring Boot) The rules processor we built for this project is extremely fast so it can handle all the rules set before the ad call is made on the page. Spring Boot is a lightweight framework well suited for this, especially when implemented alongside Java 8 and Kubernetes Engine with local caching. This turned out to be an ideal combination for processing the data and rules within few milliseconds. Ad Library Rules Processor (Java 8, Kubernetes Engine) The Rules Processor maps the ad targeting rules — such as the length of time pages associated with a major event get a special ad — into data structures that are understood by the rules engine above. Ad Library Rules UI (React/Redux, GAE) This is the client-facing GUI used by internal stakeholders to build rules for ad targeting. Access and CRUD support is provided by the Ad Library Rules Processor mentioned above. Ad Library Data Service (Go, Marvin, Memcache, Datastore) The data service’s primary function is to look up all the ad targeting data stored in the caching layer and pass it back to the rules engine. Given wide adoption of Go at The Times, and the availability of lots of shared components, we decided to leverage the speed of Go and the highly scalable GAE to build this service. The caching layer used was Memcache, which comes as a managed service if you use GAE. Ad Library Data Bridge (Go, Marvin, Memcache, Datastore) The bridge does the heavy lifting of pulling relevant information from external APIs, the data science model and publishing queues for new assets, and it stores the data in an App Engine-managed Memcache and Datastore. This component is built using Go and utilizes an easily configurable App Engine Cron scheduler and The Times’s Marvin Framework . By moving our ad logic to the server and leveraging server-side caching, we lightened our page load time and reduced duplicative processing. Consolidating our ad logic on the server means that the Ads Business team only has to go to one place when requesting changes to our ads logic. They can easily configure ad rules in the UI, which immediately triggers changes across our platforms including native apps. Having a server-side solution provides the ability to integrate data science models and third-party APIs that enrich ad targeting parameters before the ad call is made from the page. Since all the heavy lifting is done server-side and cached, this introduces new and innovative targeting capabilities without any compromise on page load and ad call speed. With much of nytimes.com powered by JavaScript, it’s becoming increasingly important to find ways to reduce page load. This is especially true in the ad tech space, where we are working to find advertising solutions on the server side. At The Times, we see a huge potential to expand our server-side solution so we can better target ads without worrying about browser restrictions or relying on cookies. In the coming months, we plan to leverage more of GCP’s solutions for managing microservices. We see the Cloud Memory Store Redis caching service and Kubernetes as tools that will allow us to scale our framework and grow with The Times. Edgar Velez is a Tech Lead with the Digital Ad Systems team at The New York Times. He is a Java to Go alchemist, and a burgeoning salsa dancer. Pranay Prabhat is a Senior Director with the Digital Ad Systems team at The New York Times. He is an AdTech enthusiast. How we design and build digital products at The New York Times 179 1 JavaScript Advertising Code Adtech Technology 179 claps 179 1 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-01-28"},
{"website": "NewYork-Times", "title": "congrats youre on call now what", "author": ["Jeremy Gayed"], "link": "https://open.nytimes.com/congrats-youre-on-call-now-what-8d36c5ad60aa", "abstract": "Code Data Product and Design Workplace Culture Work with Us Several months ago, The New York Times completed the replatform of our core news website. Initially this was supported in production by a tight on-call rotation of a few engineers who were responsible for handling any complications that might arise. But, as we began to port over features from our previous platform and expand our on-call rotation, it became clear that we needed to teach more engineers how to triage production issues. A key indicator that we needed to spread this knowledge was the discovery that not all engineers were completely comfortable or confident in being assigned to an on-call rotation, even though they had been consistently delivering features and product improvements to the code base. We did our best to produce robust and detailed playbooks, troubleshooting documentation and demos. While these materials were as thorough as possible, they were not something one could easily navigate to quickly determine action steps while alarms are blaring at 2 a.m. To help our engineers feel more comfortable, we developed a framework for simulating “war game” scenarios. War games is a process often used in software engineering to simulate defects in production — without breaking production. We use war games in our development process as a way to refine our own tooling, documentation and procedures for supporting production services. Because the process is simulated, it allows engineers to practice being on-call without the stress of a real production issue. We knew we wanted to simulate production issues and make them as realistic as possible, which meant that we had to create a new environment in which we could safely test our scenarios without affecting production. To do this, we forked our repository and renamed production items to instead be tied to a new “war games” label in Google Cloud Platform (GCP). We duplicated our CI/CD pipeline to mimic exactly how releases and rollback procedures worked. Since these releases needed to actually do something, we created a new production-like war games cluster that would be tied to deployments in this pipeline. This allowed us to simulate triaging issues in GCP and Stackdriver as if they were actually in production. We had been in production for some time before we started the war games process, so we had the benefit of hindsight on a few production incidents and could use our experience to create easily reproducible and realistic scenarios. Some scenarios included introducing buggy code updates that sneaked through our testing layers, while others included short-circuiting calls to our backend services in order to simulate upstream issues. Because we were more interested in testing our production defect procedures, we focused on simulating easily reproducible problems rather than stress testing the system architecture and resiliency. In order to put the framework into practice we spent some time designing the overall process, including thoughtful handouts that outlined how each session should run and a feedback form so we could iterate on the framework as we went. At a high level, the war games process is composed of four parts: an invite to the engineer going through the scenario, a handout to cover prerequisites and provide any necessary context, the session itself and the feedback process. We usually allot one hour for each session. When we ran shorter sessions, we ended up rushing through and were not able take time to find gaps in documentation or tooling. We found that it was best to spend about a half hour on each scenario; this way, one engineer can run through two scenarios or two engineers can run through one scenario each. As part of the invite we link to a handout that covers everything the engineer will need ahead of the session. This includes any prerequisites (such as having kubectl running locally), or any /etc/hosts entries if DNS isn’t available. For the session itself, we found it helpful to clearly define three roles: the engineer, the conductor and the instigator. The engineer is simply responsible for running through the scenarios. The conductor leads the session and walks the engineer through the process, reminding them that they are not the one being tested, rather our own procedures and documentation are. The conductor is also primarily responsible for jotting down notes during the session to find areas of improvement around where the engineer had the most trouble, such as gaps in our documentation or dashboards, or any ideas for improving future sessions. Lastly, the instigator’s role is to setup and execute the various scenarios for the engineer to run through. It’s also good to have this person take notes for a second perspective. After the session, we send out a survey to the engineer to gather some feedback. As part of the survey we try to quantify how the engineer feels about going on-call before and after the session. We also try to gather feedback on our troubleshooting playbooks, documentation, dashboards and also the war game process itself. We have since employed this framework across the organization, with a few tweaks relevant to each stack. This has not only helped new on-call engineers become more comfortable with a particular stack, but has also helped us improve our tooling, documentation and procedures for production defects in a way that is quite eye opening. How we design and build digital products at The New York Times 8 1 Software Development Technology Code Management Learning To Code 8 claps 8 1 Written by Coptic Orthodox Christian. Lead Software Engineer @nytimes. Lover of all things JavaScript 🤓 How we design and build digital products at The New York Times. Written by Coptic Orthodox Christian. Lead Software Engineer @nytimes. Lover of all things JavaScript 🤓 How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-01-11"},
{"website": "NewYork-Times", "title": "css grid for designers", "author": ["Johna Mandel"], "link": "https://open.nytimes.com/css-grid-for-designers-f74a883b98f5", "abstract": "Code Data Product and Design Workplace Culture Work with Us For years, designers have been using grids to bring order to pages. Grids as a design tool are associated with the Swiss who formalized it as a way of thinking about layout in the 1940s, according to Beth Tondreau in the book “Layout Essentials.” As people started designing for the Internet, grid systems were carried from the printed page to the digital one. During this time, CSS (the code that controls the style of elements in your browser) was limited in terms of layout capabilities. My teammate, Natalya Shelburne , an engineer at The New York Times, equates it to trying to create designs using the tooling of Microsoft Word. As a workaround to these limitations, a number of layout frameworks were developed to make working with layout easier. In 2011, Twitter released Bootstrap , one of the more popular layout solutions. Bootstrap did a bunch of calculations behind the scenes, so that developers could use simplified code to implement layouts on a 12-column grid. Grids on the web were not simply design guidelines for layout, but actual code that both limited and executed the placement of elements across viewports and breakpoints. Fast forward six years to the release of CSS Grid in early 2017. This technology removes a lot of the limitations that existed in CSS to-date. But CSS Grid is not just a tool for front-end developers; designers can now think about web layout in new ways. CSS Grid makes it easy to create grid tracks using CSS — grid tracks are just a fancy way of saying columns and rows. The 12-column grid popularized by Bootstrap was a smart solution at the time, but CSS Grid gives us many more layout options. CSS Grid allows us to quickly create custom grids for our projects. This means we don’t need to start with 12 columns — we can have five or eight. This technology advancement is so important for designers to understand, because it means we can think about the right grid for the demands of our content. We can create grids that better control the placement of elements both vertically and horizontally. All of this brings classic graphic design and art direction approaches back to web design. The language of CSS Grid is incredibly straightforward, so there’s no need to learn cryptic classnames that were popularized with Bootstrap, like col-sm-8 . There are two main steps to set up a page using CSS Grid: define the grid tracks and then place elements in those areas. To set up the grid, we’ll create a parent element that will contain all of the HTML elements in the grid. This parent element is typically a <div> with a classname of grid-container or container . In order to identify this container as the grid, we use display:grid in the CSS. Now that the grid container is on the page, we want to start dividing the grid up into columns. To define columns we’ll use grid-template-columns , and to define the gaps between columns we’ll use grid-column-gap . The number of columns on the page is controlled by the number of values that are defined in grid-template-columns (we can see in the example below there are three values that translate to three columns). In more traditional graphic design, column width is determined through a calculation of paper size and type setting. Since web design is never constrained to a specific width, sometimes a column width set to percent is the best choice. CSS Grid accepts percentages, pixels and fractional units when defining column widths. You’re probably familiar with pixel and percentage values, but I want to take a moment to quickly endorse fractional units , which are new to CSS Grid. Fractional Units, or frs, deal with gnarly math fractions by perfectly dividing the remaining space available. For example, if we wanted a grid to have three columns with no gap, the percent would have a rounded decimal value like: grid-template-columns: 33.33% 33.33% 33.33% . Fractional units take the guesswork out of declarations, and instead allow us to write: grid-template-columns: 1fr 1fr 1fr . Adding columns or adjusting ratios is simple. Just increase or decrease the numbers, like so: grid-template-columns: 1fr 2fr 1fr . CSS Grid also accepts auto for column width, which is a hugely powerful tool. auto will expand the column to the maximum width available, as defined by the surrounding columns. For example, if grid-template-columns is 100px auto 100px and the page is 500 pixels wide, the auto section will take up the remaining 300 pixels. If we want finer control over the range, we can also use minmax() which limits the column width to the ranges we specify, such as minmax(550px, 800px) . We’ve gone over columns, but CSS Grid also allows row definition. Rows can be great for finer control over the vertical rhythm of the page, and are created in the exact same way as grid-template-columns by using grid-template-rows and grid-row-gap . O.K., grids are great, but they are invisible unless there is content in them. To ensure grids appear on the page, we need to place elements in each grid track. Grid will implicitly place items. But we want to learn how to explicitly place items for clearer control. There are two approaches to this. One approach is to identify the grid lines in which an element should live. Since tracks are the space between lines, this approach specifies the tracks the element will live in. For example, if we wanted to place an element in the third column track, we would tell CSS Grid that the element starts at the third grid line and ends at the last grid line. This would look something like: This approach is important to learn, but it is most useful if we are trying to put multiple elements in the same grid track. The other approach, which I prefer, specifies placement using grid-template-areas . This allows us to name specific areas where elements should render in the grid, but most importantly it lets us keep all our layout code in one neat place. To set this up, each element first needs a grid-area declaration in its CSS, which then can be referenced in the parent container declaration. Once these elements are named, we can use the names to arrange the layout visually in the parent grid-container . In the example below, the image is assigned to the first column and second column by using the syntax, \"image image .\" . Repeating image tells CSS to span the image the first and second column. The . tells CSS to keep that area blank. Each new line in the grid-template-areas declaration correlates with a new row in the design. In the second line, caption text text tells CSS that the second row should have the caption in the first column, and the text element spanning the second and third columns. What’s even more fun with this approach is that it makes it easy to quickly rearrange our layout without needing to rename elements or move the HTML around. We only need to switch placement of the names in the grid-template-area declaration to dramatically change the layout of elements. These techniques all work responsively, and this is where CSS Grid shines. To define a layout for a smaller breakpoint, we just need to redefine our grid and reorganize the properties in grid-template-areas . Placing items in the grid using grid-template-areas allows us to actually see our layout spelled out in text. To me, it feels like designer ASCII art and I love it. I don’t want to understate how exciting this is; gone are the days of col-lg-2 and col-sm-12 . We can reorganize our layout at any breakpoint, and grid-template-areas means our design is visible in the code, across all breakpoints. Once elements have been placed in a grid track or area, we can further customize their vertical and horizontal alignment — similar to how alignment control work in design software. Align-self and justify-self can be applied to the child elements like so: CSS Grid can be used more than once on a page. Since grids are just containers with elements, there is no reason why they can’t be nested inside each other or stacked on top of one another. The next iteration planned for CSS Grid is adding Subgrids for more powerful nesting features. In the meantime, the current specification for nesting and stacking grids is still great for a variety of instances. For example, if one moment on a page requires very different placement of elements than the rest of the page, we might use a nested grid. This allows us to be precise with layout in this one moment, without overcomplicating the main grid on the page. The technique is especially useful if the main grid is still in progress, because we won’t lose nested designs by making changes to the main grid (like adding another column.) Similarly, we can stack grids. This is a great approach if the design is trying to achieve a visual break from the grid that recurs throughout the page. Wow. That was a lot. Hopefully this guide gave you a pretty comprehensive look at how you can use CSS Grid. Here are the highlights: No more 12-column grids! CSS Grid gives you complete control over how many columns and rows your design needs. You have fine grain control over width down to a pixel, but also flexible options including minmax() and auto . CSS Grid makes it easy to define new grids at any breakpoint , meaning you can easily redefine grids and rearrange elements across breakpoints. Items on mobile no longer have to stack in the order they are arranged on desktop (unless you want them to). Grid-template-areas keeps all your layout code in one place , with the added bonus of making your layout decisions feel like cool ASCII art. CSS Grid lets the content determine the page layout instead of forcing the content to fit into an existing grid structure. This follows Brad Frost’s words of advice, “ let content determine breakpoints .” These layout advancements are great for all types of design. I recently used CSS Grid for a technical search interface for The New York Times’s Content Management System, Scoop. Each search result in this interface is a grid container, using an auto column for the headline cell. I’ve recently moved onto a team with more of an editorial focus and am looking forward to finding out how CSS Grid fits in to that work. CSS Grid has personally made me love HTML and CSS prototyping again, and I hope it does the same for you. There are a lot of details that I gave short shrift, but below are some resources that go into more detail. Happy reading! CSS Grid Garden A Complete Guide to CSS Grid from CSS Tricks CSS Grid — The Beginner’s Guide CSS Grid Layout from MDN Youtube: Layout Land People: Jen Simmons Rachel Andrew Wes Bos How we design and build digital products at The New York Times 6.5K 19 CSS Css Grid Design Front End Development UI Design 6.5K claps 6.5K 19 Written by 🎶 ba dee bedebe 🎶 ~… product designer @instagram previously @nytimes, aspiring muppet. How we design and build digital products at The New York Times. Written by 🎶 ba dee bedebe 🎶 ~… product designer @instagram previously @nytimes, aspiring muppet. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-12-30"},
{"website": "NewYork-Times", "title": "reimagining the morning briefing", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/reimagining-the-morning-briefing-655100304624", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Andrea Kannapell, Jeanie Kay, Melissa Loder, Shannon Smith and Albert Sun Most of us are trying to catch up from the minute we wake up. We roll over and check our phones. Our smart speakers orate the latest news flash as we brush our teeth. Our faces are glued to little glowing mobile screens in the subway or we deftly execute voice commands in the car on the way to work. This urgency for the latest may explain why so many people subscribe to The New York Times Morning Briefing: 1.7 million (and counting). Readers say they value the succinct overview of the day’s most important news and the additional stories that help them feel connected to what’s going on in the world. But four years into the Morning Briefing’s run, the competition was growing. The editors realized they’d made a lot of ad hoc adjustments, but that it was time for a deeper reconsideration. The Times decided to try a truly comprehensive effort involving newsroom, product, design, research, data insights and technology. And the voices addressing you now are that team. We started by trying to understand more about what the briefing meant to our readers. When we sent out a survey, the difficulty of our task became clear: Of the 13,000 readers who responded, over 97 percent said they were somewhat or very satisfied. How could we make such a successful editorial product “better”? Get to know the reader: We followed the morning routine of 30 for a week, which helped us understand their reading behaviors. We found that many readers fall into one of two distinct groups: those who read every word, top to bottom, and those who skip and scan for things that interest them. Depending on the day, readers might move between these two modes based on how much time they have. We also have readers who only read hard news, readers who live for our lifestyle coverage and readers who want a moment of historical intrigue — the “back story enthusiasts.” Trial and error: Rapid testing helped us both 1) observe how readers reacted to changes and new features, and 2) understand how they navigate the current briefing. For instance, we repeatedly observed how the original briefing required many readers to read every word to grasp critical points. It signified importance with bolding, but it often did so inconsistently and without deliberate cues. The original briefing also followed a loose structure that ordered content from urgent to less urgent — but heavier news was often scattered throughout, requiring readers to shift their frame of mind quickly and frequently. Section headers like ‘Business’ and ‘Smarter Living’ invited readers to skip chunks of the briefing, sometimes missing articles they might have found interesting. A clear structure: We wanted to emphasize the sequence of information to first-time readers, as well as aiding existing readers who want to skip and scan. The new briefing starts with the top stories of the day and then moves on to stories to connect the reader to what’s going on in the rest of the world and across the internet. The briefing ends with rewards: recommendations for nice things to cook, watch and listen to. Friendly guidance: We use a conversational voice to escort the reader through the new briefing. Lines like, “If you have time, this is worth it” and “Now, a break from the news” give readers a sense of what value they’ll receive from a particular section while respecting their possibly-limited stock of time and effort. In the same way, a welcome note eases the reader into the news each morning and a goodbye note sends them on their way. Different font treatments help distinguish between guidance and content. This helps onboard new readers and allows veteran readers to skip as they choose. By improving signaling in top stories in the new briefing, we allow readers to get the gist of events quickly and choose what to engage with. We use bold lead-ins as labels, to help the reader know what kind information they are being offered. “How we know” allows us to give a behind-the-scenes look into The Times and reveal a little bit about the reporting process — like how many months our journalists spent reading through secret documents for a particular story. Other lead-ins: “Why it matters,” “Background” and “Another angle.” “Here’s what else is happening” is a section that follows top stories and the featured read. Here, the bold lead-ins are more specific and clue the reader in on what kind of current news is available in the briefing, for instance “U.S military constraints” or “California wildfires.” Empowering newsroom with insights: The briefing writer, Chris Stanford, and editors have long engaged with readers, responding daily to questions, feedback, fury and praise via email. With testing, we now could physically watch how readers interact with the briefing, which allowed for a new level of insight into reader needs. This helped us to develop a set of design principles that reflect both our editorial and user experience goals. Editing as a group: This could have been a nightmare, but — writers, brace yourselves — it wasn’t. From the initial prototypes to the final pilot test, the entire team edited together in a discussion with the writer that honed the “mission statement” of every passage. (Editor’s note: That all who participated said the experience was positive is possibly the most surprising phenomenon of the entire project.) Redesigning the workflow: Our structure allowed for advance work, allowing the briefing writer more time to focus on major news, fine tuning and grace notes. Testing the new process: All of these elements showed their value as we tested the new briefing in London alongside Stanford. He could practice and refine everything we developed together, while readers gave us qualitative feedback. The initial test (sent to around 3,000 readers) and a follow up test (sent to over 130,000 readers) helped us assess the risk of making the intended changes. Future Newsletters: Our process for evolving the briefing has laid a foundation for refreshing other Times experiences. Specific to newsletters, technical limitations have informed everything, including how we design, produce, perform VQA and measure data around a newsletter. A way of working: This project aligned how the newsroom and product work together towards our user needs and delivered a product experience that enhanced our successful journalism efforts. Not only did we redefine the Morning Briefing experience, but we strengthened trust and understanding with the newsroom, showing the value of a user-centered development process. With this process in place, we will continue to look at the valuable editorial offerings we have and find ways to elevate that value to our new and existing readers. If you don’t already receive the Morning Briefing, you can sign up here to get it by email. Albert Sun and Andrea Kannapell from the newsroom Melissa Loder on product Jeanie Kay and Thea Lorentzen from design Shannon Smith from research Calli Higgins from technology Sandra Stevenson from the Photo Desk Chris Stanford who writes the briefing each day, and Anne-Sophie Bolon who edits it How we design and build digital products at The New York Times 1K 5 Journalism Product Development UX Design Design Media 1K claps 1K 5 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-11-28"},
{"website": "NewYork-Times", "title": "experiments with link previews to help guide readers", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/experiments-with-link-previews-to-help-guide-readers-79dbe843ad29", "abstract": "Code Data Product and Design Workplace Culture Work with Us By MAILIIS LAW and JAVERIA NICOLE ALI The New York Times publishes around 160 articles per day, many of which have several links embedded within the text. While these links are a way for readers to gain background information, explore unique threads of Times content and view sources, they can often distract readers from finishing the story. Take, for instance, the second paragraph of “ Into the Wild with Kanye West ,” which include provocative blue links that jump out at the reader: “wife robbed at gunpoint,” “erratic court appearances” and “nine-day stint.” But the paragraph ends with a great hook: “He was in a state of shambles, and it showed.” While the links tempt readers to click, the power of the hook implores them to keep reading. Rather than contributing to their understanding of the article, these two forces may work against each other and leave our reader’s attention divided. In August, we launched an experiment that displays hover-over previews for links to The New York Times articles. By providing a new line of interactivity, we hope readers can use links as tools to better discover and contextualize articles. Current user interaction with links can be boiled down to one of the following paths: Opened into a new tab for reading later Clicked on and routed to another article, with a chance of returning to the original article Ignored due to a lack of immediate access or disinterest In one scenario, readers may find a link so intriguing that they stop reading the current article entirely, embarking on a tangential journey traveling from article to article. Following linked references may send readers down a long, divergent path, never returning to the article they originally intended to read. Other times, they may open links into other tabs, promising to read them later. Once they finally begin sifting through the tabs crowded at the top of their window, articles may be so removed from the original context that readers may forget where the articles came from. Easily accessible previews help readers who want more context about inline content but do not want to stop reading the current article. At the same time, they can assist readers who want to discover articles with more in-depth information. These were the most essential functions we built into the preview tool: A display that includes key aspects of the article such as its headline, lede image and publish date. A subtle delay for users who are simply moving their mouse around the page. Dynamically displaying the preview above or below the link to keep it within the reader’s window. We hoped that by giving users the flexibility to interact with links in a more streamlined and organized manner, they could enjoy a more cohesive reading experience with The New York Times. We referred to existing visual indicators on Times articles in our approach to the design of inline link previews for articles. When faced with new site behaviors, familiar elements allow the reader to identify what they’re looking at and base their interactions on previous ones. As the links featured other articles, we drew on how The Times displays articles on the homepage. We created a miniaturized version of the typographic style in the headline, timestamp and section label along with including a thumbnail image. In order to make the previews less obtrusive to the reading experience, we scaled them down to fit in a compact, white card with a subtle shadow. This choice allowed the preview to exist on a different level from the content of the article, while matching the page stylistically. To ensure that readers formed a direct connection between the action of hovering and viewing a preview link, the placement of the module corresponded directly with a reader’s hover position. While this made the tool more intuitive, it meant that the preview could fall outside of the viewport. To avoid this, we optimized the module to appear above the reader’s cursor when placed on the bottom of their viewport, or below if their cursor is on the top of the viewport. When it comes to design decisions in programming, it is always good to explore methods that will avoid writing code that may already exist. Because our website is built with React, it was tempting to take advantage of pre-existing components, such as react-modal or react-tooltip. Doing this would have offered a foundation of code for the preview. However, this strategy would have left these components sitting across our entire code base, potentially adding to loading time of all pages. Instead, we did the heavy lifting of creating a fresh, custom component to implement our design in the most direct, lightweight way. The preview tool is selective and only displays links with select criteria. As the page renders, our code first scans for links with qualifying dates. This is done by examining date parameters stored within the URL of a link. NYT URLs are structured like this: https//www.nytimes.com/2018/06/25/arts/music/kanye-west-ye-interview.html Using a simple line of RegEx, which defines the search pattern of a string, we extract the date. This allows us to determine in a lightweight fashion whether the link is valid for a preview before even sending a query. Links that pass the initial date-check must have queries that are validated and executed against our schema. The schema structure consists of the headline, summary, image, date, and section of a given New York Times article. If a linked article does not have one of these data points, it is omitted. One of the challenges in development was ensuring the preview would work well across the website. Because The Time’s article data is so diverse, our initial prototype received too many omitted data points. To combat this, we implemented a multi-fragmented query request. For example, a preview image in a standard article and an interactive article are often stored in different tables. Fragmenting the query allows the same request to check a wider range of possible requests before a link becomes omitted. We are focused on introducing these preview modules in a manner that complements readers’ experience of Times content and enhances their understanding of it. As such, we’re currently testing the impact of the modules through a series of A/B tests and qualitative research sessions. Our goal is to make sure we are augmenting the reading experience without hindering readers’ ability to easily enjoy content. These tests will help us gauge readers’ appetite for the feature, and find the best way to help readers contextualize the information they read on The Times. Editors note: this project is currently in development and not yet available on the story page. How we design and build digital products at The New York Times 268 3 Design UX Design Code Product Management User Experience 268 claps 268 3 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-11-20"},
{"website": "NewYork-Times", "title": "open questions debbie madden on why companies should hire more women", "author": ["Nick Rockwell"], "link": "https://open.nytimes.com/open-questions-debbie-madden-on-why-companies-should-hire-more-women-480e64eb4fdf", "abstract": "Code Data Product and Design Workplace Culture Work with Us Debbie Madden is the founder and CEO of Stride Consulting and author of the book, “ Hire Women .” After the revelation that she was not being paid fairly in one of her first jobs, she vowed to spend her career ensuring that every team she worked on had equal pay. Her book combines her leadership experience with a framework for creating diverse and supportive workplaces. We talked about how difficult it can be to achieve pay equity, why it’s important to have a diverse team, how to be a better leader and what the future might hold. This Q. & A. has been lightly edited. Q. You start your book, “Hire Women,” with an anecdote about getting sent compensation information for 2,000 people at the company where you worked, and finding out that you were being paid 30 percent less than your lowest paid male peer. In that moment, were you shocked or did you kind of already know? A. I was honestly shocked. This was my second job out of school, and I was happily ignorant on the whole equal pay situation. Up until that moment, I could have sworn to you that I was a vocal advocate for myself. Back then, I believed in meritocracy, and I believed that if I worked hard and produced results, then I’d get paid fairly. But, the world doesn’t work this way. I was only given a raise after I accidentally saw the salaries of my co-workers. The company didn’t fix their salary inequity, they just gave me a few dollars to basically keep quiet about the whole thing. I was furious to the point where I actually didn’t even want the raise. I actually quit shortly after, and vowed to spend the rest of my career ensuring that any team I worked on had a true meritocracy and equal pay. In your book, you point out that creating a good workplace is not just about hiring. It starts with fundamentals like equal pay, zero tolerance policy on harassment and a safe workplace. That seems obvious, but it isn’t, is it? We all want the quick fix, don’t we? It’s not obvious at all. Also, it’s not true that hiring is a quick fix. Hiring well can be just as hard as shoring up the fundamentals. But, before you recruit more people to join your team, it’s a better use of time to make your existing team safe and inclusive for all. Think about it. Why would someone want to join your team if she knows she’s going to be underpaid, or harassed? It doesn’t make any sense. I talked to a woman recently who cares deeply about inclusion, and she asked for my advice on how to hire a more diverse team. As an afterthought, she shared that there are members of her current team that make her personally feel excluded and she’s not certain if she wants to remain on the team. It’s ludicrous that she’d want to find more people to join a team that she doesn’t even feel truly a part of. So first, do whatever you can that’s within your control to increase the inclusion aspects of your current work environment. And then, and only then, can you go out and hire. It bugs me that we still feel like we have to prove the return on investment on creating a diverse, safe or fair workplace. Can’t we just say, this is the environment we want for ourselves and for each other? No. Unfortunately, we can’t just say this is the environment we want. And here’s why: not everyone wants a diverse, safe and fair workplace. This is a harsh statement, but it’s true. There are two types of people who believe that increasing diversity in the workplace is a waste of time: those who believe that diversity doesn’t have a positive impact on team effectiveness, and those who don’t care either way and would rather spend time on other initiatives. Yet, we can’t force people to care about diversity. If we do, we risk our efforts backfiring altogether, because people hate being told what to do. Instead, start with data and empower the team to identify next steps. Diverse teams are three times smarter and 35 percent more productive than non-diverse teams. Increasing the diversity of your team is the best way to achieve a high performing team. And now the question becomes: how do we increase diversity on our teams so that we achieve a 35 percent productivity boost? I do think pay equality is hard. Do you believe that pay should be relative to performance, and if so, is it hard to maintain inequality based on performance while equalizing based on gender and other factors? The short answer is yes: pay should be relative to performance, and no, it’s not hard to equalize for gender. The long answer is: this is a complicated question with a complicated answer. In my book, I detail a four step process for equal pay that I’ve personally seen work very well. The first step of the process requires setting expectations for each role on your team in terms of skill set and level of expertise. Ideally you’ll define beginner, intermediate and advanced expectations for each skill set. Next, create career ladders to show employees what it takes to advance to the next pay level as they become more skilled in their craft. Finally, tie it all together by creating transparent salary bands and promotions at any time. And yes, by this I do mean that promotions can happen 365 days a year. These practices aren’t yet wide spread, but I’d encourage teams to adopt them if possible. I recognize that this is one of those ‘easier said than done’ situations. Many individuals do not have authority or control over salary bands, or promotion process on their teams or in their companies. However, I believe strongly that these are key inclusion practices and should be taken seriously by all companies, no matter how big or small. Talking about and working on bias has been hard and painful for us, but I find that it’s also really healthy and eye-opening. Do you think the work you have done on bias has had positive effects beyond hiring and retaining women? Absolutely. I didn’t write the book to get on a soapbox about hiring women. I wrote the book to start the conversation about increasing diversity and inclusion on all teams in way that is tactical and action oriented. It’s one thing to say we care about diversity and inclusion. It’s an entirely other thing to do something about it. I’ve been working in tech for over 20 years and went to college for engineering, so I’ve been in male-dominated conversations for the past 30 years. Gender bias has always existed and will always continue to exist, because the majority of bias is unconscious. You, me and the rest of the world are biased every day without knowing it. My goal is to change the conversation from “Why me?” to “So what?” Yes, gender bias exists, and so what are we going to do about it? The answer isn’t to feel pity or complain about it. The answer is to accept reality and work around it. There are small, simple steps each of us can do right now that can help make progress here. My favorite thing to recommend is to mentor people outside of your company who are not like you. Mentor someone who is a different gender, age, race or religion than you. Putting yourself in a position where you are an advocate for someone who is not like yourself. This will result in you understanding people who are not like yourself on a personal level and it will change the way you think, hopefully for the better. I really like that you use your position as a CEO to talk directly and publicly about the subjects you are passionate about. It’s hard to do, but it’s important. Do you think that generally leaders ought to talk publicly and directly about the things they say are important? Yes! It’s confusing to me why this isn’t already being done by all. Leaders, by definition, are people who others follow. In order for folks to follow you, regardless of whether you lead a team of two or 2000, you have to share what you’re passionate about. The biggest reason people tell me they don’t talk publicly about their passions is because they are afraid. They are afraid they aren’t saying anything interesting, or that what they want to say has already been said a thousand times before, or that no one will like what they write or say. Yes, sharing your opinions is hard. But guess what else is hard: being a leader. If you are afraid, then start small. Answer a few Quora questions, comment on someone else’s article — you can even start by writing a comment for this article — ask to be on a panel or write an email to your team. Then build upon what you learn over time. Do you think we are getting better? Will the world of work in America be fairer, more inclusive and better in 20 years? Hmmm. I’m not sure. I think that right now, we are certainly talking about diversity and inclusion a lot. It’s impacting many industries right now: tech, government, Hollywood. I’m guessing the chatter will fade into the background again at some point, as it has done in the past. But, real change is possible. And, as a parent, I have to believe that by and large, the world is made up of good people who strive to be inclusive both inside the workplace and out. It’s up to us to keep the conversation going. How we design and build digital products at The New York Times 96 3 Diversity Conversations Technology Leadership Management 96 claps 96 3 Written by SVP Engineering at Fastly, ex-CTO at NYT. Passionate about tech, music, science, art, helping others be their best. How we design and build digital products at The New York Times. Written by SVP Engineering at Fastly, ex-CTO at NYT. Passionate about tech, music, science, art, helping others be their best. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-11-12"},
{"website": "NewYork-Times", "title": "how does this article make you feel", "author": ["Alexander Spangher"], "link": "https://open.nytimes.com/how-does-this-article-make-you-feel-4684e5e9c47", "abstract": "Code Data Product and Design Workplace Culture Work with Us Last year, the Advertising team at The New York Times asked a question: could we accurately predict the emotions that are evoked by Times articles? If so, we could empower advertisers to place ads more relevant to the context in which they are shown. To explore this idea, The Times’s Data Science team launched Project Feels, a project to understand and predict the emotional impact of Times articles. In a nutshell, we built prediction algorithms with large amounts of data collected via crowdsourcing. Our predictions made sense qualitatively, and we ran successful experiments demonstrating that readers’ emotional response positively correlated with engagement on articles. This approach, called perspective targeting , was one of the first data products launched by nytDEMO , a new initiative aimed at helping advertisers place the right marketer stories with the right articles. To be clear: this is an advertising project and was done without coordination with the newsroom; its findings will never impact our news report or other editorial decisions. To learn to predict emotions from articles, we first needed the right data. We surveyed over 1,200 readers who participated voluntarily to create our initial dataset. This was the first time The New York Times ever systematically crowdsourced data for machine learning. We asked respondents how they felt while reading a series of articles and asked them to choose from a number of different emotion categories (which were learned from earlier experiments), as well as a No Emotion category. According to a study from the Pew Research Center , crowdsourced respondents broadly match the type of user we were interested in studying for this project, as they are largely web-experienced, younger, educated and speak English. We know that in online paid surveys, most respondents give thoughtful replies, but some respondents speed through surveys and give meaningless answers. We hit on several steps to limit this behavior, including setting a hard limit on the number of tasks each respondent could complete per batch — this required setting up an external API to record each respondent’s quota. This both improved the diversity of respondents and limited the influence of any single indiscriminate respondent; indiscriminate respondents tend to complete 1,000 or more tasks in little or no time, as we learned from earlier runs. Another way we guarded against indiscriminate respondents was monitoring for consistency of responses: genuine disagreement often occurs on specific types of articles — highly controversial or political pieces, for instance — and follows specific emotional patterns. For example, an article about a politically charged tweet might provoke either hope or hate for different people. A respondent is likely well-meaning if they follow these patterns of disagreement, but a small number of our respondents were clearly outliers in their responses. After collecting the data, we identified and cut out bad data. Researchers typically use a small set of pre-labeled examples, or a gold-set, to detect indiscriminate respondents. Since we did not have a gold-set available, we used statistical techniques to measure task-completion time and disagreement, as described above. We uploaded our articles in multiple batches, which offered us an excellent opportunity to be smart about which articles we chose. In essence, asking respondents questions about difficult articles gave us more information than if we had asked about straightforward articles. Selecting trickier pieces can help a machine learning algorithm achieve high predictive performance with limited data. Identifying these articles in successive batches is called active learning, which is the process of defining what is hard and identifying articles that fit this description. We tried to build the most informative dataset, which meant labeling the articles that are the most difficult to classify. To do this, we needed to define what difficult means to us. A good way to assess difficulty is to see how close our models’ predictions are to random guesses. To understand this, let’s imagine that you need to determine whether a certain article evokes hope. You know that 50 percent of all articles evoke hope, but you are still unsure after reading this particular article. The safe choice is to guess and say that the article is 50 percent likely to evoke hope, because according to the Law of Large Numbers, this guess will be right more often than not. This means that when our model gives a near-average score for an emotion, it too is confused: the article’s text, X, does not help it with its prediction. Just as in the example above, the model (like the human) defaults to the “safe” prediction. (For reference: these are articles with a-posteriori expectations, or p(y | x), close to their a-priori expectation, or p(y)). To train our model to do this, we first collected data on a batch of randomly selected articles, then learned initial predictive models and used these initial models to assess the likelihood an untagged article would contain an emotion. We did this iteratively by sampling new sets of articles for scoring, then updating our models and rescoring. Processing the data this way significantly boosted our performance. We continued sampling batches in this fashion until our models stopped improving in accuracy from additional data. Modeling in data science often involves iteratively testing different model types, starting with simpler models and interpreting their specific shortcomings to determine which complex models to try. We explored three categories of models for this project: Linear methods are typically used when simple, interpretable models are needed. They assume no structure exists in the data: linear models do not capture feature-interactions or feature-outcome-nonlinearity well (I’ll get more into what that means below). In our case, we used these for sanity checks, baselines and active learning. Tree-based ensemble methods are used when higher accuracy is needed. These methods are “catch-all” in that they are used when structure in the data is unknown: they can capture all possible feature-interactions and feature-outcome-nonlinearities. Deep methods are used in cases where ensemble methods can be improved by incorporating prior knowledge about structure in the data. For instance, we know that sentences have structure — words that appear in succession often impact each other’s meaning, so local interactions between words are probably more important than distant ones. I’ll discuss this more below. Linear models were the first models we tried for their simplicity and interpretability. The model took word-frequency as input, but did not observe the order of words. For example, the headline, “Trump Tweets ‘Trump!’” would have been processed as, “‘Tweets’=1, ‘Trump’=2,… ‘Sleeps’=0.” This was like a person reading the words of a headline out of order, assessing the emotion of each word and then adding these all up. Clearly, there was a lot to miss. Though these models performed below our targets, we were able to examine words that the linear model said were most positively associated with each emotion. So, the word “scientist” is more likely to be present in articles that cause interest, while the word “couple” is likely to be present in articles that cause love. To use models that could better assess context, we next turned to tree-based ensemble methods. Using the same input style (i.e. “‘Tweets’=1, ‘Trump’: 2,… ‘Sleeps’=0”), tree-based ensembles are able to consider all the words at once before assessing emotion, which can capture structure and show how words affect each other. For example, the data we collected shows the word “nuclear” alone can cause fear, but it causes hope in the presence of “Negotiate.”The left panel in the visual below illustrates this statement, whereas the right panel illustrates another aspect of trees. Unlike a linear model where, say, if the word “attack” causes fear, then “attack” used 10 times causes more fear, tree-based models can capture nonlinearity. Nonlinearity between features and outcomes occurs all the time in real life. For instance, if an article uses the word “Economy” just once, it might be a jobs-report article. These tend to cause hope. (Note: The current models were focused on U.S.-based respondents and thus captured U.S.-based emotional reactions to news.) Ensemble models out-performed our linear model, leading us to believe that careful modeling of interactions and nonlinear effects could improve accuracy further. At this point, we had enough evidence to believe that deep learning methods would work. Deep learning, or neural networks with many layers, are often used to model specific complicated input types such as word sequences or pixels in an image. Various assumptions about the way these features interact — for example, proximal words might interact more than distal — can be encoded in the network structure. Deep learning methods typically require large training datasets to perform well (on the order of millions of examples). The size of our dataset was too small for many of the architectures we experimented with. We used pretrained layers to enhance training. Overall, we deployed the max-scoring classifier for each emotion, measured using area-under-curve ( AUC ) as our accuracy metric because of the unbalanced nature of the labels. We found that generally, deep architectures gave us performance increases for predicting many emotions, but did not outperform ensemble methods on all of them. All of our accuracy tests were calculated based on articles published after the articles used to train the model. This helped us evaluate how our models would perform on news events that emerged after training. This was important to us because it prevented our models from overfitting on topics. For instance, if during a specific time window, every article about trade was about trade wars, a model would learn that “trade” always leads to fear without considering that in new contexts “trade” might evoke hope. We wanted our models to focus on language patterns that signaled emotions, not topics. This is what our work looks like in practice. Below is a sample of articles that our models identified as having high levels of certain emotions (the articles were not included in our training set). The results look accurate, but we monitor on an ongoing basis to ensure that these results are logical. An Elderly Couple Named Harvey and Irma Offered a Respite From the Summer’s Storms (Love) Heartburn Drugs Tied to Stomach Cancer Risk (Fear) City of the Future? Humans, Not Technology, Are the Challenge in Toronto (Interest) To evaluate how well these models could differentiate articles, we partnered with The Times’s Advertising and Marketing Services department to perform an ad-effectiveness campaign. Ads were screened against top-scoring articles in each emotional category (and a baseline) in a controlled experiment over a period of two days. We tracked performance across a wide variety of metrics. Our goal was to see whether ads on emotion-tagged articles performed better or worse than our control, and whether emotions performed differently. Across the board, articles that were top in emotional categories, such as love, sadness and fear, performed significantly better than articles that were not. We saw significant differentiation between articles tagged with emotions, showing that readers’ emotional response to articles is useful for predicting advertising engagement. We were able to build a performant set of models that predicted the emotions articles would evoke in our readers. We tested that these models performed well over time both in offline evaluations, spot checks and online experiments. Because we built our dataset using crowdsourcing, we showed that we could incorporate reader feedback in a systematic way to learn new insights about our data. Does this work sound interesting to you? We’re hiring! Come work with us . How we design and build digital products at The New York Times 322 3 Machine Learning Journalism Deep Learning Data Science Data 322 claps 322 3 Written by Data Scientist at the New York Times. How we design and build digital products at The New York Times. Written by Data Scientist at the New York Times. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-10-31"},
{"website": "NewYork-Times", "title": "kickoff kit tools to help teams work better together", "author": ["Sara Bremen Rabstenek"], "link": "https://open.nytimes.com/kickoff-kit-tools-to-help-teams-work-better-together-3ca6a06b4fc2", "abstract": "Code Data Product and Design Workplace Culture Work with Us In order to build products successfully and quickly, your team has to work well together. But so often teams dive into projects without recognizing how each member best operates or what everyone is working towards. My colleague Rosy Catanach and I have started lots of projects with various teams, and we have seen what happens both when these steps are addressed (productive, positive progress) and when they’re skipped (confusing, frustrating, slow process). Rosy is currently an Executive Director of product and I am a product director here at The New York Times. We pulled together a collection of exercises that we’ve found to be helpful in aligning a team in order to move forward quickly and productively. Last June at SRCCON , we presented the exercises in a session we called Kickoff Kit. The idea is that as a team “kicks off,” either with new members or with a new project, they can avoid bigger disasters in the product development process later by using this kit of exercises. Misalignment is completely natural at the beginning, especially when working with cross-functional teams made up of people from different disciplines. Here at The Times, we’ve found that not only do we need to account for the difference in style between engineers and designers, but also with journalists. The newsroom has long-held traditions and ways of working, some of which run counter to an agile development process. Cross-functional teams — with journalists and editors — make excellent products, they just have to take the time to make sure they’re setup for success and are working toward the same goals. The exercises we pulled together come from lots of different sources. Some focus more on work habits and preferences, while others are geared more towards a shared understanding of the product’s goals and trajectory. All of them can be found in this .pdf and I’ve highlighted three of them below: Muppet Analysis; How We Work Best; and Hopes, Fears, and Non-negotiables. Why it’s important Building heavily on Slate’s Chaos Theory of Muppets , the theory goes you are either an order or a chaos muppet. Neither is good or bad, and a well performing team has a good balance of order and chaos muppets. This exercise will help each team member identify their own muppet style and better understand how they can work together as a team. Instructions Have each member of the team take the quiz (see below) to identify themselves as order or chaos. On the worksheet, choose A or B for each statement. If you are in between, choose the one that you tend to do more — this is intentionally binary! Tally how many As and Bs you get. Answer Key 7 or More A’s — Mostly an Order Muppet 6 A’s — Centrist Order Muppet 6 B’s — Centrist Chaos Muppet 7 or More B’s — Mostly a Chaos Muppet Takeaways and Follow-ups Go around the room and have everyone share their results. Talk through how the makeup of the team could impact the work ahead. Different team makeups will have different benefits and concerns: Example This exercise is particularly helpful when a team is going into a Discovery phase of a project, when there are lots of unknowns and the future can be ambiguous. Acknowledging everyone’s level of comfort with ambiguity may not make the process easier, but at least the team can develop empathy for how some members might be feeling. Why it’s important How do you work? How do other team members work? Use this worksheet to identify characteristics of your team and help create team norms. Instructions Have worksheets (see below) and Sharpies ready for the team. Give the team five to 10 minutes to mark where each of them falls on the spectrums. For example, if you are definitely a morning person, draw an X on the far left side of the first spectrum. Takeaways and Follow-ups After everyone is finished, go around and have each team member share their results. Talk about what team norms you can identify based on these preferences. Create a master set of the spectra on an easel pad or large piece of paper. Have each team member write their initials on seven Post-its or stickers and place them on the master set. Displaying the results altogether will help identify balances and imbalances. Example One of the most common differences this exercise helps to surface is the way newsroom staff are often trained to have everything perfect before “hitting publish.” Interaction designers, on the other hand, tend to prefer getting an MVP out to users quickly, knowing things aren’t perfect, in order to get feedback. Having a conversation about this tension early in the process can go a long way in mapping out a team’s roadmap and setting expectations. Why it’s important Secrets grow in darkness. Bring to light your team’s hopes, fears and things they’re not willing to give up so that issues don’t appear when it’s too late. Use this exercise to build trust among your team members as they better understand where each other is coming from. Instructions Have Post-its (ideally in three colors, one for each category) and Sharpies ready for the team. Spend three to five minutes on each category: Have everyone put all of their hopes in one pile, fears in a second pile, and non-negotiables in a third. Takeaways and Follow-ups Start with one category. Go around the room and have each person take a Post-it and read it. It doesn’t have to be theirs — anonymizing the ideas can help alleviate awkwardness and have the team share in honoring each one. Document the results, especially the Non-Negotiables, so that they can be referred back to later as needed. Example A common “non-negotiables” we hear is that the product or feature needs to be “Timesian.” That is, whatever we build must comply to the editorial and journalistic standards of The New York Times. Surfacing the concern helps the team not only acknowledge the standard, but also arrive at a shared definition of Timesian-ness. What are the qualities that we need to protect? What are the boundaries we could try to push on? If this kind of work feels completely weird and foreign, that’s okay! Go for it. And here are a few tips we can offer as you start out: Don’t use all the exercises at once. Maybe start with one to get the ball rolling, but pay attention to team dynamics and understand what’s needed. Some exercises might make sense for your team at the beginning, while others might be more effective later in the process. When in doubt, have a conversation and see what the team thinks. Don’t get lost in process. Talking about doing the thing is not the same as doing the thing — you still have to do the thing. These exercises can — and should! — be fun, but they’re not a substitute for building products. Do be honest, empathetic and grounded when running these exercises. Big emotions can come up and you need to make sure team members feel safe to express them. Remember that feelings are neither right or wrong. Lead by example. Want to run a workshop with your own team? We’ve made the kickoff kit worksheets available for download. You can access them here . How we design and build digital products at The New York Times 725 1 Process Team Building Product Management Office Culture Teamwork 725 claps 725 1 Written by Sara is a product director at The New York Times, focusing on reader experiences. How we design and build digital products at The New York Times. Written by Sara is a product director at The New York Times, focusing on reader experiences. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-10-28"},
{"website": "NewYork-Times", "title": "growing a successful and collaborative team", "author": ["Akhilesh Nayak"], "link": "https://open.nytimes.com/growing-a-successful-and-collaborative-team-4e4c608ab2fc", "abstract": "Code Data Product and Design Workplace Culture Work with Us Over the past few years, The New York Times has gone all in on becoming a subscription-first business and I’m delighted that we are absolutely killing it . To help support this growth, the Ecommerce Core engineering team has ramped up development on a number of features and backend services for our digital subscription business. Our work helps product teams build great experiences for customers, report growth accurately and drive revenue. The engineering team has grown a lot since we launched the paywall in 2011. As one of the early team members, I’ve gotten to see the team triple in size over the past few years, and I have been able to participate in shaping the tech, processes and culture of the team. The tech that powers your business can also be used to mitigate inefficiencies in your team’s day-to-day work. Our team has had great success in making technology improvements as we’ve scaled. This has allowed us to work faster, delivering the right capabilities to the business sooner while also building reliable and resilient software. In the early days, we would usually release our code to production once a month using a pseudo git-flow branching model. Individual developers would work in a feature branch that could be active for a few weeks. When the feature was ready, they would merge it into a feature-testing branch (hence the “pseudo git-flow”) and then deploy this branch to staging where the feature would be tested by our QA team. Once the QA team approved the feature, it would be merged into the development branch. Two weeks before we were scheduled to launch the feature, the release manager would cut a branch from the development branch and deploy it to staging. Once it was deployed, the QA team would run an entire regression cycle using both manual and automated test cases. We would often find bugs at this stage — this is a bad time to find and fix bugs — and would have to fix them directly on the release branch. Pulling a feature out of a release at this late stage was a painful and fraught process because we would need to manually remove all of the code related to the feature. Overall the entire process was slow and inefficient. The team has come a long way since then. We’ve taken the time to set up a continuous integration and delivery (CI/CD) pipeline using Jenkins and added a suite of over 1500 automation tests for our software. Investing in our tooling has paid dividends as we’ve grown the team. I can only imagine the chaos we would have if we were running the old process with our larger team. The CI/CD pipeline and the automated tests have allowed us to: Deploy software everyday, thus reducing lead time and the risk that comes with making large changes all at once Find and fix bugs quickly and prevent regressions Be more confident that our software works as intended Have more assurance that we haven’t broken anything when we’re refactoring Streamlining your deploy process is a great way to improve productivity and effectiveness, but I must also caution against using technology as a golden hammer for every problem. Not all problems are technology problems. Using tech to paper over a people problem will come back to bite you in the long term. Great process helps people work more effectively with each other, establishes ground rules for what needs to get done and provides guidelines on how to get there. The challenge with process is finding the right balance between giving enough support to teams without micromanaging them. It’s important to make sure they can complete their responsibilities in ways that work for them. For the last few years, our team has had a weekly on-call “production support” rotation for all engineers. Team members on production support are the first line of defense in identifying, triaging and fixing issues that surface in our production environment. Issues can be anything from investigating and repairing outages to troubleshooting database slowness. The production support process has undergone many changes over the years, but here are three main changes we’ve implemented: We used to have subject matter experts who would be expected to maintain a particular feature. But now the engineer on call is responsible for monitoring all code and systems. They are encouraged to ask for help if they need it, especially if they’re looking into an issue with something they’re unfamiliar with. This serves as a great way for people to learn about systems they haven’t worked on before and encourages collaboration. We’ve recently added a backup person to our rotation to help with a spike in support items so that we can get ahead of the issues. We’ve created documentation with runbooks of common support tasks in order to make it easier to onboard engineers to production support. This also helps maintain a knowledge base. While it can be easy to get away with having fewer processes with a small team, it gets more important once the team grows. Ensuring the team shares an understanding of how to handle technical bumps in the road is paramount to the team’s success. There’s a saying that culture eats strategy for breakfast — no matter how good the strategic vision you have in mind, its success is dependent on what people are empowered and incentivized to do. Improving culture is an impactful and long lasting way of changing organizational behavior for the better. One way to influence organizational culture is to have people who exemplify your values be role models for folks newer to the organization. When teams grow rapidly it’s harder to have new members imbibe the existing culture. As our team has grown we’ve adopted pair programming as a means to imparting cultural wisdom to new hires. A few years ago, we incorporated pair programming into our team culture to help onboard new colleagues and help them acclimate to our team and codebase. We haven’t looked back since. Pair programming has become how our team works on projects. Whether it’s getting quick feedback on technical design, helping find the root cause of a bug or just regular feature development, having a second set of eyes and mind to think through a problem is immensely helpful. This encourages a collaborative culture and builds a stronger team, which is instrumental in delivering larger projects. Pair programming is an effective means of communicating cultural norms to new hires. We pair new hires with more tenured engineers for their first few months in order to show them the ropes and help convey how we expect them to contribute to the team. It also has the added benefit of introducing team members to different ways of working. I have learned many nifty development tools and tricks from my colleagues over the years just by watching how they accomplish tasks. The Ecommerce Core engineering team continues to iterate on our technology stack, our process and our culture as we grow. We believe that these three things are important tenets in what makes a great team. If this sounds interesting to you we’re hiring . Feel free to reach out to me if you’re interested! How we design and build digital products at The New York Times 46 Continuous Integration Office Culture Workplace Tech Team Building 46 claps 46 Written by Software Engineer @ The New York Times How we design and build digital products at The New York Times. Written by Software Engineer @ The New York Times How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-09-27"},
{"website": "NewYork-Times", "title": "dont negotiate be persuasive", "author": ["Katherine McMahan"], "link": "https://open.nytimes.com/dont-negotiate-be-persuasive-f45b3db93c2e", "abstract": "Code Data Product and Design Workplace Culture Work with Us I’ll be honest, when I signed up for Persuasion, Influencing Without Authority , at Columbia University’s School of Business, my intention was to learn how to convince people to do what I wanted them to do. As a program manager, I rely on soft-authority and social capital to get things done. Both of which take a lot of time and patience. The course promised to help teach tactics on how to communicate better with your team, how to leverage soft power, and how to help persuade others to see your point of view. I wanted a secret shortcut, so I signed up for the course. I firmly subscribe to the “strong opinions, loosely held” mantra that was taught to me by a mentor and friend. However, in environments with strong willed, brilliant people, loosely held opinions can easily get overlooked. I had to find a way to unlock that secret. What I learned, however, was that like everything else, persuasion takes time, effort and above all else, self awareness. Through case studies, lectures and small group activities we learned the basic principles of persuasion. We began with a negotiation exercise, to illustrate the differences in persuasion and negotiation, and then we moved onto more specific examples of persuasion: car salesman, PTA scenarios and corporate change management. At each step we were given the scenario, asked how we would address and then we would evaluate together. Ultimately learning different tactics from each exercise. My key takeaways from the course are this: Persuasion is not negotiation. There is a lot of overlap between the two, but persuasion and negotiation are different. Negotiation is about making the first move and anchoring the conversation in the arena that you want. Persuasion is about meeting the other person where they are. Both have their time and place, but you need to know which one you’re getting into. Always prepare. Persuasion takes time and can often be difficult, so just like any tough meeting or presentation, you have to be prepared. What are you goals for the conversation? What do you think the other person’s goals are? What are all of the steps between your goals and their goals? Know yourself . Before you can convince anyone of anything, you have to know how to communicate with them. In order to that, you first have know how you communicate. Everyone has different communication styles, so once you know yours, you will know what may be successful or off-putting to people with different styles. There are many models to help you identify your style, Myers-Briggs , CARE , Chaos vs Order Muppet . Any one of those can help you better understand your strengths and weaknesses. Control yourself. Great, you know how you communicate. That will only get you so far. You have to control your natural instincts so that you don’t alienate the people you’re talking to. The minute you lose control you will lose them. For example, you and your superior disagree on what new feature your team should build in the next sprint. You rely on data and want to make a decision by looking at interaction data, while your boss keeps coming back to the testimonials from users. Instead of making your case with a lot of numbers, you should come prepared with testimonials. In fact, going too deep into the numbers may cause them to space out and miss the point that you’re trying to make. Know who you are speaking to and communicate in their style . It is important to know how your audience processes information. If I am trying to persuade someone who is an introvert and loves data, I should not try to make my point with a long story because they won’t hear me. I need to come in with specific metrics and sources that make my point. Did I leave the course with a magic trick to get people to do what I want? No. I learned that I need to get better at identifying how others communicate and meet them there. As much as I love a good story, it’s only going to get me so far. So now I need to practice — who wants to meet up for lunch and run scenarios? How we design and build digital products at The New York Times 60 1 Office Culture Management Negotiation Career Advice Careers 60 claps 60 1 Written by program manager @NYTimes, executive producer @BBQFilms, amateur baker, movie watcher, nerd How we design and build digital products at The New York Times. Written by program manager @NYTimes, executive producer @BBQFilms, amateur baker, movie watcher, nerd How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-10-04"},
{"website": "NewYork-Times", "title": "flexible icons with react svg", "author": ["Scott Taylor"], "link": "https://open.nytimes.com/flexible-icons-with-react-svg-973f310e6382", "abstract": "Code Data Product and Design Workplace Culture Work with Us I am old enough to remember when IE didn’t properly support transparency in PNG files. I am old enough to remember when PNGs were new, a better alternative to GIFs. I am old enough to remember spacer GIFs. These weren’t just things I read about, they were problems I had to work around at my job as a software developer. #dark The web has matured in a million different ways since the 2000s, and things that used to be hard or a pain are now quite easy. Even though new and shiny tech exists, it does not mean companies are immediately taking advantage of all of it. Getting an entire organization to change their workflow or setup is still hard. We have been upgrading a lot of our workflows at The New York Times in the past two years, and most of The Times is now served via Node and React. In switching to React, we have been able to unlock entirely new techniques for rendering our UIs. I would like to focus on one of them: rendering icons and logos as SVG. A logo is often provided by a designer. If it’s an image file, it is typically a PNG with transparency. If you live in a modern world, the logo is provided to you as a scalable vector graphic (SVG). We prefer SVG because it means we can change the size of the image without degrading its quality (and without having to go back to Photoshop or Sketch). It also means we can change the color(s) of the logo without exporting a new file. However, most of the SVGs we as developers receive from designers do not make this so obvious. It is also not always apparent what the “best practice” is here. When do I use SVG? How do I use SVG? If you’ve never interacted with the contents of an SVG file, MDN has great docs and tutorials , as per usual. Remember one thing: SVG is HTML and HTML attributes can be dynamic in React. We use React to render SVG (since it’s HTML!). All of this being true, our redesign of The Times over the past few years still suffered from a problem: for each logo, designers tended to make a new file if they needed a new color or if they needed a different size. We ended up with a gang of files like: One icon I found had eight variations, which meant it had eight files. When you open one of these files, you see the inner brain of the design program trying to make sense of a line drawing: Just like you wouldn’t accept the HTML output of Dreamweaver as law, you don’t need to accept this SVG content as law. Most of the output you get from design programs contains extraneous and unfortunate-looking XML. You can get rid of this junk by running the file or its contents through SVGOMG , an online GUI for manipulating and optimizing SVG. I usually just paste the markup of a file into the “Paste Markup” tab. After doing so, you get a preview of your icon and a chance to copy the optimized output. After pasting the above file, I got this markup: As you can see, our icon can actually just live as one <path> element. The d attribute value is simply a list of instructions: the numbers act as offsets, the letters tell the numbers how to behave. viewBox describes our icon’s area: 0 0 16 16 means that the numbers in d are related to an area 16 pixels by 16 pixels in dimension. It does not mean that the icon is limited to being 16 pixels by 16 pixels, it means that the instructions have a relationship with this theoretical size. We also notice that the color of the icon is controlled by the fill attribute. It should be obvious by now, but changing the value of fill will make the icon a different color. That’s great and all, but how are we supposed to change the color if the contents of the SVG are in a static file? This is where React comes in. Because SVGs are just HTML, and JSX is HTML, we can use SVG like any other nugget of HTML. Here’s our logo as a React component: We now have a React component that encapsulates our icon, and gives us the ability to change the value of fill with a property. We can use CSS to do whatever else we want to the icon, including setting a different width and height. As you can see, we never need to create another file whenever we want to change size or color. I’m using CSS-in-JS in these examples — if the syntax is foreign to you, take a glance here: medium.com You can even change the value of fill using CSS since path is just an HTML element and fill is a CSS rule: The logo in the masthead of The Times’s website works exactly this way. All of these logos are the same React component: In fact, many of our icons are rendered inline as HTML. Previously, to optimize them, we rendered the base64 inline representation of them as background images in SCSS. That technique is O.K., but doesn’t compete with the flexibility we get using React. After using a tool like SVGOMG, your SVGs will probably be much smaller anyway. Because our above approach gives us icons that are just React, we can share them in NPM packages or across render targets without needed a static file server. At The Times, we do just that. Icons as SVG as HTML as React can be used on the web, in our CMS editor and in the render tool we use for our native apps. If we required the files using Webpack, every render target would be a required to use Webpack. Any codebase that generates HTML from React can share our icon components. How we design and build digital products at The New York Times 852 7 SVG React JavaScript Styled Components Code 852 claps 852 7 Written by Musician. Lead Software Engineer at the New York Times. Married to Allie. How we design and build digital products at The New York Times. Written by Musician. Lead Software Engineer at the New York Times. Married to Allie. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-10-16"},
{"website": "NewYork-Times", "title": "open source automating release notes in github", "author": ["Yuraima"], "link": "https://open.nytimes.com/open-source-automating-release-notes-in-github-dd08f964465c", "abstract": "Code Data Product and Design Workplace Culture Work with Us For most software teams or projects that use GitHub, the process to push code to a production environment looks similar. A developer opens a pull request, or PR, which then gets reviewed by another developer who might suggest some changes. After the changes are made, the PR gets merged into the project’s master branch. When the team is ready to make the updates public, they’ll tag the commit or branch as a new release and get the option to add a release note. More often than not, the release notes get left off because they’re tedious to add. Release notes are a way to track the changes that are part of a particular release and monitor the progress of a project over time. They are particularly helpful if you want to find out if a release contains a feature you’re interested in, need a reference of where a bug could have been introduced. A quick look at Webpack ’s releases (below) shows that with every new tag, they include a list of features and bug fixes in their notes, making it easy to see exactly what changes occured. The New York Times Reader Experience team uses release notes to keep track of what we build to our production environments. This helps us communicate to stakeholders when new features or bug fixes are available, gives QA engineers a heads up on what changes to verify on staging and provides us with some insight if rolling back to a previous build is necessary. But as useful as release notes can be, they’re only as good as you write them. In the past, our dev team begrudgingly wrote releases manually. It’s a time consuming task and we found that it was hard to remember everything going out in a release, especially if it had been a few days since the previous build. Our negligence in writing release notes sometimes resulted in unhelpful notes, like this one: All of the benefits of writing release notes go right out the window as soon as we start letting them slip. So, like any proper (lazy) engineer, I decided to automate the process. My team later adopted it for our projects. We built Chronicler , a simple Node.js app that automatically adds merged pull requests to a release note draft. When we’re ready to push a release to production, we tag the latest release draft with its list of PRs and off it goes. Here’s what our neatly packaged releases look like since replacing a dev with Chronicler. With automated release notes we know exactly what PRs are going out with each release and we only have to tag, name and publish the release. The two major players in our release-drafts tool are the GitHub API and GitHub Webhooks . GitHub Webhooks subscribes a service, like Chronicler, to receive events related to a repository. Whenever a specific event occurs, like a pull request being merged, Webhooks sends Chronicler data about that pull request. When Chronicler receives a Webhook event for a merged pull request, it makes a call to the GitHub API for a list of that repo’s releases. When it receives the list, it inspects the most recent release to see if it is a draft. If it is a draft, it will append the PR title and number of the webhook event to the draft body and send a POST request to update the release note draft. If the most recent release note is not a draft, Chronicler will make a request to the GitHub API to create a new release note draft using the PR data from the webhook event. For anyone who wants to free themselves from manually creating release notes, we’ve open sourced Chronicler . You’ll need to clone the Chronicler app and set it up in your own environment (we’re using a simple instance of Google App Engine, but Chronicler can work with a variety of configurations), create a GitHub personal Access Token and secure app secret, then connect your Chronicler instance to your repository’s Webhook settings. Check out the repo README file for more details on how to get started. How we design and build digital products at The New York Times 132 3 Github Open Source Technology Code Release Notes 132 claps 132 3 Written by Sr. software engineer @ The New York Times, professional 🐶 greeter, perpetual 🌮 seeker, occasional public speaker How we design and build digital products at The New York Times. Written by Sr. software engineer @ The New York Times, professional 🐶 greeter, perpetual 🌮 seeker, occasional public speaker How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-09-20"},
{"website": "NewYork-Times", "title": "how we hire front end engineers at the new york times", "author": ["hamman"], "link": "https://open.nytimes.com/how-we-hire-front-end-engineers-at-the-new-york-times-e1294ea8e3f8", "abstract": "Code Data Product and Design Workplace Culture Work with Us If you’re a regular reader of the Times Open blog, you hopefully know that we are proud of the engineering culture at The Times. As a VP of engineering and someone who has been with The Times for 11 years, that culture is why I’m here. I love being surrounded by a diverse, multi-talented, collaborative, mission-driven group of engineers, designers, data analysts and others who contribute to the making of our products. Over the last few months, we have been tackling probably the biggest determinant of our culture: our hiring process. Our old process had problems we needed to address. With many similar jobs posted at any given time, candidates would often apply to multiple jobs and be confused about which they were considered for — or worse, they were asked to interview multiple times for multiple teams. Since our teams had different criteria for hiring engineers, they also didn’t trust each other and would sometimes give technical interviews when engineers wanted to transfer teams internally. Over the years, we’ve lost several external and internal candidates who wanted to be at The Times but were frustrated by having to prove themselves again and again. We recently made a major change: rather than having separate job postings and interview processes for each team, we consolidated to a single application and review process across all our front-end openings. By having a single application process, we hope to help candidates match to the teams that best fit their career goals early in their application. This will also make it easier for candidates to change teams and grow their careers once they’ve been hired. Having a single application process also ensures that we are being consistent and fair about how we evaluate candidates however they come to us. This was not an easy or comfortable change. Individual teams feared they would lose the ability to find candidates that fit their particular needs. We also had concerns that the process would become too impersonal and candidates would not be able to get to know the team they would join. We ultimately concluded that this process reflects the type of organization we want to be: one with an expansive definition of team where we take broad responsibility for the career development of engineers we hire. As a front-end engineer at The New York Times, you will work on a specific engineering team tackling a problem, but also join a larger community of engineers across the organization. I’m sharing our process here in the hope it will help others thinking about their own hiring process, and as a guide for what to expect if you’re interested in applying to The Times. (And please do apply !). If you are interested in a front-end engineering role at The New York Times, the first step in the process is to apply . As you’ll notice, the application explains what the role will entail, the qualities that help engineers thrive at The Times and it lists the teams that currently have open positions. Each week our Talent and Inclusion partners and a panel of engineering managers review resumes and decide who to move forward in the process. Depending on the number of applications at any given time, you should get a response within one to two weeks. If the hiring panel thinks your resume matches what we’re looking for, you’ll be scheduled for a phone call with someone on our Talent and Inclusion team. That call will focus on the kind of work you’ve done to date and what you’re looking for in a role at The Times. The goal is to begin to match you with a team and to make sure we have something that fits your career goals. Ideally, this will happen within a week of you submitting your resume. Next you will have a phone call or Google Hangout with a hiring manager or a senior engineer on one of the teams you are being considered for. This call will be an opportunity for us to evaluate your technical skills and how you work. It’s also an opportunity for you to find out more about the different openings and what it’s like to work as a front-end engineer at The Times. If there’s mutual interest after both conversations, we’ll then send you a short coding exercise that you can complete on your own time. We understand that people have busy lives, so there is no time limit. The project won’t require you to dig up any old computer science textbooks or learn a new programming language, and we’ve heard from previous candidates that it’s even fun! It’s meant as an opportunity for you to show us how you would think through a project along the lines of something you might do at The Times. If you pass the coding exercise, then the final step is a set of in-person (or remote) interviews. During these sessions you will meet with engineers and non-technical members of at least two teams that are the best fits based on your previous conversations. Each interview should be between 30–45 minutes with two other people at a time. We have you meet people in pairs to minimize the bias of a single interviewer, but not to overwhelm you. The entire interview day should take roughly four to five hours. Yes, that’s a lot, but we’ve found that candidates appreciate meeting a number of their future team members and having the opportunity ask questions. We also think it’s important that multiple members of the team, not just engineers, are involved in hiring. We are now six weeks into this new process and have candidates at every stage, from resume review to in-person interview. We are evaluating the process as we go and, like in everything we do , have already made changes to how we score and evaluate resumes. We are accepting applications now, so please apply . We look forward to hearing from you. How we design and build digital products at The New York Times 1.3K 5 Hiring Technology Code Workplace Culture Management And Leadership 1.3K claps 1.3K 5 Written by I'm a VP of Engineering at the New York Times. How we design and build digital products at The New York Times. Written by I'm a VP of Engineering at the New York Times. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-08-24"},
{"website": "NewYork-Times", "title": "a faster and more flexible home page that delivers the news readers want", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/a-faster-and-more-flexible-home-page-that-delivers-the-news-readers-want-1522ff64aa86", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Matt Douglas, Kristen Dudish, Elena Gianni, Kellen Henry, Melissa Loder and Dan Sherman For many of our readers, the New York Times desktop home page is an important and familiar place to connect with the news each day. It hasn’t changed much over the last decade, even as the story formats we use, the platforms we support and the ways our readers consume content online have rapidly evolved. We’ve invested heavily in making our mobile apps expressive and visually dynamic, but our desktop website has lagged behind, powered by a siloed and aging set of tools. These fractures in workflow and technology have meant our newsroom editors and our engineering teams had to do duplicate work across multiple systems for our mobile apps and our desktop website. They weren’t the only ones. Whenever readers switched between devices, they were met with different reading experiences, which made it hard for them to follow their interests and gave them an inconsistent experience with our brand. In a few weeks, we will update our desktop home page experience as a final step to bringing readers a consistent experience across all of our platforms and screens. Readers who visit us on mobile have already seen many of the changes. But with the desktop rollout, readers will be able to engage with the stories that interest them most on all of the devices they read The New York Times. We started our home page project with plenty of data about what people chose to do there, but it was more difficult to tell from the numbers why they made those decisions. As a product and design team, we always want to go beyond what readers say they like and dislike to understand how reading, watching or listening to our stories fits into their lives. We realized that in order to help our readers go deeper, our team had to engage deeply with our readers. We visited them at their homes and got to know them. Then we asked them broad questions about how the the news fits into their day — or doesn’t. “How do you start your day?” “What helps you stay up to speed on current events?” “How do you decide what to read?” We came away from those interviews with a better understanding of three major needs our readers wanted to fulfill on our home page: First, they wanted to catch up on the latest news and find out what they might have missed. Second, they wanted to deepen their understanding of major events through analysis and opinion articles. Lastly, they wanted to discover something unexpected from our wide variety of stories and sections. We also came away with a strategy for how to help our readers meet those needs. Readers said they wanted us to curate their experience on the home page, but not limit it. We needed a system that empowered them to follow their own interests. At the same time, readers wanted our help to navigate a chaotic world of information overload and filter bubbles. We used those insights to begin sketching out possible ways to address reader needs that also mapped clearly to our mission and goals. While we design layouts and custom-made typography with care, we also know what truly makes or breaks the reading experience is the content itself. Our readers told us loud and clear: what matters is access to New York Times journalism. To test our initial concepts, we needed to see how they would hold up with real news flowing through them. So we created a series of prototypes to gather feedback from a small panel of readers. Our first round of prototypes were pretty crude. We built them quickly, with the intention of testing our assumptions and threw most of them away after gathering data. We started out with simple paper prototypes. (Our favorite was a cardboard and paper iPhone we nicknamed “The pPhone.”) The more prototypes we built, the more confidence we gained. We knew we probably weren’t going to get everything right the first time (spoiler: we didn’t). But we also knew how much we could learn when we got things wrong. Once we gained confidence through paper prototyping, we moved on to a higher-fidelity web prototype and recruited a few news editors to run it using some bare-bones publishing tools. While our readers helped articulate the original needs that inspired our designs, our prototype editors were instrumental in stress-testing our concepts. They gave us feedback on how well the stories they wanted to highlight fit into our proposed structure and helped us calibrate what areas of the page needed to be elevated or suppressed. Having editors join the conversation early on helped us quickly understand what was working and what might be missing. The editors were also candid with us about standard newsroom practices and internal dynamics that we needed to consider. The first time a major story broke, we learned that our system and tools would need maximum flexibility to support a wide variety of news scenarios. Throughout this design process, many members of our product, design and engineering teams also volunteered to curate the home page for a day to gain first-hand experience of what the home page workflow was like under the constant pressure of breaking news. Embedding directly with our news editors showed that we were committed to making our home page work for them and gave us plenty of empathy for what it takes to produce the home page every day. By working closely together, we developed a version of the home page that was polished enough for wider distribution. To prepare for a larger-scale rollout to a subset of readers, we worked with our internal tools teams to build more realistic tools that let the newsroom curate the new version of the home page. While we always planned to launch a fully responsive home page, our early tests left us most confident in our new features at the mobile breakpoint. We solidified and rolled out our changes to all mobile readers in October of last year. Creating the right layouts to scale our newsroom curation efforts up to more complex desktop and tablet layouts took our team another cycle of iteration. With mobile fully live, we launched our initial desktop concepts to a small percentage of readers, and studied metrics and qualitative survey feedback closely, while making adjustments. Early in our desktop test, we focused on showing readers the breadth of our coverage. We limited the number of prominent stories at the top of the page and used layouts that highlighted more of our photography. The page layout was airy and encouraged readers to scroll more. But readers pushed back. While they didn’t want to be overwhelmed, they were eager to see more related news stories in order to get a complete picture of the day’s news. The ratio of photography to information also felt off. In a news cycle where much of our major news came from Washington D.C., the photos of politicians in suits soon felt repetitive and stale from day to day. In order to give readers a more nuanced picture of the news and editors the flexibility to choose which visual and text elements to highlight, we developed a system of tools and layouts that let editors group a few related stories into a “story package.” Creating a system for packages that would work across every device and support all of the possible grouping combinations was a complex design and development task, but it ultimately gave us more flexibility to create strong presentations for every news situation. It also helped the page look more dynamic for readers because there was more depth and density at the top of the page. We also added visual differentiation between hard news stories and softer features to help readers quickly distinguish between types of content. This provided a better visual rhythm on desktop where stories are frequently displayed side by side. Our home page update is a significant step forward in helping our readers meet their needs across all of their devices. Our investments in a new technical architecture will make the site faster for readers and more flexible for our teams. We are confident that the system of story groups and packages we’ve created will allow us to continue evolving the experience in ways we can’t even imagine today. We’ve created a system that’s rooted in highlighting both what our readers feel is important to read and what they want to read. Best of all, it can grow and adapt as those needs do, too. Matt Douglas and Melissa Loder are the home page team’s product leads. Kristen Dudish and Elena Gianni are the home page team’s design leads. Kellen Henry is the home page team’s newsroom lead. Dan Sherman is the home page team’s tech lead. How we design and build digital products at The New York Times 3.7K 33 Design UX Design Product Development Design Thinking Media 3.7K claps 3.7K 33 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-01-08"},
{"website": "NewYork-Times", "title": "we dont just develop software we re developing careers too", "author": ["Bailey Evans"], "link": "https://open.nytimes.com/we-dont-just-develop-software-we-re-developing-careers-too-5f4e28e3eee6", "abstract": "Code Data Product and Design Workplace Culture Work with Us It hopefully doesn’t come as a huge shock that we, the technology department at The New York Times, want our people to develop. We’re not just talking about software; We want our colleagues to develop their careers in meaningful ways. More importantly, our people want to have the opportunity to grow. And we want colleagues who want to grow, not just as Times employees but as people. On an organizational level, we want a culture where we learn in everything we do — when we fail, when we succeed and all of the steps in between. The Times has taken steps to facilitate this culture through a tuition reimbursement program, a conference budget, an annual innovation week called Maker Week , internal trainings, speakers and more. But there are gaps, and there always will be. With technology changing at a breakneck speed, and the business of journalism in flux, we wanted to do a little bit more. Beginning in 2016, Nick Rockwell (our CTO — you hear from him a lot on here ) and other leaders in the technology department started a learning program that’s pretty simple: everyone in technology receives five days per year and a budget to learn whatever they want however they want, no strings attached. Depending on how you look at it, the five days are an entitlement, an opportunity and an expectation. The program runs on the assumption that most people want to learn, so it gives people the time, space and resources to learn without feeling guilty, or using their personal time or wallets. It also greatly reduces impediments that might prevent people from learning. Five days and a mandate to tech employees to learn whatever they wanted was a good place to start, particularly because the ambiguity let us see where we needed more guidelines. We learned that telling people they could learn anything they wanted was a little too broad — it turns out people like a few strings. That much freedom (or that little guidance) can be paralyzing. There are so many ways and areas in which to develop, it can be hard to know where to start. This year, we added some light parameters. Mainly, we added a learning plan that asks employees to briefly outline how they want to use their days and how it connects to their current role, career goals or any cross-functional skill sets. Learning plans are then used as a jumping off point during one of their regular conversations with their manager about career development. We also put together a list of resources with classes colleagues recommend, online courses, different or “alternative” ways to learn and more. Parameters might feel counterintuitive to the original goal of giving employees the freedom to learn anything they want, but in practice, these guidelines just push employees to consider all of their options and have a conversation with their managers about career goals. The cross-functional component is the key to keeping the guidelines open. It’s more than an attempt to have an organization with diverse skill sets; we think it leads to empathy, something we value greatly. As our employees learn more about the various roles they work closely with, they learn not only the skills themselves but the pain points faced by those who fill those roles. Often, this leads to more empathy, better communication, stronger alignment and ultimately, a better product. This program isn’t only for technical development, we encourage employees to learn “soft skills” like communicating, giving feedback and resolving conflicts — skills that are often overlooked, but are as big of a determinant of a team’s success as a developer’s knowledge of a programming language. That’s where we’re at now. Like pretty much any culture effort in the technology department at The Times, there are many iterations to come. Right now we’re looking at more in-house trainings — not only to make them more tailored to our use-cases here at The Times but create a culture that prioritizes teaching in addition to one that prioritizes learning. We’re going to offer team-specific trainings to address problem areas and org-wide trainings on subjects we think are universal, like data literacy and unconscious bias prevention. Here are some takeaways: Start somewhere. It doesn’t have to be a robust plan, you just need an easy place to start that allows people to start thinking about what they want to learn and how they want to do it. The key is finding something doable that you can commit to and iterate from there. Keep it flexible. You want people to develop as whole people, not just as employees. Give them the space to do that. That means encouraging managers to think broadly about what contributes to growth and career development and to try to err on the side of approval. This won’t always be possible, but learning is much easier to facilitate when the default answer to attending a training or taking a course is yes. Provide resources . People might not want strict guidelines, but they do want a jumping off point. Leadership and colleague-recommended courses or ideas are helpful in getting people to start thinking about learning. As you provide these resources, also consider all of the non-traditional ways it is possible to learn, like self-guided study, participating in employee resource groups, teaching or mentoring peers. Don’t forget cross-functional and soft skill learning. It’s easy to immediately jump to technical skills when considering trainings to recommend, but they are far less valuable when individuals or teams don’t work together well. More often than not, we find soft skills and the ability to work together that determine a team’s success. How we design and build digital products at The New York Times 102 1 Leadership Technology Learning And Development Learning Office Culture 102 claps 102 1 Written by Coordinator, Tech Ops at The New York Times How we design and build digital products at The New York Times. Written by Coordinator, Tech Ops at The New York Times How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-09-21"},
{"website": "NewYork-Times", "title": "talking technology bill magnuson", "author": ["Nick Rockwell"], "link": "https://open.nytimes.com/talking-technology-bill-magnuson-66a27cbfbe2c", "abstract": "Code Data Product and Design Workplace Culture Work with Us For this installment of Talking Technology, I interviewed Bill Magnuson, co-founder and CEO of Braze. You’re 31-years-old and the cofounder and CEO of a successful tech startup — can you talk a little about your journey to get here? I grew up in Minnesota, always loved technology and ended up going to MIT for Computer Science. I graduated in the spring of 2009, just as Android was starting to gain steam, and joined a team in Google Research that was building a visual programming language for Android applications called App Inventor. My work there ended up being the foundation for my master’s thesis, but after completing the degree, I left Google to work for Bridgewater Associates in Westport, CT. However, it wasn’t long before I started to look ahead to the opportunity of building a company in the mobile space. I had seen the potential of Android first-hand at Google, so in the summer of 2011, Mark Ghermezian, Jon Hyman and I, decided to quit our jobs, move to New York and start building Appboy — now Braze. Before you stepped into the role of CEO at Braze, you were the company’s CTO; What have the easiest and the hardest parts of that transition been? Overall, I’ve really enjoyed the transition. My love for technology stems from my love of operating in a fast-changing environment, and the role of CEO at a fast-growing startup delivers that same dynamic challenge. The hardest part was the requirement to rapidly come up to speed on new areas of the business immediately after the transition. None of it was easy, but the five and a half years I spent as CTO gave me a deep understanding of the technical aspects of Braze, which has been useful in navigating the interplay between our technology and our business strategy. Last year, your company changed your name from Appboy to Braze and underwent a significant rebrand at the same time — what was that effort like for you? As an engineer, did you kind of think you could just “s/appboy/braze/g” and just be done with it? Ha! If only it were that easy. Ironically, the only part of the company where we probably could do that (the code), we didn’t fully migrate because we didn’t want to impose namespacing changes on our customers (utm tags, anyone?). All joking aside, a full company rename, including the rebrand and relaunch of updated positioning with a new brand voice, was a massive endeavor. At our stage and company size — which was about 150 people at the time — we didn’t have a lot of examples to draw from, especially within enterprise software as a service (SaaS). However, we did find great help from the creative agency community. How do you feel like the rename/rebrand has affected the company? Internally, we’re really excited about the name — Braze — and the new brand that came with it. The verb “braze” comes from metallurgy, and means to join or bond with great strength. That meaning really matches our purpose as a company, which is to bring together brands and their customers, helping to form and strengthen valuable, long-lasting relationships. Braze has seen a lot of growth over the past few years in terms of number of clients and the complexity of their needs; can you talk about how you’ve evolved your engineering team as your company’s scale and infrastructure demands spiked, and what made you realize you had to take action? We’ve grown rapidly over the last few years — we currently manage the relationships of 1.5 billion monthly active users on behalf of our customers, sending tens of billions of personalized messages every month. One consequence of that growth is that we’ve grown into one of the largest digital platforms in the world, with all the infrastructure and scaling challenges that come with it. Along the way, we’ve been battle hardened in the face of all manner of unexpected circumstances. The most interesting scaling challenges have been at the confluence of massive growth from our clients alongside big cultural events all over the world. When you’re dealing with the truly global nature of mobile, and communicating across all channels for different types of companies, you need to be ready at all times for whatever the world throws at you. The flip side of that continuous challenge is that we’ve been battle tested and have been able to build confidence in our ability to scale while maintaining high SLAs for performance and stability, but it hasn’t been easy. To meet that challenge, we have had to focus our engineering team growth to ensure that we’re bringing in people who have experience working on systems of our scale. We’re built on top of a host of new technologies that help us deliver our product, but nothing beats experience when it comes to anticipating and responding to challenges in scaling systems. The Braze platform is a cloud-hosted SaaS solution — do you find that being cloud-hosted and having a major scaling and infrastructure component to your brand’s value proposition change how you think and talk about building value for enterprise companies? We talk a lot about the importance of conceptualizing Braze as a vertically integrated stack that, while very valuable in isolation, can achieve even more when it is incorporated into the broader technology ecosystem that drives the end-to-end customer experience. To that end, we’ve built Braze as a stream processor to ease integration with built, bought and combined systems. We work with our clients to support the transformation of their infrastructure into a future state where data streams seamlessly throughout the many parts of their technology ecosystem. Do you find that you have to contend with perceptions from investors or customers that infrastructure and scale are “solved problems”? No, quite the opposite. As a technology, mobile has penetrated more of the world than anything that has come before it, which means that we’re constantly looking at new dimensions of scale. However, even if you find yourself momentarily comfortable with scale, then it’s time to challenge what you’re doing and start to work on even more sophisticated strategies, which often require more data, more computation or both. There’s often a perception that tech startups have to be based in Silicon Valley in order to prosper — can you talk about how choosing to base Braze in New York City has worked out for you? New York is obviously a vibrant business environment across nearly every industry, but when we started in 2011, the question of “Why not Silicon Valley?” came up a lot because of the depth of the technology and startup ecosystem out there. Indeed, most of our early investors were from the Bay Area, and our second office was started right in SOMA. However, in the last seven years, New York has become increasingly prominent as a home for new venture-backed startups — we see more and more technology companies growing up here and achieving large scale, and we’re proud to be among them. We now have offices in London and Singapore as well, with plans to continue to expand as our customer footprint continues to grow. Can you talk about how keeping the core of the company colocated has impacted the company’s success? While our teams work to support customers who are spread out all over the world, we’ve kept to just four offices so far. We place a ton of value on the kinds of organic in-person interactions that you get from working alongside a large team every day. We also see a ton of value being generated from the increased teamwork, knowledge sharing and mentorship that comes with interdisciplinary teams being under one roof. Do you have any concerns about GDPR and the way that shifting attitudes or new regulations related to data and privacy could impact Braze or the larger MarTech world? GDPR coming into force in May was certainly a wake-up call for many brands and MarTech companies, but it was neither the first, nor the last, piece of impactful legislation that we’ll see in this space. In the face of heightened scrutiny on customer privacy and brand stewardship of data, the prevailing product strategy for companies like Braze, as well as for our customers, is one that relies on fundamental business values like listening to and respecting your customers, and valuing the relationship with them in the long term. Adherence to those values has given us great resilience in the past, and will continue to benefit us in the future. I’m proud that Braze is on the right side of history here. Braze primarily works on earned and owned channels — places where a brand needs to earn the right to speak to a consumer, and if they don’t deliver value through that outreach, consumers have the right to rescind that permission. We were also pioneers when it came to helping brands leverage their first-party data to deliver customer relationship management strategies at consumer scale and across channels. Our business is predicated on building and strengthening the direct-to-consumer relationship. We believe that the value of selling or transferring consumer data can’t outweigh the power of listening closely to consumers and drawing insights from the resulting data to improve the brand and product experience. We see these regulations as helpful changes that ensure a more even playing field among both brands and marketing technology platforms. What do you see happening in connection with data privacy and security in the U.S. over the next few years? We’ve already seen California take action independently with the passage of the California Consumer Privacy Act, and I think we’re going to see more individual states follow suit. Ideally, we’ll also get something like that at the federal level to avoid a patchwork of independent regulations. That said, for any global technology company, handling a patchwork of regulation is already a reality. Your wife, Jen Lewin, is a light and interactive sculptor; What do you feel like you’ve learned from her and the digital art world? One thing I love about Jen’s work is that she builds pieces that deliver wonderful creativity through a medium that requires modern technology. Her pieces are all interactive, use light and sound to activate public spaces in a way that is very human and create connections between people as they play and interact with the pieces. It’s inspiring to see Jen’s work provide so much joy to the people that experience it, and to see the vital role that technology plays in delivering that experience. At Braze, we want our technology to enable our customers to express their creative vision for how they communicate and build relationships with their customers, and that means thinking a lot about the human connections between brands and their customers. Is there anybody who you think is doing particularly thought-provoking work in the digital art space? I’m a big fan of the data-driven work that Refik Anadol has been building lately. The pieces are largely display or projection based, but they represent a really creative approach to visualizing and synthesizing data in new, interesting ways. Do you see the business leaders from the technology industry becoming active in the art world, whether as collectors, supporters or enthusiasts? The entrenched power of the gallery is no longer required for the artist, and it’s just not something that people from the technology world seem to want to deal with when collecting or supporting art. You’re now seeing artists leverage technology and new ways to communicate with potential collectors and supporters to cut out the intermediary, in ways that are starting to resemble the impact that Spotify, for instance, had on the record labels. I think that’s going to drive a forced evolution of the art world’s old guard, allowing the artist to come front and center and not have it all be about the galleries and the dealers. Do you think that the art world can engage with problems and ideas that are interesting and relevant to tech? Art has always been a strong reflection of the problems and challenges of its time, and right now is no different than any other time period in that regard. Personally, I think the intersection of art and technology has a really important role to play right now. We’re experiencing massive changes not just in our relationship with technology, but in our society at large. How we design and build digital products at The New York Times 64 Startup Technology Conversations SaaS App Development 64 claps 64 Written by SVP Engineering at Fastly, ex-CTO at NYT. Passionate about tech, music, science, art, helping others be their best. How we design and build digital products at The New York Times. Written by SVP Engineering at Fastly, ex-CTO at NYT. Passionate about tech, music, science, art, helping others be their best. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-08-15"},
{"website": "NewYork-Times", "title": "what its like to intern at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/what-its-like-to-intern-at-the-new-york-times-3d27af36715", "abstract": "Code Data Product and Design Workplace Culture Work with Us Every summer, university and graduate students attending schools across the United States come to The New York Times for a 10-week internship. This year, 76 interns were hired in either the newsroom or on the business side, working alongside our colleagues in marketing, advertising, product and design, engineering and data science (special thanks to Ted Kim and Stephanie Russell from the newsroom, and Steffie Eduarte and Jahaan Singh from business for running the program ) . At the end of the summer, we asked our interns to write about their experiences at The Times. Here are a few of their responses. Claire Ballantine Business Day Intern Duke University, Class of 2018 Even though I’m only an intern, I’ve had the opportunity to get coffee in Bryant Park with a Pulitzer Prize-winning investigative journalist, learn from a hard-hitting yet hilarious San Francisco tech writer with a treadmill desk and attend a women-only lunch with Assistant Masthead Editor Carolyn Ryan. While learning from everyone here, I’ve also been able to pursue my own stories and gain reporting experience. My favorite article involved visiting an East Village eatery that encouraged customers to stash away their cell phones for a tech-free dining experience. For this story, I spent an evening at the restaurant talking with the chef and customers, gathering details that proved crucial to telling the story. My editor helped teach me the importance of thorough, nuanced reporting and how setting the scene can turn a mediocre article into a great one. I also learned the value of really taking the time to talk with sources and gain their trust. There are lessons I’ll carry with me throughout my future journalism career. This internship has exceeded my wildest expectations. I’m incredibly sad to be leaving, but my goal is to one day make it back as a full-time reporter — hopefully with a treadmill desk. Simone Tandon Marketing & Insights Intern Stern School of Business, New York University, Class of 2019 When I tell someone I am interning at The Times, their first reaction is “I didn’t know you wanted to be a writer.” Then I tell them that The Times has so much more to offer. The most important aspect of my learning experience at The Times has been to understand that many small, yet crucial, parts make up a whole. The collaborative culture of the company allowed me to grab coffee with employees form the newsroom side, business side and everything in between. However, what resonated with me the most was how every employee was firmly committed to the mission of The Times — to share the truth. It made me feel like I was also a part of this mission, even if it was in the smallest way. One of the main projects I worked on was to evaluate how we market Cooking advertisements to our clients. I had to understand how Cooking was being talked about on the consumer side and the business side. This project gave me the flexibility to explore the narrative around a media product, like Cooking, and how it differs depending on the target stakeholder. I was able to talk to several employees on the product, marketing, branding, tech and advertising side of Cooking — it was like a small start-up within The Times. This project shed light on the innovative and entrepreneurial culture that can flourish in a seemingly traditional news company. The media landscape is constantly changing and The New York Times is at the forefront of that change. As I start my senior year at NYU Stern, I hope to take forward the “big picture” mindset at The Times and strive for perfection in all my endeavors. Drew Learner International Consumer Marketing Intern Duke University, Class of 2020 This summer I had the opportunity to intern on the International Consumer Marketing team, an intimate team of two people (not including myself), that has the responsibility of growing The Times’s subscriber base globally. Growing up in London, I jumped around from British to American to international schools and developed somewhat of a multinational identity and a global curiosity. Joining the international marketing team meant that I would have the opportunity to share my daily source of news with like-minded expats, international students and more. One of the most pleasant surprises I faced from the very start of my internship was the extent of cross-collaboration between teams. I would jump from meetings with Brand to Data Analytics to Newsroom global editors. My team is positioned in both the Marketing Department and NYT Global. Having a foot in both worlds vastly opened up my network and helped me gain a better understanding of the inner-workings of the company and its goal of global digital growth. Beyond this network of teams, I truly never expected to connect with so many individuals from both inside and outside my team. I reached out to close to 30 people and received overwhelmingly positive responses and coffee invites from everyone. I believe these brief meetings made me a much more successful and well rounded intern. As a member of the global team, I was fortunate that these connections stretched beyond the New York office, all the way to London. One of my projects included working with interns in London to brainstorm how to capture the interest of international students. I am excited to see how The Times implements the insights and ideas developed throughout the three week program. Although I am sad to leave, I look forward to returning to Duke University for my junior year with an even deeper appreciation for The New York Times and a continued commitment to supporting quality journalism. Shangdi Yu Messaging Intern | Cornell University, Class of 2019 Lilian Liang Personalization Intern | University of Washington, Seattle, Class of 2018 This summer we joined forces to build a personalized analytics dashboard for newsletter editors. One of the exciting parts of this project was our close collaboration with newsletter editors. During the first half of the internship, we spent a lot of time discussing what metrics the editors found useful and then explored the available data to see if it was possible to measure such a metric. Sometimes an editor wanted a metric that couldn’t be accurately tracked or calculated. For example, we wanted to measure the number of New York Times articles read after clicking on a link from a newsletter. After exploring the data, we decided not to pursue this metric because it couldn’t be done accurately. It was important for us to be very thorough and honest with our investigation of the data. After many discussions with the editors, we narrowed the metrics down to the following areas: Geographic breakdown of the audience User engagement level (opens and clicks) analysis with the newsletters Textual characteristics of the hyperlinks (i.e. number of nouns in the hyperlink text) Shangdi worked on the first two metrics and Lilian worked on the third one. Shangdi mainly used SQL and Python, along with Google Cloud services such as BigQuery, Cloud SQL, and Google App Engine. Working on this project gave her a chance to analyze data with cutting edge technologies and advanced tools. Lilian is interested in Natural Language Processing (NLP) so she used the syntax parser from the Google NLP API to figure out how many nouns, verbs and adjectives were in each hyperlink text. She was interested in seeing if hyperlinks that were focused on the content of the link itself (which typically had more nouns) got more clicks than those that had a call-to-action (which typically had more verbs). Even though we come from different technical backgrounds, we worked well together. We mostly divided the work by our technical strengths but we also gave each other the opportunity to build new skills. Zoha Qamar Data Analytics Intern Columbia University, Class of 2019 During my internship I tracked user engagement and content performance for multimedia pieces. From evaluating the more familiar field of Video to the less traversed territory of Augmented Reality (AR), I grappled with emerging platforms that allow The Times to pioneer new forms of storytelling. For example, I worked on developing benchmarks for the emerging genre of AR, which challenges the most standardized tracking metrics. Benchmarking these pieces is of utmost importance — understanding user engagement helps us improve and enhance new forms of storytelling. As we aim to expand the coverage of quality journalism and think about what stories we tell (and how we tell them), it is equally important to think about how various media democratize information for diverse audiences. Certain platforms reach younger audiences while others reach more women, and still other platforms reach a more international audience. This kind of data helps the Times inform its journalism, at once bettering the experience for our existing users and expanding our reach to potential ones. During this summer’s product design Maker Week, my team (of all interns!) built the prototype for a personalization feature on the New York Times’s app, allowing a user to see which of their Facebook friends had read an article while also displaying a map of trending articles in a reader’s area. Through this project, I appreciated one of the most salient lessons from my internship: our multimedia platforms not only continue the work of our print division, but also open new avenues for discourse and conversation. From interns my age with similar and adjacent interests in media to all my co-workers in between, I’ve met people who have exposed me to thrilling and compelling parts of the industry. There could not be a better place to weave together my lifelong interest in journalism and my academic background in technology than at The Times this summer. I am grateful that The Times has opened my eyes to just how much there is to explore at the intersection of the things I love and how much there will continue to be. Sam Pal Digital Subscriptions Backend Team Intern University of Illinois at Urbana-Champaign, Class of 2021 Maker Week truly stood out to me, as I learned more in that week than I possibly could have in the same amount of time at school. That isn’t to say that I do not learn at school — I certainly do — but there’s a distinct type of learning that one does both on the job and while hacking a project together that transcends any university-given knowledge. This Maker Week, I was approached by my mentor with a project he had been thinking about working on but never had the time to implement, arguably the reason why a week like Maker Week exists in the first place. Ideally, after Maker Week, we would have taken an existing file-processing batch job that happened every morning and use some *magic* to not only make that process cost-effective, but use Google Cloud technologies to do so. Given that our CTO had just spoken at the Google Cloud Next conference that very week, we thought it was more than apt to embark on this journey. The magic in question was creating a pipeline to process the existing files and apply various transforms to that data. The data would eventually be sent to Cloud Datastore and processed based on what each file dictates. This would refine the current SubLink technology (creates links between Home Delivery and Digital Subscriptions for a user) and be a proof-of-concept for optimization of future processes like this one. Coming into this project, I had little experience with this technology and initially understood the goal of the project on a very high level. I came out of Maker Week not only with a working product (we swear, it ran semi-beautifully on Friday), but also a familiarity with GCP that I could not have fathomed coming out of this internship with. Annaya English Luxury Sales Intern Syracuse University, Class of 2019 Working on the Luxury Sales team has been amazing, but I think that out of all the projects I’ve done this summer my most fulfilling project has been my Maker Week project. I worked on a Diversity & Inclusion project with interns from a variety of departments to create an employee resource site. The idea came from the fact that many people were unaware of diversity initiatives throughout the company so we thought that creating a database and website to record the diversity initiatives would be a great internal resource and create visibility for the programs. First, we gathered all the information about the diversity initiatives to create the database. Second, we interviewed different people in the company like A.G. Sulzberger, Dean Baquet, Meredith Kopit Levien and other employees involved in diversity initiatives. Lastly, we formatted the website to hold the database, show diversity efforts in recruiting, the newsroom and the business side. We also added a tab for various conferences based on departments. Our showcase at Maker Week was great because employees seemed really interested in the accessibility of the website. It was one of the best projects I’ve worked on and I’m so glad to have been a part of it. I think this project really taught me to be bold in my work. I spoke to all these amazing people by just emailing them and taking a chance and it worked out which was amazing. I’ve also been a diversity advocate throughout my years in school and this project showed me how an idea from one of my passions can become a useful reality. In the fall, I’ll be heading back to Syracuse University to be a Resident Advisor for my last year. I’ll also be a peer facilitator for our first diversity-oriented freshman forum. I want to use the skills I’ve learned in this internship to create something amazing on my campus that is fueled by my passion just like I got to create at The New York Times. Illustrations by Rachel Buigas-Lopez Art Design Intern New York University, Class of 2020 How we design and build digital products at The New York Times 136 Media Internships Learning And Development College Office Culture 136 claps 136 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-09-05"},
{"website": "NewYork-Times", "title": "writing asynchronous code for android introducing coroutines", "author": ["Roberto Orgiu"], "link": "https://open.nytimes.com/writing-asynchronous-code-for-android-introducing-coroutines-20dda14a39ea", "abstract": "Code Data Product and Design Workplace Culture Work with Us Writing asynchronous code is hard, even when we have amazing tools such as Reactive Programming to help us. What if we could write synchronous code and have it work asynchronously? On the Android Team at The New York Times, we tackle writing asynchronous code with help from our Store library and from RxJava, which is a fundamental piece of our architecture. We use it to handle our most computationally intensive tasks, from parsing the news feed to reacting to UI changes. Although we have used RxJava up to this point, we also try to keep ourselves and our app up-to-date, so we have started to incorporate the use of coroutines. Coroutines were introduced only recently as an experimental feature of Kotlin 1.1 and they give developers the ability to write more concise, asynchronous code. Even if coroutines are not a new concept (they exist in multiple other languages), it is really amazing that they are available in Kotlin and on Android, where the features of Java 8 have been a dream for several years. In this post, we will walk through some examples of coroutines and talk about what is going on under the surface. Before we learn how we can make use of coroutines, we have to understand the difference between blocking calls and non-blocking calls. Let’s look at the following snippet: What we have here is pretty straightforward, but it has some peculiarities: first, we have not one but two different ways of invoking a waiting time. Something we may be familiar with ( Thread.sleep() ) and something we might have instead seen within RxJava’s operators ( delay() ). Invoking sleep() is a blocking call, while delay() is a non-blocking call. Diving deep, the first call will make the whole thread sleep, freezing its execution for as long as we request, while delay() will only suspend it, allowing the rest of the code to work normally. Let me explain this even further: when we launch this routine, it will encounter delay() , which will make the code between launch and the closing bracket suspend for one second, while the rest (the println instruction) will be executed. This is when we see the output in the console printing “Hello,”. The next step is Thread.sleep() , which will freeze the execution for two seconds, blocking everything that was in the pipeline, which means that the delay() counter will freeze as well. When this time passes, delay() will restart and finish, at which point we’ll see the last output in the console printing “World”. Visualizing this as a timeline can maybe help make this very important concept crystal clear: This concept is so important because the definition of coroutines is: Coroutines are computations that can be suspended without blocking a thread. Now that we know this, we can easily identify this snippet as our first coroutine: Before discussing more theory, let’s see why delay() is so important. For coroutines to be suspendable without blocking everything else, we have to give up a little bit of flexibility, meaning that we can only stop them at specific points; and delay() is one of them. These points (which are functions, after all) are called suspension functions , and are created by applying the suspend modifier to the declaration of the function itself: Another very peculiar aspect is that suspending functions can only be called inside a coroutine or from another suspending function. But how can we create a coroutine, then? The answer is by using a builder . A builder will help us create a coroutine by accepting suspending functions as parameters. In our previous example, the builder is identifiable with the launch function, which creates a fire and forget coroutine that will not return any value when its execution has completed. At this point, we can finally identify the launch() function: in Kotlin, this is called builder, and it is what makes the coroutine possible. Here is one possible declaration of a launch() function: As we can see, it’s nothing more than a higher-order function. Together with suspending functions, they provide us with a powerful way to write asynchronous code clearly and concisely. As of the time of writing, coroutines are still experimental and cannot be used unless we take a few introductory steps. The first thing we have to do is open the gradle.properties file in our project and add this line, which will enable coroutine support in the IDE. The next step is adding their dependency, which should look very similar to this line. We add this to our module’s build.gradle file: The last step we have to take is enabling the coroutines for our build and we do it by adding this snippet to the same build.gradle file in which we have been operating so far: Suppose we want to create a very simple countdown function, which will change the value in a TextView from ten down to one and will then replace the number with “Done!” as soon as we have finished counting. To make it slightly more complex, at each iteration of the countdown we want to wait for one second, so that the timing is as close as possible to reality. Since we want to use coroutines, what we have to do is use the launch() builder and insert the delay() function in a simple for loop, in which we also change the label of a TextView . The only odd thing here is that parameter we passed to the launch() builder: this optional parameter is the coroutine context (not related to Android’s object with the same name) which will instruct the coroutine on where we want this code to be executed. In this case, we want it to be run on the UI Context , which is a wrapper of Android’s Main Looper. Since we are going to invoke methods of a View , we can only do so from the thread which created the aforementioned View . We should worry not: as we already saw, a suspending function will only suspend the coroutine, without impacting our main thread, so we are sure that delay() will not make our app unresponsive. In the case that we want to cancel this countdown, we can do so by just holding a reference to the Job returned by launch() (as we saw when we introduced launch() declaration, this builder function actually returns a Job object) and invoking the cancel() method on it. Note: All coroutines should be cancelable, but we can also make a noncancelable coroutine. However, this discussion is out of the scope of this introduction. Let’s take this example a bit further and refactor it so that we can more clearly understand how coroutines can help us in our everyday life. We can start by wrapping the countdown routine into an extension function so that we can invoke it on any of the TextViews in our layouts: Since delay() is a suspending function, and suspending functions can only be called from inside other suspending functions, we mark our countdown() extension as suspending as well. The downside of this can be that we will not be able to call countdown() whenever we want, but since we need to suspend the execution, this is a fair limitation that we are willing to accept. At this point, we want this routine to be fired when we press a button, so that we can start the countdown whenever the user wants to. To do so, we need to wrap a builder function into a View.OnClickListener . The quickest way to reach this goal is to leverage the Kotlin language and create an asynchronous click listener. This snippet shows nothing more than what we mentioned above: we create a higher-order function, a parameter of which will be a suspending function, and we wrap our coroutine in an OnClickListener , invoking the suspending function we received as parameter. Now, we just need to bind this logic to a View and a TextView , so that we can see the magic happen: We can take this example a bit further, maybe with a network call, to demonstrate how easy and readable coroutines can make our code. Let’s use the Retrofit framework which, at the time of writing, has no official support for this feature. However a pull request has been issued and we should see this compatibility layer added sooner rather than later. Before we start diving into the code, we have to highlight a couple of other small things: We only encountered the launch() builder, but it’s not the only one. Its duty is to create a ‘fire and forget’ coroutine, which will not return any result; while its counterpart, called async() , will return a value which we can literally await. Let’s only focus to the relevant part of the code. Since coroutines have not yet a stable AdapterFactory for Retrofit , we can either create one or we can go for a different (and maybe less elegant) solution, which is having the framework perform synchronous calls that we’ll make asynchronous later. In order to do this, we instruct our interface to return a Call<OurType> : The next step is to wrap this call in a function which will only return OurType , keeping the code as simple as possible: Note: If we try and run this snippet as it is, we will incur in a NetworkOnMainThreadException which, in our example, means we are doing exactly what we wanted to do, that is make a synchronous network call with Retrofit. Now we can finally introduce async() . Differently from what we saw with launch() , this function returns a Deferred<T> (in our case, T is OurType ), which is an object that holds the promise that we will have a value, when the coroutine ends its duty. Of course, we have to create a suspending function, as we already saw several times: Now, we can wire this function together with the asynchronous click listener we already saw, and when we get our data, we just pass it to our Views in the correct thread, while executing the network call away from the main thread: Here, we changed the function we expect as parameter to match the fact that we will return a value, but the interesting thing is when we want to obtain a value from a Deferred<T> object, we invoke the await() method, which will return the T value whenever it is ready. To recap, what we do here is ask for a value which will be computed on another thread, and we await for the result, which we will obtain on the UI thread, so that we can use it right away. Coroutines are by default scheduled for execution as soon as we create them, so that we don’t have to wait as long for them to complete. In case we need them to start sequentially, maybe because they depend on each other’s result, we can make them start lazily, and they will be executed as soon as we invoke the await() method on a Deferred<T> instance. To make them lazy, we simply pass another optional parameter to the builder, which will instruct them on when to start: At The New York Times, we really like to test the code we write, so we definitely could not conclude an article without mentioning how we can test a coroutine. One way is to force our asynchronous routine to run synchronously so that our tests can run in a very predictable way. To do this, we use yet another builder, which is runBlocking() . This builder forces our code to run in a blocking way so that we can always predict the behavior of the test: Note: This test is an example of how to test a coroutine. We are specifically not mentioning the different ways to test our network layer. Coroutines are experimental but they are stable enough for daily use and the incoming support for all the major frameworks and libraries make it clear that they are here to stay. They make writing asynchronous code cleaner and easier, and we are quite happy to have them. How we design and build digital products at The New York Times 307 2 Android Code Tutorial App Development Software Development 307 claps 307 2 Written by Android developer and GDE for Android How we design and build digital products at The New York Times. Written by Android developer and GDE for Android How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-07-02"},
{"website": "NewYork-Times", "title": "order from chaos streamlining our tagging infrastructure", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/order-from-chaos-streamlining-our-tagging-infrastructure-b5bf6aff9b74", "abstract": "Code Data Product and Design Workplace Culture Work with Us By CAROLINE COX-ORRELL and RICHARD PINALES Like many organizations, The New York Times relies on data to make smart decisions about everything from product design to customer segmentation to headline verbiage. Often the most reliable of this data is what we have collected ourselves, from our audiences and to our own specifications — we call this first-party data. Developing a deep knowledge of what our readers want and how they behave on our platforms, while respecting the user’s privacy, is key to maintaining a successful subscription product. These insights have helped us launch new products like NYT Cooking and NYT Watching , and help us maintain a high-quality user experience. We gather first-party data using small snippets of code called tags that can collect and send information from any given page on our website. This helps us understand things like how often visitors to our site click on a particular article or read a column to the very end. The Data Implementation team at The Times recently finished migrating all of our tags to a commercial tag management system to aid in the organization and deployment of those code snippets across The Times’s digital properties. As we finish this project, we’re looking back on the evolution of our tagging infrastructure, and how that infrastructure has supported efforts like personalization, and data privacy and protection. Adding tags to our pages began in an ad-hoc way. We had no centralized way to view or edit tags, so code snippets were placed directly in the front-end code of many applications, which made a lot of things really difficult. Updating a tag to send or collect different pieces of data could be complicated and time consuming: we had to find where the tag lived, talk to the team most familiar with the app where the tag was located, understand the business needs of that particular app and finally, make adjustments needed. In 2013, our data implementation engineers began rolling out Event Tracker, a homegrown event tracking system, to more and more front-end applications. As the rollout continued, we realized we had no way to ensure consistency in tagging implementation or to identify whether front-end apps had any event tracking at all. Confusion intensified across the tech organization about what information was being tracked and in which tags. While Event Tracker was (and continues to be) the backbone of our custom analytics technical stack, we had little insight into how the system was integrated across many front-end applications and very little control over the data Event Tracker was receiving. Our analytics platforms rely on good first-party data, but disorganized data implementation made it nearly impossible to capture that data. We needed a centralized way to maintain our tags across many front-end applications: we needed a tag management system. A tag management system works by deploying a small code snippet called a container to the front-end; it then allows additional tags to run within that container. Rather than updating the front-end every time there’s a change in data tracking, you can deploy a container once and make changes directly in your tag manager, which is a web UI that allows you to see, manage and build tags within a given container. As you can imagine, having all of your tags and rules in one single place can provide enormous gains in efficiency and accuracy. We built our own tag management system because we needed to have easy access to our back-end data — data regarding website visitors and data from our content management system — and there weren’t any commercially available systems that provided that level of access. Our tag management system, TagX, has a built-in analytics API that is designed to fulfill our unique set of analytics requirements, and it standardizes tagging to ensure that tags implemented on front-end apps are also tracked in Event Tracker. Implementing our own tag management system had positive effects almost immediately: our analysts were able to generate reports using the exact same data points as third-party partners, and data was more consistent across all of our applications, which increased our overall confidence in our data. We were able to integrate our A/B testing data collection practices with our tag management systems, and we were even able to implement New York Times cookie values in Google AMP articles, which allowed us to gather analytics from AMP readers. This also set the stage for data governance and privacy pushes. In order to meet GDPR compliance requirements, we were able to make all of our tags respect the ‘do not track’ choice users in GDPR-participating nations can make. Without a tag management system, we would not have been able to implement the ‘do not track’ flag as easily or elegantly. After five years of maintaining TagX, it became apparent that our data tracking ambitions outpaced our tools, and we simply couldn’t grow fast enough while using a homegrown tag management system. We decided to move our tags from TagX to a commercial tag manager. At The Times, we already use many Google Tools, including Google Analytics, so opting for Google Tag Manager as our commercial tag management system was an easy decision. While Google Tag Manager would replace the tag management aspect of TagX, we still needed a tool with the capacity to integrate server-side with our custom data sets. TagX was originally designed to allow tracking tags to include New York Times-specific data and to provide complete metadata about our content and user experiences. In order to migrate our tags to Google Tag Manager without losing that important functionality, we re-designed and re-implemented TagX as a specialized data API called JSON Kidd that integrates with our applications and augments the data capabilities of our commercial tag management system. JSON Kidd is in reference to Jason Kidd, a professional basketball player who was known as one of the best assist-men of his day; We see JSON Kidd as an API that “assists” all NYT’s front-end applications with analytics data. JSON Kidd is now the hub for all our composed data items that our client applications need, and it is quick and easy to append with new endpoints. Integrating our front-end tagging and back-end data also allows our data science team to quickly model data and immediately put it to use for things such as making information about a user’s propensity to subscribe available to the front-end. It also enables us to more tightly control advertising tagging; We can reliably suppress marketing materials for anonymous users from being shown to subscribers. Lastly, it makes it easy for us to ensure that we are protecting our user’s data privacy and that we are consistently implementing data governance and privacy policies. We’ve learned a lot through this process, but the most important lesson has been the importance of having good tools for collecting and organizing first-party data. Our tag management system, coupled with JSON Kidd, plays a huge role not only in ensuring that data collection and tracking is organized and efficient, but also in enabling our data systems to talk with one another and with our application front ends. Caroline Cox-Orrell is a project manager for Data & Insights at The New York Times. Follow her on LinkedIn . Richard Pinales is the director of Data Engineering at The New York Times. Follow him on Facebook and LinkedIn . How we design and build digital products at The New York Times 181 1 Google Analytics Data Science Code Data Analysis 181 claps 181 1 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-06-22"},
{"website": "NewYork-Times", "title": "going places with html and css", "author": ["Shilpa Kumar"], "link": "https://open.nytimes.com/going-places-with-html-and-css-84ac8c8a39a6", "abstract": "Code Data Product and Design Workplace Culture Work with Us HTML and CSS were probably the first two languages you learned when you first started coding. The two languages are the backbone of web page structure and while they are straightforward to grasp, they can be difficult to master. HTML offers many advanced tools that help to better define the objects on a page and optimize search results; CSS has recently released a new feature called Grid that provides a framework for layouts that adapt to multiple screen sizes. Navigating the advanced features of HTML and CSS can be daunting, but this tutorial is intended to help demystify some of them. HyperText Markup Language, or HTML, is the most popular way of communicating with the web because it tells the browser how elements, such as images or text, should be displayed on a page. Because this is a language that controls how content is shown, it’s important to utilize HTML tags to explicitly describe the types of content on a page. Leveraging the verbose tags available, or writing semantic HTML, can help boost pages in search results, and make pages more accessible for readers with disabilities. Writing semantic HTML means writing meaningful HTML, where the markup tags convey the meaning of the content they contain. Semantic HTML acts as a layer of communication between developers working on the code, and it tells browsers, search engines and screen readers how to work with the page’s content. Essentially, semantic HTML is <div>s with definition. Semantic HTML helps create a well-defined web page structure that minimizes ambiguity. It also enhances the accessibility of a page by allowing screen readers — software that traverses the content of a page and reads it out loud to the user — to navigate pages and relay more information to the user. Here are some common Semantic HTML tags and how they are used: <header> This tag is helpful in defining any introductory content, like page navigation or logos. This tag can exist anywhere on a page except within a <footer> tag. There can also be multiple headers that exist on one page. For example, use this tag to wrap a main headline with some introductory text, as shown below: <nav> The main navigation of a page can be wrapped with the <nav> tag. This is useful for search engines, and it identifies the primary navigation more clearly in case there are other methods of navigation on the web page. <section> Use the <section> tag instead of a <div> tag to explicitly define the areas in a document that contain a group of related content. Wrap a set of paragraphs, images or a mix of content in section tags to indicate that they are related content. <article> The <article> tag is for content on a page that is self-contained, meaning it should make sense outside of the context of the page, like in an RSS feed or on another platform. Use this tag to wrap content like a news story or a blog post (shown below), for example. <footer> Just like the <header> tag, any markup for footer content, including navigation, author bios or copyright notices should be defined in the <footer> tag. There can also be more than one footer on a page. Like the <header> tag, footers can be placed anywhere on the page, but usually is placed right before the end of a </section> or a </body> tag, as shown below. The Semantic HTML Heading Tag It is important to note that each <h1> element creates a new section as well! Any subheading tags ( <h2> , <h3> , etc) are considered sub-headings under the top level heading and don’t create new sections. What about <divs>? This does not mean the <div> tag has no meaning, but should only be used when appropriate. The example markup below shows how to use some of these tags effectively. Writing search engine optimized HTML, or SEO HTML, can make it easier for search engines to find your web page and can help you reach a larger audience. How the page appears in search engine results can be controlled with SEO markup. These are some SEO tags and how to use them: <head> Most of the important SEO tags go inside the <head> tag. This section will not affect the look or feel of your web page, but most of this content will be important in the search engine results page. <title> This is what shows up as the headline on search engine result pages. What is written in the <title> tag should contain your web page’s name, and can include some of the content of your web pages. <meta name=”[your description goes here]”> This is your web page’s description in the search engine results. Make sure it is detailed and honest. For example: Here is an example of these SEO tags in practice: Another useful HTML tool is open graph tags, which provide control over how content shows up on social media when a link is shared. For example, the content that appears on Facebook when a link is shared, such as article title, author and description, is controlled by open graph tags. There are four required properties when using open graph tags: title, type, image and URL. Additional optional metadata tags can include audio, description, default language, and more. For a detailed look at open graph tags and to read documentation, check out http://ogp.me In order to make your web page into a graph object, simply add additional metadata tags to the <head> section of your HTML markup with a property attribute set to a content property like below: While the semantic HTML tags mentioned above let us write structured and readable markup, they don’t affect how our content will look in the browser. Cascading Style Sheets, or CSS, is where we define color, position, font and any other styles. CSS can also be used to control page layout and how elements change based on screen size. There are numerous ways to control page layout with CSS — tables, setting widths, floats, flexbox — and all of them come with their own unique issues. A recently released CSS feature called CSS Grid, or Grid, can break any given page layout into a two-dimensional series of columns and rows that can be controlled by CSS rules. It’s implemented by applying CSS rules to both the parent element (the grid’s container) and the child elements (the grid items nested within the container). No floats or margins are required to style the content to be responsive. It’s important to ensure your audience can access your content no matter what device they use, and CSS Grid can be is useful for creating clean layouts that are responsive across multiple screen sizes. The cells of the grid are not fixed. If a design requires a grid cell to be positioned in a specific location, you can apply the `grid-column` and `grid-row` CSS properties on the cell to control where a cell should be positioned on the page. These shorthand properties specify a “from” and “to” position on the grid. This is useful if a design requires a specific placement of grid items in the mobile layout that is different from the tablet or desktop layout. You can change the position of any cell in the grid to any location on the same grid and not stress about breaking the layout. Check out this CodePen example that illustrates these properties and placement of grid cells. There are many layout options with CSS and it can be hard to know which ones to use. A good rule of thumb is if you can draw a grid over your layout, you should use CSS Grid. If a grid doesn’t quite work, use flexbox. For more information about CSS Grid, read this extensive piece on the framework by my colleague Natalya Shelburne. When building your web page, it’s important to keep your audience in mind and think about how they’ll access your content. The powerful tools outlined here will help to streamline your layouts, make your web pages more accessible and enhance how your pages appear in search results. How we design and build digital products at The New York Times 1.4K 10 Code Web Development HTML CSS Tutorial 1.4K claps 1.4K 10 Written by Software Engineer at The New York Times How we design and build digital products at The New York Times. Written by Software Engineer at The New York Times How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-06-27"},
{"website": "NewYork-Times", "title": "building a text editor for a digital first newsroom", "author": ["Sophia Ciocca"], "link": "https://open.nytimes.com/building-a-text-editor-for-a-digital-first-newsroom-f1cb8367fc21", "abstract": "Code Data Product and Design Workplace Culture Work with Us If you’re like most people in America, you use a text editor nearly every day. Whether it’s your basic Apple Notes, or something more advanced like Google Docs, Microsoft Word or Medium, our text editors allow us to record and render our important thoughts and information, enabling us to tell stories in the most engaging ways. But you might not have ever thought about how those text editors work under the hood. Every time you press a key, hundreds of lines of code may be executing to render your desired character on the page. Actions that seem small — such as dragging a selection over a few words of text or turning text into a heading — actually trigger lots of changes in the system underlying the program. While you may not think about the code powering these complicated text-editing maneuvers, my team here at The New York Times thinks about it constantly. Our primary task is to create an ultra-customized story editor for the newsroom. Beyond the basics of being able to type and render content, this new story editor needs to combine the advanced features of Google Docs with the intuitive design focus of Medium, then add lots of features unique to the newsroom’s workflow. For a number of years, The Times’s newsroom has used a legacy homegrown text editor that hasn’t quite served its many needs. While our older editor is intensely tailored to the newsroom’s production workflow, its UI leaves much to be desired: It heavily compartmentalizes that workflow, separating different parts of a story (e.g. text, photos, social media and copy-editing) into completely different parts of the app. Producing an article in this older editor therefore requires navigating through a lengthy series of unintuitive and visually unappealing tabs. In addition to promoting a fragmented workflow for users, the legacy editor also causes a lot of pain on the engineering side. It relies on direct DOM manipulation to render everything in the editor, adding various HTML tags to signify the difference between deleted text, new text and comments. This means engineers on other teams then have to put the article through heavy tag cleanup before it can be published and rendered to the website, a process that is time-consuming and prone to mistakes. As the newsroom evolves, we envisioned a new story editor that would visually bring the different components of stories inline, so that reporters and editors alike could see exactly what a story would look like before it publishes. Additionally, the new approach would ideally be more intuitive and flexible in its code implementation, avoiding many of the problems caused by the older editor. With these two goals in mind, my team set out to build this new text editor, which we named Oak. After much research and months of prototyping, we opted to build it on the foundation of ProseMirror , a robust open-source JavaScript toolkit for building rich-text editors. ProseMirror takes a completely different approach than our old text editor did, representing the document using its own non-HTML tree-shaped data structure that describes the structure of the text in terms of paragraphs, headings, lists, links and more. Unlike the output of our old editor, the output of a text editor built on ProseMirror can ultimately be rendered as a DOM tree, Markdown text or any other number of other formats that can express the concepts it encodes, making it very versatile and solving many of the problems we run into with our legacy text editor. So how does ProseMirror work, exactly? Let’s jump into the technology behind it. ProseMirror structures its main elements — paragraphs, headings, lists, images, etc. — as nodes . Many nodes can have child nodes — e.g., a heading_basic node can have child nodes including a heading1 node, a byline node, a timestamp node and image nodes. This leads to the tree-like structure I mentioned above. The interesting exception to this tree-like structure lies in the way paragraph nodes codify their text. Consider a paragraph consisting of the sentence, “This is strong text with emphasis ”. The DOM would codify that sentence as a tree, like this: In ProseMirror, however, the content of a paragraph is represented as a flat sequence of inline elements, each with its own set of styles: There’s an advantage to this flat paragraph structure: ProseMirror keeps track of every node in terms of its numerical position. Because ProseMirror recognizes the italicized and bolded word “emphasis” in the example above as its own standalone node, it can represent the node’s position as simple character offsets rather than thinking about it as a location in a tree. The text editor can know, for example, that the word “emphasis” begins at position 63 in the document, which makes it easy to select, find and work with. All of these nodes — paragraph nodes, heading nodes, image nodes, etc. — have certain features associated with them, including sizes, placeholders and draggability. In the case of some specific nodes like images or videos, they also must contain an ID so that media files can be found in the larger CMS environment. How does Oak know about all of these node features? To tell Oak what a particular node is like, we create it with a “node spec,” a class that defines those custom behaviors or methods that the text editor needs to understand and properly work with the node. We then define a schema of all the nodes that exist in our editor and where each node is allowed to be placed in the overall document. (We wouldn’t, for example, want users placing embedded tweets inside of the header, so we disallow it in the schema.) In the schema, we list all the nodes that exist in the Oak environment and how they relate to each other. Using this list of all the nodes that exist in the Oak environment and how they relate to each other, ProseMirror creates a model of the document at any given time. This model is an object, very similar to the JSON shown next to the example Oak article in the topmost illustration. As the user edits the article, this object is constantly being replaced with a new object that includes the edits, which ensures ProseMirror always knows what the document includes and therefore what to render on the page. Speaking of which: Once ProseMirror knows how nodes fit together in a document tree, how does it know what those nodes look like or how to actually display them on the page? To map the ProseMirror state to the DOM, every node has a simple toDOM() method out of the box that converts the node to a basic DOM tag — for example, a Paragraph node’s toDOM() method would convert it to a <p> tag, while an Image node’s toDOM() method would convert it to an <img> tag. But because Oak needs customized nodes that do very specific things, our team leverages ProseMirror’s NodeView function to design a custom React component that renders the nodes in specific ways. (Note: ProseMirror is framework-agnostic, and NodeViews can be created using any front-end framework or none at all; our team has just chosen to use React.) If a node is created with a specific visual appearance that ProseMirror gets from its NodeView, how do additional user-added stylings like bold or italics work? That’s what marks are for. You might have noticed them up in the schema code block above. Following the block where we declare all the nodes in the schema, we declare the types of marks each node is allowed to have. In Oak, we support certain marks for some nodes, and not for others — for instance, we allow italics and hyperlinks in small heading nodes, but neither in large heading nodes. Marks for a given node are then kept in that node’s object in ProseMirror’s state of the current document. We also use marks for our custom comment feature, which I’ll get to a little later in this post. In order to render an accurate version of the document at any given time and also track a version history, it’s critically important that we record virtually everything the user does to change the document — for example, pressing the letter “s” or the enter key, or inserting an image. ProseMirror calls each of these micro-changes a step . To ensure that all parts of the app are in sync and showing the most recent data, the state of the document is immutable, meaning that updates to the state don’t happen by simply editing the existing data object. Instead, ProseMirror takes the old object, combines it with this new step object and arrives at a brand new state. (For those of you familiar with Flux concepts, this probably feels familiar.) This flow both encourages cleaner code and also leaves a trail of updates, enabling some of the editor’s most important features, including version comparison. We track these steps and their order in our Redux store, making it easy for the user to roll back or roll forward changes to switch between versions and see the edits that different users have made: The ProseMirror library is intentionally modular and extensible, which means it requires heavy customization to do anything at all. This was perfect for us because our goal was to build a text editor to fit the newsroom’s specific requirements. Some of the most interesting features our team has built include: Our “track changes” feature, shown above, is arguably Oak’s most advanced and important. With newsroom articles involving a complex flow between reporters and their various editors, it’s important to be able to track what changes different users have made to the document and when. This feature relies heavily on the careful tracking of each transaction, storing each one in a database and then rendering them in the document as green text for additions and red strikeout text for deletions. Part of Oak’s purpose is to be a design-focused text editor, giving reporters and editors the ability to present visual journalism in the way that best fits any given story. To this aim, we’ve created custom header nodes including horizontal and vertical full-bleed images. These headers in Oak are each nodes with their own unique NodeViews and schemas that allow them to include bylines, timestamps, images and other nested nodes. For users, they mirror the headers that published articles can have on the reader-facing site, giving reporters and editors as close as possible a representation to what the article will look like when it’s published for the public on the actual New York Times website. Comments are an important part of the newsroom workflow — editors need to converse with reporters, asking questions and giving suggestions. In our legacy editor, users were forced to put their comments directly into the document alongside the article text, which often made the article look busy and were easy to miss. For Oak, our team created an intricate ProseMirror plugin that renders comments off to the right. Believe it or not, comments are actually a type of mark under the hood. It’s an annotation on text, like bold, italics or hyperlinks; the difference is just the display style. Oak has come a long way since its conception, and we’re excited to continue building new features for the many newsroom desks that are beginning to make the switch from our legacy editor. We’re planning to begin work soon on a collaborative editing feature that would allow more than one user to edit an article at the same time, which will radically improve the way reporters and editors work together. Text editors are much more complex than many know. I consider it a privilege to be part of the Oak team, building a tool that, as a writer, I find fascinating and also so important for the functioning of one of the world’s largest and most influential newsrooms. Thank you to my managers, Tessa Ann Taylor and Joe Hart, and my team that’s been working on Oak since well before I arrived: Thomas Rhiel, Jeff Sisson, Will Dunning, Matthew Stake, Matthew Berkowitz, Dylan Nelson, Shilpa Kumar, Shayni Sood and Robinson Deckert. I am lucky to have such amazing teammates in making the Oak magic happen. Thank you. How we design and build digital products at The New York Times 14.9K 46 JavaScript Product Development Writing Code Design 14.9K claps 14.9K 46 Written by Warrior for authenticity. Uncovering my truest self & documenting the journey. http://sophiaciocca.com How we design and build digital products at The New York Times. Written by Warrior for authenticity. Uncovering my truest self & documenting the journey. http://sophiaciocca.com How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-04-26"},
{"website": "NewYork-Times", "title": "how we made the holiday gift guide", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/how-we-made-the-holiday-gift-guide-72886d02b958", "abstract": "Code Data Product and Design Workplace Culture Work with Us By RANU RAJKARNIKAR , NOREL HASSAN, YURAIMA ESTEVEZ , BRIAN FOSHEE , MATTHIAS GATTERMEIER and KARRON SKOG Every November, The New York Times publishes a holiday gift guide with suggestions for the best gifts of the season. The guides of years past were designed and coded anew each holiday season, and featured a limited selection of products and experiences chosen by editors throughout the newsroom. In 2017, our cross-functional team, which builds guides of all kinds , was tasked with taking the successes of past New York Times gift guides to develop a scalable product with an eye towards future flexibility. In order to do this, we had to work across multiple departments at two companies, The New York Times and Wirecutter, to source, input and present over 300 gifts, while also building upon an existing stack. And all of this had to be completed in a limited time frame (three months, to be exact). This project presented a lofty challenge that we were excited to take on, but we all knew that it would also be a big undertaking. Here’s how we did it. We felt that it was important to feature a large variety of gifts, spanning various interests and price points, in order to include something for everyone. From affordable stocking stuffers to more luxurious splurges, we wanted to showcase gifts that were both practical and inspirational. Partnering with Wirecutter allowed us to leverage their archive of rigorously-tested products to include only the most highly-rated gifts in our guide. (We’ll get to how we chose the gifts a little later in this post.) With the vast number of gifts and the collaboration with Wirecutter, we knew the design needed to allow for two very different brands to live in harmony, while still showcasing each publication’s unique visual style and editorial voice. Mirroring most online shopping experiences, we made photography the main design element and the focus for each gift. We found that taking advantage of Wirecutter’s in-situ photo style not only helped us combine these two brands, but also was the most useful for the reader. When in-situ photos were not available, we made sure product photos were consistent and portrayed on a light gray background, so as to not distract with disparate branding. We also wanted to highlight that these gift recommendations were coming from real people with expertise, and not from a faceless company. So, we displayed contributor headshots, titles and their respective company, a feature that we found our readers really enjoyed. With the addition of over 200 gifts, a big part of the design effort was in reconsidering the user experience. We wanted it to be flexible enough for a reader to find exactly what they were looking for, but we also wanted it to be delightful for readers to browse and explore. In order to make decisions on UX, we completed user testing with lo-fi prototypes. From the testing, it was clear that “interest” and “price” were the two primary entry points that should be highlighted in our gift guide. We created a landing page that visually laid out these two entry points in tandem with a clear and simple navigation that allowed readers to jump between different interests and price points easily. To help guide the reader through all of the recommendations, we bucketed similar interests and gifts, and added related categories to the bottom of each interest category page. At a more micro level, product pages show applicable Wirecutter reviews and related gifts. Though we were building an application and template for a gift guide with a lot of gifts, we wanted to design a modular system that could be repurposed for gift guides with fewer items, like our Valentine’s Day Gift Guide . For smaller gift guides, we decided to show all the gifts on one page, instead of bucketing them into interest groups, and readers can still filter by price. Because past gift guides were specially designed and rebuilt every year, each guide had its own theme and design. For example, 2016’s guide opened with a video animation of snow flurries, and 2015’s guide showed products in front a background that changed colors as the user scrolled. In order to productize the gift guide and make it reproducible for a variety of needs, we designed a structure, user experience and visual language that would work beyond the 2017 holiday season. Looking at designs across our other repeatable experiences ( Home , Story , Watching and Cooking pages), we set out to create a new experience that still felt part of The New York Times universe. We kept the design consistent by using our brand fonts and colors, similar rollover states and we even incorporated a grid that was also used by Watching. Our team has developed three connected applications that power The Times’s How-To Guides: the front-end application to render content; Scout, the CMS allowing editors to build guides; and our Go API, which is responsible for managing our data. We decided to leverage this stack to build the Holiday Gift Guide. To accommodate gift guides in our setup, we had to extend and adapt our application stack to varying degrees. Our CMS, Scout, is a Node React application that provides a drag and drop interface that editors can use to build web pages with a variety of deeply nested content blocks. Editors can simply move modules representing different content types — ranging from simple text to more advanced card carousels — around to create highly-customized pages. We built Scout with an eye toward scalability so we can quickly add new modules and functionality as our requirements and needs change. To achieve this, modules are entirely metadata driven. A configuration object describes the fields and field types that are supported, the default values that can be set and how to validate content. It also defines what other modules are accepted as child elements; For instance, a card carousel will accept cards as valid child elements, but not text. On the data level, we call instances of these modules representing distinct pieces of content Nodes. These Nodes are atomic units that link to each other (as stated in the example above, an instance of a card carousel links to their child cards) and represent documents. This normalized tree structure allows our Guides front-end application to recursively iterate over the data and render guides in their varying shape and form. Taking advantage of this setup, we only needed to add a number of new content types such as products, categories and price ranges to Scout, to support gift guides. The configuration object for the gift guide looks like this: Build Process To start, we needed to make sure to separate Guides and Gift Guide bundles in our Webpack build process. With a dedicated bundle for each app, we were able to load each app’s relevant javascript and stylesheets without unnecessary bloat. Luckily for us, Webpack has this functionality baked-in so we could designate multiple entry points and outputs for our build configuration. In order to use multiple entry points for our Guides and Gift Guides bundles, we passed an object with two key-value pairs containing the bundle name and file path. The bundles are identified by filename when they’re created, which leaves us with two separate files: guides.app.js and giftguides.app.js. Style and Component Structure The Guide and Gift Guide apps are both visually and functionally different, so we wanted to implement CSS Modules to leverage its style scoping at the component level. However, Guides doesn’t use CSS Modules and we were ultimately hindered by our Webpack set-up. With the short timeframe we had to work with, we decided to follow a component-based style structure. Every component has its own SCSS partial file that gets imported into the aggregate styles.scss file. Front-end server In order to take advantage of the benefits of server-side rendering, our Gift Guide front-end is powered by hapi.js , which is a web framework for building applications and services like APIs and static websites. To create a clear separation of powers on the server side, our hapi setup utilizes the plugin API. hapi plugins are essentially bundles of logic set up to remain isolated and work independently from other parts of the server. In our case, we used guides and giftguides plugins to handle the two distinct apps and create sandboxed environments for each. With this approach, our server logic in guides won’t be affected by anything done in giftguides and vice versa. API and Data Model Updates The data layer underneath Guides and Gift Guides is a Go API running on Google App Engine. The API persists to Google Cloud Datastore where each guide is represented as a tree data structure. Each visual element in a guide is a node in the tree that contains information such as the type of element it is (text, card carousel, image, etc) and the content required to render the element (text, image links, etc), as well as references to child nodes. For Gift Guides, we needed to extend the node model to handle two new content types: gifts and interests. To do this, we came up with a solution using ancestors in Datastore. Giving a node the ability to have a descendent of any kind allows us to have a base set of information which is the same across all Nodes, plus additional information in a descendent that only certain kinds of nodes will contain. This avoids the need to add additional fields to the node model, which would make it extremely large and inelegant. When an API call is made to retrieve the node tree of a gift guide, we loop through the nodes to see if any are a kind that would have a descendent. If so, we make query for that additional data. We use struct embedding in Go to achieve this result. For example, adding a Gift data type with an additional field of Price would look like this: The datastore query would then look like this: This has worked well for us and will allow us to extend the Guides platform in the future, if necessary. Once we had the user experience designed and the technological kinks worked out, our work wasn’t done: we had to fill the gift guide with gifts. In brainstorming how we would choose and present the gifts, we drew on our latest audience research and on our own buying habits. We all agreed that we were more likely to trust and take advice from a person rather than an institution (a sentiment that echoed our research), and that those people had to sound like, well, real people. We wanted the tone and look to be accessible and the categories to be based on interests, not wedded to newsroom coverage desks. We decided that Wirecutter would provide two-thirds of the recommendations, which would mostly be on the practical side, and that The Times would provide the rest — adding gifts that were unique, interesting or simply delightful. Times editors were asked to provide a specific number and type of gifts that we could sort into the 16 categories we had agreed upon. Those editors assigned the work to reporters and critics. Some had a heavier lift; The Culture desk, for instance, had to provide all of the gifts for the Arts & Leisure category, and the Books desk was similarly tasked. Writers and editors from Styles, T Magazine and Food contributed several gifts, and we hired freelance writers to choose gifts for Travel and Home. We gave each contributor a price range and told them the general idea: choose only gifts you would want to give yourself; write the description as if you were trying convince someone why yours was a perfect gift; and oh, did we mention your photo will appear next to them? We mostly got what we asked for! Some choices were vetoed because they were too practical (vegetable peeler), and some because they were too over-the-top (choir tour of Vienna). But in the end, we had a solid collection that appealed across interests and price points. Once we had all of the gifts, the guide took a large, coordinated production effort to bring to life. Over 50 people contributed to the product by the time we launched; a mix of editors, designers, engineers, product managers, advertising and data partners and many more. We truly worked in an agile way to launch the gift guide with plenty of collaboration, communication and delegation across all departments. Some of the challenges we faced were related to the sheer number of products included in the gift guide — sourcing images, copy, links and finally, fact-checking all of the gifts — was a huge undertaking. Working in batches of gifts helped us keep things moving while continuing to collect missing pieces. We even batched the image uploads to our asset management system by partnering with an engineer who helped us write and execute a script to handle image uploads overnight, which saved us a ton of time and manual upload labor. Meticulous file naming and organization of assets was another huge time saver for us. Production of the gifts and input into our CMS, Scout, was another big challenge. Without dedicated producers to do this, we adopted an “all hands on deck” mentality, and trained core team members on the system so that we could all simultaneously input our delegated lists of gifts into Scout in preparation for our launch. Coordination across teams and constant and clear communication was paramount to our success. In addition to meeting for daily stand-ups and co-locating whenever possible, we were incredibly transparent and collaborative with our documentation across all team members. Ultimately, we worked together as a team with a clear goal and deadline. There were no egos, and everyone really pitched in, whether that meant testing new features and logging bugs or inputting content. All of this paid off : we had a significant increase in the number of users visiting the gift guide (compared to 2016), and we found that over 15% of the users who did visit the gift guide actually came back over a period of two or more days — signs of a highly engaged user. And ultimately, we were able to create a scalable tool that now allows us to produce gift guides at a quicker rate. Our 2018 Valentine’s Day Gift Guide came together in less than a month. Production was a clear and streamlined process because we created reusable documentation to onboard new members to the platform. We also built the system so gifts can be reused in future gift guides, which cuts down on production time. We have given editors the flexibility to adjust the gift guide template based on their needs, and we’re excited to see the potential of our new gift guides system come to life. Keep an eye out for more gift guides through 2018! How we design and build digital products at The New York Times 30 User Experience Product Design Product Development Design Technology 30 claps 30 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-11-08"},
{"website": "NewYork-Times", "title": "scrum swarm sprint how to take the agile process and make it your own", "author": ["Olivier De Meulder"], "link": "https://open.nytimes.com/scrum-swarm-sprint-how-to-take-the-agile-process-and-make-it-your-own-b6416793ff7e", "abstract": "Code Data Product and Design Workplace Culture Work with Us Like many technology organizations, Customer Care Technology, my team at The New York Times, uses scrum as our main process. To plan our sprints, we would go through the backlog, pick stories and assign a story to each of our six engineers, who would then work hard to get their story done. Because of unforeseen roadblocks, the stories would often get pushed to the next sprint or we would work together on a story to finish it before the end of the sprint. The problem with this process was that by the time we realized we needed to work together, it was often too late in the sprint. Recently, we started working together, or swarming, for our entire sprints and only taking on a small number of stories at a time. Swarming is not a new concept; Many agile teams often swarm on a story to finish it before moving on to a new story. We took the definition of swarming and made it or own: We don’t just swarm to finish what has already been started, we swarm as soon as we start something new . And we’ve become more productive and collaborative as a result. A few months ago, the head of our department had a meeting with our team to encourage us to try a new way of working. As an engineering organization, it is important to focus on the right metrics, so we often focus on utilization or efficiency. However the more important metric is throughput: How much value can we deliver to the business and how quickly can we achieve this? Translate this to scrum. Focusing on reducing the amount of inventory (work in progress) we have at any given time means we can execute faster. Working on fewer stories at one time means we can finish more, faster. To understand how this works in practice, imagine this sprint scenario: We start with one story (let’s call this Story One), but Story One gets blocked by an external dependency, so we move on to the next story (we’ll call this Story Two). We have more work in progress. Because we started on Story Two late in the sprint, it is not done by the end of the sprint. During the next sprint planning we identify three new high priority stories (Stories Three, Four and Five). Now there is even more work in progress. At this point, the dependency that blocked Story One is resolved, so we switch gears to work on Story One again. But when our product manager asks us when we can get to Story Six, we have to finish stories one through five first. Increased work in progress hinders throughput. It takes longer and longer to get anything done. The head of our department suggested that instead of assigning one story to each engineer, multiple engineers should work simultaneously on one story. Thus we would have less inventory, less waste and increased throughput. At our first sprint planning meeting where we were going to swarm for an entire sprint, we divided the team into subteams and took on only two or three stories. When my subteam met for the first time, we looked at each other and scratched our heads; Trying to figure out how to divide the work was awkward. The idea behind swarming is to divide a story into smaller tasks that can be done in parallel, but sometimes it can be hard to divide the work because the tasks can end up being very interdependent and even overlap. Different stories will require different solutions. Here are some of the ways we tackled this. This may be the easiest and most logical one. If the story is, “Display a list of transactions, and for each transaction, there should be a ‘delete’ button to delete that transaction,” one engineer could work on displaying the list, while another could work on the ‘delete’ aspect. Another example, if the story is, “build new functionality that should only show up under certain circumstances,” one engineer could start working on the conditional display of the feature, while another engineer works on the feature itself. It is probably the most natural way of dividing up work, but everyone would still need to work closely together to coordinate the touchpoints between the two tasks. This is pretty obvious as well and is an easy way to divide work. Very often an engineer can start working on the UI, while another can work on the back-end. Again, working closely together is key. Agree on the contract that will bind the front-end and back-end first before you start working. Two engineers work together on one machine: one person is the driver and one person is the navigator. The driver writes the code and the navigator sets the direction, observes and reviews. The benefits of pair programming are well documented: fewer bugs, shared knowledge, more efficient problem solving. As part of our effort to swarm, we have done our share of pair programming as well. Especially for more thorny issues or complicated features, it has proven quite valuable. If you practice true test driven development, you’re supposed to write the test first, see it fail and subsequently write the feature. In our version of swarming, one engineer starts writing component tests and/or integration tests, while the other one works on the underlying functionality. We have gotten much better about integrating QA in our development process. We used to loop QA in after our code was pushed to the master branch, which was clunky. Now our QA engineers will identify and create a test plan as soon as we begin working on a new story. As initial development nears completion, an engineer and a QA engineer will run through test scenarios together on our local machines. The QA engineer may notice something that we had not thought of, or something that was missed in development, and at that point it is easy to remedy and fix. When the QA engineer likes what they see, we merge the branch into master and QA can verify it again on the dev server. The way we are doing QA now has been a huge revelation to me and has had a major impact on our team. Because QA is more involved with the coding earlier on in the process, we have been able to develop features much faster. Bugs and unforeseen features are discovered earlier in the process and can be handled immediately. In order to make sprint-length swarming work, you need planning and more planning. We typically have a story lead who meets with the members of the team and together, they break the story into subtasks in the way that makes the most sense. It is a collective planning effort. At that point we also agree on the contracts between the various subtasks. We also rely on the story lead to perform any needed coordination as we move along with the development. It is often believed that scrum involves less (project) planning, but we all know that this is not true. When you swarm, you need even more planning. After “swarming” for a few sprints, we started to get the hang of it. But ultimately, we are increasing throughput, which means we are completing features faster and delivering more. There are some other benefits as well. Few problems in this world don’t benefit from increased communication and software development is no exception. We talk about how to divide up the work, and we stay in close contact while we’re working because our projects often overlap. This means we can identify issues or roadblocks early in the sprint and correct accordingly. I would also argue that increased communication leads to better software design decisions. We often have a healthy debate about the best way to tackle problems, and we probably wouldn’t have these conversations if we worked independently By working closely together and discussing new features, we inevitably learn from each other: we learn about our specific domains, about the application we’re working on and general software building best practices. All in all, this has been a very positive experience for our team and I encourage everyone to try it. If you have any questions, feel free to reach out. How we design and build digital products at The New York Times 461 3 Agile Scrum Work Process Code 461 claps 461 3 Written by Software engineering manager NY Times, dad, husband, former startup founder, TaeKwonDo black belt, cook, news & tech junkie. Here are some of my mind ramblings. How we design and build digital products at The New York Times. Written by Software engineering manager NY Times, dad, husband, former startup founder, TaeKwonDo black belt, cook, news & tech junkie. Here are some of my mind ramblings. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-04-26"},
{"website": "NewYork-Times", "title": "talking technology scott belsky", "author": ["Nick Rockwell"], "link": "https://open.nytimes.com/talking-technology-scott-belsky-7a3a06bd141e", "abstract": "Code Data Product and Design Workplace Culture Work with Us Scott Belsky is the founder of Behance and 99U , and currently the Chief Product Officer for Creative Cloud at Adobe. He is also a frequent investor, a great writer and an all-around fun guy. Scott, thanks for contributing! You built a great product for designers in Behance, created one of the leading design conferences in 99U, and have focused on the contribution of design to entrepreneurship and product development; yet, you are not trained as a designer. Where does your affinity for, and understanding of, the role and centrality of design come from? While I first used Adobe Illustrator and Photoshop when I was 15 years old, I’m not a professional designer. But I’ve been a design obsessive for much of my life and have spent most of my career designing customer experiences in digital products. I entered college with interests in environmental science and economics, but completed much of the “Design & Environmental Analysis” major at Cornell by my senior year. I have always loved information design, and my interests in “making” things goes back to early childhood. But what really motivated me to found Behance and commit my professional life to serving the creative community was my frustration with the rampant disorganization in the creative world. There is so little attribution for who did what, and so much attrition in creative teams due to poor management. I was motivated to address these challenges and help “organize the creative world” however I could. How do you define design? What do you exclude from that definition The answer to this question is always changing. For me, at the moment, design is the discipline of removing life’s friction and crafting the little things that make a big difference. Over the years, and especially through Behance, I have had the opportunity to work with all kinds of designers from around the world. I’ve come to believe that the most effective designers are always solving a specific problem and seem to do so more by removing or simplifying than adding. While “new design” gets a lot of attention, the best design often goes unnoticed because it removed something that people never really needed. When a product or digital experience becomes materially easier to use, the design elements — the interface, copy and other attributes — all-together disappear. Such design decisions may not get awards or fanfare, but they make a product more accessible to more people. If design is important to your product or process, challenge yourself to look past the graphics, and what’s new and shiny at the surface. Develop a bias towards reducing rather than adding new elements. Most importantly, have faith that fewer options, shorter copy and simpler steps will always bring your product to a better place. In the moment this will feel counterintuitive — you’ll assume that progress means new features and a visual evolution of your product. But over time, you’ll learn that the incremental reductions and refinements allow customer experiences to flow better than most new features or additional copy ever could. As the saying goes, “the best design is the design you don’t see.” What has your focus on design taught you about leadership? Do designers make good leaders, and what can leaders learn from designers? So much of leadership boils down to communication, and so much of communication boils down to design. I think most leaders overestimate the value of meetings and underestimate the value of visual aids to drive alignment. If a picture is worth a thousand words, a mockup or prototype is worth a thousand meetings. Leaders without a design background should recognize the value of partnering with designers rather than outsourcing to them. Having a designer at the table when solving product or communication challenges is a competitive advantage. If a picture is worth a thousand words, a mockup or prototype is worth a thousand meetings. I’m concerned that despite, or perhaps because of, our emphasis on cross-functional teams, we have become very siloed in our approach to building things. How do you think about the relationship between designers, developers and product managers, and how they collaborate? There are books to write on this topic, but when a team has tremendous trust in each other, structure matters less than you might think. I like the idea of early explorations being designer-led and unbounded by the constraints of logic and reality, which tends to mean that designers and forward-thinking product leaders should own the first stage of product development. Of course, engineers must be engaged as soon as there are concepts to share, and [they should] ultimately empowered to challenge what designers have in mind. As for product managers, they are conductors. The worst product managers becoming the epicenter of activity and inhibit designers and engineers from having to talk to one another. The best product managers are conduits, prompting the right interactions at the right time and bringing the team together. You are a proponent of creative conflict, of surfacing tensions even to the point of “stabbing people in the front.” Do you think this can go too far? How do you create a safe and inclusive environment that is also honest and transparent? An honest and transparent culture can be uncomfortable, and great teams accept this. “Conflict” occurs when opposing viewpoints are pursued openly rather than suppressed and reconciled privately (or not at all). But these “elephants in the room” are the silent bottleneck to breakthroughs. If they persist, you will fail. The best teams in my life have endured conflict and discomfort because of the level of respect everyone has for one another. You’ve written about a product life cycle whereby well-meaning product teams just add complexity to their product, until users abandon for a simpler one. Should we just stop at some point? Can a product team continue to develop a product without ruining it? Indeed, new products win over users with their simplicity and add complexity over time to appeal to power users (and build a business), and then the process repeats itself. Teams that defy this practice continually simplify their products over time. For example, some teams try to remove or simplify features at the same pace as adding new features. Other teams attempt a reboot at some point in their product’s life cycle where they design a new version with a vastly simpler foundation. The first step is acknowledging when you’re catering too much to power users and failing to engage the latest cohort of new customers. Sometimes I think we overinvest in products that are important, even though the extra people and effort actually hurts the product. Have you seen this happen? What’s the alternative? Keep teams nimble. My former COO at Behance, Will Allen, used to always push teams to “refactor, refactor, then hire” when they came asking for more headcount and resources. Small teams can run circles around big teams faster and without as much tripping. You’ve written about the interface layer — design-oriented products that aggregate or overlay other products. Some of your examples, such as Circa or Flipboard, haven’t fared so well, but others have, like Google Maps or Alexa. Why do you think that is? How is this theory evolving? A few years ago, I wrote about how “the interface layer” would commoditize much of the technology underneath. I’m actually writing a follow article now! What I didn’t realize was just how disruptive such interfaces would be. Like a game of slap-a-hand, where hands pile upon one another until the winning hand is on top of the stack, a “disruptive interface” is one that, either by consumer preference or brute force, layers on top of other products and services, and gains control of the end-user’s experience (and thus decisions). Disruptive interfaces are successful because they are simpler and offer a better user experience than the more clunky and complex systems they supplant. Consider the step-function increase in quality of user experience over the years for a simple task like buying batteries: Before The Web: Go to store, browse brands and buy AA batteries, with manual check-out: 1 Hour Web: Go to website, browse brands, buy AA batteries, enter credit-card with online check-out: 5 Minutes Mobile/Amazon: Go to Amazon, browse brands and buy AA batteries, with Apple Pay or One-Click: 1 Minute Voice: Ask Alexa for AA batteries, hear default option, say “yes”: 20 Seconds New mediums on the horizon, namely voice and augmented reality, will do far more than save us time. They’ll eliminate browsing all-together by proposing a default answer and eliminating options. At first blush, the time-saving is a great benefit, but the implications are far reaching. As machine learning understands how we live better than we do, we will not only want but expect the best solution to every problem. As interfaces reach their own version of “singularity,” when they become intelligent and reduced enough that they stop offering choice and only present a single option (and perhaps executes it for us), the default becomes the ultimate prize. In such a world, customers will live by a string defaults — the ride they order in the morning, the lunch that is delivered, the groceries they buy, the music they listen to, and perhaps even the media they consume. We’ll favor the default option not only because it is fastest, but also because it (presumably) takes our interests into account. Such power in defaults will unleash a competitive — and potentially regulatory — dynamic that the world has never seen. I love your idea about prioritizing the needs of new users, as well as your warning about how hard this can be. How do you maintain empathy for the new user on a team that will of course be expert in their product? Ground yourself with the latest cohort of new users. The mistake teams make is to stop iterating the “first mile” of product experience once it works. The kind of customers you have at the beginning are far different from the ones you’ll have later on. Keep a decent percentage of your team’s time focused on evolving the first mile (stuff like onboarding, the tour, etc…) at all times. Is there a product that you’d like to see the New York Times build? Now that you asked, I’d love to be able to “follow” stories of interest, so I can see any future updates and related articles versus have to discover them out of luck or accident. I would also love to see a visual representation of fact-checking, so readers can grasp the iceberg of diligence and research beneath every story. How we design and build digital products at The New York Times 192 User Experience Interview Design Thinking Conversations 192 claps 192 Written by SVP Engineering at Fastly, ex-CTO at NYT. Passionate about tech, music, science, art, helping others be their best. How we design and build digital products at The New York Times. Written by SVP Engineering at Fastly, ex-CTO at NYT. Passionate about tech, music, science, art, helping others be their best. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-06-14"},
{"website": "NewYork-Times", "title": "nyt and women who code london seek to rebalance gender among uk technology hires", "author": ["Nicole Taylor"], "link": "https://open.nytimes.com/nyt-and-women-who-code-london-seek-to-rebalance-gender-among-uk-technology-hires-feeeca85c124", "abstract": "Code Data Product and Design Workplace Culture Work with Us On Thursday, March 1, The New York Times launched a technology symposium in collaboration with Women Who Code London, a non-profit organization that aims to support and retain women in technology. It’s the first time The Times’s technology group has held an event outside the United States, bringing together a panel of experts to address the problem of unequal representation of women in the technology sector and The Times’s response to the issue globally. Participants were encouraged to share their views on the current and future state of the workplace for women pursuing engineering and technology careers in the U.K. The event was organized by Gen Ashley, Director of Women Who Code London and the program was curated by software engineer Abigail Diaz. Diaz spoke to participants about The Times’s technology mission to tackle not only technical problems but also cultural problems within the current technology space, working with the wider industry to identify solutions. She emphasized The Times’s commitment to create safe spaces for healthy dialogue on how to develop, retain and advance female talent. Information security analyst Neena Kapur spoke about her work finding innovative information security and privacy solutions, and deputy editor of the interactive news desk Scott Blumenthal, together with software engineer Britt Binler, shared their experiences developing newsroom tools and digital story forms. The Times’s CTO, Nick Rockwell, joined remotely in a conversation with gender editor Alicia Wittmeyer about the recruitment, development and support available for female engineers in the media and technology industries. Vice president of international consumer revenue Charlotte Gordon also presented alongside global editorial director for T Brand Studio Nelly Gocheva. The event, held at LABS Hogarth House was attended by more than 130 participants from a variety of industries including technology, media, e-commerce and engineering, and was the first event in a series to be hosted internationally by our technology group in 2018. How we design and build digital products at The New York Times 19 Women In Tech Tech Women Who Code Technology News Code 19 claps 19 Written by How we design and build digital products at The New York Times. Written by How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-04-26"},
{"website": "NewYork-Times", "title": "five questions with orta therox", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/five-questions-with-orta-therox-d5bb9659c50b", "abstract": "Code Data Product and Design Workplace Culture Work with Us On February 14th, Orta Therox came by The New York Times’s office to talk about how his team at Artsy has adopted React Native, and he shared some of the ways Artsy documents its work and culture. We caught him afterwards to ask him some follow up questions. Interview by SARAH BURES What’s your role at Artsy and what kind of work you do? When I joined Artsy seven-ish years ago, we were a tiny team, which meant I had to wear many hats. Over time, my role became Director of Mobile, but when our team moved to React Native in 2016, we merged the mobile and web teams and I jumped back to being an individual contributor. I tend to think of my role as being an engineering janitor who has a lot of involvement with most Artsy projects. For example, in the last week: I’ve worked on consolidating our hiring process, I’ve worked on an Augmented Reality section in the app, I’ve helped to improve TypeScript support in our web infrastructure and I’ve been maintaining our internal team navigator. So I do a mix of process, product and infrastructure. You steered Artsy to work with open source by default. Can you talk about what that means and why it’s important to your team? “Open Source by Default” aims to shift a team’s mindset to a place where you need to argue that code should be kept private. Our CTO, Daniel ‘dB.’ Doubrovkine, coined the phrase internally, and I helped him take that idea and turn it into policy for the team I used to lead. Before the teams merged, we were asked by a magazine to write about how we worked in the open , which turned into our manifesto. After that point, we started to implement those across other teams. Open Source is important to me because I grew up outside of an urban center in Britain where I had very little in the way of community mentorship. Open Source gave me the ability to see how difficult things were built. I moved from being a beginner to an intermediate programmer by reading the source code that others had opened up. I became a macOS developer because of apps like Quicksilver , Adium and Colloquy . These macOS jobs evolved into iOS jobs, and now I owe my livelihood to Open Source. I choose to give back to that community by working in the open and by collaborating on the most impactful projects I can. Everyone in the Artsy Engineering team has different relationships to Open Source. Some people just work in the open — with little thought applied to the larger community aspects of it — because it’s how we work. Others embrace the ability to showcase their work to help provide a more holistic understanding of the process. Not all projects we work on are open source, so not all engineers work in the open. We made the conscious choice to keep some projects private: it’s Open Source by Default, not Open Source by Mandate. One of the best tools we have in favor of policies like this is that one of Artsy’s core values is openness. We use our interactions with the Open Source community as one way of expressing that value in the engineering team. Documentation and write-ups are obviously very important to you. What are some best practices you and your team follow for documenting your projects and technical philosophies? I believe there are many levels to documenting a project. You always start with the README, then you use tests to show the current priorities of a project, and you could use a VISION file to describe the long-term goals. Each escalating step talks about the “how,” so documentation, like blog posts, should be used to cement the “why.” I spent a long time as a remote developer, which made it harder to be involved in those passing, watercooler-type talks that can cement ideas. I opted to try and use write-ups on our developer blog for ideas, major projects and achievements. It’s generally a safe assumption that people internally have read our blog posts. It takes time to do the write up, but further down the line when you’ve forgotten the context or someone else is there for the first time, being able to understand why those decisions were made really helps make everyone’s lives easier. One of my colleagues, Ash Furrow , is really the powerhouse behind improving the state of our public documentation. He runs weekly writing workshops internally and always encourages achievements as being post-worthy. Sometimes the best practice is to have someone who cares encouraging you. It works for me. Since Artsy has adopted React Native, you’ve held public retrospectives every six months. What do those entail and who participates? The retrospectives are mainly triggered by a project coming to an end, or by external events as that tends to be when the topic naturally arises. We have an iOS front-end Slack channel that any engineer can contribute to; we use this channel for day-to-day coordination and for retrospective discussions. It’s quite informal; we could be discussing our slides or why linking to the app has failed again — even this interview went through that Slack channel for discussion. Our first retrospective was used to decide whether or not to continue with React Native. We had explored other alternatives to our engineering issues at the same time, and it took roughly six months to wrap up all of these projects. We discussed our options in person, and had team meetings where we made the agreement that React Native was the right option for us. Eloy ‘alloy’ Durán, who had initially proposed React Native, summed up our team’s feelings in an announcement blog post . In six months, I finished my first serious contributions to that codebase and understood how React Native worked, and we felt more confident in our beliefs on the trade-offs and its value. I used this as a time to collect our opinions again, and to present a nuanced take on the state of iOS development after taking some time with React Native . The next two retrospectives were written after being invited to speak on the topic of React Native, which was a perfect time for reflection. You have this great concept of “developing at the speed of thought,” can you talk about what that means to you? As iOS developers at Artsy, we were getting frustrated at the tools provided by Apple for building apps. We couldn’t make our own changes to them, so we actively contributed to projects used to augment Apple’s tooling. But we still had no control in the direction of where things were heading. React Native gave us the ability to control our destiny, and the ability to iterate considerably faster on our app. Imagine that every time you wanted to see a new message from a friend on iMessage you had to shut down the app, load it up from scratch and then click on their name again. That’s what it feels like to build something with Apple’s tools as an iOS developer. It has always been that way, so it’s not strictly frustrating until someone shows you that maybe it doesn’t have to work like that. It takes looking from outside of the native development tools to really understand the trade-offs been made for you. Seeing changes instantly as you work is “developing at the speed of thought.” It saves a considerable amount of time and can open up a larger world of creative expression. Feedback cycles are important and when you’re spending all day, every day, working in an environment like this you can really start to thrive. You want the connection between you and your work to be a close as possible. While you’re not quite building apps with your fingers and directly interacting with it, being able to change code and see your changes instantly brings us closer to inventing on principle . Orta Therox is an engineer at Artsy , runs a dependency manager, a unit test tool for culture and operates on open source by default. How we design and build digital products at The New York Times 85 1 React Mobile Artsy Conversations Code 85 claps 85 1 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-11-09"},
{"website": "NewYork-Times", "title": "improving our video experience part three accessibility", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/improving-our-video-experience-part-three-accessibility-233102847e15", "abstract": "Code Data Product and Design Workplace Culture Work with Us By CHRIS CALLAHAN , VERONICA YUROVSKY and KE XU This is the third and final post in a series about the progress and achievements of our video delivery platform. The previous posts are Part One: Our On-Demand Video Platform and Part Two: Our Live Streaming Platform . Improving the accessibility of the video experience on our web properties was one of our main goals for 2017. In this post, we will talk about how we built closed captions support into our video delivery platform and how we made the control set on our video player more accessible. The goal for adding closed captions was to make our videos accessible to more viewers in more scenarios. Some viewers are deaf or hard of hearing and need closed captions to be able to fully understand the content of our videos. Some are used to watching muted, autoplaying videos on social media feeds and want the same experience when browsing nytimes.com or our mobile apps. Some might use closed captions to help improve their language skills. Not providing closed captions to videos essentially locked these and other viewers out of experiencing the rich quality of videos produced by video journalists at the New York Times. Implementing closed captions also creates some new possibilities for our video experience. Closed captions and subtitles use the same underlying technical implementation for videos on the web — in our case, Web Video Text Tracks (WebVTT) with cross-browser support aided by hls.js — which means we’ve opened the door to adding subtitles in languages other than English in the future. Creating video transcripts based on closed captions also now becomes an easier task, which would improve the searchability of our video library. We had several considerations to keep in mind: As with our encoding integration, we wanted the process to be as straightforward as possible. We wanted to require the fewest number of mouse-clicks to generate captions, accommodate varying caption-generation speeds, have the ability to copy edit the captions, and control when the captions are visible to the viewer (the ability to “publish” and “unpublish” captions). The journalists should have the option to generate captions without depending on the encoding process. Though the captions could be generated when encoding the video, they could also be generated at any time following the initial encode without having to re-encode the asset. In the service we designed, the journalists can generate captions in various parts of the publishing process. They can opt to create captions as they upload and encode a video, or they can generate them independent of any other action if a given video asset already contains previously encoded renditions. The video team can also choose to generate captions in any one of three ways: Machine-Generated Captions : As the title suggests, these captions are generated by a computer, which makes them less than accurate (usually at about 70% accuracy) and might require extensive editing. This option is used almost exclusively for breaking news content that needs to appear on the site as soon as possible. 2-Hour Captions : This option involves a human transcriber and guarantees a 2-hour turnaround during normal business hours. The journalists are only required to do minimal editing changes with those. Same-Day Captions : This is the slower human-generated option which is mainly used for non-urgent content. If the journalists already have a captions file for the video on their computer, they can upload it and forego the above caption-creation step. Once the captions are generated or uploaded, the CMS UI reveals a ‘Review’ button that allows the journalist to review the captions with our external provider. They can change the timing, copy edit the text, and once satisfied, finalize their edits and return to the main UI. After copyediting, the captions are ready to be published. The journalist simply presses on the button to make the captions live, and they become available to the video player within seconds. If, for some reason, they are unsatisfied with the captions, they can always press another button to unstage the captions and remove them from the player. To add closed captions support into our video publishing workflow, we created a microservice called video-captions-api . Behind the scenes, we use third-party vendors like 3Play Media to generate captions from videos and Amara for editing captions. We had two major goals in mind when creating and integrating video-captions-api into our existing video publishing pipeline. First, we wanted to make this microservice agnostic to the newsroom workflow, which is always subject to change, to make it more stable and easier to open source. Second, as speech-to-text mechanisms and technologies evolve at a fast pace, we wanted the system to provide us flexibility in the vendors we use to generate captions, so we reduce the possibility of vendor lock-in, and have the potential to extend. In the implementation of video-captions-api, we created an abstraction called provider, which can be either a wrapper of a vendor API client or a module that provides some basic functionality. Each provider performs exactly one operation on captions. For example, the 3Play provider wraps a client for the 3PlayAPI and is responsible for generating captions from a video file. To generate captions from a video file, we create a job with the provider set to 3Play, and when this job is finished, we fetch the generated captions file from 3Play API and upload it to our GCS bucket. Similarly, to review and edit an existing captions file, we simply create a job with the provider set to Amara, and when the editing is submitted, we mark this job done. The lifecycle of a captions job for the CMS then consists of several jobs on video-captions-api. From the CMS’s perspective, the status of a captions job can be “generating,” “generated,” “being reviewed,” “reviewed” and potentially more, but from video-captions-api’s perspective, there are only two statuses for a job: “in progress” and “done.” To serve a captions file with a video, we just need to include captions metadata in the M3U8 manifest of that video. On the player side, hls.js parses the manifest and retrieves the captions file. Since we need the ability to publish videos and captions separately, we need to be able to update the M3U8s after videos are already published. Thanks to our service that generates adaptive bitrate streaming formats on the fly, this becomes simple and natural. Once a captions file is published, that file is uploaded to a GCS bucket. Simultaneously, the cached M3U8 manifest of this video is purged. When the next user makes a request for this video, we generate a new M3U8 manifest — with all of the video renditions previously defined as well as the captions content — on the fly. That manifest then gets cached until the next time we update a video rendition or the closed captions. After landing the closed captions project in production, we decided to do an accessibility audit of our video player’s UI using a keyboard and screen reader for navigation. Our goal was for this mode of interaction with our video player to be as smooth as it is using a mouse. We quickly realized that this interaction model was broken. Fortunately, we were able to take a few simple steps towards fixing the player’s keyboard and screen reader UX. In order to make the controls accessible, we needed to update the video player’s markup with semantic HTML. We replaced <div> s and <span> s that had masqueraded as buttons with actual <button> elements. For slider controls (e.g. the volume slider), <input type=\"range\"> was a perfect fit. We also added ARIA attributes and the HTML title attribute to the markup of our controls to provide more context for screen reader users. was updated to: The big win here was being able to take advantage of the accessibility features that browsers bake into <button> , <input> , and friends, such as focus handling. was updated to: For cases where using semantic elements wasn’t possible, we continued using <div> s but added ARIA attributes and tabindex es to make these elements behave as the semantic versions would. With semantic elements in place, we added keydown event listeners to the control elements to allow them to support keyboard interactions. These event listeners closely mirrored the existing click handlers we already had in place. For example: After some discussion with our designers, we also decided to implement a custom focus ring styling on our control set that would be consistent across all browsers. The CSS to implement this was straightforward: But we had one remaining problem: Mouse clicks also focus these elements, and we only wanted to apply focus styles on keyboard navigation. Our solution was to keep track of the currently focused control element (if any) that had been focused by the keyboard and to prevent focus events from firing on mouse events: With these improvements in place, the control set on our video player has taken a big step forward for accessibility. You can check out an example of our improved video experience with closed captions and accessible controls here . Looking ahead, we are keeping accessibility in mind while planning future improvements for our video player. Some of the features we’d like to implement going forward include multiple language subtitle support, video transcripts, and improved keyboard and screen reader experience on our audio player and the remaining parts of our video player. How we design and build digital products at The New York Times 138 Accessibility Code Video 138 claps 138 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-05-29"},
{"website": "NewYork-Times", "title": "from pyeongchang to your pocket developing a new way to follow the olympics", "author": ["Isaac White"], "link": "https://open.nytimes.com/from-pyeongchang-to-your-pocket-developing-a-new-way-to-follow-the-olympics-1e8904ee0919", "abstract": "Code Data Product and Design Workplace Culture Work with Us During the 2016 Summer Olympics in Rio de Janeiro, Interactive News — with the Sports desk, Graphics desk and Digital Design department — experimented with a new way to connect to readers throughout the Games. The deputy sports editor, Sam Manchester, sent readers short, inside-scoop text messages that supplemented the rest of our Olympics coverage. It was a success: readers loved hearing directly from Sam, but there were some problems and limitations with the project. As we ramped up planning for our coverage of the 2018 Winter Olympics in Pyeongchang, South Korea, we set out to build on and improve 2016’s text messaging project. The main workflow problem was providing responses to individual readers. Some of the questions we sent to readers received thousands of responses, far more than Sam was able to answer himself. There were also technical issues, like the high cost of sending large numbers of text messages, the limitations on character count and the types of media that were supported. We could also include only United States telephone numbers, which further limited the readers who could participate. So for the Pyeongchang Olympics, we decided to try something different. Our goal was to build on the features readers liked in the text messages from Rio. We wanted to make the interactions with Sam more scalable and to send additional types of content while keeping the conversation more personal than reading a Times article or messaging with a bot. To meet this challenge, we developed an entirely new system, separate from the text messaging tool we had used in the past. Instead of contacting readers via text, we integrated with The New York Times’s iOS and Android apps to send themed notifications that look distinct from normal breaking news alerts. We can send these push notifications to readers who have signed up for this feature, and we can also send a push notification with a message specifically for a single reader. But not using text messages, or an existing messaging platform like Facebook messenger, meant that we had to display the messages ourselves once they were received. We decided to build an interactive web page that could be displayed in The Times’s apps and could receive additional device data to coordinate the push notifications. Because that page would have different content for each reader, it was also more challenging to scale, since we needed to keep track of each reader’s history of interactions with the page. We decided to use Google’s Cloud Firestore, a solution that would allow us to make dynamic queries to user data, while also supplying real-time updates. By building the reader-facing page with React and using patterns from Redux, it was easy to handle changes to the message content while readers were viewing their messages. In this new interface, readers can respond to multiple-choice questions in addition to sending freeform replies to Sam as they did with text messages. When readers respond to multiple-choice questions, we can split them into groups based on their answers and provide them with targeted follow-ups based on those responses. For example, if Sam asks which event our readers are most excited about, and some readers say downhill skiing, he can provide those readers more detailed skiing updates than the readers who said they’re excited about bobsled. Not only can we provide more targeted updates, but we can send more types of content than we could with SMS. That’s because at its core, the view of Sam at the Games is just a normal web page, and not a view that is restricted further by device-specific limitations. So beyond images and videos, readers may encounter some of our interactive features that they’re used to seeing on the website inside their message history. To sign up and get messages from Sam, you can go to nytimes.com/SamAtTheGames . From there, you can text yourself a link to sign up in the app, or if you are on your phone already, look for the Olympics Messages option in the sections menu. How we design and build digital products at The New York Times 95 Olympics Messaging News Apps Code Design 95 claps 95 Written by How we design and build digital products at The New York Times. Written by How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-06-15"},
{"website": "NewYork-Times", "title": "talking technology nick rockwell charity majors", "author": ["Nick Rockwell"], "link": "https://open.nytimes.com/talking-technology-nick-rockwell-charity-majors-2acad1690dcf", "abstract": "Code Data Product and Design Workplace Culture Work with Us This is the first in a series where New York Times CTO, Nick Rockwell, talks to leaders in the technology world about their work. Rockwell interviewed Charity Majors, the co-founder and CEO of Honeycomb, about observability software, debugging and “getting inside the software’s head.” Nick Rockwell: Can you give us some background about the problems you’re trying to solve with Honeycomb? Charity Majors: The market is saturated with monitoring startups, logging startups, analytics startups and APM (Application Performance Management). There are so many startups, it shows people aren’t terribly happy with the options available to them. And yet, the newer entrants aren’t terrifically different from the older products. Rearranging of deck chairs aside, monitoring hasn’t fundamentally changed in at least 20 years. I don’t mean to say the existing tools are bad; some of them are actually great at answering questions — your known-unknowns — or at building dashboards for canned metrics and system-at-a-glance, or anything and everything you can predict you might want to look at. The problem is, you can’t predict everything. It used to be the case that with our monoliths, our one big database and our predictable user patterns, we were very rarely stumped. You could glance at your dashboard and see which component was at fault, or check for a recent deploy, and that got you through 90% of all problems. If it was a new problem, you would sift through dashboards and use your intuition about what was happening under the hood, maybe attach a debugger or look at the queries in your database. Eventually you’d find the problem. Then you’d have a post mortem, write a monitoring check for whatever failed and maybe make a new dashboard to find that error condition instantly. Over time, you built up a solid repertoire and were very rarely stumped by what was going on in your systems. But that model is falling to pieces. With the decentralization and ephemeral nature of modern systems, you can rarely tell in a glance where the problem originates. You rarely encounter the same problem twice. Once-in-a-million edge cases happen all the time, at scale. Most of your problems are unknown-unknowns, and they aren’t cropping up monthly or yearly but many times a day . Our tools just aren’t built for that uncertainty. NR: Can you talk about what you like about troubleshooting? Where does that passion come from? CM: I actually don’t like monitoring — it’s always felt like an after-the-fact cleanup job — but I’ve always loved debugging. There’s something so fascinating, open-ended and terrifying about encountering a problem or a bug for the first time — especially in the data world, where your mistakes can literally put a company out of business. There are no experts out there who can come to your rescue; if you don’t solve it, no one will solve it. I love high stakes, and I love problem solving. I’ve grown to love doing both under pressure; but not everyone does, to say the least. Anybody who does a lot of debugging knows about the dopamine hit you get from fixing things, especially if you can track it down before it impacts your customers. Or the surge of raw joy you get from figuring out some hard, intricate problem. I always learn the most under extreme pressure. There’s no high quite like saving the world in the nick of time. NR: We have bad tools for instrumenting, monitoring and debugging our apps. What have we been getting wrong, and why? CM: They aren’t “bad,” but they were built to solve the last generation of problems. You need to know what you’re looking for in order to find it. Older tools prioritize the health of the system over the health of the event, they don’t handle high cardinality and they aggregate at write time. In older architectures, the health of the system was reflected in your user’s experience because all components were shared. So, if your system’s availability was 99.5%, your user was experiencing a failure 0.1% of the time, and failures were pretty evenly distributed. The health of the system was a great proxy for the user experience, so you could just look at your dashboards and understand the user experience pretty well. In newer systems, everything is sharded and horizontally distributed, so perhaps your availability is 99.5%, but 0.5% of users experience your site as completely down. That is far worse. And if your dashboards are aggregating over a time interval, your users’ bad experience will never show up. The health of newer systems is all but irrelevant. Your system may be down 25% of the time, but you don’t actually care unless it’s impacting your users. What is important is the health of each individual service request, and every slice of those requests (such as UUID, request ID, shopping cart, shard and so forth). High cardinality is something that none of our tools handle well. All the data you actually care about has high cardinality, whether that’s UUIDs, request IDs, first name/last name or ip host:port pairs. Debugging is like looking for needles in a haystack made of other needles, so you need to tag the needles with the highest cardinality data possible because it’s the most identifying. This is why I say that high cardinality will save your ass : you have to be able to identify all events with pinpoint accuracy, and you need all the high cardinality dimensions you possibly can. Debugging is like looking for needles in a haystack made of other needles. Write-time aggregation, while extremely high performing and efficient, robs you of access to raw events. I don’t think you can have true observability without being able to trace your way back to the source of truth: raw events. Once you’ve smooshed everything that happens over the course of an interval into a single number, you can never un-smoosh them again. There is no such thing as right or wrong, there are only different sets of trade-offs. For decades we’ve made trade-offs based on the metric, which is the smallest point of data you can possibly have — the metric throws away literally all the context of the original event, and then tacks a few tags back on so it can be grouped with other metrics. The metric became king in an era of extreme resource scarcity and expensiveness: hard drives, CPU and RAM were extraordinarily pricey 10–20 years ago, so we just had to put up with all the terrible side effects, like the explosive write amplification of tags. Hardware has gotten cheaper, user demands have gotten more outsized, architectures have gotten more complex; it’s Moore’s Law all the way down. We need a similar revolution in the observability space to take advantage of these changes. That’s why newer tools will, I believe, revolve around the (arbitrarily wide) event, rather than the metric. Events pack way more context, and say “all these values were true at once.” And events work the way our human brains do by helping us craft a narrative. NR: What makes a great ops person? CM: Great operations engineers are made through curiosity and stubbornness. I know so many ops people who are dropouts, specifically liberal arts dropouts. Old school systems, particularly unix systems, are very friendly to people who love languages and have patience for poking around and exploring. A top-notch engineering education isn’t especially valuable when it comes to debugging hard problems. It’s much more about persistence and desire. NR: How do you think about instrumentation? Should one be selective in what you instrument, or just try to grab “all the data” and sort it out later? CM: Any time someone says, “just instrument everything” or “monitor everything,” I hear, “I am unwilling to make hard choices and have poor technical judgment.” You can’t watch everything. Instrumentation and monitoring have costs, just like anything else. You should gather as much as possible, and you should select tooling that encourages you to gather rich detailing and makes it cheap, but there are plenty of hazards attached to just dumping trash into logs and hoping someone else will sort out the signal from the noise later. NR: How do you feel about mixing metrics, such as ops metrics, other engineering metrics or product/business metrics? Where do you draw the lines, if you do? CM: Many of the lines we have drawn around tooling — metrics, monitoring, business intelligence, logging, APM — have been drawn because hardware was so incredibly expensive and we had to make trade-offs. As hardware gets cheaper, these lines will erode. Tools build silos. Teams that don’t use the same tooling can’t speak the same language, and they cannot fluidly share insights. I think that over the next five years, you will see many of these categories dissolve and vanish and be replaced by the umbrella category of “observability.” If there’s one thing dev-ops has taught us, it’s that silos are inefficiencies made manifest. Tearing down silos may be the work of generations, but data is exactly where it begins. NR: I like your idea that given enough scale, black swans are the norm. Can you talk more about that? What are the implications? How do you prepare for the unexpected? CM: Lots of things happen rarely, maybe once in a million. But at the scale we tend to run these days, that can be kind of a lot; certainly often enough to make your platform unusable for some people. In a mature system, every time you get paged should really be about an unknown-unknown. You cannot predict all the possible ways a system may break, and you shouldn’t try. You should invest that energy into guard rails for your production systems, safety measures that make failures easy to detect and recover from. Invest in canarying, rolling deploys, feature flags and rich exploratory tooling. These are the tools that Google and Facebook have had for years. Now that our problems are catching up to theirs, our solutions must too. Every individual problem is a rarity, something that almost never happens. But in aggregate, failure is incredibly commonplace. We need to treat it like a fact of life — it’s when we fail, not if we fail — and practice until it’s boring. Focus on making your critical path as narrow as possible, and make your systems resilient to all other failures. You should only have to wake up in the middle of the night for failures that will put you out of business, and those should be remarkably few. It’s amazing how much failure you can really tolerate without anybody even noticing. NR: A lot of startups are trying to apply Machine Learning to ops in general and troubleshooting in particular. Are you? Do you think there is potential there? CM: No. Not any time soon. I’ve seen their internal success metrics, and they’re pretty awful. The problem is,you first have to train the machine on your own corpus and the learnings aren’t really reusable across system boundaries. You also have to substantially retrain it every time it changes, which may be several times a day. And false positives are incredibly costly from a human perspective. So you’ve got people with large systems generating thousands of alerts every minute, and you’re trying to get some signal from that noise. This can be done, but you know what can be done better, easier, more cleanly? Removing those flappy or non actionable alerts. If you don’t have a system generating that many alerts, machine learning isn’t going to do much for you anyway. So in basically every case, I recommend more intelligent inputs rather than trying to make the robots cull the herd for you. It’s not at all hard, and the results are dramatically better. NR: I jotted down in my notes the phrase, “getting inside the software’s head,” so maybe you said that. Did you? If you did, I love it. What have you learned about how systems think over the years? CM: Yes. You have to look at the systems from the perspective of the application itself, because almost nothing else matters. This is a seismic shift in operations and observability. Nines don’t matter if users aren’t happy. User happiness has nothing to do with system health, but has everything to do with application health. We’ve been learning to treat infrastructure as a disposable resources for 10 years; these shifts in observability signal that we’re very nearly there. NR: So, what are you up to now? What is the thought behind Honycomb.io and what do you want to accomplish with the company? CM: Well, I think the center of gravity is shifting rapidly towards the generalist software engineer — even for infrastructure products. A lot of people think of it as “ops engineers vs software engineers,” when actually it’s more like “infrastructure vs product” where both are made up of software and operations engineers. But while ops and database administrators aren’t going away any time soon, they increasingly live on the other side of an API from the software engineer’s perspective. And I don’t think anybody in the space is effectively building for the software engineering eye, everyone is building for operations. That’s short-sighted. I also think the cloud vs on-premises wars are over (spoiler alert: cloud won), and that the lines are blurring between vendors and teams. A good vendor should feel like a services team inside your company, and a good services team inside your company should feel just like a vendor. People are narrowing their focus. Engineering cycles are the scarcest resource any company ever has, so why are we wasting them on things that have no competitive advantage? It’s very costly to roll your own servers, email, metrics — that whole massive iceberg of support software that empower you to build your business and your core differentiators. People are increasingly willing to outsource to companies that specialize in those services, and for good reasons. We are still in the early years of the distributed systems revolution. It’s only going to gather momentum over the next 5–10 years, which is why we are only trying to sell to the people who already know they have these problems: platforms, multi-tenant systems, microservices architecture. The way people’s eyes light up when you show them how to make impossible problems into easy problems — that’s what keeps us going. I think that treating systems like they are complex and distributed is going to be the next wave of innovation akin to Continuous Integration/Continuous Deployment. The testing phase doesn’t stop when code hits production — it’s only begun to mature with real users, real data, real services. You’ve got unit and integration tests; then you deploy a canary to production and commence production testing. This simply hasn’t been possible without high cardinality, event-oriented observability. Charity Majors is the co-founder and CEO of Honeycomb, which is building observability software for a new generation of distributed systems. Nick Rockwell is the CTO of the New York Times. How we design and build digital products at The New York Times 284 3 DevOps Debugging Continuous Integration Conversations 284 claps 284 3 Written by SVP Engineering at Fastly, ex-CTO at NYT. Passionate about tech, music, science, art, helping others be their best. How we design and build digital products at The New York Times. Written by SVP Engineering at Fastly, ex-CTO at NYT. Passionate about tech, music, science, art, helping others be their best. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-06-14"},
{"website": "NewYork-Times", "title": "play by play moving the nyt games platform to gcp with zero downtime", "author": ["JP Robinson"], "link": "https://open.nytimes.com/play-by-play-moving-the-nyt-games-platform-to-gcp-with-zero-downtime-cf425898d569", "abstract": "Code Data Product and Design Workplace Culture Work with Us Recently I wrote about moving the platform behind The New York Times Crossword to the Google Cloud Platform and mentioned we were able to cut costs in the process. I did not get to mention the move occurred during a timeframe where our traffic more than doubled and that we managed to do it with zero downtime. Even from the start, we knew we wanted to move away from our LAMP stack and that its replacement would likely be written with the Go programming language, leaning on GCP’s abstractions wherever possible. After much discussion, we came up with a microservice architecture and a four-stage process for migrating public traffic over to it. We drafted an RFC and distributed it internally to get feedback across the company and from our Architecture Review Board. Before long, we were ready for stage 1 and about to run into our first round of surprises. For the initial stage, we wanted to simply introduce a new pure proxy layer in Google App Engine (GAE). Since all nytimes.com traffic flows through Fastly , we were able to add a rule to point all crossword traffic at a new *.appspot.com domain and proxy all traffic into our legacy AWS stack. This step gave us ownership over all of our traffic so that we could move over to the new stack, one endpoint at a time, and monitor the improvements along the way. Of course, right off the bat we ran into issues, but for the first time ever, we also had an array of tools to let us peer into our traffic. We found that some web customers were unable to access the puzzle, and found the cause of the problem to be App Engine’s limit on the size of outbound request headers (16KB). Users with a large amount of third-party cookies had their identity stripped from the proxied request. We made a quick fix to proxy only the headers and cookies we needed and we were back in action. The next problem came from our nightly traffic spike, which occurs when the next day’s puzzles are published at 10pm Eastern time. One of App Engine’s strengths is auto-scaling, but the system was still having problems scaling up fast enough for our 10x+ jump over the course of a few seconds. To get around this, we use an App Engine cron task combined with a special endpoint that utilizes an admin API to alter our service’s scaling settings right before we expect a surge in traffic. With a handle on these two problems, we were ready to move to the next stage. Between all of NYT’s puzzles and game progress for all of our users, there was a lot of data in our existing system. In order to smooth the transition to the new system, there needed to be a mechanism to replay all of our data and keep it in sync. We ended up using Google PubSub to reliably push data into our new stack. For puzzle data, we added a hook to publish any updates from our internal admin to our new “puzzles” service. This service would manage upserting the data into datastore and invalidating any caches. For game progress, we went the duct-tape route and simply added a process with a cron to query the legacy database for new updates and emit them over PubSub to a new “progress” service in App Engine. While we were able to rely on PubSub’s push-style subscriptions and App Engine for the majority of our data, we did have one use case that was not a good fit for GAE: generating PDFs for our puzzles. Go has a nice PDF generation library but some of the custom fonts we needed to use led to unacceptable file sizes (>15MB). To get around this, we had to pipe the PDF output through a command-line tool called ghostscript . Since we could not do this on App Engine, we added an extra hop in our PubSub flow and created a small process running on Google Container Engine (GKE) that listens to PubSub, generates the PDF, and then publishes the file back out to PubSub, where it is consumed by the “puzzles” service and saved to Google Datastore. This is the stage where we learned a lesson on managing costs when doing heavy work in Google Datastore. The database uses the count of entity reads and writes to determine costs and, while replaying all of our historical game play, our user statistics were getting signalled to be reaggregated almost constantly. This reaggregation led to many collisions and recalculation failures which unexpectedly resulted in us spending thousands of dollars one weekend. Thanks to Datastore’s atomic transactions, we were able to toss a locking mechanism around statistics calculations, and the next time we replayed all user progress to the new environment, it was a fraction of the cost. With our data reliably synced in near-realtime, it was time to start turning on actual endpoints in GCP. Soon after data began to sync over to the new stack, we started making changes at the “edge” service to point to our newer implementations, one endpoint at a time. For awhile we were at a pace where we were confidently switching over one endpoint a day. Rewriting existing endpoints to the new stack wasn’t our only job during this timeframe. We also had a new, read-only endpoint to implement for the new iOS home screen. This new screen required a mix of highly cacheable data (i.e. puzzle metadata) and personalized game data (i.e. today’s puzzle solve time). We have two different services for hosting those two different styles of data in our new stack and we needed to combine them. This is where our “edge” service became more than a dumb proxy and enabled us to combine information from our two sub-services. In this stage, we also replatformed the endpoints in charge of saving and syncing game progress across multiple devices. This was a major step as all related endpoints dealing with user statistics and streaks also had to be migrated. The initial game progress launch was a little rockier than we had hoped. One endpoint was experiencing much higher than expected latency and a plethora of odd edge cases popped up. In the end, we were able to cut out an unneeded query to remove the extra latency on the slow endpoint but the edge cases were a bit tougher to chase down. Once again, thanks to the observability tooling available in Google App Engine, we were able to track down the worst of the bugs and we were back to smooth sailing. Once the systems around puzzle data and game progress were stable and running purely on Google’s infrastructure, we were able to set our sights on the final component to be rewritten from the legacy platform: user and subscription management. Users of the crossword app are allowed to purchase their subscription directly through their device’s app store. (For example, an iPhone user can purchase an annual NYT Crossword subscription directly from the iTunes store.) When they do so, their device is given a receipt and our games platform uses that receipt to verify the subscription when the app is loaded. Since verifying such a receipt is a task that could possibly be used by other teams at The New York Times, we decided to build our “purchase-verifier” service with Google Cloud Endpoints. Cloud Endpoints manages authentication and authorization to our service so another team in the company could request a API key and start using the service. Given an iTunes receipt or a Google Play token, this service tells us if the purchase is still valid and when it will end. To authenticate direct NYT subscribers and to act as an adapter to translate our existing authorization endpoints to match the new verification service, we add a small “ecomm” service in the mix. The final public endpoint went live on GCP a little over 2 months ago and we’ve been actively resolving small edge cases and tuning the system for maximum efficiency and costs. Thanks to GCP’s observability tooling, it’s not uncommon for the platform to have a day with 99.99%+ success rates and far lower latencies than we had in the past. We still have a PHP admin component running in AWS for managing our system’s assets and feeds, but we’re currently redesigning and rewriting it to run on App Engine. Our next iteration is already reading and writing to a Google Cloud SQL instance so we hope to be out of AWS completely in the coming months. For the future of the games platform, we’re looking into adding some new exciting features like social leaderboards and real-time collaborative multiplayer crosswords . By leaning on managed solutions from Google Cloud Platform like Firebase’s Realtime Database , we’ve had some very successful prototypes and we hope to have them available to the public sometime next year. If you’ve been intrigued by some of the engineering behind The New York Times, you may be like to know that we’re currently hiring for a variety of roles and career levels: Senior iOS Engineer, Games Team Web Engineer, Games Team All Tech Jobs How we design and build digital products at The New York Times 734 6 Google Cloud Platform Code Software Development DevOps 734 claps 734 6 Written by Senior Software Engineer at Datadog. A user of Go. A lover of cats. How we design and build digital products at The New York Times. Written by Senior Software Engineer at Datadog. A user of Go. A lover of cats. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-04-26"},
{"website": "NewYork-Times", "title": "agrarian scale kubernetes part 1", "author": ["Michael Strickland"], "link": "https://open.nytimes.com/agrarian-scale-kubernetes-part-1-7ea703d4de08", "abstract": "Code Data Product and Design Workplace Culture Work with Us Visit the Kubernetes homepage , and one of the first things you’ll see is the promise of “Planet Scale.” The S-word is plastered across the pitch for Google’s managed version of Kubernetes as well (Google Kubernetes Engine, or “GKE”). Demand-based autoscaling! Support for thousands of host nodes! Cross-region federated clusters! The ability to scale easily to heavy workloads, across geographies and even multiple clouds makes Kubernetes and GKE great choices for high-traffic websites. Because so many of the apps we create on the Interactive News Team are used only by reporters and editors in the building, we tend to take greater advantage of the less discussed dimension of scaling: fitting many applications into a single cluster. Consider our concerns on a kind of agrarian scale: a single plot of land (our newsroom) where our biggest concerns are crop rotation. We love Kubernetes because the same design we use for our infrastructure supporting hundreds of apps is simple enough for many other smaller cases. Whether it’s deploying one quick side project or a small team’s constellation of apps, we’ve found that Kubernetes on Google is achievable and sustainable for those without a background in devops. While the list of features continues to expand, GKE scales down both in hardware and in complexity and can be a practical solution for the smallest of projects. This guide is an outline of our devops philosophy on Interactive News at The New York Times, by way of tutorial. It assumes you can copy code into a command line, and that you have a rough understanding of what containers are. (Docker has a brief overview here .) You don’t need a background in cloud infrastructure. Applications need to use containers to run in Kubernetes, but if you don’t have your own app container-ready, here is an example container image you can use. You’ll also need a Google Cloud Platform account . There are more general Kubernetes tutorials out there that are worth reading. This guide focuses on using some guiding principles we’ve found helpful in designing infrastructure as a development team in a newsroom, where we try to give developers a high degree of flexibility over (and responsibility for) their own app architectures. A few of them to begin: Use default configurations to make operations simpler and maintenance mistakes harder. Expect Google’s documentation to always be better than yours. Incorporate the fewest types of resources into your infrastructure as possible, to reduce the scope of what developers need to learn. Try not to use third-party plugins. Part 1: Creating your first Kubernetes cluster on Google Kubernetes Engine, and setting up the gcloud and kubectl command line tools. Part 2: Deploying a web application using Kubernetes Deployments and Pods . Part 3: Using a Kubernetes Ingress to create a load balancer that will route public traffic to your app. By the end, you’ll have a working Kubernetes cluster that you just might find easier to use than the raw Elastic Compute instance you were about to boot up. I’ve been met with skepticism (and accused of overarchitecting) in the past when I say our team of roughly 15 developers uses Kubernetes, and for a good reason. The conceptual startup costs of building a Kubernetes cluster “from scratch” (not using a managed service like GKE) are significant. It means creating and maintaining a master node, etcd cluster and one or more worker nodes, and uses a flavor of linux most of us had never heard of. On GKE, you don’t maintain or pay for the master node or etcd cluster: they’re included components of the service. The only underlying servers you control are the worker nodes that run your containers, giving you a much better ratio of billable-to-usable hardware and freeing you from needing to understand the other components. Upgrades can normally be handled entirely through the web console. What’s the smallest, cheapest cluster we can run on Google Kubernetes Engine? If high availability isn’t required (you’re okay with some downtime when upgrading a personal site, for example), you can even run a cluster with a single node of almost any machine type on Google Compute Engine. ( f1-micros require at least three.) Tiny cluster stats: g1-small instances 1 g1-small VM instance, $13.80/mo 30 GB persistent HDD (included in free tier) or f1-micro instances 3 f1-micro VM instances, $8.18/mo ($4.09 each, 1 included in free tier) 10 GB persistent HDD each (included in free tier) Generally speaking you’ll get more for your money with larger instances since a small percentage of CPU / memory are reserved for Kubernetes itself. Log in to the Google Cloud Console with your Google account. You’ll need to do a few things after signing up: Create a project . Sign up for the free trial . (You’ll need to enter a credit card, but won’t be charged.) Follow the instructions in a follow-up email to complete your Google Cloud Console profile. Then we’ll be ready to make our cluster. Visit the GKE page , and select Create a container cluster . Give the cluster a short name that’s easy to type (we’ll stick with cluster-1 ) and pick a datacenter — preferably close to you — for the cluster to live in (the zone ). For Machine type , select “micro (1 shared vCPU) / f1-micro” and keep the size at 3. Under Logging and monitoring , uncheck “Monitoring,” which will cost extra. You get up to 50GB of Stackdriver logging for free per month, so you can leave that enabled. Click More for the advanced options. To avoid extra disk storage charges beyond the free tier, change Boot disk size to 10 GB (the free tier allotment when spread over three nodes). Permissions You can also change the Project access settings. Increasing permissions here will allow apps running in the cluster to access other Google cloud services without creating a dedicated service account or API key. For example, if your app writes to Google Cloud Storage, you can add “Read Write” access for Storage , which gives the Default Application Credentials embedded in the cluster access. This is a good introduction if you want to learn more about permissions and service accounts on Google Cloud Platform. There are good reasons to lock down permissions on larger clusters, but there’s also significant simplicity to be gained in opening them up. Always weigh convenience against risk. Click Create . This will take a few minutes, but we can install some command line tools while we wait. Google Cloud’s web console lets you create and manage clusters, but not applications running on them. For that, we rely on two command line utilities: gcloud and kubectl . Google has an interactive installation script to set up both programs. When running gcloud init , you’ll be asked to log in using a web browser, and to select your project. You can also set your default region and zone, matching those you selected above for your cluster. After init is done, we’ll log in one more time using the following command, which will send you to a browser again. (Some Google Cloud services require an alternative type of credentials.) What do these programs do? gcloud gives you access to APIs on Google Cloud Platform. For example, you can boot up a Google Compute Engine instance or set up firewall rules. It also lets you install different components for managing specialized services. We’ll install the kubectl component, which lets you run commands in your new cluster. You should now be able to use kubectl to run commands on your cluster. Try it out with this, which will list the three worker nodes that will run your application: After we’ve deployed an application to our cluster, we’ll be able to roll out new app versions, show logs and even log in to running containers using kubectl . ~*~*~ Anyone can kubectl ~*~*~ In Part 2 , we’ll deploy an application to our new cluster and learn how to update it as the app changes. How we design and build digital products at The New York Times 167 1 Google Cloud Platform Kubernetes Cloud Computing Tutorial Code 167 claps 167 1 Written by assistant editor @nytinteractive @nytimes. infrastructure, olympics, running. ex-nyu/gallatin student. How we design and build digital products at The New York Times. Written by assistant editor @nytinteractive @nytimes. infrastructure, olympics, running. ex-nyu/gallatin student. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-04-26"},
{"website": "NewYork-Times", "title": "agrarian scale kubernetes part 2", "author": ["Michael Strickland"], "link": "https://open.nytimes.com/agrarian-scale-kubernetes-part-2-91cb88dfd7a3", "abstract": "Code Data Product and Design Workplace Culture Work with Us Part 1 of this series covered the basics of setting up a development environment for Kubernetes on Google Kubernetes Engine, and creating your first cluster on Google Cloud Platform. Everything that runs in Kubernetes needs to be packaged as a container image , a snapshot of a computer that holds your application code plus all of its dependencies (and even the command needed to start your app). This process usually starts with a Dockerfile describing how to create an image from your code, followed by publishing the image to a public or private registry . We’ll use a test app that is already published to the free community registry Docker Hub . Each container image gets its own address, which functions like a URL. Some official images have very short addresses like nginx. Others (like our test image) exist in namespace such as newsdev/kube-test-app . Any address can also include a tag , which refers to a version of the image — just like git tags. Tags are appended with a colon to the image name; when we want version 1.0.0 of our test app, we’ll use the name newsdev/kube-test-app:v1.0.0. The state of your Kubernetes cluster is defined by the collection of objects that exists in it. There are dozens of object types, which can each can be expressed as YAML or JSON, and manipulated using kubectl get, kubectl create or kubectl delete . The two types we need for deploying an app are Deployments and Pods . Kubernetes runs applications by placing them in Pods (groupings of one or more containers / virtual machines), with options for how those containers can talk to other pods, share data, use environmental variables, etc. We can create a pod directly, but — as with the docker containers they turn into — you can’t update a pod once it’s running. That means we’d have to create a new one every time we deployed a new version, updated an environment variable, or had to restart an app that crashed. Kubernetes Deployments are a higher-level resource that handles that logic for us. A deployment is a template for a pod : it contains all the information needed to create pods, along with some lifecycle rules about when to delete, create or restart them. While kubectl create lets you upload a custom object into your cluster, it’s inconvenient to construct complete resource definitions yourself. kubectl run makes this easier by acting as a generator . It gives you shortcuts to create many different types of objects in Kubernetes depending on the options you pass it, running them through templates and turning a few parameters into full objects. The command below will make a Deployment based on an image name. Using the kubectl get command, you can see that kubectl run created a deployment in our cluster, and the deployment in turn created a pod: To have some fun, you can delete the pod that was just created, and watch as another pod comes to life to replace it: This means deployments are self-healing to a degree: if a pod goes away, the deployment knows to bring it back. Or, two ways to debug a pod in Kubernetes The output from kubectl get should list the pod as Running , meaning the app’s container is humming along and not crashing. If things aren’t working as expected, or you want to confirm it can receive web traffic, there are two ways to crack open the pod’s shell to understand what’s happening inside. As your docker containers run, any output sent to STDOUT / STDERR is stored so you can access it later with the kubectl logs command. Non-containerized apps often log to a file instead — Docker has instructions for how to update your app so logs are visible. Use the pod’s name from the kubectl get pods command above, and pass it as an argument to kubectl logs : With our test app, we should see something like this: You can log in to a shell prompt in a pod’s container with kubectl exec . This lets you inspect the state of the machine, or run commands like curl against the app to test how it responds to web requests. You can run any command that exists in the container image by passing it as the final argument to kubectl exec . Since bash (or sh ) is just a command, this lets you open a shell. For some more fun, try replacing bash with some other shell commands. When you change your app’s code and push a new version of the image to the registry, you can update the deployment to use the new image. Let’s update our deployment to use the v2.0.0 release, and watch for it to create a new pod: Try running kubectl exec -it with the new pod’s name to curl your app, and see which version it responds with. A few other ways of updating a deployment are documented here . Any time the deployment changes, you should see that the old pod shuts down and a new pod starts running. This pattern — making iterative updates to an object, which in turn adds and removes resources to bring them in line with the desired state — is an example of where Kubernetes uses declarative configuration . As a developer, you can initiate a complex rolling update by declaring the desired version in the deployment config. Before this style, you had to create a new pod configuration, manage scaling up the new pods and remove the old pods. We’ll see another example of this in Part 3 when the changes we make to an “Ingress” object will automatically configure networking resources in Google Cloud based on you declaring a desired end state. When it works well, this lets developers focus on the “what” instead of the “how.” Crucially, it lets developers who aren’t familiar with a cluster’s underlying infrastructure make production changes on their own safely. In Part 3 , we’ll create an Ingress and Load Balancer to bring traffic from the public internet to our application. How we design and build digital products at The New York Times 40 Kubernetes Google Cloud Platform Google Kubernetes Engine Code 40 claps 40 Written by assistant editor @nytinteractive @nytimes. infrastructure, olympics, running. ex-nyu/gallatin student. How we design and build digital products at The New York Times. Written by assistant editor @nytinteractive @nytimes. infrastructure, olympics, running. ex-nyu/gallatin student. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-04-26"},
{"website": "NewYork-Times", "title": "develop your culture like software", "author": ["Nick Rockwell"], "link": "https://open.nytimes.com/develop-your-culture-like-software-a1a3c1acfd6e", "abstract": "Code Data Product and Design Workplace Culture Work with Us Recently, I tried out a new talk at La Victoria Lab ’s innovation festival in Lima where I covered an experiment we have been engaging in, somewhat by chance, at The New York Times: working on our culture like it was software. I’m not sure how the talk went over, but personally, I think we are onto something good and novel at The Times. The story I told at the FEST was about how my team and I have gone about trying to impact the tech culture at The New York Times. It should be obvious to my readers why we want to work on the culture: we want to be better — better environment, better capability, better talent, better decisions and better results. Focusing on the team is the leverage point for all of those things, and culture is the leverage point on the team. As I put it in my talk, the benevolent laziness of the software engineer led us straight to culture. Our goals are fairly typical: we want a culture that is open and transparent, objective, risk-taking and ambitious; one that values talent, values inclusion and so on. But our goals is not what this post is about. So how do you go about changing culture? It’s notoriously difficult, but so is changing complex software systems and we know a lot about how to do that. But we didn’t think of that at first. We didn’t know how to start, so we just picked something that our technology team had asked for: a clearer engineering ladder with a technical track. (There are many reasons why this is a critical plank in the tech platform, but I won’t go into it right now.) To start, we made an artifact — we (made up and) wrote a description of our technical career track, cribbing — laziness — from Camille Fournier ’s work at Rent the Runway. We worked in a Google Doc in “suggesting” mode and added lots of comments. In my weekly direct report meeting, we talked through the contributions, accepting or rejecting changes that had been made in the week before; sometimes we reverted to an earlier version. Eventually we thought it was pretty good, but we needed more feedback. So we set up a group called the Sounding Board, made up of 30 or so people, intended to be representative across the technology team, and who we thought would provide good perspectives. We asked the Sounding Board to do the same thing we had been doing in our weekly meeting — revise as a group until they thought it was ready. As a side benefit, they were particularly good at pointing out all the things we needed to document next to ensure the technical career tracks make sense, giving particular focus to our promotion process, internal transfers and hiring. In the process, we made a little bit of our implicit culture explicit. It turns out that when you do this people get anxious, because writing stuff down makes you pretty exposed. I guess that’s why it doesn’t happen often. But the key is habituating your team to talking about these things and to make change; and to the idea that we can make mistakes with culture and process, just as we do with software, and it doesn’t have to be the end of the world. Next we needed to test our newly written career ladder out, so we sent it to the whole technology team and said, “We are going to start doing this. What do you think?” We didn’t get too much feedback, unsurprisingly. So we surveyed the team using Google Forms and got a decent signal back. As we implemented the ladder, we continued to iterate and improve it, getting more feedback and figuring out what worked and what didn’t. Then we turned to the adjacent topics: our hiring process, promotions and internal transfers. We went through the same steps with our hiring process, then moved on to the next topic, and so on. We’ve spent the last year or so doing this and have produced at least 50 documents, each materializing a little piece of our culture, including processes and artifacts like career ladders, hiring, transfers, promotions and training, but also a beliefs and values statement, a code of conduct and meeting guidelines. We’ve produced charters for each team that cover the team’s mission and values, their current goals and who to contact. Each artifact is just a little piece, but taken together, this has had the effect of making the intangible tangible and letting us work collaboratively, iteratively and transparently on our culture. And this is the central insight — culture is a bit like code. Software systems are hard to see, complex and have emergent effects, just like culture. Using the techniques that we have evolved to change software — creating artifacts, version control, iteration, code review, instrumentation and beta release — can work to change culture too. This idea, this metaphor, is now directly inspiring our next steps. We’re launching a tracker for “management bugs” to report management responsibilities that are broken. We are going to open source our culture docs, first internally, for revision by all with a pull request like system, and, soon, publicly. And, I’m trying to think of how we could do blue/green deployments… haven’t cracked that yet. So what are the takeaways? If you want to try this, what should you do? Here’s a start: Materialize your culture into artifacts. Start with anything. Then, keep going. Use a collaborative editor , with version control, like Google docs. Organize your concentric circles of review — in our case, my directs, the Sounding Board, the whole team. Introducing things in this way helps ensure that as you reach a larger group, more eyes have been on the thing, and more people are already up to speed and can explain it. Don’t skip the surveying. The hardest part is understanding the effect of what you are producing. In reality, it takes months or even years to know for sure, but you can learn a lot by asking. This might be an uncomfortable process, but that’s OK. Many companies feel safer letting culture remain implicit. As long as you are authentic and mindful, and use language carefully and deliberately, it will probably be OK. Design a good review process and trust it. It’s worth it! We’ll keep you posted on this experiment. If you have any thoughts or suggestions, or questions, please reach out to me here, on Twitter , via LinkedIn , etc. How we design and build digital products at The New York Times 263 2 Culture Workplace Culture Technology Code Office Culture 263 claps 263 2 Written by SVP Engineering at Fastly, ex-CTO at NYT. Passionate about tech, music, science, art, helping others be their best. How we design and build digital products at The New York Times. Written by SVP Engineering at Fastly, ex-CTO at NYT. Passionate about tech, music, science, art, helping others be their best. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-04-26"},
{"website": "NewYork-Times", "title": "how to concentrate in a collaborative workplace", "author": ["James Pothen"], "link": "https://open.nytimes.com/how-to-concentrate-in-a-collaborative-workplace-dfccc3310dc9", "abstract": "Code Data Product and Design Workplace Culture Work with Us How do you work effectively in a collaborative workplace? I’ve found a way to balance concentration and conversation, and would like to share techniques and habits for being productive. When I first started working in an office, I worked haphazardly. I would come in, check work email, maybe chat with a colleague, start on a task, and then check Facebook or YouTube. Working this way nearly got me fired after two years. So I took the opportunity to be more intentional about what I worked on and how I worked. What follows is my adaptation of the principles laid out in Cal Newport’s book, “Deep Work.” I’ve also incorporated material from “Rest” by Alex Soojung-Kim Pang, “Getting Things Done” by David Allen, and “The Power of Habit” by Charles Duhigg. Broadly speaking, I treat myself like a start scientist, athlete, or musician. My workday now starts with me working intensely first thing in the morning. The best research that I have suggests that humans can only be productive for 35–40 hours per week . Working additional hours yields little more productivity and leads to burnout in the long-term. Additionally the best work is often done early in the day while the mind is fresh . So I aim to spend my mornings working intensely on the day’s most important work. My mornings consist of two sessions of concentrated effort. Cal Newport defines it as: “professional activities performed in a state of distraction-free concentration that push your cognitive capabilities to their limit. These efforts create new value, improve your skill, and are hard to replicate.” My deep work sessions get blocked out on my work calendar. This signals to myself and coworkers that this time is set aside for work. Like an athlete doing runs, I have little “rules” about how I work during a session: I work two sessions, each two hours long. Wear noise-cancelling headphones No random internet surfing, email, or Slack Phone is silenced and kept in a drawer On my desk: coffee, water, hand cream, notebook and pen (for writing down tasks) Taped to my monitor: a sign that reads “Do Not Disturb from 8 a.m. – 12 p.m.” Once my work sessions are over, I check my email and text messages for the first time of the day. Then I usually go to lunch with whoever is around. Afternoons are free for walks, company events, meetings, coffees, and chance conversations. When I was a student, I hated routines and waking up early. I wanted to believe that I could be productive and happy by living a free, uninhibited life. I would just let things happen and work when inspiration struck. But the truth is, humans are creatures of habit. It’s not a question of whether or not I had a morning routine, it’s a question of whether it was an intentional one. As Alex Pang says in his book “Rest”, “Routines don’t tap into willpower, resilience, or intrinsic motivation, leaving you more of those resources to spend on hard problems.” So whether you’re single like me, have children, or a long commute into work, creating a morning routine helps to save mental and physical energy for the most important work of the day. My routine involves waking up at 6:30 a.m. After showering and eating breakfast, I aim to be out the door by 8:20 a.m. I pick up a morning paper, read for a while, and begin working by 9:30 a.m. One of the best investments I made for my health was getting an Apple Watch. It has a helpful feature called “Stand Notifications” that will tap me on the wrist and tell me to get up and walk around. Sometimes I’ll run into someone and talk. Sometimes I’ll get a new insight on how to solve a particularly vexing coding issue. Often I just get a chance to see different people than my deskmates. It’s a great way to fight through the mid-afternoon slump. I also make a point of going for a walk after lunch from the Times Building to Bryant Park. Despite the crowds, it helps me reset, get in touch with the city, and discover something new and interesting. Adult life is stressful. If we’re not caring for others, working long hours, doing side projects, or just socializing, it can be hard to slow down and stay rested. I’m lucky to work in a building has a couple of nap rooms. Napping isn’t a part of the company culture generally, but I’ve found a 20-minute or (more rarely) a 90-minute nap in the afternoon provides a useful energy boost. When the workday comes to an end I aim to set myself up for success the next day. This is what Newport describes as a “Shutdown Ritual.” The goal is to completely shut down all work and work-related thinking until I come into the office the next day. No after-hours email, phone calls with team members, or late-night coding sessions. Deliberate rest from work is one of the most important ways to work effectively, as it allows my mind to recharge so I can perform well the next day. Here’s what my shutdown ritual currently looks like: Take a final look at Slack Take a final look at my inbox Write down any new tasks (in my head or in notes) into task lists Skim every task in my task lists Look at the next few days on my calendar Make a rough plan for the next day Check action lists in notebook Check email and messages on phone Put everything on my desk away Say the Nunc Dimittis (a prayer of closing) With this done, I have confidence that every incomplete task, goal, or project has been reviewed and for each I have a plan to complete it or it’s captured in a place where it will be revisited when needed. There are few things as valuable to good mental performance as sleep. I’ve always struggled with a consistent sleep schedule. I take Melatonin to help me fall asleep, and shoot for nine hours a night. Sleep is also a time where I do much of my best work. While I’m asleep, my brain is doing maintenance, processing the events of the day, and even working on the problems I couldn’t solve during the day. Well, this all sounds very idyllic doesn’t it? But most people are busy. The real world requires constantly being on top of email and Slack, checking social media, and being available for face-to-face conversations. How on earth could someone realistically expect to concentrate intensely for four hours a day? When I stepped back and looked at the work that I was paid to do, the work that I would get fired for not doing, I realized it didn’t involve a lot of sending email or responding to Slack mentions. It was about writing code effectively and delivering it on time. So I decided to switch from always being available to being strategically available in order to best support my work. After my first work session, I have a thirty-minute block in which I am allowed to surf the internet, check email, read Slack, and attend standup. After my second work session I check the internet again before going to lunch. The point is to schedule times of distraction so that the internet doesn’t become a constant temptation. From lunch onwards I’m available to go to different work events, attend meetings, get coffee with colleagues, and socialize with my deskmates. I also make a point of checking email and Slack once an hour (rarely is there anything urgent). To further protect myself from distraction, my laptop and phone remain at my desk unless I absolutely need them for a meeting. The goal is to be fully present with my colleagues to take notes (with notebook and pen) and use the time effectively. Instead of getting lost in a long chain of emails or Slack messages, I aim to cut them down by looking at each message and asking this question posed by Newport: “What is the project represented by this message, and what is the most efficient (in terms of messages generated) process for bringing this project to a successful conclusion?” So if a colleague asks to get coffee, I respond with a suggested location and a couple of times that I’m free. If I’m asked to add my thoughts to a document, I respond by saying when I’ll be available to add my comments. When a long email thread seems likely, I ask for a face-to-face meeting or a phone call. But what if I changed jobs tomorrow and was in a client-facing role? How would I make sure to be available for when a client needed to reach me? I would communicate early with my client about when I am usually available (telling them my email schedule) and ask them to schedule phone calls in advance so I can be prepared. And of course, during important times like product launches I would plan to be available in case of last-minute changes. I am lucky to not have a job where I need to be on-call in case the website has an issue. But if I was in that situation I would suggest using the “Do Not Disturb” feature available on most smartphones to allow certain numbers to ring through regardless of the time. I don’t have children or a partner, but in the case of a family emergency I would likely give them my work phone number to call in case something urgent comes up. That number would also be provided to schools, day cares, or caregivers. For a long time I used Evernote on my phone to jot down thoughts and ideas as they came to me. Since cutting down on my phone usage I have moved to a Moleskine-based version of the Getting Things Done system . So I always carry a notebook around to jot down notes and ideas as they come during the day. And once a week I review things to make sure everything is processed. I don’t want to pretend that my system is the perfect one for everyone to adopt. It is constantly evolving to fit the needs of my work and my personal life. But I do believe that by recognizing human limits, creating healthy habits, and setting boundaries for myself and others I have found a way to be far more effective than I was before. I hope that as others consider their own habits they will find the principles presented here to be useful. http://calnewport.com/books/deep-work/ http://www.deliberate.rest/ https://en.wikipedia.org/wiki/Getting_Things_Done http://charlesduhigg.com/the-power-of-habit/ How we design and build digital products at The New York Times 82 3 Workplace Culture Culture Office Culture Collaboration Work Life Balance 82 claps 82 3 Written by Indian-American, Millennial, Depressive, Virginian, Homeschooler, and Evangelical Christian. New York City | https://www.jamespothen.com/ How we design and build digital products at The New York Times. Written by Indian-American, Millennial, Depressive, Virginian, Homeschooler, and Evangelical Christian. New York City | https://www.jamespothen.com/ How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-04-26"},
{"website": "NewYork-Times", "title": "improvandproduct", "author": ["Hannah Cassius"], "link": "https://open.nytimes.com/improvandproduct-8ddeb5e1f99c", "abstract": "Code Data Product and Design Workplace Culture Work with Us “No, it’s not possible. There are a million reasons why we can’t build that feature you want. The tech stack doesn’t support it and it’s just not doable.” As product managers, we’ve all heard or said this. When an idea comes along, whether it be through marketing, design, product, etc., it’s easy to fall into the trap of saying no and saying why something won’t work. We’re trained to do it: to protect our team’s time, to defend our prioritized roadmaps, and to avoid another headache of scrambling in the weeds. By saying no, you may be ignoring a great idea or a missing a deeper understanding of a user’s true needs. You might not hear an idea that could save your product feature from flopping. It’s usually better to listen first and explore ideas around the theme. It doesn’t mean you should build and ship every idea anyone has, but it does mean you have to be open to different ideas and new ways of thinking. Improv is a form of comedy and theater. The performers don’t know what will happen in their show until they are onstage. At the start of their show, they ask the audience for a word or prompt that the show will be based on. They will then begin the show with that prompt, working together to improvise a story as the show continues. While everything is made up in the moment, there is one main principle all good improv is based on — the most important rule of improv — Yes, and. The rule means that performers must accept whatever their scene partners do or say as part of the reality of the scene and then build on it with their own contributions. They must be present in the moment, listen carefully, and contribute freely. For example, in improv, say someone initiates a scene with, “Mother, it is such a lovely day to be working in the garden with you” . If you go into that scene and say, “No, you’re not my mother and we’re actually in a haunted house” the scene ends and the audience is confused. By not saying yes, and, you miss out on creating a unified story with your scene partner. In a job like product management, adaptability is vital. Requirements change, stakeholders express different opinions, that feature you thought you’d be able to build was killed off due to new regulations. Thinking in a yes and framework doesn’t mean you need to say yes to every request that comes your way (that would be disastrous for any type of long-term planning), but it means keeping an open mind to ideas that can come from anywhere. Being open to alternate ways of thinking and being adaptable is particularly useful when a big part of your job is being open to change. I started doing improv about two years ago after one of my managers told me that one of the most important things you can do as a product manager is listen. I was also nervous about public speaking, and trying out improv would be a way to work on that fear. I signed up for a class at The People’s Improv Theater in New York City, and since then, I’ve taken many other classes at different improv schools, am on an Indie Improv team, and have performed at an Improv festival. I still keep my old manager’s advice in mind whenever I go into a product meeting. In any meeting, and in product development in general, if you’re not listening, whether it be to your customers or your stakeholders, your end product will reflect that. Your role as product manager should require some product instincts, but the end result of what you are working on should be a collaborative effort between your stakeholders, your team, and your users. In our last improv show, one of my scene partners gave some backstory on how their character was made fun of in school for reading instead of playing outside during recess. It was my role in the scene to listen, empathize, and build on it. Instead of focusing on my own character and their storyline, I took on the role of her teacher and talked about how reading would help her grow more intellectually. In product management, your customers are often not right in front of you. Their input can come from a variety of channels ranging from Twitter, email, or customer support calls. Part of your role as product manager is to take in their comments, let them sink in, and then make your decision based off that. To build something great requires taking input from everyone and creating something that inspires and delights from it. Improv is also a creative form, so keeping your mind open and being able to create something great off of someone else’s idea comes innately. In product, you don’t want to have a rigid mindset, particularly in the brainstorming and concepting phases. If someone suggests something in a brainstorm that isn’t feasible, the brainstorm is not the time to determine that. I remember an improv scene where the first thing my scene partner did was dig an imaginary hole. The collaboration aspect allowed me to turn this into a scene about us farming, and then my partner expanded the scene into how we loved the farm subsidies. The initial idea, digging a hole, could be explored in a different creative way and only by being open to that will you see its value. In my role as a product manager, we once had a brainstorm about our K-12 educational products. Much of the team was focused on enabling more filtering for content, but when an idea came up about integrating VR into our education products, we were open to it and able to move forward and collaborate on this creative idea. Being open to new ideas, and building upon them helps to create a shared sense of ownership of a project. This is key to having a mission-focused team and deliver impactful results. Improv also helps with confidence and trust in your coworkers because a big part of improv is being able to depend on your team to support you and always being there to support them. If you’re unclear about something in an improv scene, a good improv partner will do their best to clarify it to you in a way that will allow you to continue the scene. In improv, there is something called a “walk-on”, which is when someone who is not a primary character in the scene enters to clarify a location, a relationship, or to heighten the stakes of the scene. For example, if the two primary characters in a scene are sitting down eating, the audience may not know if they are eating at home or in a restaurant. A “walk-on” person can come in as the waiter to clarify that they are in a restaurant. In product, if you’re struggling to communicate a specific design feature in a presentation, you should be able to depend on your designer or other teammates to support you or help clarify. In the same vein, if your teammate is sharing something with a stakeholder, you need to be ready to back them up and help clarify any questions they may not know the answer to. There’s no need to try and do everything yourself when you have clear confidence and trust with your team. Jeff Bezos said in this year’s stakeholder letter , “Most decisions should probably be made with somewhere around 70% of the information you wish you had.” When you need to make a decision, it helps to be able to work with a limited amount of information. In an improv scene, everything is made up based off of what was previously said, so you need to take that and act on it to keep the scene going. We had a scene on my team where Pac-Man and Pac-Woman were having some serious relationship issues. We didn’t know the extent of their relationship issues just yet, but it gave us enough information to have some other teammates come into the scene as the Ghosts from Pac-Man to console the fraught couple and continue moving the scene forward. We moved forward without having 100% of the details. In product, if you don’t make a decision, the product is often unable to move forward. Improv helps to embrace the unknown, and makes you feel comfortable moving forward because you know you are making the best decision based off of your active listening. A good product manager does well working within ambiguity and figuring out what the next step should be based off of the information available to them. Communicating effectively, reacting in the moment, collaborating and trusting your teammates, and actively listening are just some of the ways that improv and product management intersect. The best improvisers and product managers leave room for risk and uncertainty, and are always listening to make sure they’re not missing the key idea that will make their product a success. They depend on their teammates for support, and take turns leading and following conversations, working together to guide a team to developing something great for an audience. If you get the chance, try it! How we design and build digital products at The New York Times 50 Improv Product Management Product Process 50 claps 50 Written by How we design and build digital products at The New York Times. Written by How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-04-26"},
{"website": "NewYork-Times", "title": "the new york times now on apollo", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/the-new-york-times-now-on-apollo-b9a78a5038c", "abstract": "Code Data Product and Design Workplace Culture Work with Us By JEREMY GAYED AND SCOTT TAYLOR We wrote this summer about our move to React and GraphQL at The New York Times. At the time, we were using Relay, Facebook’s open source GraphQL client. We recently shipped a refactor of our app to production using another GraphQL client: Apollo . Apollo is being used by our web frameworks team and by a number of our feature teams. It is changing the way we build the reading experience for our users, and it gives our developers more tools with which to create. Facebook rewrote Relay and released it this summer as Relay Modern. We took a deep look at it, which Scott Taylor wrote about here . And while Relay Modern is a good option for many teams, there are some important differences. Most notably: First-class support for server-side rendering Server-side rendering (SSR) is a hard requirement for our site. There are important SEO considerations, as well as performance benefits like First Meaningful Paint (FMP). Relay takes a “bring your own solution” approach to this problem. In Apollo, SSR is a first-class feature. This is huge for us. Routing agnostic Relay Classic and Relay Modern do not ship with a router — you must bring your own. The open source community around Relay does not leave us with many options. Apollo is router-agnostic, which means we have choices and can pivot, if necessary. While we were using Relay Classic, Jeremy Gayed took an early look at Apollo. In his post here , he explained that it was clear there were a number of long-standing issues Apollo could help us solve. From an end-user perspective, there is little difference. However, from a development and product perspective, Apollo unlocks future platform improvements that we’re really excited about: A more vibrant ecosystem : It’s important for the Times to bet on tools that are part of an active and engaged community. Better server-side rendering/isomorphic support : This includes fine-grained control over where and when queries are fired. We can delay some queries until elements are scrolled into view, and we can isolate others to fire only on certain device types or viewports. Preloading/prefetching : With Apollo, we can selectively prefetch certain queries for a snappier reader experience. Code-splitting at the component level : This was difficult to do before, because of the static routing requirement with Relay. Apollo Link architecture : Middleware for the GraphQL fetching layer using Observables. Modeling local app state as part of the schema : In some cases, this may obviate the need for Redux. Schema stitching : This allows us to seamlessly connect to multiple GraphQL backends and treat them as if they were one. Persisted queries : We can now send a query ID instead of the full the query over the wire. Enhanced debuggability and local developer experience : We now have tools to monitor Apollo inside Chrome DevTools. The Apollo team has been helpful and responsive throughout our migration, even publishing two package upgrades as a result of our direct feedback! We are grateful for their support and excited to build out new experiences for our readers. Watch Scott Taylor’s GraphQL Summit keynote. How we design and build digital products at The New York Times 2K 5 React GraphQL Apollo 2K claps 2K 5 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-11-17"},
{"website": "NewYork-Times", "title": "srccon recap developing new live coverage story formats", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/srccon-recap-developing-new-live-coverage-story-formats-894a125b7752", "abstract": "Code Data Product and Design Workplace Culture Work with Us By TIFF FEHR The Times uses many different page layouts and media in our report. Of course this includes articles, our essential story form, but we also spend significant resources and time supporting other important forms: photos, slideshows, video, audio, interactives, story collections and much more. Some entries in that list may be familiar, but one type that might not be as obvious is our live coverage story forms, which encompass a range of events like breaking news or time-boxed events like the Oscars and Super Bowl. Both newsrooms and readers need live coverage efforts to keep evolving, so our related story forms have become a product largely developed within the newsroom itself. We are fortunate to have a number of developers working in our newsroom, as well as many journalists with significant digital skills and reporting perspectives. Collaborations between these groups has driven the evolution of our live coverage story forms across multiple generations of approaches (as we tend to call them). Within each generation ( at least six we can recall ), we were able to address some of live coverage’s significant challenges by adopting new web technologies as we built increasingly complex reader experiences. Those efforts provided some great lessons about our readership, reporting and scaling to handle unique traffic surges. Our technical explorations have included early adoption of mobile-first design/development, websockets for data communication, nascent React-based integrations and bleeding-edge browser capabilities. In August 2017, newsroom technologists Tiff Fehr, Ham Boardman and Alastair Coote (and NYT alum, now at The Guardian) led a session about this live-coverage landscape at SRCCON . SRCCON is a small, highly collaborative conference organized by OpenNews , a grant-funded project that helps newsrooms participate in open journalism efforts. We wrote up our session and its robust discussion points for OpenNews’ Source . Read the full thing at OpenNews’ Source: https://source.opennews.org/articles/live-coverage/ Tiff Fehr is a assistant editor and lead developer with the Interactive News team. Previously she worked at msnbc.com (now NBCNews.com) and various Seattle-area mediocre startups. How we design and build digital products at The New York Times 10 Journalism Srccon Code Product Design 10 claps 10 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-04-26"},
{"website": "NewYork-Times", "title": "prototyping games at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/prototyping-games-at-the-new-york-times-82092495a924", "abstract": "Code Data Product and Design Workplace Culture Work with Us By JEAN KIM , ROBERT VINLUAN AND SAM VON EHREN This summer, The New York Times Games Team set out to explore new audiences and opportunities by rapidly prototyping and user testing games. We built and tested three different prototypes: Spelling Bee, KenKen and Word Maze, and learned something new with each one. Creating a process for building prototypes that were released to our large audience (which is about a million people) was quite a journey. We’d like to talk through our methodology and share some of the things we’ve learned along the way. The Games Team is mostly responsible for the digital Crossword. We have a smaller subset of the team responsible for what we call Games Expansion: Jean Kim (Technology), Robert Vinluan (Product Design) and Sam Von Ehren (Game Design). Our primary objective is to test the viability of new games as quickly as possible. While we each have our specialities, we’re all multidisciplinary: Robert and Jean have design and engineering backgrounds, and Sam has an engineering and game design background. These mixed skillsets allow us to have a freeform team structure so we can work on projects independently or help each other as needed. At any given time, our team can work on up to three separate prototypes at once. Our team philosophy is “Live fast, die hard, document.” Which is to say, we race toward an MVP as quickly as possible, rigorously test for viability and document every step of the way. Documentation may seem like the enemy of speed, but as a small team within a much larger organization, we often have to coordinate with other teams, codify our objectives and explain our processes. On top of that, documentation provides a detailed history of our successes and failures, and records our work for posterity. We’ve made an explicit choice to use any and all libraries, APIs, SDKs and hacks available to us in our prototyping process. Our goal is to assess the viability of games, not build production-ready products, so we operate under the assumption that any code we write will eventually be thrown out. To give you a sense of how this works in practice, let’s look at some of the technical decisions that went into building Spelling Bee: Zero frameworks were harmed in the making of this game. The entire game was built with three files: index.html, main.js and styles.css. It was built specifically for mobile devices. We chose to only support iOS 9 and above, and the latest versions of mobile browsers. Puzzle data came from a static JSON file and game progress was saved in localStorage. main.js was written in es6 and manually run through Babel (read: copied and pasted into https://babeljs.io/repl/ ) to support older browsers. This approach allowed us to build the Spelling Bee prototype in three days(!!). The takeaway from all of this is that you shouldn’t be too precious — or precious at all — with your code while prototyping. Building an interactive prototype is a means to an end when testing for viability, and you should never let technical decisions slow you down. To verify and improve our prototypes, we employ an array of different testing strategies depending on what stage of development we are in and what we want to learn (There are a lot, but that’s a topic for another post). One strategy is “informal in-person testing:” make a basic version of your game, put it in front of someone and watch them play. This gives you a sense of what’s working and where your game is failing. Our KenKen prototype included an interactive tutorial. To test it, we actually walked around the Times Building asking people with no KenKen experience to play the game while we watched. In doing this, we were able to identify specific points where people struggled or succeeded. After each session we’d adjust the prototype for the next tester, developing a rapid cadence of testing and iterating that would completely transform the tutorial over the course of just a few hours. For each game, we created a slew of documents covering everything from Game Design, to outlining necessary features, to test plans that specified exactly what metrics we wanted to track. One of our most important documentation strategies is frequent post mortems — in software development parlance, a post mortem is a type of meeting where developers analyze and discuss how a project went. While this can feel like a lot of administrative overhead, it serves two vital functions: Within the actual post mortem, impediments to the process can be identified and we can collaborate on finding a solution. Within the day-to-day process, we can cut as many corners as possible (live fast), knowing we’ll reflect on the decision and assess its impact in a judgement free zone. This was most important with our third prototype, Word Maze. The development and testing process had an unusually high number of issues. We worked off year-old code, changed the visuals late in the process and engaged in a series of dubious hot fixes. Immediately having a post mortem allowed us to discuss and solidify preventative measures. In this case: a process for scrapping code, visual design convention guides and hard limitations on hot fixes. At the end of the day, our “live fast, die hard” mentality has been crucial to figuring out both our approach to building new products and our team’s process. We firmly believe in the cycle of getting feedback and iterating accordingly, and our development process will always value completion over perfection. Product development tends to focus on lengthy planning sessions and steady progress towards a “perfect” end result. While there is certainly a time and place for this approach, it exponentially increases the cost of failure during the discovery phase of a product’s lifecycle. As we’ve tried to figure out the future of the Games Team’s portfolio, it’s been liberating and instructive to embrace the possibility of failure in pursuit of new directions. We’re continuing to improve the way we approach rapid prototyping and are excited to see where it takes us. Stay tuned for more updates! Jean Kim was most recently a web developer on the Games Team at The New York Times. On October 16th, she’ll join Maven as a front-end developer. Robert Vinluan is a product designer on the Games Team, working on Crosswords and new prototypes. Play board games with me. Sam Von Ehren is a game designer on the Games Team, and a retired fighting game player. How we design and build digital products at The New York Times 133 Game Development Game Design UX Code Prototyping 133 claps 133 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-01-21"},
{"website": "NewYork-Times", "title": "register better in app billing testing on android", "author": ["Howard Goldstein"], "link": "https://open.nytimes.com/register-better-in-app-billing-testing-on-android-73af5fcc36dc", "abstract": "Code Data Product and Design Workplace Culture Work with Us Google Play Store’s In-app Billing API makes purchases and subscriptions easy. In just a few calls, your app can purchase items and subscriptions, verify previous purchases, etc. However, at The New York Times we ran into limitations while following Google’s recommended practices for testing our app’s use of the Billing API. What Google offers on their Testing In-app Billing page: Static responses allow a developer to handle different return codes on API calls (i.e. canceled , item_unavailable ). This testing works by passing special product codes to the API to get the desired response. The solution is extremely limited. Since actual product codes cannot be passed, it cannot be used for integration testing. Also, it cannot be used to test any call other than REQUEST_PURCHASE on non-subscription items. Test purchases are much more powerful. All API calls interact with the Google Play app exactly as with non-test purchases without anyone’s credit card being charged. Still, there are numerous limitations with test purchases: Since the app communicates with the actual Play Store app, there needs to be an actual app published in the Play Store in the alpha or beta channel. This can be a barrier in the case of new development. The testing app needs to be the same package and signed with the same key as the app in Google Play. This presents a problem when testing the debug version of the app, which is signed with a debug key, and might be a different package. The items being purchased must be published in Google Play. It is possible that items may not be ready to be published at development or testing time. Also, published items cannot be unpublished requiring some fields of the product to be locked in at testing time. Test purchases can only be done by testers whose Gmail addresses are registered with the developer account on Google Play Console. Those accounts must also be active on the testing device. Since the state of purchases is maintained within Google Play, it can be difficult to get into a desired state. For example, an app may present an option to purchase a subscription only if the user does not have an existing subscription. Once the tester purchases, she may need to repeat the test. This can only be done by cancelling the purchase. But when a purchase is canceled, it is still valid for the rest of the day. There is no quick way to return the tester to the state prior to the purchase. Test purchases only offer “happy path” testing. For example, there is no way to test how an integration handles a failed call to getProductDetails . Similar to a mock web server, you can point your app to use Register rather than the real Play Store In-app Billing implementation. Using Register, you will be able to validate in advance whether purchasing flows work correctly. With minimal change to source, API calls are handled by Register’s service, rather than Google Play’s. In addition, the Register app allows testers to control the state of purchases in a mock store as well as control the response code of API calls. To understand how it all works, let’s take a look at a typical In-app Billing call. Let’s say we want to know which items a user has already purchased. Assuming we have followed Google’s initial instructions for implementing In-app Billing , we just need to create a service connection: where mServiceCon is a service connection that make the actual call: Register takes advantage of In-app Billing’s use of an .aidl file to call Google Play app’s service. The Register library contains an interface, GoogleServiceProvider , which mirrors the calls of the .aidl file. There are two implementations: GoogleServiceProviderImpl is a pass-through to the Google Play App service. GoogleServiceProviderTesting works against a second .aidl file which has the same interface, but a different package. These calls are handled by the Register service. This is all invisible to the client code. The only change required is to obtain the service intent using a helper method from the Register library. The googleServiceProvider parameter can be either GoogleServiceProviderImpl or GoogleServiceProviderTesting . Typically, GoogleServiceProviderTesting would only be built into testing versions of the app. The Register sample app shows an example of a switch that toggles between the two implementations. Beyond this small code change, Register needs information about products in order to mock the store. This is done by the configuration file register.json . This file, taken from the Register sample app , contains two purchase items: an in-app purchase, and a subscription. It also includes two user emails, which will be included in the purchaseToken upon purchase. At this time, the file needs to be manually pushed to the device (adb push register.json sdcard/) but a future version will automatically push the file from the project and possibly install the Register app. Until it does this push, you will need build the app from the repository (./gradlew app:install) . To use Register from your app, you will also need to include the library in build.gradle: Once the code is properly calling Register’s bindings and the config file is in place, the Register app should be run once for the first time in order to grant permission for access to external storage (for API 23+). The app will also indicate if it could not read the config file. If all is well, testing can begin. Purchases can now be made. Upon purchase, a Register purchase dialog replaces the Google Play dialog. Once purchases are made, they are reflected in subsequent calls to getPurchases . Additionally, they can be managed in the Register app. Purchases can be viewed and removed. Register also allows testers to see how apps react to non-successful return codes from the API. In the example below, a tester changes the return code on a buy() call to RESULT_ITEM_UNAVAILABLE . Then, they return to the app and receive an “item not found” dialog on purchase. Register has been used to test purchasing flows of our flagship Reader app for three years and counting. While we have found it very useful, there is still work to be done: Many features in the Play Store are not yet supported in Register, for example: support for multiple currencies, multiple languages, timely expiration of subscriptions, free trials, and introductory prices. If your integration includes receipt verification, you will need to account for the receipts returned by Register (at some point, we may open-source our own internal system). Google has just released Play Billing Library which, because it layers on top of In-app Billing, will interfere with Register. We have no doubt that, with a little help from the community, we can make Register an all-in-one payment testing solution. In the meantime, we look forward to any feedback from you all. How we design and build digital products at The New York Times 455 1 Android Open Source Software Testing Technology Code 455 claps 455 1 Written by Android Developer How we design and build digital products at The New York Times. Written by Android Developer How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-04-26"},
{"website": "NewYork-Times", "title": "publishing with apache kafka at the new york times", "author": ["Børge Svingen"], "link": "https://open.nytimes.com/publishing-with-apache-kafka-at-the-new-york-times-7f0e3b7d2077", "abstract": "Code Data Product and Design Workplace Culture Work with Us At The New York Times we have a number of different systems that are used for producing content. We have several Content Management Systems, and we use third-party data and wire stories. Furthermore, given 161 years of journalism and 21 years of publishing content online, we have huge archives of content that still need to be available online, that need to be searchable, and that generally need to be available to different services and applications. These are all sources of what we call published content . This is content that has been written, edited, and that is considered ready for public consumption. On the other side we have a wide range of services and applications that need access to this published content — there are search engines, personalization services, feed generators, as well as all the different front-end applications, like the website and the native apps. Whenever an asset is published, it should be made available to all these systems with very low latency — this is news, after all — and without data loss. This article describes a new approach we developed to solving this problem, based on a log-based architecture powered by Apache Kafka. We call it the Publishing Pipeline . The focus of the article will be on back-end systems. Specifically, we will cover how Kafka is used for storing all the articles ever published by The New York Times, and how Kafka and the Streams API is used to feed published content in real-time to the various applications and systems that make it available to our readers. The new architecture is summarized in the diagram below, and we will deep-dive into the architecture in the remainder of this article. The different back-end systems that need access to published content have very different requirements: We have a service that provides live content for the web site and the native applications. This service needs to make assets available immediately after they are published, but it only ever needs the latest version of each asset. We have different services that provide lists of content. Some of these lists are manually curated, some are query-based. For the query-based lists, whenever an asset is published that matches the query, requests for that list need to include the new asset. Similarly, if an update is published causing the asset no longer to match the query, it should be removed from the list. We also have to support changes to the query itself, and the creation of new lists, which requires accessing previously published content to (re)generate the lists. We have an Elasticsearch cluster powering site search. Here the latency requirements are less severe — if it takes a minute or two after an asset is published before it can be found by a search it is usually not a big deal. However, the search engine needs easy access to previously published content, since we need to reindex everything whenever the Elasticsearch schema definition changes, or when we alter the search ingestion pipeline. We have personalization systems that only care about recent content, but that need to reprocess this content whenever the personalization algorithms change. Our previous approach to giving all those different consumers access to published content involved building APIs. The producers of content would provide APIs for accessing that content, and also feeds you could subscribe to for notifications for new assets being published. Other back-end systems, the consumers of content, would then call those APIs to get the content they needed. This approach, a fairly typical API-based architecture, had a number of issues. Since the different APIs had been developed at different times by different teams, they typically worked in drastically different ways. The actual endpoints made available were different, they had different semantics, and they took different parameters. That could be fixed, of course, but it would require coordination between a number of teams. More importantly, they all had their own, implicitly defined schemas. The names of fields in one CMS were different than the same fields in another CMS, and the same field name could mean different things in different systems. This meant that every system that needed access to content had to know all these different APIs and their idiosyncrasies, and they would then need to handle normalization between the different schemas. An additional problem was that it was difficult to get access to previously published content. Most systems did not provide a way to efficiently stream content archives, and the databases they were using for storage wouldn’t have supported it (more about this in the next section). Even if you have a list of all published assets, making an individual API call to retrieve each individual asset would take a very long time and put a lot of unpredictable load on the APIs. The solution described in this article uses a log-based architecture. This is an idea that was first covered by Martin Kleppmann in Turning the database inside-out with Apache Samza [1] , and is described in more detail in Designing Data-Intensive Applications [2] . The log as a generic data structure is covered in The Log: What every software engineer should know about real-time data’s unifying abstraction [3] . In our case the log is Kafka, and all published content is appended to a Kafka topic in chronological order. Other services access it by consuming the log. Traditionally, databases have been used as the source of truth for many systems. Despite having a lot of obvious benefits, databases can be difficult to manage in the long run. First, it’s often tricky to change the schema of a database. Adding and removing fields is not too hard, but more fundamental schema changes can be difficult to organize without downtime. A deeper problem is that databases become hard to replace. Most database systems don’t have good APIs for streaming changes; you can take snapshots, but they will immediately become outdated. This means that it’s also hard to create derived stores, like the search indexes we use to power site search on nytimes.com and in the native apps — these indexes need to contain every article ever published, while also being up to date with new content as it is being published. The workaround often ends up being clients writing to multiple stores at the same time, leading to consistency issues when one of these writes succeeds and the other fails. Because of this, databases, as long-term maintainers as state, tend to end up being complex monoliths that try to be everything to everyone. Log-based architectures solve this problem by making the log the source of truth. Whereas a database typically stores the result of some event, the log stores the event itself — the log therefore becomes an ordered representation of all events that happened in the system. Using this log, you can then create any number of custom data stores. These stores becomes materialized views of the log — they contain derived, not original, content. If you want to change the schema in such a data store, you can just create a new one, have it consume the log from the beginning until it catches up, and then just throw away the old one. With the log as the source of truth, there is no longer any need for a single database that all systems have to use. Instead, every system can create its own data store (database) — its own materialized view — representing only the data it needs, in the form that is the most useful for that system. This massively simplifies the role of databases in an architecture, and makes them more suited to the need of each application. Furthermore, a log-based architecture simplifies accessing streams of content. In a traditional data store, accessing a full dump (i.e., as a snapshot) and accessing “live” data (i.e., as a feed) are distinct ways of operating. An important facet of consuming a log is that this distinction goes away. You start consuming the log at some specific offset — this can be the beginning, the end, or any point in-between — and then just keep going. This means that if you want to recreate a data store, you simply start consuming the log at the beginning of time. At some point you will catch up with live traffic, but this is transparent to the consumer of the log. A log consumer is therefore “always replaying”. Log-based architectures also provide a lot of benefits when it comes to deploying systems. Immutable deployments of stateless services have long been a common practice when deploying to VMs. By always redeploying a new instance from scratch instead of modifying a running one, a whole category of problems go away. With the log as the source of truth, we can now do immutable deployments of stateful systems. Since any data store can be recreated from the log, we can create them from scratch every time we deploy changes, instead of changing things in-place — a practical example of this is given later in the article. Apache Kafka is typically used to solve two very distinct use cases. The most common one by far is where Apache Kafka is used as a message broker. This can cover both analytics and data integration cases. Kafka arguably has a lot of advantages in this area, but services like Google Pub/Sub , AWS SNS / AWS SQS , and AWS Kinesis have other approaches to solving the same problem. These services all let multiple consumers subscribe to messages published by multiple producers, keep of track of which messages they have and haven’t seen, and gracefully handle consumer downtime without data loss. For these use cases, the fact that Kafka is a log is an implementation detail. Log-based architectures, like the one described in this article, are different. In these cases, the log is not an implementation detail, it is the central feature. The requirements are very different from what the other services offer: We need the log to retain all events forever, otherwise it is not possible to recreate a data store from scratch. We need log consumption to be ordered. If events with causal relationships are processed out of order, the result will be wrong. Only Kafka supports both of these requirements. The Monolog is our new source of truth for published content. Every system that creates content, when it’s ready to be published, will write it to the Monolog, where it is appended to the end. The actual write happens through a gateway service, which validates that the published asset is compliant with our schema. The Monolog contains every asset published since 1851. They are totally ordered according to publication time. This means that a consumer can pick the point in time when it wants to start consuming. Consumers that need all of the content can start at the beginning of time (i.e., in 1851), other consumers may want only future updates, or at some time in-between. As an example, we have a service that provides lists of content — all assets published by specific authors, everything that should go on the science section, etc. This service starts consuming the Monolog at the beginning of time, and builds up its internal representation of these lists, ready to serve on request. We have another service that just provides a list of the latest published assets. This service does not need its own permanent store: instead it just goes a few hours back in time on the log when it starts up, and begins consuming there, while maintaining a list in memory. Assets are published to the Monolog in normalized form, that is, each independent piece of content is written to Kafka as a separate message. For example, an image is independent from an article, because several articles may include the same image. The figure gives an example: This is very similar to a normalized model in a relational database, with many-to-many relationships between the assets. In the example we have two articles that reference other assets. For instance, the byline is published separately, and then referenced by the two articles. All assets are identified using URIs of the form nyt://article/577d0341–9a0a-46df-b454-ea0718026d30 . We have a native asset browser that (using an OS-level scheme handler) lets us click on these URIs, see the asset in a JSON form, and follow references. The assets themselves are published to the Monolog as protobuf binaries. In Apache Kafka, the Monolog is implemented as a single-partition topic. It’s single-partition because we want to maintain the total ordering — specifically, we want to ensure that when you are consuming the log, you always see a referenced asset before the asset doing the referencing. This ensures internal consistency for a top-level asset — if we add an image to an article while adding text referencing the image, we do not want the change to the article to be visible before the image is. The above means that the assets are actually published to the log topologically sorted. For the example above, it looks like this: As a log consumer you can then easily build your materialized view of log, since you know that the version of an asset referenced is always the last version of that asset that you saw on the log. Because the topic is single-partition, it needs to be stored on a single disk, due to the way Kafka stores partitions. This is not a problem for us in practice, since all our content is text produced by humans — our total corpus right now is less than 100GB, and disks are growing bigger faster than our journalists can write. The Monolog is great for consumers that want a normalized view of the data. For some consumers that is not the case. For instance, in order to index data in Elasticsearch you need a denormalized view of the data, since Elasticsearch does not support many-to-many relationships between objects. If you want to be able to search for articles by matching image captions, those image captions will have to be represented inside the article object. In order to support this kind of view of the data, we also have a denormalized log. In the denormalized log, all the components making up a top-level asset are published together. For the example above, when Article 1 is published, we write a message to the denormalized log, containing the article and all its dependencies along with it in a single message: The Kafka consumer that feeds Elasticsearch can just pick this message off the log, reorganize the assets into the desired shape, and push to the index. When Article 2 is published, again all the dependencies are bundled, including the ones that were already published for Article 1: If a dependency is updated, the whole asset is republished. For instance, if Image 2 is updated, all of Article 1 goes on the log again: A component called the Denormalizer actually creates the denormalized log. The Denormalizer is a Java application that uses Kafka’s Streams API . It consumes the Monolog, and maintains a local store of the latest version of every asset, along with the references to that asset. This store is continuously updated when assets are published. When a top-level asset is published, the Denormalizer collects all the dependencies for this asset from local storage, and writes it as a bundle to the denormalized log. If an asset referenced by a top-level asset is published, the Denormalizer republishes all the top-level assets that reference it as a dependency. Since this log is denormalized, it no longer needs total ordering. We now only need to make sure that the different versions of the same top-level asset come in the correct order. This means that we can use a partitioned log, and have multiple clients consume the log in parallel. We do this using Kafka Streams, and the ability to scale up the number of application instances reading from the denormalized log allows us to do a very fast replay of our entire publication history — the next section will show an example of this. The following sketch shows an example of how this setup works end-to-end for a backend search service. As mentioned above, we use Elasticsearch to power the site search on NYTimes.com : The data flow is as follows: An asset is published or updated by the CMS. The asset is written to the Gateway as a protobuf binary. The Gateway validates the asset, and writes it to the Monolog. The Denormalizer consumes the asset from the Monolog. If this is a top-level asset, it collects all its dependencies from its local store and writes them together to the denormalized log. If this asset is a dependency of other top-level assets, all of those top-level assets are written to the denormalized log. The Kafka partitioner assigns assets to partitions based on the URI of the top-level asset. The search ingestion nodes all run an application that uses Kafka Streams to access the denormalized log. Each node reads a partition, creates the JSON objects we want to index in Elasticsearch, and writes them to specific Elasticsearch nodes. During replay we do this with Elasticsearch replication turned off, to make indexing faster. We turn replication back on when we catch up with live traffic before the new index goes live. This Publishing Pipeline runs on Google Cloud Platform/GCP . The details of our setup are beyond the scope of this article, but the high-level architecture looks like the sketch below. We run Kafka and ZooKeeper on GCP Compute instances. All other processes the Gateway, all Kafka replicators, the Denormalizer application built with Kafka’s Streams API, etc. — run in containers on GKE / Kubernetes . We use gRPC / Cloud Endpoint for our APIs, and mutual SSL authentication/authorization for keeping Kafka itself secure. We have been working on this new publishing architecture for a little over a year. We are now in production, but it’s still early days, and we have a good number of systems we still have to move over to the Publishing Pipeline. We are already seeing a lot of advantages. The fact that all content is coming through the same pipeline is simplifying our software development processes, both for front-end applications and back-end systems. Deployments have also become simpler — for instance, we are now starting to do full replays into new Elasticsearch indexes when we make changes to analyzers or the schema, instead of trying to make in-place changes to the live index, which we have found to be error-prone. Furthermore, we are also in the process of building out a better system for monitoring how published assets progress through the stack. All assets published through the Gateway are assigned a unique message ID, and this ID is provided back to the publisher as well as passed along through Kafka and to the consuming applications, allowing us to track and monitor when each individual update is processed in each system, all the way out to the end-user applications. This is useful both for tracking performance and for pinpointing problems when something goes wrong. Finally, this is a new way of building applications, and it requires a mental shift for developers who are used to working with databases and traditional pub/sub-models. In order to take full advantage of this setup, we need to build applications in such a way that it is easy to deploy new instances that use replay to recreate their materialized view of the log, and we are putting a lot of effort into providing tools and infrastructure that makes this easy. I want to thank Martin Kleppmann, Michael Noll and Mike Kaminski for reviewing this article. Originally published at www.confluent.io on September 6, 2017. How we design and build digital products at The New York Times 774 3 Big Data Kafka Software Architecture Content Management Data 774 claps 774 3 Written by How we design and build digital products at The New York Times. Written by How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-01-23"},
{"website": "NewYork-Times", "title": "what its like to intern at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/what-its-like-to-intern-at-the-new-york-times-d27321ab9796", "abstract": "Code Data Product and Design Workplace Culture Work with Us Every summer, university and graduate students from across the United States come to The New York Times for 10-week internships with the company. Interns embed in the newsroom and on the business side of the company, where they work alongside our colleagues in marketing, advertising, product, engineering, data science and design. At the end of the summer, we asked our business side interns to write about their experiences at The Times. Here are a few of their responses. Digital Culture & Engagement Intern | Barnard College, Class of 2018 It was a summer of change at The Times. The Cooking paywall and our new homepage launched and the Digital Operations team reorganized. As the Digital Culture & Engagement intern, I was tasked with providing support and guidance to teams at the forefront of these changes. I worked on an onboarding program and a conference strategy, collaborated with employee-run in-house groups such as the Women’s Network and Women in Tech, and helped with the employee-run Open Speaker Series. I learned that the ethos of this company is in cross-collaboration across teams, grounded by the importance of the company’s mission: helping people understand the world. Being surrounded by people at the forefront of such efforts, during a time more crucial than ever before, was daunting and yet wildly exciting. As my internship comes to a close, I leave with gratitude and a deepened commitment to journalism. To play a tiny role in this grand operation was a privilege. Android Core App Intern | Worcester Polytechnic Institute, Class of 2018 A year ago, I moved from India to the United States to be a student at Worcester Polytechnic Institute in Worcester, MA. When I was accepted into the internship program at The Times, I was excited to be a part of an organization that has been influential on public policy, even though I didn’t know much about the technology at The Times. However, when I started my summer internship I was surprised to learn how cutting-edge the tech is here; employees are given the resources and time to innovate. It was refreshing to see the tech within the company, which I didn’t know about before I started my internship. I interned with the Android team and got to see how engaged the team is with the greater tech world. Many of my colleagues are constantly in touch with Google regarding newest bugs and solutions. Most of them give talks at different conferences, attend Android meetups around New York City and go to the Google I/O event every year. It was great to have colleagues who know the subject matter in detail and are proactively willing to share their knowledge. My mentor for the summer, Brian Plummer, was one of the most talented mentors I’ve had and I learned a lot from him. Media Management Marketing Intern | University of Pennsylvania, Class of 2018 I’ve had an awesome summer here — ten weeks have never flown by faster. One of my biggest takeaways from The Times is to dream big and not hesitate to share my ideas if I believe in them. Early in the summer, I went to a Women’s Network meeting and was surprised to see only two other interns in attendance. I decided to plan an event along with the two interns I met there (Sarafina Chikita and Ariela Martin) to connect female interns with members of the Women’s Network. The event was incredible, and the room where it was held was filled with so much positive female energy. But it almost didn’t happen because I hesitated to pitch the idea to the co-chairs of the Women’s Network, Erin Grau and Rebecca Grossman-Cohen. As interns, we’re hired to help with existing work, not create new tasks for these hardworking employees. However, it’s a testament to this company and the people that work here that a small idea proposed by an intern is taken seriously and given the attention and resources necessary to grow. As I head back to the University of Pennsylvania to begin my senior year, I’m excited to maintain this carpe diem mindset and take advantage of opportunities I may have formerly shied away from. Digital Subscriptions Intern | Princeton University, Class of 2018 When I first told my friends back home that I got an internship at the New York Times, they raised their eyebrows and asked, “What happened to computer science?” Then, after I informed them that I would be in technology, their surprise faded as they assumed I would be working on the website. It was at this point in the conversation that I had to correct them and dive into the details of The Times’ backend subscription system, my area of focus this summer. One of my most significant projects this summer has been implementing a backend endpoint to populate data into The Times’ new User Hub system, which is essentially a revitalized “My Account” page. To implement the endpoint, I paired closely with a full-time engineer on the team and together we developed an API endpoint that extracts user billing data from the database. As a young engineer, it was inspiring to examine and then modify the code underlying a product I use in my personal life. While this project did not center on the latest Javascript framework or machine learning library, I was able to contribute to a product that thousands of users will someday utilize. The ultimate treasure I take away from The Times is not familiarity with enterprise-scale Java, but rather the experience of working with a group of passionate and committed engineers. Soon after I met my summer mentor, Karl Evard, he told me that working at The Times has been his dream job. It sounds cheesy, but it was that sense of community and drive to advance the company’s mission of quality journalism that got me out of bed each morning this summer. Though the Digital Subscriptions team may not fill pages in the paper, the belief in the company’s purpose is contagious and permeates throughout the building. When I return to Princeton for my senior year this fall, I hope to carry the same drive for excellence and professionalism. Customer Product Intern | Brown University, Class of 2017 Over the course of their summer internships, Times interns are tasked with a project that they work on with a group of other interns one day a week. This summer, I worked with a team of interns to design a behind-the-scenes storytelling product we called Insights. The product consists of interactive annotations that users can hover over (on web) or click (on mobile) to reveal a small box containing information about the journalistic process. We came up with the basic idea for this product by thinking about how to address a challenge for the company: communicating our credibility and trustworthiness in a fake-news era. However, after talking to product managers and designers, we learned our product’s success hinged on whether it solved a user problem. In essence, we made the mistake of not thinking about what problem our product solved for our readers, and we realized that prioritizing user needs in our product design was important. So we dug deep and asked ourselves: what user problem are we really trying to solve? We immediately looked to the wealth of knowledge from internal teams and discovered three user challenges. First, we realized that credibility challenges for users were less about trusting The New York Times and more about misunderstanding our independence from outside influence. Second, users have issues with cost transparency and lack an understanding of where money goes. Third, certain users have trouble differentiating The Times from other news sources. In the end, our product worked to solve these three user challenges by tapping into a researched desire for behind-the-scenes content. We argued that behind-the-scenes content would show that our journalists are independent and explain how much goes into producing a story. We ended with a stronger argument for why our product mattered, because we understood who we were designing it for. Data Engineering Intern | Rutgers University, Class of 2019 The Times’ Data Warehouse team is responsible for ingesting, standardizing and storing all the data from various digital products over the history of the company. We maintain systems that return data subsets for reporting, analytical and predictive modeling purposes, as well as perform queries and write reports that lend insights into our users’ behavioral data. This data is reported to both internal and external stakeholders and helps guide the future of the company. This summer, one of my main projects was creating a Dataflow that reported Subscriber Usage according to a series of business rules that dictated specific usage patterns (i.e. counting the number of registered users who access The Times on unique platforms. For example, if a user accesses The Times on two laptops, they should only be counted once, but if they access The Times on two laptops, their iPhone and their iPad, they should be counted three times). We store a lot of our data on Google BigQuery (a structured database that can query terabytes in seconds), so I started writing a SQL script that joined multiple tables and had case statements that took aggregate counts. However, I noticed that we were over-counting the data and upon closer inspection — after creating and testing hypotheses — I discovered that we had a data sanitization issue caused by a bug further up our Data Pipeline. I ran experiments to see how far back the issue reached and how much data was effected, and then I began work on the more interesting engineering process of fixing that issue. After testing a couple different approaches, I settled on using PySpark, which is a popular cluster-computing framework for large-scale data processing. This approach could scale just by adding additional nodes, came with plenty of documentation, allowed me to use the regularly maintained, open-source Python libraries that parsed User Agents into platform-types and would be easy to update in the future. I started learning the internal fundamentals of PySpark and began formulating an approach for the best setup for our Dataproc (PySpark) cluster. I had to account for the memory the Java Virtual Machine would take on each node, how much work the master node had to do and the amount of data we were sending back and forth between each node and their workers. By the end of the project, I had reduced the running time from 1.5 hours to about 6 minutes, with a total cost of $0.005 per run. I was beyond satisfied with my results, and I found it very exciting to learn about PySpark and PySpark optimizations. I definitely enjoyed my summer and I feel like I grew a lot as an engineer — I can’t wait to continue learning and apply what I’ve learned to future projects. Apply for a summer 2018 internship here: https://www.nytco.com/careers/internship-opportunities/ How we design and build digital products at The New York Times 75 Internships Culture Workplace Culture Office Culture Work Life Balance 75 claps 75 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-04-26"},
{"website": "NewYork-Times", "title": "the new york times at srccon", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/the-new-york-times-at-srccon-3ffd362c6b43", "abstract": "Code Data Product and Design Workplace Culture Work with Us SRCCON is a conference that brings together developers, data scientists, designers and other people within the news industry to discuss and collaborate on thorny problems. This August, The Times is sending eight people to present sessions. Why is it so hard for even the nerdiest among us to work across teams in a newsroom? In this session, we’ll create short comics that illustrate collaboration challenges and (possible) solutions to problems we know and love: failure to communicate early, how to tap the right partners and how to manage time effectively. We’ll show some examples and talk about the scenarios they describe, then guide the group exercise to storyboard our own solutions. Toward the end, we’ll share our work and discuss. No drawing skills required! Tiff Fehr is an Assistant Editor of Interactive News, where she focuses on building live coverage software. Tiff is co-leading this session with Becky Bowers from The Wall Street Journal and Darla Cameron from The Washington Post. In this session, we will take some time to talk about why news tagging is important and how it can be particularly useful, asking questions like, “when is machine learning useful?” and “where do we get taxonomies from?”. Then we will present EXTRA (“EXTraction Rules Apparatus”), an open source project that was developed by IPTC with the support of Google DNI and allows news editors to precisely identify the categories to which a piece of news belongs to. Katerina Iliakopoulou is a Software Engineer on the Personalization Team. She holds a dual master’s degree in Journalism and Computer Science from Columbia University, and she be began interning with The Times in 2015. In July 2016, Katerina joined the Personalization Team, where she develops systems that allow editors to pick news content for nytimes.com that is more efficiently based on user preferences and relevance. She is interested in all things machine learning and natural language processing. Liveblogs in 2016 are very different from live coverage in 2017. Breaking news formats have evolved. So have story pace and reader preferences. The New York Times has moved away from liveblogs towards a handful of new forms, each under active guidance/editing. The Guardian Mobile Lab is prototyping a future for live coverage that moves beyond the single pageview towards self-updating and sequential notifications, alongside “shifting lenses” to give different perspectives throughout a live event. But even the newest ideas continue to wrestle with being seen as a Product and all that entails. Let’s discuss the latest habits — for newsrooms, readership and notifications — and the future of live coverage tools. Tiff Fehr is an Assistant Editor of Interactive News, where she focuses on building live coverage software. Hamilton Boardman is a Senior Editor on the News Desk. Tiff and Hamilton are co-leading this session with Alastair Coote from The Guardian. Everyone agrees that mentorship is a good thing, but formal mentorship programs often fail because they are too time-consuming to run. The Times’ Women in Tech group decided to tackle this problem last year and created a mentorship program (for both women and men!) that was rolled out to the entire digital organization. We will share tips, discuss the lessons we learned and run a condensed version of the goal planning and peer coaching workshops that are part of the program. Erica Greene is an Engineering Manager for the Community Team and she helps run The Times’ Women in Tech group. Jessica Kosturko manages software engineers in Digital News Products. She is dedicated to developing her personal leadership skills as well as cultivating leadership in others. Additionally, she is one of the founders of The New York Times Digital Mentorship Program. In this session, we’ll forget about our newsrooms, tools and data sets for a while and think about the essence of interaction. What inspires us as individuals to reach out and try to affect the world? As part of a group? By what means can we do so? How might we find we are changed in turn? What invites us and what repels us? Where do exploration and interaction diverge? Britt Binler is an Interactive News Developer working on live coverage tools and prototyping new technologies for the newsroom. Previously, she worked at IBM and the University of Pennsylvania’s SIG Center for Computer Graphics. Having originally pursued study in the arts, Britt continues to research experimental approaches and innovative engagement with technology. She is currently exploring empathy in our hyper-distracted networks and is interested in developing more intuitive archives. Scott Blumenthal is a Deputy Editor of Interactive News, where he builds and oversees the development of tools that help the newsroom experiment with new story forms and communicate with readers in new ways. Since joining the Times in 2012, he has also contributed to individual features and coverage of tentpole events such as elections, the Oscars and the Olympics (including a three-week stint in Rio last summer). You’re on a product, design or engineering team but you work at a news organization. Should you play by the same rules as the newsroom, or is this an infringement on your speech? Reasonable people can disagree, so let’s do that. Let’s disagree and see what we can learn on either end of the spectrum. Brian Hamman is a Vice President of Engineering leading our Beta Engineering, News Products Engineering and Interactive News teams. Collectively these teams represent more than a hundred cross-functional engineers embedded in the newsroom and product teams working to bring Times journalism to millions of readers each day. Brian is leading this session with Carrie Brown from CUNY’s Graduate School of Journalism. Matt Ericson, Associate Managing Editor of News Platforms, and Justin Heideman, Senior Software Engineer for News Products, will also be attending SRCCON. How we design and build digital products at The New York Times 7 Journalism Conference Srccon Tech 7 claps 7 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-08-01"},
{"website": "NewYork-Times", "title": "open speaker series camille fournier on organizational culture", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/open-speaker-series-camille-fournier-on-organizational-culture-117df36385c9", "abstract": "Code Data Product and Design Workplace Culture Work with Us Editor’s note: This is a recap from the Open Speaker Series, a regular series of talks held in-house at the Times featuring industry leaders in technology, design, product, organizational culture and leadership. The Open Speaker Series and Women in Tech recently co-sponsored a conversation with Camille Fournier, founding CTO of Rent the Runway and the author of The Manager’s Path and Ask the CTO . Camille is currently Managing Director of Platform Engineering at Two Sigma. The discussion centered on three topics — career, management advice and promoting diversity in tech. Here are five highlights: On learning and leadership: “I think the most important thing new people in tech can do is get comfortable looking dumb. The most important thing that experienced people in tech can do is get comfortable letting people ask dumb questions and not shaming them for asking dumb questions.” On developing a diverse organization: “I found that when I was more flexible in where I looked, I found really amazing talent that had more non-traditional backgrounds, and they were more creative and actually worked better with the product and the team that we needed to build.” On dealing with bureaucracy: “I do encourage always digging in on the bottlenecks and inefficiencies in process, and asking the question and raising the issue and seeing what happens.” On improving technical interviews: “I don’t think that someone has cracked the code of how to give the best, most accurate interview […] I think that questioning, “what are we even looking for?”, in an interview is a good thing to do. I definitely think questioning, “how do we determine who is qualified to interview with us, for which roles?”, is another good thing to do.” On self-improvement: “I am way smarter because I know a hundred people smarter than me that are willing, that I have helped out myself and who can then teach me things in return. Don’t expect to know it or do it all yourself. You’re never going to be able to successfully do it all yourself, but relying on those around you — and being there for those around you — delegating your brain out a little bit. You’d be surprised what people will do if you just ask them nicely.” How we design and build digital products at The New York Times 60 Leadership Speakers The New York Times 60 claps 60 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-07-20"},
{"website": "NewYork-Times", "title": "things we read this week", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/things-we-read-this-week-d6c5edb79f57", "abstract": "Code Data Product and Design Workplace Culture Work with Us Welcome to Things We Read This Week, a weekly post featuring articles from around the internet recommended by New York Times team members. This is where we share articles we read and liked, things that made us think and things we couldn’t stop talking about. We will be taking next week off, but will resume on August 4th. As you take on more challenges in your organization, it’s necessary to find ways to give yourself the room to grow without burning out. This article is full of great links to resources that offer methods for managing your time and energy, which will allow you to become the leader you want to be. - Recommended by Modupe Akinnawonu, Product Manager, Android App Kotlin has been making a buzz in the world of JVM languages over the past few years. At this year’s I/O, Google announced first-class support for Kotlin in Android. This article covers companies that use Kotlin and how it has become a great replacement for Java both for client and server-side development. I found it interesting to read a more technical piece from Wired. — Recommended by Mikhail Nakhimovich, Lead Engineer, Android App Just when you thought it was safe… you also have organizational debt. - Recommended by Nick Rockwell, Chief Technology Officer How we design and build digital products at The New York Times 6 Kotlin Office Culture Reading Things To Read Recommended Reading 6 claps 6 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-07-21"},
{"website": "NewYork-Times", "title": "open speaker series simon sinek on leadership", "author": ["Katerina Iliakopoulou"], "link": "https://open.nytimes.com/open-speaker-series-simon-sinek-on-leadership-84c5843b8bf0", "abstract": "Code Data Product and Design Workplace Culture Work with Us Editor’s note: This is a recap from the Open Speaker Series, a regular series of talks held in-house at the Times featuring industry leaders in technology, design, product, organizational culture and leadership. Perhaps best known for his TED talk on leadership , which has been viewed more than 32 million times, author and motivational speaker Simon Sinek visited The Times on May 22 to share his thoughts on leadership, motivation and the power of “Why.” The event, which was co-sponsored by the Times’ Open Speaker Series and Women in Tech task force, was moderated by Times CTO Nick Rockwell. Here are five highlights: On prioritizing people in organizations : “The theme that runs through all of my work is people. It seems so obvious; I shouldn’t have to write a book about the fact that people matter and people come first in any organization and the industry, but I think we have forgotten that. Although I have never met a CEO on the planet, who doesn’t think that people are important and they all say how important people are, the problem is that when you show up in corporate events and you look at the list of priorities, yes people are on the list, but they come fourth or fifth. The reality is that people should always come first. Always.” On the advantages of putting people first : “… when people feel that the organization knows that they exist and cares about them as human beings their natural biological reaction is to offer their blood sweat and tears to the organization and to the people who care about them. It’s called loyalty.” On the importance of leadership training : “Companies should also have robust leadership training programs where people learn skills such as listening, effective confrontation, giving feedback and receiving feedback. Many companies don’t teach leadership.” On gender equality on leadership roles : “We tend to value male characteristics in leadership, such aggression and decisiveness, and traditionally female characteristics, such as patience and empathy or caring, tend to be ignored,” he says. “And what you find is that the best leaders tend to embody a good balance of both male and female characteristics and the worst leaders, both male and female, tend to be more masculine.” On the power of individuals to change organizations : “Instead of complaining of being the victim, you set yourself on the course of a people-first leadership. Be the leader you wish you had.” How we design and build digital products at The New York Times 3 Leadership Open Speaker Series Simon Sinek Recaps 3 claps 3 Written by How we design and build digital products at The New York Times. Written by How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-07-24"},
{"website": "NewYork-Times", "title": "introducing react tracking declarative tracking for react apps", "author": ["Jeremy Gayed"], "link": "https://open.nytimes.com/introducing-react-tracking-declarative-tracking-for-react-apps-2c76706bb79a", "abstract": "Code Data Product and Design Workplace Culture Work with Us The core product teams of The New York Times are investing heavily in React.js and we’re building out a completely new web platform for all of our products. As part of this, we had the rare opportunity to rethink how we do many things, including data fetching , application bundling , ads, tracking and analytics. Traditionally, the tracking and analytics concerns of our app were “bolted on” after the fact. That is, we’d often use the DOM as the source of truth for the existence and interaction of various elements on the page. This was not only brittle, but it was very difficult to do without exposing non-semantic data necessary for the analytic modules to see and attach. In some cases, it was impossible and we had to put analytic-specific code at seemingly random places within our app. We saw this re-platform effort as a great opportunity to “bake in” analytics and tracking within the framework we were building. We wanted to move away from the DOM as the source of truth and instead use the components themselves to signal interactions of interest. This also allowed us to use the app hierarchy itself to establish the contextual awareness tracking events often needed. Our solution ended up with the development of react-tracking , which provides a rich, declarative API to embed tracking information within your app. We’ve now open sourced this library. react-tracking has allowed us to move away from CSS-selecting items of interest and attaching handlers. Instead, we can decorate the handlers themselves with the pertinent tracking data. In a nutshell, this is how react-tracking works: You define a top level dispatch() function that determines where your tracking objects go. If you don’t define one, by default, they get pushed to window.dataLayer[] — a good default if you’re using Google Analytics — but easily overridable if you need it to go somewhere else, or you need to enhance with some API call before sending it to GA. You decorate various components (pages, forms, buttons, links, etc) and any handlers or lifecycle methods within those components (onClick, componentDidMount, etc) with just the data that you have, when you have it. This can either be used as a static object literal or a function that returns an object literal, and is useful in cases where data that you need is a function of props. That’s it! Whenever an event gets triggered (e.g. you’ve decorated a click handler), the tracking object will be deeply merged starting from that component all the way up the component hierarchy until the top level and then the merged object will be passed to dispatch() . This means the tracking concerns of each component is properly compartmentalized to that component. You do not need to “leak” information up (or down) the component hierarchy. This frees you up from having to worry about coupling components, or updating tracking information as components move around or are refactored. Here’s what this looks like in practice (using a theoretical sign-in page example with simplified bits relevant to react-tracking): And the sign-in form: Here’s what the tracking object looks like if the user clicked “Sign In”, for example (the register action would look similar): Simple! This is of course assuming there’s no other contextual tracking data in the app. In practice, one common pattern is to define some top level tracking data in the root <App /> wrapper, to define global things like the app name, build number, etc. In which case, this App data would be part of the resultant object that’s dispatched. Here’s a few things to note about this pattern. As with any clean component architecture, the <SignInForm /> actually has no idea where it is being rendered, however, the page context information came along for the ride automatically. Even further, the Sign In <button /> doesn’t know what module (or page) it is being rendered in (especially useful if the button was defined in a different file), it just knows about the event it needs to dispatch when it’s clicked, which is the only place this information should be known. We decorated the <SignInPage /> and the <SignInForm /> with tracking information, but we only received a tracking object when an event happened (which was also decorated!), as we would expect. TIP: There is a common use case of firing a “page-ready” event when a page renders. This is also supported via defining a process() function on some top level component; an example of this is covered in the next section. The previous example hopefully showcases how simple, yet powerful and flexible this pattern is. However, there is robust support for some fairly complex use cases. A top level dispatch() function allows you to do anything you would need to the tracking data that’s dispatched throughout the app. For example, you may want to enhance the data with some backend API call before sending it to window.someOtherDataLayer[] . A top level process() function allows you to “hook-in” to any decorated component and return an object to send to dispatch() (returning a falsy value will no-op). A common use-case is to automatically dispatch a “page-ready” event on any Page components, for example: What this is doing is checking for a page property on the tracking object, and if it has it, assumes it’s a page and returns a “page-ready” event that will then get merged with the rest of the app’s tracking data and passed to dispatch() . The @track() decorator can also accept a function. This is useful if your tracking data relies on some props data. It will also pass along any args that would be sent to handler functions (starting from the second parameter, since props is always first). This is useful for form inputs, for example: At The New York Times, we’ve taken this a step further by defining a tracking schema to validate against. Traditionally, the tracking object contracts were coordinated manually, usually via an internal Google Doc, but we’re moving to stricter and a more structured programmatically enforced schema. We’re using the excellent ajv library to define a JSON schema for our tracking data layer. In our development environment, we’ve defined dispatch() to pass through the tracking schema’s validate() function to validate all tracking objects and throw errors whenever there are any issues (in order to reduce bundle size, we turn this off in the production build). We’ve found that react-tracking has been easy for various teams to pick up, yet sophisticated enough to handle all of our use cases thus far. We’d love for you to try it out and let us know what you think. Feel free to submit issues on our Github if you run into any problems or have questions about how to do certain things. And, as always, pull requests are more than welcome! Many thanks to the cross-functioning team at The Times who helped build react-tracking thus far: Jeremy Gayed , Oleh Ziniak , Aneudy Abreu , Max Baldwin , Ivan Kravchenko , and Nicole Baram . How we design and build digital products at The New York Times 721 8 React Analytics Open Source Tech JavaScript 721 claps 721 8 Written by Coptic Orthodox Christian. Lead Software Engineer @nytimes. Lover of all things JavaScript 🤓 How we design and build digital products at The New York Times. Written by Coptic Orthodox Christian. Lead Software Engineer @nytimes. Lover of all things JavaScript 🤓 How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-10-01"},
{"website": "NewYork-Times", "title": "things we read this week", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/things-we-read-this-week-5f6368a621ee", "abstract": "Code Data Product and Design Workplace Culture Work with Us Welcome to Things We Read This Week, a weekly post featuring articles from around the internet recommended by New York Times team members. This is where we articles we read and liked, things that made us think and things we couldn’t stop talking about. Check back every Friday for a new post. Newsroom-style cowboy coding at its finest. Washington Post graphics editor Kevin Schaul explains how he and his colleagues tracked cable news Chyrons during the James Comey hearing, using a mix of hastily written code, open source software and old-fashioned manual labor. - Recommended by Chase Davis, Editor, Interactive News Virtual reality is everywhere, including in New York Times stories. VR is a very physical experience and it requires users to make use of their sensory systems and physical bodies. Thomas Logan presented “Accessibility and Virtual Reality” at a recent Accessibility NYC Meetup; his talk follows the Web Accessibility guidelines and describes the current state of inclusive VR, highlighting several products that are doing it well. VR is happening now, not in the future, and we shouldn’t wait to make it accessible. As Logan says, “Be accessible ASAP”. - Recommended by John Schimmel, Senior Integration Engineer, NYT Beta In the 1960s, Lillian Schwartz was experimenting with art and technology, and creating sculptures that combined the two. After one of her sculptures was featured in an exhibit at MOMA, Schwartz was hired at Bell Labs, which was one of the premier centers for computer innovation at the time (we can thank them for the transistor, information theory and the laser). She went on to spend three decades at Bell, exploring the intersection of science, art and film. This is a great piece (and accompanying video) about a woman who pushed the boundaries of how computers can transform cinema. - Recommended by Sarah Bures, Web Developer, News Products Brutalist design applied to digital products. Enough said. — Recommended by Nick Rockwell, Chief Technology Officer How we design and build digital products at The New York Times 3 Virtual Reality Reading Things To Read 3 claps 3 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-07-14"},
{"website": "NewYork-Times", "title": "managing a team with a co lead", "author": ["Charlyn Gee"], "link": "https://open.nytimes.com/managing-a-team-with-a-co-lead-e1778090446a", "abstract": "Code Data Product and Design Workplace Culture Work with Us Ben Solwitz and I co-lead the Digital Subscriptions Backend team at The New York Times. Our team develops core services for digital subscriptions, including the (in)famous paywall and the billing and subscription management system that has enabled The Times to grow to almost 2 million digital-only subscribers. We each have six direct reports, but we treat our team like one big team with twelve engineers. I often joke that while our developers do pair programming, Ben and I do pair managing. Just like pair programming, pair managing gives the opportunity to solve problems and bounce ideas around with someone who has shared context and goals. Last year, I observed that several team members were working late at night or on weekends, but when I asked everyone individually whether they were overworked they all said no. So I asked them whether they thought their teammates were overworked, and they all said yes! I was certain everyone had too much work but wouldn’t admit it to me. Then I talked about it with Ben, and he pointed out that the people working the most had recently taken on Tech Lead roles that had more responsibility for bigger projects. Ben suggested that maybe our tech leads were working extra hard because they felt a greater sense of ownership over their work, which was a perspective I hadn’t considered before, so we decided that we didn’t need to intervene after all. Earlier this year, Ben told his direct reports to set their goals using OKRs (“Objectives & Key Results”, a framework for defining ambitious objectives and measurable outcomes), but I told mine I didn’t care how they set goals as long as they found their goal setting method helpful. We realized we were giving different direction on goal setting and we argued about this for a couple days. In the end, I realized that OKRs weren’t out of line with what I wanted, even though the process was more disciplined. We decided that using a structured approach would work better if everyone on the team was doing it, so I got on board. Ben and I planned and ran OKR workshops together for the whole team, then we had our direct reports write and share their individual OKRs with the team. Despite our initial disagreement, I felt very happy to work together to find a solution that allowed Ben and I to effectively co-lead our team. It’s important for both managers to agree to co-lead the team and commit to doing so. It’s not necessary to set all terms and expectations up front — your partnership should be able to evolve — but you do need to take on mutual ownership for leadership of your team. Pair management can only work if both managers believe that success is not zero sum. Managers should be invested in helping each other thrive. Make time to talk to each other every day. The trick is to develop a habit of sharing the information that shapes your thoughts and decisions as a manager. This helps you build shared context, which makes solving problems together more productive and makes it easier to agree. When you read an article that illuminates new ideas, have your co-lead read it too. Discuss what you learned from the reading and decide together how to apply it to your team. Identify a mode of communication that lets you promptly share information that impacts your team. Both managers should be able to represent the team at any given time, so it’s important to be able to be aware of new information as it comes up. Whether it’s Slack, email or hallway chats, choosing a method of communication that works for both you and your co-lead will help keep you informed. Set up a weekly one-on-one meeting to cover big topics and long-term planning. A one-on-one is a chance to focus on your “important but not urgent” work. You can also use the time for peer mentorship : ask yourself and your co-lead what’s going well and what needs improvement, what you like best about your job or where you see yourself in three years. Just like in pair programming, there is communication overhead. You will have to explain yourself and justify your decisions more frequently and more thoroughly. But talking things through often results in higher quality solutions and keeps you both focused on what’s most important. Define shared values and a common vision for what it means to be a good manager and what a great team looks like. Your hiring process and your team mission are great opportunities to work together to make those shared values more explicit. You can work together to identify the competencies your team needs, and design your job descriptions and interview process to match; you can write or revise your team mission statement together. Sharing goals and values helps maintain alignment, but sharing responsibilities is important too. Pair managing lets each manager take advantage of their unique strengths. You’ll each be good at different things, so you can split up the responsibilities and cover them better than you could alone. Set up one-on-one meetings with the whole team. You’ll naturally have regular contact with your own direct reports, but your co-lead’s direct reports are part of your team too, so find ways to form relationships with them. Having occasional one-on-ones can be useful, and socializing as a team is another way to build rapport with everyone. Pair managing yields many of the same benefits as pair programming: Increased quality of work — talking things through with a co-lead results in clearer articulation of complexities and risks, and more thorough understanding of issues. Better transfer of skills — managers can share skills too, from ideas for more effective one-on-one meetings to time management techniques. Improved engagement — pair managing requires active collaboration, which fosters a sense of belonging and builds community at work. Co-leads can also help each other stay focused on the most important work. For me, pair managing also reinforces my values as a manager. Collaboration and openness are important to me, and pair managing lets me practice and demonstrate those values every day. The more my co-lead and I are willing to share, stay open to new ideas and work together to find solutions, the better we do at our job. Charlyn Gee is an Engineering Manager at the New York Times. Her team builds the backend services behind NYT’s Digital Subscriptions business. How we design and build digital products at The New York Times 87 Pair Programming Tech Collaboration Management And Leadership Management 87 claps 87 Written by I believe great software comes from great team culture. Engineering Manager at The New York Times. How we design and build digital products at The New York Times. Written by I believe great software comes from great team culture. Engineering Manager at The New York Times. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-07-17"},
{"website": "NewYork-Times", "title": "things we read this week", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/things-we-read-this-week-30f983ea98c0", "abstract": "Code Data Product and Design Workplace Culture Work with Us Welcome to Things We Read This Week, a weekly post featuring articles from around the internet recommended by New York Times team members. This is where we articles we read and liked, things that made us think and things we couldn’t stop talking about. Check back every Friday for a new post. Safia Abdalla recently started a thread on Twitter asking people with disabilities to share their biggest frustrations when navigating the web. The responses have been consolidated in this blog post and they share a unique and personal view on accessibility. When designing and building websites, we usually think about users with visual impairments and those who are hard of hearing or deaf, but this list reminds us the variety of access is much larger. - Recommended by John Schimmel, Senior Integration Engineer, NYT Beta This is a great piece about Binky, a social networking app where comments are pre-generated and interactions are futile. Binky asks us to question the nature of our relationship to social media: is tapping and scrolling just as meaningful if the content is fake? - Recommended by Caroline Cox-Orrell, Project Manager for Data & Insights How do you figure out what your company’s real problems are? This great article from Harvard Business Review explains how reframing a problem can produce wildly different perspectives and gives practical steps to help find effective solutions. - Recommended by Modupe Akinnawonu, Product Manager, Android App How we design and build digital products at The New York Times 10 Accessibility Product Development Things To Read Reading Design Thinking 10 claps 10 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-07-07"},
{"website": "NewYork-Times", "title": "why having a diverse team will make your products better", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/why-having-a-diverse-team-will-make-your-products-better-c73e7518f677", "abstract": "Code Data Product and Design Workplace Culture Work with Us By MODUPE AKINNAWONU In March, The New York Times published an article about how hard navigating the subway can be in a wheelchair, and it touched me a lot more than I thought it would when I started reading it. Months later, it’s still on my mind. The piece was penned by Sasha Blair-Goldensohn, an engineer from Google who had an accident that left him partially paralyzed. As he started navigating the city on wheels he discovered that “inflexible bureaucracies with a ‘good enough’ approach to infrastructure and services can disenfranchise citizens with disabilities, many of whom cannot bridge these gaps on their own.” Most subway stations in New York are not wheelchair accessible, and the ones that are often have broken elevators that can leave commuters stranded above or below ground. I’d like to imagine what the considerations for how to build an accessible subway system would be if there were more people with disabilities on the teams that make these decisions. It seems like more thoughtful accessibility would make everyone’s experience with this public product better. It’s so exciting for me to see the ways in which the conversation about diversity and its impact on product development is accelerating. Diversity comes in many forms, and can include characteristics that are innate or acquired, such as country of birth, being multilingual, degree of abledness, race and socioeconomic background, among others. Having less homogenous teams makes us more innovative , can make us smarter and increases profits . The variety of perspectives that come from diverse teams help make products stronger, and ultimately serve users better. Companies with more women are more likely to introduce radical new innovations into the market (hello, Rent the Runway and Stitch Fix !) and companies with a culturally diverse leadership team are more likely to develop new products . Slack celebrated their diversity very publicly last year when they sent four black female engineers to accept their award from TechCrunch for fastest rising startup . Sallie Krawcheck started Ellevest in response to an investing industry that was primarily “by men, for men” and kept women from achieving their financial goals. Halla Tómasdóttir steered financial services firm Audur Capital through the financial storm in Iceland by applying traditionally “feminine” values . And after almost 60 years, Barbies finally come in different shapes, sizes, skin tones and eye color in an effort to attract a wider demographic and increase sales. Without diverse perspectives and experiences in designing, building and testing, products can and will fail female and minority users. Some of the first air bags to be installed cars failed to protect women because they were built to men’s specifications, tested with male crash test dummies , and didn’t take the female anatomy into account. The first voice recognition programs didn’t recognize female voices or many accents because they were built and tested by men and native English speakers. You may remember Google Photos’ image recognition software labeled two black people as “gorillas.” When Apple first launched their Health app, there was one glaring exception to their promise to “monitor all of your metrics that you’re most interested in”: it didn’t track menstruation . And some phones are even too big for women’s hands. Remember Microsoft’s paperclip office assistant? The company spent $100k on market testing and ignored female participants’ feedback that the characters were too male (90% of women didn’t like the characters). The reaction was largely rejected because the men leading the project couldn’t see the issue themselves; they shipped the product with 10 male characters and 2 female characters. One of the hardest things to remember when building products is that you are not your user. Staffing teams with people who think differently from one another can remind us of our blind spots and hopefully lead us to better solutions for all users. Here are some things you can do to make better products: Great products start with great teams, so ensure you have a diverse team to design, build and test your products. Create spaces that guarantee everyone’s voice is heard by remembering that not everyone likes to speak up in meetings. Set agendas ahead of time so everyone can contribute; create space in group meetings for individual brainstorming; and provide other channels for feedback. Cultivate an environment that includes psychological safety : this allows team members to take risks and speak up when they have novel or particularly unorthodox ideas. Talk to users ! If organizing in-house user testing is too difficult, ensure users can submit feedback via email and then make sure time is dedicated to reading some of their responses. Regularly check the public feedback you get in Google Play or the App Store. To make keeping up with these messages simpler, consider setting up a bot that sends these messages to a Slack channel. Reading user feedback makes it harder for you to ignore user needs that you don’t personally feel . It can be easy to make assumptions when building a product, but listening to users whose experiences are different from your own can highlight issues you may not have encountered. With a less homogenous mix of voices at the table, imagine what we can build! If you’re hiring for digital teams and having trouble figuring out ways to diversify your staff, there are numerous organizations you can partner with, including Coalition for Queens , Code 2040 and Power to Fly . Modupe Akinnawonu is a product manager at The New York Times. She focuses on their Android news app, among other projects. How we design and build digital products at The New York Times 157 3 Diversity Product Office Culture 157 claps 157 3 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-05-26"},
{"website": "NewYork-Times", "title": "a look at apollo from a relay perspective", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/a-look-at-apollo-from-a-relay-perspective-d89cf76c263c", "abstract": "Code Data Product and Design Workplace Culture Work with Us By JEREMY GAYED Editor’s note: This article has been reposted from the author’s personal Medium account , with minor edits. Our team is hard at work on implementing an isomorphic (or, “universal”) application that we’re slowly rolling out. While the complexities introduced by this isomorphism are non-trivial, we felt the benefit outweighed the cost — we were keen on keeping TTFP low, ensuring that there are no issues with SEO (even though there’s mixed thoughts on to what extent fully JavaScript-driven apps actually perform from an SEO perspective) and we wanted to still be able to take advantage of full-page caching where it made sense to. We were also attracted to the ease of which React could be rendered server-side and then pick up from where it left off on the client-side, so we were in. As part of this new front-end stack, the back-end was also going through changes. We knew we didn’t want to continue hitting REST-based APIs where the mix of /v1 and /v2 endpoints were only growing. We decided to jump in on the GraphQL bandwagon. At the time, the de facto standard for talking to GraphQL servers on the frontend was (is) Relay. So we didn’t think twice about starting there. However, because our app needed to be isomorphic, there were some non-trivial challenges that came along with that decision. Luckily, there were a few modules available to address these issues and help us render our Relay-based app isomorphically: isomorphic-relay and isomorphic-relay-router . If you’re new to this type of stack, the names of those modules alone might raise some eyebrows. But, they were working and they seemed solid as we started building out our prototype. We were also encouraged by the fact that the super smart author behind those modules, Denis Nedelyaev , was contributing code back into Relay. If you’re only interested in the upshot of all of this, see the TL;DR at the end of this post. As our prototype started to gradually morph into a full-fledged production-level application (with more teams across the org starting to contribute), the challenges of writing an isomorphic application started to present themselves. We had established a number of patterns that were working, so the pain wasn’t spread throughout the teams contributing, but it did feel like one of those nagging itches that kept coming back. Just for some context, here is what a typical route in our app looks like: So, I started looking into some alternatives to Relay. The biggest player here is arguably, Apollo. I was quite impressed with the list of features touted on their site — not the least of which was server-side rendering (SSR) out of the box. That means SSR was a first-class citizen, which I was pretty stoked about. Plus, their documentation was absolutely superb, which is critical for a library that would be at the core of our application as we scaled out to more developers. The following is a write-up I initially did internally to my team that I wanted to share out in case others are looking for more comparisons on these two excellent libraries. Keep in mind that this list is in no way exhaustive, nor is it necessarily 100% accurate — that is, there may be (rather, likely) cases where it’s just user error on our part (e.g. we didn’t write the Relay code completely idiomatically). It’s also in no particular order. So, take what’s here with a grain of salt, but please feel free to comment or call things out. I’m much more interested in learning than I am about calling one library or the other a “winner” (spoiler: there is no winner, the “right” library is the one that works for your use case). Here goes… The isomorphic-relay and isomorphic-relay-router modules are written by a single developer. While that developer was able to contribute things back into Relay for better integration with these modules, the concern is that these are modules we rely on with a relatively small community around them (e.g. in contrast to the Apollo community). In addition, we’ve come across a couple of cases where we were not able to easily do one thing or another because of these modules. One example is we were unable to experiment with a preact alias because it was incompatible with these modules. A loading prop is provided to the component so that the component itself can handle how it should indicate loading progress. This gives us very granular control over how different components present loading state to the user. In our application, we had been handing this at our routing layer , this means our routing was doing much more than just pure routing logic, and it was done very coarsely. While a similar pattern might be possible with Relay’s pendingVariables , the mental model of a simple loading prop at the component-level seems simpler from a developer’s perspective. It was also unclear if pendingVariables still apply in the isomorphic code path, but this could have been a user-error case :) Similarly to the loading flag above, errors are provided in an error prop to the component itself ( this.props.data.error[] ). This means that error handling can be done directly in the component and does not need to happen at the route level. Which means that we can still render our shell even if some query deep in the component hierarchy results in some error. Again, this is another case we were handling at the routing layer , which means it was done very coarsely. The benefit of moving this to the component layer means we do not have to error-out the entire app and can appropriately compartmentalize error handling at the individual component level. Note that this is for query errors. React’s Error Boundaries (expected to land as part of React Fiber ) is handling a different class of errors (errors thrown within a components render() block, for example). It might be that in future versions, Relay takes advantage of React’s Error Boundaries, but that isn’t possible as of this writing. This is by far the biggest win on Apollo’s side. It’s features like these that show the benefit of going with a library that handles server-side rendering as a first-class feature. Skipping queries during SSR can be done simply by passing in an ssr: false flag into the query options. Our use case for this was in a <WithUserContext /> component that we didn’t want done server-side (for caching concerns) and only need it to run on the client: We have yet to find an appropriate solution to this problem in Relay. Unfortunately, to this day, we are still making this extraneous request server-side (which means we’re doing it twice for every request) . Currently, our <Shell /> component (a top-level component) defines a root query because of the way isomorphic-relay-router works. This is arguably a leaky abstraction, as the Shell itself does not require any GQL data. Neither does the <Masthead /> component rendered within it. Only when we get to the <UserModal /> component (that’s rendered within Masthead) is the GQL query useful. In our current app, we’ve had to “leak” this query up to the root component, <Shell /> , which essentially breaks the co-located queries with the components that use them goal. With Apollo, <Shell /> and <Masthead /> can stay pure, and the User query can stay local to <UserModal /> where it belongs. This also means being able to render the Shell even if there is an error in the User (or any other) query. It also means we can share the Shell component with other React-based apps that do not use Relay for data-fetching. We’re holding back on pulling the trigger to introduce a Redux layer into our app for as long as possible. But, introducing a Redux layer, if desired, is a smaller ask with Apollo since its data store is Redux. This means we can take advantage of the same dehydrate/rehydrate step for all of our apps data needs moving forward instead of introducing a second one for a Redux store when using Relay. Apollo provides documentation on how to integrate with an app-specific Redux store. Again, since Apollo is built with isomorphic apps in mind, it supports SSR out of the box. It works by doing a ‘virtual’ render of the app on the server to collect all the queries for the given route, then initializes a Redux store (since Apollo is built on Redux) which is dehydrated on the server then rehydrated on the client. I’m not entirely sure how isomorphic-relay does its query collecting and if it also includes a virtual render or not, but I was concerned that this may negatively impact performance so I ran some ab tests locally and it appears (*unscientifically) that there is not much of a performance impact — in fact, it appears to perform better in comparison. C aptured ab numbers below. This is for the same route with the same data, all other routes were commented out. *Unscientific because this was done on my local machine and not against some dedicated performance test cluster. relay apollo By default, Apollo tries to use the shape of a query itself as a cache so that disparate parts of the app can take advantage of data fetched elsewhere (e.g. think of the use case where User data is grabbed in <UserModal /> and also in <WithUserContext /> ). This is probably fine in most cases, but in cases where we know this may not work we can manually create an object cache key, more info here . The difference here with Relay is that the object ID is the default for Relay queries (which is why there’s Relay influence in the schema on the GraphQL server, which wouldn’t be necessary for Apollo). We could chose to continue using the Relay influenced schema and reuse the Relay-ID, or define our own object IDs client side depending on the use cases. The difference here is probably inconsequential, but worth noting. Mutation queries in Apollo also update the store state, so there’s no explicit “ fat query ” required to keep the UI consistent when doing a mutation query as is the case with Relay (although the Apollo docs do recommend to include fields that could be affected by the mutation in the query). Relay2 is supposed to solve this problem better but not sure what details are available or how that will work quite yet. The difference here may be two sides of the same coin though. We haven’t written many (read: any) mutations in our app yet, so we’re not sure of the subtleties. Apollo provides support for the @decorator() syntax out of the box. I’m a big fan of decorators . Although to be fair, adding it ourselves for Relay was easy enough , but it meant that depending on if a developer was writing a React class or a stateless functional component, they’d want to import two different things for Relay (our @withRelay decorator or react-relay respectively), which could be confusing. This is a real use case for us, and I was quite impressed to see support for pre-fetching supported out of the box and how easy it is to take advantage of with Apollo. Prefetching is just a function call, which means we can do it virtually anywhere/at any time that it makes sense to. E.g. we could prefetch common user flows immediately after mounting on the client, or when the user hovers over a certain link, etc. It’s not clear how the same can be achieved in Relay. While we’ve previously decided we do not need PropType validation on Relay-backed proptypes (since we deemed them redundant with the GraphQL schema backing), Apollo has a graphql-anywhere package that provides proptype validation based on the GQL query automatically. This means developers do not need to manually write these proptypes and we can take advantage of them when sharing GQL-backed components. This package maybe(?) useable with Relay as well, so it might be a push here. By removing isomorphic-relay et al this reopens the door for using the Preact alias for React. We had initially tried out a handful of things to see if we could squeeze out some performance wins preemptively, but this was one of those things we were unable to do because of the isomorphic tools that we needed to support Relay. We’re also unable to update to the new react-router v4 because of the hard dependencies the isomorphic tools have on how RRv3 works. Not a huge deal since the current routing solution works, but it’s certainly a concern since as the community progresses, we wouldn’t want to pin to an older version of a core library we rely on for support reasons, documentation, etc. Apollo also has a really nice Chrome devtool extension , which provides insight into the queries executed by the app, the data cache and even a Graphiql instance. I believe there is a Relay tab in the React devtools but I could not get it to work locally for whatever reason. The Apollo ecosystem also adds support for Persisted Queries . This has a few benefits, including: Whitelisting queries Minimize bandwidth usage between client/server (since query IDs are transferred over the wire instead of the entire query) The overhead here is in how we synchronize this with the server, how we have our GraphQL server understand and ingest this statically provided information at app build-time. Read more about persisted queries here: Persisted Queries And here’s the persisted query module: persistgraphql There’s an RFC to add something similar for Relay. Our Native teams are also looking into using Apollo (iOS and Android teams). They have mentioned already contributing caching strategies back into apollo-client which we theoretically should be able to take advantage of. The main benefit here for us is to be in the same data-fetching ecosystem as other teams across the org. It’s not all rosy for Apollo, of course. With everything, there are drawbacks and tradeoffs, some listed below. The drawback with using Apollo is that it’s a library not written by Facebook. So there may be some challenges when either Apollo or Facebook update their APIs as the two projects progress. Currently, the way Apollo does static analysis at build time is to define queries in separate .gql or .graphql files and then use the webpack loader provided by graphql-tag/loader . There’s pros and cons to this approach. The Apollo team is also working on babel-plugin-graphql-tag which will function similar to Relay’s. The issue to track this work is here: apollographql/graphql-tag#31 One thing to note is that there is a trade-off with doing this at build time. At build-time means a potentially larger JS bundle which can negatively impact TTP/TTI. And of course doing it at runtime can hamper overall page performance. Ideally we’d find the sweet spot and figure out the best way to do it, but it certainly would be nice to have the option either way. Since it seems Relay2 is “right around the corner” we thought it best to see what that looks like before deciding on making the switch or not. One thing to note, however, is that Relay2 will still not support SSR out of the box . So the consideration will be on whether Relay teams’ goal of making it “easy for the community to build upon [Relay’s API] to make a server rendering module for Relay” pans out or not. If you’re building an app that needs to server-side render and talks to a GraphQL server, strongly consider Apollo before jumping straight into Relay ; the complexity otherwise is considerable. If SSR is not important to you, Relay is probably a good choice here since you’ll be staying within the “Facebook ecosystem” of tools and modules. Jeremy Gayed is a lead engineer at The New York Times. He’s working on building out the next generation web platform for various teams at The Times. How we design and build digital products at The New York Times 23 1 React Code Software Development 23 claps 23 1 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-06-02"},
{"website": "NewYork-Times", "title": "introducing the new open blog", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/introducing-the-new-open-blog-23eba4463c59", "abstract": "Code Data Product and Design Workplace Culture Work with Us By NICK ROCKWELL I’m very pleased to announce today that we are relaunching The New York Times Open blog. In the process, we are making three important changes: First, while the blog began life with an engineering focus, we are expanding coverage to include everyone who builds our digital products at the Times. You’ll see posts on design, product development, management, editorial, and yes, definitely engineering. Most posts will come from our team, but you may also see occasional guest posts, from people we are collaborating with in some way. Second, we are greatly increasing our output. Previously we posted “ every sometimes ”, but from now on we are committed to posting weekly — at least. So be sure to follow us here on Medium, as well as on Twitter . Last, as you can see, we are on Medium! While it may seem strange for us, a publisher, to post on Medium rather than our own platform, we are here for a simple reason: the community. Medium is where so many of our people are, so much of the product, design and development community, so we wanted to be here too. So what is Times Open all about? Why are we doing this at all? We are very proud of our crew, and want to give them a platform to share the good work they are doing every day. We also want to share with the community, and help others who may be able to learn from our work. Writing is good for the mind — it helps each of us organize our thoughts, and become better communicators and thinkers. Today we are launching with three new posts: Why Having a Diverse Team Will Make Your Products Better Designing a Faster, Simpler Workflow to Build and Share Analytical Insights Headline Balancing Act And you can also take a look at the archives, which we have ported over from the old blog. Here are a few of my favorites: Introducing Gizmo Design Thinking for Media That Matters Our Tagged Ingredient Data is Now on Github So take a look, and watch this space. And, huge thanks to Chase Davis , Sarah Bures and Allen Tan for getting this next version of Open off the ground! Nick Rockwell is the CTO at The New York Times. Find him on Twitter and Medium @nicksrockwell. How we design and build digital products at The New York Times 137 2 Announcements The New York Times Medium 137 claps 137 2 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-05-31"},
{"website": "NewYork-Times", "title": "headline balancing act", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/headline-balancing-act-6e92d3d6119", "abstract": "Code Data Product and Design Workplace Culture Work with Us By ANDREI KALLAUR and MICHAEL BESWETHERICK The New York Times can be read on your phone, tablet, laptop, and on many other networked screens, and it’s impossible to know in advance how every headline appears on every display. Sometimes, the headline wraps just fine. But there are many times when they don’t, introducing unsightly widows . Even when there aren’t strict widows, instances where one line is dramatically shorter than others can still hurt legibility and reading flow. These blemishes are easily fixed in print. On a fixed canvas, we can fit copy to fill a space, and designers can work with editors to get the text to behave just right. On the web, where space is dynamic, we can’t adjust layouts by hand. But that doesn’t mean we have to just accept bad typography, we just have to use a different approach: translate and codify good design guidelines (which can be intuitive and circumstantial) into a concrete, reusable set of instructions. We have made several attempts to tackle this problem. For a while, we were relying on Adobe’s balance-text jQuery plugin on special feature articles. While the result looked great, performance was not ideal: sharp-eyed readers would see the headline update after the page’s fonts loaded. And since the headline is one of the first things someone will look at, this was not great. So during our Maker Week last summer , I suggested coming up with a more robust headline balancer that could be used anywhere — not just special features. After seeing some examples of bad wrapping, a few engineers agreed to search for a better solution. The winning idea came from one of our interns, Harrison Liddiard . He came up with a lightweight implementation (without a jQuery dependency, even!) that gave us what we were looking for. Michael Beswetherick proceeded to make this script ready for production. Combing through hundreds of headlines of varying lengths, we measured the effectiveness and efficiency of our balancer, adjusting based on what we saw. You can see the before/after for just a few of the headlines: We’re more than a little excited to release our work on Github. Now, we realize that a piece of code that only works on headlines might not be very useful, so we’ve abstracted our solution and named it text-balancer : https://github.com/NYTimes/text-balancer (and also, an npm module) (Now, remember: moderation is best in all things. You should apply this selectively, not to everything you can get your hands on. We suggest headlines, blockquotes, and other places where you’re using large display type. We do not recommend using this on body type, buttons, or navigational links.) Wondering how text-balancer actually works? Well, it’s a binary search algorithm applied against a text element’s max-width. We then adjust its max-width until the element squeezes right up to the point that it spills onto another line. Here it is in action: (slowed down so you can see how it works) We calculate the max-width to be the average of a bottom range that starts at 0 and changes depending on whether the updated max-width makes the text fall onto another line. One of the more subtle aspects of text-balancer is that the text element will always remain the same number of lines that it was before. It will also re-adjust when the browser size changes; all you need to do is set it up once and you can rest assured that the text will always be balanced. When we were first testing it, we kept noticing that our text look…well, didn’t actually look balanced. Finally, we figured out that we were using text-balancer before the headline font had finished loading. So: you should wait to run text-balancer until after your fonts have loaded. We looked for a way to detect when our fonts had loaded and came across Bram Stein’s https://fontfaceobserver.com/ . Calling the observer’s load method returns a promise that will tell us the right time to balance our text. In the future, we’d like to be able to place line breaks with awareness to style guide conventions: not splitting within names and phrases, not splitting after a lowercase word, and so on. (If someone wants to add this and send in a pull request, we won’t say no.) In the meantime, give text-balancer a try and let us know what you like or don’t like! How we design and build digital products at The New York Times 220 Design Code Typography JavaScript 220 claps 220 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-05-23"},
{"website": "NewYork-Times", "title": "faster simpler workflow analytical insights", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/faster-simpler-workflow-analytical-insights-ae6c7055e187", "abstract": "Code Data Product and Design Workplace Culture Work with Us By EDWARD PODOJIL, JOSH ARAK and SHANE MURRAY Data is critical to decision-making at The New York Times. Every day, teams of analysts pore over fine-grained details of user behavior to understand how our readers are interacting with The Times online. Digging into that data hasn’t always been simple. Our data and insights team has created a new set of tools that allows analysts to query, share and communicate findings from their data faster and easier than ever before. One is a home-grown query scheduling tool that we call BQQS — short for BigQuery Query Scheduler. The other is the adoption of Chartio , which our analysts use to visualize and share their results. The result has been more analysts from more teams being able to more easily derive insights from our user data. At least 30 analysts across three teams now have almost 600 queries running on a regular cadence on BQQS, anywhere between once a month to every five minutes. These queries support more than 200 custom dashboards in Chartio. Both represent substantial improvements over our previous model. This effort began when we migrated our data warehousing system from Hadoop to Google’s BigQuery. Before we built new tools, we worked with analysts to come up with several core questions we wanted to answer: What patterns and processes did the analysts use to do their work? Which of those processes could we automate, in order to make the process more hands-off? How could we make it easier for our growing list of data-hungry stakeholders to access data directly, without having to go through an analyst? How could we ensure ease of moving between business intelligence products to avoid attachment to eventual legacy software? Until the migration to BigQuery, analysts primarily queried data using Hive. Although this allowed them to work in a familiar SQL-like language, it also required them to confront uncomfortable distractions like resource usage and Java errors. We also realized that much of their work was very ad-hoc. Regular monitoring of experiments and analyses was often discarded to make way for new analyses. It was also hard for them to share queries and results. Most queries were stored as .sql files on Google Drive. Attempts to solve this using Github never took off because it didn’t fit with analysts’ habits. The act of automating queries was also unfamiliar to the analysts. Although the switch to BigQuery made queries much faster, analysts still manually initiated queries each morning. We wanted to see if there way ways to help them automate their work. Before we considered building a scheduling system in-house, we considered two existing tools: RunDeck and AirFlow . Although both of these systems were good for engineers, neither really provided the ideal UI for analysts who, at the end of the day, just wanted to run the same query every night. Out of this came BQQS: our BigQuery Query Scheduler. BQQS is built on top of a Python Flask stack. The application stores queries, along with their metadata, in a Postgres database. It then uses Redis to enqueue queries appropriately. It started with the ability to run data pulls moving forward, but we eventually added backfilling capabilities to make it easier to build larger, historical datasets. This solution addressed many of our pain points: Analysts could now “set it and forget it,” barring errors that came up, effectively removing the middleman. The system stored actual analytics work without version control being a barrier. The app stores all query changes so it’s easy to find how and when something changed. Queries would no longer be written directly into other business intelligence tools or accidentally deleted on individual analysts’ computers. Under our old analytics system, “living” dashboards were uncommon. Many required the analyst to update data by hand, were prone to breaking, or required tools like Excel and Tableau to read. They took time to build, and many required workarounds to access the variety of data sources we use. BigQuery changed a lot of that by allowing us to centralize data into one place. And while we explored several business intelligence tools, Chartio provided the most straightforward way to connect with BigQuery. It also provided a clean, interactive way to build and take down charts and dashboards as necessary. Chartio also supported team structures, which meant security could be handled effectively. To some degree, we could make sure that users had access to the right data in BigQuery and dashboards in Chartio. Along with new tools, we also developed a new set of processes and guidelines for how analysts should use them. For instance, we established a process to condense each day’s collection of user events — which could be between 10 and 40 gigabytes in size — into smaller sets of aggregations that analysts can use to build dashboards and reports. Building aggregations represents a significant progression in our analytical data environment, which previously relied too heavily on querying raw data. It allows us to speed queries up and keep costs down. In addition, being able to see our analysts’ queries in one place has allowed our developers to spot opportunities to reduce redundancies and create new features to make their lives easier. There’s much more work to do. Looking ahead, we’d like to explore: How to make it easier to group work together. Many queries end up being the same with slightly different variables and thus a slightly different result. Are there ways to centralize aggregations further so that there are more common data sets and ensure data quality? Where it makes sense to design custom dashboard solutions, for specific use cases and audiences. Although Chartio has worked well as a solution for us with a smaller set of end-users, we’ve identified constraints with dashboards that could have 100+ users. This would be an excellent opportunity to identify new data tools and products that require the hands of an engineer. Shane Murray is the VP of the Data Insights Group. Within that group, Josh Arak is the Director of Optimization and Ed Podojil is Senior Manager of Data Products. How we design and build digital products at The New York Times 48 Analytics Data Technology Automation 48 claps 48 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-05-23"},
{"website": "NewYork-Times", "title": "using microservices to encode and publish videos at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/using-microservices-to-encode-and-publish-videos-at-the-new-york-times-c183d102da9c", "abstract": "Code Data Product and Design Workplace Culture Work with Us By FLAVIO RIBEIRO, FRANCISCO SOUZA, MAXWELL DA SILVA and THOMPSON MARZAGÃO For the past 10 years, the video publishing lifecycle at The New York Times has relied on vendors and in-house hardware solutions. With our growing investment in video journalism over the past couple of years, we’ve found ourselves producing more video content every month, along with supporting new initiatives such as 360-degree video and Virtual Reality. This growth has created the need to migrate to a video publishing platform that could adapt to, and keep up with, the fast pace that our newsroom demands and the continued evolution of our production process. Along with this, we needed a system that could continuously scale in both capacity and features while not compromising on either quality or reliability. At the beginning of this year, we created a group inside our video engineering team to implement a new solution for the ingesting, encoding, publishing and the syndication of our growing library of video content. The main goal of the team was to implement a job processing pipeline that was vendor agnostic and cloud-based, along with being highly efficient, elastic, and, of course, reliable. Another goal was to make the system as easy to use as possible, removing any hurdles that might get in the way of our video producers publishing their work and distributing it to our platforms and third-party partners. To do that, we decided to leverage the power of a microservices architecture combined with the benefits of the Go programming language. We named this team Media Factory. The first version of our Media Factory encoding pipeline is being used in production by a select group of beta users at The New York Times, and we are actively working with other teams to fully integrate it within our media publishing system. The minimum viable product consists of these three different parts: Acquisition: After clipping and editing the videos, our video producers, editors, and partners export a final, high-resolution asset usually in ProRes 442 format. Our producers then upload the asset to an AWS S3 bucket to get it ready for the transcoding process. We implemented two different upload approaches: An internal API that supports multipart uploads, called video-acquisition-api, used from server-side clients, like small scripts or jobs. A JavaScript wrapper that uses EvaporateJS to upload files directly from the browser, which is integrated with our internal Content Management System (CMS), Scoop . Transcoding: After the acquisition step is complete, we use another microservice called video-transcoding-api to create multiple outputs based on the source file. Currently, we create a single HLS output with six resolutions and bitrates to support adaptive streaming, four different H.264/MP4 outputs, and one VP8/WebM for the benefit of the 1 percent of our users on the Mozilla Firefox browser running on Microsoft Windows XP. The transcoding service is by far the most crucial part of our workflow. In order to integrate with cloud-based transcoding providers, we decided to design a tiny wrapper containing provider-specific logic. This design gives us great flexibility. We can schedule and trigger jobs based on a set of parameters such as speed, reliability, current availability, or even the price of the encoding operation for a specific provider. For instance, we can transcode news clips (which are time-sensitive) on the fastest, most expensive encoding service, while simultaneously transcoding live action videos, documentaries, and animations (which are not time-sensitive) using lower-cost providers. Distribution: The transcoding step transfers the final renditions into another AWS S3 bucket. Since we use a content delivery network (CDN) to deliver the video to our end users, we need a final step to transfer the files from S3 to the CDN (leveraging Aspera’s FASP protocol to do so). Once the files are on the CDN, our video journalists are able to publish their content on The New York Times. Today, we are open sourcing the video-transcoding-api and the video encoding presets that we use to generate all of our outputs. We are also open sourcing the encoding-wrapper , which contains a set of Go clients for the services we support and that are used by the video-transcoding-api. We believe the format we’ve created will be of particular interest to the open source community. By leveraging the abstractions found in the video-transcoding-api, any developer can write the code necessary to send jobs to any transcoding provider we support without having to rewrite the base preset or the job specification. Sending a job to a different provider is as simple as changing a parameter. We currently support three popular transcoding providers and plan to add support for more. See a sample preset below, in JSON format: Our philosophy for presets: “Write once, run anywhere” In order to fulfill our vision of having a fully open sourced video encoding and distribution pipeline, we thought it best to also tackle the issue of actually encoding the video. We’re officially taking on the development and maintenance of the open source project Snickers to serve this purpose. We’ll not only gain the freedom of deploying our own encoding service anywhere, but we’ll also be able to experiment and implement new features that may not be available with existing service providers or and respond to specific requests from our newsroom. A few examples on the horizon are the automatic generation of thumbnails and accurate audio transcripts. We’ve also turned our sights to fragmented MP4 (fMP4), and we’ll be investing some time into fully moving to an HLS-first approach for our on-demand videos. In case you missed it, last June at WWDC 2016, Apple introduced fMP4 to the HLS protocol, making it so now almost all devices and browsers support fMP4 playback natively. This means we can now eliminate the overhead of having to transmux the MPEG-TS segments into fMP4 on the fly when playing videos using our video player (we use hls.js to do this) and instead just concatenate and play fMP4 fragments on our local buffer. Lastly, content-driven encoding is a trendy topic within the online video community, especially after the release of VMAF . We are planning to adopt this approach by splitting the content-driven encoding project into two phases: Classify our content into four different categories, each with its own preset. For example, animation videos, like the ones we have for our Modern Love show, require fewer bits than our high-motion videos, like some of our Times Documentaries , to achieve the same content fidelity. Create and integrate an additional microservice within the Media Factory pipeline for the purpose of checking the quality of our outputs using VMAF and triggering new re-encoding jobs with optimized presets. Our Media Factory team ( Maxwell Dayvson da Silva , Said Ketchman , Thompson Marzagão , Flavio Ribeiro , Francisco Souza and Veronica Yurovsky ) believes that these projects will help address the encoding challenges faced by many of you in the online video industry. We hope to receive your crucial feedback and generate contributions from the open source community at large. Check them out: https://github.com/NYTimes/video-transcoding-api https://github.com/NYTimes/video-presets https://github.com/NYTimes/encoding-wrapper https://github.com/snickers/snickers And feel free to ask questions via GitHub Issues in each of the projects! How we design and build digital products at The New York Times 2 Code Open Source Encoding Microservices Scaling 2 claps 2 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-05-18"},
{"website": "NewYork-Times", "title": "introducing kyt our web app configuration toolkit", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/introducing-kyt-our-web-app-configuration-toolkit-9ccddf6f6988", "abstract": "Code Data Product and Design Workplace Culture Work with Us By CARRIE PRICE and MATTHEW DELAMBO Every sizable JavaScript web app needs a common foundation: a setup to build, run, test and lint your code. Fortunately, there’s a multitude of tools to assist you, but they have one downside: extensive configuration. It’s not uncommon to see a combined several hundred lines of configuration and script before you can start building your product. Typically, you’ll need the following configurations: transpiler, server build, client build, test, style and script linting and several scripts to tie those tools together. To make matters worse, configuration can lead to a complicated matrix of dependencies, where one minor change can cause bugs with cryptic errors and waste hours of time spent on debugging and searching the internet. As a consequence of this configuration hell, boilerplates have become a popular resource to start an app. The most significant benefit to using a boilerplate is getting to more quickly start a new project with an opinionated toolset. There are many ways to cut a client-side app, which frustrates users from the outset. While boilerplates make setup easy, they become problematic soon after you start using them. They dump several hundred lines of configuration into your app. What made initial startup easy thereby becomes burdensome and it is now the developer’s responsibility to understand and maintain hundreds of lines of code written by someone else, which is brittle and time consuming. There is a need for a tool that exists in between large boilerplates and their customizable toolsets. That’s why we built kyt (pronounced “kit”). kyt is designed to abstract away complicated configurations and allow developers to focus on writing their source code, while still having the power to make important choices about their app. It provides a solid base for building web apps in Node, while being flexible enough to be useful for a variety of projects. kyt manages configuration for all aspects of development. It can be installed as a dependency into a new or existing project. kyt’s goal is to encapsulate only development tools, giving users the freedom to control their source directory and make important decisions about app architecture. kyt includes base features such as Node server support, client and server hot reloading, latest stable ES feature syntax, style and script linter rulesets, production performance optimizations, and a pre-configured test runner. Developers design their own architecture, choosing the tools they need for rendering, styling and handling data. kyt provides a simple command line interface for running all development tools: dev runs a development server with live reloading; build and start compiles and runs source code, optimized and ready for a production environment; test and lint keep code healthy; and proto creates a simple scratch space for prototyping alongside your app. In advanced use cases, kyt’s base opinions can be extended. While kyt can be easily integrated into new or existing Node projects, it is even more powerful when used with a starter-kyt. The kyt CLI includes a setup command, which installs any preconfigured starter-kyt git repository, adding additional dependencies and building a source directory. kyt setup -r git@github.com:NYTimes/kyt-starter-universal.git A starter-kyt offers the benefits of boilerplates while minimizing the number of new tools to learn and maintain. Current starter-kyts support a variety of use cases including universal React and Angular2 apps. Developers can create new starter-kyts and share them with the community. kyt lies on a spectrum of tools created for web development. Some simple tools, such as Create React App , work well for quickly setting up an app. However, these kinds of tools are of limited utility when building an advanced application. If a project becomes too complex for Create React App, developers are forced to “eject,” leaving them with yet another configuration boilerplate. Frameworks for advanced use cases have also popped up. In these cases developers are given a lot of power, and only one way to use it. kyt is designed for a variety of intermediate to advanced projects, existing in between these two extremes. It gives developers control to make choices about their app architecture, while avoiding the configuration hell that comes with setting up and maintaining development pipelines. ✅ Use kyt in real life Developers at The New York Times are currently using kyt in several new projects and working to create new features and starter-kyts. Today we’re open sourcing kyt and offering other developers a chance to escape from configuration hell. Feedback and contributions are welcome. We ( Matt DeLambo , Carrie Price , Jeremy Gayed , Olov Sundström , Jared McDonald , Ken Kaji , Felipe Da Silva and Eitan Konigsburg ) hope kyt will help you as much as it’s helped us. How we design and build digital products at The New York Times 225 2 Code Open Source Configuration Toolkit Nodejs 225 claps 225 2 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-05-22"},
{"website": "NewYork-Times", "title": "we went to the grace hopper celebration heres what we re bringing back", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/we-went-to-the-grace-hopper-celebration-heres-what-we-re-bringing-back-cfa1b213964e", "abstract": "Code Data Product and Design Workplace Culture Work with Us By CORINA AOI, NICOLE BARAM, RACHEL GOLDSTEIN, JESSICA KOSTURKO, TESSA ANN TAYLOR and CHRYS WU Members of The New York Times Developers recently made their first group trip to the Grace Hopper Celebration. At 15,000 attendees, GHC is the world’s largest gathering of women in computing. We chose it because nowhere else could we find so many women software engineers coming together to talk about what we do with technology, and what it’s like to work as a woman in technology. The conference was overwhelming and… dare we say it… awesome. Not only did we meet hundreds of women from all sorts of backgrounds, industries and levels of experience, we ourselves got the opportunity to let people know the breadth and depth of our work. Those things alone made the experience worth it. It is rare to see so many women technologists all at once, and the experience made us reflective in a way that felt important to share. Below are thoughts from some of the team who attended. I came to the Grace Hopper Celebration representing The New York Times with the hope that my presence and interactions as an underrepresented woman of color could encourage women of all shades and labels to continue exploring roles in technology. What I got in return was that plus so much more. Not only did the conference re-energize my love for all things code, it solidified the importance of being a role model for engineers who are also women of color. It was gratifying to have young women come up to me and tell me how reassuring it was to see a face that looks a lot like theirs talking to them about what it is like being an engineer at The New York Times. The conference also ignited a firestorm of ideas for exploration in solving civic and social problems using data and diversity considerations in natural user interactions for emerging technologies. I learned that I am capable of a lot more than I may give myself credit for and that I can use my vast experience as both an engineer and an artist to become a person of influence. More importantly, I discovered there is still so much work to do to advance women in technology, so many open questions that need to be answered, and many conversations that need to be had. Looking ahead I want to continue searching for gaps in diversity that have yet to be bridged and help the The New York Times diversity initiative stay dynamic and progressive, while continuing to raise the bar with innovative thinking. — Corina Aoi, Software Engineer, Home team I left Grace Hopper thinking about what it means to be an ethical programmer. As software engineers we are continuously making architectural decisions, like how to store and interpret sensitive user data. These choices carry weight, and have real, sometimes unforeseen, consequences. This year’s first keynote speaker was Dr. Latanya Sweeney, who is the director of Harvard’s Data Privacy Lab, focusing on data privacy and the societal impact of technology. Her keynote speech covered her most famous research findings that proved algorithm-based ad delivery can perpetuate racial discrimination. She first became aware that this was even possible when a search of her name surfaced an ad falsely suggesting she’d been arrested. Her research proved this was a systemic problem, with far-reaching implications. We know that there is a diversity problem, but we don’t know how that lack of diversity costs us. The rise of the internet has had a meaningful impact on all our daily lives; women and other underrepresented groups need to be given a voice in shaping what our online reality looks like. I’m bringing back from Grace Hopper an increased sense of responsibility to advocate for diverse perspectives at The Times. — Nicole Baram, Associate Engineer, Subscriber Experience Group Just being in a space where the minority becomes the majority was disorienting and exhilarating. The presence of the students — so many highly qualified young women at the very beginning of their careers — was energizing and provided a glimpse into a future when technology teams will be more diverse. In the workshops, I discovered just how much we are not alone in the challenges we face in recruiting, retaining and advancing women in technology. I learned that important factors in retaining and developing women include dealing with a lack of role models and the feeling of isolation, and lack of support of a robust women’s community. One aspect of my experience that may end up being the most significant takeaway over the long run, was making contact and building a network of powerful women who are effecting organizational transformation in their companies throughout the industry. I’m hoping to continue to mine their insight and experience as I contribute to the planning and execution of Women’s Network initiatives here at The Times. — Rachel Goldstein, Director, Advertising Layout & Production Systems My intention at the Grace Hopper Celebration was to learn from other companies about retention and advancement. My experience was quite moving in an unexpected way. For the first time, I was surrounded by 15,000 people who support women in computing. It was quite the contrast from the tech environments I have been in in the past. I was in a majority group: straight white female — among other subgroups such as women of different racial backgrounds who code, lesbians who code, etc. I was able to relate to the straight white male in a way — learning that subgroups have challenges dissimilar to my own, wanting to help, curious and nervous of how much I belong, but unsure how to contribute. I will bring this learning back to The New York Times, to embrace inclusion as we expand the scope of our programs from women in digital to diversity in digital. As we broaden our diversity initiative, I will dedicate myself to digging deeper into the unique challenges of subgroups, bi-racial, moms, LGBTQ-A, and others. I will encourage an open, welcoming environment to be able to ask questions at the risk of using wrong language for the sake of learning. — Jessica Kosturko, Development Manager, Article Experience team I had a non-traditional path through the study of computer science — I began my studies at an all-girls high school (Annie Wright School in Tacoma, Wash.) and received my degree from a women’s college (Smith College in Northampton, Mass.). Attending these institutions meant that I spent my time as a female computer science student as the rule rather than the exception. That is the power of Grace Hopper — the next group of female engineers (as well as current engineers) get to spend a few days as the rule. We’re surrounded by people who look like us, and we can seek inspiration, find solace, and learn from each other. I particularly enjoyed the LGBTQ-A lunch — I’ve never seen that many queer techies in one room. Who knew there were so many of us? Though Grace Hopper is a nice respite, the lack of female and minority representation in computer science is very real. I focused my time at Grace Hopper on ally-ship — what it means to find and nurture allies and what it means to be an ally. I first attended Sharon Mason’s talk about empowering and engaging male allies, “Advocates and Allies: Engaging More Men in Institutional Transformation.” She pointed out that women are often stretched thin acting as gender equality advocates, unconscious bias educators, etc., in addition to our regular responsibilities. To redistribute this workload, Sharon suggested empowering male allies to share responsibility for this extra work by training other allies and taking on equal responsibility for promoting gender equality. To learn how to be a better ally myself, I also attended Hazel Havard’s talk, “Trans Issues in Tech.” She brought up issues that’d I’d never considered, like the discomfort of having to select a gender on HR onboarding forms, and the struggle to choose a gendered bathroom or find a gender-neutral bathroom. In an ideal world, conferences like Grace Hopper wouldn’t need to exist because “women in computing” would be synonymous with “people in computing.” I will keep pushing for that day, and until then, I look forward to next year’s Grace Hopper Conference. — Tessa Ann Taylor, Senior Software Engineer, Content Management Systems (CMS) Going to Grace Hopper was something I pushed for at The Times, and I was fortunate to have the support of upper management to make it happen. We wanted to meet other women in the profession. We, as women technologists at The Times, wanted to be more visible in the community. And each of us defined personally important aspects of diversity in a way that could make our collective outcome more inclusive. I am one of the approximately 6 percent of Americans who identify as Asian . As someone whose personal, racial and ethnic history in the U.S. contains explicit acts of exclusion , inclusion broadly defined has always been my personal and professional motive. It was neat to be able to talk with women who look like me and represent the broad spectrum of what it is to be Asian in America and around the world. The attendees we met made a point to tell us how excited they were to talk us, the technologists who make it possible for New York Times journalism to reach the public. It was a good reminder that our engineering work matters — and that our perspectives as a team of diverse women matter too. Our input shapes the company’s technical output and its culture, and our presence shows others that it is possible to couple the desire to work in technology with the desire to do work that means something to others. The “old-school Chinese” part of me can’t bring myself to talk about pride, but gratitude is universal. I’m grateful to the people outside The Times who, thanks to GHC, are including us in their efforts to create vibrant networks of local women technologists. I’m grateful to have had the chance to work alongside my colleagues — each of whom work on different teams within The Times — to bring our best game to the conference. And I am looking forward to the changes that will come because of what we are bringing back to The Times. — Chrys Wu, Developer Advocate, Technology How we design and build digital products at The New York Times 1 Conferences Grace Hopper Celebration Code Culture Women In Tech 1 clap 1 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-05-22"},
{"website": "NewYork-Times", "title": "testing varnish using varnishtest", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/testing-varnish-using-varnishtest-341e611f7e70", "abstract": "Code Data Product and Design Workplace Culture Work with Us By RUSSELL SIMPKINS I work on the Content API team at The New York Times and we have a lot of legacy code. Over the past year I spent months modernizing our platform for our continuous delivery initiative. If you have a lot of legacy code, and the people before you weren’t developing with continuous delivery practices, chances are you have your own fair share of challenges. One of the tougher challenges I faced was learning how to test the systems I inherited, and one of those platforms I inherited was our Varnish stack. Varnish (Varnish Cache) is a caching proxy server that’s full of features. It’s written in the C language and has its own “Varnish configuration language,” VCL. VCL has a lot of features you can adjust to make Varnish do what you need it to do, but not everything. If you want to add features, you can either create your own module, or you can add a feature using inline C. When our VCL was created, we included inline C, which is frowned upon now. C is powerful, but it’s also easy to make big mistakes and it isn’t a language our team uses often. So, after careful analysis, I determined that I could replace the inline C with VCL, which would make the VCL easier to read and maintain. But I needed a good way to test my changes. Testing VCL, which is necessary for continuous delivery, was painful in the beginning. When I started testing, I would start up a development server, make the modifications to the VCL, restart varnish, use curl to make a request and tail the logs or examine the output to verify everything worked correctly. Pretty painful. I did some digging around and eventually discovered there’s an easier way. Learning how to test VCL wasn’t easy, but it can be, and that’s what I want to share with you in this post; how to test varnish VCL. Let’s imagine a real-life feature and how we can go about testing the feature. Programmers use jQuery and sometimes turn on jQuery cache busting. When enabled, jQuery adds a timestamp, e.g., _=1331829184859 , to the query string in an attempt to bust the cache. If I strip the query string parameter, I can prevent jQuery from busting our cache. Here's one way I could clean our URL using VCL: The first if statement strips the _=1331829184859 and the rest of the lines are there to clean the URL so it isn't left with unneeded characters. The URL is reset on line 11. How can I test this code? I could start a Varnish server with a backend Apache or Nginx instance that logs requests, issue a variety of curl requests and then manually verify the logs, but there’s an easier way. Varnish ships with the ability to test using the testing tool varnishtest . Varnishtest gives you the ability to write VCL tests you can run on the command line or as part of your build process. Here's an example: Line 1 is just for documentation purposes. Lines 2–6 define a server that will accept a request and issue a response. Since I intend to clean the URL before it get’s passed to a backend server, I added a test to verify the backend URL sent to the server with the expect syntax on line 4. If the value doesn’t match, the test stops and you get lots of debugging style output. Line 7 is the syntax to add a backend definition and VCL. Line 8 is optional. I added it to illustrate that you’re allowed to import vmods. At line 9 I define the vcl_recv subroutine and lines 10–16 has the logic I need to remove the cache busting parameter. Lines 19–21 define vcl_deliver to set a response header. I did this to illustrate one way to validate logic during a client request. Line 23 is where I define a client. The client is where you issue requests with the txreq (transmit request) and receive the response with rxresp (receive response.) At line 26, I use expect to verify the test variable is as expected. Adding expect in the client logic is a better way to test multiple inputs. I kept the example short, but it's trivial to add multiple txreq -url , rxresp , expect lines to test different inputs. You can also copy and paste the client c1 to create c2, c3...cN clients. Line 28 is where I run the client logic. Our tests are saved in files e.g. test01.vtc. Assuming you compiled and installed Varnish in the standard locations, running varnishtest is this easy: When the test fails, you get a lot of output to look at. Normally, code that passes your tests will produce very little output. However, you can run your tests in “verbose” mode -v to get full output. For the simple test above, a passing test in verbose mode produces 253 lines of output. A failing tests produces fewer lines of output, but only a few less: 189. Varnishtest allows you some flexibility as well. If you’re building and testing tweaks to Varnish, you can specify what varnishd binary file to use with -D flag, e.g.: You can also use the -D option to your advantage and pass variables to your test, since ${varnishd} (or anything else defined with -D) will be available to your VCL when the test is compiled and run. For example, when building and compiling custom Varnish modules, you can import the library from the build directory, e.g.: Testing with varnishtest made a huge impact when working with my VCL. I can quickly and easily add logic and test theories on my local vagrant box. There is a bit of a learning curve to get started with varnishtest, but the official documentation and the book are useful and hopefully this post helps too. How we design and build digital products at The New York Times 50 Code Testing Varnish Varnishtest 50 claps 50 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-05-22"},
{"website": "NewYork-Times", "title": "summer intern report prototyping an improved search query with machine learning", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/summer-intern-report-prototyping-an-improved-search-query-with-machine-learning-926a35e1214f", "abstract": "Code Data Product and Design Workplace Culture Work with Us By TUSHAR BARAIYA I was thrilled when I was offered the summer internship for two specific reasons. First, it was with The New York Times and second, I was going to join the Search team. I was looking for an opportunity that intersected with my interests in information retrieval and machine learning. More importantly, I would have a chance to use what I had been learning in grad school. Before starting, I had several assumptions about the internship: I expected that it would be a great learning experience. I would also learn how search systems are structured in a professional setup and what exactly the Search team does everyday. I learned the high level architecture during the first week, and it was way more complicated than I expected. Over time, I learned about several of its components in more depth. By attending daily stand-ups where each team member reviewed what they were going to do that day, I got a detailed idea of their work in the team. Another assumption was that I would be a part of a project going on in the Search team and my work would be limited to a small component of it, but I was wrong. It was made clear that I was going to have my own project and I was given full freedom to decide my own project! The team gave me some awesome ideas, and after brainstorming for about a week I decided on my project: to increase the relevancy of article search results from The New York Times search engine. Sometimes it is difficult to construct a query for the information you are looking for for a multitude of reasons. For instance, if you’re looking for context for a specific term, or missing a particular word entirely, using the search engine can be a hassle. What you have in mind is a vague idea and some generic words, but you are looking for specific information. Since the basic text search algorithms use the query you’ve typed — verbatim — to fetch and rank documents, the results sometimes are not satisfactory, or may be entirely irrelevant to what you are looking for. For example — you know that something happened in the Britain, but you don’t know where and what it is about. If you search for “UK”, the ranking of the document will be based on the traditional tf-idf scoring, so the ranking of a document highly relies on the user query. So instead of documents on Brexit or any other recent event, you will get the documents in which “UK” occurs more frequently. One of the aims of my project was to solve this problem. And thus I designed Word2vec-based query expansion. The high level idea is to take the user query, statistically figure out the most relevant words based on recent events, and add them to the user query to create an expanded query. If the expanded query — with recent, related terms included — fetches and ranks articles, the results should be considerably more relevant to the original user query and recent events. Continuing the previous example, if I can add “Brexit” or “EU” to your query, the chances are higher that you will get more recent information on current events going on in Britain. The most interesting part of this project was how to figure out what words are relevant to a given input word. To accomplish this task, we used Word2vec, a machine learning tool that takes text as input and returns a vector model representing words grouped by their latent contextual meanings. The high level idea of Word2vec is that it’s a two-layer neural net and uses the context of each word to calculate its vector. That means if two words are used in a similar context, the similarity between them would be higher. This vector representation of words allows us to perform all kind of useful math on these vectors. To find similar words to a query, we map the query in the vector space, calculate cosine similarity of each word in the space with the query, and take the most similar words and use them to expand the user query. To test the hypothesis, I trained several Word2vec models with The New York Times text corpus with different parameters. The results were really fascinating and useful. For the word “UK”, following are the closest words with their cosine similarity score. Then I designed an experiment to test if Word2vec-based query expansion actually works. It turned out query expansion outperformed the normal model, and the results were way better than expected with an 18 percent rise in precision, recall and NDCG were also higher. Apart from having my own research project, I also enjoyed my internship because I got to learn Clojure, a LISP that follows a totally different programming paradigm than what I’m used to. In addition, the guidance and support I got from the team was tremendous. Even though I was working alone on my project, it never felt like that because of the team. They helped me debug and optimize my code, and even suggested proper directions whenever I was stuck somewhere. I learned a lot more than coding this summer. Tushar Baraiya is a summer intern on the Search team. He will return to University at Buffalo in the fall as a graduate student in computer science. How we design and build digital products at The New York Times 3 Code Culture Internet 3 claps 3 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-05-22"},
{"website": "NewYork-Times", "title": "searching for feelings an intern works on topic and sentiment analysis", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/searching-for-feelings-an-intern-works-on-topic-and-sentiment-analysis-9de0d05791c1", "abstract": "Code Data Product and Design Workplace Culture Work with Us By ISAAC PENA Despite the prestige of an internship with The New York Times, when I signed on to do software development with the Search team — before I ever stepped in the building — I assumed I’d be working on small projects, fixing bugs that needed to be fixed, and essentially coding only in whatever spare quantity was required. I was perfectly happy to do so, of course, but I was quite prepared to receive piecemeal assignments for completion in small fragments of time. As things turned out, I’m writing this while my code is compiling. It’s been about 25 minutes so far. As orientation to the internship program was phasing out at the beginning of June, I was greeted by the Search team and almost immediately given a swath of personal projects to choose from — individually-directed, team-assisted tasks that I could spend the full ten-week period of the internship on, with the end goal of leaving the team (and indeed, The Times at large) with a complete tool they could actually integrate and use in the search engine. For many years, I’ve had a pretty serious interest in linguistics, but I never had the chance to do much with it save for taking a few linguistics classes at college. I always wondered if I could apply the skills I was learning as a computer science major to my academic hobby, but the two fields never seemed to cross while I was at school. So, when I was asked which of a selection of projects I wanted to pursue this summer, one prompt — linguistic sentiment analysis of articles’ subjects — stood out. That’s how I came to be waiting 25 minutes for my code to compile. The initial idea for the semantic analyser has come to fruition through the use of already-extant linguistic tools. The Search team suggested exploring Google’s recently released SyntaxNet parser — a neural network pre-trained on a massive syntactic corpus which can read new sentences and break them down into their constituent parts and then explain exactly how the constituents are related. Additionally, the project uses vaderSentiment , a Python tool out of Georgia Tech which — based on website comments and user posts on Twitter — can determine with accuracy what the overall sentiment (positive or negative) of a snippet of text is. My project has a fairly simple goal: to step through any given article published by The New York Times and to return a list of its major subjects or topics and whether the article relays positive or negative sentiment about those topics. On a large scale, I’ve used the Java-based Lisp dialect Clojure to construct a pipeline from the article itself through SyntaxNet into vaderSentiment — the output of which is the list of subjects and their positive or negative bent. This output can be integrated into the Times search engine — those readers interested in seeing the latest uplifting news on some subject will be able to search with a positive filter, and those who want to read more sobering news about a given figure will be able to search with a negative filter. The project has, thus far, been an incredible opportunity to work with cutting-edge programs in the field of computational linguistics — which I’ve never had the chance to study in school — and to build a library of tools that The Times can implement as they see fit. I hope to walk away from the experience with a new swath of knowledge and experience in this technology, and that The New York Times finds good reason to deploy my project. But above all, I hope that it eventually provides value for the readership of The Times, and that this additional search feature improves improves our ability to understand our entire text corpus. Isaac Pena is a summer 2016 intern on the Search team. He will return to Yale University in the fall as a junior in computer science. How we design and build digital products at The New York Times Internship Machine Learning Sentiment Analysis Code Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-05-22"},
{"website": "NewYork-Times", "title": "why we should all digest our data", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/why-we-should-all-digest-our-data-c2dd6d4761ab", "abstract": "Code Data Product and Design Workplace Culture Work with Us By AYESHA BAJWA The shift from reading news in print to reading news online has dramatically increased the data available about our products. With print, user engagement is opaque — if you recycle your Sunday paper without reading it, we’ll never know. With digital products, it’s increasingly easy to collect data on how users interact with online articles, smartphone apps, or email newsletters. However, a mere increase in statistics collection is no guarantee of accurate interpretation or insight. The challenge now lies in effective analysis and distribution of data in a noisy environment. Big data may be a hot, new buzz phrase of the digital future, but the critical question is unchanged: How do we understand our metrics and use them to better our products? As a software intern at The Times this summer, I’ve been lucky to work on a project that both enables data insights and serves as a nice example of how product and technology teams can support our mission in the newsroom. Working on the NYT Email team, the team responsible for the internal email platform that supports our popular, free email newsletters , I built a software package to process some of the statistics we already track. My package, endearingly dubbed Stats Digest, detects changes in basic email engagement metrics — like open and click rates for each instance of a newsletter product — as well as large changes in subscriber counts. When a change is deemed significant, an email alert notifies a relevant person, likely a newsletter producer, of the change. The sensitivity in detecting changes is customizable and dynamic, though the math is not complicated. Essentially, I’m looking at averages and day-to-day deviations to determine what constitutes a significant change. It’s conceptually simple, but the potential impact on the usability of these metrics is huge. An example of an email alert sent when the engagement or subscriber statistics for a product deviate from the expected average beyond a particular threshold. Internal reporting tools like Stats Digest enable those in business and editorial roles to actually leverage their data. At The New York Times, this point is essential. If you’re working to produce high quality news content on a tight schedule, it’s unrealistic that you’ll spend much time digging through tables of numbers to find the important ones. It’s not that the statistics aren’t important. If a newsletter receives an unusually high number of opens or precedes a massive exodus of email subscribers, you probably want to think hard about the cause. But how would you learn of such a change? There needs to be less overhead for those hoping to use data insights without spending all their time analyzing raw numbers. My summer project leaves ample room for improvement, for both Stats Digest itself and for the general space of internal monitoring tools. A challenge inherent to the structure of any large company is that critical information must be analyzed and distributed in the right places, at the key moments, by those with the relevant expertise. Simple reporting tools are then a worthwhile investment, saving time and easing communication across the company. Back in February, I’d craned my neck at a campus career fair, amazed to recognize a familiar newspaper logo among aisles crowded with technology companies. I was instantly curious about the experience of writing software at a company whose central goals are seemingly tangential to tech. I was also skeptical. Many of the developer positions available at non-tech companies strike me as distinctly separate, relegated to back rooms where the main work of the company is only peripherally discussed. I disliked the idea that I could have an employer whose mission and creed might not influence my daily work. Not so at The Times. I learned it’s perfectly normal for software developers to remain in communication with not only product and project managers but with newsroom editors and producers as well. Technology interns participate in most of the same orientation as other business and newsroom interns, and we collaborate with marketing interns on a separate intern-only project on Fridays. We in technical roles are supposed to reach out to those of completely different backgrounds to bring new perspectives to the products we build. Something I’ve come to expect of potential employers, something I’ll certainly remember in the future, is this deliberate, encouraged openness in communication and collaboration across roles. And what’s the magical constant I’ve witnessed that continually motivates us to do so? The Times’ mission to enhance society by providing high-quality news and information keeps us on the same page as we each work to make our own small, hopefully impactful contributions. I’ll begin mine by digesting some statistics. Ayesha Bajwa, a rising junior in Electrical Engineering and Computer Science at MIT, is a summer 2016 software intern on the Email team. How we design and build digital products at The New York Times 11 Data Data Analysis Internship Code Email Newsletters 11 claps 11 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-05-22"},
{"website": "NewYork-Times", "title": "the future of the past modernizing the new york times archive", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/the-future-of-the-past-modernizing-the-new-york-times-archive-e217e88af133", "abstract": "Code Data Product and Design Workplace Culture Work with Us By SOPHIA VAN VALKENBURG and EVAN SANDHAUS The New York Times recently celebrated its 20th year on the web. Of course, today’s digital platforms differ drastically from those of decades past, and this makes it imperative that we modernize the presentation of archival data. In 2014, we launched a redesign of our entire digital platform that gave readers a more modern, fluid, and mobile-friendly experience through improvements such as faster performance, responsive layouts, and dynamic page rendering. While our new design upgraded reader experience for new articles, engineering and resource challenges prevented us from migrating previously published articles into this new design. Today we are thrilled to announce that, thanks to a cross-team migration effort, nearly every article published since 2004 is available to our readers in the new and improved design. As so often happens, the seemingly ordinary task of content migration quickly ballooned into a complex project involving a number of technical challenges. Turns out, converting the approximately 14 million articles published between 1851–2006 into a format compatible with our current CMS and reader experiences was not so straightforward. Challenge Accepted At first, the problem seemed simple: we had an archive of XML, and we needed to convert it into a JSON format that our CMS could ingest. For most of our archive data, from 1851–1980, the XML files included sufficient data and all we needed to do was parse the XML and rewrite it in the new format. Stories from 1981 through 2006 were trickier. We compared the articles parsed from XML to a sample of articles currently served on the website and found that in 2004 alone there were more than 60,000 articles on our website that were not included in the XML archive. From 1981 onward, there were possibly hundreds of thousands of online-only articles missing from the archive, which reflected only what appeared in the print edition. This posed a problem because missing articles would show up as 404 Not Found pages, which would deteriorate user experience and damage our ranking on search engines. Creating the Definitive List of Articles To successfully migrate our archive, we needed to create a “definitive” list of all articles appearing on the website. To construct this list we consulted several additional data sources including analytics, sitemaps and our database of book, film and restaurant reviews. The Archive Migration Pipeline With our definitive list of articles established, it became clear that we would need to derive structured data from raw HTML for items not present in our archive XML. To achieve this, we implemented an archive migration pipeline with the following steps: Given the definitive list of URLs and archive XML for a given year, determine which URLs are missing from the XML. Obtain raw HTML of the missing articles. Compare archive XML and raw HTML to find duplicate data and output the “matches” between XML and HTML content. Re-process the archive XML and convert into JSON for the CMS, taking into account extra metadata from corresponding HTML found in step 3. Scrape and process the HTML that did not correspond to any XML from step 3 and convert into JSON for the CMS. Combine the output from steps 4 + 5 to remove any duplicate URLs. Our plan for the archive migration pipeline presented a few technical challenges. Scraping Raw HTML and XML Our CMS stores a lot of metadata about articles — for example, publication date, section, headline, byline, dateline, summary, etc. We needed a way to extract this metadata in addition to the article content itself from raw HTML and XML. We used Python’s built-in xml ElementTree parser for processing the XML and BeautifulSoup for processing HTML. URL Redirects As part of our migration process, we are generating new, SEO-friendly URLs for old content so that readers can more easily find our historical data. SEO-friendly URLs typically include some keywords related to the content of the page, a practice that wasn’t standardized in our archive. For example, on Feb. 12, 2004, the article “ San Francisco City Officials Perform Gay Marriages ” appeared under a URL ending with “12CND-FRIS.html.”. Realizing we could provide a much more informative link, we derived a new URL from the headline. Now this article is referenced by a URL ending with “ san-francisco-city-officials-perform-gay-marriages.html ,” a far more intuitive scheme. Handling Duplicate Content Once we identified which URLs were missing from our archive, we realized we had a new problem: duplicate content. Some “missing” URLs pointed to HTML documents containing content already present in our XML archive. If we converted both the XML and HTML to JSON without identifying duplicated content, many articles would end up with more than one URL, which would cause duplicate pages to compete against each other for relevance ranking on search engines. Clearly, we needed to find which XML articles correspond to which HTML articles. As an additional challenge, we had to use a method that didn’t rely on exact string matching, because there could be slight differences between archive XML and HTML, such as extra text, that would prevent the two sources from being exactly the same. To tackle these issues, we used an algorithm developed for another one of our projects, TimesMachine , which relies on a text “shingling” technique. Read more about the technique here . This technique successfully matched a majority of “missing” HTML articles to existing XML articles. For example, in 2004, we initially had 60K missing articles, but this step successfully matched over 42K articles, reducing the number of potential duplicates by 70%. The remaining 30% of articles would be scraped using BeautifulSoup. New Opportunities While our original goal was to modernize our digital archive, the migration project has led to opportunities for future projects to engage our readers in our treasure trove of historical news data. For example, we recently expanded TimesMachine , our custom PDF reader, to include newspaper scans from 1981–2002. However, article text from 1851–1980 is still only available as scans in TimesMachine. Full digital text will take this experience a step further. We’re currently collaborating with a transcription services company to bridge that gap, starting with 1960–1980, so that readers can more easily find, research, and experience content throughout history. Things are going well: we’ve just released the full digital text of every article written in the 1970s . We will continue to update NYTimes.com with newly migrated and transcribed articles in the near future. Stay tuned! You can follow @NYTArchives on Twitter for more updates. How we design and build digital products at The New York Times Code Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-05-22"},
{"website": "NewYork-Times", "title": "why the new york times is working with matter", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/why-the-new-york-times-is-working-with-matter-24178e0ea569", "abstract": "Code Data Product and Design Workplace Culture Work with Us By NICK ROCKWELL For years I’ve followed the progress of Matter Ventures, the San Francisco-based media accelerator run by Corey Ford. I can no longer remember exactly how I was introduced to Matter and to Corey, but I do remember the first demo day that I attended a few years ago, at an event space associated with WNYC. Somehow I had gotten an invitation, but I was on the fence about whether to go. I had recently started in a new role, and was feeling pressed for time. In the end, I went, mostly because an engineering lead I was trying to hire was likely to be there and I was hoping to stalk him in his natural habitat. When I got there, I recognized a face, then another, and another, and I realized I was walking into a room full of many of the most talented people in digital media in New York, with all sorts of opportunities for stalking talent! And this from an accelerator that was based in San Francisco. When the demos started, and the ideas began to flow, I was sure there was something special going on. Over the next several years I got to know Corey and his program better. I was more and more impressed. The rigorous application of design thinking, the selectiveness applied to the participating startups, the quality of the ideas and the people, the energy surrounding the whole process, all supported my initial reaction. I also loved the enthusiasm and optimism around the potential of digital media. Despite the very real disruption of the industry, Matter clearly believes in the potential of media to reinvent itself, evolve and thrive. I do too. However, it was never practical for my New York-based organization to actually work with Matter because they ran their program in San Francisco. While I understood the obvious appeal of the Bay Area, I thought it was a shame for Matter’s presence in New York to be limited to the demo day — a missed opportunity for both Matter and the city that is the undisputed media capital of the world. So I couldn’t be more pleased that Matter is finally launching a class in New York — with the participation of The New York Times and the support of the Google News Lab. I’m so happy to be able to offer the team here at The Times the opportunity to work alongside the inaugural Matter NYC class. And as a veteran of the first wave of the Silicon Alley startup scene back in the ’90s, I am thrilled to play a small role in injecting this wonderful ingredient into what is now an incredibly vibrant tech/media/startup scene in New York. The Times, to me, has always manifested a masterful balance of innovation and tradition. As a newcomer, I’ve been amazed to see how deeply the entrepreneurial spirit runs throughout this company. Collaboration with organizations like Matter is a key component of how we keep our creative fires stoked. You can’t have too much energy, too many good ideas, too many smart people around. Similarly, discipline, user focus, design thinking, cross-functional collaboration, risk-taking, passion and determination — all the characteristics that drive innovation and are so evident in the Matter participants — are never mastered. Constant reminders, honing, and reinforcement are necessary to keep our practice and our instincts sharp. Working side by side with inspired developers, designers and entrepreneurs is the best way to do that. For all these reasons, I’m delighted to have The New York Times collaborating with Matter, and I can’t wait till the Matter NYC demo day in October. I expect to see great things. Nick Rockwell is CTO of The New York Times. Talk with him on Twitter at @nicksrockwell . How we design and build digital products at The New York Times 5 Announcements Matter Design Thinking 5 claps 5 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-05-22"},
{"website": "NewYork-Times", "title": "learning and exploring on 100 day", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/learning-and-exploring-on-100-day-7830c3dae212", "abstract": "Code Data Product and Design Workplace Culture Work with Us By CORY BORG When you hear “hackathon” you envision a scene from “The Social Network”: bleary-eyed developers working into the early morning, slamming energy drinks, furiously typing away on keyboards; the end goal being to best your competition, and be showered in glory from your peers. When I joined The New York Times two years ago, I assumed my first 100% Day would be similar; nothing could be further from the truth. The Times periodically hosts an internal 100% Day. A typical 100% Day, or “Maker Day” at The Times fosters a spirit of collaboration and personal development. We use this time to better ourselves, to learn something new, or build something that we may be interested in. It’s a time where we can dig in, hang out with other members of the organization, and just learn. At the end of the day, we share whatever knowledge we’ve gained, or things we’ve built, with the rest of the company. The March version of 100% Day was no different. Inspired by the work of Lara Hogan , I spent most of my day investigating ways to boost the speed of our current site. I dug into a tool called vmprobe and found ways to optimize our autoscaling efforts on the Real Estate section. There were dozens of talks, ranging from researching findings to full blown demos. Here are some that I personally found interesting: Jared McDonald, Jeff Sisson and Angel Santiago, from Technology, built a system to allow emoji reactions to articles. The goal was to create a mechanism for user feedback that’s more at ease in a mobile setting, and which could attract a reader that would not otherwise be comfortable composing a fully fledged comment. The system was designed to be flexible enough to accept a range of emotional reactions; so anything from “Recommend” to “😳“ is possible. Chris Ladd, from Digital Design, built a Slack bot to respond to the question: “What’s on the menu in the cafe on the 14th floor?” Chris demonstrated his code live on stage, and integrated the bot into several NYT Slack channels. He has also graciously open sourced his code. If you’re so inclined, you can check out the code on GitHub . Ethan G, from Technology, explored what was possible with the Alexa Skills Kit (ASK) for the Amazon Echo. Ethan provided a lighthearted demo showcasing the Echo, with Alexa providing the color commentary using the headlines from The Times’s morning briefing as content. Ethan explained his motivation for the project: “Sci-fi movies make it look all magical and cool to see humans interact in natural language with machines, but from my experience it quickly gets old and I just want Alexa to get stuff done while using my voice as little as possible.” This led him to spend most of his time designing and implementing a reduced instruction set for the parsing schema, allowing him to speak less and still get the same response from Alexa. The end result was a very compelling demo. Cory Borg is a development manager on the NYT Beta team at The New York Times. His focus is on helping the readers of Real Estate section. A self-described coffee snob, Cory can be found frequenting the many third wave coffee shops scattered throughout NYC. How we design and build digital products at The New York Times Projects Hackathons Code Innovation Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-05-22"},
{"website": "NewYork-Times", "title": "introducing gizmo", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/introducing-gizmo-aa7ea463b208", "abstract": "Code Data Product and Design Workplace Culture Work with Us By JP ROBINSON At The New York Times, our development teams have been adopting the Go programming language over the last three years to build better back-end services. In the past I’ve written about using Go for Elastic MapReduce streaming . I’ve also talked about using Go at GothamGo for news analysis and to improve our email and alert systems at the Golang NYC Meetup . We use Go for a wide variety of tasks, but the most common use throughout the company is for building JSON APIs. When we first began building APIs with Go, we didn’t use any frameworks or shared interfaces. This meant that they varied from team to team and project to project with regard to structure, naming conventions and third-party tools. As we started building more and more APIs, the pains of microservices started to become apparent . Around the time we reached this point, I came across Peter Bourgon’s talk from FOSDEM 2015 , “Go and the Modern Enterprise,” and its accompanying blog post . A lot of what Peter said hit close to home for me and seemed very relevant to our situation at The Times. His description of the “Modern Enterprise” fit our technology teams quite well. We’re a consumer-focused company whose engineering group has more than doubled in size to a few hundred heads in recent years, and we have had a service-oriented architecture for a long time. We have also run into the same problems he brought up. As the need for more and more microservices arose, we needed a common set of tools to orchestrate and monitor them, as well as a common set of patterns and interfaces that enable developers to concentrate on business problems. An RFC for a new toolkit named “Go Kit” came out of the talk, and eventually open source development of it was under way. Peter’s talk and the concept of Go Kit made me very excited but also somewhat dismayed. I knew a lot of the RPC and tracing technology involved would likely take a long time to be adopted throughout the company without some stepping stones to get us there. We also didn’t have a whole lot of time to wait around for the toolkit to be completed, so we decided to build our own set of tools that could bridge the gap and hopefully complement Go Kit by implementing some of its “non-goals.” It’s my pleasure to announce that as of today our toolkit, Gizmo , is open source. Gizmo offers four packages to help developers quickly configure and build microservice APIs and pubsub daemons. The Gizmo logo was created by Jean Kim , based on the Go mascot designed by Renée French and copyrighted under the Creative Commons Attribution 3.0 license. The config package provides a set of common, composable structs for working with tools common to technology currently at The New York Times: MySQL MongoDB Oracle AWS (SNS, SQS, S3) Kafka Gorilla’s securecookie Gizmo Servers The package also has a generic Config type that contains all of the above types. It’s meant to be a catchall struct that most applications should be able to use. config also contains a set of functions to help populate data into config types from JSON files, JSON blobs in Consul’s key/value store or, with the help of Kelsey Hightower’s envconfig , environment variables. The helper functions work with any structs, so you aren’t required to use a gizmo/config type to use them. The server package contains the bulk of the toolkit. It provides a set of interfaces that define how a server and service should look and interact with one another starting with the Server interface: The Server implementation is in charge of providing health checks, monitoring, logging, graceful shutdowns and hooks for adding in middleware handlers for any registered services. There are currently two implementations of the Server interface in Gizmo. The first and most used implementation is called SimpleServer. The SimpleServer is composed of the mux and context packages from the Gorilla web toolkit , go-metrics from Richard Crowley and logrus from Simon Eskildsen . The second implementation is the RPCServer, an experimental server that exposes endpoints over gRPC on one port and JSON over another. This server is what we hope to be our next stepping stone on our path toward RPC and Go Kit. Servers are meant to host services that (at a very minimum) must implement the Service interface: The SimpleServer can accept three different flavors of Service interfaces. The first is SimpleService, which is exposed via http.HandlerFuncs: The next service type is JSONService. It is meant to cut out a lot of the boilerplate code behind a pure JSON response. It also provides an additional middleware function to have more control over how a service responds at a global level. A JSONEndpoint is a function that accepts an http.Request and responds with the HTTP status code, an object to marshal as JSON and an optional error. It is converted to an http.Handler via Gizmo’s helper function, JSONToHTTP, which sets the appropriate Content-Type header and status code, then encodes the response as JSON. The last service that the SimpleServer can register is a mixture of the simple and JSON services. It’s called MixedService and can be useful in cases where a service may need some pure JSON endpoints and some endpoints that do more generic web tasks like dropping cookies. When it comes to the RPCServer, only the RPCService can be accepted. It offers service creators the option to expose their gRPC service over JSON: For some basic examples of how to implement, configure and structure Gizmo servers, take a look at the examples/servers directory in the repository. This is the smallest package and consists only of handy functions for parsing types from request queries and payloads. Most of the functions involve extracting integer and date types from input but there is also a function to parse ‘truthy/falsy’ to help with transitions away from legacy services. The pubsub package provides a high-level abstraction for building publisher and subscriber services and implementations for the two messaging systems in use at The New York Times: Amazon SNS / SQS and Apache Kafka . The Amazon implementations are widely used in production here, but the Kafka implementation is still somewhat experimental. To pair well with gRPC, the pubsub interfaces default to accepting protobuf messages but also allow users to work with byte slices. The Publisher interface is pretty small as publishing is a fairly basic concept: The Subscriber interface is somewhat more involved as it needs to be able to offer the ability to acknowledge processed messages and also shut down gracefully. A `SubscriberMessage` interface provides users with access to the message payload and a hook to mark a message as done. The underlying SQS implementation will send an SQS delete message request on `Done()`; Kafka will emit the message’s offset. To help Gizmo users write tests for pubsub services, the toolkit also provides a set of test implementations of the interfaces that can be found in pubsub/pubsubtest . For some examples of how to use the pubsub package, take a look at the examples/pubsub directory in the repository. We currently have five teams using Gizmo to get stuff done at The New York Times, but we know the toolkit is far from done and far from perfect. While we’re open sourcing it to help others adopt Go, we’d also like the awesome Go community to take the toolkit to the next level. See something you’re unsure of or any missing configurations or tools? Please create an issue or a pull request and feel free to contribute to our new public github repository: http://github.com/nytimes/gizmo We’d love to get some help making other Server and Service implementations. Over the next year, I’d like to work together on the following additions to the toolkit: a GoKitServer composed of the awesome tools available in Go Kit a ContextServer composed of Olivier Poitrey’s xhandler and xmux a FastSimpleServer for using Julien Schmidt’s httprouter a WebServer with the html/template toolset from Steve Francia’s Hugo If you have any questions you can reach out to us on the Gopher Slack community under the #gizmo channel. How we design and build digital products at The New York Times 254 Code Go 254 claps 254 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-10-01"},
{"website": "NewYork-Times", "title": "using go and python nltk for news analysis", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/using-go-and-python-nltk-for-news-analysis-2fecdc23ee8", "abstract": "Code Data Product and Design Workplace Culture Work with Us By JP ROBINSON I had the opportunity to speak at this year’s GothamGo conference in New York City about a side project I’ve been working on at The New York Times for several years now: Newshound . Newshound is a breaking news email aggregator that originated at one of the company’s developer events and ended up winning an internal contest in early 2013. Since then, I’ve used the platform as a guinea pig for trying out new technologies. In the latest iteration, I rewrote the core of Newshound with the Go programming language but left an essential piece of software in its original Python implementation. My talk covers the obstacles I had to overcome to complete this recent rewrite. How we design and build digital products at The New York Times 13 Conferences Code Golang Python 13 claps 13 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-05-22"},
{"website": "NewYork-Times", "title": "iot and cassandra topic wildcards in retained storage", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/iot-and-cassandra-topic-wildcards-in-retained-storage-f7b738b2a812", "abstract": "Code Data Product and Design Workplace Culture Work with Us By MICHAEL LAING I recently presented at the 2015 Cassandra Summit on the Internet of Things (IoT) and our work at The New York Times, drawing on over fifty years of experience in computing. The IoT contains Things of Interest (ToI) to our users and to The New York Times. While the intersection contains objects we are familiar with now (such as mobile devices, watches and laptops), by 2020 the mutual ToI will vastly expand. How should we respond? One way, which I discuss in my presentation, is to generalize and expand our global services at a reasonable cost. This will allow our very creative marketers and developers to deploy great apps quickly and solidify each user’s experience across their ToI. How we design and build digital products at The New York Times Conferences Code Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-05-19"},
{"website": "NewYork-Times", "title": "meeting aiyana brooks software engineer at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-aiyana-brooks-software-engineer-at-the-new-york-times-7bd4e4d5ec8c", "abstract": "Code Data Product and Design Workplace Culture Work with Us What are your pronouns? She/her What is your job title and does it mean? Software engineer. This means I write code to provide the solutions needed to drive business value. I currently work on an application called Event Tracker which enables The New York Times to collect data and metrics about how our readers use our various products. How long have you been at The Times? This is actually my second time working at The Times. I first worked here from 2007 to 2013 as a software engineer on the CMS team, and I rejoined in July, 2020 on the Data Collections team. Most Times employees are working remotely right now. What does working from home look like for you? Working from home right now is … interesting. My oldest daughter is in second grade and doing remote school. She and I share the dining area as our work space and we usually have competing video calls. My partner is also an engineer and he takes his video calls in one of the bedrooms. In between meetings, we both take turns entertaining our two-year-old. After doing this for over a year, we have settled into a routine that enables us to be surprisingly efficient and effective. Tell us about a project you’ve worked on at The Times that you’re especially proud of. The Times and the Data Collections team take reader privacy very seriously, and readers who have visited our site can request to have any of the data we have collected about them removed — this is called a Data Subject Request (DSR). I wrote the code that takes a DSR, finds all of the instances of that reader’s data in our database and removes them. This was challenging because the team had to find a way to effectively search through all of the data in a fairly large database. Additionally, we needed to be able to do this on a regular basis for any reader who submits a DSR, so I wrote the code, using Apache Airflow, in a way that could be run on a schedule. What is the biggest challenge you faced in your career and how did you overcome it? Knowing what you know now, would you do things differently. One challenge I faced early in my career was not knowing how to advocate for myself. I approached my early career the same way that I approached school: I did the work that was assigned to me to the best of my ability. I soon realized that this was not the best way to move my career forward. Today, I am much more deliberate in identifying the kinds of projects that excite me and I am not afraid to make suggestions or volunteer for challenging assignments. I also make sure that I frequently communicate my goals with my manager and that I am getting opportunities that keep me on track toward meeting my goals. Do you have any favorite life hacks or work shortcuts? I’ve recently started using TiddlyWiki to organize all of my ideas. I like it because it’s really just a self-contained HTML file. This means I don’t have to worry about installing special software to be able to view my notes. What is your best advice for someone starting to work in your field? Learn how to learn. Software engineering is a field that changes rapidly; You need to have curiosity and you need to understand the learning style that works best for you. There are so many great resources out there, many available for free or with a free trial. Massive open online courses can provide a great introduction to any software topic, but it’s also important to learn by doing. There are many sites, such as Advent of Code, Exercism and Free Code Camp, that offer code challenges. Cloud platforms, such as Amazon Web Services and Google Cloud Platform, typically offer a free tier or free credits so that someone interested in learning can experiment with the platforms. With so much information available, it can feel intimidating to get started, but the best way is to just choose a resource and stick with it. Be patient with yourself and accept that being confused is part of the job, as is the satisfaction that comes when things start to “click.” Meeting… Tony Giaccone, Senior Software Engineer at The New York Times Meeting… Alexandra Shaheen, Program Manager at The New York Times Meeting… Vanessa Jiménez, Associate Software Engineer at The New York Times How we design and build digital products at The New York Times 19 Nyt Open Meeting Software Engineering Women In Tech Code Data 19 claps 19 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-05-18"},
{"website": "NewYork-Times", "title": "building the next new york times recommendation engine", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/building-the-next-new-york-times-recommendation-engine-19ac4715b9fa", "abstract": "Code Data Product and Design Workplace Culture Work with Us By ALEXANDER SPANGHER The New York Times publishes over 300 articles, blog posts and interactive stories a day. Refining the path our readers take through this content — personalizing the placement of articles on our apps and website — can help readers find information relevant to them, such as the right news at the right times, personalized supplements to major events and stories in their preferred multimedia format. In this post, I’ll discuss our recent work revamping The New York Times’s article recommendation algorithm, which currently serves behind the Recommended for You section of NYTimes.com. Content-based filtering News recommendations must perform well on fresh content: breaking news that hasn’t been viewed by many readers yet. Thus, the article data available at publishing time can be useful: the topics, author, desk and associated keyword tags of each article. Our first recommendation engine used these keyword tags to make recommendations. Using tags for articles and a user’s 30-day reading history, the algorithm recommends articles similar to those that have already been read. Because this technique relies on a content model, it’s part of a broader class of content-based recommendation algorithms. The approach has intuitive appeal: If a user read ten articles tagged with the word “Clinton,” they would probably like future “Clinton”-tagged articles. And this technique performs as well on fresh content as it does on older content, since it relies on data available at the time of publishing. However, this method relies on a content model that, sometimes, has unintended effects. Because the algorithm weights tags by their rareness within a corpus, rare tags have a large effect. This works well most of the time, but occasionally degrades the user experience. For instance, one reader noted that while she was interested in same-sex pieces, occasionally in the Weddings section, she was being recommended wedding coverage about heterosexual couples. This is because a low-frequency tag, “Weddings and Engagements,” was in an article previously clicked, outweighing all other tags that may have been more applicable for that reader. To accommodate the shortcomings of the previous method, we tested collaborative filtering. Collaborative filters surface articles based on what similar readers have read; in our case, similarity was determined by reading history. This approach is also appealing: If one reader’s preferences are very similar to another reader’s, articles that the first reader reads might interest the second, and vice versa. However, this approach fails at recommending newly-published, unexplored articles: articles that were relevant to groups of readers but hadn’t yet been read by any reader in that group. A collaborative filter might also, hypothetically, cluster reading patterns in narrow viewpoints . It turns out that straddling both techniques can give us the best of both worlds. We built an algorithm inspired by a technique, Collaborative Topic Modeling (CTM), that (1) models content, (2) adjusts this model by viewing signals from readers, (3) models reader preference and (4) makes recommendations by similarity between preference and content. Our algorithm starts by modeling each article as a mixture of the topics it addresses. We can think of a topic as an unobserved theme, like Politics or Environment , that affects the words observed in the article. For example, if an article is about the environment, we’d expect words like “tree” or “conservation.” We model each reader based on their topic preferences. We can then recommend articles based on how closely their topics match a reader’s preferred topics. As an example, we run our algorithm supposing that all New York Times articles published in the last month can be represented as a combination of two topics. Under these constraints, the algorithm identifies these topics, roughly, as Politics and Art . Our algorithm finds an article, America Deepens its Footprint in Iraq Once More , as 100% Politics , and a film review by A.O. Scott as 100% Art . It labels mixtures, too; for example, an article about art politics, Frick Museum Abandons Contested Renovation Plan , is labeled 50% Politics , 50% Art . In this Politics - Art space, we might describe our articles in the following manner: Next, suppose that one reader prefers to read about Art 60% of the time and Politics 40% of the time. We might represent that reader with the red x. The magical part is that they are spatially close to articles that align with their interests, even if they haven’t read them yet; we recommend articles that are closest to them in the space. There are further questions for us to answer. Can this topic space capture ambiguous word usage? And how do we best observe the preferences of our readers? Clicks are, after all, not robust: I’m sure that at some point, you have clicked on something you didn’t enjoy and missed something you would have found interesting. We tested many options carefully; the algorithm we built brings us closer to addressing some of these questions, and gives us a powerful new way to understand The New York Times. This is a three-part challenge: Part 1: How to model an article based on its text. Part 2: How to update the model based on audience reading patterns. Part 3: How to describe readers based on their reading history. Part 1: How to model an article based on its text. First, our algorithm looks at the body of each article and applies Latent Dirichlet Allocation (LDA), a content modeling algorithm. LDA learns the mixture of “topics” in each article: A topic is formally defined as a distribution over a vocabulary. If a document has a certain topic weighted highly, the words seen in the article are more likely to be words weighted highly under this topic. LDA is quick, accurate for our purposes and capable of online inference (or learning topics in real time as new articles are published). LDA topics tend to be broad (some examples are Middle East , Film and Healthcare ), which allows us to relate pieces from differing viewpoints. LDA is based on a graphical model , which can easily be extended to incorporate new assumptions and information. In our case, we extend our model to model not only the text of an article, but also the specific readers reading that article, described in the next section. Part 2: How to update the model based on audience reading patterns. LDA takes words as input, but words are often ambiguous: Context, style and voice can adjust their meaning. For example, if Gail Collins writes a piece with the words “dog,” “car” and “roof,” can we tell that she’s being allegorical, and not just writing about animals and automobiles? Indeed, a purely LDA-based approach gives weight to travel, placing her piece at the blue point in the diagram below. However, a large sample of readers reading the piece have also read pieces about Hillary Clinton and Ted Cruz (visualized for illustration at the red x’s), so we’d like our algorithm to adjust it to the green point in the Politics topic. By adding offsets to model topic error, as described in the CTM paper, our algorithm incorporates reading patterns on top of content modeling to create a hybrid approach. The CTM algorithm works by iteratively adjusting offsets and then recalculating reader scores. It runs until there is little change in either. A randomly chosen subset of readers, called our training sample, gives us the information we need. We tested two methods for calculating offsets: (1) CTM and (2) an approach called Collaborative Poisson Factorization . In online A/B testing, we found CTM to perform better. Part 3: How to describe readers based on their reading history. The methods used for adjusting article topics also calculate reader preference, but they can’t scale to all our users. Therefore, we needed a quick way to calculate reader preferences, which can occur after finalizing article topics. A simple approach would be to average together the topics of all articles you’ve read: If you’ve clicked on one article that is 40% Politics , 60% Art and another that is 60% Politics , 40% Art , you’re [. 5, .5] in the Politics - Art topic space. However, this assumes that clicks perfectly indicate preference. What if you clicked on an article you didn’t like, or missed one you would have? One way to approach this is to back off a bit, and say that you only “90% like” the articles you read, and “10% like” the ones you didn’t. This leaves room for mistaken clicks or missed gems. In this diagram, the green dots represent articles a reader has read, and the red dots represent ones they haven’t. The black x might be the reader’s preferences calculated using an average of articles read, and the blue x would be using the back-off approach. The back-off approach makes a more conservative estimate of preferences, allowing us to be more robust to noisy data. It also, we’ve noticed, brings readers out of niches and exposes them to different, “serendipitous” recommendations. By implementing some neat algorithmic speed-ups, we were able to calculate preferences in less than one millisecond per reader, enabling us to scale to all registered users. By modeling article content and reader preferences with topics, then adjusting based on reading patterns, we’ve reconceptualized our recommendation engine. Our system is now a successful, large-scale implementation of cutting-edge research in collaborative topic modeling, and it provides significant performance increases when compared with previous algorithms used to make recommendations. Recommendation systems, we hope, can enable a dynamic New York Times to serve interesting articles at opportune times. They also help shine light on the types of articles we’re writing, and who they appeal to. The New York Times technology team is responsible for building, maintaining and improving NYTimes.com, our mobile apps and products, and the technology that powers them. We’re a group of over 250 people, delivering content from one of the largest news organizations in the world. If you’re interested in leveraging one of the deepest datasets in the news industry and helping us develop better products, make smarter business decisions and reach larger audiences through our personalization efforts, then we’d love to hear from you . How we design and build digital products at The New York Times 8 Data 8 claps 8 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-05-19"},
{"website": "NewYork-Times", "title": "the training is coming from inside the cms", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/the-training-is-coming-from-inside-the-cms-55849d795779", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Eric Athas and Taylor Poulos In an era where storytelling is constantly evolving, how do you seamlessly train a newsroom with 1,700 journalists spread around the world? That’s a question near and dear to the Newsroom Development & Support team (or, N.D.S.), a department responsible for driving change at The New York Times. The team has trained reporters and editors on everything from live briefings to data reporting to visual journalism and new story formats like explainers. In 2019, N.D.S. completed one of its biggest undertakings: training the entire newsroom on an expressive and collaborative CMS, called Oak . The N.D.S. team coached every single reporter and editor one-on-one — in New York, Washington, D.C., Hong Kong, London, San Francisco and remotely for correspondents — through every part of the tool, and explained how it all worked and best practices for its powerful storytelling capabilities. And then, when journalists began using Oak, the team was there to answer questions in-person and on Slack. We also worked closely with the Oak product team to incorporate feedback and make the software more effective and easier to use. The work was exhaustive and time intensive. And, because the team spent so much time training reporters and editors on how to use Oak, that left less time to train them to master different story formats, move swiftly during breaking news, make stories more visual and other skills needed in the new tool. To help make Oak training more efficient, the N.D.S. and Oak teams launched a project aimed at building guidance — such as tooltips, helper text and best practices — directly into Oak. The goal: Give reporters and editors the help they need, in the places where they work, at the moments they need it most. With that goal firmly in mind, we interviewed our colleagues within The Times and outside experts on training to understand where our documentation worked well and where it fell short. Through this research, we uncovered several major challenges. 1,700 people is a lot of people The first challenge was the size and scope of the newsroom itself. With over 1,700 journalists who touch our CMS, there are many different roles that need to be accounted for. Our CMS users include reporters who work on one major feature story for a long period of time; editors who shepherd dozens of stories toward publication every week; and visual journalists who are focused on making our report striking and beautiful. Varied expectations for what a CMS can do A journalist’s previous experience with a CMS can affect their expectations of our tools. People who have joined The Times from organizations with less effective CMS teams had limited expectations about what a CMS could do. Because the first step of learning how to do a task is being aware that the task is possible, these lowered expectations made people less likely to try new things; They simply assumed that whatever they wanted to do wasn’t possible. On the other hand, some people were used to asking more of their CMS, and were comfortable pushing its limits through insightful questions and feature suggestions. It’s hard for busy journalists to keep track of every new feature With a dedicated product and development team for our CMS, we are constantly tweaking our tools, especially the tools our journalists use most often. This means we need to continually provide training that covers new changes. And because our tools are complex, these training sessions are sometimes over an hour and a half long. We can’t expect every person to remember every detail of the sessions. [If this work is interesting to you, come work with us. We are hiring !] Training isn’t one and done — tools and best practices evolve As the world we report on changes, so do our tools and best practices. Our tools need to have the capability to surface, document and remind users about these changes. One participant in our research put it succinctly when he compared journalism to medicine, where knowledge is constantly evolving, and practitioners constantly need to stay up to date with the latest techniques. The research was essential in learning what guidance would be most useful for the Times newsroom. It also helped us identify the challenges we would need to navigate when placing tips in the space where our journalists work. Our next step was to make sure that the guidance would be informed by the journalists doing the work day in and day out. We made a list of every field that our reporters and editors touch in Oak — such as headline, summary, captions and URL — and asked over a dozen colleagues about each one. We wanted to know what tips we should include and how we might frame guidance in the CMS. We also wanted to know where there are sticking points in the CMS, and what is most important to flag when journalists are making decisions on deadline. Although we already had extensive best practice documents and how-to guides for every aspect of newsroom work, space is limited in Oak. This process allowed us to narrow in on the guidance that would be most essential to surface as our colleagues write and edit. Once the list of items was refined, then it was time to figure out where they should live in the CMS. Here’s where we landed: For most of the guidance we came up with, the right rail was the best place to put it. The information in the right rail shows up when a user is focused in a specific field, making it targeted to the moment users need it most. Auxiliary information, like a character count, can be shown within the same context, giving live feedback as users perform an action. And unlike tooltips, which show up only when users think to click or hover over the right icon, the guidance is shown by default; always there, but designed to be differential and not distracting. Oak is an element-based editor, meaning that journalists build their stories out of a wide array of multimedia and text based elements, such as images, pull quotes, headings and embedded tweets. To document these elements, we expanded the element menu to include space for an image, a description and a link to learn more about the type of element, leaving plenty of room for explanations about what the element is, and how it can be used. In addition to this in-CMS, N.D.S. has produced a lot of documentation about our best practices for things such as SEO, visual journalism, editing processes, and story formats. However, it wasn’t clear where people could access this information within Oak. The help center is integrated into the tool itself, accessible through an icon in the lower right hand corner of the screen. It has a curated list of documentation and links, as well as the option to search our full documentation library. It also has a place for people to submit feedback about the tool directly, making it easier for people to submit feedback or questions the second they run into issues. How we tell stories will only continue to change. And so our journalists will continually have new things to learn: new tools, updated standards and best practices to ensure they’re able to make the best journalism possible. Just as our storytelling formats will change, so will our tools. It’s important to have a clear process for keeping all of the documentation we have placed into Oak up-to-date. Our colleague, Jin Kim, an editor with N.D.S., will lead the next chapter of this work to keep in-tool guidance relevant. Jin will coordinate between the Oak team and N.D.S. to determine when the text in Oak has become out of date and will be able to update the information on the fly. In collaboration with newsroom experts, Jin will also keep a pulse on emerging journalistic practices — such as new SEO tactics or updated standards guidance — that can be surfaced to reporters and editors. By building this capacity, we hope to continue evolving the guidance built into Oak, well into the future. Eric Athas is a Senior Editor for Digital Training at The New York Times Taylor Poulos is a Senior Product Designer in Publishing at The New York Times. How we design and build digital products at The New York Times 39 Design User Research Journalism UX User Experience 39 claps 39 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-05-20"},
{"website": "NewYork-Times", "title": "meeting ahmed bebars lead software engineer at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-ahmed-bebars-lead-software-engineer-at-the-new-york-times-208105b2f6e9", "abstract": "Code Data Product and Design Workplace Culture Work with Us What are your pronouns? He/Him What is your job title and does it mean? Lead Software Engineer. I work with Customer Care, specifically on the Insights and Analytics team. We build platforms that gather and analyze data that help improve our readers’ experience when they contact The New York Times. How long have you been at The Times? It will be two years in July. Most Times employees are working remotely right now. What does working from home look like for you? I work from my cozy home office in central New Jersey. How do you start your day? My day starts with a short drive to drop my daughter at daycare. When I get home, I prepare my espresso to get my workday started. What is something you’ve worked on recently? We built an automated Machine learning pipeline to tag and categorize customer interactions to help our product colleagues prioritize feature work and make decisions based on the generated data. Tell us about a project you’ve worked on at The Times that you’re especially proud of. Our team migrated our Contact Center to Amazon Connect and built an intelligent Interactive Voice Response to assist customers with their requests. It was a large project that involved a number of services including, AWS Lex and Lambda. I presented this project at AWS re:invent in December, 2019 . What is the biggest challenge you faced in your career and how did you overcome it? Knowing what you know now, would you do things differently. Switching from accounting to software engineering wasn’t the hardest decision to make, but the challenge was in achieving the career change. The hardest part was finding the support and help to guide me along the way. The one thing that I would change is reaching out to more people in the community for their perspectives and to get more support. What was your first job? When I was 16, I started my technology adventure by fixing computers at an internet cafe in Alexandria, Egypt — I also learned how to plan and install wired networks. It was fun, but I learned that I love to build and architect systems more than networks. What is something most people don’t know about you? I am an Advanced Nitrox-certified scuba diver, and my last maximum dive depth was 102 feet. Hopefully, I will be able to travel and break that personal record soon. What is your superpower? Building proofs of concept is a powerful instrument that I often use to quickly verify ideas and solutions without investing too much time or energy until the idea is proven to work. What are you inspired by? My wife. She is very supportive, hard working and my go-to person when I need advice on complex problems. Complete this sentence: Over time, I have realized that __________. Learning has no limits and every day there is something new to learn. What is your best advice for someone starting to work in your field? Passion is the critical element to success in anything. It will guide you through your career and keep you thirsty to learn more and complete more achievements that you can be proud of every day when you look back. Meeting… Vanessa Jiménez, Associate Software Engineer at The New York Times Meeting… Steven Nedlin, Data Engineering Director at The New York Times Meeting… Cindy Taibi, Chief Information Officer at The New York Times How we design and build digital products at The New York Times 44 Nyt Open Meeting Technology Software Engineering Developer Data Engineering 44 claps 44 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-04-21"},
{"website": "NewYork-Times", "title": "how we redesigned the new york times opinion essay", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/how-we-redesigned-the-new-york-times-opinion-essay-ad5e0270f5bc", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Dalit Shalom Picture a dinner party. The table is set with a festive meal, glasses full of your favorite drink. A group of your friends gather around to talk and share stories. The conversation swings from topic to topic and everyone is engaged in a lively discussion, excited to share ideas and stories with one another. This is what we imagined when we — a group of New York Times editors, strategists and designers — teamed up last summer to talk about how to think about how our Opinion coverage is presented and packaged to our readers. We envisioned a forum that facilitated thoughtful discussion and would invite people to participate in vibrant debates. The team was established after a wave of feedback from our readers showed that many people found it difficult to tell whether a story was an Opinion piece or hard news. This feedback was concerning. The Times publishes fact-based journalism both in our newsroom and on our Opinion desk, but it is very important to our mission that the distinction between the two is clear. The type of Opinion journalism our group was tasked with rethinking was the Op-Ed, which was first introduced in the Times newspaper in 1970. The Op-Ed was short for “opposite the Editorial Page,” and it contained essays written by both Times columnists and external contributors from across the political, cultural and global spectrum who shared their viewpoints on numerous topics and current events. Because of the Op-Ed’s proximity to the Editorial Page in the printed newspaper, it was clear that published essays were Opinion journalism. Then The Times began publishing online. Today, most of our readers find our journalism across many different media channels. The Op-Ed lost its clear proximity to the Editorial Page, and the term has been used broadly as a catch-all phrase for Opinion pieces, leaving the definition of what an Op-Ed is unclear. To learn more about the friction our readership was describing, we held several research sessions with various types of Times readers, including subscribers and non-subscribers. Over the course of these sessions, we learned that readers genuinely crave a diversity of viewpoints. They turn to the Opinion section for a curated conversation that introduces them to ideologies different than their own. In the divided nature of politics today, many readers are looking for structured arguments that prepare them to converse thoughtfully about complicated topics. Some readers said they want to challenge and interrogate their own beliefs. Others worry that they exist in their own bubbles and they need to understand how the “other side” thinks. And across the board, readers said they are aware that social media platforms can be echo chambers that help validate their beliefs rather than illuminate different perspectives. They believe The Times can help them look outside those echo chambers. Considering this feedback, we took a close look at the anatomy of an Op-Ed piece. At a glance, Opinion pieces shared similar, but not necessarily cohesive, properties. They had an “Opinion” label at the top of the page that was sometimes followed by a descriptive sub-label (for example, “The Argument”), as a way to indicate a story belonged to a column. That would be a headline, a summary and a byline, often accompanied by an image or video before the actual text of the story. By looking at those visual cues, it became clear to us that they could be reconfigured to better communicate the difference between news and opinion. We created several design provocations and conducted user testing sessions with readers to see how this approach and a new layout might resonate. Some noticeable changes we made include center-aligning the Opinion label and header, labeling the section in red and providing more intentional guidance and art direction for visuals that accommodate Opinion pieces. While many readers could tell the difference between news and opinion stories, they didn’t understand why certain voices were featured in the Opinion section. They wanted more clarity about the Op-Ed, such as who wrote it and whether the writer was Times staff or an external voice. In the case of external contributors, readers wanted to know why the desk chose to feature their voice. These questions took our team back to the drawing board. We began to realize that the challenge at hand was not solely a design problem, but a framing issue, as well. We had long philosophical conversations about the meaning of Op-Ed pieces. We talked about the importance of hosting external voices and how those voices should be presented to our readers. The metaphor of a dinner party figured prominently in our conversations: the Opinion section should be a place where guests gather to engage in an environment that is civil and respectful. We began to sharpen how we might convey the difference between an endorsement of a particular voice and hosting a guest — one of many who might contribute to a lively debate around a current event. The more we thought about the Opinion section as a dinner party, the more we felt how crucial it was to communicate this idea to readers. As we approached the designs, we set out to create an atmosphere for open dialogue and conversation. Two significant editorial changes came out of our group conversations. After many iterations, we decided to introduce a two-tiered labeling system, so that readers could understand unequivocally the type of Opinion piece they were about to engage with. For external voices, we added the label “ Guest Essay ,” alongside other labels that indicate staff contributors and internal editorials. The label “Guest Essay” not only shifts the tone of a piece — a guest that we are hosting to share their point of view — but it also helps readers distinguish between opinions coming from the voice of The Times and opinions coming from external voices. The second important editorial change is a more detailed bio about the author whose opinion we are sharing. With the dinner party metaphor in mind, this kind of intentional introduction can be seen as a toast, providing context, clarity and relevance around who someone is and why we chose them to write an essay. Some of these changes may seem subtle, but sometimes the best dinner conversations are nuanced. This body of work signals an important moment for The New York Times in how we think about expressing opinions on our platform. We believe that one of the things that makes for a healthy society and a functioning democracy is a space for numerous perspectives to be honored and celebrated. We are confident these improvements will help further Times Opinion’s mission of curating debate and discussion around the world’s most pressing issues. Dalit Shalom is the Design Lead for the Story Formats team at The New York Times, focusing on crafting new storytelling vehicles for Times journalism. Dalit teaches classes on creative thinking and news products at NYU and Columbia, and in her free time you can find her baking tremendous amounts of babka. How we design and build digital products at The New York Times 260 Journalism News Design Thinking UX Design 260 claps 260 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-04-27"},
{"website": "NewYork-Times", "title": "over 150 million photos some perl scripts and a creaky user interface", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/over-150-million-photos-some-perl-scripts-and-a-creaky-user-interface-c00f7b6d5fd9", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Kate Brenner On an assignment, a New York Times photographer might take hundreds of photos but only file a handful of their best shots. These best photos, often referred to as “selects,” are typically uploaded directly from the photographer’s camera to our CMS for a photo editor to access. It is a workflow that is geared towards efficiency, and to get the news out as quickly as possible. But just because a few photos have been chosen to publish doesn’t mean that the outtakes are unusable or irrelevant. Many of these photos do in fact get published, sometimes days or even years later. Over time, The Times has collected these outtakes, which number more than 150 million, and has stored them in Amazon Web Services (AWS) storage gateways. For Times photo editors to access the outtakes, an in-house team built a system called Scrounger, which was written as a series of Perl scripts that ran on an AWS server. Scrounger had a search UI that editors could use to find photos, but only if they knew the numerical assignment ID that is generated with each news assignment. If an engineer needed to access the photos on the back-end, they had to connect to a remote desktop and sift through the storage gateways rendered as network drives. While this was a challenge in itself, there was another major flaw: no descriptive information was stored in a database, which meant there was no efficient way to query this massive collection of images. The only searchable information was in a photo’s file path, which included the date of the assignment, the assignment ID number and the file name, which looked something like this: 20210401/12345678A/test_photo_1.jpg. In the past few years, the Times Photo Team has been systematically updating our photo management software. After updating the search algorithm for our main search tool for selects , we set our sights on building a system for outtakes — a Scrounger 2.0. Some of the Photo team’s work has included consolidating our systems onto a single cloud provider — we use Google Cloud Platform (GCP). Our first step in creating Scrounger 2.0 was to transfer all of Scrounger’s photos to Google Cloud Storage (GCS) to make them easily accessible to our system. This was more complex than we anticipated. Because the photos were stored in AWS storage gateways, they first had to be synched to an Amazon S3 bucket before they could be transferred to GCS using Google’s Storage Transfer Service. Luckily, we were able to preserve the file path for each photo. This was a huge win because most of the information we had about these photos was in the file path. Once the photos were in GCS, we had to determine the best way to efficiently ingest and store them. We built a database to keep relevant information about each photo, and we created a flexible schema that could be updated as needed. We built four tables in our new system. The Metastore table , which was the raw dump of all the information we had about an incoming photo and included all image metadata stored as JSON. This table was set up with a trigger to send each row to the second table. The Event Queue table , in which rows were stored temporarily until they were processed and inserted into the third table. The Assets table , which contained columns for metadata fields, such as description or credit, that were relevant to the photo. If we need to update the schema of the Assets table, we can “replay” ingestion and resend all rows from the Metastore table to the Assets table, without duplicating any records. The Search table combined several columns from the Assets table, such as the identifier, creator, description, filename and assignment ID as a tsvector , so we could apply a full-text search on these fields. We could have our API query for assets on many different query parameters. We built an application called Gateway as the initial point of ingestion for all past and future outtakes. Gateway listens for notifications of incoming images and runs exiftool on each image to combine its image metadata with GCS metadata and store all of that information in the Metastore table. An application called Megaphone listens for database events and publishes them to two more applications, Materializer and Enhancer. Materializer scans and externalizes specific metadata fields, such as photographer and caption, and stores them in the Assets table. Enhancer updates the Assets table with additional information from The Times’s assignment database, such as credit or photographer. Combining the information from the original file path, externalizing several different forms of metadata, using information gathered from the assignments table, and storing all of this information in our new schema enabled us to make these photos searchable. We wrote an API in python to interact with our database, and we created a UI for Scrounger 2.0 in React. Once the new system was built, we ran the migration and kicked off ingestion for all 150 million photos. We created a temporary manifest from the image dump from the old system. For each photo in the GCS bucket, we extracted and parsed its original storage path to obtain the assignment ID, assignment date, file name, file size and file extension. We then put all that information into the manifest so we could perform queries and learn more about the photos in the image dump. From there, we set up ingestion into the new system. We wrote a script that iterated through the manifest and applied each image’s metadata to the corresponding GCS object. Our GCS bucket sent notifications to the Gateway service with each metadata update. To verify that all 150 million records had indeed been transferred over, we wrote a verifier script that iterated through the metastore table. For each Scrounger 1.0 entry, the script ensured that every row had been ingested into Scrounger 2.0 and it updated the temporary manifest with a status of “verified.” Because the old system stored multiple versions of each image — such as high resolution, medium resolution and thumbnail — we needed to deduplicate them. Storing all resolutions from the old system would take up too much space in the Assets table, and it would create noisy search results in the UI. We didn’t want to permanently delete any photos, so we added a special metadata field that leaves the files in the Metastore table but deletes them from the Assets table. Since we still need different crops for different views in the UI, we created an API that can cut and cache renditions on the fly without taking up unnecessary storage space. Since we launched Scrounger 2.0, our team has implemented enhancements around search, such as sorting and filtering capabilities. Now, in addition to assignment ID, Times editors can search by a variety of terms, such as photographer name or keywords that might be found in a photo’s description. There is plenty more work to be done on this system. Not every outtake was stored in Scrounger 1.0; some outtakes were stored on DVDs in the Times newsroom. Now that our new system is up, we hope to finish transferring all of these images to help preserve the historical record these photos contain. Kate Brenner is a software engineer on the Photo Team at The New York Times. When she’s not coding, she enjoys running, going on adventures with her dog and exploring food that can be used as a vehicle for ketchup. The Photo Team is: Farah Abbasi, Frank Borell, Kate Brenner, Chris Frank, Chris Grillo, Sherman Hewitt, Jenny Hottle, Michael Laing, Michael Moffitt, Shonta’ Singleton and Sharon Tartarone. Special thanks to Photo Team alum Suman Roy. How we design and build digital products at The New York Times 33 Code Software Development Technology Photography Engineering 33 claps 33 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-04-22"},
{"website": "NewYork-Times", "title": "an update to our sql interviews", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/an-update-to-our-sql-interviews-cf39dafeddcf", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Luke Summerlin and MacKenzie Gibson Over the last few years, the Data & Insights Group at The New York Times has more than doubled as we have integrated data into all our business and newsroom processes. Our data analysts’ responsibilities, and the tools they use, vary greatly depending on the team they work on. Whether a data analyst works with the marketing team to develop media mixed models, partners with editors and product managers to run A/B tests on the homepage or analyzes Crossword engagement, we expect our analysts to foster a culture of curiosity, intellectual honesty and clear communication. The one technical skill that unifies all analyst work is SQL. In 2018, we implemented a standardized SQL assessment as part of the hiring process for all Times data analyst positions. Once we launched the assessment, we began holding monthly retrospectives with interview panelists to see what was working and what was not. Through the retrospectives and candidate feedback, we came to the conclusion that our current assessment was not upholding the diversity, equity and inclusion values that The Times seeks to foster through our hiring processes. So, we sought out to change this. The core part of our assessment needed to be rethought: the SQL test was not seeing consistent pass rates. Live-coding in a time-boxed environment is neither a realistic working environment nor is it stress reducing, especially given the already high-stress nature of a technical interview. In our monthly retrospectives, we evaluated the assessment’s strengths and weaknesses. We paid particular attention to where the intent of the assessment diverged with the experience of taking it. Among its strengths, the format allowed candidates to ask questions on the fly; use documentation; explain their approach while constructing queries; and provide interpretations of results. Additionally, the structure ensured all candidates were able to dedicate equal time to the assessment and it minimized opportunities to cheat. When considering shortcomings, we found that the live-coding format created a high-pressure environment, which hindered some candidates’ performance. It was clear to us that we needed to create a more equitable format. We considered other established evaluation practices and we laid out strengths and weaknesses of each approach: Live-coding exercise Normalizes the amount of time spent. Standardizes access to resources and subject matter experts. Assesses the ability to apply documentation, debug queries and communicate results. Creates a high-pressure environment that can impact performance, especially among candidates unfamiliar with the structure. Take-home assessment Allows candidates to work at their own pace. Favors candidates who have fewer time constraints and access to strong knowledge networks. Whiteboarding exercise Can cause the same pressure as a live-coding format. Does not assess fundamental skills we look for in analysts, such as the ability to apply documentation, debug queries or interpret results. We needed a standardized SQL assessment that had consistent deadlines and access to resources, yet minimized the pressure felt by candidates. The format we chose needed to allow us to evaluate candidates’ abilities to think through analytical problems using SQL; to apply appropriate functions that reference documentation, when necessary; interpret and communicate results; and provide an inclusive environment for neurodiverse candidates. The format we developed is a hybrid model that combines elements from take-home and live-coding exercises. Our new structure still takes place over a video call. Shortly before the assessment begins, the candidate is given access to the BigQuery browser tool. The assessment is broken into three primary parts: set up, work and interpretation. Set up (5 minutes): After introductions, the candidate will share their screen so the assessor can help them set up the BigQuery console and walk through the datasets. The assessor will review expectations of the assessment and share a problem set. Work (30 minutes): The candidate will stop sharing their screen, but stay connected to the video call. With cameras off, they will have 30 minutes to independently work on the problem set. Candidates will write SQL, run queries and return results using documentation when necessary. Assessors will be available to answer questions in the video call, but otherwise candidates will work in an unmonitored environment. Interpretation (15 minutes): The assessor and candidate will turn their cameras back on and the candidate will share their screen again to walk through each question they answered, run the query and interpret the results. The assessment screens for core competencies, including the ability to aggregate, categorize and transform data, as well as apply documentation when necessary. Candidates are expected to be familiar with many of the competencies, although they do not need to demonstrate knowledge of everything to pass. After the assessment is over, the assessor will spend 15 minutes writing in-depth feedback on the candidate’s performance with regard to their understanding of the core competencies and how they interpreted the data. In the new format, we have extended the time candidates have to work on the problem-set from 20 minutes to 30 minutes without increasing the requirements to pass. By providing 30 minutes of uninterrupted time to work, we hope to reduce the stress of the assessment; if candidates need additional time, they may request it when scheduling the assessment. We have introduced a survey that we encourage candidates to complete after taking the assessment. Formalizing a feedback loop can help focus where we need to refine the format which we will discuss in monthly retros, and allow us to continue improving upon an inclusive hiring process. We are currently hiring analysts at various levels. Come work with us . Luke Summerlin is a Data Manager on the Games team and he barely passed the SQL assessment in the summer of 2018 but has increased his SQL skills a lot since then. MacKenzie Gibson is a Data Manager on the Messaging and Personalization team. She is a former beekeeper and is a firm believer in the power of public transportation. How we design and build digital products at The New York Times 206 Data Analysis Data Hiring Work Analytics 206 claps 206 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-03-25"},
{"website": "NewYork-Times", "title": "meeting vicki crosson software engineer at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-vicki-crosson-software-engineer-at-the-new-york-times-2ed88e1743ab", "abstract": "Code Data Product and Design Workplace Culture Work with Us What are your pronouns? She/Her What is your job title and what does it mean? My job title is software engineer on the Search team. That means I write and maintain various software systems that my team operates. It’s not a terribly descriptive title, as I wear a lot of hats that aren’t just writing code. I’m currently serving in another role as well: Chairperson of the Architecture Review Board, or “ARB.” The ARB is a resource for all technology teams at The Times, which helps to foster the architectural community as well as provide reviews on Requests for Comment. As Chairperson, I primarily help organize meetings and the ARB application process, promote initiatives and working groups, and I interface with management. How long have you been at The Times? I have been with the company for 55 months; I’m coming up quickly on the five-year mark! Most Times employees are working remotely right now. What does working from home these days look like for you? I’m fortunate that my job can be done from anywhere and I have been working remotely since before the pandemic. I have chronic issues that make it difficult for me to travel into the office every day. For me, working remotely means being able to show up in the morning without being exhausted from walking a half-mile to the subway, riding the train for 45 minutes and climbing a bunch of stairs to get out of the station. Of course, I have found that others who are usually in the office recently have a newfound understanding of remote life, and that’s had a positive impact on a lot of things. Remote meetings run a lot more smoothly now that we’ve all had practice this past year! Tell us about a project you’ve worked on at The Times that you’re especially proud of. When I first started out at The Times, I was fortunate to work on the schema for a publishing pipeline that was new at the time. My team collected the JSON schemas being used by various APIs around the company and combined them into a mega-schema that could be shared by everyone. We also researched which binary serialization protocol we would use (Protobuf), as well as the best way to manage constraints on the forward and backward-compatibility of the system as the schema changed over time. Even today, my favorite part of my job is consulting with teams who want to add new asset types to the schema. We have a schema governance board that helps teams make updates, and we ensure that all of the downstream consumers of the system continue to operate smoothly through the changes. Tying everything together into a unified system makes me incredibly happy. What is the biggest challenge you faced in your career and how did you overcome it? Knowing what you know now, would you do things differently. This was my first job out of college and I came into work with an extremely open mind — possibly too open. I have always taken to heart commentary that could be construed as feedback and leapt to improve myself so I would “be better” the next time. It turns out that this can come across as wishy-washy or insincere. It’s also impractical; one person’s advice might contradict another person’s advice. Now, I strive to take in all feedback and thoroughly consider it before deciding what I want to learn from it. The Times has six core values (Independence, Integrity, Curiosity, Respect, Collaboration and Excellence) by which the company operates. Is there one that you find best describes your work? I try to enable collaboration wherever possible, especially through my work with the ARB. I firmly believe that we are stronger when we work together. The ARB is well-suited to do this, as we work with all Times technology teams. We have a unique vantage point where we can highlight solutions that others have already found, and we can bring disparate groups together that are interested in solving the same outstanding problem. What is a goal you hope to accomplish this year? I’m working on my Masters in Library and Information Science right now, with the help of The Times’s tuition reimbursement program and dedicated 40 hours of learning time per year. It’s not as much of a stretch from library science to computer science as you might imagine. My engineering work encompasses many of the same skill sets as library science, such as indexing and finding information, managing metadata and maintaining the Times digital archive . My biggest goal this year is to connect the dots between the things I’m learning in my classes and the real-world problems we face on the Search team. You have probably noticed that I like to make connections that others may not immediately see; This is a lot more of that same theme! As a software engineer working on a digital product, how do you approach your work with inclusivity in mind? I think that if we’re not a diverse and inclusive place to work, and we don’t take care of each other at work, we have no hope at all of delivering a product that puts inclusivity first. I’m fortunate to have been involved with a grassroots group at The Times called Diversity in Digital since its inception. The group aims to drive change along the lines of recruitment; inclusivity with the aim of improving retention; and advocating for clear career advancement for employees of all backgrounds. Additionally, I have been extremely enthusiastic about the work being done by my colleagues in creating a group focused on people with disabilities and neurodiversities. As someone who struggles with several issues myself, it’s great to find a place to push for greater understanding and acceptance of our differences. What change do you hope to see in your community? I want to see more people who don’t identify as male in back-end development roles. I tend to notice a pretty big difference between the gender ratios in front-end, full-stack and back-end teams. I value all of my coworkers, but I always feel more at home on a team that is not all male. I’m fortunate to have that right now — shout out to Sarah McNeil and Minnie Ko! Do you have any favorite life hacks or work shortcuts? My memory doesn’t always store things away as well as I would like, especially when working on such scattered topics as I encounter in my job. I started using the note-taking Zettelkasten Method about a year ago, and I just recently had to upgrade my note card storage to a filing drawer. The system organizes knowledge in a web structure that is easy to search through, so I can always find what I’m looking for. What or who are you inspired by? Here is where I admit that I’m a huge nerd: my biggest hero is General Leia Organa from Star Wars! She’s diplomatic, courageous and willing to put in the hard work to get things done. I have a little figurine on my desk to remind me to embody these characteristics in everything I do. Fill in the blank: What is the best part of being ______? If you had it your way, what could make it better? What’s the best part of being an avid reader? The book clubs! I love discussing what I read with other people and being exposed to more perspectives. Our employee resource group Times Reads is my favorite place to discover books that I never imagined existed, based on suggestions from my coworkers. What could make it better? I honestly just need more time to read. I used to do a lot of reading on my commute, but I’m not commuting these days. Complete this sentence: Over time, I have realized __________. Over time, I have realized that there is always someone who thinks you can’t do it — whatever “it” is in your specific context. Sometimes, that person is going to be right, but that doesn’t mean you are worth any less as a person. Be kind to yourself. What is your best advice for someone starting to work in your field? Don’t pay a zillion dollars to go to a fancy university for a computer science degree. Go to a bootcamp, a community college, a state school or just watch online videos and teach yourself at home. Coding is for everyone; you don’t have to be a genius. Just pick a project and run with it, asking as many questions as you can dream up! Meeting… Tracy Z. Maleeff, Information Security Analyst at The New York Times Meeting… Charity Garcia, Software Engineer at The New York Times Meeting… Drue Thomas, Senior Product Designer at The New York Times How we design and build digital products at The New York Times 73 Software Engineering Technology Women In Tech Work Nyt Open Meeting 73 claps 73 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-03-26"},
{"website": "NewYork-Times", "title": "meeting véronique brossier lead software engineer at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-véronique-brossier-lead-software-engineer-at-the-new-york-times-52088bb534ac", "abstract": "Code Data Product and Design Workplace Culture Work with Us What are your pronouns? She/Her What is your job title and what does it mean? I am a Lead Software Engineer. I principally work on the iOS newsreader app. My team and I are at the end of a production line of engineers: some build tools for the newsroom to input content, others store it and still others deliver it. Our role is to fetch and present the freshest news in a multitude of structures and displays in a constantly evolving environment. How long have been at the Times? I started working at The New York Times right after Hurricane Sandy about eight years ago. My previous experience was in digital exhibitions for museums and interactive games. Most Times employees are working remotely right now. What does working from home these days look like for you? I usually start my day by listening in on the morning news meeting while having breakfast. I particularly enjoy listening to Elisabeth Bumiller, Washington Bureau Chief, and Ellen Pollock, Business Day Editor, and I see them both as role models. I live near Union Square in Manhattan, so my break from work is to walk through the farmers’ market, check the dog run and get a baguette at Breads (best bread maker in town). I am lucky to live in a large bright apartment but I miss the workspace camaraderie. I am looking forward to going back to the office. Tell us about a project you’ve worked on at The Times that you’re especially proud of. Developing a body of work in a medium that has become prevalent has been rewarding. The most satisfying projects are the ones where I identified a problem and figured out a solution that brought noticeable value. Last year, I developed an interface to help the newsroom streamline the process for sending notifications; I am now finishing a feature that will enhance the reading experience. During Maker Week , my favorite time of year, I created several visual and editorial experiments and tools, some of which were adopted in production. I enjoy building things for people. Working on an app is particularly satisfying because users have a very intimate relationship with their device. I am always surprised by how quickly our readers report issues. Success for me is when the technology works seamlessly without being noticeable. My colleagues and I take a lot of pride in our craft. What is a goal you hope to accomplish this year? I hope to find new challenges to continue growing while contributing to The Times. It is a big place and there are always opportunities to work with new colleagues across teams. A dream project would be to collaborate with the Graphics desk on some of our most creative content and experiment using a native solution for it. Do you have any favorite life hacks or work shortcuts? I have been practicing yoga for several years at a studio and I now do it at home. It is my happy place. I also started sewing shortly before the beginning of the pandemic, learning by watching YouTube videos. I am now making my own clothes. I absolutely love it and am dreaming of traveling where traditional textiles are made. What is your best advice for someone starting to work in your field? Writing software can be both engaging and very tedious. Being curious, and a bit of a perfectionist, will help you embrace this constantly changing field and keep things exciting. Seek out people who strive for excellence. Meet people and ask questions. Be kind. Meeting… Vicki Crosson, Software Engineer at The New York Times Meeting… Tracy Z. Maleeff, Information Security Analyst at The New York Times Meeting… Charity Garcia, Software Engineer at The New York Times How we design and build digital products at The New York Times 17 Nyt Open Meeting Software Development iOS Women In Tech Technology 17 claps 17 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-03-29"},
{"website": "NewYork-Times", "title": "meeting alexandra shaheen program manager at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-alexandra-shaheen-program-manager-at-the-new-york-times-2450946576f6", "abstract": "Code Data Product and Design Workplace Culture Work with Us What are your pronouns? She/Her What is your job title and what does it mean? I am a program manager who works primarily on engineering projects. I love bringing structure and order to messy and hard problems or situations. I will hustle as I need to in order to enable my teammates to perform to the best of their abilities. I hate the term “servant leadership,” but the definition suits this role. How long have you been at The Times? I’ve worked at The Times for two and a half years. Most Times employees are working remotely right now. What does working from home these days look like for you? I moved to Rockaway Beach, NY during the pandemic and I hope to stay here. In my opinion, this is one of the most beautiful places in New York City and the quality of my daily pandemic walks has greatly improved since moving here. There are more animals than people in my household. My colleagues regularly see my cats and dog popping into my meetings. This has been one of the better parts of work-from-home life. Tell us about a project you’ve worked on at The Times that you’re especially proud of. Though I loved my work on election readiness , the rollout of Oak, our custom article editor , to the newsroom was especially rewarding. When I arrived at The Times, a small subset of the newsroom was using Oak in limited capacity. In what now seems like a very short period of time, the Oak team fully built out the application and successfully released it to the greater newsroom. The technical challenges that were undertaken ( such as track changes, collaborative editing, version history ) were some of the most complex of my career. I will always be proud to have worked on this special team. What is the biggest challenge you faced in your career and how did you overcome it? Knowing what you know now, would you do things differently. For some time, I battled with regular bouts of imposter syndrome. Finding my voice and gaining confidence in that voice has not been easy. I have faced gatekeeping, which is not uncommon for women working in technology. Earlier in my career, I was told repeatedly, “you aren’t able to do this work” or “you can’t take on this project,” despite my track record of sound performance. I later learned that the gatekeeping stemmed from office politics happening above me. If I could go back in time, I would have immediately removed myself from that situation. It took some time for me to prove to myself that I was capable of that project and much more. I’m grateful for those who have helped me build my confidence and I’m trying my best to pay it forward. The Times has six core values (Independence, Integrity, Curiosity, Respect, Collaboration and Excellence) by which the company operates. Is there one that you find best describes your work? Collaboration. Program managers infuse collaboration in all that we do. Our job is to reinforce the value of collaboration and ensure our teams work well together. What is a goal you hope to accomplish this year? I would like to learn to surf! I was too busy in the fall to take lessons and don’t have what it takes to embark on this hobby in the current temperatures. I’m looking forward to spring! As a program manager working on a digital product, how do you approach your work with inclusivity in mind? I believe you should approach everything, including your work, with your own reflexive statement in mind: I see the world in a certain way because paradigms, people and places have structured this viewpoint. This shapes my biases, the questions I ask and how I operate. I strive to remember that everyone around me comes from a unique place that I only see a small part of while we work together each day. It’s non-negotiable that our work environment needs to be empathetic and supportive of all people. I (along with my teammates) strive to bring psychological safety, transparency and respect to all that we do. If we’re in a situation where any of this is challenged, we need to talk about it. What change do you hope to see in your community? Since I moved to the Rockaways during the pandemic, I haven’t been able to get involved in my new community as much as I would like. While many service activities have been shelved for now, I’m looking for ways I can safely contribute and meet my new neighbors! Do you have any favorite life hacks or work shortcuts? The basics truly keep me going. I take my own set of notes in every meeting, because writing things down helps me better process information. I also live by and for to-do lists. I have a main to-do list that is maintained digitally. At the start of each day, I look at the list and prioritize what I want to get done. This manageable checklist goes on a Post-it. It feels great to cross things off with a pen. What or who are you inspired by? This has been a tough year for all of us. However, I remain in awe of our New York Times journalists. The combination of an ongoing pandemic and the 2020 election have presented a grueling and relentless news cycle. I have immense respect for their ability to keep going and provide the public with incredible journalism. Helping to serve as stage crew for these efforts has been a great honor. Fill in the blank: What is the best part of being a New Yorker? If you had it your way, what could make it better? The food and dining in New York! We are privileged to have endless options and standards of excellence embedded in our culture. Like many others, I’ve watched restaurants I’ve loved for years close during the pandemic. In reality, it’s been hard to operate a restaurant in NYC for way too long. If I had my way, we would look at the circumstances that have made it so difficult for these small businesses. Complete this sentence: Over time, I have realized __________. It is wise to pick your battles. Some goals are best tackled slowly over time. A wise friend put the phrase “Pack your patience” into my brain and I often repeat it to myself. What is your best advice for someone starting to work in your field? Take the time to listen. Challenge yourself to see problems from different perspectives. Always remind yourself that you have much to learn and are privileged to operate in an environment where continuous learning is possible and celebrated. Meeting… Véronique Brossier, Lead Software Engineer at The New York Times Meeting… Vicki Crosson, Software Engineer at The New York Times Meeting… Tracy Z. Maleeff, Information Security Analyst at The New York Times How we design and build digital products at The New York Times 47 Nyt Open Meeting Project Management Software Engineering Technology Women In Tech 47 claps 47 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-03-30"},
{"website": "NewYork-Times", "title": "meeting vanessa jiménez associate software engineer at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-vanessa-jiménez-associate-software-engineer-at-the-new-york-times-db4fe9488bb9", "abstract": "Code Data Product and Design Workplace Culture Work with Us What are your pronouns? She/ Her What is your job title and what does it mean? Associate Software Engineer How long have you been at The Times? Almost a year and a half now! Most Times employees are working remotely right now. What does working from home these days look like for you? I wake up, make myself a latte and figure out what I’ll have for breakfast. Then, I’ll catch up on some news and emails, get ready for my first meeting and start off my workday. Around 1 p.m. is when I tend to have lunch. Thankfully, I live in a building with an amazing rooftop so I take a nice walk around to get some fresh air and then come back and continue the rest of my day. After work I try to find the willpower to work out or do something productive. Tell us about a project you’ve worked on at The Times that you’re especially proud of. I recently started working on an internal tool that allows us to build and deploy reader segments in a way that preserves reader privacy . I love working on data-based apps that pull together information about readers’ habits. What is the biggest challenge you faced in your career and how did you overcome it? Knowing what you know now, would you do things differently. Career transitioning. I used to be a technology risk consultant who would perform technical audits. I realized it wasn’t what I wanted to do and that I really wanted to build things. I decided to just quit my job and start this new chapter in my life. If there was anything I could go back and change, it would be accepting that I genuinely wanted to be an engineer and follow that career path sooner. The Times has six core values (Independence, Integrity, Curiosity, Respect, Collaboration and Excellence) by which the company operates. Is there one that you find best describes your work? Collaboration! I think we have a really great team and we are always working on trying to share knowledge with each other. Especially now that we are all working remotely, I find that collaboration is key to stay sane at home and to bond as a team. What is a goal you hope to accomplish this year? To get promoted! What change do you hope to see in your community? More diversity. I know imposter syndrome is very much a real thing and it can be discouraging and lonely to be in a field where no one looks like you. You have to work harder just to feel like you belong. Do you have any favorite life hacks or work shortcuts? This is not so much a life hack, but remember to always take breaks! Mental breaks are so important especially now that we’re at home and constantly staring at screens. It’s important to remember that it’s O.K. to take time to recharge. What or who are you inspired by? My parents. To this day I still don’t understand how they have managed to be successful and raise a family with the limited resources and lack of education they had growing up. I always remember this to motivate myself to keep going. Fill in the blank: What is the best part of being a __________? If you had it your way, what could make it better? The best part of being a Latina engineer is being a role model for other women and girls in this field. I wish I had a mentor who looked like me and who I could go to with questions, but the most I can do at this moment is be that person for someone else. If I had it my way, the industry would already be diverse, and equal opportunity and pay wouldn’t be issues. We are not there yet, but I’m hopeful. Complete this sentence: Over time, I have realized __________. Unless I’m on call for something, I’m not saving lives and the work can always wait till tomorrow. What is your best advice for someone starting to work in your field? Remember to still have fun! You have a ton of time to learn and things are always changing, so don’t feel like you have to rush and know it all at once. Remember, it’s all about learning. Meeting… Alexandra Shaheen, Program Manager at The New York Times Meeting… Véronique Brossier, Lead Software Engineer at The New York Times Meeting… Tracy Z. Maleeff, Information Security Analyst at The New York Times How we design and build digital products at The New York Times 52 Nyt Open Meeting Technology Women In Tech Software Development Work 52 claps 52 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-04-14"},
{"website": "NewYork-Times", "title": "meeting christina malis director of customer care at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-christina-malis-director-of-customer-care-at-the-new-york-times-9d3a262e94ed", "abstract": "Code Data Product and Design Workplace Culture Work with Us What are your pronouns? She/Her What is your job title and what does it mean? Director, Customer Care. I serve as product owner for one of Care’s cross-functional scrum teams: the Care Insights and Analytics team. Our work focuses on providing insights to the company based on what we hear directly from our customers, and maintaining efficient operations. I am also a member of the leadership team advising our Vice President of Customer Care on strategic, short-term and long-term planning decisions. Customer Care Operations merged with our Product, Engineering and Design counterparts just over a year ago, and the Care Insights and Analytics team was an experiment to see if we could all work together in the agile product development methodology. We have been very pleased with the success of this experiment, both for our team culture and for our productivity, and we now have two fully operational scrum teams on Care. How long have you been at The Times? Four and a half years. Most Times employees are working remotely right now. What does working from home these days look like for you? I live in an area of lower Westchester, NY called the “Rivertowns” because we are right along the Hudson River — if I walk across the street I can see the Manhattan skyline in the distance. I spend my working hours at a little desk in a corner of my bedroom, facing the river and trying to keep my new rescue dog from hogging all the attention during meetings. Tell us about a project you’ve worked on at The Times that you’re especially proud of. In 2019, I worked with a number of my Care colleagues to completely redesign and replace our Interactive Voice Response system, a.k.a. the robo-voice you hear when you call customer service. Instead of expending a lot of effort to recreate the complex decision trees in our old system, we chose to start the phone experience simply by asking the customer why they are calling and relying on intent recognition to take it from there. Every time I encounter another company’s Interactive Voice Response or when I hear family or friends complain about the long menus they must wade through on a phone call, I’m proud of our decision to reduce that effort up front. What is the biggest challenge you faced in your career and how did you overcome it? Knowing what you know now, would you do things differently. My biggest challenge has been saying “yes” to too many things and being hard on myself if I don’t live up to my own internal standard for excellence. Thanks to a wonderful team (Care folks are great cheerleaders!), I’ve gotten better at prioritizing my own bandwidth, as well as asking for help when I need it — which can also be a great way to give others exposure and opportunities to grow in their own work. The Times has six core values (Independence, Integrity, Curiosity, Respect, Collaboration and Excellence) by which the company operates. Is there one that you find best describes your work? I would say collaboration best describes the nature of my work for the past few years. Through multiple roles and structures on the Care team, I have always sought out opportunities to connect people and develop a shared purpose in tackling our individual goals for the success of The Times. Everyone who works here has a deep passion for the mission of The Times; I am excited to continuously find ways to weave together various teams’ mutual commitment to upholding the mission, standards and products of the company. What is a goal you hope to accomplish this year? Developing connections with more colleagues outside of Care. As I’m sure many can attest, this past year of remote work has removed the ability to bump into folks in the hallways, have ad hoc catch ups in the elevator and other unscheduled socialization opportunities. I’m very proud of the culture we have developed on the Care team, and I feel that we have gotten even closer in this past year. I hope to take this a step further and deepen contact with other amazing people at The Times! As a director working on a digital product, how do you approach your work with inclusivity in mind? I am very proud of and humbled by numerous members of the Care team who keep important topics such as accessibility and DEI (diversity, equity and inclusion) front of mind as we develop new features and services. The team has committed to specific objectives and key results around DEI targets for ourselves and our vendor partners, to ensure we are prioritizing actions and not just conversation. Do you have any favorite life hacks or work shortcuts? I am a chronic multitasker. While my colleagues say I’m good at it, I believe the research that shows it is not effective and that it’s just constant, rapid context switching. I really feel the impact on my mental capacity, especially in a remote environment. One trick that has helped me is keeping my hands busy when I’m listening to a meeting that doesn’t require as much vocal participation. If I have an embroidery needle in my hand or some Play-Doh, I’m much less likely to check email and Slack during a presentation that I would much rather give my full attention to. What or who are you inspired by? At risk of sounding clichéd, my mom. She has had (and continues to maintain) a high-powered career for my entire life, doing the lion’s share as a single parent when I was young and most in need of care. Her tenacity and competitive nature, coupled with boundless warmth and compassion, set the example that I could thrive in my own path without compromising my own ambition — or friendliness. Complete this sentence: Over time, I have realized… That it’s important to be flexible, and not take anything too personally. I like to assume folks are coming to the table with the best of intentions. Even if that isn’t the case, it starts an interaction off with a positive mindset which often carries through to a better outcome. What is your best advice for someone starting to work in your field? Stay curious and speak up! I love working in a customer-driven function. The more we learn about people’s experience with our products and comparable products, the better we can make our offerings. If a question or an idea seems silly, voice it anyway — you’ll never know what it could lead to if it’s never said. Meeting… Carrie Price, Lead Software Engineer at The New York Times Meeting… Alice Liang, Sr. Manager of Data & Insights at The New York Times Meeting… Cindy Taibi, Chief Information Officer at The New York Times How we design and build digital products at The New York Times 125 Nyt Open Meeting Technology Women In Tech Management Customer Experience 125 claps 125 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-03-15"},
{"website": "NewYork-Times", "title": "meeting drue thomas senior product designer at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-drue-thomas-senior-product-designer-at-the-new-york-times-7c2ed6cad016", "abstract": "Code Data Product and Design Workplace Culture Work with Us What are your pronouns? She/Her What is your job title and what does it mean? I’m a Senior Product Designer on a team called Workflow, which supports the editors who publish the Times homepage multiple times a day. Technically, my job is to design the end-to-end experience for a CMS called Curator — along with my design colleagues Orr Shtuhl and Tina Ye — but I prefer to think of myself as a professional listener and complexity mitigator. How long have you been at The Times? Three years this April! Most Times employees are working remotely right now. What does working from home these days look like for you? It changes month-to-month. Because we are able to be fully remote right now, I sold all my stuff in December, bought a car and started a nomad lifestyle. I don’t have an address or a lease — just a car, my dog and a few suitcases. After 10 years in NYC, it’s a huge change! In a lot of ways it’s freeing to have control over where I am in a time where I feel like I have control of so little. If I feel uninspired or restless (or honestly, too cold) I pack up my car and I’m gone. On the flip side, safety is my highest priority so I have to take a lot of precautions — I try to move around slowly and pick places with wide open spaces. Luckily that means spending a lot of time outdoors with my dog and best friend. Right now I have two set ups: I’m either literally working from my bed (I know, I’m terrible) or sitting outside soaking up the sun in Austin, TX. Tell us about a project you’ve worked on at The Times that you’re especially proud of. Working with my product design “squad” to investigate the state of Diversity, Equity and Inclusion in Product Design. We have spent the last six months doing in-depth research across several themes, such as Growth, Retention and Hiring and we recently presented our findings to the rest of the Product Design team. I am so proud to see Product Design committing to being a leader in The Times’s DEI efforts. Also, as a Black woman, it’s amazing to see my own lived experience amplified by the voices of my peers and by leadership. This is just the beginning and I’m so excited to see where this work goes. What is the biggest challenge you faced in your career and how did you overcome it? Knowing what you know now, would you do things differently. Making my first portfolio. I’ll be honest, before working at The Times, my confidence as a designer was absolutely trash . I spent years (yes, years) putting off making a portfolio because I was convinced that I would never meet the expectations of the companies I dreamed about working for. Working at The Times has taught me that the only expectations stopping me were my own. I have to give a shout out to my best friend and colleague, Yuraima Estevez for: 1) putting up with me; and 2) for pushing me to apply to The Times. I can now own that I am an amazing and talented product designer. The Times has six core values (Independence, Integrity, Curiosity, Respect, Collaboration and Excellence) by which the company operates. Is there one that you find best describes your work? Curiosity. In my opinion, being curious is one of the best traits a designer can have. If you aren’t interested in the world around you, you’ll never even begin to understand how to fix it. I’m lucky enough to spend most of my days in curiosity mode: thinking, sketching, asking questions, filling in blanks and attempting to untangle gnarly user experiences challenges. I love it. What is a goal you hope to accomplish this year? Do at least one pistol squat. As a Designer working on a digital product, how do you approach your work with inclusivity in mind? I keep universal design principles at the forefront of my design practice. Universal design principles is an approach that aims to make design as inclusive as possible with features that enhance access for everyone regardless of age, size, ability or disability. In my own practice, this looks like designing simple and intuitive internal tools that have a high tolerance for error and keep accessibility at the forefront. What change do you hope to see in your community? To be frank, I’d like to see more racial diversity in design, especially at The New York Times. Do you have any favorite life hacks or work shortcuts? If you’re feeling overwhelmed by meetings and feel like you have no time to work, download a smart assistant extension or app for your calendar. I use a smart assistant to do things like reschedule meetings so I get much-needed breaks and optimize for “focus blocks” of time that are at least two hours. Genius! What or who are you inspired by? I draw a lot of inspiration from my design peers, colleagues and friends. But I think I have learned the most from just talking to people who have taught me how they communicate; what they care about; and what brings them pain and pleasure. Over time I have accumulated stories that amount to a library of patterns and behaviors that I can draw upon in my everyday design practice. Fill in the blank: What is the best part of being ______? If you had it your way, what could make it better? What is the best part of being in Austin? Tacos and family. What could make it better? If I could somehow be both in Austin and in New York City pre-pandemic at the same time (minus alternate-side parking). Complete this sentence: Over time, I have realized __________. Progress is better than perfection. What is your best advice for someone starting to work in your field? Don’t be so hard on yourself. Everyone has to start somewhere, so don’t be afraid to work out in the open. Meeting… Christina Malis, Director of Customer Care at The New York Times Meeting… Carrie Price, Lead Software Engineer at The New York Times Meeting… Alice Liang, Sr. Manager of Data & Insights at The New York Times Meeting… Cindy Taibi, Chief Information Officer at The New York Times How we design and build digital products at The New York Times 123 Nyt Open Meeting Product Design Design Design Thinking Women In Tech 123 claps 123 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-03-17"},
{"website": "NewYork-Times", "title": "meeting sarah duncan lead data engineer at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-sarah-duncan-lead-data-engineer-at-the-new-york-times-6e2c43348aeb", "abstract": "Code Data Product and Design Workplace Culture Work with Us What are your pronouns? She/Her What is your job title and what does it mean? Lead Data Engineer. A data engineer is a software engineer who specializes in data-intensive applications. How long have you been at The Times? A little over two years. Most Times employees are working remotely right now. What does working from home these days look like for you? I live with my boyfriend, Kenny, and our cat, Tugboat, in an apartment in Brooklyn. I have my desk in the living room and Kenny has his in the bedroom. Once we sign off for the day, we have fun in the kitchen trying out new recipes! Tell us about a project you’ve worked on at The Times that you’re especially proud of. For the past year and a half, I have been working on a data pipeline framework called Octopus that was initially built to support pulling data from third-party sources. Recently, I participated in an ETL working group in The Times’s Data Platforms team to help define a strategy for our ETL/data pipeline tools. As a result, I’m now on a new team called Data Pipelines Infrastructure that is accountable for defining and maintaining best practices for data pipelines and supporting a centralized, extensible tool that implements those best practices. What is the biggest challenge you faced in your career and how did you overcome it? Knowing what you know now, would you do things differently? People have regularly underestimated me, which often pushed me to work even harder. Knowing what I know now, I would have kept that drive but stopped trying to impress people earlier in my career. The Times has six core values (Independence, Integrity, Curiosity, Respect, Collaboration and Excellence) by which the company operates. Is there one that you find best describes your work? Collaboration best describes my work. The work on my teams, on The Times’s Architectural Review Board or in our Communities of Practice have all focused on collaborating with colleagues to come up with innovative solutions within Times engineering and data. What is a goal you hope to accomplish this year? I hope to learn more about the data pipeline needs that exist outside of my immediate circles and collaborate with my colleagues on ways to solve them. As a Lead Data Engineer working on a digital product, how do you approach your work with inclusivity in mind? I purposefully make space for anyone to ask a question or share an idea, regardless of things like title or role. I would much rather have a pause in a meeting so others can contribute to the conversation than take up more space than I need to. What change do you hope to see in your community? I hope to see fewer unnecessary barriers put up. What or who are you inspired by? My colleagues inspire me regularly. Aside from the incredible mentors I have found here, I’m inspired by the people I work with every day who put so much effort and talent into The Times’s mission. Fill in the blank: What is the best part of being a data engineer? If you had it your way, what could make it better? Helping other people do their jobs more easily by doing something I love. It gets better the more others teach me what they need so I can improve our data tools. Complete this sentence: Over time, I have realized __________. Everyone has something to learn and something to teach. What is your best advice for someone starting to work in your field? You deserve to be in this field as much as anyone. Just keep pursuing what you enjoy and want to get better at. Meeting… Drue Thomas, Senior Product Designer at The New York Times Meeting… Christina Malis, Director of Customer Care at The New York Times Meeting… Alice Liang, Sr. Manager of Data & Insights at The New York Times How we design and build digital products at The New York Times 109 Nyt Open Meeting Data Engineering Engineering Technology Women In Tech 109 claps 109 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-03-19"},
{"website": "NewYork-Times", "title": "meeting charity garcia software engineer at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-charity-garcia-software-engineer-at-the-new-york-times-a7f6defa0bde", "abstract": "Code Data Product and Design Workplace Culture Work with Us What are your pronouns? She/Her What is your job title and what does it mean? I’m a Software Engineer on NYT Cooking’s engineering team. That means, I get to torture myself every day by looking at amazing recipes and enticing pictures while building and maintaining features on our web application. How long have you been at The Times? I have been at The Times for almost three years. Wow, time really flies by! Most Times employees are working remotely right now. What does working from home these days look like for you? Working remotely has pretty much been the same for me since I was remote pre-pandemic. However, at the beginning of the pandemic, it was tough balancing working full-time and being a full-time teacher to my 8-year-old son. Luckily, The Times now has extremely helpful programs for employees that assists parents with child care and tutoring fees. Tell us about a project you’ve worked on at The Times that you’re especially proud of? Our team had upgraded all of our dependencies, but when we tried to upgrade the CSS-Loader for Webpack, all of the images that were served from the client-side would break on our website. The issue was bigger than just changing a few paths, and there was little documentation on how to upgrade from Webpack 2 to Webpack 4. Online searches returned some solutions, but nothing that fit NYT Cooking’s unique needs;I developed a fix by piecing together a few solutions that worked for others. While working on the Webpack upgrade, I saw that it would be better if the images served from the client side were imported from only one file. Migrating the images to a single file would enable us to easily fix any image path issues we ran into in the future. I decided to incorporate a major image refactor that not only fixed the Webpack issue, but also addressed some tech debt that we had. It was one of the toughest projects I have had in my career so far, but one of the most rewarding. What is the biggest challenge you faced in your career and how did you overcome it? Knowing what you know now, would you do things differently. The biggest challenge I’ve faced in my career was still recovering from a traumatic brain injury while being a full-time software engineer . Feeling like I needed to catch up to my colleagues by reading and working on outside projects after work or making sure every pull request and commit was as close to perfection as it could be was very taxing. Imposter syndrome was strong, but as I spoke with other colleagues and saw they had the same thoughts and fears that I had made me feel more confident in my abilities. Learning as much as I could outside of work was very helpful to overcoming my traumatic brain injury and imposter syndrome. But, if I could do it differently, I would not have put so much pressure on myself. No one is perfect. The Times has six core values (Independence, Integrity, Curiosity, Respect, Collaboration and Excellence) by which the company operates. Is there one that you find best describes your work? Integrity — that’s my approach in life, in general. In my work as a software engineer, shipping clean code by the deadline is extremely important to me. In tech, there are many circumstances that can affect when a project is shipped, but I try to minimize that as much as possible. In my work as the founder and leader of The Times’s employee group, Black and Latinx in Technology, integrity is key in making real progress for our communities in and outside of The New York Times. What is a goal you hope to accomplish this year? Personally, I want to be able to complete a half-marathon this year. It’s a very ambitious goal since I have been pretty inactive since the beginning of the pandemic. Pray for me! Professionally, working on increasing my technical depth is my priority. I love to learn, not only for the advancement of my career, but to be in a position where I can help others advance in their careers as well. As a software engineer working on a digital product, how do you approach your work with inclusivity in mind? Our team has made strides in addressing accessibility improvements where we can and continue to make it a priority. What change do you hope to see in your community? I identify as Black and Latinx. Our communities can only do so much to make a real change in this country. We do a lot within and for our community but I would hope to see other communities practice more equity, empathy and openness towards our communities. Action speaks louder than words. Do you have any favorite life hacks or work shortcuts? Learn Linux and Git command lines. With Git, create shortcuts with Git bash aliases because it will save a lot of time in the long run. What or who are you inspired by? People who have been counted out every step of the way but still succeed time and time again are who inspire me. Fill in the blank: What is the best part of being ______? If you had it your way, what could make it better? What’s the best part of being Me? I am who I am, unapologetically. As a child, I was very shy and never spoke my mind or stood up for myself. As I have grown and experienced life, I have learned to love myself first, speak up, stand strong in my beliefs, and fight for the people and things I care about. Complete this sentence: Over time, I have realized __________. That burnout is real and self-care should be one of your main priorities. What is your best advice for someone starting to work in your field? Do not get discouraged. There are people who will root for you and people who won’t, but what they cannot take from you is your knowledge, experience and passion. If you do what you love, keep working hard at it and you will succeed. Meeting… Sarah Duncan, Lead Data Engineer at The New York Times Meeting… Drue Thomas, Senior Product Designer at The New York Times Meeting… Christina Malis, Director of Customer Care at The New York Times How we design and build digital products at The New York Times 101 Nyt Open Meeting Software Engineering Technology Women In Tech Work 101 claps 101 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-03-22"},
{"website": "NewYork-Times", "title": "meeting tracy z maleeff information security analyst at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-tracy-z-maleeff-information-security-analyst-at-the-new-york-times-b7a5f40e7772", "abstract": "Code Data Product and Design Workplace Culture Work with Us What are your pronouns? She/Her What is your job title and what does it mean? Information Security Analyst. I am a member of the cybersecurity defense team. How long have you been at The Times? About one and a half years. Most Times employees are working remotely right now. What does working from home these days look like for you? I was hired as a remote employee, so the only thing that is different is that my co-workers are remote as well. But, I do miss visiting the office on occasion! Tell us about a project you’ve worked on at The Times that you’re especially proud of. It would be bad “OpSec” (Operational Security) for me to disclose any specifics. However, I can generally say that I’m proud to have worked on projects that protect our human assets. What is the biggest challenge you faced in your career and how did you overcome it? Knowing what you know now, would you do things differently. Prior to working in Information Security, I was a librarian. When I decided that it was time for a career change about five years ago, I looked to tech and eventually realized that my natural paranoia and distrust of things made me suitable for a career in cybersecurity. (That’s a joke… sort of.) The biggest challenge was the learning curve going from Library Science to Computer Science. Learning about computer networks and security threats required me to use a different part of my brain. I had to learn new skills and learn the ways of a completely different industry. I studied very hard every chance I got and I don’t think I would have changed a thing. The Times has six core values (Independence, Integrity, Curiosity, Respect, Collaboration and Excellence) by which the company operates. Is there one that you find best describes your work? A lot of the work as an information security analyst revolves around troubleshooting problems. Therefore, curiosity best describes my work. You can’t take things at face value and need to ask questions — the right questions — in order to solve the problem. You need curiosity to wonder what’s not being said or what’s not being seen, in addition to what has been said or is obvious. Curiosity to go beyond the surface is essential to proper problem remediation. What is a goal you hope to accomplish this year? A professional goal of mine for 2021 is to pass the Certified Information Systems Security Professional (or, CISSP) exam. The CISSP is an independent information security certification granted by the International Information System Security Certification Consortium, also known as (ISC)². A personal goal of mine for 2021 is to create a non-profit for cybersecurity students and professionals in Africa. In my free time, I volunteer with a few different groups to help build their skills, help with professional networking, promote their work and assist however I can with getting more people in Africa into cybersecurity careers. As an Information Security Analyst working on a digital product, how do you approach your work with inclusivity in mind? Just recently, I started to type the word whitelist in context to something work-related. I stopped myself and thought, “I know there is a better word for this, but it escapes me.” So, I took a second to look it up and revised what I was writing to say allowlist instead . Words matter, even in tech. What change do you hope to see in your community? I dedicate a lot of my free time to helping people from underrepresented groups start information security careers. My professional community has been homogenous for too long, and my goal is to help make it more diverse. Diversity of thought solves problems, so it’s crucial for the industry to have people with different perspectives and experiences be security practitioners. Do you have any favorite life hacks or work shortcuts? My favorite work hack is being an observer on the Times morning news meeting! Not only is it great to connect faces and voices with names, but also to know what we are working on for publication helps the security team be aware of things that could impact the enterprise. As a news geek, it’s very exciting and it just makes me really proud to be a part of this organization. What or who are you inspired by? I’m inspired by people who have overcome adversity, in whatever form. I’m inspired by immigrant success stories. I’m inspired by brave LGTBQ+ folks who are living their lives in the face of hate. I’m inspired by the Black cybersecurity community who are boldly shaping their futures by not accepting the status quo in the industry. I’m inspired by anyone who, as Maxine Waters famously said, are “reclaiming my time.” Fill in the blank: What is the best part of being ______? If you had it your way, what could make it better? What’s the best part of being a Philadelphia-area native? Gritty. Churry Wooder Ice. Hoagies and Cheesesteaks. (It’s a tie.) If I had my way, Philadelphia would have more social and financial equity for its residents. Better support and services so that the residents don’t struggle as much as they do. (Also, more sports championships.) Complete this sentence: Over time, I have realized __________. It’s never too late to start something new. Whether it’s a college degree, a career change or something else. I was a non-traditional student for all three of my college degree programs. I made what looked like a strange career pivot from a librarian to a cybersecurity professional at an age when most of my peers were firmly embedded in their professional lives. I used to agonize over what I perceived as being behind everyone. It’s not that I’m behind; I’m on my own path. What is your best advice for someone starting to work in your field? Network with people, early and often. There is immense value in connecting with people to learn from them, to help them and to have them help you. I strongly believe that human networking is a huge factor in professional development and success. Meeting… Charity Garcia, Software Engineer at The New York Times Meeting… Drue Thomas, Senior Product Designer at The New York Times Meeting… Christina Malis, Director of Customer Care at The New York Times How we design and build digital products at The New York Times 11 Nyt Open Meeting Infosec Information Security Technology Women In Tech 11 claps 11 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-03-24"},
{"website": "NewYork-Times", "title": "meeting corina aoi technical product manager at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-corina-aoi-technical-product-manager-at-the-new-york-times-bd0aaf258c95", "abstract": "Code Data Product and Design Workplace Culture Work with Us What is your name? Corina Aoi (pronounced Ah-wee) What are your pronouns? She/Her What is your job? I am a technical product manager. What does that mean? I support platforms as a product, in particular the platforms that power The Times’s native and web apps. My focus is to provide teams and engineers with the tools, standards and systems that enable them to develop easily, work quickly, ship with quality and measure the impact of what they have built for readers. How long have you been at The Times? Five years. I started as an engineer then transitioned to product in 2018. Most Times employees are working remotely right now. Where are you working from these days? From laid-back and always sunny Southern California with my husband, my daughter and our dog, Jellybean. How do you start your day? Because of the time difference in relation to New York, I get up before everyone else in the house is awake and the first thing I do is take our dog out for a walk. As a parent working during the pandemic, it is rare to have a moment to myself. These walks really help to clear my head so I can start the day feeling relaxed. What is something you’ve worked on recently? I recently worked on decommissioning some legacy software that was used by a bunch of products and systems. It took a lot of technical detective work to identify dependent products, and I collaborated with many stakeholders and teams to strategize a plan to migrate these products off of the system. While decommissioning the software, we also had to ensure that the security of the dependent products and systems wasn’t compromised ahead of the 2020 U.S. Elections (no pressure!). In a large organization with so many systems, removing even just one system can be complicated. But this was an important project that taught me a lot about cross-team communication, the value of project management skills for a product manager and how the process of decommissioning as a practice has a lot of room for improvement. Tell us about a project you’ve worked on at The Times that you’re especially proud of. I am most proud of a web accessibility sprint we did last year. It was a large project where my team partnered with 11 other teams across the organization to resolve as many issues as possible in a 90-day sprint. There is still so much work to do in this space, but I am proud that we were able to improve the experience for our readers — especially those using assistive technologies — in such a quick time frame. What was your first job? Fresh out of college, I worked as a game developer for Mattel, Inc., the toy company. In particular, I developed games for Barbie.com back when Flash ActionScript was the new rage. Most games amounted to interactive drag and drop where kids could decorate Barbie’s cake skirt or something like that. However, I am very proud that I engineered an underwater adventure game where I used randomized Bezier curves to create bubbles that floated up at varying speeds and had to be popped in order to save Barbie’s little sea creature friends that were trapped inside. What is something most people don’t know about you? Most people are surprised to hear that I am a classically trained dancer who went to a performing arts high school. I danced professionally in commercials, film, television and entertainment while I majored in Computer Science in college and I was able to continue dancing throughout my early years as an entry-level web developer. In fact, coding was the ideal day job for a professional dancer like me because I had a lot of flexibility as long as I got my work done. It beat working at a restaurant and it paid better, too! This went on for a decade until a major injury set me back and I began to focus more on my career in tech. I was lucky to have a job in tech to fall back on! What is your secret to career success? Be adaptable. Not just in your career, but in life. I’ve moved so much in my adult life that I’ve learned if you are open to new situations and experiences, opportunities will follow. What is your superpower? Hmm, I don’t know. I guess it would be adaptability. Is that a superpower? [editor’s note: yes, it is.] The ability to adapt comes naturally to me and it has served me well in life. My friends used to say that I was a bit of a chameleon because I seemed to comfortably settle into whatever new environment I found myself in. What are you inspired by? Nature, 100 percent. Being out in nature reminds me of how insignificant all my worries are in the grand scheme of the planet and it inspires me to think bigger than myself. Name one thing you’re excited about right now. Watching my daughter grow. I don’t think there can be anything more humbling (and terrifying, while simultaneously rewarding) than raising a human in this world. She is far better and smarter than I could ever be, and her presence in my life makes me a better person every single day. What is your best advice for someone starting to work in your field? Ask a lot of questions early on and don’t worry about how you sound to others. There will always be people in the room who want to ask the same questions but don’t have the courage. Have courage for them and everyone will benefit. Meeting… Jessie Wu, Software Engineer at The New York Times Meeting… Steven Nedlin, Data Engineering Director at The New York Times Meeting… Ashka Gami, Marketing Director for New York Times Games How we design and build digital products at The New York Times 78 Nyt Open Meeting Product Management Technolog Code Women In Tech 78 claps 78 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-01-21"},
{"website": "NewYork-Times", "title": "meeting jessie wu software engineer at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-jessie-wu-software-engineer-at-the-new-york-times-f31264d400bb", "abstract": "Code Data Product and Design Workplace Culture Work with Us What is your name? Jessie Wu What are your pronouns? She/Her What is your job? I’m a full-stack engineer with a focus in UX engineering for the Care Platforms team. What does that mean? The Care Platforms team works on the customer relationship management, or CRM, software that our call center agents use for customer accounts, as well as the interactive voice response system behind 1–800-NYTIMES. As a full-stack engineer, I focus on converting designs to code, building out our design system, optimizing the workflows between design, dev and business, and I advocate for our users. How long have you been at The Times? A little over a year. Most Times employees are working remotely right now. Where are you working from these days? Crown Heights, Brooklyn, a neighborhood where people still say hi to each other in passing. How do you start your day? I start with a heavy breakfast and a quick meditation to mentally prepare for the day. What is something you’ve worked on recently? The Care team just started a diversity, equity and inclusion working group to complement the DEI efforts being done by the wider Times company. and I am working on strategies for hiring and sourcing opportunities to diversify our pipeline and career management within our team. It is at a very grassroots level and I am grateful we have the support from our team leads. Tell us about a project you’ve worked on at The Times that you’re especially proud of. My team and I received a Publisher’s Award last year for building the automated phone system for 1–800-NYTIMES. I learned how to build chatbots with Amazon Web Services, and I will never look at bots, voice-activated smart devices or calling customer service the same way again. What was your first job? I was 10 when I started working at my parents’ restaurant. I went from packing to-gos to running the restaurant over the span of 16 years. In 2018, I was able to take a two-week vacation; it was the first one I’d taken since I was a kid. What is something most people don’t know about you? I took wheelchair dancing classes when I worked with people with disabilities. I used to take multiple trips driving this large cargo van to transport everyone to the studio where we would learn how to dance salsa and ballroom.We learned how to take the lead and maneuver around our dancing partners in wheelchairs. I was not very good at it; I was much better at driving the cargo van. What is your secret to career success? Invest in yourself: take advantage of education stipends, take initiative for career development and take care of your mental well-being. Invest in your team because when your colleagues succeed, so do you. Bring the best out of everyone and see their potential. When you treat people with respect you open up opportunities and referrals down the line. My favorite quote by Maya Angelou is, “I’ve learned that people will forget what you said, people will forget what you did, but people will never forget how you made them feel.” What is your superpower? I am very fast at making Slack emojis and gifs of my team members. What are you inspired by? There have been a few conference talks that changed my perspective and shaped who I am today. Anjuan’s Lending Privilege made me realize being privileged doesn’t necessarily have to be a bad thing; use your privilege to lift others up with you. The other one is bdougie’s Swift vs. React Native talk where he compared the two languages to Taylor Swift and Kanye West. Since then, I tend to gravitate towards using analogies and gifs in my presentations. Name one thing you’re excited about right now. I am really into the Buy Nothing movement and similar local Facebook groups where people in your neighborhood give or lend each other things for free. Someone gave me their 100-percent silk Chinese comforter that reminded me of my childhood. I’ve seen posts looking for things like loft beds and people have actually replied saying they have one that they are happy to give away! Someone even lent me their steam mop. What is your best advice for someone starting to work in your field? Learn how to ask for help efficiently: explain the task you’re trying to accomplish, the steps you took, what you think the possible solutions are and where you are stuck. By looking into possible approaches, you’re doing half of the work for the other person. Also, when it comes to debugging CSS for layouts and styling in general, it helps to add background colors or borders around elements to better understand their relationship to each other. Meeting… Steven Nedlin, Data Engineering Director at The New York Times Meeting… Ashka Gami, Marketing Director for New York Times Games Meeting… Kendell Timmers, VP Ad and Growth Data at The New York Times How we design and build digital products at The New York Times 148 Nyt Open Meeting Code CRM Software Development Women In Tech 148 claps 148 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-01-07"},
{"website": "NewYork-Times", "title": "meeting steven nedlin data engineering director at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-steven-nedlin-data-engineering-director-at-the-new-york-times-1a66ee05bca4", "abstract": "Code Data Product and Design Workplace Culture Work with Us What is your name? Steven Nedlin What are your pronouns? He/Him What is your job? I’m an engineering director in Data Engineering, and the engineering lead of the Transformation and Records group in the Data Platforms mission. What does that mean? I manage the data engineers and database administrators who build and support several critical databases, data systems, data APIs and data engineering tools at The Times. I have managed the Database Reliability team for my entire Times tenure. How long have you been at The Times? This August marked my 10th year at The Times. A decade! I’m so proud of this milestone! Most Times employees are working remotely right now. Where are you working from these days? I’m working from my summer-now-turned-semi-permanent home with my husband, Patrick, and our dog, Tory, on the Jersey shore in Asbury Park. How do you start your day? Every day starts with a nice walk with Tory. I put in my AirPods and usually listen to news programming like “The Daily,” but lately I’ve been listening to Italian pop songs and mouthing the lyrics as I walk. People must think I am crazy! What is something you’ve worked on recently? Earlier this year after we all started working from home, I was chosen to be part of the Digital Operations Sounding Board, a group created to find ways to support Times employees as they work from home during the pandemic. It gave me the opportunity to offer a suggestion that the company sponsor a single day where there are no meetings so everyone can focus on work of their choosing. The very next week, we announced “No-Meeting Fridays” at the end of every month. Tell us about a project you’ve worked on at The Times that you’re especially proud of. I’m incredibly proud to have been a part of the first cohort of the Times Sponsorship program in 2018. It allowed me to connect with senior leaders in all corners of the company; I learned so much about myself and how much I value empathy and inclusiveness in our company’s culture. I went on to champion these values along with a group of other like-minded peers to create the Communication and Conduct Guide for Technology in 2019. What was your first job? My first job was as a copy editor for baseball cards for the Topps Company. They took a chance on a young writer who happened to know nothing about sports (and still doesn’t), but loved English and grammar. They quickly realized I had no talent in sports and gave me an opportunity to work on their e-commerce team to test quality assurance for their new website and it started my entire career in technology. What is something most people don’t know about you? I am a major Tori Amos fan! (Yes, my dog is named after her.) I have seen her play live at hundreds of concerts and when she tours, I like to travel to different cities to see her play. It is one thing I’m very much looking forward to once the pandemic ends. What is your secret to career success? My secret to career success is three-fold: always bring your authentic self to what you do (and tell that inner saboteur to stay quiet and let you be you); stay honest with yourself and with others; be prepared to put in some hard work and you’ll reap the rewards. What is your superpower? I am an autodidact. I’ve taught myself many things in life, including engineering and database administration. I’ve learned several foreign languages on my own, including most recently Italian (listening to songs in a foreign language is one of the best ways to learn language nuances!). But I’m most proud of teaching myself to play piano — I channeled all of my Tori Amos fandom into learning the craft of pop-piano performance. I play pop music, lots of Broadway and even some Chopin! What are you inspired by? I learned an important lesson this year in an unexpected way. In May, during the height of the pandemic, I had to travel to Florida to take care of my father who unfortunately passed away from lung cancer by the month’s end. During his home care, I assisted his hospice nurse with all of her duties, many of which required two people. In this work we bonded, perhaps a bit reluctantly, knowing full well that we would be connected for only a short time. She likely has met hundreds of families in her career and has seen it all at the end of life. But with her help, I learned that it’s not useful to fear what’s to come, and if we focus our energy instead on caring for one another, we can get through even the toughest of times. I am inspired by those who show kindness and care deeply for one another in so many different ways. This made me realize that in this difficult year we may be the most distant from one other, in truth we are all actually as close as ever. Name one thing you’re excited about right now. I’m excited for 2020 to be over! Seriously, how can one year be so challenging!? I often remind myself that it’s through these tough times that we become better people. Life may seem off the rails, but we will emerge stronger for having lived through it. What is your best advice for someone starting to work in your field? Be kind to yourself, and stay honest with yourself and others. Everyone has their own journey; All you need to do is be open to it and it will take you where you need to go. Meeting… Shay Culpepper, Software Engineer at The New York Times Meeting… Ashka Gami, Marketing Director for New York Times Games Meeting… Kendell Timmers, VP Ad and Growth Data at The New York Times How we design and build digital products at The New York Times 77 1 Nyt Open Meeting Data Data Engineering Engineering Tech 77 claps 77 1 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-12-16"},
{"website": "NewYork-Times", "title": "to serve better ads we built our own data program", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/to-serve-better-ads-we-built-our-own-data-program-c5e039bf247b", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Pranay Prabhat When you browse the internet, the majority of the ads that you see are served by one or more ad technology providers that traffic in behavioral and demographic data collected from users. These third-party vendors, as they are often called, use that data to inform which ads are shown to specific audiences. There are two types of ads that appear on the web: programmatic ads and direct-sold ads. For the direct-sold ads business, publishers almost always rely on a Data Management Platform, or DMP, to support audience targeting. DMPs typically use third-party cookies in the user’s browser to be able to match what they already know about a user and then help their publishers build further on that data by ingesting behavioral events as users browse their site or mobile apps. Over the past couple of years, there has been a shift away from relying on third party data because of the risk to user privacy. Legislation like G.D.P.R. in Europe and the C.C.P.A in California have begun to shape how websites handle user data, including to what extent ad-tech software can use third-party cookies. Similarly, the recent move by popular browsers like Safari, Firefox and Chrome to block the use of third-party cookies has pushed the advertising industry to find alternatives that can serve relevant ads while also respecting user privacy. In June of 2020, The New York Times launched an advertising data program for our direct-sold ads business that uses our own data and data science techniques. This first-party program is our answer to the shifting landscape of online advertising data and part of our move to better protect our readers’ privacy . Our program doesn’t rely on third-party data or cookies, but instead focuses only on what readers do on our site and mobile apps. While DMPs are capable of providing additional solutions that work without third-party cookies, The Times opted to build an in-house solution so we could control our data and audience targeting, and be flexible as requirements change. The entire functionality was handled via three streams of work that were closely connected. Over the past several years, The Times has built an analytics system to capture millions of behavioral events across our website and mobile apps. Since we use Google Cloud Platform as a cloud services provider, we picked Google Cloud Dataflow to stream these events in near real-time into Google BigQuery. All the events data is then batch processed and fed into multiple machine-learning models that were built by Times data scientists specifically for this advertising program. The machine-learning models are primarily based on detailed survey responses from our readers. Tens of thousands of readers volunteered to participate in the survey with the explicit messaging that the information gathered would be used to improve advertising at The Times. Our data science colleagues were able to use the survey data, along with our digital engagement event data, to train models that accurately predict the segment a user falls into. Each segment called for different supervised learning approaches (including regression, ranking, classification and multiclass classification) to make sure we have results which are statistically predictive as well as interpretable. The output of these machine-learning models are pushed into a set of BigQuery tables that are orchestrated using Airflow. In order to build a more comprehensive user portfolio, the Airflow orchestration also includes many other behavioral data points in addition to our machine-learning models. Millions of rows in these BigQuery tables are then pushed into our activation system using a suite of technologies from Google. Our activation systems are highly scalable Go microservices that rely on Google Cloud Memorystore to cache all of the user data we collect. Whenever a user visits a Times page on the web or in one of our mobile apps, a call is made to these microservices and ad targeting data is pushed into the page with an average latency of less than 100ms. Once the user data is on the page, a JavaScript ads framework reads and passes this data into the ad server. The ad server finds the most relevant ad campaign and serves it back when the targeting criteria of the campaign matches the data passed from the page. Because the processing and data activation happens on the server side, we were easily able to scale to all browsers, including Safari and Firefox, and to our mobile apps. Server-side processing is especially important to keep our front-end web and mobile apps lighter and faster. Since we launched our program in June, our observation is that ad campaigns targeted on the first-party data perform equally well as campaigns targeted on third-party data. We’ve been able to target on all platforms and browsers, regardless of their current state of cookies and tracking, which provides us additional scale. Because we exclusively control the data, we are better able to protect our readers’ privacy while they navigate our site and apps. This leads us to believe that first-party data is a proven alternative for audience targeting. The primary focus of this program has been our direct-sold ads business. Programmatic ads are an important part of our ads business, and we hope to make improvements as a separate stream of work with a focus on experimenting and testing different solutions being proposed in the AdTech industry which could replace third party cookies. To help shape the conversation around new standards for programmatic advertising in the coming years, we joined the Improving Web Advertising Business Group run by W3C. We will keep investing in how to expand this program by making user data processing more real-time, improve the machine-learning models and find ways to further enrich our contextual and audience data while keeping user privacy as the highest priority. Pranay Prabhat is a Senior Director overseeing Digital Ads Engineering at The New York Times. He is an AdTech enthusiast and a burgeoning guitar player. How we design and build digital products at The New York Times 208 1 Adtech Advertising Tech Code Data 208 claps 208 1 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-12-17"},
{"website": "NewYork-Times", "title": "a year in illustration", "author": ["Jason Fujikuni"], "link": "https://open.nytimes.com/a-year-in-illustration-d23ed37f1831", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Jason Fujikuni As the art director for NYT Open, I have the privilege of working with artists and designers from all over the world to illustrate for The New York Times. Every piece that is published on Open is led by a unique illustration that is commissioned specifically for that article — and sometimes our articles have a closing illustration , too. At The New York Times, we use illustration to add layers of humanity and emotion, and to convey ideas that build upon our articles through visual metaphor, narrative storytelling and thoughtful design. At Open, our approach to illustration is conceptual. Before I assign an illustration, I talk with Sarah Bures, Open’s editor, about the ideas behind the article; I then think about ways to complement those ideas with the unique voice of an outside artist. When we’re ready to assign an illustration, I look for not just a technical hand to illustrate our ideas, but a conceptual partner who can bring their own perspective to the piece. I like to hire artists who have never worked with The Times because they bring diverse visual approaches and voices to the column. This year as we adapted to the new normal of working from home , we published 38 articles, including a new interview series called “ Meeting… ,” which is illustrated by Claire Merchlinsky and features Times colleagues from different parts of the company. Reflecting on a year like no other, we chose five memorable pieces to highlight from 2020. In our first visually driven piece on Open, Agnes describes her process and findings illustrating the weekly “Metropolitan Diary” column — applying her characteristic grease pencil and charm that bring the column to life. Annie captures the hustle-bustle of both our internal teams working on “The Morning” (from home) and subscribers reading the newsletter in their morning routine in this dynamic, visual orchestra. Archival imagery becomes modern in the bold compositions made by Suzie using photographs from The New York Times archive. Wren’s piece expresses the prolonged sense of anticipation and anxiety as readers around the world tuned in to the United states presidential election results this year. The simplicity of Braulio’s typographic solution captures the move away from problematic language into an inclusive world of new possibilities. Jason Fujikuni is an art director at The New York Times. How we design and build digital products at The New York Times 135 Illustration Design Visual Design Storytelling 135 claps 135 Written by Digi AD + Brand ID @nytimes How we design and build digital products at The New York Times. Written by Digi AD + Brand ID @nytimes How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-12-21"},
{"website": "NewYork-Times", "title": "meeting ashka gami marketing director for new york times games", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-ashka-gami-marketing-director-for-new-york-times-games-c883d668dd6b", "abstract": "Code Data Product and Design Workplace Culture Work with Us “Meeting…” is an ongoing series from NYT Open that features New York Times employees from different corners of the company. What is your name? Ashka Gami What are your pronouns? She/Her What is your job? I am the marketing director for New York Times Games. What does that mean? I focus on elevating the value of game play to drive subscription growth for our business. I work cross-functionally to help shape our brand identity and voice, and I build out strategic (and delightful!) programs that support all stages of the user journey and lifecycle. How long have you been at The Times? About a year and a half. Most Times employees are working remotely right now. Where are you working from these days? I have been working from a corner of my living room in Astoria, Queens. I will occasionally switch it up and work from my “standing desk” in the kitchen (it’s really just a high bar table with cookbooks stacked on top). How do you start your day? I don’t wake up as early as I did before the pandemic, but I try to wake up around 7:30 a.m. (after hitting the snooze button a few times). I usually check email, Slack and my calendar in order to mentally prepare for the day ahead, but I generally aim to use my “commute” time thoughtfully. Sometimes I’ll go for a run outside or do a short workout at home, then I’ll make tea and breakfast, breathe deeply and head into all of the video meetings. What is something you’ve worked on recently? I’ve been building a gallery wall in my living room! It’s a great quarantine activity that spurs both nostalgia and wanderlust. Tell us about a project you’ve worked on at The Times that you’re especially proud of. In May, I worked alongside a large, cross-functional team to launch a new subscription landing page for Games . This was a massive undertaking that ran concurrently with a lot of other initiatives to bring our new brand to life. In addition to reflecting a new brand identity and showcasing our full games suite, the landing page displays game-specific branding based on what a user has played before. This allows us to be flexible and experimental with our marketing approach: we can lean into the existing brand equity of the Crossword and increase awareness of our other games. What was your first job? I worked for Parks and Recreation in my hometown. Essentially, I made arts and crafts with little kids at my neighborhood playground over the summer while wearing a bright orange, way-too-big T-shirt. What is something most people don’t know about you? I am weirdly good at remembering people’s birthdays. What is your secret to career success? My secret is probably leaning into discomfort, no matter how uncomfortable it might feel at the onset. I’ve found that the greatest rewards, both personally and professionally, come from not shying away from a challenge. What is your superpower? I am an active listener with a pretty good memory, which I find beneficial working at a large, cross-functional, matrixed organization. What are you inspired by? As a first-generation American, I continue to be inspired by my parents who instilled a work ethic in me that guides me every day. I am also inspired by young people, especially in this moment, and those who are challenging the status quo by advocating for widespread social change. Name one thing you’re excited about right now. My favorite Vietnamese place opened back up after a long hiatus during New York City’s lockdown. What is your best advice for someone starting to work in your field? Be authentic, be open-minded, be bold and be resilient. And be patient with the process and with yourself! Meeting… Gaëlle Sharma, Technical Product Manager Meeting… Jeremy Gayed, Lead Software Engineer Meeting… Nimpee Kaul, Lead Program Manager How we design and build digital products at The New York Times 59 Nyt Open Meeting Game Development Game Design Work Marketing 59 claps 59 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-10-15"},
{"website": "NewYork-Times", "title": "announcing the new york times widget for ios 14", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/announcing-the-new-york-times-widget-for-ios-14-e97944645923", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Jon Lazar, Kika Gilbert, Mark Murray and Taylor Poulos Keeping up with the news can feel like a full-time job, and we want to make it easy for New York Times readers to stay informed. We provide a variety of ways to do this, from newsletters to push alerts to social media posts, and today, we’re adding another feature to that list: a widget for Apple’s iOS 14 that will feature the latest news headlines. This new widget will allow readers to quickly catch up on the most important news of the moment. Readers who install the widget to the home screen of an iPhone or iPad running iOS 14 or later will see two headlines that will refresh as new content is published. To install the widget, readers with iOS 14 installed can “long press” anywhere on their home screen to enter jiggle mode, then tap the “+” button in the top left corner and scroll down to find The Times’s widget. The project was started by a group of Times iOS engineers who were eager to explore the new features announced with iOS 14. In the weeks leading up to The Times’s annual Maker Week in July, Mark Murray, an iOS engineer, started generating excitement for the widget and Taylor Poulos, a product designer, prototyped designs. Pretty soon, a cross-functional group of people from the newsroom, design, product and data had teamed up to build a widget that matched our ambitions to reader and product needs. By the time Maker Week started, we had prioritized a couple of things we hoped to gain by the end of the week. We wanted to learn more about SwiftUI and WidgetKit; we wanted to give readers a way to quickly catch up with the news, without adding to our newsroom’s workflow; we wanted to deliver an accessible feature that scales with a reader’s type settings. At first, the headlines in the widget updated when a reader opened the NYTimes app on their device. However, we quickly realized that since the widget is visible on the home screen at all times, the headlines needed to be updated more often. Jon Lazar, an iOS Engineer, created a way to do this and now the widget pulls new headlines every 15 minutes or whenever the app gets refreshed. To make sure the widget provides an easy way for readers to stay up-to-date, while also reflecting editorial intent and the Times brand, we made specific modifications to widget behavior and type treatment. Headlines are most informative when they can be read in full, yet our first prototype truncated headlines that were too long. This certainly didn’t meet our readers’ needs. Due to time constraints — Maker Week is only five days — we didn’t want to build a new API, so we instead worked with our existing publishing pipeline. The widget now scales to a single headline based on the accessibility settings of a device, or the specific ranking of our newsroom editors. By the time Maker Week was over, we had a working prototype of the widget and a team of devotees who stuck with this project as a passion project until Apple released iOS 14 to the public in September. To prepare the widget to launch publicly, we implemented data tracking that will inform future widget projects. We worked with the design members of our team to make visual improvements, and we worked with our colleagues in product to make sure the headlines in the widget accurately reflect the most important news of the day. With just five days to focus on this project, we not only built this widget that will be incredibly useful during an already busy news cycle, but we also discovered some opportunities for improvements in our iOS app that we’ll be exploring in the coming months. We’re excited about the opportunity this widget creates to have an “always on” news update that helps keep readers informed, while expanding their understanding of our coverage. Jon Lazar is a Senior iOS Engineer who joined The New York Times in 2020. He enjoys collaborating with his peers to quickly prototype and deliver new iOS features leveraging the latest technologies. Before joining The Times, he was a lead mobile engineer at Betterment where he helped shape technologies and processes as the company transitioned to becoming mobile first. Kika Gilbert is a Product Manager on the UX Foundations team at The New York Times. Mark Murray is an iOS Engineer who works on The New York Times news app. He is an avid consumer of tech news and enjoys tinkering with new technologies. Prior to joining The Times in 2019, he worked at Betterment where he updated the iOS app with Face ID prior to its public launch. Taylor Poulos is a Product Designer on the Publishing team at The New York Times. The Maker Week team: Mark Murray, Jon Lazar, Kika Gilbert, Taylor Poulos, Jamal Rogers, Karina Nguyen and Priya Arora. How we design and build digital products at The New York Times 161 2 Design iOS Swift Product Development Technology 161 claps 161 2 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-10-21"},
{"website": "NewYork-Times", "title": "meeting gaëlle sharma technical product manager at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-gaëlle-sharma-technical-product-manager-at-the-new-york-times-20e71ae878b5", "abstract": "Code Data Product and Design Workplace Culture Work with Us “Meeting…” is an ongoing series from NYT Open that features New York Times employees from different corners of the company. What is your name? Gaëlle Sharma What are your pronouns? She/Her What is your job? I am the technical product manager on the Authentication team. What does that mean? I help make sure that New York Times readers can log-in and register seamlessly on our website and apps. How long have you been at The Times? A little less than a year. Most Times employees are working remotely right now. Where are you working from these days? I am working from Brooklyn. My office space also doubles as my living room, dining room and kitchen. We make the most of the space! How do you start your day? I start my day by brewing pour-over coffee while listening to “The Daily” podcast. I like to start slow and gradually take the day in before I dive into my to-do list. What is something you’ve worked on recently? Recently, the team worked on stress testing the Authentication system in preparation for the November election news cycle. We conduct periodic stress tests to observe how our login and registration reacts under heavy traffic and to identify any improvements we may need to make. Tell us about a project you’ve worked on at The Times that you’re especially proud of. Earlier this year, The Times added an option for readers to register and log-in to The Times using their Apple accounts. Launching this new feature required close coordination across many teams. However, a couple days before our scheduled launch, the entire company began working from home due to the pandemic. We found ourselves unable to collaborate in person, as planned. Despite this new challenge, none of the teams missed a beat. What was your first job? In my first job, I was a fellow at a community development bank on the South Side of Chicago. I’ve always been passionate about helping people. What is something most people don’t know about you? I used to compete in ballroom dancing and to this day I remain a big fan of the sport. What is your secret to career success? Always be learning! What is your superpower? I am extremely curious, which leads me to consistently discover new ideas. What are you inspired by? I am inspired by people who have changed the world for the better. For example, I marvel at the work of Dr. S. Josephine Baker who transformed the field of public health and child hygiene in New York City in the early 1900s. What is your best advice for someone starting to work in your field? Start by shadowing an experienced technical product manager and learn as much as you can from observing how they partner with their team. Meeting… Jeremy Gayed, Lead Software Engineer Meeting… Katerina Iliakopoulou, Lead Software Engineer Meeting… Nimpee Kaul, Lead Program Manager at The New York Times How we design and build digital products at The New York Times 44 Nyt Open Meeting Product Management Product Manager Work Workplace Culture 44 claps 44 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-10-01"},
{"website": "NewYork-Times", "title": "to find photos in our archive we taught the cms how to read", "author": ["Chris Frank"], "link": "https://open.nytimes.com/to-find-photos-in-our-archive-we-taught-the-cms-how-to-read-f9bd5f6703d7", "abstract": "Code Data Product and Design Workplace Culture Work with Us Imagine you’re a photo editor at The New York Times. It’s early evening, a few hours before the print deadline, and a story breaks involving Alexandria Ocasio-Cortez. As fast as you can, you run a search for “Alexandria Ocasio-Cortez” in our internal photo archive and begin to scan the results. You see a handful of photos of Alexandria Ocasio-Cortez, but they’re mostly crowded out by photos of other people and, somewhat more strangely, photos like this: Why on earth is an image of a sunset over a farm one of the top hits for “Alexandria Ocasio-Cortez”? The answer is that when someone enters a search term, our 20-year-old search algorithm checks the caption of every photo in our archive for that term and returns anything that matches. In this case, the caption is: “The sun sets over a farm in Central Iowa, near where Democratic Presidential hopeful Bernie Sanders held a rally today with Rep. Alexandria Ocasio-Cortez.” The phrase “Alexandria Ocasio-Cortez” appears verbatim in that caption, so the algorithm considers the photo a perfect match. For a photo editor, this is a frustrating experience. The names of widely covered public figures appear so often in our photo captions — whether the person is in the photo or not — that it can be impossible for photo editors to find the images they are looking for. In the language of information retrieval, our search engine has high recall (meaning it returns nearly all of the relevant results) but low precision (meaning it also returns many results it should not). Ideally, instead of searching against unstructured captions, we would search against structured tags of who, or what, is in each photo. However, because photos enter our archive from many different sources with different metadata conventions, those tags usually don’t exist and captions are the best data we have. The CMS Photo team bet that if, somehow, we could accurately tag the tens of millions of photos in our archive, we could deliver a dramatically better search experience to the newsroom. Our first thought was to use facial recognition to tag photos based on the faces detected in them, but we quickly ran into two big problems. The first was that state-of-the-art facial recognition models continue to be bad at identifying people of color. In one of our first tests, a widely used facial recognition API told us with 95 percent confidence that a portrait of Alexandria Ocasio-Cortez was of Michelle Rodriguez. (It was wrong.) Even if the models have improved since this 2018 A.C.L.U. study — and it wasn’t clear to us that they have — this technology still has a long way to go. The second problem was one I started calling the “Air Force One problem,” because it can be illustrated by this photo of Air Force One with President Trump aboard: From a photo editor’s perspective, this is a photograph of the President and should be included in search results. From the perspective of a facial recognition algorithm, this is not a picture of anyone — there are no faces in it. Many of our most compelling photos capture their subjects in creative ways that facial recognition software can’t detect. Given the limits of facial recognition, we took a second look at our captions. Earlier, I called these captions “unstructured,” but in fact they are only unstructured if you are a computer. To an English-speaker, the captions are neatly structured according to the rules of English grammar, and the grammatical subjects of each sentence can tell us immediately who is in a photo. We figured if we could just get a computer to recognize grammatical subjects in the same way a human can, we would be all set. Making computers extract structured data from raw text is part of the study of natural language processing (N.L.P.). N.L.P. breaks down the hard problem of extracting meaning into smaller and simpler tasks. Each step in an N.L.P. sequence makes a small change to its copy of the text before passing it to the next step. The overall sequence is called a pipeline and might look something like this: Input : accepts unstructured text as a String. Tokenizer : splits the String into an Array of discrete word-like units called tokens. Tagger : tags each token with a part of speech, like noun or verb . Parser : labels the relationships between tagged tokens. A noun before a verb might be a subject , an adjective before a noun may be a modifier , and so on. While each step in the pipeline might look mysterious, there is no magic at work here. One could write a passable implementation from scratch using just a scripting language, a dictionary and some statistics about word usage. We tried a few libraries implemented that way before landing on spaCy, an open-source Python toolkit whose more complex implementation was more accurate for our use case. (The steps in the pipeline above are the ones spaCy runs by default.) When we ran the caption, “The sun sets over a farm in Central Iowa, near where Bernie Sanders held a rally today with Alexandria Ocasio-Cortez” through our N.L.P. pipeline, we got this: The spaCy pipeline did some fancy things, such as treating “Central Iowa” as one token and distinguishing between “noun” and “proper noun.” Most importantly, the parser correctly labeled “The sun” and not “Alexandria Ocasio-Cortez” as the grammatical subject (“nsubj”) of the text. N.L.P. provided the structured data we needed to write code to extract the grammatical subjects from a caption and store them as tags to search against. Armed with a way of tagging grammatical subjects, we built a quick prototype that let us toggle between the old caption algorithm and the new tag-based search. Even in our earliest version, the results were dramatic. In caption searches for public figures, we were used to seeing the whole screen filled with irrelevant results. In our new tag search, nearly every photo on the screen was of the person we’d searched for. At this point, we knew we could ship a more precise search experience, but we weren’t sure what it would cost us in terms of recall. How many relevant results was our tag search leaving out? To find out, my colleague Sharon Tartarone built an assessment framework in Jupyter that let us score the new algorithm against the old one. We focused on eight of the most searched-for people from our logs. For each person, we then built a dataset of the results returned by the old caption search and manually classified each result as relevant or irrelevant. With the expected results classified in advance, we could then search the same people via our N.L.P.-generated tags and let Sharon’s framework calculate recall and precision. The scores matched our subjective impressions: the tag search really was filtering out almost 100 percent of the irrelevant results, but it was also filtering out about 40 percent of the relevant ones. Our subject-detection pipeline was failing to detect subjects almost half the time, and we weren’t immediately sure why. To understand what was happening, we took a closer look at how our N.L.P. pipeline was handling some of the missing captions. By coincidence, one missing caption was “The President boards Air Force One,” which ended up being a good illustration of the broader problem. The tokenizer worked well on this caption, but the tagger interpreted “boards” as a noun rather than a verb. This mistake propagated to the parser, where it cascaded into nonsense. According to our pipeline, “The President boards Air Force One” had no subject, no verb and no object — just a bunch of barely-grammatical relationships it called compound . In general, when our pipeline was wrong, it was very wrong. Because each step in the pipeline depended on the output of the step before it, early errors would cascade into bigger errors downstream. This meant we saw many results that lacked subjects, verbs and objects entirely, but we didn’t see many results with subjects, verbs or objects assigned to the wrong tokens. We had a hard time preventing these kinds of mistakes, but we did find a way to work around them. Instead of collecting only noun-subject tokens, we adjusted our algorithm to collect all tokens except noun-objects. In a simple, correctly-parsed caption like “Bernie Sanders held a rally with Alexandria Ocasio-Cortez,” collecting subjects is the same as collecting non-objects, so this adjustment makes no difference. But for a sentence like “The President boards Air Force One,” where the algorithm had failed to identify subjects or objects at all, collecting subjects gave us nothing, while collecting non-objects gave us the entire sentence. With this adjustment, even when we couldn’t parse a caption correctly, we could still make something available to search. This indirect approach resulted in 98 percent recall for our test dataset, and we were able to achieve precision between 80 and 95 percent, depending on the search term. The old search algorithm, which searched plain captions, had just 50 percent precision, so this was a big improvement. The results were impressive enough to make our team, and more importantly the photo editors, feel excited about this approach. We have been gradually rolling out tag-based search to the newsroom and making improvements as we go. My teammate Kate Brenner improved precision by finding a more accurate way to detect sentence boundaries, while my teammate Michael Moffitt improved recall by working around long job titles, such as “Speaker of the House Nancy Pelosi,” that were confusing the parser. Michael also implemented some deliberate exceptions to our policy of filtering out the objects of a verb, after noticing that the objects of verbs like “embraces” and “hugs” are usually in the photographs and shouldn’t be filtered out. Looking further ahead, we will work with perceptual hashes to improve information density by grouping similar images together, and we will work with facial clustering to help surface photos from the archive we didn’t know we had. We also plan on integrating a version of this search experience into our in-house collaborative text editor . This work is all in service of creating a richer, more visual report for our readers. Chris Frank is a Senior Software Engineer on the Publishing team at The New York Times and the Tech Lead of the CMS Photo project. The CMS photo team is: Frank Borell, Kate Brenner, William P. Davis, Chris Frank, Chris Grillo, Sherman Hewitt, Jenny Hottle, Michael Laing, Monica Landrove, Justin Lucente, Michael Moffitt, Shonta’ Singleton and Sharon Tartarone. Special thanks to alum Suman Roy, Director of Engineering. If this project sounds as fun to you as it does to us, apply to work with our team . We’d love to meet you. How we design and build digital products at The New York Times 76 1 Code NLP Machine Learning Tech Journalism 76 claps 76 1 Written by How we design and build digital products at The New York Times. Written by How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-10-08"},
{"website": "NewYork-Times", "title": "meeting natalya shelburne senior software engineer", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-natalya-shelburne-senior-software-engineer-a1bf3eb4b6d9", "abstract": "Code Data Product and Design Workplace Culture Work with Us “Meeting…” is an ongoing series from NYT Open that features New York Times employees from different corners of the company. In this installment, we meet Natalya Shelburne, a senior software engineer. What is your name? Natalya Shelburne What are your pronouns? She/Her What is your job? Senior Software Engineer What does that mean? I work on all things front-end at The New York Times . How long have you been at The Times ? It will be four years in October. Most Times employees are working remotely right now. Where are you working from these days? My tiny apartment in Midtown Manhattan. How do you start your day? I usually wake up to a loud “mama!” shouted sometime before dawn, and I make a quick coffee (or two). I then do everything I can to set up as many Montessori-style activities for my daughter that allows me to work in enough 15-minute intervals to get through the day. Basically, I feel like I accomplish a whole day’s worth of tasks before 9 a.m. What is something you’ve worked on recently? A book! I collaborated with incredible design and engineering leaders on a book called “Design Engineering” about modern ideas, workflows and tools. The future of design and engineering collaboration is bright. Tell us about a project you’ve worked on at The Times that you’re especially proud of. The year I served on The Growth Framework committee — a team tasked with updating our old software engineering career ladder. My favorite contribution was pushing for intentionally shifting language to include the variety of contributions made by engineers at The Times . For example, shifting from “having ownership” to “showing initiative” to explicitly recognize the contributions of collaborators and discourage gatekeeping. What was your first job? A Christmas elf! Pointy ears, stockings, candy canes. It may have also been the best job I have ever had and definitely set a high bar. What is something most people don’t know about you? Last year, I co-wrote a short film that was accepted into three film festivals. What is your secret to career success? Reconciling the potential of what something could be with the reality of what it actually is and accurately measuring the impact I can have. In other words, the ability to read a situation and know when to push through, wait out or move on. What is your superpower? The simultaneous coexistence of relentless optimism and deeply pragmatic preparedness. What are you inspired by? People who have a clear mission and whose actions line up with their priorities. Also, toddlers: they know how to live in the moment better than anyone. Name one thing you’re excited about right now. The world is in a state of unprecedented disruption, but I have to believe that the potential for profoundly positive change exists. For example, the sudden shift to remote work and lack of childcare has pulled back the curtain on the realities of just how much extra work parents and caregivers do, and the fragility of the support systems we have had to cobble together in order to go to work during the pandemic. Will we, as a society, rise to the occasion and improve these systems so that we can better support people? I hope so. We have to. Teaching and childcare are both full time jobs, and they should be valued and funded. What is your best advice for someone starting to work in your field? Value yourself, your opinions and your contributions. Seek out and work with people who see your value and potential, and who don’t ask you to repeatedly prove yourself to them. There are a lot of people out there who are willing to take advantage of your self doubt. Don’t fall for it. Spend your energy on learning, growing and creating. Meeting… Tiffany Peón, Senior Software Engineer at The New York Times Meeting… Nimpee Kaul, Lead Program Manager at The New York Times Meeting… Katerina Iliakopoulou, Lead Software Engineer at The New York Times How we design and build digital products at The New York Times 34 Nyt Open Meeting Work Life Balance Women In Tech Code Tech 34 claps 34 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-09-08"},
{"website": "NewYork-Times", "title": "design prototype zoom how new york times interns built a game remotely", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/design-prototype-zoom-how-new-york-times-interns-built-a-game-remotely-8b7bff755983", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Milena Correa, Stephanie Lu, Jenna Kim, Natalie Erjavec, Rohan Shaiva and Shandler Mason How do you design a digital game with people you have never met in person? This was a question we faced this summer as interns with The New York Times Games team, which is working remotely due to the coronavirus pandemic. The team typically develops new game prototypes every month to test with Times subscribers. They assigned us — a team of six interns with skills in design, tech and data — an ambitious task for our summer internship project: to design and prototype a digital game in three weeks. To do this remotely, we had to get creative with our design and playtest approaches. The first step was to decide what kind of game we wanted to make. We were encouraged to explore fresh ideas, so we held an ideation session over video chat to brainstorm game concepts. To guide our thinking, we filled out ideation worksheets and framed our ideas in the form of questions, such as “How might we make a game about space?” We then voted on our favorite concepts. Our initial ideas were wide-ranging, but we chose to make a “clock game”: where players must swap the mixed-up numbers on a clock to find the correct order. After we settled on a concept, we began building sample prototypes on paper and in Google Jamboard, where we could test our ideas with our families and members of the Games team. To make our game appeal to a wider range of players (and to make it more interesting), we replaced the numbers with visual icons. We wanted these icons to indicate linear progression since our game was centered around the themes of time and evolution. Our first design showed an embryo developing into a chick. (To answer the age-old question, we decided that the egg comes before the chicken!) Milena Correa, game design intern, recognized that the sequential visuals evoked animation. We realized we could refer to the icons as “frames” that could reveal a simple animation when arranged in the right order. Our source of inspiration changed from a clock to a zoopraxiscope, an early motion picture device that cycled through images rapidly to animate them. This informed the name of our game: Animatic. Once we had the visual metaphor sorted out, we had to decide on key interactions. A major component of gameplay was how players would move the frames around. We explored many possibilities. Through trial and error, we decided that each frame could be swapped with the frames two spaces to the left or right. This gave the gameplay two layers of complexity: players had to recognize the sequence of the frames, and they had to strategize about how to move the frames into the correct positions. We paid close attention to how Animatic would fit with the rest of the Games portfolio, especially through its visual design. Jenna Kim, product design intern, began conceptualizing the game’s visual design early in the development process. With a zoopraxiscope as our inspiration, Correa and Kim decided to transform the original clock layout into a film reel. This made the theme and objective clearer, while elevating the game’s visual aesthetic. Kim designed the icons and color palette with simplicity in mind. To make our game accessible to diverse audiences, we chose easily recognizable symbols for each set of icons that visually indicated some sort of change over time. We settled on four sequences: a chick hatching, an apple being eaten, a burning match and a pizza being eaten. A big part of the design process was figuring out how to get players to start their sequence at the top of the film reel and continue clockwise. Kim tried to highlight the top of the reel in various ways, such as with arrows, symbols and even words. After some testing, we decided that the arrow was the most intuitive option. Animatic is the first Games prototype that was simultaneously built for iOS and the web. This allowed us explore how the game might feel both in-browser and in-app. It also enabled us to take advantage of Rohan Shaiva, Shandler Mason and Stephanie Lu’s diverse tech skill sets. To keep both versions of the prototype in sync, we communicated frequently and checked in daily over video calls. Shaiva and Mason built the iOS prototype in Swift, while Lu created the web version using React. The highly interactive nature of the game presented a number of technical challenges. For example, animating the frames and showing their swapping movements required a carefully timed sequence of transitions and events. To allow for this chaining, Shaiva and Lu implemented code asynchronously — the animations run in parallel with the code that handles the logic. That way, if you’ve made the winning move, you won’t see the “Congratulations!” message until you’ve seen the frames swap. Because users interact with mobile and web interfaces differently — through tapping and clicking — we wanted to create a single interface that was consistent between our iOS and web prototypes. The original designs for both platforms contained a swap button that users would click or tap after choosing two frames to swap. However, we found that this approach required too much clicking and tapping, so Kim worked with the developers to explore different interactions. We decided that drag-and-drop for iOS and click-to-swap for the web made the gameplay most engaging. Usually, the Games team playtests their prototypes with users in person so they can closely follow how the users interact with the game. Our challenge was to recreate this experience in a virtual setting with members of the Games team and the wider Times intern cohort — these sessions were coordinated by Natalie Erjavec, data analyst intern. Although we hadn’t yet deployed our web prototype, we found ways to test it out. We sent playtesters a temporary link generated by ngrok, an application that creates access to a local development server. Playtesters then shared their screens with us so we could observe their facial reactions and their interactions with the game. The process was trickier to figure out on iOS. Playtesters couldn’t download the app on their phones or run the latest development build, which would take too much time to set up. Shaiva developed a way to test the game over Zoom. During calls, he shared his computer screen and showed everyone the latest prototype on an emulated iPhone. Then, he gave playtesters remote control of his screen, which allowed them to play the game. This approach required several layers of abstraction and suffered from an occasional lag, but it ended up being an effective way to playtest. Our remote playtesting hacks enabled us to obtain crucial feedback to improve our game. We made several improvements based on playtester feedback, including adding easier levels. Some players found it difficult to see where the sequence started, so we added a fade-in transition to indicate the order of the frames. While Animatic is a prototype and not a fully polished game, we are proud of what we were able to accomplish in three weeks. We were able to leverage our different skill sets and collaborate cross-functionally, which allowed us to work efficiently and with fewer hiccups. Making Animatic was a core part of our summer internships. While the Games team is not currently testing new prototypes, you can play Animatic here . Enjoy! Milena Correa is a Game Maker Intern and a rising Junior at Parsons School of Design (Class of 2022), majoring in Design and Technology with a focus in Game Design. Jenna Kim is a Product Design Intern and a rising Senior at Carnegie Mellon University (Class of 2021) studying Communication Design with a minor in HCI. Natalie Erjavec is a Data Analyst Intern and a rising Senior at the University of Washington pursuing a B.S. in Informatics and a certificate in Sales. Stephanie Lu is a Front-End Engineering Intern and a rising Junior at Santa Clara University (Class of 2022), majoring in Computer Science and Engineering. Shandler Mason is an iOS Mobile Engineering Intern and a rising Junior at North Carolina Agricultural & Technical State University studying Computer Science with a minor in Applied Mathematics. Rohan Shaiva is an iOS Mobile Engineering Intern and a rising Senior at Tufts University majoring in Computer Science and Film. How we design and build digital products at The New York Times 35 1 Game Development Design Thinking Gaming Games Design 35 claps 35 1 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-08-25"},
{"website": "NewYork-Times", "title": "meeting tiffany peón senior software engineer", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-tiffany-peón-senior-software-engineer-54a207411934", "abstract": "Code Data Product and Design Workplace Culture Work with Us “Meeting…” is an ongoing series from NYT Open that features New York Times employees from different corners of the company. In this installment, we meet Tiffany Peón, a senior software engineer on NYT Cooking. What is your name? Tiffany Peón What are your pronouns? She/Her What is your job? Senior Software Engineer on NYT Cooking. What does that mean? I write and maintain software for NYT Cooking. As a backend engineer, a lot of it isn’t work you can see, but it powers features for the website and the iOS and Android apps. How long have you been at The Times? My four year anniversary is coming up! I started on July 11, 2016. Most Times employees are working remotely right now. Where are you working from these days? Mostly from my couch in my East Village apartment. If I’m feeling a little crazy, sometimes I’ll work from my bed or the kitchen. How do you start your day? I pull my pet guinea pig out of her cage so she can cuddle with me on the couch while I work, and I crack open a Diet Coke — the signature breakfast beverage of people from Atlanta. What is something you’ve worked on recently? Lately I’ve been doing some clean-up work on our free-trial experience. We have a lot of complicated logic to determine whether or not someone is eligible for a free trial with Cooking, so I’ve been working on simplifying it so it’s easier to make changes to it in the future. Tell us about a project you’ve worked on at The Times that you’re especially proud of. Last year, I wrote the API for our grocery lists feature, which was something I had been wanting to put in our app for a very long time. I worked with one front-end and one iOS engineer so that we could launch the product cross-platform, which was something I hadn’t done before. I use the feature almost every time I go grocery shopping! What was your first job? I was a hostess at Waffle House (another Southern staple). The official title was “Door Corps” and one of my biggest responsibilities was sweeping cigarette butts off of the sidewalk every hour. I lasted about two months. What is something most people don’t know about you? I once auditioned for Wheel of Fortune and got cut in the first round for not being animated enough. What is your secret to career success? I had a pretty negative college experience that resulted in me feeling like a huge failure for most of my twenties. When I decided to go to a coding bootcamp, I looked back on the mistakes I’d made as a result of feeling scared or not good enough in school and I didn’t let myself make the same mistakes. I learned how to push past my feelings and trust the process. What is your superpower? I’m pretty good at binge-watching TV shows? What are you inspired by? I feel my best when the people around me are happy and comfortable. Whether it be in work or life, I find opportunities to help and enhance the experiences of those around me—that’s the driving force behind most of my actions. Name one thing you’re excited about right now. Chiu Chow style chili oil! I went to a dumpling making class in January, and the instructor introduced me to it. It’s life changing. What is your best advice for someone starting to work in your field? Programming is an exercise in humility. Learn to separate your work from your ego — ask the dumb question, and ask for clarification when you don’t understand the answer to the dumb question the first time. Pair yourself up with people who think differently than you, even when it’s frustrating or intimidating. The reason this job can be so rewarding is because you end up accomplishing things you thought to be impossible. Meeting… Jasmine Chan, Engineering Manager at The New York Times Meeting… Storm Hurwitz, Senior Analyst at The New York Times How we design and build digital products at The New York Times 84 Software Engineering Code Work Nyt Open Meeting Women In Tech 84 claps 84 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-08-05"},
{"website": "NewYork-Times", "title": "could blockchain be a solution to the issue of misinformation online", "author": ["Pooja Reddy"], "link": "https://open.nytimes.com/could-blockchain-be-a-solution-to-the-issue-of-misinformation-online-492ca63ae42", "abstract": "Code Data Product and Design Workplace Culture Work with Us A version of this story was published in Times Insider, which delivers behind-the-scenes insights into how our journalism comes together. When a news photo makes its journey from a camera to publication, it passes through many devices, technologies and people. Each step in this journey is designed to ensure the truthfulness and accuracy of the person or event depicted in the photo. However, once the photo makes it to the internet, it can end up anywhere in a matter of minutes — sometimes without its original context or with purposely misleading information . The R&D team at The New York Times has been exploring a number of different solutions to address the issue of misinformation online. One of those explorations was The News Provenance Project , which experimented with blockchain technology. A prong of The News Provenance Project was to conduct research around how readers make judgments about the photos they see online . To help with that research, we built a prototype that leveraged blockchain to surface a news photo’s contextual information on a simulated social media feed. We wanted to see whether visible contextual information, such as the photographer’s name and the location depicted in the photo, could help readers better discern the credibility of news photos in their social feeds. Blockchain allows multiple organizations to read from and write to a shared database. It tracks these changes in a log of actions, otherwise known as a “ledger.” We wanted to see if it was possible to record everything that happens to a photo, from capture to publication, in the form of photo metadata and display that information on social media platforms. Blockchain’s ability to preserve the full history of a photo separately from the image file itself made it a compelling technology for our explorations around tracking provenance. For our prototype, we created a private network of theoretical news organizations and a simulated social media platform that shared ownership of a database and a ledger. The news organization that were part of the network could make changes to photo metadata in the database. The ledger ensured that there was a transparent record of the time and author of the changes. Our blockchain system was built by a team of developers from IBM Garage using IBM’s Blockchain Platform. To architect the system, we created a network model to ensure the right members of the network had the appropriate permissions for the metadata. We also created a data model that would help us track the necessary metadata fields to understand the history of a news photo. The scope of a news photo’s journey is large, and there are numerous possibilities for network membership across all of its touch points. A photographer’s camera could be a network member that sends photo metadata through mobile networks into the database, with no human intervention required. A photo editor could also be a network member and their photo edits would be reflected in the metadata. For our prototype, we focused on a simple scenario where a news organization was aware of a photo’s origin information and was responsible for publishing the photo in an article. We constructed a blockchain network that involved three network member organizations, or “nodes”: two theoretical news organizations ( Local Gazette and National News ) and one social media organization (which we called “the Social Media Platform”). With these nodes, we were able to explore a few interactions on the blockchain: two different news organizations could create photo instances and update their associated metadata; the news organizations could publish the same photo in different articles; and the social media platform could access all photo history and publishing information. In blockchain systems, interactions are written in software and stored in smart contracts. These smart contracts can additionally include checks to ensure that changes made to the database are truthful and accurate, avoiding the need for human input. For our prototype, we kept it very simple: all possible interactions between network members were included in a single smart contract. Only one other organization needed to approve interactions and every interaction was automatically approved. For example, anytime Local Gazette wanted to create a new photo record on the blockchain, it had to get permission from National News . But, National News automatically approved the transaction without actually checking for truth or accuracy. After conducting 34 user research interviews with people with different political perspectives, we came up with a list of contextual information that the people in our interviews found most useful about a photo, such as who took it and where it was taken. We mapped this contextual information to IPTC photo metadata fields , which are encoded in photo files and are used in the photo industry to preserve copyright and licensing information. This exercise helped us construct a data model for storing metadata in our blockchain database in the form of a photo record. The people we interviewed indicated that in addition to learning about the origins of a photo, they wished to understand the publishing history of a photo, such as where the photo had been published and what captions had been written for it. Because wire services, like the Associated Press or Reuters, often work with multiple news organizations, a single photo might be published in many different news articles. With this in mind, we created a separate publishing record in our data model that would enable us to track publishing information around a photo. When testing our prototype with users, we found that it effectively helped them make informed judgments about photos in a social media feed. Yet, there is more research and exploration that needs to be done. While blockchain technology could be a viable tool in helping preserve the origin of news photos, there are a number of challenges that would need to be addressed before it could be widely used. Content on the blockchain must be reviewed by network members. In our prototype, we set up simple smart contracts, where changes made to a photo’s record were approved automatically. In a real-world scenario, smart contracts would be required to validate any changes made to a photo’s record to ensure credibility. Encoding those validation rules would be complex for certain metadata fields, like the description of an event in a caption. Photos on the internet must be matched to their original versions on the blockchain. For our prototype, we assumed the social media platform would be able to associate a photo on its feed to a photo in the blockchain through an ID. In reality, the social media platform would need to associate a photo without any knowledge of whether that photo already exists on the blockchain. The photo on social media might have been heavily edited, making it even more difficult to find its instance on the blockchain. Bhaskar Ghosh, a student at Columbia University who conducted research for The News Provenance Project, investigated perceptual hashing and computer vision as potential mechanisms for associating photos on social media with photos on the blockchain. However, Ghosh noted that those mechanisms would require further refinement. Blockchain networks must be accessible to news organizations. This prototype was the R&D team’s first attempt at using blockchain technology for media provenance and it required significant operational and technical overhead. In order for a blockchain solution to become a reality, news organizations with varying financial and technical resources need to be able to participate. Finding ways to lower the barriers to entry is an essential component of any future explorations. This prototype was an experiment that taught us a lot about the power of credible, contextual information in social media feeds, but there is a long way to go before something like this can be fully realized. Nevertheless, there is a large opportunity for using blockchain to help fight against misinformation in news photos. As with any network, it’s only as powerful as the size of its participation. The R&D team has partnered with media and technology companies to build exactly this kind of participation. The team’s projects include a collaboration with Adobe and Twitter on the Content Authenticity Initiative , as well as participating in Project Origin and Partnership on AI . The R&D team continues to look for opportunities to share its findings and collaborate with organizations or individuals interested in solving the problems of misinformation. Pooja Reddy is a product manager at The New York Times. How we design and build digital products at The New York Times 221 2 Blockchain Misinformation Code Journalism Technology 221 claps 221 2 Written by How we design and build digital products at The New York Times. Written by How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-07-08"},
{"website": "NewYork-Times", "title": "meeting jasmine chan", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/meeting-jasmine-chan-5a8b71a16bd4", "abstract": "Code Data Product and Design Workplace Culture Work with Us “Meeting…” is an ongoing series from NYT Open that features New York Times employees from different corners of the company. In this installment, we meet Jasmine Chan, an engineering manager on the Technology team. What is your name? Jasmine Chan What are your pronouns? She/Her What is your job? Engineering Manager What does that mean? I lead a team of passionate and engaged engineers who are focused on solving complex technical problems, and I work with product managers to strategize our team’s roadmap. As an engineering manager, I coach and help engineers so that there are minimal obstacles for them to get to their goals, and I support any decision making that needs to be done. How long have you been at The Times? Shy of 8 months. Most Times employees are working remotely right now. Where are you working from these days? When the news broke that many non-essential businesses were being shut and that The Times was moving to remote work, my fiancé and I escaped to Connecticut. I’m very lucky to have a larger space to work from. I’ve converted the dining room table to my office. How do you start your day? Honestly, it’s been tough to wake up early because I know it doesn’t take a long time for me to “commute to work.” I set my alarm clock to 7 a.m., but usually end up rolling out of bed at 8:30 a.m. I then, finally freshen up, go to my “office,” turn on “The Daily,” make a cup of tea and breakfast, and I check my Trello Board, emails, Slack and calendar to figure out what I want to accomplish in the day and to catch up on anything I missed the day before. On a good day, I’ll actually wake up at 7 a.m. to go work out. What is something you’ve worked on recently? Currently, I’ve been taking up knitting, baking and cooking. I’m working on a baby blanket, and last weekend I made some dumplings from scratch (skin and all!). Tell us about a project you’ve worked on at The Times that you’re especially proud of. A couple weeks ago, we rolled out the PayPal smart button with the use of the new Braintree SDK. It was a huge undertaking with three teams, and it showed how great we collaborated with each other. This allowed us to refactor some of our code to make our systems more scalable and maintainable. It also opens up many avenues and opportunities to introduce simpler workflows for our readers. What was your first job? My first job was a pager at a library. I basically lived and breathed the Dewey Decimal system. What is something most people don’t know about you? I have done 15 skydiving jumps, and I once did a cross-country ski road trip chasing the snow. What is your secret to career success? My secret to my career success is to not be afraid to take on new opportunities even if they are in unfamiliar territory. This allows me to learn new things and to discover what growth areas I can work on. What is your superpower? I am attentive, which allows me to absorb the opinions and ideas of others. What are you inspired by? I’m especially inspired by how people are coming together to help each other during this moment, and all the essential workers out there who are risking their lives. I’m also inspired by the women in leadership, past and present, who paved the pathway for my generation. Name one thing you’re excited about right now. I’m excited to finally meet my niece once we’re able to travel again. What is your best advice for someone starting to work in your field? Be patient, and don’t be afraid to challenge yourself. Meeting… Storm Hurwitz, Senior Analyst at The New York Times How we design and build digital products at The New York Times 73 Code Work Nyt Open Meeting Women In Tech Software Engineering 73 claps 73 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-06-26"},
{"website": "NewYork-Times", "title": "how to prepare for an engineering interview at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/how-to-prepare-for-an-engineering-interview-at-the-new-york-times-83f4ee6a68b5", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Jason Cornelio and Jeff Louden Editor’s note: this article has been updated to reflect a remote-only interview process due to the coronavirus pandemic. Over the last couple of years, we have written about how we have changed our application and hiring processes for software engineering candidates at The New York Times. To ensure all candidates are being evaluated consistently, we consolidated multiple job postings into one listing , as our colleague Brian Hamman wrote in 2018. And last year, a group of volunteers from our Technology and Talent & Inclusion departments redesigned our hiring process to check for bias and give candidates a chance to showcase their strengths. We are now sharing what candidates can expect from the interview process and how they can best prepare. There are a few stages of the interview process, which include a phone call with a tech recruiter, a remote code evaluation and a day of virtual interview panels with the team. Many of the interviews included in our hiring process are designed to help us understand how you might approach common scenarios that developers encounter at The Times. However, you are not being tested for your knowledge of The Times, and you will always have the opportunity to ask us questions about anything you don’t understand. Here are some tips before you start the process: Familiarize yourself with The Times Please be sure to visit NYT Open and The New York Times Technology Careers page for more information about our engineering community. These resources will give you more information about what we do and our company culture. Come prepared Be prepared to talk about some of the recent projects you enjoyed building. Select a few past experiences and projects to share during the interview; It will be easier to draw upon a pre-written list of examples, instead of coming up with something on the spot. Please don’t discuss anything that your previous or current employers would consider confidential. Rest up Be well-rested and ready to think on your feet, as some of the interviews will require you to solve problems in real-time. Think of your goals Consider what’s important to you in a job, what you would like to see in a work environment, and how you partner with colleagues and managers. Take some time to carefully review the job description. Feel free to ask for more details about the role, or about our company goals and values, how we are organized, how we work together or about anything else on your mind. The first step in our interview process is a scheduled phone call with a recruiter. The phone call typically lasts for 15 to 30 minutes and consists of an overview of the teams here, a review of your professional background and a few quick logistical questions. Think of this discussion not as an interview, but as an opportunity to open up about your technical background and your interest in The Times. At the end of the call, your recruiter will open the discussion for any questions you have about the company or our process. Our interview process varies depending on whether you are interviewing for a native mobile developer or software engineering job. If you are a native mobile developer, please skip the following section and read “Technical Interview for mobile developers,” below. Otherwise, read on. For software engineering roles, our team will schedule a 45- to 60-minute remote technical assessment over Google Meet with a Times software engineer or engineering manager. This gives us an opportunity to assess your ability to build software, and to understand how you learn and teach. We know that connecting to the internet can be flaky sometimes. If you happen to be having a problem with your connection on the day of your technical interview, you can let the interviewer know that you need to reschedule for another time. As you navigate through the technical interview, we want you to feel comfortable discussing your professional background and showcasing your technical knowledge. Your interviewer will dive technically into your favorite or most recent projects, guide you through a short coding exercise and open up the floor for any questions that you have about being an engineer at The Times. Again, please don’t discuss anything that your previous or current employers would consider confidential. The following is a typical interview format: Introductions — five minutes Introductions give you and the interviewer an opportunity to share a little bit about who you are, what your current role is and how your day is going. Diving into favorite projects or most recent work — 15 to 30 minutes This section of the interview helps us learn about your direct experience in a more meaningful way than a high-level overview. Your description can illustrate what projects you have worked on, how you collaborate with others and how you think about tough engineering choices. You can also share certain lessons you have learned within your career. Coding Exercise — 15 to 25 minutes The goal of the exercise is to get a baseline signal on your ability to design an algorithm, translate it to code and discuss their solution. Our coding exercise adds variety to the interview, leveling the playing field for candidates who may not be as strong talking about their background. Please feel free to let the interviewer know what language you prefer working with. Question and Answer — 10 minutes This portion of the interview will be held for any questions that you may have for the interviewer. If you are an Android or iOS developer, your recruiter will send you a technical challenge that will form the basis for an interview with the team. As you complete the challenge on your own time, it’s important for you to use this time to showcase your engineering prowess. We understand that it can be difficult to find time to do take-home assignments, so there is no deadline or timeframe for the completion of this exercise. Let your recruiter know when you think you will be able to complete it, and please feel free to communicate any updates. Once you have completed the technical challenge, your recruiter will schedule a remote, one-hour interview for you with two Times engineers; the engineers will review the code you have submitted prior to your meeting. This conversation will be a chance for the engineers to talk with you about the choices you made in the code, problems you encountered and where you would go next. It can be a great chance to clarify your intention, exchange points of view and talk shop with potential colleagues. After the technical part of the interview process, the interview paths converge again. The rest of this article applies to all engineers. Once you have completed the technical challenge, our recruitment team will contact you to schedule a day of virtual interview panels with members of our teams — this is the final round of our process. By this time, you will know which teams have expressed interest in your profile and who will be part of your interview panels. Your day will consist of one or two technical interviews and two non-technical interviews, as well as an interview with the hiring manager and a conversation with your recruiter. Software engineering technical interviews will focus on subject types such as algorithms and data structures, or architecture and system design. Mobile development interviews will focus on foundational programming concepts required for mobile development, as well as platform-specific SDK knowledge. During the non-technical interview, we will ask questions to better understand how your values and our company values align. We also want to get a sense of how you work collaboratively on a team, and how you learn and teach. In these interview panels, you will be asked about your experience and interests, your thoughts about the position or positions you are being considered for, and what you think of The Times. These interviews also give you an opportunity to ask about anything else that might be on your mind related to this position or the company. While some candidates may have a shorter day with us, it’s best to expect the day to last four to five hours. If you have any time constraints, please be sure to let your recruiter or recruiting coordinator know. We will do our best to provide a 45-minute break during your time, especially if your interview day is scheduled to last more than three hours. We are happy to accommodate additional or fewer breaks depending on your preferences; just let us know what works best for you. During your break, you will be free to relax, use the restroom, check your messages and stretch your legs. We encourage you to wear headphones with a mic during your interviews, however they are not required. As most people are currently working remotely, we understand that there might be background noise during your interview. Let your interviewer know if you need a question repeated or clarified, and they will do the same. Our video interview platform, Google Meet, offers real-time captions. To turn them on, click on the menu (three vertical dots) in the bottom left corner of the video screen and select “Turn on captions.” We are committed to the full inclusion of all qualified candidates. As part of this commitment, we will ensure that people with disabilities are provided reasonable accommodations. Please let us know if a reasonable accommodation is needed for you to participate in the job application or interview process, to perform essential job functions or to receive other benefits and privileges of employment. We will do our best to make sure your interview is as seamless as possible. While we are not currently working from the Times building, we want to mention that the office is wheelchair accessible, provides gender-neutral restrooms and welcome service dogs (unfortunately, no other animals are allowed). We recommend simply wearing what you are most accustomed to wearing, and we promise no one will judge you for it. While some Times employees wear business clothing, many people work in casual clothing such as jeans and a T-shirt, or a button-down shirt or blouse. We hope that this step-by-step process on what it’s like to interview here at The Times will help you navigate and best prepare for success in every interview you go through. Please check out our open roles at https://www.nytco.com/careers/ . Jason Cornelio is Associate Manager of Talent Acquisition who works on Technical Recruitment at The New York Times. Jeff Louden is currently based in Seattle, Washington. He was most recently the Director of Engineering at NYT Cooking. Jason and Jeff would like to thank the Technology Hiring Group and Talent & Inclusion team at The Times for their support on this piece and their non-stop work on improving every step of the engineering hiring process. How we design and build digital products at The New York Times 159 Code Workplace Culture Technology Hiring Careers 159 claps 159 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-07-22"},
{"website": "NewYork-Times", "title": "what the new york times metropolitan diary taught its illustrator about new york", "author": ["Agnes Lee"], "link": "https://open.nytimes.com/what-the-new-york-times-metropolitan-diary-taught-its-illustrator-about-new-york-195686a4852d", "abstract": "Code Data Product and Design Workplace Culture Work with Us Three years ago, I uprooted myself from California and moved to New York City. Like many New York transplants, I moved with the idea that the city would bring exciting opportunities and I’d experience new culture, food and sights. This was a big milestone in my life, but when I got to New York and my boxes were unpacked, the change was harder than I expected. The lifestyle in New York is very different from what I was used to. I exchanged my car for the subway; vast hiking trails for city parks; a temperate climate for wide-ranging weather patterns. New York felt too big, too crowded. I missed my friends, my family, the place I used to call home. I was committed to my choice though, figuring it was just a matter of time before I got comfortable. So, I learned to get by, but I got by without feeling very connected to life here. Shortly after I arrived, I started drawing illustrations for The New York Times’s Metropolitan Diary . Since 1976, Times readers have been sending short stories about life in New York City to Metropolitan Diary. The column features stories from all five boroughs, told by New Yorkers past and present. Every week, there are five honest vignettes that range from funny, sad, absurd, nostalgic and poignant. Ed Shanahan, Metropolitan Diary’s editor, sifts through the submissions that readers have sent in and chooses which ones to include in that week’s Diary. When the week’s stories have been edited, Ed sends me an email that the stories are ready for me. I read through them and start brainstorming ideas for illustrations for each one. (Ed is a great editor, but he’s my favorite editor because he lets me draw whatever I want.) Once I’ve decided how I want to illustrate each story, I gather all of my tools. These are my materials and set up: Computer for background noise and reference images. Grease pencils. Mohawk 98lb smooth paper that I call “special paper.” I like to use this smooth semi-matte print paper because its surface is perfect for grease pencils. Razor to sharpen the pencils. Bucket for pencil shavings. When I’m brainstorming, I do a lot of rough sketches to see which ideas I like. Sometimes I will draw the same thing multiple times to ensure I get it right. I most often draw people, taxis, hands and elements of the subway; I once drew a lot of chickens for a story about a chicken found in Riverside Park (the story had only one chicken, but I don’t draw chickens very often so I went through a lot of drafts to get it right). When I’ve settled on a direction, I send Ed two to three sketches per story. Ed makes his selections and usually thatʼs that, but sometimes I will overlook some key details or draw an element of a story incorrectly and he will gently point out… “I think they meant the front part of the car, not the roof.” “He was tall, but I don’t think that tall.” “I think it was a dad, not a mom, driving the son.” “Pretty sure theyʼre talking about a bicycle, not a motorcycle.” I’ll take Ed’s feedback and make adjustments to my sketches, readying them for publication online and in the paper. Sometimes Ed will provide important context to some stories, getting me reference photos from the author, or sending along a movie clip or photography. Our correspondence is short and efficient and very quick — Ed never seems to take a day off work and will often respond to my emails within minutes. Like I said, he’s my favorite! When I first moved to New York, my list of things to do in the city was pretty typical: walk the High Line, visit The Met, eat a bagel, see a Broadway show. I did all of those things and I experienced the city through its greatest hits. But when I started illustrating Metropolitan Diary, I started learning the deep cuts. Through the stories I read each week, I learn more about New York than I ever expected. Over time, the things on my to-do list have become a little more interesting: catch a glimpse of the Chrysler Building from a specific spot on the High Line; try to find a poppyseed cake reminiscent of the one Lindy’s used to serve ; watch recordings of live theatrical productions at the New York Public Library for the Performing Arts archive. The stories in Metropolitan Diary have expanded my view of New York, but they’ve also condensed it. The city doesn’t seem as big as it felt three years ago. I can now relate to the subway stories—both the good ones and the bad. Neighborhood names aren’t just words, but places I’ve visited. Sometimes when I’m walking around I’ll notice a building or landmark that someone wrote about. “I know that from Metropolitan Diary,” I’ll think. “That’s pretty cool.” I’m still no New Yorker, but after three years here I feel a little more settled in. New York has a lot of people, but we also have a lot in common and we’re all just doing the best we can in this crazy city. Who knows, maybe one day Iʼll even write my own Metropolitan Diary entry. Agnes Lee is an illustrator living in Brooklyn, NY. She still manages to find ways to get her nature fix while living here. You can find more of her work at www.ahjlee.com , on Instagram and, of course, The Metropolitan Diary . How we design and build digital products at The New York Times 84 1 Illustration New York City Design Storytelling Drawing 84 claps 84 1 Written by How we design and build digital products at The New York Times. Written by How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-10-13"},
{"website": "NewYork-Times", "title": "how do people decide whether to trust a photo on social media", "author": ["Emily Saltz"], "link": "https://open.nytimes.com/how-do-people-decide-whether-to-trust-a-photo-on-social-media-e0016b6080ae", "abstract": "Code Data Product and Design Workplace Culture Work with Us This is part one of a behind-the-scenes look into the research, design and prototyping behind The News Provenance Project’s proof of concept that shows how publishers can use blockchain to surface source information about news photography. Read part two here . With every hurricane that hits American shores, the shark photo makes a comeback. It appears to be taken from the driver’s seat window of a car, showing a flooded highway and, surprisingly, a shark swimming down the middle lane. The image was photoshopped and has been debunked, but that hasn’t stopped it from ping-ponging around social media every time a major disaster hits. Even without photoshop, visuals with misleading content , missing context and false information are common on the internet, and with the help of social platforms, they can be spread far and wide in a matter of minutes. Posts with visuals are shared more widely and rapidly than text-only posts and are central to the spread of misinformation. Within this polluted information ecosystem , it’s difficult to discern which visuals are credible. According to The Pew Research Center , almost half of American adults say it’s hard for them to recognize when visuals have been made up or altered. The result is a muddled discourse about what’s true: a majority of American adults say that made-up or altered visuals can create confusion about the facts of current events. If anything can be faked, how can people trust that credibly sourced visuals are accurate? Do people still believe what they see in photojournalism? Spurred by questions like these, the New York Times R&D team created The News Provenance Project to explore solutions to issues of misinformation around visual journalism. During the summer and fall of 2019, we conducted 34 total interviews over one round of user research and two rounds of prototype testing to investigate ways of attaching provenance information to news photography. What we found was that despite concern otherwise, Americans do not operate from a “post-truth” psychology. Even in today’s polarized climate, people with wildly different political views still appreciate the original context of a news photograph. Yet, as we tested different designs that displayed context, a new question arose: will people even notice accurate source information in the first place? At The News Provenance Project, we wanted to find out how publishers can help readers make more informed, confident judgements about the credibility of news photography. To do this, we focused on how we might surface the metadata — such as descriptive captions, time and location information — that journalists embed in photography files. At the same time, we wanted to see if we could leverage the history-tracking capabilities of blockchain technology to ensure that that metadata stays embedded with news photography as it travels around the internet. We worked with IBM Garage, which built a prototype using the open-source Hyperledger Fabric platform (more on the prototype later). However, even if we could use blockchain to effectively display the history of a news photo, we still needed to understand what gives people the confidence to make informed judgements about the credibility of news photography when it matters most. The work started in May, 2019, when a group of people from the Associated Press, Hearst, The New York Times and the Wall Street Journal met with IBM Garage to look at better ways to communicate the provenance of photojournalism to readers when photos appear off platform. The group developed an assumption: that it is difficult for news consumers to trust the authenticity of images they see online, and a blockchain-based signal of trust could help them judge what visuals are credible. Building off the work of this group, The News Provenance Project began by trying to see how their assumption lined up with real user problems. We first conducted in-depth interviews with 15 daily users of social media from different backgrounds, geographic locations and with news preferences for both left-leaning and right-leaning news. We wanted to learn how people decide whether to trust a photo on social media, and what kinds of information would help them feel confident in judging what’s credible. To do this, we asked participants to walk us through how they view news photos in their social media feeds. We also had the participants scroll through several example posts and asked them to think aloud about what they noticed and how credible the posts seemed. The examples varied widely in source type (individual, local, national), language style (words like “shocking” or evidence of reporting, like citing city officials) and post type (attached to an article or a stand-alone photo). Through these conversations, we gained insight into how people view news photography on social media, and how they think about the quality of information they see. What these conversations revealed was that overall, the people we spoke to are capable of being discerning, yet rather than asking themselves whether a post is true or not, they are motivated by whether they find a post interesting. A few distinct patterns emerged around the level of attention people pay to a post’s context and their trust of mainstream media institutions. More aware of contextual elements Some people were more likely than others to factor in contextual cues like source, date and reactions about a post as cues of credibility. For example, when asked to consider the credibility of a Facebook post depicting a “mutant creature” from Chernobyl, some people paused to consider whether the source was credible or noted the laughing reactions as an indication that this post was intended for entertainment. They were confident in using these details to investigate whether or not they thought a post was credible. Less aware of contextual elements, more visual-centric Other people were more emotionally reactive to the visual in the post, interpreting it at face value. They read just enough of the headline and description to get an understanding of what was in the picture, then focused solely on the visual, using their personal experiences for insight into the post’s credibility. Even when probed to talk through how they would fact-check whether or not the post was accurate, they sometimes ignored details like source completely. Though we observed meaningfully different baselines of analytical thinking and digital literacy, we sensed some fluidity between these categories depending on the context. If an issue was interesting and surprising enough, someone might shift into a more critical assessment than they would for a post that they didn’t care about. We observed a division between people who want to strengthen and preserve traditional mainstream media institutions, and people who might abandon them entirely in favor of alternative media providers. More trusting of mainstream media institutions Some people were more likely to trust what they perceive as fact-based reporting by news outlets they were familiar with, such as CNN and The New York Times. They were wary of sensational, outrage-based posts from individuals and lesser-known, hyper-partisan news outlets. Posts with words like “shocking” immediately triggered skepticism, compared to a matter-of-fact “newsy” stylistic tone, which they perceived as more objective. Less trusting of mainstream media institutions Other people we spoke to were skeptical about the credibility of all news outlets that report on political issues. They believe all outlets are biased and cherry-pick content toward agendas under the guise of objectivity. This distrust was often applied across political lines, with outlets as different as Fox News and The New York Times being regarded with skepticism. This anti-media sentiment has been noted by previous research, such as the 2019 Poynter Media Trust Survey , which reported 53 percent of respondents as having a negative or very negative view of mainstream media institutions. People with less trust in mainstream media institutions either said they follow a variety of news outlets to balance out any perceived bias, or they were so jaded by these news outlets that they depended on their own local communication channels and alternative media streams. They were more likely to trust sensational language and vivid imagery as cues that a post was local and authentic. Importantly, we saw that these two factors — the behavioral tendency to be more or less aware of photo context on social media, and degrees of trust in news outlets — could interact, creating unique sets of needs that we separated into four categories: Distrustful news skeptic (low trust, high awareness): Seeking to call out bias in mainstream media, a person in this category may use motivated reasoning to find any evidence to confirm their belief that the media is pushing a particular agenda. Building trust in specific news outlets is difficult in these cases: it may be part of a person’s identity to be skeptical of mainstream media and hyper-alert to perceived cues of bias. Importantly though, this skepticism applied more to the editorial framing of a story than a complete denial of facts, such as when and where a picture was taken. Confident digital news subscriber (high trust, high awareness): A person in this category is digitally savvy and is comfortable distinguishing between true and false news when provided information from news outlets they trust. They want to avoid appearing uninformed or misinformed about news issues. Media-jaded localist (low trust, low awareness): This person may feel marginalized by mainstream media and uncritically accept hot takes from unofficial accounts as truths. They want news that feels local and authentic, but they don’t want to be misled by false information intended to deceive. Additionally, they need clearer cues to identify false and misleading content from unofficial accounts that they trust in good faith. Late-adopter media traditionalist (high trust, low awareness): A person in this category may be more comfortable learning about news through older mediums such as television or newspapers, but less comfortable making sense of news online within the noise of social media. On this front, people need more education on misinformation and disinformation tactics, as well clear cues to more readily distinguish credible content from media sources they already trust. [ Read more about the work The News Provenance Project is doing .] From this preliminary framework, we identified at least two clear classes of news consumers that would benefit from provenance information for news photography: those who trust the media, but lack the baseline digital literacy to reliably assess the credibility of posts, and those who are already confident in their abilities to distinguish credible news photography, but would benefit from even more context to factor into their understanding. For those with less trust in the mainstream media institutions, the challenge might be greater. Yet even in these cases, news outlets have an opportunity to provide clear cues about the origins of news photography and show their journalistic process as inroads to trust. Revisiting the initial assumption from the IBM Garage design thinking workshop — that news consumers find it difficult to trust the authenticity of images they see online — we learned that the real issue is that news consumers most often fail to critically assess a visual because their relationship to social media is one of entertainment and connection-building, rather than fact-checking. This can lead to error-prone leaps in judgment within a context of information overload. In the case where people distrust a post on a contentious topic, such as immigration or politics, that doubt can come from a perception of editorial slant in the framing of the story, rather than a fundamental rejection of primary details of the post. These findings point to more nuanced ways to think about how to surface provenance information for visuals that intervene with the spread of misinformation. People do care about what’s true, however they arrive at an understanding of truth in different ways. Some people place more weight on mainstream media institutions, while others turn more to voices that feel personal and speak to their direct experiences. Earning trust from people who have become disillusioned by mainstream media is a hard, long path, but there are simple steps at hand to help: Publishers have an opportunity to build trust photo by photo by providing more clear, prominent cues about what their photojournalism represents. In this way, publishers can provide clarity to readers in the moment by providing transparency into what they know and how they know it. To learn how we used this research to develop a blockchain-based proof of concept for displaying source information about photojournalism on social media, read Part Two . Emily Saltz is UX Lead for The News Provenance Project in The New York Times R&D Lab. Find her on the Internet @saltzshaker, trying to keep up with the latest critical tech hot takes. How we design and build digital products at The New York Times 103 1 Journalism Design Design Thinking Blockchain UX 103 claps 103 1 Written by How we design and build digital products at The New York Times. Written by How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-01-27"},
{"website": "NewYork-Times", "title": "can publishers use metadata to regain the publics trust in visual journalism", "author": ["Sasha Koren"], "link": "https://open.nytimes.com/can-publishers-use-metadata-to-regain-the-publics-trust-in-visual-journalism-ee32707c5662", "abstract": "Code Data Product and Design Workplace Culture Work with Us “The thing about photos is that they carry with them a lot of credibility. Someone took a picture of something! The fact that you can have a genuine photograph, but the way it’s being used is bogus — that’s interesting.” These are the words of Roger (not his real name), an avid newspaper reader and TV news watcher who also keeps up with the news through Twitter. Roger was generally aware of the prevalence of misinformation on the internet, but he was surprised to learn that it affects the photos he sees — and that he could easily believe images that are accompanied by false information. Roger’s realization came during a conversation with Emily Saltz , a user experience researcher and designer for The News Provenance Project . Emily had been showing him an example of a social media feed where photos had been posted with inaccurate information about the events shown. His reaction was far from unusual in the more than 30 interviews Emily did as part of our research into how American news consumers from a variety of backgrounds and political leanings make sense of the images they see online. That it is easy for people to be swayed by fake content should come as no surprise. The arenas in which news and information appear these days are messy ones, with social media platforms making no visible distinction between legitimate posts and deliberately misleading ones. Almost every major news event brings a new set of examples: as Buzzfeed News reported in the last few weeks, multiple instances of misinformation emerged both after a United States airstrike killed a top Iranian general and after Iran retaliated with airstrikes on American military bases in Iraq . And critically, misinformation continues to disrupt elections around the world, as it did in the run-up to Britain’s general election last December, and threatens to interfere with the United States presidential race this year. What might clear up this polluted environment? And how can news outlets help audiences better understand the legitimacy of what they publish? While there is no one-size-fits-all solution, the urgency for creating effective interventions continues to grow. We launched The News Provenance Project in mid-2019 to address the misinformation crisis through a product and reporting lens. Our goal was to contribute to the work of a growing number of organizations and projects addressing this issue. The initial idea was that publishers could contribute to creating a healthier information ecosystem by surfacing information they already have about the work that they publish. Our main hypothesis was that adding context to news photos — in the form of metadata, with information that is often contained in a caption, but gets stripped out as a photo travels beyond a news outlet’s own sites and apps — might help people make better decisions about the credibility of the images they see on social platforms and elsewhere around the internet. Today we are publishing the results of the research we conducted , and a few examples of best practices for designs that help people better understand what they see. A key component in that research is a proof of concept, which we’re also making available today . The News Provenance Project team, working out of the New York Times R&D Lab , built it as an example of how our hypothesis might be realized, and we developed it in response to several rounds of user testing. We also explored the feasibility of publishing the data associated with each photo, from which that context is derived, on a blockchain (more on that below). As we develop plans to expand our work in 2020, we hope that sharing this research might also inspire others to build upon it. But first, a bit of background: In addition to serving as a visual example of how provenance information could be added to the presentation of photos, the proof of concept gave us an opportunity to experiment with blockchain as an emerging technology, one that lends itself well to the features we wanted. As a database, a blockchain can provide network members increased confidence in the reliability of its data, due to its enhanced security in the way it stores that data, which makes the records published to it more or less immutable. It also ensures transparency of all “transactions,” or updates to the records stored in the system, so that any major changes made to a record would be recorded and visible. In addition, it offers shared ownership of a database among a number of entities — in this case, publishers. Here’s a hypothetical scenario on how those properties could become useful: Let’s say five news publishers agreed to participate in a network and publish some or all of their photos through a News Provenance database. All five, and potentially also the public, would be able to see the metadata of the others, as well as any changes made to those photos after their publication. Those changes would not be alterable by anyone. The News Provenance team — mainly Emily Saltz and Pooja Reddy , a product manager at The New York Times — worked with technologists and designers from IBM’s Garage to build the proof of concept on IBM’s blockchain platform, which uses Hyperledger Fabric, an open-source blockchain technology. We set up the basics of a data structure and a network and refined the designs, then published a number of photos and their metadata to the database. That work is behind-the-scenes of the proof of concept. [ Go behind-the-scenes into the research, design and prototyping behind The News Provenance Project’s proof of concept .] From the user’s perspective, there is no discernable sign of how the data is stored. In our original hypothesis, we guessed that those properties, if represented clearly to users, could encourage their trust in both the legitimacy of the photos. However, we learned from the people we interviewed that words like “immutability” and “encrypted database” were not important factors in establishing trust and confidence. If we were to build out such a network in the real world, we’d need to explore the feasibility on a few fronts. The operating speeds may not be as fast as we would need them to be and costs might be high, which are two barriers to news organizations, especially smaller ones, for whom slow speed and high expense might be prohibitive. And a system of governance would need to be put in place so that all the organizations on the network agreed to work with it in the same way, both in the data they would provide with each file and how they would represent it on their own sites. We don’t expect that a layer of additional information alone will be enough to change the minds of people who distrust a given news brand, or that it will help them completely avoid being swayed by false context and manipulated media. But it could help. Along with the reactions garnered in our own research, there are other signals that transparency helps readers. According to Trusting News, a project that has done research and training for newsrooms on what helps readers trust news outlets, labelling and explaining the journalistic process are two ways that can help engender audience trust . Critical information that typically goes into a photo caption, such as time, date, location and the accurate identification of people and events shown doesn’t travel with a photo when it’s posted to social media, where it can be reposted with egregious inaccuracies. News organizations have this information. With a bit of work and some thoughtful designs, we could use it to help platforms and, more importantly, news consumers avoid inaccurate uses. Our proof of concept only focused on the point at which a photo is published. To ensure that the verification work done by reporters, photojournalists and their editors is not lost once a photo gets shared on social media, we need innovation at every stage of the process, from photographing (or capture) through publishing, through distribution. However, to put it simply, this is easier said than done. To give a sense of what it would take to realize the full vision of surfacing provenance information on news photography, we’d need changes at every step of the process, from the time a photo is taken, to every instance of its publication and display. In brief, an ideal set of changes would be for: Camera makers to help photographers ensure time, date and location settings in cameras are exact. Every news publisher to modify their management processes for photo metadata so that they adhere to a common set of standards, such as those maintained by the International Photo Telecommunications Council (IPTC) . All platforms such as Google, Facebook, Twitter and Apple, as well as chat apps like WhatsApp and Signal, to ensure the consistent display of this information. Within this big and complex endeavor, a proof of concept is a small drop in a very big, complicated bucket — but before taking bigger steps, our goal was to explore its feasibility, including how it might resonate with real people who encounter misinformation online every day. We’ve seen that it could have an impact with people of varying ages, from different geographic locations and party lines. We are eager to bring it to life with further experimentation in the future. The News Provenance Project is grateful to a number of people who contributed to our work in 2019: IBM’s Garage team were excellent collaborators who worked with us on the design and implementation of our ideas. Bernat Ivancsics , a PhD candidate in communications at Columbia University School of Journalism, joined our small team as summer fellow through the Brown Institute of Media Innovation . Having done earlier work on blockchain in journalism , Bernat came with a depth of knowledge and a breadth of thinking about the topic, and helped us grasp the wider context and the workflow considerations. Bhaskar Ghosh , a dual-degree masters candidate in journalism and computer science, also at Columbia, was also a summer fellow through the Brown Institute. His work on a Chrome extension that could surface metadata as an overlay on photos on twitter provided an initial visualization at a time before we had any designs, and demonstrated another potential route to the display of provenance. He also explored the technical feasibility of identifying publisher photos and researched perceptual hashing and computer vision algorithms. Niko Koppel , a visual journalist and photo editor who works on the Times R&D team’s 5G projects , provided photos of scenes he had shot while on assignment, as well as critical insight into the photo assignment and editing process. Representatives from several news organizations, including the AP, Wall Street Journal, Hearst and others, contributed to a design thinking workshop in the spring out of which came the initial ideas and problem statements. Sasha Koren is an independent editorial consultant who has served as project lead on The News Provenance Project. Previously, she was the editor and co-lead of the Guardian Mobile Innovation Lab and held a number of digitally focused roles in The Times newsroom. How we design and build digital products at The New York Times 65 User Experience Blockchain Journalism UX Design Thinking 65 claps 65 Written by Journalism things. Past: Editor @GdnMobileLab,@nytimes community/social, features, opinion etc. How we design and build digital products at The New York Times. Written by Journalism things. Past: Editor @GdnMobileLab,@nytimes community/social, features, opinion etc. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-01-22"},
{"website": "NewYork-Times", "title": "what if every news photo on social media showed contextual information", "author": ["Emily Saltz"], "link": "https://open.nytimes.com/what-if-every-news-photo-on-social-media-showed-contextual-information-8936cf4e8c45", "abstract": "Code Data Product and Design Workplace Culture Work with Us This is part two of a behind-the-scenes look into the research, design and prototyping behind The News Provenance Project’s proof of concept that shows how publishers could use blockchain to surface source information about news photography. Read part one here . How might news outlets leverage blockchain technology to surface the source information for news photography? This is a question we set out to explore at The News Provenance Project , which is a part of the New York Times R&D Lab. After speaking to 34 users total over one round of discovery research and two rounds of prototype testing, we learned how news consumers decide whether to trust a photo on social media. We used these findings to design a proof of concept to explore how news outlets might provide provenance information for news photography on social media platforms. First, as part of our discovery research, we conducted in-depth interviews with 15 daily users of social media from different backgrounds and geographic locations, and with diverse news preferences. During these interviews, we elicited reactions to several design concepts around surfacing the provenance of news photography. Each concept framed provenance slightly differently: from a “verified” checkmark, to an emphasis on verification by a network of major news organizations. We also asked them to rank metadata by what information most convinced participants that an image was credible. Here are some of our findings: A checkmark isn’t enough information to provide credibility Participants explained that a checkmark — similar to what appears on verified accounts on Twitter and Facebook — did not give them enough information to feel confident about what was being verified. The concept showing a simple checkmark was the bottom-ranked choice for nearly all of our participants. Frame as “sourced” instead of “verified” While many participants said they found confidence in the word “verified,” a concept framed around the word “sourced” was more successful with the majority of our participants. They valued having more information that they could follow up on themselves, rather than an endorsement that a photo was verified by others, without more information about what it meant to be verified. Multiple pictures build more confidence instead of the edit history of single picture In one of our concepts, we showed a feature that displayed the edits, such as a change in color contrast, made to a photo. Several participants noted that they didn’t need data this detailed unless they had reason to believe the edits dramatically altered what the photo represented. In contrast, they noted that other related pictures or videos from the scene would give them more confidence that an event occurred. Emphasize familiar photo metadata that’s easy for a consumer to understand In an exercise where we asked participants to rank photo metadata according to what they thought was most useful, they chose familiar details such as “source,” “original caption” and “publication history” over more technical and unfamiliar terms, like “encrypted” or “stored in an immutable database,” that are relevant to blockchain technology. Show the process, with evidence of oversight and accountability In another exercise, we asked participants to compare and discuss a selection of common credibility indicators, such as the Nutrition Facts label and the USDA organic icon. Because these indicators are connected to organizations that provide oversight, participants told us they inspired confidence that there would be consequences for failing to comply with standards. What this indicated to us is that a provenance signal for news photography could provide assurance that an umbrella organization is responsible for ensuring transparency and accuracy. If a provenance signal fails a user once, they may not fully trust it again. A signal that uses language like “true,” rather than “sourced” may fail in breaking news cases or if a correction is needed later on. To build trust, we should clearly emphasize what is known about the history of a photo, rather than offering a guarantee that a photo does or does not represent the complete truth. We incorporated these findings into a prototype that included visuals with and without a provenance signal, as well as fake ads and other elements to simulate a real social media feed. The provenance signal we designed was a label overlaid on the photo, which expanded to show more information about the photo’s metadata, publishing history and related photos captured of the same event. We conducted two rounds of testing, first with a group of seven people, followed by iterative design changes and a second round with 12 frequent users of social media. The content in our prototype fit into two main categories: “hard to believe, but true” and “false context.” We wanted to know how source information could influence the perceived credibility of dramatic but accurate “hard to believe” photos. We also wanted to know what participants thought about “false context” posts, where the social media poster claimed a photo showed one event when it actually depicted another. [ Read more about the work The News Provenance Project is doing in this overview .] We had participants complete a series of tasks that were designed to help us understand the usability and comprehension of the provenance signal, as well as how our participants made judgements about a photo’s credibility. People trust photo source details, even if the perceive an editorial slant in a headline In our discovery research, we’d spoken to many people who have low trust in mainstream media. We wondered whether that distrust would inform how people view individual news photos even if the source information was visible. Encouragingly, this is not what we observed. There was almost no skepticism of the surfaced source information, though people did express skepticism about perceived editorial slant. This is promising, as it meant that people with low trust in mainstream media institutions could still trust basic facts of a news photo, even in cases where social media users apply false context. When source information is provided, “hard to believe” photos become easier to trust Including source information on photos on contentious topics, such as immigration, did not affect most participants’ confidence in the veracity of the photos. If someone did express a lower confidence in a photo, it was because of an unknown source or because a photo “looked photoshopped.” Providing source information on some photos doesn’t completely discredit others We wondered whether the presence of source information on some photos but not others might delegitimize credible news publishers without access to these provenance tools. We did not find support for this. Some posts, such as a cat picture, were completely trusted even without a provenance signal. Other posts, such as a news story about a flood, were largely still found credible even without signal, though some people expressed that the signal would have made them more confident. This indicates that the use of a signal like this would not necessarily damage the credibility of amateur photographers and credible outlets who don’t surface photo metadata, but could instead act as an incentive for publishers to use in order to increase audience confidence. Perhaps most encouraging of all, many people expressed unprompted enthusiasm for the concept: they appreciated having convenient access to details about the origins of a photo and its context, and reflected on times they could have used it to confirm ambiguous visuals on Facebook or Twitter. Many people didn’t discover false context at all Unless explicitly pushed to consider a post’s credibility, almost all the people we spoke to glossed over the details in the source information. Even if they noticed the photo source peripherally, they assumed the source must match what the social media poster had written about the photo. We realized we needed clearer cues that were more prominent for people to include the source information in their judgement of a photo. It was hard for people to comprehend why there would be false context Many participants expressed confusion when the details didn’t match the post’s description. They didn’t quite understand how that dissonance could happen, assuming it was an accident or a technical glitch. We realized the signal needed to factor in the potential of photos shared with false context. The shorter signal made participants overconfident In one version of our prototype, we displayed the photo source information in a tab that people needed to click to expand (only the name of the news outlet was visible). The name of the source provided enough proof to some participants that they believed that a post was accurate, even if it had been miscaptioned. Many people noted they would not have expanded the source unless they were motivated to learn more. This risk was less likely with the longer signal, where more details were presented on the surface. More editorial history and related articles The people we spoke to were less interested in seeing the history of how publishers used a photo and more interested in having access to other headlines, captions, summaries and links about the event depicted in the photo. This tied back to our earlier findings that interest, more than truth-seeking, drives user behavior on social platforms. People want more context because they are interested in a story, not because they are trying to prove whether a photo is real. The lessons we learned from our discovery research and prototype testing informed how we built a blockchain-based proof of concept, which is available to view on our website . Our changes included drawing more attention to details that could inform a person’s gut reaction, like age and caption of a photo. We also incorporated prompts and resources to support more critical thinking, and to help people make sense of potential dissonance between a mis-captioned photo and its original context. Finally, we provided more photos and article links related to the event depicted in a photo to help people explore a story more on their own. This proof of concept was created as a provocation to show publishers that it is possible to use the journalistic work they already do to promote clarity in public discourse. Yet, there are still many open questions for how publishers might further expand on this work to address problems of misinformation and trust in news photography online. Providing basic source information for visuals is relatively low tech, yet we see the potential to build an entire system that connects accurate source information for all images, from point of capture to publication and distribution across the internet. We hope that these findings can also serve as an encouraging starting point for other publishers looking for ways to use metadata to build trust, helping audiences believe in what they see in credibly sourced visual journalism. To learn more about the user research and design we did for this project, read Part One . Emily Saltz is UX Lead for The News Provenance Project in The New York Times R&D Lab. Find her on the Internet @saltzshaker, trying to keep up with the latest critical tech hot takes. How we design and build digital products at The New York Times 94 Journalism UX Blockchain Design Design Thinking 94 claps 94 Written by How we design and build digital products at The New York Times. Written by How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-01-22"},
{"website": "NewYork-Times", "title": "5 questions with bailey richardson", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/5-questions-with-bailey-richardson-e533e9f9d5e0", "abstract": "Code Data Product and Design Workplace Culture Work with Us On November 21, Bailey Richardson , co-founder of People & Company and author of “ Get Together ,” stopped by The New York Times with her colleague Kevin Huynh to talk about their research on what makes communities thrive. We caught her afterwards to talk more about her career, her time as one of Instagram’s first 10 employees and what makes a long-lasting community. This interview has been edited for clarity and length. 1. Where did you start your career, and how did community building and engagement become the focus of your work? At the start of my career I had no idea what I wanted to do professionally, but I did know that I wanted to be around creative people. So, I found my way to an unpaid internship at the San Francisco Museum of Art, but I realized that working in an art world institution wasn’t right for me. I wanted to be on a smaller team where I had more freedom and agency, so I went to work at a startup that sold art, including photography, online. In 2011, I began to notice that young photographers in San Francisco were turning to a new app called Instagram to share their work. I emailed the early Instagram team and we met for coffee. Eventually, I joined the company as one of the first 10 employees on the community team. Our community team acted as the conduit between the people using Instagram and the people making it. My favorite part of the work was foraging for exceptional Instagrammers. I’d spend hours combing the site for interesting and creative people around the world. We would spotlight these Instagrammers on the Suggested Users List, our blog and the main Instagram account to show what Instagram was all about. Instagram gave me my first taste of intentional community building. The early days at the company felt like we were building the platform with our most passionate users, not for them. It was a deeply collaborative experience that felt radically different from what I sensed more traditional business and customer relationships were like. After leaving, I wanted to learn more about communities — how they start and grow — and I began doing research with two partners, Kevin Huynh , and Kai Elmer Sotto . We interviewed as many people as we could about what makes a good community, and we gathered our findings into a book called “ Get Together: How to build a community with your people .” 2. Community is a commonly used word that can mean different things to different people. How do you define community and the value of it? Today, the meaning of “community” can feel ambiguous. It’s become a euphemism for groups of all kinds, including an audience or a user-base. But authentic communities are simply groups of people who keep coming together over what they care about. The most vibrant ones offer members a chance to act on their passions with one another. In the research we’ve done with hundreds of extraordinary clubs, networks and societies, there was one big takeaway: the secret to getting people together is that you must build a community with people, not for them. The implication of this small change of approach is simple yet significant. Alone, we are limited, but with others we extend our capacity. If you join forces — as artist and fans, organizer and advocates, company and customers — you can do more together than you ever could alone. (Plus, you’ll likely have more fun in the process!) 3. In your book, “Get Together,” you discuss building communities with people, not for people. What’s an example of a successful community that embodies that ethos for you? One community that I fell in love with recently is GirlTrek. GirlTrek was started by Morgan Dixon and Vanessa Garrison to empower black women and girls to improve their overall health by walking. In 2010, Dixon and Garrison challenged the women in their local community to commit to walk at least 30 minutes per day for 10 weeks. The challenge caught on, with hundreds of women participating across the country. Eventually, the two women created a Facebook group called “GirlTrek: Healthy Black Women and Girls” for trekkers to connect and share stories. Today, the GirlTrek community has over 200,000 members who participate in weekly neighborhood walks and longer treks. Dixon and Garrison’s team connects groups of walkers in neighborhoods across the country. One group recently completed a 100-mile walk along the Harriet Tubman Underground Railroad Byway GirlTrek is an in-person community, but they’ve used digital tools to train, connect and empower leaders around the world to extend what was once a very small, local effort. In that, they’re an example that individuals and organizers can look to for inspiration. If you’re hungry for more business-focused examples, I suggest checking out what companies like Notion , Instant Pot and Girls’ Night In are up to. 4. You outline three key stages of building a community: getting together, sticking together and growing together. What stage can be the most difficult to navigate? The challenges differ whether you’re an organization or an individual. Organizations struggle with sticking together. A community, by our definition, is a group of people that keeps coming together. If companies want to build communities, they too will need to keep showing up, and they will need to be consistent if their community is going to stick together. Some organizations are willing to make a long-term investment like that. Others are not. The ROI of community investments can’t be measured as immediately or evidently as other tactics like advertisements. Priorities, leadership and KPIs can change from quarter to quarter, which can start and stop their community investments and erode relationships with their most passionate people. This keeps communities supported by organizations from building momentum and reaching their potential. For individuals organizing grassroots communities like basketball teams or interest-based Slack groups, the challenge is often the final stage: growing together. Growing a community isn’t about management, it’s about developing new leaders. I’ve seen many individuals who organize grassroots groups struggle to shift their perspective from building everything for members in the early days, to building with members as the group grows. But if a group’s founder can train the most passionate, committed members to be new leaders of the group, that community will reach more people and sustain itself longer than the original founder could have managed on their own. 5. What do you think are the emerging generation’s expectations of community? The internet has transformed our expectations for how we relate to one another. Our communication with faraway organizations used to be one-directional. Audiences were on the receiving end of marketing, advertising and product development that were controlled by organizations. Our relationships are no longer so simple. People who grew up with the internet expect to not only voice their opinions, but to be acknowledged for doing so; These are two-way relationships. We see companies like Twitch and LEGO share the designs and thinking behind new products with passionate users before the products ever ship. And we see superfans of TED, Notion and Rapha raise their hands to host events on behalf of those organizations (as TEDx organizers, Notion Pros and Rapha Clubhouse ride leaders, respectively). This demand for more participation will be a big shift for all types of organizations — from businesses and nonprofits, to independent and political groups. Organizations will have to change their mindset from assuming they can control all of the interactions with their brand, to empowering communities of customers and users to drive interactions themselves. This change, while daunting at first, is also a great opportunity for those who can invest in it. Organizations that develop the capacity to build with their customers, users and advocates will be able to grow and diversify their impact in a more authentic way than they could have alone. How we design and build digital products at The New York Times 112 Community Conversations Audience Social Media Instagram 112 claps 112 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-12-04"},
{"website": "NewYork-Times", "title": "take notes lessons from a project management internship", "author": ["Madison Flanders"], "link": "https://open.nytimes.com/take-notes-lessons-from-a-project-management-internship-9745ebdb9fdb", "abstract": "Code Data Product and Design Workplace Culture Work with Us One of the most memorable parts of my childhood is flipping through the stack of New York Times newspapers my dad kept on his desk. I would strike pages with a red crayon pretending I was a mean newspaper editor whose writing staff just wasn’t up to snuff. At that time, I would never have guessed that years later I would get the opportunity to intern at the paper I had destroyed with red crayon. When I was little I always thought I would be a reporter, which isn’t surprising considering most 7-year-olds don’t know about project management. In fact, even when I first started at The Times, my project management knowledge began and ended with scrum ceremonies. I had no idea about all of the intricacies that go into such a pivotal role. While I learned a lot during my internship, I walked away with five big takeaways that I think would be helpful to any incoming intern or project manager. My internship with The Times was in technical project management. This was a new field for me and it was terrifying, to say the least. During the first week of my internship, I would leave meetings feeling as if everyone had been speaking a foreign language. When I was at the point of feeling like I was drowning in unfamiliar technical acronyms, I started taking notes on everything going on around me. When I wasn’t in meetings I would research different programming languages, map out our stakeholders, read every wiki relevant to our project and even work on a glossary of those pesky acronyms (if someone emailed about SQL I wanted to be in the loop). I realize now that letting myself feel overwhelmed was what forced me to take action. I knew that I would probably not learn any backend programming languages over the course of my two-month internship, but understanding the general concepts would take me farther than I could imagine. By taking things one step at a time, I found that I learned things I didn’t think I could. I always thought a “manager” should dive right in and start telling people what to do. It never occurred to me that one of the most important parts of starting a new job as a project manager would be to take a step back and really listen to the whole team. Listening to members of the team can highlight gaps in the team’s process, which in turn can assist the product manager with prioritization. Evaluating the team’s health is a project manager’s first priority, and understanding each team member’s mindset when it comes to their work can be essential in ensuring your project runs smoothly. If you were to search the words “project manager” on the web, you would most likely find the word “organized” in the search results. That’s because it is a project manager’s job to keep track of all of the moving parts in a project. This may sound easy, but when you have internal and external stakeholders, plus the members of your team coming at you from all directions, it can be quite the challenge. It’s good to have a system in place so nothing gets lost. One thing I learned pretty early on was to save everything. You may not think that brief email from a team member is important now, but trust me, there is nothing worse than being in a meeting and having to explain you deleted a resource that may be vital to the project. It’s easy to believe that your team of highly skilled engineers is close to perfect, especially when they rarely have tech debt and love going to scrum ceremonies. But even for perfect-seeming teams, everything can be improved upon. Through my experience shadowing project managers at The Times, I learned these iterations can lead to improvement and innovation. Every team I had the chance to meet had their own way of iterating on process and not letting mistakes go unnoticed. Through learning reviews or long discussions in their retros, they always found different ways to improve. Great communication between team members requires constant tweaking and is something to actively monitor — building a strong community takes time. With that being said, the best advice I could give to an incoming project manager is to put processes in place that will continue to pay off. The teams I shadowed during my internship had project managers who worked to bring people together. Whether they scheduled monthly surveys to check in on team health or created fun traditions in their scrum ceremonies (like playing a game at the beginning of each retro), the project managers established processes for team building. My summer internship at The Times helped me grow exponentially. Getting to understand the intricacies of what goes on in the background of a project, as well as the ins and outs of a role in project management will always serve as a great foundation for my career. I’m glad to have had the opportunity to collaborate with some of the teams at The Times, and to learn the true value of building a strong community within a team. Madison Flanders was a 2019 project management intern with the Technology department at The New York Times. How we design and build digital products at The New York Times 12 Project Management Organizational Culture Internships Work Workplace Culture 12 claps 12 Written by How we design and build digital products at The New York Times. Written by How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-12-06"},
{"website": "NewYork-Times", "title": "looking forward to 2020 here are 10 themes for news", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/looking-forward-to-2020-here-are-10-themes-for-news-166d84125172", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Kourtney Bitterly, Meg Fee and Thomas Mitchell How are people using established and emerging technology? How do they use technology to understand the news? As a research team made up of designers, software developers, researchers and writers at The New York Times, we interview consumers and experts to find answers to these questions. In our human-centered design research process, we believe that in order to grasp how media is evolving, it’s important to start with people. In 2019, we traveled. Our research took us to people’s homes in Vancouver, Minneapolis, Detroit, Delhi and many places in between to better understand people’s needs and behaviors. We explored areas such as the increased use of voice assistants, group texting, audio habits and wellness. Research participants gave us a peek into their lives. We watched how people use their social media accounts, we listened to podcasts alongside them in their cars and we sat in their kitchens while they asked Alexa for the weather forecast. No matter where we spoke to people, certain themes continuously came up regardless of the topic we were researching. We looked at these themes through the lens of news, but they are indicative of how people consume content and use technology. We’ve collected 10 of our top themes and are sharing them below and as a downloadable packet . Everywhere people turn, there are curated lists and carefully tweaked algorithms telling them what to read, watch or listen to. It can feel like there’s a never-ending list of recommendations to sort through. In a hyper-connected world where time can feel like it’s in short supply, people want to know that their time will be well-spent. They don’t want recommendations that simply replicate what they have previously consumed, they want to discover new things. While algorithms can offer interesting suggestions, nothing beats the recommendations from co-workers, family and friends. Personal recommendations, which are the product of ongoing personal conversations, allow for the discovery of new content to feel seamless and nuanced. Content that is available on-demand means people can watch and listen to whatever they want whenever they want it. But there’s something lost by the fragmented nature of how people now consume that content. If everyone is watching or listening to something different, connection over shared experience can be harder to achieve. When people watch or engage with scheduled content, the experience becomes a ritual and the content becomes a cultural touchpoint. We see this when people join thousands of others for live Peloton rides, or when people check their favorite music streaming service for new music every Friday. And who can forget those few weeks in April and May when it seemed like everyone was talking about the final season of “Game of Thrones”? The conversations about the content often feel as valuable as the content itself. Consistent programming facilitates these conversations — and ultimately fosters a sense of connection — by turning that scheduled content into an event. At a time when turning on the news or scrolling through Twitter feels like a firehose of information, the desire for contained stories is particularly acute. In what feels like a relentless and never-ending news cycle, people are hungry for a sense that they have reached the end of a story or that they have caught up on a topic. People are looking for content that has an endpoint, if not a succinct resolution. This is particularly true with developing news stories: people feel like they are often thrown into the middle of the story, without context of what has already happened. Through our research, we heard that people flock to true crime stories for just this very reason. Whether they listen to podcasts or watch shows such as “Dateline,” people said they enjoy the contained nature of the content: they know that that the mystery will be solved by the end. When it comes to news, people want that feeling of accomplishment, as well. In the United States, we heard from person after person who said they have turned off push notifications, exhausted by the constant demand for their attention. Many users are turning to voice assistant technology , like smart speakers, because it allows them to get the information they need without ever having to look at a screen. Notifications can feel intrusive and disruptive, but asking a smart speaker for a news alert allows individuals to get information on their own terms. The Americans we spoke to said they are setting boundaries in order to mediate the influence that social media has in their lives. People — particularly young people — told us they have deleted social media apps from their phones, but in reality, they have not totally abandoned these platforms. They might delete the Facebook app from their phone and check it in a web browser, or they might remove the Instagram app during the week and indulge only on the weekends. To the people we spoke to, this self-imposed friction feels like an attempt to regain and maintain control. During interviews, we often asked people to walk us through a typical day so we could learn how they consume news. We saw that the majority of people prefer to consume hard news in the morning, and less demanding content, such as a true crime or pop culture podcast, in the evenings. In the morning, they’re more willing to engage with the news that make them feel prepared for the day. But then the day unfolds with work meetings, child care, errands and seemingly infinite list of decisions to be made; People’s daily lives demand a lot of them. By the end of the day, they want content that is relaxing. Rarely do media organization take time of day and the cognitive load of their users into account when publishing content. But if organizations acknowledged these behaviors and surface content accordingly, they can meet users where they are. Similar to the shift we’ve seen in the farm-to-table movement around food sourcing and production, people want to know what goes into news production. In dozens of conversations with people around the world, we heard that people want more than just the story: they want to know why it’s being told, who is telling it and how it came together. News consumers want to pull back the curtain to understand why a headline was written a certain way, or why a particular story was featured over another on a home page. They want to know that specific information was verified by multiple sources, or that reporters pored over thousands of pages of documents for a particular story. The public hears claims of “fake news” just as often as people who work in media. When people understand the process and people involved in telling a story, they are more likely to trust it. People are looking for avenues where they can have more intimate conversations. They want spaces where they can truly connect with people, rather than passively follow people. The people we spoke to talked about moving away from “posts on the grid,” in places like Instagram, and status updates on Facebook in favor of one-on-one and small group conversations. The professionalization of social media, where it feels like everyone has to cultivate a personal brand, is less appealing for many of the people we spoke to. They are instead looking to Instagram stories and group texts because they feel like they can be more vulnerable and honest there. Most importantly, stories and texts are an invitation to participate in dynamic, real-time communication with other people in a way that static posts are not. Our research participants told us that receiving a private reply to an Instagram story feels more meaningful than a like on a post. To many people, what makes a platform social is not that it allows people to broadcast their opinions to the world, it’s that it enables intimate conversations among people they trust. As we talked to people in the United States, a common refrain we heard was that politics and morality feel so intertwined that people feel obligated not only to stay informed, but to have an opinion. In fact, people told us that the lack of an opinion — by celebrities, brands and news organizations — actually implies a political stance. Despite the rise of political discussion, people on both sides fear seeming out of their depth or being attacked for sharing a political viewpoint. People want to have those conversations privately with the people they trust. Group texts in messaging platforms like WhatsApp, Slack, iMessage and Instagram Messenger feel like far safer spaces to have nuanced political conversations. News consumers and news producers aren’t always aligned when it comes to how to surface content. Sometimes readers are interested in the most current information or the latest events, and sometimes they are seeking out a specific topic which may lead to more evergreen content. News organizations tend to surface the most recent content, but that often gets people only some of the information they’re looking for. This emphasis on the latest information puts more weight on what’s just been published and less weight on content that might help readers contextualize and make sense of an issue. In getting people the information they need and want, we need to think about how information fits into the bigger picture. Kourtney Bitterly is the Research Lead for the Product and Design Discovery team at The New York Times. Meg Fee is a Design Strategist with the Product and Design Discovery team at The New York Times. Thomas Mitchell is a Technical Strategist with the Product and Design Discovery team at The New York Times. How we design and build digital products at The New York Times 623 1 Journalism User Research News Design Design Thinking 623 claps 623 1 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-02-27"},
{"website": "NewYork-Times", "title": "how to present an easy to follow tech demo", "author": ["Angie Siu"], "link": "https://open.nytimes.com/how-to-present-an-easy-to-follow-tech-demo-d0ffce96c3b4", "abstract": "Code Data Product and Design Workplace Culture Work with Us A while ago, I worked on a simple side project to explore React’s Context API and higher-order components (HOCs), as well as the ES7 decorator syntax. While making this project, I read many articles and blogs that explained, or attempted to explain, these concepts and how to use them. Unfortunately, many of them were not very helpful. Some were too high-level and some didn’t help me make the logical connections needed to understand why things were done in a certain way. Others were so technical that I wound up spending so much energy and time wading through the jargon, that I didn’t even get to what I wanted to learn in the first place. Fortunately, not all of the articles were bad, and the ones that were easy to follow helped me build a solid understanding of the concepts I was exploring. I wanted to be able to do the same for other engineers at The Times, so I decided to present a step-by-step demo on how to use the things I learned at JavaScript+ Talks, a bi-weekly forum we have to present anything JavaScript-related. My presentation wound up being deemed the “standard for all presentations moving forward” by one of the forum’s organizers! (If you want to take a look, see my repo .) I’ve put together a quick guide based on my experience and the feedback I received that can help you ensure your demo is successful. This may sound obvious, but it is a great first step to understand what assumptions you’re making of your audience and whether those assumptions are valid. Did you assume that everyone already knew what Context was for? Or what an HOC is? Find out what knowledge gaps you need to fill. Also, what level of engineer are you making this for? Keep in mind that an associate engineer may not have been exposed to the same jargon or programming concepts as a senior engineer. Not everyone is going to understand why you’re doing things a certain way. For my demo, my audience needed to understand why I used Context in the first place. I illustrated that I had sibling components, ChildA and ChildB, that needed to share the same state and update at the same time. If we put state management in the parent component, we’d have to pass props into those children components. What if ChildA and ChildB were each nested 4 or 5 levels deep in other components? We’d have to drill those props all the way down! For each step, I explained the problem we were solving as well as provided a preview of the problem we would solve in the next step. To create this step-by-step organization of the code, I created branches representing each step in the process of setting up the project , creating the Context and Provider , using the Provider without HOCs , refactoring to use HOCs , and refactoring to use decorators . Now that you’ve presented the issue, demonstrate how your approach solves that problem; Make the logical connection so that your audience understands why you’re doing what you’re doing. For my demo, I explained that Context solves the problem of passing props down into deeply nested components by serving as the master state by which our components can get the information they need to function. People may ask why they should use your approach and not some other one they’ve used or seen. That’s normal. Acknowledge that there are other approaches, but explain why you chose yours. For the issue of passing props to nested components, I explained that I could’ve used Redux to handle state management, but I didn’t want to add so much overhead for such a simple app. Pretend that your audience does not understand a single thing you’re doing and add detailed comments to your functions. Even better, number those comments so that the reader knows the sequence of steps you took. Within each of my branch’s README, I wrote a top level explanation of the steps to follow and in what files, and also left numbered comments explaining what my code does. I also found that it’s helpful to provide a short summary of the walkthrough so that your audience can easily remember it before you go into the details of the implementation; for example, “In order to use Context, we must create it, provide it, and consume it.” If you feel like there’s someone else out there that has a better or extended explanation, provide a link to it. Chances are, your audience will also find it useful. These basic steps should help you develop an outline or framework for your demo. However, each demo is different and audience needs will differ, so ask your peers for advice and don’t be afraid to adapt the process. And if you have tips, please share! Angie Siu is a frontend engineer on the Inbox Engagement team at The New York Times. She’s a native New Yorker and spends a lot of time thinking about food. How we design and build digital products at The New York Times 110 Public Speaking Technology Work Code Software Engineering 110 claps 110 Written by Web Engineer @ The New York Times | Perpetual Food Fantasizer How we design and build digital products at The New York Times. Written by Web Engineer @ The New York Times | Perpetual Food Fantasizer How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-09-19"},
{"website": "NewYork-Times", "title": "we prototyped a news app to reach gen z readers", "author": ["Amine Toualbi"], "link": "https://open.nytimes.com/we-prototyped-a-news-app-to-reach-gen-z-readers-45e3c18977ba", "abstract": "Code Data Product and Design Workplace Culture Work with Us Every year, the Technology department at The New York Times hosts Maker Week, an annual five-day event that gives Times employees from Design, Product, Project, Marketing and Technology the freedom to learn, create and develop new products. Times employees are encouraged to take a break from their day jobs and spend the workweek collaborating with colleagues and diving into self-directed projects . Oftentimes, newsroom colleagues contribute to projects, and offer guidance and feedback. This year’s Maker Week was held in July, and Times employees took the time to explore many ideas, producing over 60 projects in the five-day event. We asked three colleagues to write about their projects. Jazz Lyles, a developer on the Games team, writes about an AR experience their team designed that highlights stories from overlooked and marginalized people. Romello Goodman, a software engineer on the Reader Guidance team, writes about the visual-first prototype he built that makes photos, not headlines, the main navigation for Times content. And finally, Amine Toualbi, a student who interned with the Android team this summer, writes about a product he built with a team of interns that caters to Generation Z’s news reading habit s. I do not read newspapers. I do not go on news apps on my phone and browse articles. I do not read lengthy pages about a specific event, unless I have a particular interest in it. I do not consume news the way it has traditionally been consumed. However, I do read the news on social media. I follow news accounts on Instagram and Facebook, and I consume my daily dose of news through pictures and short captions. When something interests me, I’ll do more research into the topic. The important point here is that I am not the only one who thinks this way. My generation, Generation Z, consumes news very differently than our older peers. For media companies like The New York Times, effectively reaching these younger audiences is both a challenge and an opportunity for growth. With that in mind, a group of New York Times colleagues and I decided to experiment with a possible solution for The Times’s Maker Week and came up with a visual-first landing page for Times content . Our concept for the project was to provide a gateway for younger audiences to discover the broader ecosystem of The Times. Using an Instagram-like interface with a feed and an explore tab, we focused on developing a visually rich experience that leverages Times photography. In essence, we wanted to develop a prototype where photos, rather than headlines, are the way users access Times articles. With a team of eight — six interns and two Times staffers — we focused on how Gen Z browses through content on social media. We concluded that users usually scroll fast through posts and pay closer attention if a picture piques their interest. Around this idea, we built a clear navigation flow for our app. Over the course of Maker Week’s five days of work, we sketched out a plan and set deadlines to deliver certain features and tasks. The three main areas of work were the retrieval of data from The Times’s database, the development of the backend in Python to relay that data and the development of the iOS app. The data engineering was assigned to Christina Indudhara and Viswajith Kumar, the work on the backend to Elizabeth Mieczkowski and Yanxing Yang, and the work on the iOS app to Times staffer Clint Mejia, Elizabeth and myself. I also officiated as the project manager with the help of Times staffer Kathleen Kincaid, who worked as an advisor for the project. Product design was handled by Spence Blood. We researched how The Times presents visual stories on its website, apps and social media accounts, and we looked at social media feeds like Instagram and VSCO for inspiration. After reviewing the different visual presentations, we had a clear idea of what the interface for our prototype might look like. Next, we had to develop our feature requirements. A lot of my peers and I tend to have short attention spans, and we move through social feeds very quickly. When I scroll through content and a post catches my interest, it usually takes only a couple of seconds for me to decide whether to continue reading or continue scrolling. Text that conveys the context of a post in a succinct way is what keeps me reading. On a platform like Instagram, links that go to content outside of the app can only be placed in the profile section of a user’s account, which means readers have to leave the feed in order to get more information about the post. Because of the steps needed to access the off-platform content, I usually continue scrolling and lose interest in that particular post. With these things in mind, we knew we wanted to create a prototype that combined the freshness and directness of social media with the spirit and aura of The New York Times. We wanted to create an app experience that presents strong visuals and easily accessible content in a way that keeps users’ attention. Our designer, Spence, was able to come up with an intuitive interface that matched the requirements gathered by the team. Ultimately, our goal was to create a prototype that caters to the behavior of Gen Z users. At the end of the week, we demoed our prototype to Times employees and it drew a lot of attention. Employees gave us interesting feedback, such as ways to implement a recommendation algorithm and different use cases we hadn’t considered. For now, the prototype is unfinished, but I hope it gets turned into a public-facing product some day. Coming into my internship at The New York Times, I was really eager to explore how I could contribute to the company and its mission. As a member of Gen Z, I was able to share my habits and lifestyle with my Times colleagues and present a new approach to deliver content. Being in control of designing the news for this project was very empowering and eye-opening to many aspects of product management and engineering I had not thought of before. I am really proud of my team and of the work we have done. I am really grateful to have lived this experience with some amazing people. Amine Toualbi is a college student at Southern Utah University. He is originally from Algeria, but was born and raised in France. He was a Technology intern with The Times during the summer of 2019 and worked on the Android Newsreader team. How we design and build digital products at The New York Times 121 Journalism Design Innovation Technology Audience Engagement 121 claps 121 Written by CS Student @ Southern Utah University. :-) How we design and build digital products at The New York Times. Written by CS Student @ Southern Utah University. :-) How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-09-26"},
{"website": "NewYork-Times", "title": "what if we used images to navigate new york times content", "author": ["Romello Goodman"], "link": "https://open.nytimes.com/what-if-we-used-images-to-navigate-new-york-times-content-5a6d87ab3688", "abstract": "Code Data Product and Design Workplace Culture Work with Us Every year, the Technology department at The New York Times hosts Maker Week, an annual five-day event that gives Times employees from Design, Product, Project, Marketing and Technology the freedom to learn, create and develop new products. Times employees are encouraged to take a break from their day jobs and spend the workweek collaborating with colleagues and diving into self-directed projects . Oftentimes, newsroom colleagues contribute to projects, and offer guidance and feedback. This year’s Maker Week was held in July, and Times employees took the time to explore many ideas, producing over 60 projects in the five-day event. We asked three colleagues to write about their projects. Jazz Lyles, a developer on the Games team, writes about an AR experience their team designed that highlights stories from overlooked and marginalized people. Romello Goodman, a software engineer on the Reader Guidance team, writes about the visual-first prototype he built that makes photos, not headlines, the main navigation for Times content. And finally, Amine Toualbi, a student who interned with the Android team this summer, writes about a product he built with a team of interns that caters to Generation Z’s news reading habit s. As the saying goes, you should never judge a book by its cover. But when it comes to choosing what to read on the internet, I’ve always had a tendency to read articles because of their cover images. So when Maker Week was announced, I knew that I wanted to create a project that highlighted the images The New York Times publishes. The goal was to create a version of The Times’s website that was just an image feed which users could navigate to discover stories. If you look around the web for examples of photo-centric sites you’ll see that most sites either load all of the images in a single column (like Instagram’s feed), or use multiple columns and sizes in what is called a Masonry design (like Pinterest). For this project, I decided to go with a Masonry design because it allows more photos to be laid out on the screen at once, and it creates a visual experience with more variety. But, the number of images can also be a downside when thinking about the user experience. If your app is constantly loading a large number of images, it can slow the page down as it tries to process the image requests. Nothing puts a damper on a web experience like a bunch of slow-loading images. This is even worse on mobile where there is often less power to handle these requests than a full-size computer. The design solution to help prevent slow-loading images is a technique called lazy-loading. As the user scrolls, the app checks to see whether each image is close the viewable screen and loads it. To the user, it looks as if the images magically appear as they scroll without the frustration of a slow experience. The best part about Maker Week is that we get to build things from scratch and have full control over the tech we use. The Times uses Node.js and React.js to render its pages on the server and client, so I decided to make that the foundation for my app. Because I only had five days to complete my project, I decided against writing my own Server-Side Rendering (SSR) logic and instead went with the popular SSR framework Next.js . Besides the ability to perform SSR, it provides other benefits like code splitting, webpack and ES2018+ support that overall gives you a production ready website right out of the box. With a foundation for how the React would be rendered, I had to decide on styling and chose to explore the popular pattern of CSS-in-JS and I used the library styled-components . The last part to figure out was where the data for the project would come from. Luckily, this ended up being easy because The Times has a robust GraphQL API. In only a few minutes, I was able to use the schema explorer to find my data and determine what pieces I needed. From there, I could put all of the pieces together. When the week was over, I was really happy that I had a fully functional prototype. If this ever gets built it would be a great opportunity for users to discover information by judging stories by their covers. Romello Goodman is a software enthusiast located in Washington, DC. At The New York Times, he works as a Software Engineer on the Reader Guidance team. How we design and build digital products at The New York Times 55 Journalism Design Product Development Innovation Technology 55 claps 55 Written by How we design and build digital products at The New York Times. Written by How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-09-26"},
{"website": "NewYork-Times", "title": "an experiment with ar technology that elevates hidden stories", "author": ["Jazz Lyles"], "link": "https://open.nytimes.com/an-experiment-with-ar-technology-that-elevates-hidden-stories-d7c48c84d009", "abstract": "Code Data Product and Design Workplace Culture Work with Us Every year, the Technology department at The New York Times hosts Maker Week, an annual five-day event that gives Times employees from Design, Product, Project, Marketing and Technology the freedom to learn, create and develop new products. Times employees are encouraged to take a break from their day jobs and spend the workweek collaborating with colleagues and diving into self-directed projects . Oftentimes, newsroom colleagues contribute to projects, and offer guidance and feedback. This year’s Maker Week was held in July, and Times employees took the time to explore many ideas, producing over 60 projects in the five-day event. We asked three colleagues to write about their projects. Jazz Lyles, a developer on the Games team, writes about an AR experience their team designed that highlights stories from overlooked and marginalized people. Romello Goodman, a software engineer on the Reader Guidance team, writes about the visual-first prototype he built that makes photos, not headlines, the main navigation for Times content. And finally, Amine Toualbi, a student who interned with the Android team this summer, writes about a product he built with a team of interns that caters to Generation Z’s news reading habit s. “Who are my people?” I often ask myself. As a black nonbinary transmasculine person, I’ve always struggled to find stories in history of people who share my experience. It’s not, of course, that they’re not there, it’s that their stories haven’t been told. With websites like the AAIHS’s Black Perspectives blog, and coverage like The Times’s Overlooked and 1619 Project , the historical record is being corrected. The cultural influences of people of color have been here from the beginning, and their stories are defining parts of our collective identity. I have always wanted to see an app in the world that could help connect me to those stories. When I pitched the idea of an app as a Maker Week hackathon project, I expected to pique the interest of maybe one other person who identified similarly. I was instead met with an overwhelmingly positive level of interest from people within my own team and from many other teams across the company. We united around the desire to forge a real connection to history — both a shared history and of our individual selves — and decided to own this project as a group. The team was made up of three engineers, three product designers, a video graphics designer and a director of program management who all brought their unique experiences to the project. We took what the idea meant to us and created two app prototypes to showcase what we could accomplish within a week. We decided to build a prototype of the mobile app as a technical proof of concept that people could interact with, and we also built a supplemental visual mock-up of the user experience using Figma, Photoshop and After Effects that showed the potential of the project. We wanted the app to be immersive and allow users to engage with black history in a way that connected past and present. We also wanted to experiment with augmented reality, so we designed an AR experience that delivers content relevant to historically significant locations. We drew inspiration from the 1619 Project and leveraged The Times’s existing Morgue photo archives , the Overlooked column and published stories — paired with audio and other research to create the content for our prototypes. Given that we only had five days to put these stories together, we decided to look within a few blocks of the Times building, hoping to discover some gems in the rich history of Manhattan’s Theater District. Just around the corner from the building, on 41st Street and 8th Avenue, we found the site of the first black kindergarten and home of Elizabeth Jennings , who desegregated New York City street carriages in 1891. A few blocks away, was the former site of the Casino Theater on the corner of 39th Street and Broadway, where “Clorindy: The Origin of the Cakewalk”, the first one-act musical with an all black cast premiered on Broadway in 1898 . In the visual prototype, we designed a geotagged mobile notification system that alerts users when they’re near a historically significant location. Tapping on the notification takes users to an immersive augmented reality audio-visual experience that allows them to see and interact with the story at that location. In the technical prototype, we used Viro React, an AR/VR development platform built on top of React Native, ARKit and ARCore to trigger stories with image recognition and create the user experience of interacting with the story landmark. To simulate a location interaction within the AR view, we used 2D historical images as life-size visual landmarks enhanced by narration and archival environmental audio in 3D world space. We created short audio narratives, combined with archival music and sounds, to guide viewers through the stories at each historical location. Creating an experience that evoked the time and place specific to the story was important to us. We designed both prototypes to give users the sense of walking through a living museum transposed on top of the real world. Each landmark invited users to dive even deeper with a detailed article view. Jazz Lyles is a QTPOC founder and UX Engineer passionate about innovative, creative and accessible tech. Afrofuturist, builder of warm and fuzzy inclusive experiences. Follow them on Github , Facebook and YouTube . Nicole Fineman contributed writing. How we design and build digital products at The New York Times 41 Augmented Reality Design LGBTQ React Native Black History 41 claps 41 Written by UX Engineer @ New York Times | I build cool things that help people. How we design and build digital products at The New York Times. Written by UX Engineer @ New York Times | I build cool things that help people. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-09-26"},
{"website": "NewYork-Times", "title": "how might the new york times sound on smart speakers", "author": ["Kourtney Bitterly"], "link": "https://open.nytimes.com/how-might-the-new-york-times-sound-on-smart-speakers-3b59a6a78ae3", "abstract": "Code Data Product and Design Workplace Culture Work with Us “Alexa, set a timer for 15 minutes.” “Hey Google, what’s the weather?” It’s likely that in the past year, you’ve heard someone talk about their smart speaker. Or you’ve heard a friend ask their smart speaker to play music, check the weather or set a timer. Maybe you have a smart speaker of your own. Whatever your relationship to smart speakers, it’s likely that you’ve been around one. According to a recent survey published by Voicebot.ai, one in four Americans own a smart speaker and that number continues to grow; smart speaker ownership increased by 40 percent in 2018 alone. Those numbers indicate that the smart speaker market is growing, but what does that mean exactly? How do people interact with the technology and what do they expect from it? If people want content from these devices, what kinds of opportunities might that offer for publishers? As part of the New York Times R&D Team, I set out to look beyond the statistics to explore some of these questions alongside my colleague Daniel Miranda, a design researcher on the Audience Insights team here at The Times. I’ve spent the last nine years working on research projects of all types, and have learned that design research is incredibly valuable when exploring nascent spaces. When the future is undefined, the best way to gain clarity is to spend time with users and understand their behaviors. The market is huge. There are voice assistants in smartphones and speakers, televisions and computers. They’re even in cars and refrigerators. Though it seems like voice assistants are everywhere, we decided to center our research on smart speakers in the home because they represent the most rapid adoption of the technology. Focusing on smart speakers allowed us to anchor our initial explorations in a technology that is familiar to most people — even if they don’t own a smart speaker. Because smart speakers are fairly new, the ways people use them varies widely. Every person might have different boundaries and comfort levels with the devices. Why do the research? We wanted to understand how people use smart speakers so we can identify new ways of connecting with audiences. To gain insight into how people behave around smart speakers, as well as their needs and pain points, we took a human-centered research approach and conducted 22 two-hour interviews with participants in their homes. We observed the participants as they went about their daily routines using smart speakers (two people we interviewed were former smart speaker owners who had discarded the devices). Our participants were Times subscribers and non-subscribers, and avid Times readers and non-readers who are part of a growing audience that is younger, more racially and geographically diverse, and leans female. To get a more complete picture of the potential benefits and limitations of smart speakers, we chose our participants from three distinct areas of the United States. We visited Seattle because it is a leading behavioral market and people are frequently exposed to the rapid pace of consumer technology shifts. Then we went to Miami to see how a more bilingual population experiences the existing capabilities of voice platforms, like voice recognition. Finally, we visited Detroit to explore how an environment that has fewer on-demand services might affect how people use smart speakers. Through our interviews, we wanted to go beyond any basic understanding of why people choose to use, or not use, smart speakers. We wanted to see how our participants currently interact with the devices, what interactions they might be open to having, and how smart speakers differ from other devices in their lives. In other words, we wanted to push participants’ boundaries to get a sense of what types of content and experiences they might be open to exploring. To do this, we prepared a range of “sacrificial concepts,” which were rough sketches for smart speaker experiences designed to invoke reactions and facilitate conversations. Our sketches were intentionally silly: in one sketch, a voice assistant would listen to the tone of your voice and deliver content to match your mood. (For the record, nearly everyone we interviewed found that concept creepy.) Ultimately, we wanted to open up a conversation with people about what a voice assistant should have permission to do and when the technology has gone too far. What we found through these conversations is that people are still trying to understand the full potential of smart speakers, and their expectations, interactions and boundaries are evolving. Through our conversations, we identified six key tensions: People are buying A LOT of smart speakers, but that doesn’t mean they aren’t nervous about eavesdropping. Curiosity about what smart speakers can do for people and their homes is being weighed against privacy concerns. Talking to a machine feels futuristic, but the auditory interface can stir up feelings of nostalgia. An interactive voice assistant feels beamed from the future, but a speaker can feel like radio. Smart speakers can help accomplish tasks, but they can also feel like toys. A person’s relationship to the device changes depending on whether they view it as a tool that completes tasks, or a content delivery mechanism that provides fun diversions. People want a voice assistant to be friendly, but not too friendly. While it’s possible to humanize voice assistants by adding accents or emotions, people don’t want the devices to have an unprompted or imposing presence. The people we spoke to said they feel overwhelmed by a nonstop connection to technology. They said they feel out of control, particularly with their phones. Whether they bought a smart speaker or whether one was gifted to them, most people said they appreciated how it allowed them to step away from their phones. One participant told us that the simple act of looking at his phone for a recipe or measurement conversion while he was cooking often led him down a mindless rabbit hole of scrolling social media. When he got a smart speaker, the temptation to scroll was removed and he could find answers to his cooking questions without leaving the conversation with his partner; he gleefully told us how he frequently misplaces his phone at home now. Another participant told us that she struggled to get up on time in the morning. She got a smart speaker and programmed it to be her alarm. The act of having to speak to the device to turn off the alarm made her more aware of her behavior, and made it easier to get going in the morning. It’s a relatively small act — talking versus pushing a button — but it had a big impact on her day and her life cumulatively over time. While phones push information at their users, smart speakers must be interacted with to get information. The people we interviewed told us that they felt more in control of their time when using their smart speakers instead of their phones. They said that interacting with their smart speakers sometimes results in frustrating, or even funny, exchanges, but that feels like a better experience than being tethered to a phone that pushes out notifications. News fatigue is real. Our participants spoke about feeling overwhelmed and exhausted by the cadence and tone of the news. They told us they don’t feel like they’re able to handle so many breaking news notifications, particularly when they felt the notifications were so often negative. With this sense of a relentless news cycle, people are looking to strike a balance between staying informed and staying mentally healthy. It makes them want news from someone they trust, and getting news from a smart speaker allowed them to regulate their news intake. Currently, native content developed for smart speakers is limited, yet the platform is ripe with opportunities to tell stories. We already know that audiences respond to audio-on-demand. Podcasts in particular have seen a huge boom in the past few years, with close to a quarter of Americans listening to them weekly. However, in order to apply voice lessons from podcasts to smart speakers, we need to explore new formats. People are using smart speakers most at transitional moments, like getting ready for the day and preparing dinner once they get home. If we are going to meet audiences where they are, we need to explore audio formats that fit well with this multitasking behavior. That means exploring short-form audio or acknowledging the time of day we’re releasing something. In order to design engaging and differentiated voice experiences, we need to think about shifting our mindset. We’ve highlighted a few considerations. Smart speakers are a multi-user medium , where multiple people from a single household might use a device; Kids are particularly active users. Discovery doesn’t happen on-platform: Most people learn about new smart speaker skills through other avenues — podcasts, newsletters, marketing. People infrequently stumble on new content while listening to their smart speakers, so we need to promote using other channels. Match the voice to the moment. The default computerized voices that come with smart speakers are best for navigating the platform, but listeners’ want human narrators for stories. In January of this year, we launched six new skills on Alexa, including a flash briefing that quickly gets people up to speed on the morning’s headlines. We used the considerations above to help guide our design decisions. These are early days of smart speakers and finding what types of content works on the platform requires experimentation. But more than anything, it means talking to our audience to better understand their needs. Those needs will help inform what the news sounds like coming from a smart speaker. How we design and build digital products at The New York Times 201 3 Artificial Intelligence Voice Assistant User Experience Journalism Design 201 claps 201 3 Written by R&D @nytimes. Exploring the future of media through a human-centered lens. How we design and build digital products at The New York Times. Written by R&D @nytimes. Exploring the future of media through a human-centered lens. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-08-23"},
{"website": "NewYork-Times", "title": "we re launched the new york times paywall and no one noticed", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/we-re-launched-the-new-york-times-paywall-and-no-one-noticed-5cd1f795f76b", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Jeremy Gayed, Said Ketchman, Oleksii Khliupin, Ronny Wang and Sergey Zheznyakovskiy If you’ve read an article on The New York Times website any time in the past eight years, you’ve probably seen a little message telling you how many free articles you have left to read. You may also have seen our paywall: that big box that pops up and asks you to register or subscribe once you’ve hit your monthly article limit. This is our Meter Service and it’s an important part of our subscription-first business model. The Meter Service has been around since we first launched our paywall in 2011 and it determines if our readers can access the hundreds of articles we publish every day. It also handles over 30 million user requests daily and it is the gatekeeper for how we acquire new subscribers. In early 2018, we decided it needed to be rewritten. To up the stakes, we had to ensure there was zero interruption to the business while also writing it to scale for future needs. No big deal, right? To be clear, we don’t take rewrites lightly. If they can be avoided, then it’s probably best to avoid them. We combed through old documentation for the Meter, talked to people who had been involved throughout the years and determined what improvements it needed to continue to meet our business objectives. What we had on our hands was an eight-year-old application that had been in maintenance mode for most of its life. The original creators were long gone, and it was built at a time when the industry doubted whether a subscription-based digital news service would even work. When we cleared the cobwebs, what we found was a complex NGINX configuration that fronted a parsing engine in C and an architecture that couldn’t autoscale, all deployed to Amazon Web Services (AWS). The only saving grace was that the XML-based metering rules were versatile enough to meet our current business logic needs. It was obvious that we were years behind the type of architecture we develop at The Times today. To ensure that the Meter could scale, we needed business logic consolidated within the service itself, instead of spread out across our apps and website; Our Android app had its own metering service separate from the main service. Additionally, we needed the ability to quickly test and implement new metering rules and logic, which was something the XML configuration and C engine made extremely difficult to do — it was time consuming to make, test and deploy changes, and often prone to errors. Most importantly, we needed confidence that the system was working as expected. A lot has changed in the years since we first launched the paywall, especially with how we architect our applications. We knew we needed to update the Meter with more modern technology, like a properly auto-scaled environment that could provide better latency for our application. Previously we had to pre-warm AWS load balancers ahead of anticipated traffic spikes, such as the elections. We wanted to avoid that by moving away from our over-provisioned cluster in AWS, to a newer auto-scaled Kubernetes infrastructure in Google Cloud Platform (GCP). We don’t write applications in C anymore, so we needed a new language that wouldn’t mean compromising on speed and stability, yet was more widely used at The Times and closer to the core technical competencies of our engineering teams. We decided on Go. Logging and metrics are a critical part of our current applications, and the Meter needed to be brought up to date. To be confident in its performance, we determined that having proper Service Level Objectives, or SLOs, would help in this effort. When something goes wrong, we need to see why the problem is happening and if action needs to be taken — PagerDuty works well for that. It’s tempting to jump right in once you’ve architected a solution, but if you’ve ever done that before, then you know that it can lead to a lot of problems down the road. Getting different perspectives to vet our solution and make sure we had a plan for long-term stability and support were all essential for a smooth launch. Here are a few of the areas we made sure to cover. The Times engineering group believes strongly in the Request for Comments (RFC) process because it helps bring visibility to a major architectural change and engages colleagues in decision making. An RFC is not very complicated; it is simply a technical document that proposes a detailed solution to a specific problem. We shared our RFC with all of our colleagues in the Technology department and asked for their feedback. Before we started coding, we spent several weeks preparing a couple of RFCs that outlined our plan to rewrite the Meter Service. This included documenting the current system and dependencies, analysis of multiple proofs of concept and creating clear architectural diagrams of our new solution. In the end, we were able to tighten up our plan and identify possible edge cases that we hadn’t thought through. The time it took to solicit feedback was worth it. The beauty of rewriting a service is you can make sure it’s done right from the start. We wanted to have several testing layers that we could automate (because who enjoys manual testing) and included coverage from unit tests, contract tests, load testing and end-to-end functional testing. Remember, this was a high-stakes replatform and we couldn’t mess it up. So, we needed a way to definitively demonstrate that the new service wouldn’t break existing integrations or business behavior. With our testing strategy vetted by our RFC process, we could prove feature parity with the old meter and be confident in our comprehensive test suite. The lack of visibility into the old Meter’s performance and stability was a problem for both technical and business reasons: the Meter is a key way we incentivize subscriptions purchases. The old service didn’t provide much visibility into performance, so we were never really sure how well it was working. Since we had little to work with, we decided we wanted to better understand how the existing service performed for our users. We put in place robust Real User Monitoring (RUM) to capture response times, error and success rates. This helped us determine not only what to watch for, but what benchmarks we should set for acceptable behavior. Before rolling out our new service, we put in place dashboards in Chartio (for client-side data) and Stackdriver (for service-level data) that allowed us to observe any changes to existing metrics. With this in place, we had yet another method for ensuring we could prove our rollout wasn’t going to break anything. The prep work we did allowed us to move extremely quickly to rebuild the service, spin up the new infrastructure and create a solid deployment pipeline. The next step was to launch, but we wanted to make sure we did it right to avoid a high-stress and high-stakes situation. We couldn’t afford to have our launch end up like Indiana Jones trying to snatch the idol treasure in Raiders of the Lost Ark , so we came up with a tactical approach. Our challenge was to guarantee the new Meter Service performs at par or better than the old service, and to ensure the response is identical between the two services for every user. To achieve this, we had both services run simultaneously, though the new service didn’t impact users at first. We called this our “dark rollout.” The graphic above shows the call to the legacy service and the additional silent call we added to the web client that went to the new service. The call was non-blocking and had no impact on the actual user experience. The responses received from each service were tracked and compared, and we used this opportunity to load-test the new service to see how well it performed during real news-related traffic spikes. The benefit of this approach was that the legacy service was still functioning throughout, which meant we had the freedom to modify the new service without worrying about impacting users. We could even take it down if we needed to make configuration changes to the infrastructure, such as auto-scaling policies or instance sizes. We let this run for a couple weeks until we ironed out the last bugs and felt confident that we could proceed with a phased rollout. We accomplished what we needed from the dark rollout and felt ready to start relying on the response from the new service. Before we fully launched it, however, we did an initial test on The Times’s website to be extra safe. Within the web client integration itself, we routed one percent of traffic to the new service and the remaining 99 percent to the legacy service. Additionally, we added a back-end validation layer, which allowed us to compare the new and legacy service results to make sure they completely matched. Once we knew we were good on our website, we moved on to test all other applications. At this point we knew the service worked, but thought that a gradual rollout was a smart way to have a smooth transition. There are a lot of ways to accomplish this, but we wanted to avoid having to update code in each integration. We opted to do it on the DNS level, pointing one percent of all traffic to the new infrastructure and 99 percent to the old. Then we watched and waited. A huge milestone for us was the ramp up to 50 percent of all traffic to The Times’s web offerings using our new service. Things were humming along pretty well until we discovered a problem. Our AMP platform wasn’t handling requests properly and wasn’t metering users at all. That was great for users, but terrible for business. In short, AMP requires custom headers to be included in the response our service provides, but we weren’t providing them. After spending a day investigating, we realized these headers weren’t provided in the original legacy C code, but rather in the NGINX layer. We missed something big, but because we could easily throttle traffic to the new service, we had a disaster plan ready. We scaled down traffic to the new service and quickly added in the necessary headers before ramping back up to 50 percent. We triple checked everything, then watched to see how it fared. The glorious day finally arrived where we felt confident enough to turn the dial and serve all traffic from our new Meter Service. The best part was that no one even knew we had launched — though, we did inform senior leadership and stakeholders. Part of launching a replatform is retiring the old systems, so we thanked the old system for its service and officially said goodbye to the old AWS stack. Overall our entire rollout took about a month. While that may seem long, it ensured we were completely confident that our new solution works. We avoided having a chaotic launch and actually felt a little awkward with how little drama there was. It’s now been a year since our launch and because of our approach, we have had a lot of time to improve the system, rather than chase production issues. We were even able to scale during record breaking United States midterm election traffic , handling over 40 times our normal traffic. This project allowed us to hone our playbook for how to handle launches: Peer review your plan before building. Ensure proper test coverage for key moving pieces. Ensure you have metrics and observability in place to watch for issues. Consider a very gradual rollout (even a dark rollout) instead of a full cut-over. Keep an eye out for anomalies during and after launch, and have an easy way to roll back if any issues come up. We’re trying hard to make great software here at The Times and are always looking to improve. Hopefully we’ve inspired you to do the same! Jeremy Gayed is Lead Software Engineer focused on evolving The New York Times’s web architecture. Follow him on Twitter . Said Ketchman is a Senior Engineering Manager overseeing the meter and marketing technology teams at The New York Times. Ronny Wang is a Software Engineer on the meter team. Sergey Zheznyakovskiy is Lead Software Engineer on the meter team. Oleksii Khliupin is a Senior Software Engineer formerly on the meter team. How we design and build digital products at The New York Times 444 6 Code Technology Deployment Journalism Golang 444 claps 444 6 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-08-29"},
{"website": "NewYork-Times", "title": "we built collaborative editing for our newsrooms cms here s how", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/we-built-collaborative-editing-for-our-newsrooms-cms-here-s-how-415618a3ec49", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Sophia Ciocca and Jeff Sisson It takes a lot of people to publish an article at The New York Times, and sometimes things get messy. Several reporters and editors may participate in the writing, revising and publication of a single story, and that collaboration is often nonlinear, which can lead to people stepping on each other’s toes. This is especially true in breaking news situations when many types of collaborators (photo editors, copy editors, reporters, producers) need to make edits to a document at the same time. When we first created Oak, The Times’s next-generation article editing interface , only one person could work on a document at a time. Oak used “field locking” to facilitate some simultaneous collaboration features, like letting different people edit separate metadata fields, but only one person could edit the body of an article at a time. It was clear to us that a more perfect article editor would allow collaborators to work in a document concurrently and seamlessly. Oak needed a collaborative editing feature. But collaborative editing is a hard problem to solve. It presents many new puzzles, including how to incorporate live updates, what to do about conflicting edits, and how to handle errors resulting from spotty wifi. A product like Google Docs has huge teams and resources devoted to solving these kinds of problems at scale. Our team only had a couple of months to solve these puzzles in a way that suited The Times’s editorial workflow. Luckily, support for these types of technical challenges was one of the original reasons we chose ProseMirror, an open-source text editing library, as the technical substrate for Oak. For an Oak article to be collaborative, every person with access to the article needs to have the most up-to-date version in real time. That means that every time an edit is made, it needs to be visible from every collaborator’s computer. Translating individual edits into a form that can be sent over the internet is something ProseMirror does at a low level; it calls each of these edits “steps.” When a user types a letter, that’s a step. Pressing the enter key to go to a new line? Also a step. Anything that manipulates the document — adding an image, editing the headline, deleting a paragraph — counts as a step. What does the data of a step look like, exactly? We portray steps as JSON objects that act as directions of sorts for how exactly the step changes the document. Here’s what it looks like to place the letter “H” in the second position in a document: When a user types words, changes an image or adds a comment, the steps of those actions are added to the user’s local document, but those steps haven’t yet been sent to anyone else. In order for the steps to show up on other people’s computers, they need to be sent to and confirmed by a remote server, which we call the “authority server.” The authority server acts like a bouncer at a club: when it receives steps from a user, it has to decide whether to let those steps in to its database. If it sees that no steps have been saved since the user’s browser last talked to the authority server, it will save them to its database. Otherwise, it will tell that user’s browser to fetch any steps it hasn’t seen yet. A typical conversation between the local document and the remote authority server might look like this: Notice how in line four the local document tries to send steps four, five and six, but the remote server tells the browser that steps already exist there. The browser needs to fetch the steps, rebase and try to send the steps again. What’s going on there? Rebasing is the process that happens when two users have inserted steps around the same time and the code needs to negotiate how they fit together. It involves one of the most important parts of ProseMirror’s collaborative editing support: an algorithm called Operational Transformation , which determines how to place a user’s steps on top of a newer version of the document. Though ProseMirror provides great building blocks ( and a fully working demo ) to implement a collaborative editing server, it doesn’t specify how to store steps in a database. We had to architect and implement our own solution that catered to our specific needs. Some of the questions we considered in our prototyping phase included: How can we scale the authority server to allow for lots of edits — up to 25,000 per article? How might we preserve the editing history of a collaborative document? And finally, how can we support a host of features, like pushing the latest document to our print production systems, that are unique to our newsroom’s needs? After sketching out a few different prototypes, we landed on using the real-time database Firestore to store our steps and act as the bouncer for incoming steps. Firestore supports database transactions, which means that steps submitted from multiple people will be retried by the Firestore library until one person’s insertion “wins” and is written to the database. Ordering multiple peoples’ steps in this way makes Firestore a good fit as an authority server. When a write operation to the database has succeeded, Firestore will notify remote users that new steps have been added to the database, which causes the app to fetch any newly-confirmed steps and bring their copy of the document up-to-date. Keeping the collaborative document up-to-date is important, but so is knowing who else is lurking in a document. We wanted everyone in a document to be able to see where their collaborators’ cursors might be, or if their collaborators highlight a certain passage with a mouse. Leveraging APIs from ProseMirror and Firebase (a sibling of Firestore), we added a feature to Oak that shows who is in the document and where they’ve left their cursor. Any time a user changes their selection within the Oak editor by typing, clicking or dragging, ProseMirror observes the change to the current state of their browser selection and creates a Selection data structure with that information. This data reflects information about where a user’s cursor is in the text, and contains the start position (or the head) and the end position (the anchor). If a user makes a selection in a document, the selection gets rendered for every computer that has the document open and displays the name of the user next to it. When the user changes their selection in their browser, that change needs to be mirrored in the document, so we push the updated selection data (head + anchor positions) into Firebase. To handle these selections, we sometimes have to predict the future. Because selection data and changes to the document are being sent to separate servers, the Oak app might receive selection changes for versions of the document that the browser hasn’t yet received. If the Oak app receives an edit to the document before a corresponding change to a selection, it has to simulate how it thinks that selection would change. Similarly, if it receives a change to a selection that’s tied to an edit that hasn’t arrived yet, the app waits until that edit arrives to render the change to the selection. To accomplish this, we use Redux Sagas to wait for and then apply these selection updates from the future. It’s worth noting that we chose to use Firebase to store these selections, as opposed to Firestore (which we use to store steps), because Firebase makes an onDisconnect hook available, which allows us to perform database modifications that are guaranteed to run even if the user closes the tab. This helps to ensure that when a user leaves the Oak editor, their cursor will be cleaned up after them. Once all of the article edits, or steps, have been inserted into Firestore, every browser window open to that article is updated with the latest steps. When an article is ready for publication, the backend service that handles publishing also gets up-to-date article data, which it sends to the publishing pipeline that our website and apps pull from to render articles on the user end. Before we implemented collaborative editing, this flow was simpler: The backend service could go straight to our MySQL database where the article’s contents and metadata lived. For new collaboratively edited articles, however, we created an App Engine service (which we nicknamed the “collab service”) that pushes the contents of an article from Firestore to our publishing service. When a user hits the publish button, the browser makes a request to this collab service, which copies the data from Firestore onto the publishing pipeline. Once a collaboratively edited article has been published digitally, it may need a tune-up for print. Before an article can be sent to the printing plant, editors in the newsroom need to remove hyperlinks and embedded content, and may need to shorten the article for print. The interface for making these print edits relies on the existing MySQL database. Because collaborative articles are stored in Firestore and therefore disconnected from this print database, we developed a system that copies the collaborative state of an article to our primary MySQL database at regular intervals. This system consists of a set of Google Cloud Functions and Google Cloud Tasks, and allows up-to-the-second collaborative changes to be previewed as they will be printed in the newspaper — a helpful feature for our print editors. Once a collaboratively-edited Oak article has been published and sent to print, it has finally made it to the finish line! Some articles might be updated with corrections after publication, and the steps will remain stored in Firestore for change-tracking purposes, but digital publication is where the story ends for our articles and their steps. We now have a working collaborative editor that seamlessly works with our existing news workflow, providing a massively improved user experience for collaborators across the newsroom. This has been a huge, multi-team effort. Many people on the Oak and CMS teams past and present had a hand in getting us to a place where articles can be edited collaboratively. The Oak team in particular — Minerva Archer, Sophia Ciocca, Tom Holcolmb, Dmitriy Matveev, Shane Moore, Dylan Nelson, Thomas Rhiel, Alexandra Shaheen, Jeff Sisson and Matthew Stake — has done an amazing job chipping away at this since 2016. Thank you also to Travis Rich of PubPub, who provided our first insights into using ProseMirror with Firebase, and to Marijn Haverbeke, the author of ProseMirror, who has given helpful guidance on this project. Sophia Ciocca is a Software Engineer on the Publishing team at The New York Times, working on Oak. Follow her on Medium . Jeff Sisson is a Lead Software Engineer on the Publishing team at The New York Times, working on Oak. Follow him on Twitter or his personal homepage . How we design and build digital products at The New York Times 1K 2 JavaScript CMS Code Journalism Collaboration 1K claps 1K 2 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-10-11"},
{"website": "NewYork-Times", "title": "across down diagonal how we test crossword puzzles on android", "author": ["Ben Oberkfell"], "link": "https://open.nytimes.com/across-down-diagonal-how-we-test-crossword-puzzles-on-android-cd2bcea7e829", "abstract": "Code Data Product and Design Workplace Culture Work with Us The digital New York Times Crossword puzzle often has clever tricks that go beyond the basic word game. It’s not uncommon for Crossword solvers to be called upon to put more than one letter in a square or play games with whitespace . One puzzle we published even had a third list of clues that offered an extra challenge. Subscribers to the Crossword have access to over 25 years worth of daily puzzles, as long as Will Shortz has been editor (he started editing the Crossword in November 1993). Our iOS and Android apps have put all these puzzles in your hand so you can play on the couch, the subway or wherever you choose to pass the time. And unlike solving on paper, the digital puzzles can check your work. Our app also connects you to the daily Wordplay column , where you can get hints and learn more about the person who created the puzzle — we call them constructors. With such a deep archive, Crossword devotees often visit puzzles months or years after they’ve been published. This opens a challenge for the developers on The Times’s Games Team. We have to ensure the digital versions of the puzzles work properly, even as the puzzle app itself continues to evolve. While we could manually play a collection of puzzles from the past 25 years, it would be too time consuming and would distract us from building new features. In our Android app, we run a suite of automated tests that allow us to check that the app is still working according to specification, even after changes are made. Every time we make a change to the code, our testing suite robotically plays through a set of the more clever puzzles in our archive, to confirm that any code changes didn’t impact the ability to view and solve them with the app. When implementing a new gameplay-related feature or working through a bug, we’ll create a test case to cover the issue. For a bug, we’ll write a test that follows the steps to reproduce the problem, and then, if we’ve solved the issue, it will confirm that the problem no longer exists. For a new feature, we’ll build a test that engages with the feature to make sure it’s working as our product designer intended it. These tests help us in two ways: they help us verify that later changes didn’t break functionality, and they live on as code-level documentation for future developers working in the app. It’s also really fun to watch the Crossword “play” itself as the tests run. Up until recently, the Android Crossword app only supported “across” and “down” clue lists, which was a problem if a constructor had clues that didn’t fit into those two categories. We added support for lists that went beyond the traditional clues, and built an infrastructure that made it easy to test whether users can navigate through every clue list and type the answers. Here, we see an example of our testing tools playing through a Mini puzzle by navigating the clue lists and typing the answers: The automated gameplay tests are built on Espresso , a user interface testing tool that is included as part of the Android SDK. Espresso allows you to write code that navigates the app and peeks at how the user interface appears. You can have Espresso click on buttons, type into text views or even navigate complex views like a Crossword game. To confirm that an element on the screen looks the way you expect it to, you can have Espresso make an “assertion” about the element. For example, consider a simple Espresso test for the gameplay screen below: we’d like to build a simple test that “clicks” letters on the keyboard and solves the puzzle (the answer for this clue, by the way, is James BOND). We’d want to tell Espresso to look at the keyboard and find a view on the screen that matches two qualifiers: a keyboard key (first qualifier) with the letter B for BOND (second qualifier). Once we’ve found it, we want Espresso to click it. Here’s what that would look like in code: While this is pretty straightforward, the syntax is still fairly verbose and what’s going on is not immediately clear to a future developer reading the test. To make this easier, we implemented a testing robot pattern to leverage some of the language features in Kotlin that allow us to write a clearly descriptive gameplay test. The robot abstracts away the Espresso heavy lifting, and provides a way for the test to look more like plain English. To illustrate how this works, here we have a puzzle with diagonal clues . Let’s walk through how we’d implement a test to confirm that a solver can navigate the diagonal clues as expected. We’ve assigned each of the cells in the puzzle a number from 0 through ( n — 1), where n is the number of cells in the whole puzzle. When we want the robot to click on a cell, we pass it the cell number. We want the robot to do the following: Start the puzzle off in “across” mode, then click the top left-most cell to cycle through “down” mode to get to “diagonal” mode. Verify that the clue shown is the expected diagonal clue: “Disappearing.” Enter the answer for this clue (no spoilers here!). Check to make sure the game has automatically moved the selection to the next diagonal clue, “Proceeding with little effort.” Enter the answer for this clue (again, we won’t share spoilers here). Finally, verify that we’ve looped all the way back to 1-Across again, and the 1A clue “Agile for one’s age” is showing. Here’s the code to do this test, using our robot: Here’s how it looks when watching the puzzle solve itself: The robot component is intended to be extremely reusable, so it reduces a lot of the effort involved in writing additional tests for the same screen or user interface flow. The descriptive nature of the test is also helpful when coming back to the code in the future. Having to debug a test failure is no fun when you don’t know (or can’t remember) what the test was aiming to validate. The goal of these tests is to make them emulate real user interactions as closely as possible. This includes the code that communicates with our backend to fetch puzzles, as well as the code that parses puzzles and presents them in the game board. This is because a change to the parsing code might impact how the app might render a puzzle, especially a “peculiar” one like the diagonal puzzle above. We set up local instances that mirror the same server interactions that take place in the production app. Our testing framework uses a fake web server, provided by Wiremock , that responds to the app’s network requests for puzzle data. We use Dagger throughout the app for configuration and dependency management, but it’s also useful for switching from the live production backend to the fake web server when we’re running our tests. When the app runs a test, Dagger sets up the app to communicate with the Wiremock server on localhost rather than the production backend at www.nytimes.com . This way, we have complete control over what network interactions will happen during testing. We configure how the network interactions will take place by setting up matchers for various URLs. For instance, here’s the URL for puzzle 1,001 that returns the puzzle in JSON format: We want to tell Wiremock that when it receives a request for a given puzzle URL, it should return a static JSON file for that puzzle for our tests. To do this we’ll build a matcher, which looks something like this: We’re telling Wiremock that when it sees a GET request for that URL, we’re going to respond with an HTTP status code of 200 (signifying that everything is working as it should), along with the contents of the JSON file on disk. Then we’ll call this code from our tests, so that when the game requests a URL for a puzzle, it receives the puzzle JSON data from our test case. This way, the app’s network and parsing muscles are flexed as well as the gameplay logic itself. The mocking layer is also handy in other parts of the development workflow, including a Test-Driven Development process. Recently, we launched Leaderboards , which allows solvers to share their Mini puzzle times with their friends. We wrote tests while building the Leaderboards screens, so that as we worked, we knew that we were meeting requirements. By using mocked data, the tests also saved us time in testing different scenarios. For example, you can’t add yourself as a friend, and you can have a maximum of 25 friends. By providing mocked server responses for each of these scenarios, we can make sure the app renders the right error message in every circumstance, without having to set up a number of test users on a live server. Because it’s easy to mock out the end-to-end network activity and script interactions with the UI, we’ve been able to increase our UI test coverage as we add new features. It also makes it easier to add new tests to existing features, as the reusable test robot pattern reduces the effort involved. Our automated tests proved particularly helpful recently when doing a large, complicated refactor across the entire app. An overzealous find-and-replace had inadvertently impacted some of the UI resources in the gameplay screen. But our suite of tests caught the problem and made it easy to pinpoint the source. Had we not had the backing of our tests, we might not have caught this until later (or not at all), and it would’ve been much harder to trace back to a root cause. Ben Oberkfell is a Senior Android Engineer on the Games Team at The New York Times. He lives in St. Louis and enjoys coffee in all its forms. Follow him on Twitter . How we design and build digital products at The New York Times 172 1 Android Games Testing Code Tech 172 claps 172 1 Written by How we design and build digital products at The New York Times. Written by How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-08-09"},
{"website": "NewYork-Times", "title": "how to take your open source project from good to great", "author": ["Yuraima"], "link": "https://open.nytimes.com/how-to-take-your-open-source-project-from-good-to-great-49c392175e5c", "abstract": "Code Data Product and Design Workplace Culture Work with Us Not too long ago I wrote a post about an open source project I released through The New York Times. Although I have had some experience contributing to open source software (OSS) in the past, this was my first time launching an open source project where I was the sole contributor and wanted others to use what I had written in their own projects. As someone who has benefitted from plenty of incredible OSS projects, I had some idea of what a “good” open source repo on GitHub looks like: it should have a README.md file, installation instructions and enough documentation to get started. But beyond that, I was totally lost: what would take my repo from good to great? What follows is a short guide, pulled from my own experience, on best practices when making a project open source. Most of what I learned was found through research online, conversations with coworkers and friends and checking out dozens of projects available on GitHub. Probably one of the biggest pitfalls for open source projects is a lack of documentation. Having easily accessible, human readable and reference-able documentation can be the difference between a project that is readily consumed by others and one that falls by the wayside without much fanfare. There are a few places where you can place important information, but the most central and accessible is in the project’s root README.md file. The README.md is the most visible file in your repository and likely the first one a person will see. The project’s main README file is usually located in the root of your repository and acts as the landing page for your repo; it should communicate the most important information about your project clearly and concisely. There aren’t hard and fast rules about what should and shouldn’t be in a README, but the following are some good starting points. Why your project exists. What purpose does it serve and who does it serve? This is a mission statement of sorts and should be prominently visible for anyone who’s visiting the repo for the first time. Quick start instructions. Usually includes instructions on how to download and use your code as quickly and easily as possible. In-depth API documentation. Depending on how robust your API is, you could opt to include the documentation for it directly in your README file. If there is too much to fit in one place or you need more documentation features (such as search capability, FAQ, forum, etc.), this is where you can link to an external site. How to contribute. The next part of this post will do a deeper dive on how to instruct others to contribute to your project via a contributing guide, but the README.md file is a great place to encourage contributions and link them to that guide. Shout out to your contributors. It’s important to give thanks and recognize those who help support your project. The All Contributors project is a great resource on how to best reward different kinds of contributions along with some handy tools that make it easier to streamline the process. Where to turn for help. If a user or contributor needs help using your code, who should they reach out to? Would you prefer they ask you directly, open an issue in GitHub or reach out to others working on the same things? Some larger communities set up IRC or Slack spaces where anyone can ask questions and get help from others. Code of conduct. No one wants to deal with a jerk on the internet. Including a code of conduct can clearly point out the kinds of behavior that aren’t tolerated and can help structure an inclusive community around your project. The Contributor Covenant is a widely adopted code that celebrates and encourages diversity of thought and people, and clearly defines enforced punishments for those who act in discriminatory or ill-intentioned ways. There are a plethora of examples of different types of code of conduct out there, so do your research and pick the one that best aligns with how you and your community members want the developers around your open source project to behave — or create your own. The README file is meant to direct users to where they need to go, either with code samples, set-up instructions or links to more in-depth forms of documentation. These are just some of the topics you can include in your README, but there are so many others that might be right for your particular project. Don’t be afraid to take a look at other repos , whether or not they’re similar to yours or completely different, and borrow ideas whenever you think it makes sense! Whether or not you expect anyone to contribute to your project, you should be prepared for the possibility of others wanting to help your cause. And when that happens, your contributing guide will show those helpers exactly how they can get involved. This guide, usually in the form of a CONTRIBUTING.md file, should include information on how one should submit a pull request or open an issue for your project and what kinds of help you’re looking for (bug fixes, design direction, feature requests, etc.). The following are some examples of information you can include in your contributing guidelines. Instructions on how to work in the codebase locally. This is for anyone who wants to make code contributions. It should include any start or run scripts, suggestions for how to navigate the codebase, code style expectations and other details you deem necessary to successfully have changes incorporated into the project. Testing instructions. If your codebase has tests that need to pass for any PR to be considered, include instructions on how to run tests for your project and how to write additional tests for the contributor’s proposed changes. An issue template. Clearly define the information you want included in new issues . Details like the kind of issue being filed (bug, feature request, documentation change), OS version, browser, language/environment specifics and steps to reproduce can save you and the contributor hours of debugging. To help reporters write a helpful issue, consider including an issue template that will prepopulate a new issue with the information you expect to be included. A section on your repository’s license. Having a license protects you, your contributors and anyone who uses your work. Knowing which license will work for you and your audience is probably the most difficult part of checking this requirement off, but choosealicense.com and tl;dr legal make it easier for anyone to make an informed decision. Having a thorough README, contributing guidelines and helpful templates are just the beginning of getting your OSS project ready for launch. While these can be considered the “bare bones” of any project worth its salt, there are plenty of additional steps you can take to create a project that is both pleasant to use and to contribute to. Make sure your codebase is secure. Your code could be used or seen by tens, hundreds or maybe even thousands of people. Take precautionary steps to secure your accounts by following best practices like keeping your passwords and secrets out of your git history, running regular security scans on your codebase and keeping your dependencies up-to-date with the latest security packages. Luckily, GitHub makes this task easier by providing automatic security alerts for public repositories so you can stay up-to-date on the latest vulnerabilities in your projects. Write and enforce tests. Including tests in your codebase can help reduce the possibility of accidentally introducing bugs or making a breaking change; This is especially important in a codebase where many people are working simultaneously. If you’re accepting Pull Requests from contributors, make sure you clearly define when and how to include tests. Use a code linter. Linters can help catch the small mistakes, like using a tab instead of a space, and the big mistakes, like when forgetting a semicolon can be absolutely detrimental (*cough* PHP *cough*). They also give you the power to enforce certain coding styles without having to personally enforce coding styles character by character. Include git hooks . Git Hooks are commands or scripts that are automatically run before certain actions take place in Git. They can hook into several different git commands — commit, push, merge, etc. — and are used to automatically run processes that you deem necessary before or after these commands. For example, many engineers use git hooks that run tests before a commit or push; If the tests fail, the commit or push will fail. This adds another level of protection to a project by automatically rejecting any code changes that break tests or fail linting standards, before ever making it into a PR or the master branch. Add Continuous Integration/Development tools. CI/CD are great for automating the mundane tasks associated with reviewing, maintaining and shipping code. This could be anything from assigning someone to perform a code review on a PR to deploying a branch to a staging environment. There’s an ocean of resources and tooling available for any type of project, so I won’t go into too much detail here. But the GitHub Apps Marketplace is a smorgasbord of tools you can integrate into any project. Include Editor/IDE configuration files. Helping your contributors set up their code editors or IDE to work within the constraints of your project’s can reduce a contributor’s time spent toying with settings. Popular (and free) text editors like VSCode and Atom allow you to control settings like whether to use tabs or spaces in a project, running linters automatically on save and many others. The basics covered above are only the tip of the iceberg, but they will help get you well on your way to creating a well-organized, maintainable and accessible open source project. However, there’s no one right way to set up or maintain your project, so continue to do some research to find out what works best for you and your codebase. Pull inspiration from OSS repos that you’ve used or have contributed to, or ask your colleagues and peers for any advice they can share. How we design and build digital products at The New York Times 296 1 Open Source Programming Tips Code Technology Programming 296 claps 296 1 Written by Sr. software engineer @ The New York Times, professional 🐶 greeter, perpetual 🌮 seeker, occasional public speaker How we design and build digital products at The New York Times. Written by Sr. software engineer @ The New York Times, professional 🐶 greeter, perpetual 🌮 seeker, occasional public speaker How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-08-15"},
{"website": "NewYork-Times", "title": "introducing the news provenance project", "author": ["Sasha Koren"], "link": "https://open.nytimes.com/introducing-the-news-provenance-project-723dbaf07c44", "abstract": "Code Data Product and Design Workplace Culture Work with Us The Times’s Research & Development team is exploring ways to make the origins of journalistic content clearer to news audiences. In a time of heightened political polarization and widespread social media use, the prevalence of misinformation online is a persistent problem , with increasingly serious effects on elections and the stability of governments around the world. In addition to false statements published as fact in text and photos that have been manipulated or republished out of context, instances of manipulated video are now on the rise . How should news organizations respond to this crisis ? The news media may not have created this problem, but it is theirs to contend with. More crucially, the audiences for news must navigate an all-too confusing landscape of information and, according to a recent Pew Research Center study, they want the news industry to fix it . Finding solutions that help news readers distinguish material published in good faith from that which is deliberately misleading is no small challenge, and we realize we’re not the first to take it on within a news context. Newsrooms around the world diligently continue to cover the social, political and technological factors that contribute to misinformation and its consequences. Many also now regularly work to debunk false claims, which tend to proliferate more during campaign seasons. As misinformation tools continue to evolve, so have strategies to identify and avoid it. Some recent standout examples include the Washington Post’s visual explainer of manipulated video and the Wall Street Journal’s creation of a team to help its journalists identify deepfakes . In addition, a number of news-centric nonprofits — including First Draft , which provides guidance in verifying content found on the social web, consortiums like Misinfocon , the Credibility Coalition and many , many others — have emerged to study the issue from a variety of perspectives and provide much-needed research and training. Beyond these valuable strategies, we feel there is additional potential in exploring how product and technical-level approaches can help. In altering how we produce and present what we publish, news outlets may be able to help readers better understand the tangled landscape of information online, especially on social platforms and messaging apps. What if we could provide them with a meaningful way to differentiate between misleading content and credible news? Earlier this year, The Guardian made such a change to the way the dates of its old articles is displayed, after seeing spikes in traffic on stories about years-old events that had been shared as new, and with incorrect context, on Facebook. Along those lines, The New York Times Research & Development team is launching The News Provenance Project to experiment with product design and user-facing tools to try to make the origins of journalistic content clearer to our audiences. Our first project is focused on photojournalism. Because photos can be easily manipulated — and then circulate widely through digital spaces with few brakes applied from social platforms, messaging apps or search engines — we are aiming to learn what happens when we give audiences better insight about the information associated with a news photo published online. To that end, we are approaching this task with a hypothesis: that adding context to images might have a positive or clarifying effect on the wide ecosystem of information published to the web. Around that hypothesis, we are conducting user research, which we’ll use as the basis for a proof of concept. We’ll test the effectiveness of that proof of concept to find out whether access to that information helps audiences better understand the veracity of professionally produced photojournalism. Some examples of what we hope to learn: Could information about a photo’s digital history help people better understand the way it is produced and published? How much information might be helpful or necessary in sourcing a photo shared outside of its published context? What kinds of metadata — for example, the time and place the photo was captured, the original publisher and caption, the photo’s revision history— might be important to include or prioritize? How helpful might a symbol or watermark be in establishing credibility? How might access to photo metadata change how audiences perceive photos that don’t have metadata? This summer, in addition to conducting user research, we’ll also build a proof-of-concept technical implementation. We believe attributes of blockchain technology show promise in developing a workable solution, so we’ll begin by exploring Hyperledger Fabric, a permissioned and private blockchain framework. We are developing this proof of concept in collaboration with the IBM Garage , which has executed similar projects in other industries. Why blockchain? Its underlying structure as a “distributed ledger” (a database that is not housed on one set of servers owned and operated by one entity, but by many entities and servers that are kept updated simultaneously) is useful for this project because it makes the records of each change traceable: files are not so much changed as built upon. Any updates to what is published are recorded in a sequential string (or “blocks” in a “chain”) with the string of those changes adding up to create a provenance. (If you’re are still puzzled about what blockchain even is or how it’s different from cryptocurrencies, we recommend episode 2, season 1 of the excellent ZigZag podcast , this Dealbook explainer and Reuters Graphics’ visual explanation .) By experimenting with publishing photos on a blockchain, we might in theory provide audiences with a way to determine the source of a photo, or whether it had been edited after it was published. In exploring the applications of blockchain for photojournalism, we hope to learn more about where and how it may be sensibly used for journalism as a whole. We’re working from within The New York Times Company, but not solely on behalf of it. A successful implementation will require collaboration and use among many organizations. To that end, we’ll make what we learn publicly available in the hopes that it may be of interest and of use to other publishers. We would love to have more participants join us in this experimentation — particularly news outlets that publish original photos and that serve different audiences from The Times’s. If you’re from another news organization and interested in finding out more, please fill out the form at the bottom of this page and we’ll be in touch. We will be sharing more as we go, so look for future blog posts here, and updates on the project site . In the meantime, we are eager to hear thoughts and reactions from those interested in any aspect of this work. Sasha Koren is the project lead on The News Provenance Project. Previously, she was the editor and co-lead of the Guardian Mobile Innovation Lab and held a number of digitally focused roles in The Times newsroom. How we design and build digital products at The New York Times 692 5 Journalism Innovation Misinformation Technology Blockchain 692 claps 692 5 Written by Journalism things. Past: Editor @GdnMobileLab,@nytimes community/social, features, opinion etc. How we design and build digital products at The New York Times. Written by Journalism things. Past: Editor @GdnMobileLab,@nytimes community/social, features, opinion etc. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-07-23"},
{"website": "NewYork-Times", "title": "how we helped our reporters learn to love spreadsheets", "author": ["Lindsey Rogers Cook"], "link": "https://open.nytimes.com/how-we-helped-our-reporters-learn-to-love-spreadsheets-adc43a93b919", "abstract": "Code Data Product and Design Workplace Culture Work with Us Five years ago, a lot of people in journalism were asking, wide-eyed, “Should journalists learn to code?” The consensus for most journalists was: probably not. And over time, the “should we code?” questions quieted down. But, some people did learn. At The New York Times and elsewhere, coder-journalists have mashed databases to discover wrongdoing , designed immersive experiences that transport readers to new places and created tools that change the way we work. Even with some of the best data and graphics journalists in the business, we identified a challenge: data knowledge wasn’t spread widely among desks in our newsroom and wasn’t filtering into news desks’ daily reporting. Yet fluency with numbers and data has become more important than ever. While journalists once were fond of joking that they got into the field because of an aversion to math, numbers now comprise the foundation for beats as wide ranging as education, the stock market, the Census and criminal justice. More data is released than ever before — there are nearly 250,000 datasets on data.gov alone — and increasingly, government, politicians and companies try to twist those numbers to back their own agendas. Last year, The Times’s Digital Transition team decided to look at how we could help grow beat reporters’ data knowledge to help cover these issues. Our team’s mission is to “continuously transform the newsroom,” and with a focus on training all desks, we were well positioned to address these issues on a large scale. We wanted to help our reporters better understand the numbers they get from sources and government, and give them the tools to analyze those numbers. We wanted to increase collaboration between traditional and non-traditional journalists for stories like this visual examination of New York football , our campaign finance coverage and this in-depth look at where the good jobs are. And with more competition than ever, we wanted to empower our reporters to find stories lurking in the hundreds of thousands of databases maintained by governments, academics and think tanks. We wanted to give our reporters the tools and support necessary to incorporate data into their everyday beat reporting, not just in big and ambitious projects. After talking to leaders in our newsroom about how we could support journalists who wanted to obtain more data skills, we ran two pilot training programs, then expanded into an intensive boot camp open to reporters on all desks. Over the past 18 months, we’ve trained more than 60 reporters and editors, who have gone on to produce dozens of data stories for The Times. [ Learn how 5 reporters in our newsroom used data skills from the training to create groundbreaking work. ] The training is rigorous. Based in Google Sheets, it starts with beginner skills like sorting, searching and filtering; progresses to pivot tables; and ends with advanced data cleaning skills such as if and then statements and vlookup . Along the way, we discuss data-friendly story structures, data ethics and how to bulletproof data stories. We also invite speakers from around The Times, including the CAR team, Graphics and the Interactive News team, to talk about how they report with data. Over a period of three weeks, the class meets for two hours every morning. This includes time for reporters to work on data-driven stories and apply the skills they’ve learned in the course to their own beats. We also train the reporters’ editors. In separate lunch sessions, they come together to discuss tips for editing data stories, common pitfalls to avoid and advice for working with reporters. Each time we run the training, we have two or three times as many sign-ups as we have slots. As a result, we instituted a selection process where reporters are nominated by the leaders of their desks. From that group, we build the cohort with the aim to have a diverse mix of desks, beats, gender, race, reporting timelines, ages and tenures at The Times. Once selected, reporters commit to attend all sessions and come prepared with data-driven story ideas for their beats. To help reporters with their first data stories, we support them with on-demand data help for the two months after the training. Every month, we gather all the groups together for a lunch and learn. Releasing Our Materials While we recognize most publications aren’t able to offer their reporters a three-week data training, we know that increasing data skills is hardly a Times-specific need. Even in smaller newsrooms, making time to teach someone data skills has benefits in the long run. But it can be difficult and time-consuming to build out proper materials, especially if developing training programs isn’t your sole job. So, we’ve decided to share our materials in the hopes that students, professors or journalists at other publications might find them useful. Over the last four rounds of data training, Digital Transition has amassed dozens of spreadsheets, worksheets, cheat sheets, slide decks, lesson plans and more, created by me, my fellow Digital Transition editor Elaine Chen and various speakers around The Times. View them here. Here’s an overview of what’s included in these files: Training Information : A list of skills included in the training, both technical and things like data ethics, as well as the schedule from our last round of training. The schedule shows how we switch off between “core skills” sessions that show new skills with a fake dataset, “practice” which applies those skills and “story sessions” which help reporters apply the skills they’ve learned to stories they are working on now. Data Sets: Some of our data sets and worksheet activities from practice sessions. We’ve organized them into three difficulty levels. Note that we’ve altered these datasets in order to relate closely to what we cover each week, so please don’t use them in your reporting . Cheat Sheets: Taken from each core skill session, covering most of the technical skills we practice with reporters. They are meant as reference materials for reporters as they practice and apply skills. Since the training is in Google Sheets, the technical prompts are for that program. Tip Sheets: Some of the more random and non-technical skills we cover, such as how to bulletproof your work, how to brainstorm with data and how to think creatively while writing with data. If you have any questions about these materials, feel free to contact me at Lindsey.Cook@nytimes.com . Lindsey Cook is an editor for digital storytelling and training at The Times. Previously, she worked as the data editor for news at U.S. News & World Report. She has taught journalism at American University and is a graduate of the University of Georgia. How we design and build digital products at The New York Times 1.3K 1 Journalism Data Work Data Journalism News 1.3K claps 1.3K 1 Written by Data and digital storytelling at NYT. How we design and build digital products at The New York Times. Written by Data and digital storytelling at NYT. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-10-29"},
{"website": "NewYork-Times", "title": "what it means to design for growth at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/what-it-means-to-design-for-growth-at-the-new-york-times-2041e0f5e64a", "abstract": "Code Data Product and Design Workplace Culture Work with Us In November of last year, The New York Times announced that it had surpassed a lofty goal : to have four million paid subscribers. Achieving that goal is the result of a strategy to shift the company away from relying on advertising dollars to being sustained by subscribers. Driving that growth is a team — known within the company as the Growth Mission — that is made up of people from audience research, brand, data, design, marketing, product and technology. It isn’t enough to put up a paywall and a place to input credit card information, there needs to be a product and design strategy driving the subscription experience, too. It’s a big job that often requires thinking about the needs of the user, while also working towards business goals. No one knows that challenge better than product designers Asiya Yakhina and Nana Marín , who are embedded in the Growth Mission and work on the pay flow, the registration process and the onboarding experience for new subscribers. I talked to Yakhina and Marín about what it means to design for growth, how they use testing to inform their design decisions and how they work with cross-functional teams. –– SARAH BURES Sarah Bures I’d like to start by asking you to explain your jobs. What do you do? Nana Marín I am part of the Growth Mission and my focus is optimizing the registration process and the subscription flow. So, that’s everything from the landing page with the subscription options through the sign-up form and the payment flow. Asiya Yakhina I’m also a product designer under the Growth Mission, except I focus on onboarding the user after they subscribe or create an account. The onboarding experience could be a set of initial set-up steps, or contextual messages explaining how to use certain features on the site. SB What is your main focus? NM I’d say that my team’s main focus is explaining to users why we want them to subscribe. It’s not just about making money, it’s about funding journalism. Sometimes that gets a little lost, so it’s our job to always have that in mind and push that information out. AY From the onboarding standpoint, our focus is to help readers find ways of extracting value from our product. The user might create an account or subscribe for many different reasons, but they will only come back to us if they found some value in using the product. On the onboarding team, we think about how to make that happen, how to nudge the reader towards building a meaningful habit of reading The Times. SB How would you say growth design is different from regular product design? NM In my previous roles at other companies I had to be a jack of all trades and work on different parts of the customer journey, but this is the first time that I get to be laser focused on just two sections of that journey. The benefit of getting to be so focused is that you realize you can come at the problem from different angles. I find it really challenging and exciting to be able to have such clearly defined objectives. AY The way I see it, the “growth” part means that there is a clear business objective that needs to be solved for; in our case it’s growing our subscriber base. The “product design” part of it means that we get creative about solving that problem. It also means that, as designers, we think carefully about how the solution will meet an existing user need. That’s why we often operate in this tight space where business and user needs are at slight odds with each other. A lot of testing and experimenting is needed to land on a solution that meets both. SB: That sounds tricky. How do you reconcile the business needs and user needs to create a user-centered design? AY: Let’s take an example of our onboarding experience for readers who just subscribed. It’s in the interest of the business to encourage a new subscriber to sign up for newsletters because it will help them establish a habit of reading The Times regularly. And here we are likely to encounter two scenarios. In one scenario, the new subscriber welcomes the opportunity to sign up for newsletters because they see how it will help them stay on top of the news they care about. In another scenario, the new subscriber just paid for their subscription to unlock a story that was behind the paywall and likely wants to return to the story right after the purchase. How do we get the user in the second scenario to check out our newsletters, while also acknowledging their desire to continue reading? We present them with a screen that shows some newsletters they might subscribe to, but we’ll give them a clear option to skip this step. We’ll also do our best to communicate the value of signing up for newsletters and make it clear that this quick distraction will be worth it in the long run. SB What is it like working on a cross-functional team? NM It means that we’re constantly talking to product managers, developers, copywriters, data analysts and other designers. With any project, I try to bring in developers early on. For example, say, I’m working on a new project and maybe I don’t quite understand it or I have questions; I’ll do some research, and then put together some user flows and wireframes. Then I’ll show it to the developers to make sure we’re on the same page. AY Agreed. We share the project and the deliverables with people in multiple roles — and it’s best to collaborate early and often for best results. Before I jump into design exploration, I want to be aware of technical constraints, testing requirements, and have the copy-writer from brand weigh in on what this experience could sound like. With all these pieces in place, it’s easier for me to come up with an informed design decision, and avoid last-minute workarounds because some constraint wasn’t accounted for. It’s pretty great to see early collaboration pay off in the long run — and it always does. SB Earlier you were talking about testing. What are the types of tests you do? NM I’ve never worked at a company that does testing or user testing sprints the way the team does them here and I just think it’s great. Basically, you talk to a member of the qualitative testing team and you kick off, say, on Monday, your prototype is ready Tuesday, a discussion guide is written Wednesday, then Thursday you’re in user testing all day and then Friday to Monday you start getting results. It’s so quick; It’s kind of crazy. AY I find qualitative tests very useful because they often become a source of great directional feedback. As we listen to users’ reactions to our design provocations, we find new ideas to try out. Those ideas are later incorporated into bigger tests that will bring more definitive quantitative learnings. SB So, the qualitative tests are user interviews; what types of quantitative tests do you run? AY Most are A/B or multivariate tests, where we measure the effectiveness of two or more different solutions against each other. Quickly seeing how a user engages with a new feature tells us how effective a given solution is — and it shows how that affects their behavior in the long run. To continue with the newsletter example, if we launch an experience that lets new subscribers sign up for newsletters, we’ll look out for two metrics: how many newsletters a user signs up for and, as a result, how often they come back and read us, in the long term. SB How do you incorporate lessons from the tests back into the design process? NM It varies depending on the test. For example, let’s say we were testing three copy variants on the subscription landing page and more people clicked on one option. Then we can gauge that maybe this copy variant worked the best because more people clicked on it, so we test it a little further which might lead to other designs or other tests. But sometimes it’s a little trickier to gauge what the winner is. SB How do you make decisions in those tricky situations? NM Maybe more testing or advocate for a redesign. For example, let’s say we are testing form fields in the payment flow and we see that the numbers are flat, regardless. But we know that a redesign of the form field is important for accessibility reasons. We’ll just say that even though the numbers are flat, we know the form should be accessible, so let’s proceed with a redesign. SB: Have you ever been surprised by the results from quantitative testing? NM: Yes, we used to include text that said, “You can cancel anytime” in a prominent place at the top of the subscription landing page. We tested decreasing the prominence of the copy and moved it below the purchase buttons to see if it could reassure a user at the decision making moment. While we wanted the new test variant to perform positively, we were surprised that it dramatically out performed the control landing page. It’s an example of how empathizing with a user’s mindset and potential anxiety towards purchase commitment can result in a win-win experience that meets the needs of both the business and the user. SB Do you usually drive what you design next or is it a team decision? NM A little bit of both. Because we could have some ideas and then it’s pretty open for us to talk to the product manager and pursue it. Or sometimes a product manager will have it. I work very closely with the product managers, so it’s all kind of symbiotic in that respect. SB As you look to the future, what are you really excited about with your jobs? NM I’m excited about how open everyone seems to be about redesigning things. The New York Times has been around for so long that I thought it might be a little trickier than it is to redesign anything and there is a lot of opportunity for that. So, it’s pretty fun. AY What excites me is the unique challenge of the work I do and the consequent opportunity to learn and grow as a designer. The experiences I create are often inserted in moments when the user doesn’t necessarily expect them or want to interact with them because they’re trying to do something else (like, read a story). This means that sometimes I sit through user testing sessions filled with unimpressed reactions, like “I usually skip these screens.” But hey, that builds a humble but sturdy designer character. It also reveals blind spots in my thinking and challenges the assumptions that were made. And whenever that happens, I learn something new and get a chance to find a better and a more informed solution to a given problem. How we design and build digital products at The New York Times 302 UX Design Conversations Product Journalism 302 claps 302 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-06-13"},
{"website": "NewYork-Times", "title": "exploring the future of 5g and journalism", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/exploring-the-future-of-5g-and-journalism-a53f4c4b8644", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Aharon Wasserman, Serena Parr and Joseph Kenol This month, the fifth generation of wireless data networks made its debut in Chicago and Minneapolis, marking a big shift in wireless technology. Over the next few years, the transition to 5G will provide Internet speeds at least 20 times faster than 4G networks, enabling smartphones to download entire movies in seconds or stream massive multiplayer games without latency. (You can read more about the new network and its expected impact here .) At The New York Times, we’re interested in how higher and faster bandwidth can unlock new ways for us to tell stories, and for our readers to experience them. To explore what kind of storytelling opportunities 5G might enable, this year we’ve launched a 5G Journalism Lab. We’re collaborating with Verizon, which is providing us with early access to 5G networking and equipment for us to experiment with. We believe 5G’s speed and lack of latency could spark a revolution in digital journalism in two key areas: how we gather the news and how we deliver it. In the short term, having access to 5G will help The Times enhance our ability to capture and produce rich media in breaking news situations. Over time, as our readers start to use 5G devices, we will be able to further optimize the way our journalism is delivered and experienced. Even before 5G devices are used widely, we see high potential for leveraging 5G to enhance our ability to gather the news, so we’re experimenting with how 5G in the hands of our journalists might enable new workflows and capabilities not possible with today’s 4G technology. The Times has journalists reporting on stories from over 160 countries. Getting their content online often requires high bandwidth and reliable internet connections. At home, too, covering live events means photographers might take thousands of photos without access to a reliable connection to send data back to our media servers. We’re exploring how 5G can help our journalists automatically stream media — HD photos, videos and audio, and even 3D models — back to the Newsroom in real-time, as they are captured. We’re also experimenting with how we can deliver more dynamic storytelling formats to our readers as 5G devices become used more widely. Over the past year The Times has honed its ability to tell immersive stories , allowing readers to experience Times journalism in new ways. As 5G devices become more widely adopted, we’ll be able to deliver those experiences in much higher quality — allowing readers to not only view more detailed, lifelike versions of David Bowie’s classic costumes in augmented reality, but also to explore new environments that are captured in 3D. The promise of 5G is huge, and we’re eager to experiment with the technology to understand what possibilities it might unlock for The Times and our readers. Along the way, we hope to share our successes and roadblocks — and engage with a larger community of technologists, designers, storytellers and readers. To start, we’ll be publishing our findings here every few weeks. Looking forward. Aharon Wasserman is the Technical Lead of the 5G Lab and a Lead on the Research & Development team at The New York Times. Follow him on Twitter . Serena Parr is the Partnerships Lead of the 5G Lab at The New York Times. Joseph Kenol is the Newsroom Lead for the 5G Lab and Visual Strategy Director at The New York Times. How we design and build digital products at The New York Times 158 6 Journalism Technology Design 5g Internet of Things 158 claps 158 6 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-05-05"},
{"website": "NewYork-Times", "title": "launching a product in one sprint", "author": ["Angelica Hill"], "link": "https://open.nytimes.com/launching-a-product-in-one-sprint-932d7bad8cd6", "abstract": "Code Data Product and Design Workplace Culture Work with Us A few months ago the Email and Messaging team decided to develop a new product using a swarming sprint format. This meant everyone on the team focused on delivering one Minimal Viable Product, or MVP, during the sprint rather than completing the project over a series of sprints. One product. One sprint. The entire team. Not only was this a new way to work for the team, but it was entirely new to me. A year and a half ago, I moved from London to New York to attend the Columbia School of Journalism. Shortly after graduating, I walked bright eyed and excited into The New York Times office for my first day at work as a product analyst. Three months later, I found myself working on an automated re-engagement campaign for our email newsletter subscribers. I am in a newly created rotational product role at The Times that reports to the Storytelling Product lead in our Engagement department. I partner with product managers to help create strategies for their teams, provide product requirements and communicate to external stakeholders. I get to learn what it means to be a product manager from a range of different perspectives, and they get an enthusiastic and highly motivated extra pair of hands. We decided to tackle the re-engagement campaign by having all the key stakeholders — design, software development, project, legal, customer care and the newsroom — involved in the entire process: from brainstorming solutions, to approving design mockups and product launch. It was something we hadn’t tried before. The spirit of inclusion and getting multiple perspectives on one problem seemed great in theory, but the reality didn’t quite align with what we anticipated. The Problem: We had a large pool of inactive newsletter readers — people who hadn’t read any of our email newsletters in over 60 days — and that number was only growing. When readers became inactive we stopped sending them the newsletter, but we did not tell them we were unsubscribing them. While it helped to clean up our subscriber list, it did nothing to potentially reinstate them as active readers. Clearly, this was a missed opportunity we needed to address. The Solution: Our primary business goal was to retain our engaged newsletter audience. We decided to target readers who were at risk of becoming inactive with messaging focused on re-subscribing to the newsletter. We proposed and developed an MVP that included two emails. The first email warned them that they hadn’t opened the newsletter in a while, and were at risk of being unsubscribed; the second presented the opportunity to re-subscribe before being automatically unsubscribed. If they didn’t take action and were unsubscribed, we deleted their information from our databases. By removing personal information about unsubscribed readers, we were also supporting our company’s effort to incorporate more privacy into the design of our products.This also improved our overall data privacy practices because we only retained information of engaged readers. We aimed to have an initial five percent re-subscribe rate. The Execution: Our two-week swarming sprint began and ended on Wednesdays. During the first two days, the entire team gathered in a large meeting room. As the product lead, I explained the problem and after a careful discussion, all team members brainstormed solutions, determined the work required, wrote user stories and finalized the roll-out strategy. By the first Friday, we had developed a timeline for the launch, created design mockups and drafted copy, which set us up to launch by the final day of our sprint. Initially, the concept of the swarming sprint sounded exciting and inclusive, but the practical challenges of tackling a problem this way consumed a lot of energy. The structure and process of the swarming sprint allowed everyone on the team to feel like they had their say on the direction of the product. All members of this team learned about the issues for each group, including the back-end infrastructure of Helix (our email Content Management System) and the front-end design. The tech side also learned about the business side, such as stakeholder mediation with other departments, the formalities associated with rolling out a new product, and the granular details required by both internal and user-facing messaging. As the stakeholders came up with new ideas, the scope of the work changed in small ways (font and copy) and large ways (the timing between emails and when a reader was deemed “inactive”). All team members had equal input and could suggest changes, so we had constant revisions to our MVP, which sometimes meant developers had to make last-minute updates to their code. We realized in this energetic chaos we were missing some of the advantages of a normal sprint process, like having more time to develop design mocks, groom tickets and hash out details between product and tech. Despite all this, we had a basic MVP that we could test at the end of two weeks. While the swarming format resulted in a more collaborative workflow, we needed to work out some kinks in order for it to be truly effective for the entire team. After testing, we concluded that we were able to re-engage enough readers to validate rolling out the re-engagement emails as an ongoing automated campaign. We achieved a total re-subscribe rate of 10.71 percent surpassing our initial five percent goal. After an in-depth retrospective, we realized that we needed to be far more organized in defining roles and responsibilities, as well as making sure we had clear definitions of what “done” means for all user stories. We were able to look back on our first swarming sprint with appreciation, acknowledging that although the two sprint styles were very different, they were both worth it because we learned how to work as a team, make decisions quickly and turn around an MVP in one sprint. The biggest takeaway for me was that no matter how things felt at the time, the team continued to support and help each other throughout, which made me feel proud to be a part of the team. It may have been disorganized and hectic at times but there was no blame or pointed fingers. Despite the chaos with the swarming sprint, we decided to give it another try. How we design and build digital products at The New York Times 36 Design Product Development Product Management Work Agile 36 claps 36 Written by How we design and build digital products at The New York Times. Written by How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-03-28"},
{"website": "NewYork-Times", "title": "does this product spark joy", "author": ["Eugene Wang"], "link": "https://open.nytimes.com/does-this-product-spark-joy-575c77ee1271", "abstract": "Code Data Product and Design Workplace Culture Work with Us Almost as soon as The New York Times debuted our first website in 1996 , we started experimenting with different digital product strategies. At first, we just put our articles and photos on the web, but as digital trends evolved, so did our site. To connect with new audiences and take advantage of emerging technology, we built new features to augment our core news report. As you might imagine, over 20 years of digital product development had given us a portfolio that included a hodgepodge of features that reflected several different strategies. But like many things on the internet, not everything we’ve built has landed well or withstood the test of time. Over the years, our digital portfolio became cluttered with many features that didn’t make sense for us to maintain as a news organization. So in the summer of 2017, we embarked on a nearly year-long project to identify which products and features to keep and what to scrap. At this same time, we were in the process of migrating our tech infrastructure to the cloud, so we thought it made sense to use the migration as an opportunity to get our digital portfolio in order. And because we were sifting through over 20 years of accumulated tech debt, we decided to apply a few of Marie Kondo’s home organization principles to our digital portfolio. We even dubbed the effort “Project Kondo” as a reminder for us to let go of clutter and accept a organized approach to product development. But before we could dive into cleaning up our digital house, we first had to take a look at the stuff we had accumulated. Throughout the years, we’ve tried on several different digital product models in addition to our daily news report. These efforts often reflected the prevailing internet trends of the time instead of highlighting our strengths as a journalism company. For instance, in the mid-2000s, we launched a feature called TimesPeople that tried to piggyback off of the social networking trend exemplified by MySpace and a new start-up at the time called Facebook. TimesPeople was basically a social network for Times users. The feature allowed users to add others as friends to see what Times stories they were reading and recommending. While it was an admirable effort to engage our large audience of commenters, the feature didn’t get much traction and after a handful of years we stopped investing engineering and product resources into expanding it. TimesPeople was an attempt to help facilitate connection between our users, but we weren’t able to effectively monetize it. However, other features we developed in the 2000s were tied more clearly to business goals. As it became clear that the future of media would be online rather than in print, we tried to transfer over some of our print money-makers to the digital world. We developed a digital classifieds product that — you guessed it — allowed users to post classified ads online for whatever stuff they were selling or for things they needed. Print classifieds had been a big source of revenue for newspapers like ourselves for a long time and we hoped to continue making money from digital classifieds. However, that model quickly unraveled as free classified sites like Craigslist made it easier, cheaper and more effective to post classified listings online. Needless to say, by the time we started Project Kondo, our classifieds section resembled a ghost town. While these features reflected valiant efforts to grow our business as the internet evolved, over the years, our priorities changed and we shifted our focus away from things like TimesPeople and classifieds. Yet, while we knew that our users and business had moved on from these features, we didn’t put in the effort to properly shut them down. Instead, we built new features without doing the hard work of re-evaluating the old ones. To make matters worse, the underlying servers, infrastructure and code continued to run for the old features. Our product portfolio started to look like a hoarder’s closet, but instead of piles of stuff, we had acquired a ton of technical debt and zombie products. Little by little, this accumulation of digital clutter weighed us down and made it harder to iterate quickly on the product experiences we actually did want to maintain. However, with Project Kondo we finally had an opportunity to take everything out of our digital closet, hold it with both hands and ask whether it sparked joy before deciding to discard it or put it in its proper place. Choosing which products and features to keep and which to toss proved difficult; it turns out that deciding what sparks joy can be just as hard for a large company as it can be for someone going through their own closet. Some didn’t fit cleanly into our portfolio but offered side benefits like a dedicated audience or a stream of revenue. Others served as technical dependencies for yet even more features or had dedicated stakeholders with ingrained workflows or processes, so untangling this knot of technical and human processes proved difficult. Ultimately, we decided to use these guiding principles to help us decide what to keep and what to toss. Are people using this? Obviously, if no one is using a feature it’s O.K. to retire the thing. Does this have a distinctive purpose or further our editorial mission? Some features don’t get much user traffic, but they mean a lot to the users who do use them. Or, the feature is necessary to accomplish some editorial goal. Does this make us money? If yes, then there’s a larger concern with shutting down the feature. In general, products or features that advance either subscription or advertising revenue needed to be considered for migration rather than retirement. Does this get us closer to our company goals? Sometimes, a feature can make us money but that doesn’t mean it aligns with our goal of being a subscriber-first company, which was laid out in a public memo that detailed where we wanted to be by 2020. Does this require considerable maintenance? The main goal of Project Kondo was to reduce the long-term maintenance costs associated with nytimes.com. We wanted to retire or archive anything that required a level of maintenance beyond the value they brought to our users, our newsroom or our business. After we evaluated each feature in our digital portfolio against these guidelines, we developed a project plan that laid out the steps necessary to shut down or migrate them. The individual steps for shutting down a feature weren’t complicated — adding user messages or redirecting traffic —but what proved most difficult was the coordination around what to shut down and when, given how tangled the technology underlying these features had become. Ultimately, we shut down poor performing features that didn’t align with our core journalism mission. Other features that still had a strong user base or aligned with our news site, such as sections like Today’s Paper , were upgraded and migrated to a more modern platform. We were able to successfully shut down or migrate all of the features on our list before our data center migration deadline. However, if we had been more diligent about keeping our digital house in order over the past two decades and periodically clearing out the clutter, Project Kondo may not have been necessary in the first place. If you work at a company that does business online, it’s a worthwhile exercise to evaluate your digital portfolio periodically to see what products and features continue to make sense and what should be shut down. But keeping it tidy and organized is hard. Once something has been launched and has acquired users, it’s easier to just keep it going. This is often at the expense of maintenance and technical cost, and it can lead to drift in both your tech stack and product direction. We certainly learned that the hard way throughout Project Kondo. Here are some tips on how to keep your product portfolio lean and focused so you don’t need to go on a year-long, cleaning binge just to keep your digital house in good shape. Shutting down non-performing features can be demoralizing, but it’s important product portfolio hygiene. But if you regularly audit your portfolio for non-performing features, you’ll be better positioned to identify where to invest resources, leading to a more focused portfolio and fewer distractions for your product team. Just like how user onboarding is critical to convert new users into happy and active customers, off-boarding users is important as well. When you shut down a feature, you should have a plan of what to you’d like those users to do. Show them the value of other features that you’re still actively supporting. But be warned: users probably won’t be happy that you’re shutting down a feature; even if the feature is neglected, habituated users generally don’t like their habits being disturbed. Bonus: document your off-boarding plan so it can be replicated for future non-performing features that have outlived their usefulness. Most old features, even under-performing ones, will have stakeholders who are involved in keeping them alive and running. In our experience, stakeholders were amenable to the idea of shutting down products if they understood that the products were no longer relevant or fit into the overall business strategy. Rather than acting as roadblocks, stakeholders can shed light on the history that lead to the development of the products, and they can help strategize anything that could help make the off-boarding process smoother. After identifying the features that should be shut down, you’ll need to determine which to shut down first. It’s important to prioritize the features that are making it more difficult to build the product experience you ultimately want, since it’s likely that there is a web of dependencies that emanate from your oldest products and features. Identifying roadblocks and prioritizing their shut down will help your organization iterate on more important things. Shutting down old systems, products and features can be a thankless, difficult job. However, decluttering your product portfolio can be immensely beneficial in terms of lower maintenance costs, faster team velocity and improved business efficiency. And similar to the benefits of the actual KonMari methods, you’ll likely find yourself less stressed and better able to identify what parts of your digital house actually spark joy in your users. How we design and build digital products at The New York Times 83 Konmari Product Product Management Design Journalism 83 claps 83 Written by How we design and build digital products at The New York Times. Written by How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-04-17"},
{"website": "NewYork-Times", "title": "a window into our sql interviews", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/a-window-into-our-sql-interviews-dcc9a8f756d8", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Alice Liang , Max Gendler and Robin Lee We have published an update to our SQL interview process for data analysts. You can read more about it here . The New York Times is a data-driven company with a large team of data scientists, analysts and engineers who provide insight on everything from site analytics to subscription modeling . Our analysts work with teams in the newsroom, advertising and marketing to run A/B tests, build models for complex data questions and architect data flows. While analysts may have different responsibilities depending on the team they’re embedded with, every part of the work requires a strong understanding of SQL. With such a broad range of teams, we needed an effective way to evaluate our candidate pool. So, we recently implemented a common technical SQL exercise for all open analyst positions. This means we have a base from which to evaluate incoming candidates, and we know that everyone hired into analyst roles will have similar skills. Here, we’re sharing an overview of the technical exercise we give candidates that has brought a more transparent, efficient and consistent hiring process to our team. The interview process for each data analyst position starts out similarly: a candidate first has a brief phone call with a member of our Talent and Inclusion team to discuss their experience and whether the open position fits what the candidate is looking for. When a candidate passes the phone screen, they’re scheduled for a 30-minute technical interview via Google Hangouts with an SQL assessor, who is either an analyst or a manager within the Data & Insights group. The SQL assessment is designed to understand both a candidate’s technical abilities and how they use that knowledge to answer business-focused questions. This exercise is not to test how well a candidate has memorized SQL functions, so we encourage candidates to use documentation or other online sources if they get stuck. We want to see how well they can ask questions about the data, work with documentation to get effective SQL statements and interpret the results of a query. The exercise allows a candidate to experience the kind of work we do and to evaluate if they are interested in doing it full time. We settled on 30 minutes for the interview because it’s a short commitment with great benefit for both sides. We broke the interview into three parts: five minutes of set-up, 20 minutes for the SQL exercise and five minutes for the candidate to ask any other questions. Right before the interview, the candidate receives an email with a link to join BigQuery, which is the Google database service our analysts use, as well as some relevant documentation. The first five minutes are spent signing in to and setting up BigQuery. For the next 20 minutes, we give the candidate access to a randomized and anonymized subset of actual data from the Times’s website, which allows them to run queries on the platform and see the results, just as any Times analyst can. The exercise can be quite fun. Candidates who have gone through the exercise have told us that it’s exciting to see and work with the data. We prompt candidates to use the data provided to look for specific patterns in how our readers interact with our main site. Our prompts don’t ask direct SQL questions such as, “How would you use a CASE WHEN statement in SQL?” but rather more open-ended questions to ask candidates to make comparisons using the data and combine information from different datasets. We want to see that the candidate can translate business requirements into things that can be done in SQL, mirroring what our analysts do on a day-to-day basis. We follow a rubric when evaluating a candidate during the SQL assessment. In particular, we look for the candidate’s process in writing an effective SQL query, as well as how they interpret the resulting dataset in a way that answers the business-focused prompt. We also encourage candidates to ask insightful questions about the data and the prompt. Our SQL assessors take notes along the way, and we can provide some helpful hints if needed. Over the past couple of months, we’ve gathered information from the SQL assessments we’ve given, and we’re still iterating on the best questions we can ask candidates. We’re continually making other improvements to the process. Hiring a diverse workforce and being inclusive in our hiring practices is important to our team and to The Times. With the SQL technical assessment, we have developed a few best practices such as meeting every few weeks to discuss how to make these assessments more consistent. We also believe making the process transparent may help us hire better qualified and more diverse candidates. We take extra care to continually make sure the assessments are fair and fun for everyone involved. Our assessors will not see a candidate’s resume before the technical interview. Since the SQL assessment’s objective is to evaluate candidates’ skills in SQL and data analysis, information such as a candidate’s school or company do not add signal to the technical evaluation. A candidate’s background shouldn’t affect how we assess them; it doesn’t matter where they learned SQL or if they used it in a past job. We’re most interested in how a candidate uses their SQL knowledge in a Times context. Assessors are able to peer review each other’s evaluations along with the queries run by candidates. From time to time, we sit in on each other’s interviews to make sure we’re evaluating the candidates in a uniform manner. The SQL test is only the first part of the interview process, and candidates who do well on it can move forward to meet with the hiring manager and other team members. Outside of the SQL test, an assessor is not part of the rest of the candidate’s hiring process. This helps to ensure that the assessor can give an unbiased score to the candidate’s technical ability. We know technical tests, and especially live ones, can be intimidating — we hope this helps to clarify what our technical interview is like, and what we’re looking for in data analyst candidates. Please apply to an opening in Data & Insights if you are interested in JOINing our team. Alice Liang is a Marketing Data Analyst for the Data & Insights team at The New York Times. Follow her on LinkedIn . Max Gendler is a Senior Data Analyst for the Data & Insights team at The New York Times. Follow him on Twitter . Robin Lee is a Data Analyst for the Data & Insights team at The New York Times. Outside of work, he’s a data meetup organizer. Follow him on Medium . How we design and build digital products at The New York Times 774 2 Recruiting Data Work Careers Technology 774 claps 774 2 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2021-03-25"},
{"website": "NewYork-Times", "title": "we built a collaborative documentation site deploy your own with the push of a button", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/we-built-a-collaborative-documentation-site-deploy-your-own-with-the-push-of-a-button-134de99c42fc", "abstract": "Code Data Product and Design Workplace Culture Work with Us By Isaac White, Andrew Fischer and Suzanne Wang Maintaining useful documentation is hard. Whether it’s tips for running a program, publication guidelines or company rules, keeping track of resources can quickly become unwieldy. This is especially true at larger organizations where thousands of people care about similar tasks: It’s easy to end up with silos of duplicated instructions that only small groups of people know about. The New York Times is no different. Several years ago, it was common for each desk to have an internal wiki that they used to collect these instructions. As the use of Google Docs grew within the newsroom, the wikis began to be used and maintained less frequently, and knowledge of existing documentation became scarce. When the older wikis were shut down in 2017, several teams that often collaborate realized we no longer had an effective strategy for sharing documents across the newsroom. We realized we could do better, and decided to build a centralized tool, called Library, that would host our documents in a way that could be shared across the newsroom. Our solution to this problem has worked well for us. We hope others will find value in the technology we built, so we’re releasing Library to the open source community. Library is a wiki powered by a Google Docs backend. When you connect Library to a shared folder or team drive, it will traverse the documents in the folders and create your site content. Documents in Library are searchable, taggable, and can be grouped by desks or categories. To add a page to Library, you simply create a new Google Doc, or move an existing document into the folder or team drive that powers Library. Existing pages feature a convenient link that enables quick access to the Google Docs interface for any particular document, and editing the Google Doc makes changes to the page in Library. Powering a website based on Google Docs might seem like an odd choice. Plenty of other solutions for wikis provide their own interface to edit content and are self-contained. But many desks in the newsroom had already begun keeping their notes in Google Docs, so we wanted to meet people where they already were, rather than trying to teach them something entirely new. Using Google Docs as the editing interface for Library helped us create a living repository of documents, how-tos, tips and guides that everyone could contribute to. It already provides a robust set of tools for document history and real time collaboration, which makes it an ideal editing interface for a wiki. With the editing interface handled by Google Docs, we used the Google Drive API to retrieve the content from each document and render it inside the wiki. Instead of just showing a list of links to Google Docs, Library provides a clean interface for viewing and navigating between those documents. Our intention with Library’s browsing experience was to make it as intuitive as the editing interface. We anticipated that most Library users would be looking for documentation by keyword or phrase, so we placed a search bar as a prominent element on each page. When a user searches for a document, the results will include relevant documents, annotated with information about who last edited it, and where in Library the document is stored. For users who would rather explore specific topics, there is a “View All Docs” page that will list the top level of each folder in Library by category. A basic version of Library works “out of the box” without the need to write any code. To demonstrate the features of Library (and facilitate an easy deployment pattern) we’ve created a “Deploy to Heroku” button that is accessible through Library’s Github README page. Clicking the button will guide you through how to set up a new Library instance. Deploying to Google App Engine is also supported, via the instructions on the documentation site . With a little code knowledge, you can customize the site language, create themes or use a specific authentication method. We’re also releasing a Docker image, which more advanced users may find useful for deploying in other environments. Library can be deployed with or without an additional customization layer, and we encourage you to explore the example to see how easy it is to use. We’ve been collaborating with Northwestern University’s Knight Lab to alpha-test this release (special thanks to Maxine Whitely and Joe Germuska for their feedback). In the spring, the Knight Lab will be piloting an internal Library for student use. We plan to partner with the Lab to expand Library’s features and explore other uses for Library in the news community. To contribute to Library, check out the README on Github and consult the contributor guide . For more information about what Library can do and a demonstration of a running copy, consult the sample deploy . We’re looking forward to collaborating with you. Isaac White is a Senior Software Engineer on the Interactive News team at The New York Times. Follow him on Twitter . Andrew Fischer and Suzanne Wang were summer interns with the Interactive News team in 2018 and contributed to this project. How we design and build digital products at The New York Times 797 4 Journalism Work Collaboration Open Source Code 797 claps 797 4 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-03-20"},
{"website": "NewYork-Times", "title": "from audio waves to words episodes of the daily now come with transcripts", "author": ["Dalit Shalom"], "link": "https://open.nytimes.com/from-audio-waves-to-words-episodes-of-the-daily-now-come-with-transcripts-298ab8cb9481", "abstract": "Code Data Product and Design Workplace Culture Work with Us It’s an introduction familiar to many: “From The New York Times, I’m Michael Barbaro. This is ‘The Daily.’” But a large number of Times readers have never heard Barbaro’s greeting. That is because “The Daily” has only been available in audio form, which means its report is inaccessible to many of our readers. What makes podcasts so special, also renders them inconvenient: they can only be heard. Over the past few months, we’ve experimented with ways to make our audio content more accessible to readers. We’re releasing audio transcripts for each new episode of “The Daily,” with transcripts rolling out for other Times podcasts in the future. It’s important to us that all of our readers can engage with our report, whether they choose to listen, share or read, and audio transcripts are a big step forward in our commitment to make Times content accessible to all users . An audio transcript is a word-for-word text document of an audio file. Each line of the transcript is printed alongside its corresponding timestamp, making it easy to navigate the audio file. Reporters often use transcripts to find and reference quotes from interviews, but transcripts can be useful to readers, too. The script-like layout is great for understanding what is mentioned in an audio clip, finding a line that covers a particular subject or copying a salient quote to share on social media. The process of transforming audio into text can be tedious. While we could have a Times producer listen to every episode and type out what they hear, that would be too time consuming. For podcasts that publish frequently, like “The Daily,” doing our own transcription wasn’t a feasible option for us. We instead opted to use 3Play, a third-party service, to transcribe the audio. Being able to hand off the task of the transcription is key in a workflow that is already packed and very fast-paced. The document that 3Play produces not only captures the words of the show, but also includes labels that indicate when different people are speaking. Before the transcript is published, a Times editor reads over the document to review its accuracy and replace the generic labels with the names of those speaking. Although we could have simply pasted the full transcript on the page, we decided to introduce more interactivity into our transcript pages. We took feedback from Times readers and listeners of “The Daily,” and we designed for accessibility, shareability and reference. When we approached this design project, we knew that transcripts needed to be easily findable, and we knew that they had to be closely tethered to the original audio piece. We decided to build the feature into our podcast pages and our embeddable audio player, but what that actually looked like took some experimentation. The audio player on “The Daily’s” podcast pages is often followed by supplemental content related to the episode. With that in mind, we wanted to give readers the option of toggling between the transcript and the supplemental content, without sending them to a new page. Some of our initial designs included text that appeared, karaoke-style, as an overlay on the audio player. While this gave weight to what was being said in the audio at a given moment, it didn’t allow for searching through the episode. Much like closed captions on video, how quickly text appeared was dependent on how fast words were said in the audio. Since many people often process audible words faster than they read printed words, we didn’t see this as an optimal experience for our users. A reading experience that was so tied to the audio was problematic because it prioritized audio in a way that wasn’t great for our readers who are hard of hearing. This led to us explore other options, like the one below. In this version, we considered revealing more text in an overlay on the audio player. As the audio advanced, the corresponding line would be highlighted. Though this exposed more of the text, it was limiting and still too closely tied to the audio. Anyone who wanted to search through the transcript would have to navigate through the audio. Our initial designs presented the transcripts tightly bound to the audio, meaning readers would have to engage with the player to read the text. We wanted readers to be able to skim the transcript without playing the audio, but still be able to control the audio if they chose to listen and read at the same time. Creating a page with its own URL was important for shareability reasons, so we opted for an overlay with a dedicated URL that could be accessed from the podcast page. As a nice side effect of dedicated pages, the content of Daily episodes now surfaces in search results. Let’s say, for example, that “The Daily” aired an episode about climate change, and in that episode coral reefs were discussed. With transcripts attached to the metadata of an episode, anyone searching ‘coral reefs’ can discover that episode of “The Daily.” In future releases, we are planning to build in functionality that allows readers to click on a line in the transcript and be taken to that segment of the audio. We are also exploring ways that our readers might share specific clips of the podcast on social media. Transcripts will also be rolling out in the coming weeks for “ The Argument ” and for the next season of “ Still Processing .” But for now, with this launch of audio transcripts for “The Daily,” we’re excited to provide an additional way for readers to experience The Times’s journalism. As with all of our products, we are receptive to feedback from our readers and listeners and are eager to make improvements that would better the overall experience. How we design and build digital products at The New York Times 288 4 Podcast Design Design Thinking Accessibility Product Design 288 claps 288 4 Written by Design @ The New York Times How we design and build digital products at The New York Times. Written by Design @ The New York Times How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-12-10"},
{"website": "NewYork-Times", "title": "no code no problem writing tests in plain english", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/no-code-no-problem-writing-tests-in-plain-english-537827eaaa6e", "abstract": "Code Data Product and Design Workplace Culture Work with Us By NAIDELE MANJUNATH and OLIVIER DE MEULDER Behavior Driven Development, or BDD, is an approach to software development where the behavior of a feature is defined through examples in plain text. These examples, known as feature files, are defined before development starts and are used as acceptance criteria for new features. Written using the Gherkin language , which uses English words, the feature files are readable to anyone regardless of programming ability. Feature files are written in a “behavior-driven” style, meaning they contain details on how a feature is supposed to behave when something happens in a given situation. This behavior is the only information that is mentioned in the feature file; the underlying implementation details of the feature are not mentioned. Our cross-functional team — the Customer Care Technology team at The New York Times — uses feature files to have deeper conversations about our product, which helps create a shared understanding of what should be developed. When everyone understands our user stories, we waste less time in the production process and have fewer instances where we redo the work we’ve done. Writing feature files together encourages collaboration, and helps developers and QA understand the business aspects of the story. Because anyone on the team can read and write feature files, we don’t need to rely on testers or QA engineers to write the tests. At the beginning of each sprint, our product manager writes the user stories for each feature, following Agile principles. Here is a simple example of a user story that we might include in one of our sprints: As a customer care advocate, I want to update a customer’s credit card on file, so that the customer’s new credit card will be charged during the next billing cycle. When the user stories have been written, our product manager and our developers sit together to translate the user stories into feature files. The feature files serve as the outline for the automated end-to-end tests that the developers are responsible for writing. Following our example of a user story above, the feature file may look like this: The automated tests are written in Javascript. Each Given , When and Then line in the feature file correspond to a simple Javascript function, and the Then line will contain the test assertion. Our team uses the Mocha assertion library , webdriver.IO as a test runner and the Cucumber framework to interpret the test feature, but any can be used. The developer working on the automated end-to-end test can run the test locally on their machine. And this is where the magic happens. The test runner parses the feature file, figures out which JavaScript functions to run and reports back. Once all the end-to-end tests pass successfully, there is one more step. The BDD testing framework is integrated in our continuous integration (CI) pipeline. This allows everyone to verify that the tests run in the staging environment. A report from the test may look like this: As you can see, the report is easy to read, even if you do not have a technical background. So, what makes BDD worthwhile? Our team has seen four tangible benefits: Increased collaboration. The product manager is involved in designing the tests, which means they work with the developers (and QA, if applicable) to clearly state the business rules. Everyone on the team has a strong understanding of new product features and the progression of the project is clearly visible to each member. Living documentation. Because the feature files serve as the checks before features reach production, they need to be kept up-to-date. Any modifications to the product or features means that the files have to be updated to avoid failures caused by the feature definitions. While documentation is often an afterthought in software development, BDD makes it an integral part of the development process. Quick Ramp-up. Code doesn’t make sense to everyone. It also doesn’t make good documentation. Working with team members who don’t understand code usually means that the team has to create a separate document, like a spreadsheet, to describe what is covered by the test code. BDD helps solve this problem with feature files. Newcomers to the team can read feature files and quickly understand what the feature does. This is better than going through tons of documentation. Readable Reports. Usually, test results are not presented in a user-friendly format — a log in the report could say something cryptic like, “expected false to equal true.” Although this may be simple to read, the context or meaning is not clear to the reader: what was expected to be true and is now false? With BDD results, each result falls under the corresponding scenario in the BDD feature file, which provides better readability. Our team started using BDD a few months ago. At first it was a bit scary and overwhelming because everyone needed to learn a new technical skill and work together in a new way. Over time, the team mastered BDD testing and found that working closely together was a very natural process. When the team collaborates on feature files, we’re more aligned on the development cycle and the product becomes better. Naidele Manjunath is a Software Engineer with The New York Times Test Automation Team. Olivier De Meulder is an Engineering Manager with The New York Times Subscription Platforms Group. How we design and build digital products at The New York Times 960 Software Development Technology Code Programming Software Testing 960 claps 960 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-02-01"},
{"website": "NewYork-Times", "title": "how we designed our front end engineer hiring process", "author": ["Mike Reifman"], "link": "https://open.nytimes.com/how-we-designed-our-front-end-engineer-hiring-process-9b8f20cc31fb", "abstract": "Code Data Product and Design Workplace Culture Work with Us My colleague Brian Hamman recently wrote about how we are piloting a new process for hiring front-end engineers at The New York Times. We consolidated separate job postings for each open position into a single posting, and we streamlined the interview process across all teams. This unified process is an attempt to meet a number of different organizational goals, from changing how we present ourselves as an engineering organization to building consistency in how we evaluate candidates. And frankly, we’re growing quickly and have many roles to fill, which we’d like to do efficiently and with candidates who will be assets to the company and our culture. While trying to meet all of these goals, we — a group of volunteers from the Technology and Talent & Inclusion departments — sought to design a consistent evaluation process that is attentive to a diverse candidate pool while being pragmatic and iterative. Our evaluation process is based on expectations that are shared across the Technology organization. Each stage of evaluation is aligned to a specific rubric that helps us evaluate candidates consistently. For example, we expect to see certain things in a take-home exercise that we wouldn’t be looking for from whiteboard coding. Committing to rubrics keeps us honest about what we’re looking for and realistic about whether we can get quality signals on those criteria for each step in the process. We created evaluation rubrics for assessing resumes, phone screens and take-home exercises. For our in-person interviews, we borrowed from Medium’s rubric for grading engineering interviews because it has terrific in-depth coverage on criteria that align with our hiring values. However, it’s not enough to simply list our evaluation criteria. To provide richer context on what we’re looking for, we give interviewers sample interview questions with answers we consider to be good and bad. This helps interviewers ensure that they can accurately evaluate candidates for each criteria, and it promotes consistency across interviewers. As a company, we believe that achieving diversity and being inclusive is not only the right thing to do, it is the smart thing for our business. We state this in all of our job postings. It’s therefore important that our tech hiring process is open and attentive to a broad candidate pool. To work towards that goal, we started with the job description. Postings that focus on a list of skills can discourage women from applying , because candidates preemptively disqualify themselves if they don’t meet all of the criteria. We framed our job posting as an advertisement for the role, using language like, “you will get to do x, y and z.” This helps candidates understand that new hires aren’t expected to know everything on day one. While we used to ask for cover letters, we found that they tend to be formulaic and don’t offer meaningful information. Instead, we now ask candidates to fill out a short questionnaire that includes the question, “Is there anything else we should know about you?” This free-form space invites candidates to share information that might be relevant to their application — such as a gap between jobs — without the constraints of a traditional cover letter. As candidates move through the interview process, we evaluate them in a variety of contexts. Phone interviews include a technical discussion, as well as hands-on coding done using a shared screen. The take-home exercise we sometimes give candidates is meant to approximate the type of work we do at The Times. Finally, the in-person interview segments cover a range of technical and non-technical skills, and involve colleagues from departments other than Technology. All together, these contexts give candidates a variety of opportunities to show their strengths and make sure our process isn’t biased toward one kind of person. For interviewers, we put a focus on countering unconscious bias. Each evaluation phase has assessments from multiple interviewers to prevent blind spots. We found this especially useful for reviewing applications, since resumes can be vague and varied, and elicit divergent reactions from different reviewers. To address this, we created structured feedback forms for each phase of the interview process that reflect the corresponding evaluation rubric. This format ensures that interviewers submit their feedback in the same way, which creates consistency between candidates as well as between multiple reviewers of the same candidate. Designing an interview process is no easy feat, and it needs to be open to changes. As we designed the process and put it into practice, we made iterative tweaks to ensure that it wasn’t too cumbersome or off-putting, all while making sure that our original goals were still being met. Those tweaks ranged in scope from how the entire process was structured to the nitty-gritty details of how rubric criteria were worded. One idea we explored early on was to anonymize resumes by removing identifying information about the candidate, such as their education and the companies they’ve worked for. (It’s illustrative and fun! Here’s an example of what this can look like.) A few teams at The Times tried this and found it useful, but it’s a very heavy lift, especially when there are multiple open positions and lots of incoming resumes. Instead, we leaned on repeatedly reminding reviewers about unconscious bias and linking to resources like 18F’s terrific guides for reviewing resumes in our resume review rubric. We ultimately decided that a low-fidelity process was acceptable at the resume review phase. Rather than have each reviewer score every resume on a scale of one to five for a set of criteria, reviewers now give a thumbs up or thumbs down, guided in their judgement by our rubric. If there is any disagreement, they discuss their votes and reassess. Otherwise, they keep moving. The rubric still provides a framework for decision-making, and we can assess candidates more quickly. A nice side effect of this effort is that it has produced a framework for designing new hiring processes and making changes to existing ones. As we continue to evaluate and iterate on how we hire, we are building shared expectations across teams, which means that we can focus on the things we value. It’s an exciting time to work in Technology at The Times. Not only do we develop technology that powers our incredible journalism, we’re committed to building a engineering culture that is open, inclusive and ambitious. We’re hiring! Come work with us . How we design and build digital products at The New York Times 92 Hiring Technology Code Management Diversity In Tech 92 claps 92 Written by How we design and build digital products at The New York Times. Written by How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2019-02-06"},
{"website": "NewYork-Times", "title": "open questions carlos a gomez uribe", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/open-questions-carlos-a-gomez-uribe-fa60d5b738c9", "abstract": "Code Data Product and Design Workplace Culture Work with Us By NICK ROCKWELL and CHRIS WIGGINS Carlos A. Gomez-Uribe is the former Vice President of Product Innovation at Netflix, where he oversaw algorithm development for movie recommendations and search. New York Times CTO, Nick Rockwell, and Chief Data Scientist, Chris Wiggins, spoke to Gomez-Uribe about his career, the evolution of machine learning at Netflix, and how companies should be very thoughtful about how they integrates machine learning into products. The following has been edited and condensed. Q. How did you come to work in Product at Netflix? Do you think it’s important for product managers who work on recommendation have math skills? A. I started at Netflix as a data scientist, and worked on a wide range of projects across the still-small company. However, after talking to the engineering and product teams working on the recommendation algorithm, I became very interested in that specific area. Netflix was planning a streaming-based global product, and the recommendation algorithm was still relatively basic; it optimized mostly with the information that was available from the DVDs-by-mail product. I came up with a number of ideas to learn statistical models based on streaming data to improve the recommendations, and I proposed the ideas to the product team. They were open and interested in the models, but did not feel comfortable enough with the quantitative methods involved to decide to sponsor any of them. Thankfully, my boss at the time, Chris Pouliot, was supportive (although skeptical) of the ideas, and gave me a few weeks to develop one of them into an offline prototype. The recommendations that the prototype produced looked interesting enough that once we showed them to the product team they sponsored the project. We worked with engineering and other teams to fully develop and test it, and based on the results, we deployed it. This success led the product team to invite me to work on other recommendation-related projects. In the course of one of them, I became convinced that it was suboptimal to have people — the product managers in this case — who were not deep on quantitative methods manage the entire innovation process. So I passed on that criticism to the product team. To my pleasant surprise, their reaction after thinking about it for a few days, was to agree that it would be interesting to experiment having product managers with a deep and broad quantitative experience, and created a new position to try the idea out. Even more surprising: they asked me to interview for the new position. So I moved to the product innovation team. The result worked well enough that I was then asked to build a team of product managers with a strong quantitative background to manage the innovation process for recommendations and search at Netflix. Finding the right people for this team took time, but the effort was well worth it because they were better able to lead the cross-functional teams that built the global recommendation and search technology for Netflix streaming. This experience is in stark contrast to what I have seen in other firms I’ve spent time in, and I remain convinced that strongly quantitative product leaders managing the innovation process is the only way to create high quality algorithmic products. You were at Netflix for seven years; what changes did you see in the way machine learning was used over that time? It became more sophisticated. We started with few relatively simple time series or regression models for video ranking, and over time we found more important use cases such as a recommendations page construction or selecting the right image to support a recommendation. In parallel, we found that more complex models of various kinds, appropriately tuned and used, delivered a better experience. It can be hard to entrust critical parts of the product experience to machine learning, but only deploying machine learning in marginal parts of the product guarantees limited impact and limited learning. How do you think about making the leap of faith to trust machine learning with impactful aspects of the product? I think you should never blindly trust a machine learning system to behave better than an alternative (such as hand-curation), until proven otherwise. Even after getting such proof, a machine learning system needs constant monitoring to make sure the entire system or product continues to behave well — in a way that is consistent with the mission of your organization — as the world around it changes. The point is to articulate how you expect machine learning will improve a product or experience, and then invest in the research and development to explore that hypothesis. Only through careful testing and analysis aimed at understanding the full implications of a change should you switch to a product that is based on machine learning. The process is long and expensive enough that it does not make sense to only try it on small parts of your product, because even in the best cases, the return to the business and to the people who use your product will be small. Last summer, Monica Rogati wrote a great piece called “ The AI Hierarchy of Needs ” and argued, “You need a solid foundation for your data before being effective with AI and machine learning.” However, sometimes cool results through machine learning can provoke the kind of improvements a company needs to extract more value from a company’s data. Is it productive to develop machine learning capabilities before your data engineering is perfect? Your data engineering will never be perfect, so it is unwise to wait for perfection to develop machine learning solutions. However, if the data is too noisy, brittle or sparse, you will waste your time building and deploying large-scale machine learning solutions. You need to be somewhere in between. One approach is to have a hierarchy of data that you care about, and start to develop machine learning solutions once the first hierarchy of data is solid. In parallel, continue to work on improving the quality and availability of other data. Also, I think it is always productive to try to better understand your clients, your business, your product and any interactions between them. Data modeling and analysis can be a great way to do that; it can help generate hypotheses and potentially useful input signals for machine learning technologies that can be developed later. Much of this exploratory work can be done before the data is production ready. Talent feels very constrained right now. With such an intense recruiting effort from big tech companies, it’s very hard for the rest of us to hire qualified people, even straight out of school. So how do we move forward when talent is so constrained and what does it mean for the development of AI? Universities are responding by starting to train more and more people in the combination of skills like statistics and computation that are necessary for this kind of work, so supply is increasing. But demand is also growing as more organizations realize they can derive value from these skills. It is unclear to me how the next decade will play out in terms of this. However, I also think companies that want folks with an AI background should be very clear about the mission of their organization, and the role AI can play within that mission. Surely, within the pool of well-trained people in AI, you should be able to find those who are not just interested in it, but rather passionate about the specific intersection of it with the mission of your organization. There’s several ways data can influence product, such as A/B testing and reinforcement learning to optimize or personalize. But even before that, Netflix has been able to use data to suggest new features to test, or even new content strategies. Can you talk about how digital companies can use data to suggest new features,new products, or even new content strategies? This goes back to an earlier question: using data analysis and modeling to better understand your business, your clients, your products and their interactions. For example, to find groups of people who tend to behave similarly when interacting with your product. Using the sizes of such audiences and analyzing the kinds of content each of these audiences engages with may lead you to change the content mix to better match the audiences with the offering. However, analyzing past data should mostly be used to generate hypotheses. Many will turn out to be false, such as simple correlations that play out differently when implemented. So testing, whether fully controlled (as in an A/B test) or not (changing something and analyzing the before and after) is always essential. You wrote a paper this summer about an online approach for matrix factorization models, which Netflix became famous for as a way to do recommendations. But you’ve also written about multi-armed bandits . When is a supervised learning approach like matrix factorization the way to go for recommendations, and when should a company be using bandits? Factorization models have proven to work very well for personalization because they efficiently share information across individuals and items to learn one small (e.g., 100) set of numbers to describe the behavior of each person and each item. On the other hand, multi-armed bandits are essentially a regression model that predicts an outcome based on a weighted sum of input signals. This is problematic for personalization, where by definition, we expect that the interaction of an individual and an item is important. But quantifying such an interaction to turn it into a small enough number of input signals for a regression model can be complex. Multi-armed bandits can be very successful in unpersonalized settings because they use so-called explore-exploit strategies to avoid missing out on good decisions (such as which articles to recommend) just because you do not have enough data for them. The point of the first article you mention here is that one can also implement such explore-exploit strategies with factorization models, if relevant for a particular problem. Since Netflix is a subscription service, it seems like the most important thing to optimize is retention, which only gives you a signal every few months. How do you prioritize fast proxy KPIs like clickthrough against more important but slow KPIs like retention? How do you balance quick optimization via reinforcement learning vs. the slow response of A/B testing? I left Netflix almost two years ago, so I don’t know how they make algorithm decisions today. But in the internet tech industry in general, you find a very quick proxy (plays, reads, clicks, etc.), then you carefully test a model trained on such short-term data to determine if the longer-term metric actually improves. At Netflix, this always meant waiting three to six months before we would be confident about having found a better version of the product. Most companies I know aren’t as patient and I think that’s a mistake. In internet tech, I have not yet seen any successful application of reinforcement learning to directly optimize the long-term metric one may care about, but I think this direction is interesting and has not been explored enough. Overall, what lessons did you learn about how a company should (or should not) integrate machine learning into their product development? Very carefully and thoughtfully, in particular, making sure that the resulting product is of high quality (not favoring the worst quality of content or interaction one can imagine, regardless of your KPI). That the product ends up being at least consistent with, and ideally supportive of, the company’s mission. And finally, having an opinion about the product’s societal consequences. How we design and build digital products at The New York Times 34 Machine Learning Data Science Data Netflix Conversations 34 claps 34 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-12-04"},
{"website": "NewYork-Times", "title": "were making changes to our front end engineering process", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/were-making-changes-to-our-front-end-engineering-process-abfc9654693d", "abstract": "Code Data Product and Design Workplace Culture Work with Us By THE TECH HIRING TEAM A few months ago, Brian Hamman, Vice President of Engineering at The New York Times, wrote about our new process for hiring front-end web engineers. We replaced nearly a dozen different applications to similar positions with a single process to apply to all teams. Now that we’re a couple months into that process and have reviewed over 1,000 applications, we figured it would be a good time to update how we’ve fared so far and talk about some of the changes we’re making. We realized that requiring a code test before the interview was asking a lot of our applicants. They had to invest a lot of time before they even had the chance to meet our teams and determine whether The Times was a good fit for their career. This is especially true for experienced candidates who often look for more specific roles. So we’re streamlining the process. From now on, we’ll advance some candidates from phone interview to on-site interview without first requiring a code test, provided their professional experience is comparable to our work at The Times. For on-site interviews, candidates get a chance to visit the office and meet with several engineering and cross-functional members of our teams. The interviews are structured to give candidates time to ask questions during each interview slot, so they should get a better sense of our teams and culture by the end of the day. After the interview, we’ll check in and see if there’s mutual interest in moving forward. We’re still asking some candidates to complete a code test before coming to the office. We recognize that not everyone is comfortable live coding during an interview, so we want to make sure candidates have a fair opportunity to showcase their skills. We think these changes reflect our mission to provide rewarding, instructive, efficient and fair experiences for engineering candidates — while ensuring that we hold those candidates to the high technical and collaborative standards that we hold ourselves to every day. This is the first of many iterations to our process and we’ll continue to make announcements as we make changes. If that sounds interesting to you, apply to work with us ! Allison McHenry, Director of Engineering, Games Austen Lein, Associate Manager, Recruitment Bennett Yates , Director of Engineering, Content Management Systems Brian Hamman , Vice President, Engineering David Yee , Senior Director of Engineering, Parenting Jerry B ., Director of Engineering, Subscription Growth How we design and build digital products at The New York Times 42 Hiring Engineering Technology Code Talent Acquisition 42 claps 42 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-12-21"},
{"website": "NewYork-Times", "title": "5 questions with giorgia lupi", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/5-questions-with-giorgia-lupi-23e2ba972fd8", "abstract": "Code Data Product and Design Workplace Culture Work with Us On October 18th, Giorgia Lupi , award-winning information designer, co-author of the book “Dear Data” and founder of Accurat , a data-driven design firm, stopped by the Times office to talk about her work and career. We caught up with her afterwards and asked about her career, how to find the human element in data-driven stories, and whether there is room for creativity in the creation of datasets. This interview has been edited for length. 1. Where did you start your career, and what got you interested in telling stories with data? I have a masters in Architecture, but I have never built any houses. During my studies I was particularly fascinated by the scale of the city and urban mapping projects, and also in how to represent the many information layers underlying an architecture project. After my graduation and for the following four years, I collaborated with different interaction design firms in Italy, primarily working on information mapping projects and interactive installations displaying complex systems of knowledge. Over time, I discovered that data can be an incredible lens to find and build stories and ideas. It is a material we can use to visually narrate stories. I simply fell in love with this world and the realm of possibilities it opens. I see data visualization design as the combination of my artistic side and my extremely rational side. What drives me in what I do is the overlapping space between analysis and intuition, between logic and beauty, between numbers and images. 2. Today, we have access to more data about ourselves and our world than ever before, but we all too often see stories reduced to a data point. What are some of the ways you approach data to find the human element in the story? Especially in my more speculative projects, I use data as a tool to better understand our human nature. By distilling our personal experiences into what we so coldly call data, and by actively building and expressing my datasets as an artist, I actually seek to grasp glimpses of humanity and discover overlooked details. Every time there is data available, I try to humanize it, to make it speak our language and represent our human nature. In my opinion, this is the ultimate goal of any design work, especially with data. I often combine what is already in the form of data with layers of softer and more qualitative information that can render more of our human aspects. When working with data, we often focus only on the hard numbers that are readily available to us without realizing they become more meaningful if we use more nuanced and expressive data along with them. In the end, my actual work with data is mostly hand-crafted, detail-oriented, laborious and inevitably human in the process. 3. So much of your work has been rooted in collaboration. What are some of the things you’ve learned through these collaborative projects? I recently came to realize that my idea of success for a project depends not only on the goals I am trying to achieve or how the project is received, but especially on the person or group of people I’m collaborating with. When I look back at the projects I have worked on, what feels most successful are the experiences where, by means of working with other talented people, I could experiment, venture out of my comfort zone and push myself to places I couldn’t imagine on my own. Collaborations are necessary for designers to grow, to question themselves, to discuss all their ideas and to avoid “getting married” to the first idea they have. I have also learned that I love sharing the results of a project (its publication moment and the, hopefully, positive response it triggers); it’s one of the best outcomes of a work relationship! Especially for self-initiated projects, a collaborator whose work you respect can help keep yourself accountable. They can get you through the project even when you feel overwhelmed and would like to give up. 4. Your company, Accurat, has launched some innovative projects using new technologies like AR. Are there any technologies you’re excited about for the options they give for telling human data-driven stories? I believe we are in a very interesting moment in time. With the hype around many new technologies finally fading, I think we can focus on the ideas we have and finding opportunities to tell stories. I am excited to be in this space right now because, thanks to open source and to the democratization of software technologies, individuals and small studios have access to the same tools as the “big guys.” This leads to a constant and positive tension between organizations that are very different, but that share the same tools. For example, newsrooms — who by definition have the best content and stories to tell — are now also leading on technological aspects and are teaching Silicon Valley how to use web technology to better serve people and stories. This was unthinkable even just six or seven years ago. And I’m excited not for the idea of technological progress in and of itself, but for what it will allow us to do. In general, I want our team to use technology as a tool, to master it so that we can get to the point where it can completely disappear in favor of the story we want to tell. I believe immersive technologies like AR and VR could eventually help us get there: we are still confined by bulky devices, but we are finally able to let content “live” in our physical world, and screen are becoming more and more invisible. And this, I believe, is a crucial aspect to telling real human stories with data. 5. You’ve created your own datasets, like in the project you did for MOMA’s “Items: Is Fashion Modern?” exhibit and your collaboration with Kaki King . How might journalists train themselves to have a more open mind about what counts as data? Is there room for creativity in the definition of a dataset? They can do that by remembering that data doesn’t really exist. Data is one of the tools we have to represent reality, but it is always a placeholder for something else and never the real thing. It can be easy to forget that. When designing, we need to always think about the content that the data represents, not the numbers. It’s never about numbers, technology or any design itself, it is always about the ideas and the stories. People think data will solve our problems, but we invented that data, so we are the ones actually solving them. No data is perfect, nor objective; it’s actually a very subjective process. We have agency in collecting, processing and interpreting data. If we recognize this, we can start seeing data as the beginning of the conversation, not the end. If we recognize it’s less perfect than we think, then we can question it, collect and define our own datasets. One of the goals of my research is to liberate the idea of data from academic definitions and show it for what it is: a material, a gimmick, a source of inspiration, a lens to look at the world or whatever else you want. In a time when misinformation is growing, I choose to put my trust in people rather than data. I can trust a person and their process, but not a dataset in a vacuum. I trust some reporters are able to look at data critically and I trust their judgement in telling the story they see. Learning how to deal with this uncertainty is crucial, and I believe the way to do it is to be very clear about where the data comes from, how it’s been collected and what has been done to it. The more we know about this, the more we understand the inevitable biases it includes and the more we are able to focus on the stories. And then we should embrace this uncertainty and subjectivity. Data is a tool that filters reality in a highly subjective way and how a dataset is collected and the information that is included — and omitted — directly determines the course of its life. This is why I think we have to reclaim a personal approach to how data is captured, analyzed and displayed. This proves that subjectivity and context play a big role in understanding big events and social changes — especially when data is about people. How we design and build digital products at The New York Times 255 2 Design Data Data Visualization Design Thinking Conversations 255 claps 255 2 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-11-08"},
{"website": "NewYork-Times", "title": "measuring what makes readers subscribe to the time", "author": ["Daniel Mill"], "link": "https://open.nytimes.com/measuring-what-makes-readers-subscribe-to-the-time-fa31f00a3cdd", "abstract": "Code Data Product and Design Workplace Culture Work with Us Understanding what drives someone to purchase a news subscription is far from simple. Each potential subscriber is exposed to different news stories, advertisements and messages both on our site and off of it. Separating these influences is an overwhelming task, but understanding the power of news and marketing drivers is necessary to build an effective subscription business. If we are to spend money on marketing and media efficiently, we need to quantify and understand how each stimulus, both on-site and off-site, influences and contributes to subscriptions. An entire industry exists to tackle this very problem, with varying solutions from Market Mix Models (MMM), to user-tracking Attribution models, to surveys. While all of these methodologies offer the ability to determine signal from noise, each comes at a great cost in terms of both time and money. When working with a vendor, a considerable amount of time and resources can be spent passing data, validating it, building a model and finally having the work presented back. Due to the steps required, a typical model can take weeks to come to fruition. But what if we need to react to market responses more immediately? To solve this problem, we decided to build a Market Mix Model infrastructure in-house. Statistically speaking, an MMM is a process to decouple competing subscriber-conversion events; it’s a time series, multivariate regression model. For example, if we wanted to determine the effectiveness of a TV campaign on subscriptions, we would measure TV’s historical correlation with subscriptions after holding out the effects of sales, seasonality and other marketing vehicles. Simply put, to understand how any one channel is driving subscriptions we need to build and quantify all drivers holistically. An MMM is only as strong as the inputs and leaving out any significant variable in the model can inflate results. Building out a rapid-response MMM requires having all potentially useful data on hand and in an easily accessible environment. Building the MMM in house starts with an immediate advantage: Most of the data necessary to build one is already being reported internally somewhere. The most important dataset, our internal event tracking of onsite behaviors (e.g. NYT pageviews), already exists in our Google Cloud Platform (GCP). While this dataset can help us understand what stories may be impacting subscription, understanding what off-site influences lead up to a visitor reaching our site is critical. Almost all of this data comes from third-party partners such as Facebook and Google, but generally is used by analysts and marketers in a siloed UI. We found that data accessibility was an obstacle, so our first step was to build APIs of each external datasource to funnel into one cloud storage. These data sources include, but are not limited to: Search Clicks and Impressions Offsite and Onsite Displays Facebook Owned and Paid Impressions Twitter Impressions, Engagement, Retweets, Replies, Likes App Downloads Sale Dates Economic Variables Having all this data pulled into a central GCP warehouse on a consistent basis gives us the data we need, but in different formats that cannot be easily pulled into a statistical model. For that, we rely on Python to not only clean and format the data, but also to run complex regressions from which we can glean insights. When preparing to build a model, various data vendors typically ask what data we need and we almost always need all of it. The second our model finds an input variable significant (or insignificant), we need to break it down further and parse out what underlying factor is driving the result; and in order to do this we require all of the surrounding metadata. Since we store and process data with a high amount of granularity there is always the potential for processing data incorrectly or missing it altogether, which is why it is necessary to validate it. Any econometric model is only as strong as the inputs gathered: “garbage in, garbage out,” as the adage goes. The common approach in the industry is to pull in all sources of data, manipulate and visualize the data and finally present it back to stakeholders and experts to ensure quality of the inputs. Since sending this data to external agencies can be time consuming to all parties involved, a lot of friction can be removed by keeping the process internal. To do this, we introduced a cloud-based reporting infrastructure connected directly to our BigQuery warehouse. This allows us to have the inputs we use for modeling transformed and directly pipelined to our analysts who can monitor the data for accuracy as soon as it is ingested from the APIs. Our data validation is thus a daily process which allows our data analysts to focus their effort on modeling. Often in data science or econometrics, the majority of the time spent on building a model can be in the prep before any actual modeling has taken place. We have found success in reducing the time spent for processing data using the Pandas Python library. Pandas has a pre-written wrapper for pulling data from GCP using BigQuery which allows for data ingestion from BigQuery to a DataFrame. (A Pandas DataFrame is a powerful, open source tool with an Excel-like structure that allows us to efficiently manipulate data.) We can migrate data to or from BigQuery in as little as three lines of code. With simple access to BigQuery, we use Python to loop through multiple queries to ingest all necessary data from separate tables into one location. With the data in one place, we are able to transform it as needed with Pandas. There are a number of necessary manipulations needed to run a Market Mix Model, such as: Bucketing all data into consistent time ranges Creating seasonal indices Creating adstock transformations to measure latent effects Smoothing data Most of these transformations already come with prewritten functions in the pandas library to make the manipulations as painless as possible ( pivot_table for quickly bucketing data, rolling_table for smoothing data). For any custom transformations, such as adstocking, we can write our own logic to automate the process. While all of these are technically possible in SQL, Python and Pandas simplify the process with a fraction of the code. When thinking about automation and fast model turnarounds we want as little code to debug as humanly possible, and the simple connectivity between Pandas and BigQuery allows us to choose which tool can manipulate the data most efficiently. Following our data transformation process we’re ready to build our model. There are multiple Python libraries well suited for statistical modeling but for an MMM, we prefer Statsmodels as it is more suited towards traditional econometric interpretation of our input variables. Statsmodels takes DataFrames created by Pandas, runs our regressions, which we then programmatically decompose the results of and store back in BigQuery. With the model results stored in BigQuery, we can then use the same reporting tools (Chartio) that we used to validate the data to distribute our newly modeled results back to end users. Ingestion, cleaning, modeling and redistribution of data is in one rapid and simple process. Reducing friction from a process rife with data transfers is essential to getting answers quickly. Cutting out vendor reliance on modeling alleviates the need to send mass data to external agencies. Moving data reporting and ownership from individual UIs to a central repository democratizes necessary model inputs. And lastly, one programmatic workstream to automate ETL (Extract, Transform, Load), data transformations and modeling saves data analysts time in producing necessary modeled insights. Owning all of this information also gives us full view of all data processing up to modeled results. Having in-house models allows us total insight into potential data gaps, assumptions going into the model and full transparency of modeled outputs in order to validate and maintain a level of statistical integrity. If this type of work sounds cool to you, come work with us. We’re hiring! Apply here . How we design and build digital products at The New York Times 770 1 Data Science Technology Economics Python Data 770 claps 770 1 Written by Analytics Director at The New York Times How we design and build digital products at The New York Times. Written by Analytics Director at The New York Times How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-11-15"},
{"website": "NewYork-Times", "title": "open source simplifying serverless secrets in google cloud", "author": ["JP Robinson"], "link": "https://open.nytimes.com/open-source-simplifying-serverless-secrets-in-google-cloud-a95451e545b1", "abstract": "Code Data Product and Design Workplace Culture Work with Us Over the past year, several New York Times engineering teams have been busy transitioning systems to run on either Google App Engine or Google Kubernetes Engine. We use these platforms to host systems like our games , email and core news applications. As we’ve transitioned to these technologies, we’ve also started adopting HashiCorp’s Vault as a unified solution to securely store, share and access application secrets like database passwords and API keys. Our applications running on Google’s Kubernetes Engine use the sidecar container pattern to interact with Vault. Instead of requiring developers to add additional code to get secrets from Vault, the sidecar logs into the service, fetches the configured secrets and writes the secrets onto a dedicated and secure shared memory volume for the application to read on startup. Unfortunately, applications on Google’s serverless solutions, which includes the App Engine Standard and Flexible environments, don’t have the option of configuring sidecar containers or shared volumes. This has forced us to fall back to injecting our secrets as environment variables at deployment time. A recent change to the App Engine console has enabled users to see these secrets in plain text, which is not ideal. We needed a more secure way of managing serverless secrets and we needed to unify our secrets solutions across different styles of infrastructure. Today, we’re happy to introduce gcp-vault , a new Go library that eases the use of Vault in the Google Cloud’s serverless solutions by reducing a four step interaction with Vault and GCP to a single function call. Both gcp-vault and our sidecar solution rely on a Vault plugin that allows applications to authenticate against Vault using Google credentials . Once the plugin is added to a Vault installation, developers must give Vault access to their GCP project so it has the ability to verify Google-signed JSON web tokens (JWT). After this configuration is completed, an application must look up its default credentials , sign a JWT using Google’s IAM service and then login to Vault using that JWT . Our new library reduces all of that application-side work to a single GetSecrets() function. Beyond simplifying the interaction required for accessing Vault from GCP, the library also includes a method for logging into Vault while developing locally and a small utility package to help mock out Vault and Google’s IAM and metadata services in unit tests. To safely initialize secrets on application startup, we recommend users of App Engine’s legacy Standard Environment call the gcpvault.GetSecrets function within a sync.Once block and hook it into their application’s middleware. The process of logging into Vault is somewhat expensive and can take upwards of one second. To deal with this, we also recommend using Warmup or Startup requests to ensure the secrets are fetched before exposing the service to clients. Users of the App Engine Flexible Environment and the new Go 1.11 beta runtime in the Standard Environment don’t have the same restrictions on network access as App Engine’s legacy Standard Environment (Go ≤1.9) so users can make the GetSecrets call on application startup inside their main() or init() functions. We’ve included more information and a handful of examples of using the tool in our GitHub repository. Here are some links to help developers get started: How to install Vault’s CLI tool All examples on GitHub An example of generating an app.yaml for local development Documentation for the gcpvault package Documentation for the gcpvaulttest package We’re open sourcing this project not only to aid the community, but also to ask the community to help make gcp-vault better . If you are interested in helping out, please feel free to contribute or reach out on the #gcp-vault channel in the Gopher Slack Community if you have any questions. If you find solving problems like this interesting, we’re hiring! We currently have several open engineering positions: Senior Engineer Delivery/Site Reliability All Tech jobs How we design and build digital products at The New York Times 127 Google Cloud Platform Open Source Technology Code Serverless 127 claps 127 Written by Senior Software Engineer at Datadog. A user of Go. A lover of cats. How we design and build digital products at The New York Times. Written by Senior Software Engineer at Datadog. A user of Go. A lover of cats. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-10-16"},
{"website": "NewYork-Times", "title": "open questions a conversation with fastly ceo artur bergman", "author": ["Nick Rockwell"], "link": "https://open.nytimes.com/open-questions-a-conversation-with-fastly-ceo-artur-bergman-9c5e023baf57", "abstract": "Code Data Product and Design Workplace Culture Work with Us Artur Bergman is the Founder and CEO of Fastly, a cloud computing services provider. I spoke with Artur about building Fastly on open source technology, why early internet protocol design could have benefited from more diverse contributors and how the speed of light kind of pisses him off. Editor’s note: The New York Times uses Fastly in our technology infrastructure. Q: One of the things I admire about Fastly is that from the beginning, you went straight at a powerful, entrenched incumbent with a long track record of crushing upstart rivals through various means. And, you did it with nothing but a better product. Was that scary at the start? A: We never really thought about it that way. We had a unique product that solved a specific set of problems for companies with changing and evolving content, and we started selling it that way. It wasn’t until we started talking to investors that we heard their fears about how past competition in the space has fared. I think it pushed us to grow up faster, and operate in a strict legal and ethical fashion, something other Bay Area startups probably should have done. This paid off in our compliance work, and when we started working with larger companies that had the same expectations of us. Someone recently said to me that you are one of the people who most deeply understand the internet at the protocol level. What’s your take on the success of early internet protocol design? What would you like to travel back in time and change? Historically, we (protocol designers) didn’t adequately threat model the core protocols. Because of this, we paid for it with spam, traffic interception, spying and other abuses of the commons. The flip side is that we didn’t know how successful the internet would be, so maybe focusing on threat modeling wouldn’t have allowed it to take off in the way it has. I also feel that, despite the early focus on a reliable network operation with limited resources, we lost track of that vision, and the parts of the world without the same level of infrastructure are paying that price now. Take HTTP/2 PUSH as an example. Server Push allows the server to preemptively “push” website assets to the client without the user having explicitly asked for them. When used with care, we can send what we know the user is going to need for the page they’re requesting, which makes the perceived page load time quicker. And this is fine, until you realize that large parts of the world pay for bandwidth, which doesn’t take into account request data, just data. So we now move from a model where the user-agent — a.k.a. the browser — decides what to get based on the user’s actions, to a model where the server side decides. This is a new example of the same problem. You built your company very literally on open source — in particular, on Varnish. What drove that choice, and to what degree have you forked or diverged from Varnish and why? We built Fastly on top of Varnish because it let us reverse proxy, it was highly customizable and it was built with performance in mind. We forked from Varnish to make it scale at our size. Our version of Varnish is optimized for large-scale deployments, since we have caches in many locations across the globe. Most of the changes we’ve made to customize Varnish for ourselves don’t make much sense for many people, which is why we didn’t upstream the changes. We give back to the open source community in many other ways; we give free Fastly services (including CDN, DDoS mitigation and Image Optimization) to open source projects and nonprofit organizations. Projects like PyPi, Rubygems, Terraform, Haskell, Tor Browser and Debian all use Fastly for free to deliver their software and packages around the world. We also continuously sponsor meetups, conferences and projects that center around open source. We still care about the success of open source Varnish. We subsidize the maintainer’s work on it monthly. It seems like we have transitioned from a time when open source was driving infrastructure innovation (Linux, MySql, Varnish) to a moment when it’s the big cloud providers (AWS, GCP, Azure) doing that. Do you think that’s true? What does it mean for open source? Is an era ending? To me, the era ended when we won the battle — it’s hard to have a movement when the enemy isn’t clear. Are the large cloud providers the new enemy? It seems like a difficult argument, since they all continue to invest in open source, releasing new software and tooling. Cloud providers are driving infrastructure innovation using open source, and just like in the past, second movers are using open source more aggressively to counter the first mover advantage. The era ended when people could operate things on their own, because the complexity grew to a level where specialists took over. I am sure open source will adapt to that era. As an infrastructure startup, how does it feel to compete, cooperate, exist alongside the big cloud providers? It seems perilous… With a career in 24/7 critical infrastructure, things some might view as ‘perilous’ don’t feel that way to me. We have mastered operating a distributed system in the most unfriendly environment you can have — the internet. If you look at the 10 fallacies of distributed computing, we hit all of them. Our servers have to be in the most power and space constrained, yet bandwidth-rich, environments. This is not an environment the core cloud can presently operate in. I believe that more workloads should be at the edge (like personalization, data validation, authentication), but certainly a lot of workloads belong in the core cloud (like data storage and analytics), and we have to work well with them. Doesn’t the speed of light kind of piss you off? Wouldn’t the Universe be more fun and interesting if something could go faster? Without it, I wouldn’t have this interesting business and technical challenge to solve :). Then again, I could travel to any planet and solve different problems… So yes, it does piss me off. You have spoken about how to expose people — young engineers, new additions to an existing ops team — to appropriate risk, so they can learn. This is something I worry about a lot, that the youngsters don’t get to do enough stupid things. Do you think that’s a real problem, if so how do you address this at Fastly? It is a real problem: how to create an environment where people can safely learn. I think both of us grew up in a world — and I am dating us — where the penalty for error was much lower. No one really used the internet for critical things; if a site was down, it wasn’t a big deal. Sites went down all the time. It was an environment where people could just do things, and quite frankly, had do things because no one else had done them. When Brad Fitzpatrick invented memcache, it was because it was absolutely necessary, but I don’t think we can claim that we actually really knew what we were doing. I think the social networks we see today will be the last large sites that have survived early years of instability. If Snapchat had to work through those problems, I doubt the current generation of consumers would have tolerated it. Fastly has traditionally been a workplace of senior engineers. We have an on-boarding pipeline but it is not very easy for junior people to be successful. We are working on correcting by investing in guardrails, in shadowing and mentoring, and in giving people time to gain context and expertise. We strongly believe in the idea of recoverability as a point of resiliency. Attempting to eliminate downtime and impact is always a laudable goal, but systems that are not designed to gracefully handle failure and recover easily are still brittle. The longer they go without exercising failure modes, the harder those failure modes will be when they inevitably come. By embracing resiliency over brittle availability, we also create safer environments for engineers who are still learning and growing. This enables stronger pipelines for newer engineers, growth within the company and continued focus on ownership of our own hiring destiny. The average age of a Fastly employee is 38 years. Many of our leaders and engineers are veterans who have had chances to learn through some pretty massive outages. At today’s scale however, we need to control how our engineers learn to manage failures. This is where reliability engineering, architecting for failure management, guard rails built into tooling and even chaos engineering come into play. And really, it’s a much better option for all of our collective sanity! As a company, Fastly does a lot of good things without seeming to make a big deal about it, such as donating services to charitable and open source organizations. In particular, Fastly has been pretty direct and outspoken in support of inclusivity. Where does that come from? Donating services to open source and nonprofit organizations is one way we give back to the communities that enabled us to exist as a company. Open source also personally gave me the opportunity to become who I am, so it is incredibly important to both Fastly employees, our business and me. I grew up in a significantly more feminist environment in Sweden, as well as a significantly smaller power distance culture; committing to a culture of inclusivity is the right thing to do. Studies show that diverse teams that reflect your customer base deliver better outcomes — the more diverse your leadership, the easier it is to attract diverse talent and build products that truly add value for customers. An inclusive environment also makes it easier to hire and retain great people. Going back to the HTTP/2 PUSH example, I feel that if the group of people writing the protocol had been more diverse, we would have had a different outcome. If the contributors were immigrants or had families in third-world countries, or had themselves experienced periods of slow and expensive connectivity, they probably would have left that control on the client side. I’ve noticed that many of the people that work at Fastly seem happy. Why is that? We work on a product that matters and helps customers reach, enrich and inform a vast global user base. We work with some of the best companies in the world on meaningful technology that makes an impact. We prioritize transparency and caring. 90 people at Fastly have been here over four years — that’s nearly 25 percent of the company, which is a testament to our internal values and culture. And those same values are at the helm when it comes to growth at Fastly. As we continue to grow, we want to make sure we bring on new voices, opinions and experiences. Diverse teams deliver better outcomes. Our executive team is almost evenly split between men and women, while over 50 percent of our engineering leads have self-identified as women, people of color or LGBTQ. Over 50 percent of the company works outside of San Francisco. We’re building a global product, and you have to have a diverse company to execute on this vision. I found an old picture of you on the internet with… a Smart car. That made me sad and confused. Can you explain this to me? I am not a big believer in compromise. It tends to make everyone unhappy, or products that do nothing well. When it comes to cars, I seek out ones that excel at the thing they are designed for. In the case of my truck, this means off roading into remote parts of the American West. In the case of the Smart car, it means parking anywhere in a city and having fun at slow speeds on tiny mountain roads in the Bay Area. And just to be clear, it was a convertible. This interview has been edited. How we design and build digital products at The New York Times 111 1 Cloud Computing Internet Diversity In Tech Software Development Conversations 111 claps 111 1 Written by SVP Engineering at Fastly, ex-CTO at NYT. Passionate about tech, music, science, art, helping others be their best. How we design and build digital products at The New York Times. Written by SVP Engineering at Fastly, ex-CTO at NYT. Passionate about tech, music, science, art, helping others be their best. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-09-07"},
{"website": "NewYork-Times", "title": "supporting ar experiences in new york times mobile apps", "author": ["Ramona Harrison"], "link": "https://open.nytimes.com/supporting-ar-experiences-in-new-york-times-mobile-apps-48c3731a4dbf", "abstract": "Code Data Product and Design Workplace Culture Work with Us Earlier this year, The New York Times introduced augmented reality (AR) experiences within interactive articles. This new digital storytelling medium allows readers to bring three-dimensional objects captured by our newsroom into their own space. From catching Olympic athletes mid-jump , to closely examining the intricate textures of David Bowie’s costumes , to exploring NASA’s latest mission to Mars — augmented reality brings a new and interactive dimension to our stories. These experiences have been enabled on the native app side by new technologies that were released in the past year: ARKit became available on iOS in late 2017 and ARCore became available on Android in February 2018. Fundamentally, these software development kits, or SDKs, allow an app to understand the environment around a user’s device and to place objects and information within it. To parse the user’s environment, ARCore and ARKit use the device’s camera to identify distinct feature points in areas of high contrast, such as the corners of a table, and keep track of those points as the user moves their device. As the device is moved, the feature points reposition within the camera frame and the change is used by the SDKs to infer how much the user has moved their device. This visual information is combined with motion data from the device’s sensors to estimate the position and orientation of the device camera over time — this is called pose. Developers can use this information to align the pose of the real device camera with the pose of a virtual camera that renders 3D content. Because the rendered virtual content is aligned on top of the real camera image in each frame, it appears as if it is part of the real world around the user. When we first started to explore how we wanted to support AR in our Android and iOS news apps, we identified three key goals: We wanted to support these experiences in our existing news application — we did not want to require our readers to install a companion app. This also meant that any dependencies we added would need to be minimal in order to keep the download size of our core app lightweight. We wanted to be able to publish new experiences separate from the app release cycle, which happens every two weeks. We also wanted to make the app as agnostic to the content and flow of these experiences as possible, so that our colleagues in the newsroom would be able to craft unique and varied interactions across stories. We wanted our colleagues in the newsroom to be able to author each story just once and have this same version run seamlessly on both Android and iOS platforms. These goals really came to define our options and as a result, we built the framework that we’re using today. Our first goal to support AR experiences in our existing news application meant that we could not rely on common cross-platform rendering solutions like Unity or Unreal Engine since these frameworks could not be integrated into our existing native apps. We also had to turn down any solution that involved a large dependency which would add excessive bloat to our app download size. In order to satisfy all three of these goals, we considered a number of different approaches before settling on one that worked. The first approach we considered is what I’ll call “the native approach.” In this approach, the complete AR experience — including all rendering and user interactions — is controlled by the native application. Because the rendering is handled on the native side and there is no back and forth communication with the web side, the experience is synchronous, performant and responsive. However, we very quickly ran into some serious limitations to this approach. The main the AR experience had to be baked in at build time. This meant that it failed to meet our second goal: to be able to publish new experiences with the news cycle, and independently of our app release cycle. It also failed to meet our third goal — to produce once and have it work across Android and iOS — since interactions would need to be pre-scripted and implemented separately for both platforms. The second approach we looked at is what I’ll call “the web rendering approach” — WebAROnARCore and WebAROnARKit. In this approach, which is built as an extension to the existing WebVR browser API , the device exposes AR data to the web page via a browser interface. The native app is responsible for rendering the camera image, as well as sending important AR data to the web page, such as the current camera pose. The web page then uses WebGL to render all of the virtual content on top of the camera image, and it renders any of the virtual content that should be visible in the experience. There are two advantages to this approach we really loved. First, iOS and Android versions of the WebAROnARCore and WebAROnARKit projects adhere to the same interface. This means that our colleagues in the newsroom would be able to author each AR experience just once and it should behave the same on both platforms. Second, since all of the virtual content rendering is handled by the web page, the newsroom can craft unique and varied AR experiences by simply creating a new web page rather than waiting on an app release. Each new experience does not need to adhere to a standard formula when it comes to how a scene will be rendered or how a user might interact with the virtual content. However, we ultimately steered away from this approach for a couple of reasons. Because the camera image is rendered by the native application on the GL rendering thread and the virtual content is rendered by the web page in its own thread, there is a mismatch in synchronicity between frames. This means that when the device moves around quickly it appears as if there is a slight drift between the real world camera image and the virtual content. The Android implementation relies on an experimental Chromium fork that would need to be packaged with the APK in our app release. The dependency is quite large, meaning this would not meet our first goal to provide the AR experiences in our existing app without bloating the APK size. The third, and final, approach we looked at is an approach I’ll call “the hybrid approach.” In this approach, all of the rendering related to the AR experience — including rendering the camera image and the virtual 3D content — is handled by the native app while the content of the experience is delivered and controlled by a web page. The visual experience is composed of two layers on the screen. The top layer is a web view that renders the web page that presents 2D content, such as text, and user controls. It has a transparent background, allowing the user to see through to a native layer below where the camera image and 3D virtual content are rendered. The web page acts as a controller for the AR experience. It has a JavaScript interface that it uses to call through to the native layer, sending instructions about what virtual content to load, how to position it and how it should react to the user’s interactions. This means that the native app remains as agnostic as possible to the content and flow of each experience. It doesn’t care which or how many virtual models are being rendered, at what time they are placed or how they are positioned relative to the user. Because the web page can be authored and delivered at any time, we can meet our goal of publishing new experiences along with the news cycle rather than the app release cycle. Since the JavaScript interface is implemented to control ARKit on iOS devices and ARCore on Android devices, the web page only needs to be authored once and will work similarly on both platforms. Before I can talk about the hybrid interface between the web page and the native app, I need to do a quick detour to talk about scene graphs. A scene graph is a common approach to managing data in a graphics engine. A scene graph is a tree made up of nodes that can each have as many children as they want — we call this an n-tree. All of the nodes in our scene descend from a single root node, which itself is attached to a scene anchor. This anchor tracks a real-world position across time, meaning that the virtual content rendered by the scene will appear fixed to a real-world point in the user’s space. Each node has some information associated with it. In our case, it has: A unique identifier used to find or reference the node. A position and rotation in three-dimensional space, i.e. a pose. Information about what, if anything, to render. The native app uses the scene graph to understand how the 3D virtual content should be rendered. In our hybrid approach, we enable the web page to control details of the scene graph in order to create unique AR experiences across stories. We also enable the web page to perform managerial tasks like starting and stopping an AR session or loading and unloading the file resources required to render an experience. To enable the web page to control the AR experience, we’ve created a command and result loop. Commands are created and issued by the web page. They’re passed to the native app through a Javascript interface on the containing web view. Any action that the web page wants to perform on the AR session or the scene graph is encoded as a command. Each command has a unique identifier, a type indicating the action to be performed and an optional map of values to configure the action. Commands are serialized to a JSON string that looks something like this: When a command is issued by the web page, it is added to a queue on the native app side. The app then processes the command and sends an asynchronous result message with the same identifier back to the web page. The result indicates whether or not the command was executed successfully and delivers an optional map of return values. The command and result loop provides a mechanism for the web page to direct the flow of an AR experience, but how does the web page learn about events that happen spontaneously during the AR experience? This technology has to contend with constantly changing and potentially disruptive visual input. If a device’s camera is recording in a room with a table, the web page would want to know that the table is there so that virtual objects appear as if they were on top of it. To notify the web page of events that occur during an AR experience, we added an event listener interface. Event listeners give the web page a way to listen for things that happen spontaneously within the experience. This saves the web page from constantly polling for certain events, such as when a table becomes visible and a new plane is detected on its surface where objects can be placed. Instead, it can set a planeDetected listener and be notified by the native app whenever a new plane is discovered. Event listeners can be set by the web page on the native side with the addEventListener command. This command takes an option specifying the type of event it should listen for, and returns an ID as the result so that events from this listener can be identified in the future. After the event listener has been added, it will notify the web page anytime the specified event has happened via the onEvent function on the web interface. Here’s an example of an event message. It indicates the type of event, the listener ID that it was sent from, and any additional data related to the event that the web page might care about. In this case, the event lets the web page know that a new plane of the specified extent has been detected at that center position. By putting these components together, we’ve been able to deliver immersive, unique stories with AR content outside of our app release cycle. These stories enable readers to interact with the news in new ways, like stepping inside a Thai cave to experience the real-world scale of the obstacles that rescuers faced in retrieving a soccer team and their coach earlier this summer. How we design and build digital products at The New York Times 348 Augmented Reality Android Android App Development AR Code 348 claps 348 Written by How we design and build digital products at The New York Times. Written by How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-09-13"},
{"website": "NewYork-Times", "title": "how to run 13 design sprints at once inside maker week at the new york times", "author": ["Jake Knapp"], "link": "https://open.nytimes.com/how-to-run-13-design-sprints-at-once-inside-maker-week-at-the-new-york-times-5d3b95ca2441", "abstract": "Code Data Product and Design Workplace Culture Work with Us T his summer I got to do a super fun project, and I thought I’d write it up. It started several months ago, when I got an email from Laura Prah, who leads culture and engagement at The New York Times. Among other things, Laura is in charge of an event at The Times called Maker Week. Maker Week is like a hackathon. For one week every summer, folks are encouraged to step away from their regular work (as much as humanly possible at a newspaper) and experiment with new projects. They start on Monday, and on Friday they share prototypes with the company. Laura was considering integrating the design sprint into Maker Week and she wondered what I thought. Well… I was stoked. I mean, first of all, it was The New York Times! I figured if I played my cards right, they might even invite me to visit. (Spoiler: this actually happened!) Second, the design sprint seemed like a good fit for Maker Week. The design sprint is a step-by-step process for starting new projects — a sort of recipe for team problem-solving. In a design sprint, the team creates competing solutions, decides on the best, then builds and tests realistic prototypes, all within a single week. It was quite easy to imagine overlaying the design sprint steps over the top of what The Times was already doing. And there was one more reason I was excited. This idea of a “Maker Week Remix” offered a chance to tinker with the traditional hackathon, which is a format I both love and hate. Hackathons are awesome because they offer protected time, an artificial deadline and an experimental mindset that can stick in the team culture long after the event is over. In fact, hackathons were one of my inspirations when I created the design sprint (back in 2010 while I was at Google). But hackathons are also not awesome. Without a clear game plan, newly-formed teams can waste time and lose their way. Many hackathon projects go nowhere when the event is over. And people often exhaust themselves working super long hours — as Jason Fried noted , you might be better off with a sleepathon than a hackathon. By combining design sprints with Maker Week, Laura and I figured we might highlight the good stuff in hackathons while fixing some of the trouble spots. Design sprints typically have five to seven people, but Maker Week would have 65. So I had to “scale up” the design sprint to work with several teams at once. I had a few ideas, because for the last year, I’ve been running design sprint workshops that often have 100 or more people. But those workshops use a “canned” project so that every team is working on the same fictional challenge. Multiple teams working on multiple real projects is much more complex, so I was a bit stressed out. In the end, it worked out even better than I hoped. If you’d like to run a similar large-scale event with lots of teams, try making these six modifications to the normal design sprint process — they really helped me. 1 The design sprint is intended for one small team with one facilitator leading them through a checklist of activities. For Maker Week, I had 13 teams all together in one big room. There was no way I could rotate and coach each of the teams, so instead, I treated it like a big workshop (or yoga class) with me at the front talking everyone through the steps. 2 With so many people, I needed more than verbal instructions. I’ve developed a slide deck for my training workshops, and I adapted those slides for Maker Week. With them, I had a visual cue to go along with each step. This helped teams move super fast and stay focused. 3 Normally, the design sprint process takes five days. On Monday, the team creates a map of the problem and chooses a target; on Tuesday, they sketch solutions; on Wednesday, they decide which solutions are best; on Thursday, they prototype; and on Friday, they test the prototype with customers. But — knowing that not every team could take all five days off — Laura and I decided to compress Map, Sketch and Decide into just two days. To tell the truth, I was apprehensive about getting all these different teams through the condensed schedule. I put together this spreadsheet to plan the activities minute by minute, adjusting the times as we went: 4 For Maker Week, I used the checklist from my book Sprint along with two improved techniques: the Note-n-Map (from Stéph Cruchon in Switzerland) and Storyboarding 2.0 (from AJ&Smart in Berlin). These techniques provide extra structure for the mapping and storyboarding activities, which normally require a lot of hands-on facilitation. Both worked like a charm. Even though they didn’t have dedicated facilitators, the Maker Week teams quickly created maps and storyboards without a lot of discussion. 5 I brought my buddies Jonathan and Luke to roam around and help if teams were confused about a specific step. As a bonus, Jonathan — who has run more design sprints than I have — watched the energy level of the room and helped me figure out when to speed up and when to slow down. 6 Many of the activities in the design sprint require silence, but it’s hard to enforce silence with 65 people in the room. And once one group starts murmuring, the broken focus quickly spreads. So I played some ambient music to remind people when to stay quiet and focused. (My playlist includes instrumental music by Marconi Union, Jamie xx, the Beastie Boys, Kamasi Washington, Chromatics, Dave Brubeck, Daft Punk, and others — and I used this tiny bluetooth speaker which projected sound throughout the space remarkably well.) Remember how I was nervous about squeezing three days into just two? Well, at 2 p.m. on the second day the teams were already finished with three days worth of work! So we moved on to what is normally the fourth day of the design sprint: prototyping. From 2 p.m. to 5 p.m., the teams put their heads down and cranked out their prototypes. Then, at 5 p.m., we shared progress. This was amazing: almost every team was finished with their prototype. They had done just 15 hours of work (seven and a half on day one, seven and a half on day two) and they were already done with what normally takes all of Maker Week. I think there are a few reasons why the teams were able to sprint and prototype so quickly. First of all, because the hackathon projects were all new or speculative, there wasn’t a lot of background knowledge to share or politics to work out. Part of what takes time during the map step of a design sprint is working through the messy details of real, long-term projects. For better or worse, a hackathon environment avoids those details and starts with less information — so day one was a breeze. The projects were also fairly well scoped. Laura and her colleagues Kelci Shipley and Jody Mak had supplied each team with a “How Might We?” question to seed their design sprints (for example, “How might we allow subscribers to engage directly with editors?” or “How might we allow users to track the physical delivery of their paper?” ). These questions had been carefully phrased to keep the scope appropriate to Maker Week. It also helped that the people in the room knew the app, website and editorial tools inside and out. I’m used to working with startups, who might try to define a brand and a marketing plan and a technology stack all at once. The New York Times has been around for 167 years (really) and they’ve had a website for about 142 years (not really, but it seems like it). There’s already a strong foundation and many components to work with, so when it came time to build the prototype the teams could really fly. Finally, and I think this is important, everybody came in with the right mindset. In a design sprint, part of the facilitator’s challenge is to help a team move quickly, forget about being perfect and get into an experimental mode. Maybe it’s because Maker Week is already an institution at The Times, or maybe it’s because the digital team is used to quickly experimenting with new ideas and technologies. In the end, even a design sprint-ified Maker Week was still a hackathon. The projects were all explorations — answers to questions that the Times is curious about, but perhaps not quite ready to act on. When the dust settled, everybody went back to their real work and had to catch up. Most teams didn’t test their prototypes with target customers, and most didn’t plan to take their prototypes anywhere. Normally this would absolutely kill me. I hate it when the projects go nowhere. I crafted every step in the design sprint to be pragmatic, each one making progress toward building something real. And yet… fundamentally and intentionally, the Maker Week projects are short-lived experiments that are never intended to see the light of day. Laura was explicit about this from the very beginning: Sending new projects to production is not the goal. Instead, Maker Week is about practicing exploration. So I’ll add one more suggestion for multi-team sprints: 7 Decide in advance whether the goal is launching or practicing. And be honest, because it’s very hard to keep hackathon projects alive, and very frustrating to be told something has a chance to launch only to watch it go nowhere. If you decide to make it practice, do what Laura did and be very clear at the beginning, and remind people over and over: This is practice. The point is to flex our experimentation muscles. It’ll take some time to know if the design sprint-ified Maker Week was a success, but I have a good feeling about it. With a little luck, The New York Times will use design sprints on more real projects (they already started last year) and… who knows, maybe one of the Maker Week experiments will defy the plan and catch on? Either way, it was good practice. If you try a large-scale design sprint/hackathon at your company, let me know how it goes! Photos by Jonathan Courtney and Luke Knapp Want to learn more about Maker Week? Check out these posts: How we design and build digital products at The New York Times 1.7K 7 Design Sprint Product Development Design Thinking Visual Design Technology 1.7K claps 1.7K 7 Written by Writer, designer, person. Author of SPRINT and MAKE TIME. More at jakeknapp.com. How we design and build digital products at The New York Times. Written by Writer, designer, person. Author of SPRINT and MAKE TIME. More at jakeknapp.com. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-09-20"},
{"website": "NewYork-Times", "title": "maker week 5 days of collaboration and innovation at the new york times", "author": ["Laura Prah"], "link": "https://open.nytimes.com/maker-week-5-days-of-collaboration-and-innovation-at-the-new-york-times-77951103c90d", "abstract": "Code Data Product and Design Workplace Culture Work with Us One of the most anticipated tech events at The New York Times is our annual Maker Week, when employees in Technology, Data, Product and Design get a full five-day work week to collaborate or work independently on innovation projects. In the weeks leading up to the event, we brainstorm, share ideas and start forming teams to make sure employees can be productive during the week. The point of Maker Week is not to develop products for our website or apps, but to encourage a spirit of collaboration and learning. We want employees to make new connections across the company and have the breathing room to explore. The learning culture at The Times runs deep and we hold ad hoc Maker Days throughout the year, but Maker Week allows employees to go all in. We want to give people the space and time to work outside their typical structure and teams, so we recommend that meetings and other commitments are postponed for the week. This gives employees the freedom and autonomy to experiment with new ideas, and allows them to grow in ways they might not when saddled with deadlines and directives. The event gets a lot of support from our executive committee. Our CTO, Nick Rockwell wrote, “I love Maker week because it gives everyone a chance to work on that idea that has been driving them crazy, and learn some stuff and meet some new people while we are at it!” The success of Maker Week isn’t measured by how many projects make it to production; the success is measured in employee enthusiasm, creativity and trying to solve a problem that may not be obvious to the larger organization. We end each week with a casual show and tell, set up like a science fair, that employees can opt in to. This year’s event happened in late July and saw a wide range of projects and workshops: One team created a tool to measure gender diversity in our obit coverage Developers ran hands-on workshops on technical topics like building an iOS app A developer created a handheld device using Arduino, an e-paper screen and 3D-printed parts so people could play the New York Times Spelling Bee game on the go. A team of product designers explored how they could mitigate concerns from subscribers about paper pile up by offering fun and practical ways to upcycle. They spent the week creating gift bows, tags, drink coasters and tote bags — all formed out of newspaper. We’ve been running Maker Week at The Times for a few years now, and we’ve learned that giving employees the freedom to experiment and explore pays off in dividends. When employees have the time to try new things and collaborate, new connections are formed and a people learn from each other. Ultimately, the company benefits by allowing staff to have the time to make these connections, to observe, to listen, to talk and share knowledge. We’re continually improving how we run Maker Week and Maker Days. Each year, we poll colleagues about what was successful from last year’s Maker Week and used that feedback to inform the next event. Here are some of the things we’ve learned: Form a Planning Committee: This event requires a lot of planning, a lot of coordination and a lot of input from people across the company. Our planning committee was made up of employees who volunteered their spare time to run the event. To help keep ourselves on track, we appointed a colleague to be the project manager for the event. By having a diverse planning team from members across various teams, we were able to reach out to more people and also understand pain points for participants. Create a Communication Plan (and follow it): It’s a good idea to devise a communication plan early in the planning process, because once things start rolling, it can be easy to forget to send reminders and announcements. To reduce the number of emails that hit our colleagues’ inboxes, we set up a Slack channel for the event. This way, we didn’t spam people who weren’t interested or couldn’t participate. People who were participating knew exactly where to find information about the event. When we did send emails we included a “What is Maker Week” statement to help explain the event to colleagues who might be unfamiliar with it. Offer options (like a learning track): In addition to our traditional maker track, we offered a learning track for employees who wanted to participate in Maker Week without working on a project. We invited employees to attend a two day Design Sprint workshop led by Jake Knapp . For this workshop, we assigned participants to teams and dolled out problems identified by the Maker Week team. We also had some colleagues lead pop-up workshops on technical subjects. Generating ideas: In Maker Week tradition, we held three brainstorming sessions run by different people highlighting different themes like “Diversity and Inclusion” and “Storytelling.” Each session used a different methodology and we kept a running list of ideas that were shared across the company. By offering a variety of techniques, each session felt fresh and surfaced a variety of ideas. We also held two pitch and pitch-in sessions to help people make connections they needed for their project (e.g. if they needed someone with design experience, or a JavaScript developer) or to find a project team to join. Show It Off (Bragging Rights Are Nice) : We end each Maker Week with a celebratory science fair show and tell. The last day is exciting as teams scramble to make their prototypes functional before they show off their creations to colleagues. In the weeks following Maker Week, we host one or two internal lightning talks and invite participants to demo for five minutes. We invite decision makers and The Times’s leadership team to see all the good work that came out of Maker Week and hopefully help teams find a sponsor for their projects. This year we listed all projects in a Google site, which also serves as a nice record of the 2018 event — which will come in handy next year when we do this all again. Want to learn more about Maker Week? Check out these posts: How we design and build digital products at The New York Times 49 UX Innovation Makers Office Culture Design Sprint 49 claps 49 Written by How we design and build digital products at The New York Times. Written by How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-08-03"},
{"website": "NewYork-Times", "title": "maker week roundup homegrown product development at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/maker-week-roundup-homegrown-product-development-at-the-new-york-times-4a32c5250a0", "abstract": "Code Data Product and Design Workplace Culture Work with Us Maker Week is an annual event that gives New York Times employees from Design, Product, Project, Marketing and Technology the freedom to envision, design and develop creative new products. It is meant to encourage employees to come together to think through challenges, form cross-functional teams and explore ideas. We held this year’s event in late July. Here is a roundup of some of the projects that came from the event. Team: Christina Oh, Annaya English, Rachel Lederer, Clare Kenney, Tyra Searcy At The New York Times, there are a number of diversity-related initiatives, but there is no centralized location where all of this information lives. We set out to create a database and website to organize the data and make it easy for Times employees to access information about the initiatives and learn about ways to get involved. The information we collected ranges from documents on controlling for unconscious bias in the hiring process and in the workplace, to employee resource groups and task forces, to projects in the newsroom to cover issues of gender and race more thoroughly and to engage more diverse audiences. Throughout the process, we interviewed a number of employees at the Times involved with task forces and employee resource groups, as well as executives on the newsroom and business side. These conversations helped us better understand the Times’ commitment to diversity and the views of those working here so we incorporated quotes from these conversations throughout. The website also allows users to submit feedback about resources that are missing so that the site can grow and stay up-to-date. We hope this project will create more transparency in relation to Times initiatives and that it will make it easier for more employees to get involved. Team: Sara Rabstenek, Ranu Rajkarnikar, John-Michael Murphy, Alessandra Villaamil, Megan Elliott, Claire Chen, Bassey Etim, Karron Skog, Sarah Graham, Solace Francine Sabado, Daniel Miranda Using a design sprint process inspired by Jack Knapp, we explored how to encourage reader participation directly on the Story page. Our group consisted of members of the Community and Ask teams who are eager to drive more reader engagement around our journalism. In five days, we: Identified the problem we wanted to solve: How might we surface Ask at the most helpful time so that users can seamlessly ask a question? Interviewed experts in the building Sketched design solutions Built a prototype Tested it with users We landed on Highlighter, a way for readers to highlight passages within a story and respond directly. Our hypothesis was that an open-ended Comments box can be intimidating for some readers, and that specifying a prompt might encourage readers to participate. Highlighter could also provide an opportunity for writers and editors, and they could prep a story by pointing out passages to their readers. The hypothesis still stands that more people will want to contribute their reactions and thoughts to a story if the prompt is more specific. Our prototype also included the ability to share the passage or ask a question about it. Long term, we’re interested in how we can build a closer connection between our readers and the newsroom by encouraging journalists to answer reader questions. From our interviews, we learned that our prototype needs finessing, but that the overall idea of prompting a conversation around specific passages and of asking questions of the writer could be interesting and helpful. Team: Vladimir Ramik The New York Times receives many emails everyday. Some of these emails can take as long as several days to be replied to because responses are created and sent manually. Magic Mail is an application that handles the automatic response to and labeling of inbound emails. Through the use of natural language processing (NLP) it can sort, categorize and prioritize how each email is handled. Magic Mail can be used a few different ways: it can run alongside manual workflows so that we can compare manual and automated responses; it can be used to target a specific mailbox to handle a certain subset of emails; or it can act as a proxy and respond to certain emails right away while forwarding along more complex ones to be handled manually. With a simplistic implementation of NLP parsing we can likely handle many inbound emails automatically. If significant resources are spent on using machine learning and more advanced language, we could greatly increase the types of emails that receive automatic responses. Team: Patrick Hawley, Jonathan Hadis, Julio Vela, Michelle Ng For Maker Week, we built a standalone web app to demonstrate the power of location-based news in two ways. ‘News Near You’ displays a list of articles based on the user’s GPS location while ‘News From Elsewhere’ allows users to choose a place on the map and see any news that is relevant to the selected area. Currently, the articles displayed are filtered on a city level. With more granular data, the app can be extended to show articles based on neighborhood, street, or even building. Although TLocal is a web app, we envision it as being a seamless part of the mobile app experience. Team : Julia Swearer, Drue Thomas, Jennie Hottle Previous to Maker Week, we had heard from subscribers about the guilt they feel when they see their paper pile up each weekend, and we wanted to explore ways to mitigate that guilt. As a company, The Times is committed to protecting the environment, but our subscribers aren’t necessarily aware of that. Our goal was to show our readers (and our staff) how they could reuse the paper for fun and practical purposes. We spent our Maker Week creating gift bows, tags, drink coaster and tote bags — all formed out of newspaper. Moving forward, we hope to incorporate some of these ideas into an insert in a special section of the paper, such as the monthly kids’ section. In this spread, we’d include an explanation of how our paper comes from environmentally protected forests, discuss the art of upcycling and provide instructions for turning part of that week’s paper into something new. Stay tuned! Team: Jeremy Gayed, Eric Bishop, Michael Owen Currently, the Newsroom relies on Slack threads and emoji reactions to iterate on push alerts and to signal approval and sign off. It can be difficult to follow the conversation and to understand the current state of an alert at any point in time. We decided to build a Slack bot to help with this. The NYT Alert Bot can be invoked with an /alert command which will bring up an initial dialog to fill out the slug and language, and to assign roles to people for approvals, desk sign off, and sending the alert. Once the dialog is submitted, the bot will post an initial message to the channel. This message will be kept up-to-date via its action buttons. Updates, including a diff-like view for any language edits, are posted by the bot as a reply to the initial message thread. The next step in the workflow is also displayed, so that it is clear what actions need to be taken to move the alert forward in the publication process. Team : Yao Gbanaglo, Carron White We created a gender analysis dashboard with help from Albert Sun and Amy Padnani to enhance the Obituaries desk’s efforts to reach gender parity. The dashboard tracks the daily and monthly breakdowns of published obituaries, allowing editors to visualize the gender disparity at large as well as drill down to individual days. The dashboard provides a rough estimate of the percentage of obituaries needed to reach 30% of obituaries featuring women. As two new Times employees, we wanted to focus on a project that would be immediately useful by improving the bottom line of diversity inside the company as well as the wider public. As decisions are increasingly decided with the rubric of data, we wanted to provide a concrete foundation for uplifting those historically marginalized individuals that have been overlooked. In the future, we plan to implement a deeper analysis of obituary subjects through a more rigorous intersectional lens to shed more light on the race, religion, and other facets by combining Wikipedia biographies with internal APIs. Team: John Michael-Murphy, James Robinson, Lev Akabas Package Mapper is a network map that visualizes user navigation across article collections on nytimes.com. It helps editors identify which articles are most effective at redirecting users to other parts of our coverage, and which are “dead ends”. Not only can paths through any collection of content be analyzed, but specific user segments can also be selected: for example, users from a specific country or speaking a particular language. Package mapper encourages users to think about articles not as a discrete unit but as dependent on and embedded in a network of content. Want to learn more about Maker Week? Check out these posts: How we design and build digital products at The New York Times 19 Innovation Office Culture Makers Product Design Design Sprint 19 claps 19 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-08-30"},
{"website": "NewYork-Times", "title": "building a serverless email platform at the times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/building-a-serverless-email-platform-at-the-times-84d77760d824", "abstract": "Code Data Product and Design Workplace Culture Work with Us This is the first post about the progress and achievements of our email delivery platform. We’ll start with how we rebuilt our email platform from scratch on Google Cloud Platform to improve the scalability, resilience, and sustainability of sending email at The Times. By AUSTIN HESS and CARLOS RYMER The New York Times sends nearly 4 billion emails per year to its customers, ranging from daily newsletters to breaking news alerts to transactional emails. The old system originally built to perform these functions was integrated with over a dozen internal services and provided a custom UI for editors to author emails. But by 2017, it was over a decade old and full of legacy code that could barely meet the demands of The Times’ growing subscriber base, frequently resulting in major user-facing errors. We decided to move all our infrastructure to the cloud by the end of March 2018, spurring us to design a more stable and scalable email platform from the ground up. The end result was a platform with a serverless architecture built on top of Google Cloud Platform. The old system was built before cloud services took off. At the time, that meant building many components on dedicated virtual machines within our data centers, manually updating the software running on those machines and making architectural choices based primarily on short-term considerations. As a result, the core sending infrastructure relied on layers of archaic and often undocumented scripts to select audiences and compile emails. Countless frustrating hours of debugging and coaxing were needed to address the near-weekly failures. These limitations severely limited our ability to react to problems, develop new features and meet the needs of growing email audiences. The new platform we built fulfills the same fundamental requirements the old system did. Most of the emails The Times sends are bulk newsletters which are delivered to an audience of anywhere from tens of thousands to millions of users who subscribe to a particular email product. Newsletters are assembled in advance by editors who use our custom interface to pull in UI elements and schedule a time for the dispatch, while the content of breaking news alerts is generated programmatically at the time of dispatch. A small but important portion of the traffic comes from transactional emails sent to individual users triggered by specific NYT events, such as the confirmation email sent when someone upgrades to a paid subscription. The new platform is comprised of a suite of microservices that are each responsible for a specific function. These functions include: Keeping track of a user’s newsletter subscriptions and metadata Quickly selecting an audience for a newsletter when sending Providing an admin UI for assembling email content and scheduling newsletter dispatches Compiling and sending an individualized email for each recipient Collecting and aggregating data about the emails sent and user behavior Providing convenient consumer APIs for other teams to send transactional emails and access business-critical data When choosing the infrastructure for building these microservices, one of the defining considerations was how our system would deal with spikes in demand. The process that compiles individualized emails can go from a steady, low-traffic state to having millions of compilation tasks queued up and waiting to be processed, all within the span of a minute. Each email generation task may need one or more network calls for each recipient to gather relevant information. After some internal discovery work, we settled on using Google App Engine (GAE) for nearly every microservice in the new platform. GAE’s standard environment allows us to build APIs that scale incredibly quickly with minimal need for manual tuning. GAE Standard imposes constraints — for example, the code must only run in the context of an HTTP request, and there are time limits on the length of execution responding to a request — that lend themselves to design patterns that make full use of the latest Google Cloud Platform tools and enhance scalability. Instead of long-running processes doing complex operations in memory, we use GAE services to transform and store data, publish data to queues (a “Pub/Sub” in GCP), break up multi-step tasks, spread out load and facilitate retries. We chose to use Go for all of our apps, both for its performance and ease of use, as well as its prevalence at The Times. The following descriptions highlight some of the most interesting design problems we faced: Our API consumers rely on highly available get/set capabilities for each user’s data, especially newsletter subscriptions. For example, on a registered user’s account page, an API call gets the user’s newsletter subscriptions by their system ID, allowing the user to view and edit their newsletter subscriptions. Given that we wanted the schema extensibility of a No-SQL database, the GAE-specific Datastore seemed like a good fit for this purpose. But Datastore is poorly suited for querying for an entire newsletter audience, which depends on several user properties. Moreover, neither standard SQL nor No-SQL options were well suited to the most advanced audience querying capabilities we hoped to support, such as filtering out users who hadn’t opened recently delivered emails. The solution was to use a GAE API with Datastore to manage each individual user data object. Every time a user object is modified, a record of the updates to the data (e.g. a new subscription to a given newsletter product) is published to a Pub/Sub from which it is then inserted into BigQuery, GCP’s data warehouse that runs SQL-like queries. Importantly, inserts are cheap and query cost in time and dollars depends on the size of the data the query runs over rather than the complexity of joins, but updating existing data or querying individual rows is very expensive. So by keeping the history of every user subscribe/unsubscribe and metadata change with timestamps, a few simple group-bys allowed us to quickly select currently subscribed members of a particular newsletter audience, even when joining on email open and click data. Now that we had a solution for consistently storing user data in ways optimized for both quick gets and sets, and also complex bulk queries, we had to build components to support an admin interface for editing email content templates and scheduling email dispatches, retrieving the IDs of audience members for a dispatch, and generating and sending out an individual user’s email based on the template. The new platform’s admin is comprised of RESTful APIs for modifying newsletter audiences (which translate to BigQuery queries), email content (templates), and schedules, among other components, and all this data is stored in a relational database on Google Cloud SQL. We use a cloud-based cron job to check whether there is a bulk email dispatch that should be triggered each minute. When it is time for a dispatch, data comprising the task is passed to our audience selector service, designed to retrieve from BigQuery the IDs of the users in the audience and publish each as an individual message (with metadata) onto an email generation Pub/Sub. Each such message (a “compile task”) will kick off the generation and sending of an individual email when it is processed in the next step. The last step in the process is the email compiler, which provides a worker endpoint that accepts these compile tasks. It retrieves (and caches) a generic form of the email content based on the compile task’s template ID, and it retrieves the full user info from the user API with the user ID. This user API call is needed because many fields beyond the user ID included in the compile task may be needed to generate the individual email, like showing or hiding certain sections from the daily ‘Today’s Headlines’ newsletter. Then, using Go’s built-in templating language, it turns the template content into the individualized emails, with transformations such as adding click tracking parameters to links, adding or hiding sections from the long newsletters based on user preferences, and in the near future, adding personalized article suggestions based on NYT’s recommendation API. Finally, after it generates the individualized email, it is dispatched to the user’s email address using an API from our mail relay vendor. GAE’s quick scaling means that many instances of the email compiler can spin up very quickly to handle the potentially millions of compile tasks coming from the Pub/Sub, and this architecture makes it easy to add additional API calls as data sources for email content (such as the personalization API or an A/B testing framework) without re-tuning the scaling. Transactional email dispatches also go through the same pathway and are simply triggered by a synchronous API call rather than a message from the Pub/Sub. In addition to the components that comprise the core email sending infrastructure of the new platform, we also were able to quickly and easily set up several auxiliary GAE services for tasks like collecting email delivery and open logs. The benefits of building the new email platform cannot be overstated. Whereas the old system could take hours to deliver a newsletter to a large audience, the new platform rarely takes more than 10 minutes, and is usually faster. Since launching, we have seen a dramatic reduction in weekly system failures and have set up an extensive suite of alerts and monitoring dashboards that provide us with significant visibility of the system’s inner workings. When problems do occur, they are easy to identify and debug due to the careful separation of concerns throughout the system, as well as the polished GCP logging tools. The new data storage setup is transparent and performant, making everything from GDPR compliance to measuring email recipient engagement far easier. When adding new features, the GAE architecture makes it easy to integrate an additional API call or data source into a service without re-tuning the scaling behavior. This platform will allow us to greatly expand both the capabilities of the editors composing emails and the features of those emails for the recipients in ways on par with the rest of the exciting technical innovation happening at The Times. We now have confidence that we can rely on a platform that’s scalable, resilient, and sustainable. Rather than simply trying to keep things running, we’re now able to focus on building out features and tools that will help editors create more engaging newsletters to build even deeper relationships with our readers. We’ll cover what this means from a product perspective in an upcoming post, but we’re excited to see what we can build in the future given a solid foundation. How we design and build digital products at The New York Times 910 4 Google Cloud Platform Code Email Serverless Technology 910 claps 910 4 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-07-25"},
{"website": "NewYork-Times", "title": "five questions with will sentance", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/five-questions-with-will-sentance-125a368142f7", "abstract": "Code Data Product and Design Workplace Culture Work with Us On June 6, Will Sentance came by the New York Times office to lead a JavaScript workshop. We caught up with him afterward to talk more about JavaScript and about his work at Codesmith. Interview by OLIVIER DE MEULDER . What is Codesmith, and what inspired you to start it? Codesmith is an organization that teaches software engineering, computer science and machine learning. We do it in person in New York and Los Angeles, and now, for the first time, we’re able to offer our curriculum globally through our online platform. I was fortunate to study politics, philosophy and economics at Oxford. It was a wonderful experience, bringing an eclectic group together to think about how to solve tough problems. But studying there in the midst of the 2007–08 financial crisis highlighted to me the missing pieces of traditional education. I came to believe what would give organizations, missions and companies an edge in the next generation was the ability to understand, build and lead with technology. I wanted to give people the chance to develop those skills in a setting that would, like Oxford, bring people together from every background, empower them through a Socratic model of teaching to become autonomous individuals, and accelerate them to leadership in software engineering and technology. What’s nice is seeing some grads getting mid-level and senior positions at big technology companies and others doing development at non-profits. The two campuses in New York and Los Angeles are full of remarkable residents (‘residents’ is the title we give students) building extraordinary projects. In the last year alone three of the largest 25 projects in open source space were developed by Codesmith residents. This year we’ve begun teaching online as well. It follows the same Socratic method — it was a huge surprise to me that it worked online. It’s allowing us to reach people around the world. We’ll have people from Bangalore tune in at 4 a.m. alongside someone in Lagos pair-programming live online with a student in Cleveland — it’s pretty extraordinary. In your bootcamp and online classes, you focus almost exclusively on JavaScript. What has drawn you the language, and why do you like to teach it? Graduates work in Golang, machine learning with R, iOS development, solidity for blockchain. Codesmith is really more about teaching computer science and programming sufficient to get someone a mid/senior position. That being said, that acceleration does require focus. The beauty of JavaScript is its versatility: browser, server, hardware. I also like it deeply as a language. Back in the day there were the ‘good parts’ of JavaScript, but those days are long gone. It was a disliked language because of some genuinely bad judgment calls in its design. But much of the dislike was not a critique of JavaScript, but of the web browsers in which it ran (with all their varying implications of everything from timers to the console itself). Much of that variation has now been fixed. New ES2015 onwards features have brought super sophisticated methods for interacting with data (iterators, generators) and for working with asynchronous code (the ability to complete slower tasks like getting updates from a server without affecting performance) like async/await You wrote in HuffPost that you believe pair-programming is one of the most effective ways to learn to code. Why do you think that is? Pair-programming works by separating the responsibilities of solving a coding challenge between two people. One partner verbalizes an approach to the challenge and the other must implement it an actual code. Being an effective engineer is about learning how to learn — in other words how to push through blocks and encounter a new framework, language feature or design pattern and have the confidence, strategies and resilience to navigate through it. The traditional way to learn to code is to watch tutorials that teach ‘content,’ such as a language feature or a framework. But while this may teach someone how to code for the specific situation in the tutorial, it is rarely translatable to another situation, and it can hinder a student’s ability when they encounter a new challenge. So how do you get better at navigating through new challenges? Unfortunately the only way is to do it again and again. I call this ‘hard learning,’ like with Harvard’s online computer science-focused program, EdX, which has a 96 percent attrition rate. It’s hard, but f you make it through the program and complete all of the material and challenges, you effectively receive a Harvard Computer Science degree. The alternative is ‘easy learning,’ like online tutorials or simple challenges, which are great to keep you going but they’re never going to take your skills to a level where you can be hired as a software engineer. So what’s the solution? Do the hard learning work through tough blocks, but with a programming partner to help keep you going. Even if you’re confident and you can tackle the hard learning, there’s still a tendency to spend too much time researching and not enough time coding. Pair-programming again helps with this. Finally, one of our core beliefs at Codesmith is the role technical communication plays in helping someone be an effective senior developer. Teaching students to explain their approach to a pair-programming partner improves the quality of technical communication. Coding bootcamps have become very popular in recent years, yet some people in the tech industry are still skeptical about their effectiveness and favor job applicants with Computer Science degrees. Do you think that’s a valid skepticism? I think some of it is reasonable and it’s why I’m always a little cautious to put Codesmith in the bootcamp category. The reason employers like computer science degrees is that CS degrees teach problem solving and autonomy, and they and teach the underlying principles of programming and computer science. Bootcamps have by contrast been tempted to teach things like ‘how to implement React v16,’ which is a very narrow take on what it is to be an effective software engineer, and one that doesn’t always lead to sustainable code or even careers. That was why we decided to go deep on programming and computer science-first principles in the Codesmith program: algorithms, data structures, operating systems, threading, lexical scoping, eventing systems There’s also a sense that CS degrees attract people with a true passion for computers. This is naive; people should have a chance to discover their love for technology at any stage of their life. A recent graduate of Codesmith, who received a senior developer position had been a electronic musician for over 10 years. As she worked with music technology, she discovered a love for building the tools she used, which turned into a love for software engineering. She found a path for doing that with her career. Codesmith has schools in New York City and Los Angeles, and I understand you travel between the two cities. Do you have plans to open more schools? I love the tight knit community in Los Angeles and New York . It takes time and an amazing team — people like Schno Mozingo who heads up curriculum, and Shanda McCune and Olivia Leitner running all aspects of the program — for that to emerge. To have any other locations, we’d have to have that same level of leadership I’m also excited by the online potential. We launched an online-only learning platform this year — CSX — that a lot people spend over 20 hours per week on. I’d like to keep expanding that and see if there’s a way of giving people ongoing support online for the rest of their careers. Will Sentance is a Frontend Masters course author and CEO of Codesmith, a software engineering school in Los Angeles and New York. How we design and build digital products at The New York Times 966 Learning To Code Technology Conversations JavaScript Edtech 966 claps 966 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-11-09"},
{"website": "NewYork-Times", "title": "announcing a new ios feature that helps readers find stories relevant to them", "author": ["Norel Hassan"], "link": "https://open.nytimes.com/announcing-a-new-ios-feature-that-helps-readers-find-stories-relevant-to-them-a8273f8fcca4", "abstract": "Code Data Product and Design Workplace Culture Work with Us The New York Times publishes around 160 articles per day, with only a fraction of those articles making it to the digital home page. We wanted to find a way for our loyal readers to easily keep up with the stories that are most relevant to them. We’ve created a new space within our iOS app called Your Feed where readers can choose from 24 channels to follow, giving them more control over their experience with The Times. Some channels pull stories from existing New York Times sections and columns, such as Modern Love, while other channels, such as Gender & Society, pull content from a variety of sections. These curated channels highlight the breadth of journalism we publish and surface relevant content readers may have missed. Some channels include commentary from our reporters and editors, and feature worthwhile reads from outside of The Times. This added context is only available on Your Feed, and we’re experimenting with this extra layer to bring deeper insights and context to stories. Reading a printed paper is a customizable experience. When you hand someone a paper, they have access to all the stories; they pick out the sections they want and read stories of interest. Maybe while they’re thumbing through, they find a story or section that they didn’t realize they wanted to read! Chances are, different readers will select different sections and stories. It’s been my job as a product designer at The New York Times to take this idea and translate it to your phone. 1. Readers told us follow is the thing to do Following is not a new concept. It’s a common feature in apps and on websites: we follow on Twitter, Instagram and on other platforms to get the content we want to see. The New York Times is not new to the following space, either; we’ve experimented with different ways of surfacing customized content over the years. While some of our experiments have been more successful than others, they all have informed the latest iteration of Your Feed. The biggest ‘ah-ha!’ moment came from in-person research we did to explore what a customized space within our digital experience could look like. Our initial hypothesis was that readers wanted a better way to save content, but in the end, we discovered that the ability to follow different types of content was the greater user need. In the research we conducted, we presented research participants with four hypothetical customized features: “Archive,” “Follow,” “News you can use” and a “Queue.” Along with each of the four hypothetical features, we also showed participants a deck of cards, with each card representing a piece of New York Times content, and asked them to select all of the cards they were interested in for that hypothetical content space. We then asked participants to take the physical cards they had in hand and group them on on a blank canvas, or “screen,” based on how they would find the different content types the most useful. We then discussed the reasoning behind how participants organized their cards, and their expectations around different messaging channels, such as notifications, and the relationship to both the idea of a new space and the home page. After talking with participants about their decisions over several rounds, and thinking about the different use cases that arose, it became clear that the ability to follow New York Times content was a promising opportunity to serve unmet user needs. Of all the hypothetical features we tested, Follow proved to have the fewest number of workarounds, while also solving for several different user needs at once. It was the biggest hole our team could fill in our product. Through our research, we also learned that users were interested in having a space separate from the home page that delivered a customized feed of content. To validate our research, we created a very hacky prototype of Follow for desktop web. This prototype featured a matrix of channels based on page views and engagement, and it allowed readers to follow channels from article pages. Although the test was held together with Scotch tape, readers were following channels and coming back more often to see what was published. It quickly proved the research right: our readers wanted a way to follow our journalism and have a customizable space. 2. Showcasing a writer’s voice and tone is really important When I first started at The Times, I joined a team that was working on a mobile prototype that delivered stories and photos in a more conversational way. Through that prototype, we learned that readers were interested in interacting with our content in a more casual way. With this in mind, we simultaneously did a text message experiment throughout the summer 2016 Rio Olympics. Readers could sign up to get text messages from our Deputy Sports Editor, Sam Manchester, as he covered the Games. The texts were funny and offered behind-the-scenes insights that readers couldn’t get anywhere else. People really engaged in this two-way communication; They texted Sam back and asked specific questions at a volume and rate that was, frankly, difficult for one person to keep up with. We’ve since improved . Both of these projects highlighted how our design-led team needed a more streamlined workflow with the newsroom. Part of the challenge was figuring out how two departments with different disciplines — Product & Design and the newsroom — could create a workflow that served each other’s needs. This didn’t happen with our previous projects and we planned accordingly for Your Feed. We learned that we needed to create a new workflow for editors and reporters that fit seamlessly with their already hectic days. To achieve this, we leveraged The Times’s wide use of Slack to act as the CMS for Your Feed, to prototype quickly. Our back-end engineer, Brandon Hopkins, built a bot that interacts with editors, producers and reporters to guide them through the process of sharing links and publishing commentary. 3. We need to help our readers, not overwhelm them With previous messaging experiments, we learned to limit the number of stories we delivered to readers. Too many new stories resulted in users ignoring the feature. Readers said it was too close to their real email inboxes and it made them feel like they were working through a to-do list, instead of catching up on their interests in an enjoyable way. This sentiment came up during our in-person research as well. Interview after interview, users discussed how they feel overwhelmed and want solutions for navigating a nonstop news cycle. When we were determining what channels would be offered in Your Feed, we knew we had to strike the right balance with channel topics. There had to be enough channels to satisfy a range of interests, but not so many options that we would overwhelm our users. We took the same considerations for the publication cadence within channels. We couldn’t make topic-based channels draw content algorithmically because it could inundate users’ feeds — we may publish dozens of stories on a particular topic in a given week, for example. So our topic-based channels (Climate Change, Health & Fitness, Space) are curated by New York Times editors who ensure we deliver a diverse selection of stories. Over the next several months we will be adjusting the channels we offer, expanding how readers can follow channels and adding new features to Your Feed. We’ll be watching and listening closely to how readers are engaging with the channels. We’ll also continue to explore what a customized space within The New York Times means by testing new features that will help us determine the future of Your Feed. We’re excited to iterate on different versions of incorporating save, notifications and managing your interests. Take a look and let us know what you think . Shannon Smith contributed writing. How we design and build digital products at The New York Times 313 1 Journalism Design Thinking Product Design UX Design 313 claps 313 1 Written by Lead Product Designer at The New York Times How we design and build digital products at The New York Times. Written by Lead Product Designer at The New York Times How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-09-24"},
{"website": "NewYork-Times", "title": "improving our video experience part one our on demand video platform", "author": ["Flávio Ribeiro"], "link": "https://open.nytimes.com/improving-our-video-experience-part-one-our-on-demand-video-platform-cf818e03353d", "abstract": "Code Data Product and Design Workplace Culture Work with Us This is the first post in a three-part series about the progress and achievements of our video delivery platform. We’ll start with detailing what has changed since the launch of the microservices we implemented for encoding and publishing our on-demand videos. Read part two here . If you want to know more about this project, please read this post. Since the release of our new publishing pipeline, we’ve encoded and published a total of 133,452 videos between H264/MP4, VP8/WebM and HLS H264/MPEG-TS levels. We’ve also received and accepted some external pull requests on the open source components of the pipeline. Three more encoding providers were added . The rollout was considered a huge success for both technology and the newsroom, as speed of encoding and overall system stability has improved dramatically. Until the middle of this year, all the video assets were hosted and served by a content delivery network (CDN). As part of the company’s technology strategy, we recently decided to move all product deployments to Google Cloud Platform, including how we run, host, and serve our video content. In order to achieve this, we started a project to migrate our library and add support for Google Cloud Platform to our publishing pipeline. Before starting the migration process, we discussed whether there might be a better way to migrate and serve our content. Inspired by Ellation , it seemed like a smart idea to use the nginx open source module created by Kaltura that is capable of generating adaptive bitrate formats from H264 encoded files. Deploying this module would not only bring us the ownership and control of the origin, but also save storage costs by using our existing H264 files for serving the adaptive formats. The module would also give us MPEG-Dash and Microsoft Smooth Streaming support for free. In addition, with this setup, we could benefit from the progress in the module coming from the strong open source community, like the support for serving fragmented MP4s, which is one the items we have in our backlog. Before starting the assets transfer, we wanted to make sure we weren’t impacting the user’s experience with this new approach. In fact, we were thrilled to improve the QoS/QoE after the migration process. In order to measure the current QoS/QoE score, we first integrated our web video player with Mux . Once the player integration was complete, we had a better picture of our playback experience across devices and browsers. The second step was to migrate our static assets. The on-the-fly packager works by dynamically chopping the existing video files in small chunks and generating manifest files for guiding the players to download and play them in an adaptive streaming fashion. This way, we transferred all our MP4 files to a Google Cloud Storage (GCS) bucket to be used by the module. We also transferred a VP8/WebM rendition for fallback purposes on old browsers that don’t have the ability to playback H.264 content. With all the assets in place, we set up four nginx servers running the on-the-fly packaging module in a Kubernetes cluster on Google Container Engine (GKE) to serve as origin servers. Next, we set up a Fastly layer for caching the segments and playlists that were generated on-the-fly by the origin. We also created another location on the same nginx servers that route requests directly to the GCS bucket, allowing players to play the MP4s and WebM files too. For the nginx module to find the files on the GCS bucket, we developed a component called gcs-helper . When given a video slug from our CMS, the GCS helper service finds all available H264/MP4 renditions for the on-the-fly packager and levels for the adaptive formats. We deployed the new approach for 10% of users and set up an A/B experiment on Mux. After some tweaks on the segment size, caching timeouts and hls.js parameters, we were able to achieve a higher playback experience score for the users watching from the on-the-fly packager. This is especially true when we have traffic peaks where more edge servers have the segments cached, allowing users to download them faster. We increased the number of users consuming videos from the new endpoints and investigated the server’s load and cache hit ratio until we finally launched for 100% of the users. As a final step, we added the support for sending the new encoded videos to GCS buckets on the distribution component of our pipeline.We also removed the generation of HLS levels during our transcoding process, speeding it up and helping our journalists to publish our news clips and time-sensitive content faster. As mentioned above, the nginx module is now able to generate fragmented mp4 files for HLS. Since we are using hls.js for all client playbacks except for Apple devices/browsers, we want to give it a test and compare the performance between fragmented MP4 versus MPEG-TS. Avoiding the transmuxing on the browser will probably help a bit on the startup time and save some battery on mobile devices. We also want to try a faster start with smaller segments on the beginning of the playlists. Both tests will be executed in A/B fashion. When it comes to new features, during our last Maker Week , we played with some open source projects for thumbnails generation . We will revisit the project this year, and the goal is to make it ready for real users. We also have plans to work on a metadata service to generate extra information about the video to help with searchability and to feed our recommendations systems. If you want to know more about the components we are using for our on-demand publishing and on-the-fly packaging, GCS-Helper and the docker image are available as open source software. The encoding profiles are available here . For our next post in our Improving Our Video Experience series, we will walk through the problems we had on our Live Streaming infrastructure and explain how we solved them. We will also describe how we made it possible for journalists and publishers to create and manage live streaming events without the need of technical support. How we design and build digital products at The New York Times 416 6 Google Cloud Platform Online Video Online Video Platform Open Source Code 416 claps 416 6 Written by Brazilian, Senior Director of Engineering at ViacomCBS. How we design and build digital products at The New York Times. Written by Brazilian, Senior Director of Engineering at ViacomCBS. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-05-25"},
{"website": "NewYork-Times", "title": "the new york times ranks as a top company for women in technology", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/the-new-york-times-ranks-as-a-top-company-for-women-in-technology-22950f5a342", "abstract": "Code Data Product and Design Workplace Culture Work with Us By NICK ROCKWELL and ERIN GRAU For the second year in a row, we’ve been named to the 2017 Top Companies for Women Technologists Leadership Index by the Anita Borg Institute . This award recognizes the effort of many women and men in the company to build a diverse and inclusive workforce, which fuels innovation, growth and profitability. We have focused, in particular, on three areas: RECRUITMENT: Recruiting and hiring high quality talent with an emphasis on identifying women and other underrepresented minorities. We rewrote our hiring process, and every candidate who interviews with our department is met by a diverse interview panel. Our public job descriptions are following new guidelines to attract candidates from the largest talent pool with the broadest range of abilities. And we are working to build out a diverse talent pool by posting to diverse job boards, attending meetups and conferences, and by holding sourcing sessions with our staff. Through these efforts, we have significantly increased the number of female engineers over the last two years. ENVIRONMENT: Retain, support and promote an environment where diverse talent thrives. We wrote communications and conduct guidelines, and partnered with organizations like Girls Who Code, Power to Fly, Women in Tech & Entrepreneurship New York and TechLadies, to empower women internally and externally in the field. We’ve sponsored countless hackathons, conferences and events with the goal of bringing female and other underrepresented technologists together. And a huge milestone was accomplished when we strengthened and broadened our parental leave policy across The Times. ADVANCEMENT: Strengthen the internal pipeline of women and underrepresented minorities into leadership positions. We launched a mentorship program, introduced unconscious bias training, and created allies and agents of change throughout the entire technology department. We are honored to share this year’s list with companies we admire, and we’re proud to be recognized by an organization that shares our commitment to advance women in technology. Nick Rockwell is the CTO at The New York Times. Find him on Twitter and Medium Nick Rockwell . Erin Grau is the VP of Transformation and co-chair of The Women’s Network at The New York Times. How we design and build digital products at The New York Times 36 Diversity Women In Tech Technews Code Inclusion 36 claps 36 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2018-04-26"},
{"website": "NewYork-Times", "title": "abra an enterprise framework for experimentation at the times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/abra-an-enterprise-framework-for-experimentation-at-the-times-57f8931449cd", "abstract": "Code Data Product and Design Workplace Culture Work with Us By JOSH ARAK and KENTARO KAJI Systematic experimentation — in the form of A/B and multivariate testing — has become embedded in the workflow and culture of teams across The New York Times: Product teams test new features; newsroom editors test the framing of individual stories; and marketing tests to learn what it takes to turn casual visitors into subscribers. Like many organizations, we debate the weight given to instinct versus data-driven decisions and grapple with the best ways to measure long-term success. But we also recognized the need to establish a common language, framework and set of tools for running experiments across The Times. Two years ago, our landscape of testing technologies was extremely fragmented, with five separate testing platforms and five separate methods of tracking and reporting being used to accomplish the same task. Teams used different processes and methodologies, which made it difficult to report and interpret consistent results. To address these issues, we convened a team of developers and analysts to research ways to simplify and standardize our testing strategy. It was out of these efforts that our new system, known as ABRA, was born. ABRA, short for A/B Reporting and Allocation architecture, was developed with two key goals in mind: first, to provide an embedded, light-weight framework that allows for flexible testing on both the front-end and back-end; and second, to tie that framework directly into our data infrastructure to ensure accurate, fast and flexible reporting. Today, ABRA supports a range of experiments at The Times, including the replatform and redesign of desktop and mobile home screens, a well as experiments in paywall innovation and personalization, to name just a few. Our work on ABRA began in 2015. After meeting with industry counterparts, reviewing available vendors and determining the vast array of tests we needed to support, one thing was clear: Our most important tests (e.g. home page redesign, meter rule and paywall testing, ad pattern changes) required experiments to live deeper in our infrastructure than vendor solutions would allow. So we decided to build ABRA ourselves. Before we started coding, we researched which capabilities from vendor products we wanted to preserve and also how to embed a custom framework deeply into our technology stacks. That led to several core components around which we could focus our development efforts: User ID Management Allocation Framework Targeting & Segmentation Capabilities Integration & Deployment Data Model: Collection & Aggregation Reporting Interfaces The project was then split into two major development initiatives: One focused on the development of the allocation framework, which allows for the creation of experiments and the allocation, management and tracking of test visitors. The other was a dedicated data pipeline and tools to support the reporting needs of our users. To understand some of the challenges we face in A/B testing at The New York Times, let’s look at ABRA’s earliest implementation: a snippet of JavaScript that emerged from our core news products and now lives on multiple sites across the nytimes.com domain. The snippet, which usually lives inline and above the fold, initializes DOM attributes on the document root based on the user’s randomly-assigned variations. Using these attributes, CSS rules and other inline scripts can change the display and styling of content before first paint. It also installs a library with facilities for reporting variation assignments and user actions to our data pipeline. The variations a user gets aren’t truly random; in fact, we use a consistent hashing algorithm to persist A/B test groups, hashing each experiment ID with the user ID and mapping the result to one of a list of variation IDs. (This common technique is better described in a 2007 paper by Kohavi et al. , under “Hash and partition.”) What’s perhaps unusual about our approach is that we calculate this hash not on the server, but in client-side JavaScript within the ABRA snippet. Why would we do this? Our site comprises many disparate stacks, none of which share much in common. Client-side JavaScript is the lowest common denominator. The hash function we use, @jbt’s pithy implementation of SHA1 , turns out to be quite fast for our purposes (even on CPU-starved mobile devices) compared to the alternative of a blocking server roundtrip. We also knew some experiments would have to span multiple subdomains of nytimes.com, but we wanted to avoid adding more to the already overburdened nytimes.com cookie. Hashing on the client requires only a single fixed-length user ID cookie, which (unlike other forms of client-side storage) is shared by all subdomains of nytimes.com, and a configuration object that’s identical for everyone and therefore trivially cacheable at the edge. And in order to avoid interdepartmental gridlock, we wanted to enable the teams responsible for all web products to conduct experiments independently of one another, while allowing teams whose products span multiple properties (our marketing assets, for example) to run tests across all of them at once. This implementation has spread across The New York Times’s web products, including to stacks that might theoretically benefit from more tailored versions of ABRA — products that operate without an edge cache, for example — but which find the inline snippet good enough. Future iterations may integrate more tightly into the underlying stacks, since there seems to be a move towards consolidating previously disparate products like desktop and mobile core news. The future is bright! The sheer number of data sources being used in our old system made it difficult and slow for analysts to draw consistent, meaningful insights from their experiments. We knew that one of the most impactful improvements that could come out ABRA was improving data accuracy and giving experiment owners easier access to data and insights. Our first goal was to develop a unified data pipeline to ensure we were collecting all experiment data in a single place. With this data pipeline we were looking to accomplish a few key objectives: Provide a single source of data for all experiments being run across the company Collect and store hit-level experiment data that our analysts can use for deeper exploration into experiments Develop rollups of our hit-level data and join it to key data sources for a summary of critical engagement and revenue metrics, surfaced via a fast, friendly UI Next we developed a user interface for end users to access key metrics on their experiment, where we apply a Bayesian methodology for determining lift and confidence. For more complex experiments, the analyst creates a custom report from the ABRA data pipeline to incorporate the necessary metrics and audience segments of interest. With the expanded use of ABRA across the organization, there are a number of enhancements to come: Deeper integration into our native and replatformed web apps More flexible and detailed reporting for teams running experiments with ABRA, surfacing the most relevant metrics and audience segments for their goals Smarter optimization methods including contextual bandits, for experiments that are evaluated in real-time and optimized perpetually Expanded targeting capabilities, for delivering experimental and optimal treatments to behavioral and geographic audience segments How we design and build digital products at The New York Times 360 3 Analytics Data Ab Testing Technology 360 claps 360 3 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2020-03-24"},
{"website": "NewYork-Times", "title": "moving the new york times games platform to google app engine", "author": ["JP Robinson"], "link": "https://open.nytimes.com/moving-the-new-york-times-games-platform-to-google-app-engine-e9337f2c9444", "abstract": "Code Data Product and Design Workplace Culture Work with Us The New York Times crossword has been an integral part of daily life for many people since it started appearing in print in 1942. When The Times built its first website in 1996, a digital version of the crossword followed shortly after as a stand-alone digital product. Though it was first built as a web-based Java applet, the crossword has grown into a suite of mobile apps and a fully interactive website that has over 300,000 paid subscribers. To serve puzzle data to that many subscribers and to handle advanced features like syncing game progress across multiple devices, our backend systems were running on Amazon Web Services with a LAMP-like architecture . The introduction of the free daily mini crossword in August 2014 brought a larger daily audience which put a lot of strain on our architecture. As the crossword grew in popularity, our architecture started to hit its scaling limitations for handling game traffic. Due to the inelastic architecture of our legacy system, we needed to have the systems scaled up to handle our peak traffic at 10PM when the daily puzzle is published. The legacy stack leaned on technologies that required some level of human interaction and could take hours to scale up and down. We needed to scale within minutes. The system is generally at that peak traffic for only a few minutes a day, so this setup was very costly for the New York Times Games team. Luckily, we at The Times recently decided to move all product development to the Google Cloud Platform where a variety of tools awaited to help us move faster and save money. After shopping the Google product suite, we decided to rebuild our systems using Go , Google App Engine , Datastore , BigQuery , PubSub and Container Engine . I’ll discuss the architecture in greater detail in future posts but for now, I’m going to concentrate on App Engine, which is the core of our system. The platform, which has been available as a Platform as a Service (PaaS) since 2008, abstracts away most of the inner workings of a web server and allows developers to concentrate on writing code to solve their business problems. Here are a few features worth highlighting that the Games team has taken advantage of: Local Development : Google provides an SDK that enables users to run a suite of services along with an admin interface, database and caching layer with a single command. Combined Access and App Logging : Using the provided logging libraries, developers can write application logs that the platform ties to server access logs within Google’s cloud logging interface. This greatly simplifies debugging our systems as we can see exactly what happened within any given request. Monitoring/Alerting : To launch any system reliably, developers need insight into their system’s performance. Without any extra configuration, the platform tracks response latency, error rates, network usage, memory, CPU usage and much more. Everything is displayed through Stackdriver dashboards, which offer the option to set up alerts based on metric data. User Authentication : By adding a single line to a service configuration, developers can force users to authenticate with their Google credentials. Google can also handle authorization so the service is exposed to only a select audience. HTTPS/DNS : When a service is deployed to app engine, it is immediately available on the internet with HTTPS enabled at a domain that looks like “https://{service-name}-dot-{project-name}.appspot.com”. This allows developers to go from concept to sharable prototype within minutes. PubSub Push-Style Subscriptions : Google’s PubSub service can be configured to post to an HTTP endpoint whenever a new message is delivered to a subscription. Traditionally this would require developers to add an additional layer of security, but App Engine manages that for you. Using this concept, we can easily fan out large workloads to a fleet of servers to do offline tasks like personal statistic calculations and bulk data loads into BigQuery. While most of our replatforming to App Engine has seemed almost magical at times, some of the out-of-the-box features didn’t meet our needs. While none of the issues were blockers, our work-arounds may be useful for other teams considering the platform. Deployment Tools : Google does provide some excellent tools for versioning and deploying code to App Engine, but we use Drone CI at The Times and there was no existing plugin so we developed one that would work well with Drone and App Engine and recently open sourced it . API Security : While user authentication works great on App Engine, authenticating other services is a little more difficult. Google’s Cloud Endpoints product is not yet available for App Engine and Go so we added logic to our services for whitelisting IP addresses to restrict access to non-production environments. For internal requests from one App Engine service to another, we rely on a non-spoofable HTTP header . In the future we hope to rely on Google’s OAuth tooling within App Engine. Autoscaling : Autoscaling is one of App Engine’s strengths, but it did have some initial problems with our 10pm traffic spike, which you can see in the chart below. Since our traffic spike is predictable, we ended up resolving this by adding a cron to hit a special endpoint on our service once shortly before the spike to scale the system up, and again just after to scale down to normal levels. This special endpoint uses App Engine’s admin API to quickly add or reduce additional idle instances to handle the brief increase in traffic. Though we migrated to GCP about seven months ago, all games API traffic is flowing through App Engine and 90% of the traffic is served purely by App Engine services and GCP databases. This accomplishment would not have been possible for our three-person team of engineers to achieve without the tools and abstractions provided by Google and App Engine. Beyond being able to quickly move to a more reliable platform, we’ve also managed to cut our infrastructure costs in half during this time period. As gaming at The New York Times continues to grow, I’m confident we made the right choices to enable us to experiment, iterate and scale at speed with ease. Editor’s note: this post has been updated to better explain the reason behind the Crosswords Team’s decision to move from AWS to GCP. How we design and build digital products at The New York Times 2.7K 9 Google Cloud Platform Golang Code Tech 2.7K claps 2.7K 9 Written by Senior Software Engineer at Datadog. A user of Go. A lover of cats. How we design and build digital products at The New York Times. Written by Senior Software Engineer at Datadog. A user of Go. A lover of cats. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-09-15"},
{"website": "NewYork-Times", "title": "introducing marvin a go kit server for the app engine standard environment", "author": ["JP Robinson"], "link": "https://open.nytimes.com/introducing-marvin-a-go-kit-server-for-the-app-engine-standard-environment-ab5b2586cfae", "abstract": "Code Data Product and Design Workplace Culture Work with Us We recently covered how The New York Times Games team moved their server infrastructure to Google App Engine from Amazon Web Service. When we started building software on App Engine, we found we did not need our existing server, gizmo , because App Engine automatically provides more than half of gizmo’s server functionality. To keep a similar structure but strip out all the unneeded tooling, we built and open sourced Marvin . Marvin provides common tools and structure for services being built on Google App Engine by leaning heavily on go-kit libraries. The service interface in Marvin is very similar to the service interface in gizmo so software can look the same, but use vasty different styles of infrastructure. To show off how easy it is to compose a service using Google Cloud Platform’s abstractions with Marvin, we’ve created an example service that allows a user to save, retrieve and delete an www.nytimes.com article URLs via Google OAuth and Google Cloud Datastore: https://github.com/NYTimes/marvin/tree/master/examples/reading-list#the-reading-list-example We’re open sourcing this project to not only aid the community, but to also ask the community to help make Marvin better . If you are interested in helping out, please feel free to contribute or reach out in the #marvin channel in the Gopher Slack Community . How we design and build digital products at The New York Times 97 1 Google Cloud Platform Golang Open Source Code 97 claps 97 1 Written by Senior Software Engineer at Datadog. A user of Go. A lover of cats. How we design and build digital products at The New York Times. Written by Senior Software Engineer at Datadog. A user of Go. A lover of cats. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-08-23"},
{"website": "NewYork-Times", "title": "set up your mac like an interactive news developer", "author": ["Sara Simon"], "link": "https://open.nytimes.com/set-up-your-mac-like-an-interactive-news-developer-bb8d2c4097e5", "abstract": "Code Data Product and Design Workplace Culture Work with Us Developers know the scenario: Just as you get comfortable with one machine, it comes time to upgrade to a new one. Maybe you’re used to wrestling your way through the setup process, running long lost commands until you run out of error messages. The New York Times Interactive News team is here to help. Using this NPR tutorial as an example, I spent some time during my first days on the job here documenting my setup process. You can follow the steps below to set up your machine so that it’s ready to build and deploy like we do. First a little context: Interactive News is a newsroom development team that builds software for newsgathering and storytelling. We use many different technologies; we’ve got running projects in Python, Node, Rails, Go and even Haskell. This guide focuses on the core technologies we use to create newsgathering tools like web scrapers, database frontends and other data-processing scripts. A quick note before we begin: I’m using a recent-model MacBook Pro running macOS Sierra 10.12. First things first: Open up your App Store and check to see if there are any new updates to install. You’ll want to make sure your computer is set up with the latest security and operational updates. Next up? Command line tools. Open up your terminal, and run this command: This will get your machine ready to install software packages that will help you as you begin to build news applications. As you just discovered, your Mac comes with a fully functional built-in terminal. But if you’re looking to get the most out of your experience I recommend using iTerm2 , which gives you the flexibility to customize the number of vertical and horizontal panes in your window. iTerm2 also provides a robust search and autocomplete and allows you to set up a hotkey to launch the terminal quickly. There are a handful of options for text editors, and personal preference will be your best way to decide. I use Atom , GitHub’s free and open-source text editor. Members of the team here also use Visual Studio Code , Vim, and Sublime Text 2 . Homebrew is a package manager that will help you install software quickly and painlessly. To install Homebrew, run this command from your terminal: Follow the instructions in the prompt. You’ll be all set with Homebrew once you see: We use a combination of Amazon Web Services and Google Cloud Services to host most of our scripts and public applications. This section assumes that at least part of your work will be hosted with Amazon Web Services and that you’ve been set up through the AWS portal with an access key and secret access key. Make a directory called .aws and change into it: Create two files, config and credentials: In config, paste in your AWS region: In credentials, paste in your AWS key and secret key: Whether you’ll be working solo or on a team, version control will allow you to keep track of your code in all its iterations. The Git client should come automatically installed on your machine, so you’ll just need to create an account on Github . Once you’ve created a GitHub account, you’ll need to give your machine access to pull and push to repositories. GitHub’s documentation will help you through setting up your SSH keys. For database software, the team uses a mix of MySQL, PostgreSQL, MongoDB, ElasticSearch or Redis depending on the needs of the project at hand. The news applications team tends to favor Postgres because of its configurability and capacity to load and query large amounts of data quickly. Installing it with Homebrew is a snap. One command will help us to get Postgres ready to use: Your Mac comes with Python 2.7 pre-installed, which is great! We use Python 3 for new project builds, though. So that we can leave the system Python at 2.7, we only set Python 3 to default within virtual environments that sandbox your projects. Here’s how to get started: Add the following to your ~/.bash_profile: In your terminal, type: Although we typically use Python and Flask or Django to back most of our internal reporting tools , our public-facing applications are more often built using technologies like Node and React . Finally, you will want to install what you will need for your deployment process. Most of the Interactive News team’s deployment infrastructure lives on the Google Cloud Platform, so my setup involved initializing Google Cloud SDK and Kubernetes services . These steps should be all it takes to get you started building projects on your Mac. If you still have some questions, come find me on Twitter or on the News Nerdery Slack . How we design and build digital products at The New York Times 339 1 Code 339 claps 339 1 Written by asking about the data with @covid19tracking • past: @spotlightpa, @nytinteractive, @vprnet, @softwareforgood • she/her How we design and build digital products at The New York Times. Written by asking about the data with @covid19tracking • past: @spotlightpa, @nytinteractive, @vprnet, @softwareforgood • she/her How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-08-16"},
{"website": "NewYork-Times", "title": "bootstrap to css grid", "author": ["Natalya"], "link": "https://open.nytimes.com/bootstrap-to-css-grid-87b3f5f830e4", "abstract": "Code Data Product and Design Workplace Culture Work with Us Despite many clever hacks and creative workarounds, there hasn’t been a simple answer for creating layout on the web. From misusing tables, to over-engineering simple floats that push around content, developers have consistently struggled to translate designs to code. Developers have been saying for years that there has to be a better way to create responsive websites, and finally, there is: CSS Grid, a proper layout tool for the web baked right into CSS itself, is here. It’s fantastic! It’s exactly what we’ve been waiting for! And yet, it seems to me that developers are hesitating. What’s the hold up? You’re absolutely ready to declare display: grid if you’re the only person contributing code. However, if you’re working with a bigger team, on an older project or are faced with some real-world constraints, there may be some challenges ahead of you: Your designers have heard, “No, you can’t do that, that’s not how layout on the web works,” too many times, so they’re not designing anything that calls for you to learn CSS Grid. Your developers have heard, “You can’t use that yet, we still have to support x browser,” too many times. They don’t dare dream that all of the excitement about CSS Grid can apply to them quite yet — adding CSS Grid is out of scope. You’re on a tight deadline and you’re still not over how long it took you to really wrap your head around Flexbox. You promise yourself that you’ll take the time learn CSS Grid next time… for the next project… someday. If any of the scenarios above sound familiar, then start small with Progressive Enhancement. Use feature queries to enhance your components with CSS Grid, and worry about deleting old code later. Use the time to show the potential of CSS Grid to your designers. Learn without worrying. You might have to override some styles, but the gains will outweigh the temporary extra code. Don’t let that stop you from progressively enhancing your app with the new and exciting features of CSS! CSS is a powerful tool and remarkably flexible. I made an example on Codepen that embraces CSS Grid without removing the Bootstrap code or functionality for old browsers. Try it out, resize your browser, and then toggle off the CSS Grid enhancement. I tried to make just about every breakpoint a little different to show the creativity and flexibility made possible with CSS Grid. Fork it, play around and make something new. It’s just an example, and I hope you have fun with it. Yeah, yeah. Listen, I get that I could have just used Bootstrap and called it a day; it works just fine, and it’s incredibly fast to throw together once it’s already on a project. That’s why it’s still the fallback. But once you get a glimpse of the future, it’s hard to stay in the past. I have seen the power and potential of CSS Grid and I wanted to start using it. Or, more specifically: I didn’t want to declare a height to accommodate the maximum content. I would much rather have the rows know how tall each item should be. I wanted the option of having variable widths for each item, and I didn’t want to have them be split evenly or predictably all of the time. I was bored by having to always think in terms of 12 columns. Lots of websites use 12 columns and they all look the same. I felt trapped by fixed breakpoints for columns, and I wanted to set my own breakpoints to best serve my content. I didn’t want to keep making the choice between affecting global layout rules and writing hacky overrides. I wanted to easily change the gap between my columns. Sometimes a 3px column gap is all you need. I wanted to be able to set a min and max for each item and let the browser figure out how many items fit in each row. I am a huge fan of letting the browser do the math. It took about three lines of CSS to write the grid layout I wanted, and I wanted to live in the bright and beautiful future where layout is always that simple. Most importantly, I wanted to be excited about layout on the web again, and I wanted the designers I work with to feel the same. CSS Grid isn’t a hack, it’s a proper layout tool for the web. You don’t need to install anything, you don’t need a preprocessor, and you don’t need to twist your brain into knots just to understand how it works. Using CSS Grid doesn’t mean writing throwaway code — the throwaway code will be the old code you’ll want to delete when the timing is right, and that will be much sooner than you think: Chrome, Firefox and Safari all support CSS Grid, and soon Edge 16 will support CSS Grid, too. Turns out, it’s pretty great in practice, too. I implemented this CSS Grid progressive enhancement on The New York Times Watching media card component. Users on old browsers see Bootstrap, but users on browsers that support the display: grid property get the CSS Grid enhanced styles including the thin column gutters that our designers envisioned. Plus, next time there’s a redesign, our designers know they aren’t beholden to the old way of doing layout on the web. It may not look like it right now, but it’s actually a major step forward. There are so many great resources out there! Personally, I recommend checking out the following: Online Resources: Amazing work done by Jen Simmons (labs.jensimmons.com) and Rachel Andrew (rachelandrew.co.uk). Both are experts on CSS Grid and I am grateful for their hard work in pushing the web forward. In Person : If you’re like me and are a fan of conferences, how about going to CSS Dev Conf ? It’s awesome (I’ve been 3 times now), and as a bonus, it’s in New Orleans this year. If you go, make sure you attend Brenda Storer’s talk on CSS Grid or Miriam Suzanne’s talk on CSS grid systems. Codepen: Check out this CSS Grid Codepen collection by Stacy Kvernmo . DIY: Download Firefox and start using their handy grid inspection tool — it looks like a little waffle icon right next to display: grid in the inspector. Trust me, being able to visualize the changes you’re making is key. Visit some websites that are already using CSS Grid in production, inspect, and play around in the browser dev tools. A great place to start is the very instructional labs.jensimmons.com . There are a couple of good places to start. Do you have anything that’s only used internally? For example, I think one of the best places to start is with your style guide. (If you don’t have a style guide, get one and start documenting your design patterns!) To start, you can lay out your blocks of brand colors with CSS Grid. Alternatively, you can take a progressive enhancement approach on just one component at a time. Use feature queries to wrap your grid declarations and you’ll be able to start using CSS Grid without having to make sweeping changes to your whole site all at once. Start small, start simple, and build it up slowly! I promise it’s worth it. I hope you’ll share your work! It’s an exciting time for layout on the web. Get creative and make something new. How we design and build digital products at The New York Times 3.7K 11 CSS Front End Development Css Grid Bootstrap Technology 3.7K claps 3.7K 11 Written by Designer, engineer, author, fine artist, speaker, educator, illustrator, relentless optimist, and doer of good deeds. How we design and build digital products at The New York Times. Written by Designer, engineer, author, fine artist, speaker, educator, illustrator, relentless optimist, and doer of good deeds. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-09-28"},
{"website": "NewYork-Times", "title": "react relay and graphql under the hood of the times website redesign", "author": ["Scott Taylor"], "link": "https://open.nytimes.com/react-relay-and-graphql-under-the-hood-of-the-times-website-redesign-22fb62ea9764", "abstract": "Code Data Product and Design Workplace Culture Work with Us The New York Times website is changing , and the technology we use to run it is changing too. As the new site rolls out over the next several months, a look under the hood will reveal a number of modern technologies designed to make the site faster and easier to use — for readers, most importantly, but also for our developers. At the center of this has been our adoption of React, Relay and GraphQL. More than a year ago, when we first started talking about the technology that would power our new website, simplifying our stack was one of our biggest priorities. Our current desktop and mobile websites are written in entirely different languages: The desktop is predominately PHP; mobile runs on Node. Other products, such as our foreign-language sites, run on their own unique codebases ( Español , 中文 (Chinese) . Some do not even rely on our standard CMS, Scoop. All these sites read data from different origins and endpoints in different ways. It is hard to find a common denominator between them all. If I want to make a new app tomorrow, chances are I need to: Obtain credentials for multiple web services Write an HTTP client (for the umpteenth time) to talk to said services Create my view layer, probably from scratch, because there is no real central repository for NYT components We thought it would be nice if there was one place to add and retrieve data and one way to authenticate against it. It would also be helpful if there was a common language and repository for creating and reusing components. If a new developer joins our team, I want to point them at a single page of documentation that explains how to get up and running — and preferably start building apps the same day. This is not at all a dream scenario. We are moving towards this reality. That future is Relay and GraphQL. Relay is an open source project by Facebook that exposes a framework they have been using internally for years. It is the glue that binds components written in React to data fetched from a GraphQL server. Relay is written in JavaScript, and we are using it as the basis for our new website’s codebase to power our desktop and mobile versions as one on Node. GraphQL is “a query language for APIs”, which has a default implementation in Node. Facebook developed it to provide a data source that can evolve without breaking existing code and to favor speed on low-powered and low-quality mobile devices. The schema can evolve, but should never break. Products are described in graphs and queries, instead of the REST notion of endpoints. It works like this: GraphQL queries contain nodes, and only the nodes that are requested are returned in a given response. GraphQL nodes do not have to represent a flat data structure — each node can be resolved in a custom manner. Here is a simple example of a GraphQL query: It doesn’t matter how the query is resolved. The hard initial work is designing it in a way that will survive redesigns, backend migrations and framework changes. A query might be resolved by multiple data sources: REST APIs, database, a flat JSON file. A product might begin by returning data from a simple CSV file, and later be grow to return data from a cluster of databases or remote storage like BigTable. GraphQL is simply a clearinghouse for queries. It also comes with a tool called GraphiQL that allows you to view and debug your queries visually. And Facebook has open-sourced a library, called DataLoader , that makes it easy to query multiple backends asynchronously without having to write custom Promise logic that ends up in callback hell. Relay acts as a partner to GraphQL and React. A top-level query usually happens on a route — a URL pattern that loads a component when it is matched. GraphQL “ fragments ” are co-located with your React components. A component describes what slices of data it needs on certain types. Relay queries “spread” the fragments of other components. In this particular case, the “slug” is extracted from the URL path and passed to our GraphQL query. The Page component will be populated with a “viewer” prop that contains the data specified below: As React components become more nested, queries can become increasingly complex. In Relay Classic, all of the query-parsing logic happened at runtime. As of Relay Modern , queries are now parsed at build time and are static at runtime. This is great for performance. Migrating from Classic to Modern can be a big lift. The project has provided a compatibility guide to allow your code to incrementally adopt new features, but the fragmented nature of the Node ecosystem can make this complex. Your codebase might be on the latest version, but some of your dependencies might be pinned to an earlier version. We handle a lot of the complexity around upgrades and dependencies using our open source project, kyt . Relay Modern is such a massive improvement that it requires a “cutover” of old to new code. However, the benefits are exciting. By default, GraphQL queries are sent to the server by Relay as an HTTP POST body containing the text of a query and the variables needed to fulfill it. Queries compiled by Relay Modern at build time can be persisted to a datastore, and IDs can be sent to the GraphQL server instead. We look forward to taking advantage of this optimization. It has been exciting moving our codebase to React, and leaning on the great features kyt provides out of the box, such as CSS Modules. We are finally creating the central component repository we’ve longed for. As we transition away from using REST APIs, we no longer have to query the canonical representation of an article, when all we really need in some display modes is five to seven fields. When we want to update our design across all products, we will no longer have to make changes across several codebases. This is the reality we are moving towards. We think Relay and GraphQL are the perfect tools to take us there. Scott Taylor is a senior software engineer on the Web Frameworks team. How we design and build digital products at The New York Times 1.4K 8 Thanks to Chase Davis . Code React GraphQL 1.4K claps 1.4K 8 Written by Musician. Lead Software Engineer at the New York Times. Married to Allie. How we design and build digital products at The New York Times. Written by Musician. Lead Software Engineer at the New York Times. Married to Allie. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-08-23"},
{"website": "NewYork-Times", "title": "things we read this week", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/things-we-read-this-week-1cf68873d4a7", "abstract": "Code Data Product and Design Workplace Culture Work with Us Welcome to Things We Read This Week, a weekly post featuring articles from around the internet recommended by New York Times team members. We will be sharing articles we read and liked, things that made us think and things we couldn’t stop talking about. Check back every Friday for a new post. Caitlin Kalinowski (who worked on hardware at Apple and Oculus) shares some practical principles for developing prototypes and how to best use them for learning what to ship. I’m thinking about how many of them can be adapted for non-hardware product work. - Recommended by Allen Tan, Lead Product Designer, News Products I read the iOS 11 AVDepthData documentation this week and found it pretty exciting. Depending on the device, it looks like iOS 11 apps will have per-pixel distance-from-the-camera-in-meters information for photos and videos, which will make it easy for an iOS developer to isolate different objects in a scene. Combined with face detection or some other human detection API, we might see a lot of camera apps in the future capable of cutting out the people in the frame and putting them on a different background. I’m interested to see if this is an indication of how camera technology will evolve. - Recommended by David Stolarsky, Software Engineer, T Brand Studio Incredible piece about Glenn McDonald at Spotify and his creative approach to metadata. There is something important here: metadata should be expressive, should capture the essence of the domain being classified, and this only happens when done by people who are passionate about and have a deep understanding of the domain. - Recommended by Nick Rockwell, Chief Technology Officer American illustrator Sarah Glidden traveled to Turkey, Syria and Iraq with independent journalists to observe their work. “Rolling Blackouts”, a beautiful watercolor comic, is the result of her journey. It is a reflection on journalism and a unique form of reportage with a gentle personal touch. - Recommended by Véronique Brossier, iOS Software Engineer How we design and build digital products at The New York Times 3 Technology Reading Links Design Thinking Things To Read 3 claps 3 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-07-06"},
{"website": "NewYork-Times", "title": "things we read this week", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/things-we-read-this-week-e64deb92cc57", "abstract": "Code Data Product and Design Workplace Culture Work with Us Welcome to Things We Read This Week, a weekly post featuring articles from around the internet recommended by New York Times team members. We will be sharing articles we read and liked, things that made us think and things we couldn’t stop talking about. Check back every Friday for a new post. Through its mix of catchy headlines and viral social distribution, particularly on Facebook, Upworthy was labeled one of the fastest-growing media sites of all time back in 2013. But then Facebook tweaked its newsfeed algorithm and everything changed. NPR dives into what has happened since. - Recommended by Chase Davis, Editor, Interactive News Mike Riethmuller expertly explains CSS Variables and how to use them effectively in a project. He highlights the benefits of separating logic from design with some great examples including using custom properties for modular scale headings as well as proper scoping to reduce the use of media queries. Good read for anyone who cares about organized CSS. - Recommended by Natalya Shelburne, NYT Beta Web Developer This meandering history of the UUID, by way of introducing a new k-sortable UUID implementation called “KSUID” gives this workaday unique identifier the attention it deserves. As a developer, I’m always eager to pause and learn more about the widespread computing concepts we often take for granted, and this post doesn’t disappoint! - Recommended by Jeff Sisson, CMS Web Developer By taking a human-centered, prototype-driven approach, the entrepreneurs in this program are looking at media in a unique light. For example, one of the companies created an SMS platform that connects users and journalists in a two-way messaging-based conversation and another company is working to open up podcasts to search engines for greater discovery in audio storytelling. The Times is an investor in Matter which makes it all the more important to leverage Matter’s design-thinking and entrepreneurial processes in our everyday work. - Recommended by Hannah Cassius, Product Manager, Customer Product Meta-analysis of experiments is an excellent way to reflect on the value contributed by A/B & multivariate testing programs. This paper from the research team at Qubit delivers a sober analysis of 6700 e-commerce experiments (contrasted with the usual case study hype) and highlights the value in applying behavioral psychology to experiment design. - Recommended by Shane Murray, VP, Data Insights Group How we design and build digital products at The New York Times 3 Tech Design Thinking Reading Things To Read News Articles 3 claps 3 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-06-30"},
{"website": "NewYork-Times", "title": "all in a weeks work how we tackled the five day sprint process", "author": ["Kelci Shipley"], "link": "https://open.nytimes.com/all-in-a-weeks-work-how-we-tackled-the-five-day-sprint-process-c0aba01a6446", "abstract": "Code Data Product and Design Workplace Culture Work with Us It may have been the second week in October, but it felt like summer camp. For five consecutive days, eight members of the New York Times Games team hid away in a conference room armed with pads of sticky notes, a blank whiteboard wall and a bit of nervous energy: we were actually going to give this thing a shot. “This thing” being an entire work week dedicated to product development and design thinking, inspired by the book “ Sprint: How to Solve Big Problems and Test New Ideas in Just Five Days ” by Jake Knapp, John Zeratsky and Braden Kowitz at Google Ventures. Our team is known for the New York Times Crossword, but we’re always thinking about ways to improve our existing product and new playing experiences we could create. Compressing these ambitions into the five day sprint process meant that each day had a specific focus, which allowed the week to go from talking about big problems on Monday to testing a solution with a working prototype on real users on Friday. But we didn’t just show up Monday to see what happened — we did a lot of prep work. We assembled our sprint team and assigned roles. I took on the role of Facilitator, which meant reading the book cover to cover and knowing how to guide the team through the process while keeping everyone on track. By the time the first morning came, we were ready. The first day also happened to be the boldest. The morning started by revisiting our long-term goal to create an experience that gives our users a sense of accomplishment every day. We turned our assumptions into thoughtful questions and asked ourselves things like, “What does it mean for a user to feel accomplished?” and “What motivates them?”. The afternoon was spent talking to our Marketing, Design, Editorial and Technology teammates who are experts on our product. Those conversations helped us define the challenges we wanted to focus on for the week: to create a sense of fulfillment and meet users in their individual moments. Our product’s complex nature means that we have an array of users with different levels of knowledge and skill. But whether our users can solve a Monday puzzle in 15 minutes, or whether they consider doing half of a Sunday puzzle a victory, we want them to feel good in each instance of their experience. At the end of the day, we synthesized this information and mapped it to a user journey, which helped us focus on the solution we wanted to design for. With day one behind us, we started sketching solutions to the problems we defined in our discovery. We started by discussing elements of comparable experiences that we could look to for inspiration, such as developing reading skills or feeling accomplished in a fitness app. The solution sketching segments were highly structured and timed, meant to emphasize critical thinking over artistry. Each person left with one solution sketch to be reviewed the next day. One of the keys for the week was to keep moving through it, even when we found ourselves in moments of doubt. The uncertainty of our success was my greatest challenge because I had to balance the execution of a particular day’s segment with the hope that I was guiding everyone on the correct path. This made Wednesday a critical day in the sprint, and a convenient one to get breakfast catered. Energized and caffeinated, we reviewed each person’s sketches using methods of evaluation such as silent voting, written comments and verbal discussion. The methodical approach felt a bit awkward at times, but it minimized irrelevant tangents and accelerated decision-making. And it led us to one of the most exciting moments of the week: illuminating the thing we would create. At this point, we threw some of “Sprint’s” rules out the window. The book suggests creating a prototype with elements from each sketch, but we decided to focus on one idea we really liked and evolve it. On Wednesday, we put together a storyboard of how our prototype would function, so Thursday was devoted to bringing that prototype to life. To make our prototype, we used a sequence of pieces of paper to mimic the look and feel of interacting with a digital screen. The afternoon was spent designing game elements, crafting editorial and shuffling through a lot of Spotify songs. I did my best to keep the momentum going with help from of Michael Jackson, Whitney Houston and other ’80s pop icons. And then like that, it was on to day five. Getting to Friday is an accomplishment in and of itself. By design, the week was packed with moments of anticipation, doubt and exhilaration. Though we felt all of these emotions leading up to Friday, when we gathered to watch real people interact with our prototype a sense of calm settled over the room. Armed once again with pads of sticky notes and sharpies we noted interesting behaviors, insights and emotions as the five user testing sessions were conducted by The Times’ Audience Insights team. Through the user testing, we were able to confirm that what we created was something people were delighted to play. But even if our prototype was something people didn’t enjoy, it wouldn’t have meant the sprint was unsuccessful. The point of going through a five day sprint is to learn and gather insights, so the pressure wasn’t on whether or not the prototype performed well (although it was a nice bonus). In addition to seeing what worked well in the prototype, we learned what things people craved and how we could provide our users with an even better experience. The goal of the sprint was to learn and we achieved it. So what happens now? After that week, we left with many questions we still wanted to answer. We’ve been actively iterating on the prototype and figuring out more variables we want to test with users. The sprint asked for a big commitment, however our return on the five day investment was immense. We gained new tools and frameworks for executing brainstorms and we continue to incorporate pieces from this process into our discovery strategy. Kelci Shipley is a Program Manager for The New York Times Games team. She works closely with the Crossword product and the people that build it. How we design and build digital products at The New York Times 95 Design Design Thinking Design Process User Experience User Research 95 claps 95 Written by New York Times Program Manager. Former Journalism major who still carries a torch for words. How we design and build digital products at The New York Times. Written by New York Times Program Manager. Former Journalism major who still carries a torch for words. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-06-15"},
{"website": "NewYork-Times", "title": "things we read this week", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/things-we-read-this-week-72a9902aabc2", "abstract": "Code Data Product and Design Workplace Culture Work with Us Welcome to Things We Read This Week, a new weekly post featuring articles from around the internet recommended by New York Times team members. We will be sharing articles we read and liked, things that made us think and things we couldn’t stop talking about. Check back every Friday for a new post. This piece is a reminder that we are not Google. Or Amazon. Or LinkedIn. And that the technologies developed at tech giants to solve their problems might not be necessary or appropriate for tech problems at a smaller scale. To decide whether a technology is appropriate for your needs, it’s necessary to consider the historical context in which that solution was developed to see if matches. What was the original problem that this tech was built to solve? How a technology fits a problem is often more important than the technology itself. - Recommended by Albert Sun, Assistant Editor, News Platforms We’re loving this inclusion style guide from Buffer! It’s the most comprehensive and easily digestible guide we’ve seen, and we’re using it across technology to align around a common vocabulary as we continue to sharpen our focus on building a diverse and inclusive workforce. - Recommended by Erin Grau, VP of Operations In this post, Jason Yuan, a student designer, leverages user centric design principles to propose a revamp of the Apple Music app that considers Apple’s design aesthetic, their presumed goals, and real user feedback. - Recommended by Modupe Akinnawonu, Product Manager How we design and build digital products at The New York Times 2 Links Things To Read Reading Readinglist 2 claps 2 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-06-23"},
{"website": "NewYork-Times", "title": "things we read this week", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/things-we-read-this-week-c8eddb1ab4db", "abstract": "Code Data Product and Design Workplace Culture Work with Us Welcome to Things We Read This Week, a weekly post featuring articles from around the internet recommended by New York Times team members. We will be sharing articles we read and liked, things that made us think and things we couldn’t stop talking about. Check back every Friday for a new post. As an iOS developer, I often fall into the trap of obsessing over a screen but giving little thought to how a user actually navigates to and from that screen and how these actions influence their perception of the application layout. This article argues that applications can create better interfaces by considering how the user perceives space outside of the viewport when designing gestures, animations and transitions. — Recommended by Alex Brashear, iOS Software Engineer I’m always happy to learn more about the history of a brand’s identity, especially when it’s the history of The New York Times. David Dunlap , a Times reporter, wrote a great piece on how The Times’ nameplate has evolved over time, and includes some quotes from letters sent by readers who were angry about changes made in 1967. — Recommended by Andrei Kallaur, Creative Director of News Products Choose Your Own Adventure books — those classic nonlinear, branching novels from the ’80s and ’90s — have become something of an unofficial mascot for some of the quiz-like articles we create on Interactive News. So we loved these visualizations of the winding paths those novels sometimes took (some of which were a lot more complicated than you remember). — Recommended by Aaron Krolik, Interactive News Developer Apple’s Worldwide Developer Conference was held last week and Steven Sinofsky did a great job dissecting the announcements. I found his technical analysis and insight especially interesting as Sinofsky was the former president of Microsoft’s Windows division. We use a lot of Apple products and technologies here at The Times and this report did a terrific job outlining how the software and hardware announcements could impact us and our customers. — Recommended by Alan Yacavone, Director of End User Services A glimpse into the promise of what artificial intelligence could bring to newsgathering, based on a fascinating report from the Associated Press about how it is already being used today. — Recommended by Chase Davis, Editor, Interactive News How we design and build digital products at The New York Times 4 Reading Things To Read Links Design Technology 4 claps 4 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-06-30"},
{"website": "NewYork-Times", "title": "quick and statistically useful validation of page performance tweaks", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/quick-and-statistically-useful-validation-of-page-performance-tweaks-39ecce4328d7", "abstract": "Code Data Product and Design Workplace Culture Work with Us By JUSTIN HEIDEMAN Improving page performance has been shown to be an important way to keep reader’s attention and improve advertising revenue . Pages on our desktop site can be complex and we’re always looking for ways to improve our performance. Since 2014, when our desktop site was last rebuilt, there have been big changes in client-side frameworks with great improvements to performance. Some of those site improvements will take us some time. We wondered if in the shorter term there are some smaller changes we could implement to make www.nytimes.com more performant. A quirky problem we ran into was how to effectively measure modest performance changes when a page has many assets of variable speed and complexity that can impact its performance. We used the magic of statistics to compensate for the variability and allow us to get usable, comparable measurements of a page’s speed. In order to make our site faster, we have to figure out what is slow first. We do fairly well with much of the attainable low-hanging page performance fruit: compression, caching, time to first byte, combining assets, using a CDN. Our real bottleneck is the amount and complexity of the JavaScript on our pages. If you look at a timeline of a typical article page in Chrome’s Developer Tools, you’ll see that there is an uncomfortably long gap between DOMContentLoaded event and the Load event. Screenshots show that the page’s visual completion roughly correlates with the Load event. The flame chart shows a few scripts that take a fair amount of time, but there isn’t any one easily fixable bottleneck that could be removed to make our site faster. Slow pages are death by a thousand protracted cuts. Some of those cuts are our own doing and some of them stem from third-party assets. The realities of the publishing and advertising world demand that we include a number of analytics and third-party libraries, each of which impose a performance cost on our site. In order to start weighing the impacts and tradeoffs of the logic and libraries we have on our page, we wanted to get real timing numbers to attach to potential optimizations. For instance, in one experiment we investigated, we wanted to be able to know how much time is consumed rendering the ribbon of stories from the top of the story template and how much faster the story template could render if the ribbon were to be removed. One way to do this would be to use the User Timing API and measure the time it takes from when the ribbon initializes to when its last method completes. This works for when we have things we control and can easily modify the code for. It’s not as easy when we want to weigh the impacts of a third-party library because we can’t attach timing calls to code we don’t control. There is another problem with this approach: instrumenting one module provides an incomplete picture. It doesn’t show the holistic down-the-timeline impacts that an optimization may have, or account for the time it takes a script to download and parse before it executes. An even more fundamental problem is that any type of performance measurement on a page will give different timing values each time a page is reloaded. This is due to fluctuations in network performance, server load, and tasks a computer is doing in the background, among other factors . Isolating a page’s assets might be one way to solve it, but that is impractical and will give us an inaccurate picture of real-world performance. To correct for these real-world fluctuations and attempt to get usable, comparable numbers, we ran our timing tests multiple times, collected the numbers and plotted them to make sure we had a good distribution of results. The values that the graphs show aren’t specifically important, but the shape of the curve is; you want to see a clear peak and drop off of values to indicate you have enough sample points and are distributed in a logical manner. We found using the median of the collected timing values to be the most useful comparison number for our tests. The median is typically most useful when a dataset has a skewed central tendency , like ours, and is less susceptible to outlying data points. Gathering enough numbers by hand (e.g., reloading Chrome, writing down numbers) would be tedious, though effective. We use some open-source browser automation tools for functional testing of our sites, but they require some careful setup and retrieving page performance numbers out of them is not straightforward. Instead, we found and used nightmare , an automatable browser based on Electron and Chrome, and nightmare-har , a plugin that gives access to the http archive for a page full of useful performance information. Here’s what a simple script looks like to get the load event timing for a page: We want to get multiple timing numbers to be useful, so we need to loop the test. Unfortunately, with the HAR plugin, nightmare acts erratic when being looped, so our solution is to wrap the Node script with a simple loop in a shell script, like so: You might notice in the above script, we’re actually testing two URLs. This is due to another intricacy of the oscillations of page performance. We found that if we ran two tests sequentially, e.g., 40 runs of control, 40 runs of our test, our numbers were perplexing and sometimes did not match what we expected from our optimizations. We found that even an hour separation in time could produce variations in timing that would obfuscate the performance changes we were attempting to see. The solution is to interleave tests of the control page and the test page, so both are exposed to the same fluctuations. By doing this, we were able to see performance deltas that were consistent across network variations. Put it all together, let it run (go get a cup of coffee), and you’ll get two columns of numbers, easily pastable into the spreadsheet of your choice. You can then use them to make two nice histograms of your results, like so: These are still not real, in-the-wild numbers, but they are easier to attain than setting up a live test on a site, which we’re planning to do in the near future. Quick testing like this gives us the confidence to know that we’re on the right track before we invest time in making more fine-grained optimizations. How we design and build digital products at The New York Times 10 1 Code 10 claps 10 1 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-05-18"},
{"website": "NewYork-Times", "title": "https on nytimes com", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/https-on-nytimes-com-ed04bca88ed6", "abstract": "Code Data Product and Design Workplace Culture Work with Us By EITAN KONIGSBURG and VINESSA WAN We are thrilled to announce that we have begun to enable HTTPS on NYTimes.com, an effort that helps protect the privacy of our readers and ensures the authenticity of our content. This is a significant milestone in the 21-year history of our website, and though it’s taken us some time, we are very excited to share this wit our readers NYTimes.com consists of millions of pages, so we’ve prioritized HTTPS for areas of our site that receive the most visits. You should already be seeing a padlock next to our URL in your browsers on the following: The NYTimes.com home page Articles published in 2014 and later Most section, column and topic pages The NYTimes.com mobile site Most blog pages TimesVideo Podcast pages Improved privacy: HTTPS encrypts the data sent between your computer and our servers, making it more difficult for a third party to monitor what you are doing. While HTTPS will not hide the fact that you are visiting NYTimes.com, it will significantly diminish the ability of a third party, such as your internet provider, to see which articles you are reading. Authentic news: Another benefit of HTTPS is that it validates that your computer is communicating with the website you intended to reach, and that any data you receive has not been modified in-transit. When you see the padlock in your address bar, the browser has validated that you are getting authentic NYTimes.com content. Enhanced experience: Some newer web technologies are only made available to HTTPS pages. As we implement HTTPS, we are able to take advantage of these features to make our pages load faster, create innovative interactive projects and provide more personalized content. The benefits of HTTPS that we wrote about in 2014 remain relevant today. Other media companies have migrated to HTTPS: The Washington Post , Wired , BuzzFeed , The Guardian , and most recently, Quartz . (For more information, the Freedom of the Press Foundation launched a service to track HTTPS implementations on many major media sites.) It’s been a complex undertaking for us and we’ve discovered a lot in the process. We’ll be sharing a deeper dive into the technical aspects and the challenges we encountered on our journey to HTTPS. This is just the beginning, and we intend to bring the rest of our site under the HTTPS umbrella. There is still a significant amount of work remaining, but we are committed to seeing it through. Securing our site is good for our users and the right thing to do. Our core purpose as a company is “to enhance society by creating, collecting and distributing high-quality news and information.” We believe the implementation of HTTPS furthers this purpose. How we design and build digital products at The New York Times Product Announcements Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-05-18"},
{"website": "NewYork-Times", "title": "continuous deployment to google cloud platform with drone", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/continuous-deployment-to-google-cloud-platform-with-drone-7078fe0c2eaf", "abstract": "Code Data Product and Design Workplace Culture Work with Us By TONY LI and JP ROBINSON Over the course of the last year, the software development teams at The New York Times have been evaluating Google Cloud Platform for use in some of our future projects. To do this, we’ve surveyed a wide variety of software management techniques and tools, and we’ve explored how we might standardize building, testing and deploying our systems on GCP. Our newly formed Delivery and Site Reliability Engineering team came up with two methods of deployment with Google Container Engine and Google App Engine for computing environments and the open source implementation of Drone as a continuous integration tool. As a result of this work, we are open sourcing two plugins for Drone: drone-gke and drone-gae respectively. Container Engine is Google’s managed Kubernetes container orchestration platform. Kubernetes is an open source project that provides a declarative approach to managing containerized applications, enabling automatic scaling and healing properties. It encourages a common standard of how our applications are designed, deployed, and maintained across many independent teams. And because Kubernetes pools compute resources, developers can run many isolated applications in the same cluster, maximizing its resource usage density. App Engine is a mature serverless platform Google has offered since 2008. It is capable of quickly scaling up and down as traffic changes, which is ideal for many scenarios at The New York Times when you consider possible sudden spikes from breaking news alerts or the publication of the new daily crossword every weekday at 10 p.m. Drone is an open source continuous integration and delivery platform based on container technology, encapsulating the environment and functionalities for each step of a build pipeline inside an ephemeral container. Its flexible yet standardized nature enables our teams to unify on a plugin-extensible, ready-to-use CI/CD pipeline that supports any custom build environment with isolation, all with a declarative configuration similar to commercial CI/CD services. The result is the ability for developers to confidently ship their features and bug fixes into production within minutes, versus daily or weekly scheduled deployments. As a containerized Go application, it is easy to run and manage, and we hope to contribute to the core open source project. Google provides an excellent set of command line utilities that allow developers to easily interact with Google Container Engine and Google App Engine, but we needed a way to encapsulate those tools inside of Drone to simplify the workflow for developers. Luckily, plugins for Drone are simple to create as they can be written in Go and are easily encapsulated and shared in the form of a Docker container. With that in mind, the task of creating a couple reusable plugins was not that daunting. drone-gke is our new plugin to wrap the gcloud and kubectl commands and allow users to orchestrate deployments to Google Container Engine and apply changes to existing clusters. The Kubernetes yaml configuration file can be templated before being applied to the Kubernetes master, allowing integration with Drone’s ability to encrypt secrets and injecting build-specific variables. Here is an example Drone configuration to launch a Go application in a container via a Kubernetes Deployment resource into Google Container Engine: And the corresponding Kubernetes configuration: And the corresponding Kubernetes secrets configuration: drone-gae is our new plugin to wrap the gcloud and appcfg commands and allow users to make deployments to Google App Engine standard environment with Go, PHP or Python or to the flexible environments with any language. Here’s a very basic example of all the configuration required to launch a new version of a Go service to Google App Engine’s standard environment with a second step to migrate traffic to that version: Deploying new versions to the flexible environment requires a little more work, but it’s straightforward when using the plugin. We first use a build step to test and compile the code, then a publish step to build and publish a Docker container to Google Container Registry (via the drone-gcr plugin ) and finally, we kick off the deployment via our new plugin. We hope open sourcing these tools helps other engineers who want to leverage Drone as a continuous delivery solution. We are also looking to the community to take a look and help us harden our systems. Please raise an issue if you find any problems and follow the contributing guidelines if you make a pull request. For further reading and more documentation, you can visit the code repositories on Github: github.com/NYTimes/drone-gae github.com/NYTimes/drone-gke How we design and build digital products at The New York Times 14 Projects Code Open Source Container Engine Continuous Integration 14 claps 14 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-05-26"},
{"website": "NewYork-Times", "title": "building a cross platform 360 degree video experience at the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/building-a-cross-platform-360-degree-video-experience-at-the-new-york-times-c35afa92a2e8", "abstract": "Code Data Product and Design Workplace Culture Work with Us By THIAGO PONTES and MAXWELL DA SILVA Over the past few months, 360-degree videos have gained a lot of traction on the modern web as a new immersive storytelling medium. The New York Times has continuously aimed to bring readers as close to stories as possible. Last year we released the NYT VR app with premium content on iOS and Android. We believe VR storytelling allows for a deeper understanding of a place, a person, or an event. This month, we added support for 360-degree videos into our core news products across web, mobile web, Android, and iOS platforms to deliver an additional immersive experience. Times journalists around the world are bringing you one new 360 video every day: a feature we call The Daily 360 . We’ve been using VHS, our New York Times Video Player, for playback of our content on both Web and Mobile Web platforms for the last few years. Building support for 360 videos on those platforms was a huge challenge. Even though the support for WebGL is relatively mature nowadays, there are still some issues and edge cases depending on platform and browser implementation. To circumvent some of those issues, we had to implement a few different techniques. The first was the use of a “canvas-in-between”: We draw the video frames into a canvas and then use the canvas to create a texture. However, some versions of Microsoft Internet Explorer and Microsoft Edge are not able to draw content to the canvas if the content is delivered from different domains (as happens with a content delivery network, or CDN), even if you have the proper cross-origin resource sharing (CORS) headers set. We investigated this issue and found out that we could leverage the use of HTTP Live Streaming through the use of an external library called hls.js to avoid this problem. Safari also has the same limitation regarding CORS. It seems to have been an issue in the underlying media framework for years and for this scenario, the hls.js workaround doesn’t solve the problem. We tackled this issue with the combination of two techniques: The creation of an iframe with the video player embedded in it. The use of progressive download renditions such as MP4 or WebM on the embedded player. By doing this, we avoid the CORS video texture bug since the content and the iframe are in the same domain as the CDN and we were able to show the player in the parent domain, and the content inside the iframe. Many of our users see our videos from within social media apps on their phones. On iOS, almost all of these social network applications load off-site content on their own in-app browsers instead of using the native browser, which raises a longstanding technical issue: the lack of support for inline playback video, even on iOS 10 . This happens because inline playback support is still disabled by default on web views. The technical problems listed above aside, the basic theory on how we should view 360 content is pretty straightforward. There are basically four steps to implement a simple 360 content view solution: Have an equirectangular panoramic image or video to be used as a source. Create a sphere and apply the equirectangular video or image as its texture. Create a camera and place it on the center of the sphere. Bind all the user interactions and device motion to control the camera. These four steps could be implemented just using the WebGL API but there are 3D libraries like three.js that provide an easier way to use renderers for canvas , svg , CSS3D and WebGL. The example below shows how one could implement the four steps described above to render 360 videos or images: codepen.io When we first started to work on supporting 360 video playback on VHS, we researched a few projects and decided to use a JavaScript library called Kaleidoscope . Kaleidoscope supports equirectangular videos and images in all versions of modern browsers. The library is lightweight at 60kb gzipped, simple to use and easy to embed into the player when compared with other solutions. Solving 360 video playback on iOS and Android was interesting and challenging since there wasn’t a video library that satisfied our requirements on both platforms. As a result, we decided to go with a different approach for each platform. For the iOS core app, we created a small Objective-C framework that uses the same approach as Kaleidoscope. Initially we considered to start the development using Metal and OpenGL, but those are lower-level frameworks which require significant development work to create scenes and manipulate 3D objects. Luckily, there’s another option: SceneKit is a higher-level framework that allows manipulation and rendering of 3D assets in native iOS apps. Investigation revealed that SceneKit provided adequate playback performance, so we chose to use it to render the sphere and camera required for 360-degree video playback. We also needed to extract video frame buffers into a 2D texture to be applied as a material for the sphere, and to do that we decided to use SpriteKit . SpriteKit is a powerful 2D graphics framework commonly used in 2D iOS games. Our playback framework uses a standard iOS AVPlayer instance for video playback and uses SpriteKit to render its video onto the sphere. Finally, we bind user interactions and device movements to control the camera’s motion using standard iOS gesture recognizers and device motion APIs. By using these tools we were able to create a 360 video framework that is very similar to Kaleidoscope. We call it NYT360-Video , and we are happy to announce that we are open sourcing the framework. On the Android platform we did a deep evaluation of some open source libraries that support 360 video and images, and after an initial prototyping, the Android team decided to use the Google VR SDK . The NYTimes Android app works on various devices and Android OS versions, and Google VR SDK has the features and capabilities that we needed and a straightforward API that allowed a relatively easy integration. The Google VR SDK has evolved quite a lot from the day we started to work on the integration, and the Google VR team has invested a lot of time improving the project. Along the way, we worked together with Google on feature requests and bug fixes, and that collaboration gave us the certainty that we made the right decision to adopt it. The integration worked as we expected and now we have an immersive 360 video experience on Android. We are investigating new ways of encoding and playing 360 videos to increase performance and improve the user experience. We are excited to explore other interesting features such as spatial audio, stereo images and video. On the video transcoding side, we are exploring the use of cube map projections, which avoid the use of equirectangular layouts for a more space efficient approach. In theory, we can reduce the bitrate applied to the video by approximately 20 percent while keeping the same quality. Below you can see a very basic example on how we could support playback of 360 videos encoded with cube map: codepen.io The use of cube map projections is a more complex approach than using equirectangular projections since it would not only require changing our video player but also the way we transcode our videos. Earlier this year Facebook released a project called Transform , an FFmpeg filter that converts a 360 video in equirectangular projection into a cube map projection. We are investigating ways to integrate this into our video pipeline . We are also open sourcing the video encoding presets that we use to transcode all of our 360 video outputs. We hope to receive your crucial feedback and generate contributions from the open source community at large. Feel free to ask questions via GitHub Issues in each project. Check them out: github.com/NYTimes/ios-360-videos github.com/NYTimes/video-presets How we design and build digital products at The New York Times 3 Code Open Source 360 Video Video 3 claps 3 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-05-18"},
{"website": "NewYork-Times", "title": "store grand opening wrangling android data loading and caching", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/store-grand-opening-wrangling-android-data-loading-and-caching-c214cc062ab5", "abstract": "Code Data Product and Design Workplace Culture Work with Us By MIKE NAKHIMOVICH The New York Times strives to deliver our users the best possible experience. On Android, this means creating an offline-first, reactive architecture that minimizes how much data our app uses. The Android team used open source libraries including Dagger , RxJava , OkHttp , and Okio . We then tie these technologies together with a simple, open-source library we have developed called Store . A Store (instance) is that magical middle piece that aims to simplify fetching, parsing, storage, and retrieval of data in your application. A Store follows the Repository pattern while exposing a Reactive (RxJava) API that adheres to a unidirectional data flow. Store provides a level of abstraction between UI elements and data operations. We tried to simplify the logic around data fetching for offline and online users, helping us be an offline-first application. Stores also help boost app performance by preventing unnecessary network calls or disk reads. The architecture of our flagship news app is made up of immutable data (M)odels, Custom (V)iews, (P)resenters and (S)tores — which we like to call MVPS. Modern Android apps need their data representations to be fluid and always available. Users expect their UI experience to never be degraded (blocked) by new data loads. Whether an application is a social, news, or business-to-business app, users expect a seamless experience both online and offline. International users expect minimal data downloads, as megabytes of download can quickly turn into astronomical phone bills. Within our app we create lightweight, single responsibility Stores. A Store is responsible for managing a particular data request. A couple of years ago we rewrote our flagship news reader app to leverage new patterns in Android such as reactive architectures and dependency injection. During the rewrite we created something called a ContentManager which ended up being a middle tier god class that all data operations passed through. After our rewrite we started thinking of ways to break up this class into single responsibility fetchers/savers/parsers. The idea for Stores was born. Fast forward 6 months and we now had a few base classes to extend from that would enforce a Repository pattern. From a technical standpoint we were able to solve our specific issue: each store would now be responsible for abstracting a single fetcher/parser/persister. A few months later, a new app (Crosswords) was getting spiraled up. Unlike our main app which uses a custom network client and parser implementation, Crosswords was built using Retrofit/SQLite. We took steps to make the Store library more configurable, moving a few specific implementation into the Middleware package and keeping Stores as generic and pluggable as possible. While creating the Middleware module, we also created a new module for our specific persistence implementation called FileSystem. We found that streaming json from network to disk to be the fastest type of persistence. Subclassing stores did not seem to be optimal when using Retrofit so we created builders for store instantiation. As the store module grew into four distinct packages, we separated it into its own project and git repo. Fast forward to now: we are using Stores in two apps as well as any Maker Day project we start on. The core team wanted to push out our first open source library and Store seemed like it would be a great contribution to the community. Now came the hard part: how to go from internal code to open source. Like most internal code, we had a few blockers prior to going open source. One of our issues was that we rely heavily on Guava and did not want to release a library that depends on 10k methods. After a bit of trial and error we were able to separate/shade a jar containing only a subset of Guava, the cache implementation. Next, we had a few helper methods from Guava that we ended up rewriting. One of our devs did a fine job with writing a breadth-first file traversal somewhere besides a whiteboard. Some other tasks included removing anything specific to our internal systems, creating proper build scripts, creating README and diagrams, registering with Maven Central, and dropping dependencies to internal build tools with a switch to Travis for CI. When it was all said and done we had four modules which could be turned into libraries (all with minimal method counts): Store — Store artifact which contains base classes for constructing a new Store Implementation com.nytimes.android:store:1.0.1 Middleware — Sample gson parsers to use when building a store. com.nytimes.android:middleware:1.0.1 FileSystem — A disk persistence implementation that can stream to disk from network (contains a bit of middleware we will go into below) com.nytimes.android:filesystem:1.0.1 Cache — Extracted from Guava com.nytimes.android:cache:1.0.1 When you create an implementation of a Store, you provide it with a Fetcher . Additionally, you can define how your Store will cache data, both in-memory and on-disk, as well as how to parse it. Since you’ll be getting back an Observable of your data, threading is a breeze! Once a Store is built, it will handle the logic around data flow, allowing your views to use the best data source and ensuring that the newest data is always available for later offline use. Stores can be customized to work with your own implementations or use our included middleware. Store leverages RxJava and multiple request throttling to prevent excessive calls to the network and disk cache. By utilizing our library, you eliminate the possibility of flooding your network with the same request while adding two layers of caching (memory + disk). Fully Configured Store Let’s start by looking at what a fully configured store looks like, we will then walk through a few simpler examples. See the README for a more detailed rundown of functionality. The above builder is how we work with data at The New York Times, no loaders, content providers, sync adapters, or database required. With the above setup you have: In-Memory Caching Disk caching Parsing through streaming API Ability to get cached data or bust through your caches And now for the details: Creating a Store Barcodes Stores use Barcodes as identifiers for data. A Barcode is a class that holds two strings: type and key. The two values act as unique identifiers for your data. When .fetcher() is called, it will be passed to the Barcode. Similarly, the Barcode will be used as a identifier in your cache(s). Public Interfaces for Accessing Data — Get, Fetch, Stream The first time you subscribe to store.get(barcode) , the response will be stored in an in-memory cache using the Barcode as a key. All subsequent calls to store.get(barcode) will retrieve the cached version of the data, minimizing unnecessary data calls. This prevents your app from fetching fresh data over the network (or from another external data source) in situations when doing so would unnecessarily waste bandwidth and battery. A great use case: any time your views get recreated after a rotation, they will be able to request the cached data from your store. Having your data available has helped us retain less within our view layer. So far our Store’s data flow looks like this: By default 100 items will be cached in memory for 24 hours. You may pass in your own instance of a Cache to override the default policy. Busting Through the Cache Alternatively you can call store.fetch(barcode) to get an Observable that skips the memory (and optional disk cache). A fresh data call will look like: Overnight background updates within our app use .fetch() to make sure that calls to store.get() will not have to hit the network during normal usage. Another good use case for .fetch() is pull to refresh. Calls to both .fetch() and get() emit one value and then call onCompleted() or throw an error. Adding a Parser Since it is rare that data comes from the network in the format that your views need, Stores can delegate to a parser by using a ParsingStoreBuilder rather than a StoreBuilder . Our updated data flow now looks like this: store.get() -> Middleware — GsonSourceParser As mentioned in the intro, we are also releasing a separate middleware library with parsers to help in cases where your Fetcher is a Reader, BufferedSource or String and your parser is Gson: GsonReaderParser, GsonSourceParser, GsonStringParser. Our example can now be rewritten as: Disk Caching Stores can enable disk caching by passing in a Persister to the builder. Whenever a new network request is made, it will first write to the disk cache and then read from the disk cache. (See the README for example code.) Now our data flow looks like: Ideally, data will be streamed from network to disk using either a BufferedSource or Reader as your network raw type (rather than String). Stores don’t care how you’re storing or retrieving your data from disk. As a result, you can use stores with object storage or any database (Realm, SQLite, CouchDB, Firebase, etc.). The only requirement is that you can store and retrieve the data using the same type as your Fetcher. Technically there is nothing stopping you from implementing an in-memory cache for the Persister implementation and having two levels of in memory caching (one with inflated and one with deflated models, allowing for sharing of the Persister cache data between stores. Note: When using a parser and a disk cache, the parser will be called after fetching from disk and not between the fetcher and persister which will allow your persister to work on the network stream directly. Bonus: FileSystem & SourcePersister You may have noticed in the first example that we were using something called a SourcePersister. We’ve found the fastest form of persistence is streaming network responses directly to disk. As a result, we have included a separate artifact with a reactive FileSystem which depends on Okio BufferedSources. We have also included a SourcePersister which will give you disk caching that works beautifully with the middleware: GsonSourceParser. Let’s revisit an example that is structured like our first one, this time looking at a real Store we built for our New York Times Best Sellers screen: We recommend using the above builder to build most Stores. The SourcePersister implementation has a tiny memory footprint as it will stream bytes from network to disk and then from disk to parser. The streaming nature of our stores allows us to download dozens of 1MB+ JSON responses without worrying about OOM on low-memory devices. As mentioned above, Stores allow us to do things like calling bookStore.get() a dozen times asynchronously before our Main Activity finishes loading without blocking the main thread or flooding our network. We thought about what is truly necessary for data retrieval and concluded we only really need files, Guava caches, and a Reactive API — no loaders, content providers, sync adapters, or databases required. We enjoy our lightweight setup and hope you will too. We’d love to hear about what you build. And your contributions are welcome as well. How we design and build digital products at The New York Times 5 Code Open Source Android 5 claps 5 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-05-18"},
{"website": "NewYork-Times", "title": "putting style into the online new york times stylebook", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/putting-style-into-the-online-new-york-times-stylebook-939d68a114c8", "abstract": "Code Data Product and Design Workplace Culture Work with Us By ANDREI KALLAUR In 1895, the editors of The New York Times created the inaugural version of the paper’s Manual of Style and Usage — a guidebook to the publication’s particular rules of grammar, punctuation, spelling and capitalization that remains an essential part of our newsroom toolkit. Since then, it’s been updated regularly to reflect the changing times (the word email, for example, appeared as early as 1985 and was styled as “e-mail”). In 1999, the first online version of the manual, known as the Stylebook, became available on the NYT intranet. In 2013, when I was working as a mobile product designer for The Times, I helped to create an iPhone-only “app” version of the manual. This was a step in the right direction, but I wanted to do even more. I was interested in creating a new version of our living document that was more modern, accessible and usable. So, in 2015, I started to reimagine and redesign the Stylebook as a fully responsive web app — one that could be used on any device, regardless of platform. Along the way, I considered the importance of search, ease of use, and of course, typographic elegance. I designed a desktop version, tablet version and phone version, all maintaining the same functionality. Then came along this year’s Maker Week. During the kickoff meeting, I mentioned this project and asked if anyone would be interested in helping me push it further along. Sure enough, a flurry of emails started coming in. People from different departments, disciplines and backgrounds, including some I had never met, ended up forming the team. Over the course of five days, the Stylebook team (Chris Ladd, Nina Feinberg, Oliver Hardt, William Davis, Marie-France Han, Hamilton Boardman and myself) was able to build out a beautiful, fully-functioning prototype, complete with feature enhancements that are crucial to modern-day newsroom usage: Clean, legible typography Fully responsive web app Deep linking to entries Newsroom editors have started using the prototype and are giving us plenty of feedback — we’ll be using this to continue to make improvements and resolve issues. We’re very excited about what we’ve created so far and know that it wouldn’t have been possible without all of the work that was done on the original version by Walt Baranger, Tom Brady, Bill Connolly, Ray Lewis, Merrill Perlman, Al Siegal, Keith Urban and Ted Williamson. How we design and build digital products at The New York Times 5 1 Design Product 5 claps 5 1 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-05-22"},
{"website": "NewYork-Times", "title": "girls who code visit the new york times", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/girls-who-code-visit-the-new-york-times-94ada52d56c1", "abstract": "Code Data Product and Design Workplace Culture Work with Us By ANGELICA HILL A sea of excited young female faces. A crowded room of high school students fidgeting and waiting expectantly. Taking selfies and snaps from the moment they entered the room. But this is not a gaggle of adolescent fans waiting for a Zayn Malik concert to begin. These are young, ambitious girls exploring the possibility of joining the ever-expanding tech industry. The New York Times’ Technology department, in partnership with Girls Who Code, hosted “The New York Times: Reporting Online and Around the World.” The July 28 event gave 90 participants in 10th and 11th grade a glimpse into the inner workings of the newsroom, the technology group, and the product development teams of one of the best known newspapers in the world. The girls were shown the roles that technology, innovation and collaboration play in our multi-platform organization. “We are thrilled to welcome Girls Who Code and the next generation of female tech leaders at The Times,” said Erin Grau, Vice president of operations at The Times and co-chair of the Women’s Network. ”We are so inspired by the work of Girls Who Code, an organization who shares our commitment to closing the gender gap in technology.” Girls Who Code is a national non-profit organization that encourages girls to get into coding and development. Many of the 15- to 17-year olds were already passionate about going to college to study computer science. They were enthused by the program but complained that their schools either don’t offer any programming or computer orientated classes or if they do, that they tend to be male dominated. Development and coding wasn’t considered a future option until Girls Who Code came into their lives. One girl went as far as to say “coding is easy, you just need to know the language and practice.” This is the kind of confidence that programs like Girls Who Code were set up to instill. Carrie Price, one of the coordinators of the event and a software engineer at The Times, credited her confidence and determination to pursue a career within the tech sector to a similarly early exposure to coding and development. “Working with a program like Girls Who Code is awesome because we are getting an opportunity to be a little part of these girls’ summers,” she said. “The Girls Who Code program is doing a great job in instilling confidence in these girls really early on.” Carrie hoped that meeting successful female employees, “doing these things in real life”, would convince the girls that jobs in programming and coding are plausible options in the future. Teachers in the Girls Who Code program, such as Zoe Bachman, were universally impressed by the girls’ passion, hard work and commitment to the program. Zoe only started coding later in her career. Computer science wasn’t “cool” when she was at school. She returned to college to learn coding and development in order to teach kids the skills needed in the media and arts industries. But she says there still “needs to be a lot of changes in the tech industry” in terms of diversity. This is why Zoe wanted to work for Girls Who Code: “Their mission fits really well into my vision of diversifying the field.” The program introduces “a new image of what a programmer is.” Software developers Carrie Price, Alex Ording, and Jean Kim welcomed the girls to The Times and then Erin described the mission, history and structure of the newspaper. She outlined the evolving relationship between the newsroom, business and Technology departments. After a short video, Erin quizzed the girls with trivia about The Times, underlining the “boots on the ground reporting” and the determination to “get the story first and get the story right.” The girls were taken aback to discover that The Times produces a Harry Potter book worth of stories every day: and the equivalent of the complete works of Shakespeare every week. Erin described her own journey to The Times. After majoring in journalism and writing for television, she joined the newspaper industry. She described how she’d been told early on that the only measure of performance should be “did you make The Times a better place?” Erin encouraged the girls to “plan rich lives” and emphasized that when planning your career it is essential to know that “you can do multiple things, not just one.” The girls could code during the day and do yoga at night. Erin was as excited about the girls’ futures as they were by the inspirational vision that she presented of opportunity and equality for women in the workplace. One of the teachers observed that Erin was just the sort of role model needed by the girls. After a tour of the building, where the newsroom and the “cool” Pulitzer Hall were the highlights, the students heard from Chief Technology Officer Nick Rockwell. He spoke about his job, and answered a few questions from the girls. Three women from the Digital department — Elena Gianni, Rebecca Lai and Shirwah Tam — described their roles in Design (design is “not just about what things look like but much more about how things work”), in the Newsroom (astonishing the girls when she ended her talk by creating a basic website in front of their eyes), and as a software engineer on the Cooking team, respectively. The speeches underlined the crucial importance of collaboration and teamwork. The key message was to “just go out and do it.” The girls then got a chance to put the skills they had been learning at Girls Who Code to the test. They divided into small groups and carried out a paper prototyping activity, designing an app that gives recipe recommendations from NYT Cooking. Carrie Price hoped the activity would give “the girls time to brainstorm, think critically, think about a problem with different constraints”. The girls sketched their app designs on a piece of paper and gave them some great titles: “Slice, Slice Baby,” “Quizine” and “We Can Get You Out of a Pickle”. Carrie said she hoped the girls would come away being able to “look at programming from a different perspective, thinking more holistically about software design and what goes into it from beginning to end.” At the end of the day, the girls were tired but reassured that coding and development is undoubtedly a plausible option for their future: “If I don’t do it as a job, then I will definitely do it as a hobby.” There is a real skills gap in the technology industry. There’s simply not enough talent coming in. Nick Rockwell described the problem in terms of the failure of the education system, particularly at the high school level, to encourage both boys and girls towards careers in technology. Events like this are helping to rectify this by exposing girls to the job possibilities in the tech industry and giving them a chance to talk to role models. The New York Times strives to fill the skills gap and increase the number of women working in its Technology group through its Diversity in Digital task force, who are currently in the process of drafting various policies to improve the workplace environment. Carolyn Price believes that this task force has done a great job at “figuring out where the core problems are and trying to address those problems, particularly around recruitment, environment and advancement.” Erin summed up with two key secrets for success: “outwork everyone” and “build relationships.” She reassured the girls that “you are going to be scared of a lot of things, just do it!” Angelica Hill is a summer intern in Operations. She will return to Queen Mary University of London in the fall as an English Literature major. How we design and build digital products at The New York Times Culture Code Diversity Women In Tech Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-05-22"},
{"website": "NewYork-Times", "title": "design thinking for media that matters", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/design-thinking-for-media-that-matters-686e4642c3d4", "abstract": "Code Data Product and Design Workplace Culture Work with Us By ALEX ORDING At the end of May, eight New York Times product managers and engineers participated in Matter ’s media startup accelerator bootcamp. Over four strenuous days, we learned the process of design thinking: a human-centered, prototype-driven approach to creating something that fills a meaningful need in someone’s life. The bootcamp was a chance to collaborate with some of Matter’s other media partners: my team for the week included a photo editor from the Associated Press, the public editor of the Kansas City Star, and the CEO of PRX. Even though we all had vastly different professional backgrounds, the design thinking exercises we learned allowed us to start working as a productive team quickly. Of all the techniques we learned in the course of the week, I want to focus specifically on some that can be applied to engineers working on cross-functional product teams. Engineers are often partially immersed in product development, but writing code doesn’t feel like a user-focused task compared to a role like design or product management. Design thinking encourages the sort of radical collaboration that values diverse skill sets regardless of specialization. As an early part of the design thinking process, we ventured onto the streets of Manhattan to talk to potential users and learn about their needs. We set aside our assumptions about what we expected to find and started by simply asking questions, listening, and then looking for patterns and insights in what we heard. Our subsequent ideation sessions and prototype development were informed by the perspective we’d gained. This type of user empathy can help with technical decision-making as well. Performance considerations and other technical details that are delightful parts of a good user experience gain traction from an empathetic viewpoint. Plus, basing as many decisions as possible on feedback from real (or potential) users helps not only to ensure the success of the product but to prevent any individual’s preferences or biases from arbitrarily influencing it. In our bootcamp ideation sessions, we set explicit norms around generating at least a hundred ideas and building on others’ suggestions rather than critiquing them. Once we had a hundred options to choose from, we concluded our brainstorming and voted on two or three we found most exciting and meaningful. Most teams have some sort of hierarchy, with a limited number of decision-makers. Opportunities to widen the range of contributions — to include engineers and others less frequently invited to brainstorms — can be a valuable way to generate new ideas. Constructing a space with the shared understanding that everyone’s ideas are welcome permits that range of contributions. When engineers actively participate in user research, facilitated brainstorms, or product ideation sessions, they have a larger stake in the team’s success, and that success is grounded in creating meaning for users. The open-ended, exploratory nature of the design thinking process underscored the importance of adopting techniques that the entrepreneurs in Matter’s program use on a daily basis. Building low-res prototypes, testing them early, and iterating quickly all help to avoid investing resources in an untested product, which is just as important for large, risk-averse organizations as for small startups. We already use many of these techniques on the Beta team, but the Matter bootcamp reinforced the need to use them even more widely and consistently. As media changes rapidly, we understand the need for lots of experiments. We’re participating in Matter’s partner parallel program to experiment more with design thinking, in an effort to find new ways to make The Times more useful to readers. Each month during the 20 weeks of the program, we gather with other partner companies and the entrepreneurs in Matter’s accelerator to pitch our ideas and receive feedback. It’s exciting to be surrounded by a community of innovators tackling similar challenges in media and technology — all with the goal of making media that matters. Alex Ording is a software engineer on the NYT Beta team. She works on product development for Well . You can find her on Twitter at @alexording . How we design and build digital products at The New York Times 4 Design 4 claps 4 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-05-22"},
{"website": "NewYork-Times", "title": "improving startup time in the nytimes android app", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/improving-startup-time-in-the-nytimes-android-app-a693f08ddc94", "abstract": "Code Data Product and Design Workplace Culture Work with Us By MIKE NAKHIMOVICH Improving application startup and load time has been a priority for The New York Times Android development team, and we’re not alone. As device manufacturers continue to offer faster and more fluid experiences, users expect their native apps to be faster still. Our team recently rewrote our news app to take advantage of modern patterns such as dependency injection and reactive programming. The rewrite offered improvements in maintenance, code modernization and modularization benefits, but required some adjustments to optimize. When we initially released our new app, which we nicknamed Phoenix, startup time was a modest 5.6 seconds on a Nexus 5. This was longer than our goal: 2 seconds or less. This motivated us to put some effort into improving our performance. We found that most of the slowdown was caused by issues with reflection. After addressing these and fixing other smaller things, we’ve reduced our current startup time to 1.6 seconds. First, we captured our app’s startup time with Android’s method tracing feature. We measured from the Application Class constructor to the end of the progress indicator appearing on screen (see the documentation ). We then collected the resulting trace files for analysis by loading the trace into DDMS and finding the largest performance offender. We eventually switched to using NimbleDroid , which also offered a simple way to identify bottleneck issues, making it easier to compare performance across traces. The first major slowdown we found was related to the large number of classes, memory-intensive runtime and expensive calls to loading Jar resources required by Groovy, something previously identified as a problem in other libraries such as Joda Time . We primarily used Groovy for closures; improvements in code folding within Android Studio have resolved that need. Since we didn’t use any other constructs of the language, we decided to move away from it. We reverted back to plain old Java 7 syntax and stripped our codebase of Groovy. We’re currently exploring other options but enhancements in IDE support for viewing anonymous classes in Java have made it less of a priority. Next, we found some slowdowns within RxJava which were costing us about a second. Thankfully, a fix was issued in the next release . Some third-party analytics clients we have incorporated into our app had some blocking calls during app startup. We made some changes to how they were being instantiated and worked with vendors to help improve large upfront instantiation. We also uncovered a number of small technical debt issues in our codebase: blocking object instantiation on an md5 calculation, blocking in constructors and generally doing too much work up front. After these tweaks were implemented, we cut our startup time to about 3.2 seconds — half of what it had been and faster than before the rewrite. Our next focus was optimizing data flows. This is especially critical for our app, which is highly data-intensive. Since all of our data observations are asynchronous, we initially started with a single content manager to act as an abstraction between presentation and data layer. While this helped with encapsulation, it caused slowdowns by instantiating what gradually became a god object any time data was needed from persistent storage. This became a pain point when, for example, an analytics configuration value was needed from the disk during app launch but had to wait for blocking SSL-enabled network clients to instantiate. As the app grew and more dependencies were added, our content manager instantiation time increased, causing subsequent app starts to be as slow as initial installs. Rather than using a content manager as a single gatekeeper, we have moved toward individualized data stores, which let us load cached data as quickly as possible. Similar to recent work done by the Facebook Android team , we made sure to optimize the code path from disk to UI as much as possible. We began by breaking our content manager into individual singleton data stores backed by disk and network DAOs. For example, we broke out a ConfigStore backed by ConfigNetworkDAO and ConfigDiskDAO from our content manager. We leaned on Dagger’s Lazy instantiation, which allowed us to inject a lazy network client and not instantiate it until we actually do a network operation — important when offline or after the first load. Our architecture relies heavily on downloading data using background services. As a result, data is mostly loaded from disk storage to UI rather than having to make a network call. After we were able to create an optimal path from disk to screen we came to our next major speed hog: reflection. While trying to improve performance in data loading, we found that it was taking 700 milliseconds or more to parse the data for our Top Stories section, regardless of whether we were fetching from persistent storage or over the network. It surprised us to see how poorly Gson performed by default on Android for a largely data-driven app like ours. By analyzing startup traces, we zoomed in on calls to Reflective Type Adapters as the culprit . We tried to minimize and remove reflective calls from Gson, but the only viable approach was to painstakingly write type adapters by hand. This led to a long and fruitless journey to find serialization techniques that do not use reflection and do not have an expensive startup time. We were left with only a few options, all of which required adding additional code to our models. So we went back to the simplest working solution: Gson with custom type adapters . We saw a tenfold improvement in parsing performance after writing our own type adapters. To keep developer overhead to a minimum, we have leaned heavily on the Immutables library . This generates custom type adapters for our data models at compile time and also gives us the added benefit of immutability in a manner similar to AutoValue. Our current data flow looks something like this: A background Service subscribes to an RxStore which lazily instantiates a network client and downloads fresh data in JSON. This is done on a schedule or from a push alert. We then stream the JSON data to disk. We use the streaming API rather than saving the JSON as a single object because it prevents us from needing to instantiate value objects over one megabyte into memory. Now when the UI needs data, it subscribes to immutable data from a data store that is backed by caches in memory ( Guava ) and on disk. We only instantiate a network client if disk values are not present or if the format has changed since the last save. Data flows unidirectionally from persistent storage to UI and never directly from the network to our UI. This unidirectional data flow means that 99 percent of subscriptions to data store observables will never have to hit anything but disk values. We will continue to explore other methods such as FlatBuffers for serializing data for disk storage; however, we are generally pleased with our current results. A relaunch of our app offers users a full view of the home page in under two seconds. Reflection can cause significant performance issues on Android, especially for large, data-driven apps. For this reason, it should be avoided whenever possible, especially during app startup. Finally, we’d like to challenge our fellow Android developers working on performance issues: Tweet your startup times with the hashtag #StartupTrace. Our current time on a Nexus 5 is 1.6 seconds and always improving. For our typical users on newer devices (Nexus 6P, for example), relaunches take under 1.5 seconds to go from the home screen to all the news that’s fit to scroll (at 60 frames per second, of course). Interested in working on ambitious Android problems at The New York Times? Come join us. How we design and build digital products at The New York Times Code Android Android App Development Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-05-22"},
{"website": "NewYork-Times", "title": "flash free video in 2016", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/flash-free-video-in-2016-77df1efebf56", "abstract": "Code Data Product and Design Workplace Culture Work with Us By SCOTT WOLYNSKI and FLAVIO RIBEIRO At the beginning of this year, we officially turned off Flash support for VHS, the New York Times video player. We now use HTML5 video technology for all video playback on desktop and mobile web browsers. Flash was a very powerful and popular technology in its day but it has waned over the years as browsers have embraced the open standard of HTML5. Throughout the second half of 2015, Chrome, Firefox and Safari also began blocking the Flash plugin from automatically loading content unless users gave their permission. In order to continue providing a quality video experience for our viewers, switching exclusively to HTML5 video became necessary. Video has become a critical part of storytelling at The New York Times, and it has seen tremendous growth over the past few years. With this growth, as well as a new company-wide focus on video, we decided to build our own video player last year rather than continuing to use third-party solutions. There were many reasons for the move, but primarily we wanted to own the entire video experience in-house in order to focus on our needs and values. Performance, premium video quality and ability to customize the experience were our primary concerns. With video used in both articles and in unique, custom experiences , we have a diverse set of requirements. We wanted to give the newsroom a flexible, extensible player with a core foundation so they could focus on creating the experience. With this aim, we built a JavaScript wrapper around a video element that could either be an HTML5 video element or a Flash OSMF video object. For extensibility, we included a light, event-driven plugin system. When we first developed the player, Flash was still the dominant technology for publishers. This was largely because most of the ad inventory was still in Flash. VPAID ads were almost exclusively created with Flash, and advertisers preferred to deliver their ads in a VPAID wrapper so they could add their own tracking. Another reason we needed Flash was to play legacy content. Most of our older content (stretching back to 2006 on our earlier website ) was encoded with On2 VP6, which requires Flash. Lastly, we needed Flash in order to support our live content for breaking news and live events. Our live feeds are delivered using HLS Adaptive Streaming, so for browsers that don’t natively support HLS, we used the Flashls project to support HLS via a Flash OSMF player. For newly encoded video that wasn’t ad-supported and not live, we were free to use HTML5 video. This allowed stories that weren’t ad-supported to take advantage of the performance we were getting from HTML5 video while we could still support the business. These HTML5 experiences include our more visual story experiences where video enhances a larger feature story like in “ Ten Years After Katrina ” or the video for “ Bieber, Diplo and Skrillex Make a Hit .” In these instances, we found HTML5 video more performant and easier to work with for the customization the newsroom needed. As we saw the industry move toward HTML5 video, we knew we wanted to get ahead of it. The browsers blocking Flash really hastened our efforts. We needed to support legacy, VPAID and live content with an HTML5 player to give our users a seamless video experience. Legacy Content To support our legacy content, we re-encoded and republished all of our old content, creating both MP4 and WebM renditions with different resolutions and bitrates. We also created HLS renditions with six different levels, enabling us to serve our on-demand videos with adaptive streaming. This was a large effort that we were only able to do with the support of the business. HTML5 VPAID To support HTML5 VPAID content, we updated our ad integration and made our player VPAID 2.0 compliant for HTML5. Then we approached our ad vendors and requested HTML5 VPAID ads to start the certification process. We had some hiccups along the way, but the vendors worked with us. We both made adjustments to our code to make everything work as required to give users a good ad experience. We needed to be able to resize and move the VPAID ads so we wouldn’t get any collision between our controls and any VPAID controls within the ad. The volume and mute controls didn’t work across the board; however, this was fixed. We also ran into playback state synchronization issues with some HTML5 VPAID ads. If a user paused or played the ad with the in-ad controls but the ad didn’t trigger the AdPaused and AdPlaying VPAID events, then the player didn’t accurately reflect the state. The VPAID specification only required those events to be called in response to method calls to pauseAd and resumeAd : VPAID 2.0 Spec Excerpt — Section 3.3.17 Page 31 — “The AdPaused and AdPlaying events are sent in response to the pauseAd() and resumeAd() method calls, respectively, to confirm that the ad has either paused or is playing.” Since the ad can be paused or resumed from various vectors in addition to the pauseAd() and resumeAd() functions, this leaves no way to ensure synchronization of the playback state between the player and the advertisement. We recommended to the IAB Video Group that usage of the AdPaused and AdPlaying events should be extended. The events should be triggered when the playback state of the ad changes — regardless of what function initiated the change of state. This way, a video player can confidently maintain playback state with a VPAID ad. We’re hoping that change makes it into the next version of the specification to improve the ad experience everywhere. All the vendors were HTML5 VPAID certified, and we are now trafficking HTML5 VPAID content from Sizmek, DoubleClick and Innovid. Live For live support in HTML5, we investigated moving to MPEG-Dash by integrating with ShakaPlayer or Dash.js , but then HLS.js was released . HLS.js allowed us to use HLS in any browser that supports MediaSource Extensions. HLS.js integration with VHS was smooth and took less than a week. With HLS.js, we didn’t have to change our current live feed to support HLS adaptive streaming. We’re still exploring whether MPEG-Dash will improve the video experience in browsers that don’t support HLS natively. For now, using HLS.js allows us to retire Flash support sooner. From here, we want to expand our support of adaptive streaming. We’ll widen our usage of HLS.js to our on-demand content library on browsers that do not support HLS natively. That will enable us to take advantage of adaptive streaming on all our content, in all platforms and improve video quality and performance. We also have plans to expand and enhance our plugin system so we can extract all our business logic and open source our core player. We’re excited to keep improving the player and can’t wait to see what new experiences are built with it next. If you’re a senior iOS engineer, come work with us to extend The New York Times video experience. How we design and build digital products at The New York Times Code Html5 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-05-22"},
{"website": "NewYork-Times", "title": "how to build a timesmachine", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/how-to-build-a-timesmachine-f14e6c855fa5", "abstract": "Code Data Product and Design Workplace Culture Work with Us By JANE COTLER and EVAN SANDHAUS At the beginning of this year, we quietly expanded TimesMachine , our virtual microfilm reader, to include every issue of The New York Times published between 1981 and 2002. Prior to this expansion, TimesMachine contained every issue published between 1851 and 1980, which consisted of over 11 million articles spread out over approximately 2.5 million pages. The new expansion adds an additional 8,035 complete issues containing 1.4 million articles over 1.6 million pages. Creating and expanding TimesMachine presented us with several interesting technical challenges, and in this post we’ll describe how we tackled two. First, we’ll discuss the fundamental challenge with TimesMachine: efficiently providing a user with a scan of an entire day’s newspaper without requiring the download of hundreds of megabytes of data. Then, we’ll discuss a fascinating string matching problem we had to solve in order to include articles published after 1980 in TimesMachine. Before TimesMachine was launched in 2014, articles from the archive were searchable and available to subscribers only as PDF documents. While the archive was accessible, two major problems in implementation remained: context and user experience. Isolating an article from the surrounding content removes the context in which it was published. A modern reader might discover that on July 20, 1969, a man named John Fairfax became the first man to row across the Atlantic Ocean . However, a reader absorbed in The New York Times that morning might have been considerably more impressed by the front page news that Apollo 11, whose crew contained Neil Armstrong, had just swung into orbit around the moon in preparation for the first moon landing. Knowing where that John Fairfax article was published in the paper (bottom left of the front page) as well as what else was going on that day is much more interesting and valuable to a historian than an article on its own without the context of other news of the day. We wanted to present the archive in all its glory as it was meant to be consumed on the day it was printed — one issue at a time. Our goal was to create a fluid viewing experience, not to force users to slowly download high resolution images. Here’s how we did that. Our digitized print archive is big, containing terabytes of high-resolution page scans. Even for a single issue, the storage requirements are appreciable. The May 22, 1927 issue announcing the success of Charles Lindbergh’s pioneering trans-Atlantic flight consists of 226 pages which require nearly 200 megabytes of storage. When we built TimesMachine, we knew that there was no way we could expect users to sit through multi-hundred-megabyte downloads in order to browse a single issue. We needed a way to load just the parts of an issue that a user is looking at. We found an answer from a somewhat unexpected quarter and now, when you load that 200 megabyte Lindbergh issue in your browser, the initial page load requires the transmission of just a couple of megabytes. We achieve this by using mapping software to display each issue. Like the pages of a scanned newspaper, a digital map is just a really big image. The technique most often used to display digital maps (and the same technique we employ for TimesMachine) is image tiling. With image tiling, a large image is broken down into a myriad of small square images, or “tiles,” computed at a variety of zoom levels. Clever software then runs in the browser and loads only those tiles that correspond to the region of the image the user wants to see. Numerous open source software libraries have been created to make and display such tiles (we used GDAL for tile generation and leaflet.js for display). All we had to do was adapt these libraries to show you a newspaper. To do this we created a processing pipeline called The TimesMachine Publisher. Here’s how it works. For a given issue, the pipeline takes in three inputs: high-resolution scans of pages from microfilm, XML files of article metadata, and INI files describing the geometric boundaries of every article on every page. The pipeline first stitches the pages together into one large virtual image. The coordinates of every article on every page are then projected from cartesian (x, y) coordinates into geographic (latitude and longitude) coordinates. These projected coordinates are combined with article metadata into a large JavaScript object describing the contents of a complete issue. The large virtual image is then cut up into thousands of 256×256 pixel tiles computed at several zoom levels. All of this data is uploaded to a content distribution network (CDN). Whenever a user requests a day’s paper in TimesMachine, the client- side software downloads the JSON object describing the paper’s contents and requests only those tiles necessary to display the portion of the paper that fits into the user’s viewport. Additional data is loaded only when the user pans or zooms. Using this approach, TimesMachine delivers any day’s newspaper to the client quickly and efficiently. We encountered a fascinating issue in our attempt to expand the number of issues in TimesMachine. Initially, TimesMachine contained only those articles published between 1851 and 1980. The exclusion of data from after 1980 stems from an interesting historic quirk of our archive. Starting around 1981, The Times began keeping an archive of the complete digital text of every article published in print. In order to expand TimesMachine beyond 1980 and include links to the full text, we needed to know how our scanned print archive and our digital text archive aligned. Here is how we figured this out. The first step was to run optical character recognition (OCR) on articles in the scanned print archive to transcribe the text as cleanly as possible. We used tesseract-ocr for this. Here’s an example of some nicely-OCRed text: After doing this for every article in a single day’s issue, we ended up with a bucket of scanned print articles OCRed with tesseract, and a bucket of articles from the full text archive. We then had to figure out which articles matched up between these two buckets, which was an interesting process. Because an OCRed article is seldom an exact match for its full text counterpart, we could not align articles by simply testing for string equality. Instead, we used fuzzy string matching. Our approach was applied one issue at a time and relied on a technique known as “shingling.” Using shingling, we transformed the text of articles in both datasets into a list of tokens, and then turned the list of tokens into a list of n -token sequences called “shingles.” We’ll illustrate with this quote by Abraham Lincoln: This is our full text. We tokenize it by splitting it into a list of words separated by spaces. The string “secret” is considered a token in the full text. Now we convert the list of tokens into a list of “shingles,” which are sequences of tokens. If we use a shingle size of 4, we end up with the following: 5 lists of tokens. (As you can see, the contents of the lists overlap like shingles on a roof.) When we generate the list of shingles for every article in the full text digital archive, we get something that looks like this: It is a reasonable hypothesis that sequences of words from an OCRed article will overlap a fair amount with sequences of words in that same article in the full text archive. We want a list of articles that contain each shingle so we can narrow down our options. Iterating through the above list, we can transform our data into the following hash table: Now that we have a mapping of all the shingles appearing in a given issue to all the full text articles from that issue containing each shingle, we repeat the first part of the process with the OCRed text, getting a list of shingles for each article. Let’s say OCRed article_A consists of shingle_2 and shingle_5. We can use the table above to generate a list of article candidates that might be a “match” with article_A. By looking up shingle_2 and shingle_5 in the table, we conclude that article_1, article_2, article_2 and article_5 are all potential matches for article_A. This greatly reduces the problem space. Now, instead of having to compare every OCRed article in an issue to every full text article in an issue, which could involve tens of thousands of computationally expensive comparisons, we need only compare a short list. This ends up reducing the number of comparisons by several orders of magnitude. To quantify the difference between the OCRed data and the full text articles, we used the Python difflib library. It gave us a nice, clean result: From this particular example, it is clear that OCRed article_A is most likely the same article as full text article_1. Using this process, we could match approximately 80 percent of the articles. The remaining 20 percent did not have clear enough distinctions in scores, which required us to be a little more clever. In a perfect world, the relationship between our two buckets of articles would have been one-to-one, but in this world, it was actually many-to-many. Some full text articles were represented as multiple regions in the scanned archive, and some single regions in the scanned archive corresponded to multiple items in the full text archive. We reconciled the disparity by splitting the data into paragraphs and carrying out a similar process to the one described above, on the paragraph level. We ended up with a near-perfect, many-to-many matching of zones to the full text archive which is wonderfully searchable. You can check it out by exploring the entire Times archive at timesmachine.nytimes.com . How we design and build digital products at The New York Times Code Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-05-22"},
{"website": "NewYork-Times", "title": "our tagged ingredients data is now on github", "author": ["The NYT Open Team"], "link": "https://open.nytimes.com/our-tagged-ingredients-data-is-now-on-github-f96e42abaa1c", "abstract": "Code Data Product and Design Workplace Culture Work with Us By ERICA GREENE and ADAM MCKAIG Since publishing our post about “ Extracting Structured Data From Recipes Using Conditional Random Fields ,” we’ve received a tremendous number of requests to release the data and our code. Today, we’re excited to release the roughly 180,000 labeled ingredient phrases that we used to train our machine learning model. You can find the data and code in the ingredient-phrase-tagger GitHub repo. Instructions are in the README and the raw data is in nyt-ingredients-snapshot-2015.csv . There are some things to be aware of before using this data: The ingredient phrases have been manually annotated by people hired by The New York Times, whose efforts were instrumental in making the success of our model possible. The data can be inconsistent and incomplete. But what it lacks in quality, it makes up for in quantity. There is not a tag for every word and there are sometimes multiple tags per word. We have spent little time optimizing the conditional random fields (CRF) features and settings because the initial results met our accuracy needs. We would love to receive pull requests to increase the accuracy further. How we design and build digital products at The New York Times 5 Code Data Science 5 claps 5 Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Written by We’re New York Times employees writing about workplace culture, and how we design and build digital products for journalism. How we design and build digital products at The New York Times. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking. Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. Explore If you have a story to tell, knowledge to share, or a perspective to offer — welcome home. It’s easy and free to post your thinking on any topic. Write on Medium About Help Legal Get the Medium app", "date": "2017-05-22"}
]